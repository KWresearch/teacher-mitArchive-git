MIT OpenCourseWare
http://ocw.mit.edu 

5.74 Introductory Quantum Mechanics II

Spring 2009 


For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

Andrei Tokmakoff, MIT Department of Chemistry, 2/13/2007 

2-1 

2.1.  TIME-DEPENDENT HAMILTONIAN 

Mixing of eigenstates by a time-dependent potential 

For  many  time-dependent  problems,  most  notably  in  spectroscopy,  we  often  can  partition  the 
time-dependent  Hamiltonian  into  a  time-independent  part  that  we  can  describe  exactly  and  a 
time-dependent part  

+ ( )
H H  V t
= 
0

 

(2.1) 

Here  H 0  is  time-independent  and  V t( )   is  a  time-dependent  potential,  often  an  external  field. 
Nitzan,  Sec.  2.3.,  offers  a  nice  explanation  of  the  circumstances  that  allow  us  to  use  this 
approach.  It  arises  from  partitioning  the  system  into  internal  degrees  of  freedom  in  H0 and 
external  degrees  of  freedom  acting  on  H0.  If  you  have  reason  to  believe  that  the  external 
Hamiltonian can be  treated classically,  then eq.  (2.1)  follows  in a straightforward manner.   Then 
there  is  a  straightforward  approach  to  describing  the  time-evolving wavefunction  for  the  system 
in terms of the eigenstates and energy eigenvalues of H 0 . We know 

The state of the system can be expressed as a superposition of these eigenstates: 

H n   E= 
0 

n

n . 

ψ( t )  = ∑ n ( ) 
c t n
n 

 

The TDSE can be used to find an equation of motion for the expansion coefficients  

Starting with 

c t = k ψ( t ) 
k ( ) 

∂ ψ −i
=  H ψ 
(cid:61)
∂t 
∂ c tk (  ) = −
∂t 

i k H  
ψ( )
t  
(cid:61)

inserting ∑ n n = 1 
n

i
= −  ∑  k H n c t  
n( )
(cid:61)
n 

(2.2)

(2.3)

(2.4)

(2.5)

(2.6)

(2.7)

substituting eq. (2.1) we have: 

∂ c t( ) 
k 
∂t 

( ) ) n c t
( 
( )
k H   V t
 
+ 
n
0 

i
∑= − 
(cid:61)  n 
i
∑ ⎣  n δkn +  kn ( ) ⎤⎦  n ( )
⎡ E
c t
 V t
= − 
(cid:61) n 

 

 

∂c t( ) +
k 
∂t 

i E c t  
( )  −
=
k
k
 
(cid:61) 

i  V   t c t  . 
(cid:61) ∑ kn 
( ) 
( ) 
n 
n 

c
m

t( ) = e−  m
iE t  (cid:61)

( ) , 
b t
 
m 

or, 

If we make a substitution 

2-2 

(2.8)

(2.9)

(2.10)

that 

= c
k 

which  defines  a  slightly  different  expansion  coefficient,  we  can  simplify  considerably.  Notice 
2
2 
b t( )
( ) 
.  Also, bk ( ) = ck ( 0 ) .
t
 
0 
k 
“trivial”  part  of  the  time-evolution,  the  time-evolving  phase  factor  for  state m.  The  reasons will 
k ( )
b t
become clear  later when we discuss  the  interaction picture. It  is easy  to calculate 
 and  then 

In  practice  what  we  are  doing  is  pulling  out  the

add in the extra oscillatory term at the end.  Now eq. (2.9) becomes  
e− iEk t (cid:61)  ∂bk = −
i  V t e− iEn t  b t
∑ kn ( ) 
n ( )
(cid:61) 
(cid:61) n 
∂t 

 

or 

b
i(cid:61) ∂
∑V t
kn ( ) e− iωnk t b t
n ( ) 
 
k = 
t
∂ 
n 

 

(2.11)

(2.12)

This equation  is an exact  solution.  It  is a  set of coupled differential equations  that describe how 
probability  amplitude  moves  through  eigenstates  due  to  a  time-dependent  potential.    Except  in 
simple  cases,  these  equations  can’t  be  solved  analytically,  but  it’s  often  straightforward  to 
integrate numerically. 

2-3 

Resonant Driving of Two-level System 

As an example of  the use of  these equations,  let’s describe what happens when you drive a  two-
level system with an oscillating potential. 

V t(  ) = V cos ωt V= f

( ) 
 
t

(2.13) 

Note: This is what you expect for an electromagnetic field interacting with charged particles, i.e. 
dipole transitions.  In a simple sense, the electric field is 

E t (  ) = E0  cosωt 

For a particle with charge q in a field E , the force on the particle is 

which is the gradient of the potential 

F q= E 

(2.14) 

(2.15) 

∂V
F = − 
x
∂x 

= qE  ⇒  V = −qE x
x 
x

 

(2.16)

qx is just the  x  component of the dipole moment μ.  So matrix elements in V look like: 

More generally, 

k V t  
|
( ) |

 (cid:65)  = −q x
 (cid:65)
E   k x   cos
|
|

 ωt 

V

E μ.
= − ⋅ 

We’ll look at this a bit more carefully later. 

So, 

V t( ) = V cosωt = − E0  ⋅μcos ωt 
V t( ) = V cos ωt = − E ⋅μ  cos ωt
k (cid:65) 
k (cid:65) 
k (cid:65) 
0 

. 

We  will  now  couple  our  two  states  k   and  (cid:65)   with  the 

oscillating  field.  Let’s  ask  if  the  system  starts  in  (cid:65)   what  is  the 

probability of finding it in  k  at time t ? 

(2.17) 

(2.18) 

(2.19)

The system of differential equations that describe this situation are: 

i(cid:61)

∂ 
∂t

Or more explicitly 

( ) e 
t
− iωnk t

∑ n 
b t( ) = 
( ) 
b t V 
k 
kn 
n 
∑ n ( )  kn 
b t V  e− iωnk t × 
= 
n 

1 ( 
+ ω ) 
tω + e i
e− i
t
2 

⎡  i (ωk(cid:65) −ω)t
(cid:61) (cid:5) 
e 
i b =  b V 
1 
2  (cid:65)  k (cid:65)  ⎢⎣ 
k 
(cid:61) (cid:5) 
b V(cid:65) 
i b(cid:65)  =  2 
1
(cid:65)(cid:65) 

i (ωk(cid:65) +ω)t ⎤ 
⎡ei
tω + e i
t ⎤
− ω
+  b V 
+ e 
1 
kk  ⎣
⎦ 
⎥⎦ 
2  k 
tω ⎤ + 1  b V   ⎡ei (  (cid:65)k −ω)t + ei (ω(cid:65)k +ω)t ⎤
⎡ei
t + e− i
ω 
ω
⎣
⎦ 
2  k  (cid:65)k  ⎢⎣ 
⎥⎦ 
or 
− i (ωk(cid:65) +ω)t 
⎡
⎢ e 
⎣

− i (ωk(cid:65) −ω)t ⎤ 
+ e 
⎥
⎦ 

2-4 

(2.20) 

(2.21) 

Two of these terms can be dropped since (for our case) the diagonal matrix elementsVii = 0 .  We 
also make  the  secular  approximation  (rotating  wave  approximation)  in  which  the  nonresonant 
terms  are  dropped.  Whenωk (cid:65)  ≈ω,  terms  like  e i
 or  ei (ωk(cid:65) +
ω)t
  oscillate  very  rapidly  (relative 
t
± ω
−1
) and  so don’t contribute much  to change of cn .   (Remember  that ωk (cid:65)   is positive). So we 
to Vk (cid:65) 
have: 

b(cid:5)  =
k 

b(cid:5)  =
(cid:65) 

−i b V  ei (ωk(cid:65) −ω)t 
(cid:65) 
k (cid:65)
2(cid:61)
−i b V  e− i (ωk(cid:65) −ω)t 
(cid:65)k
k 
2(cid:61)

Note  that  the  coefficients  are  oscillating  out  of  phase 
with one another. 

Now if we differentiate eq. (2.22): 
−i ⎡b V  ei (ωk(cid:65) −ω)t + i (ω  −ω) b V  e i (ωk(cid:65) −ω)t 
(cid:5) 
2(cid:61) ⎣⎢ (cid:65) 
k (cid:65) 
(cid:65) 
k (cid:65)
k (cid:65) 

(cid:5)(cid:5)
b =
k 

⎤ 
⎦⎥ 

(2.22)

(2.23)

(2.24)

Rewrite eq. (2.22): 

b(cid:65)  = 

2i(cid:61) b(cid:5)
k e− i (ωk(cid:65) −ω)t 
Vk (cid:65) 

and substitute (2.25) and (2.23) into (2.24), we get linear second order equation for bk . 

(cid:5)(cid:5)
(cid:5) 
bk  − i (ωk (cid:65)  −ω) bk  + 

2 

Vk (cid:65) 
4(cid:61)
2

b  = 0 
k

This is just the second order differential equation for a damped harmonic oscillator: 

ax(cid:5)(cid:5) + bx(cid:5) + cx = 0 

x = e −(b a t
2  )
 ( A cos μt + B sin μt ) 
1 
1 
⎡⎣4ac − b 2 ⎤⎦
2 
a 
2

μ= 

2-5 

(2.25)

(2.26)

(2.27) 

(2.28) 

With a little more work, and remembering the initial conditions  b  ( 0 ) = 0 and b(cid:65)  0  = 1 , we find
( )
k

Pk 

= b t  2  =
k  ( )

2 

V 
(cid:65) 
k 
( 
ωk (cid:65)  −ω)
+ (cid:61)
2 

2

Vk (cid:65) 

sin  Ω t 
2
r

2 

Where the Rabi Frequency 

Ω =
R 

1  ⎡ Vk (cid:65)  + (cid:61)  (ωk (cid:65)  −ω) ⎤
1
2
2
2 
2(cid:61) ⎣ 
⎦ 

2 

Also, 

P(cid:65) = −1  bk 

2

(2.29)

(2.30)

(2.31) 

The  amplitude  oscillates  back  and  forth  between  the  two  states  at  a  frequency  dictated  by  the 
coupling  between  them.  [  Note  a  result  we  will  return  to  later:  Electric  fields  couple  quantum 
states, creating coherences! ] 

An  important  observation  is  the  importance  of  resonance  between  the  driving  potential 
and  the  energy  splitting  between  states.  To  get  transfer  of  probability  density  you  need  the 
driving field to be at the same frequency as the energy splitting.  On resonance, you always drive 
probability amplitude entirely from one state to another. 

2-6 

The  efficiency  of  driving  between  (cid:65)   and  k   states  drops  off  with  detuning.    Here  plotting  the 
maximum value of  Pk (cid:65)  as a function of frequency: 

Readings 

This lecture draws from 

1.	

2.	

C. Cohen-Tannoudji, B. Diu, and F. Lalöe, Quantum Mechanics, Vol. 2. (Wiley-
Interscience, Paris, 1977) 

J. J. Sakurai, Modern Quantum Mechanics. (Addison-Wesley, Reading, MA, 1994). 

Andrei Tokmakoff, MIT Department of Chemistry, 2/13/2007 

2.2.  QUANTUM DYNAMICS 

2-7 

The  motion  of  a  particle  is  described  by  a  complex  wavefunction  ψ( r t,  )    that  gives  the 
probability  amplitude of  finding  a particle  at point  r   at  time t .  If we know ψ( r t , 0 ) , how does 
it change with time? 

t

>

?
ψ( r t, 0 ) ⎯⎯→ ψ( r t,  ) 
t0 
We will use our intuition here (largely based on correspondence to classical mechanics).  We are 
seeking  an  equation  of  motion  for  quantum  systems  that  is  equivalent  to  Newton’s  (or  more 
accurately Hamilton’s) equations for classical systems. 
We  start  by  assuming  causality:  ψ( t0 ) precedes  and  determines ψ  t 
( ) 
.    So  will  be  
ψ( r t ,  ) .  Also,  we  assume  time  is  a  continuous 
deriving  a  deterministic  equation  of motion  for 
parameter:   

(2.32)

 

lim ψ( t )  =
ψ( t )0
t
t0→ 
Define an operator that gives time-evolution of system.   
0 ) ψ( t )0 
ψ( t )  U t t
= ( 
 
, 
This  “time-displacement  operator”  or  “propagator”  is  similar  to  the  “space-displacement 
operator” 

(2.33)

(2.34)

ψ( r ) 
which moves a wavefunction in space.  
We  also  say  that  U   does  not  depend  on  the  particular  state  of  the  system ψ  .  This  is 

= e (  − 0 )
ik r  r 

ψ( r )0 

(2.35)

necessary for conservation of probability, i.e. to retain normalization for the system.  If 

(
) 
ψ  t0  = a1 

ϕ1 ( t ) 
0 

+ a2 

ϕ2  ( t )
0 

then 

ψ( )t

= ( 
0 ) ψ( t )0 
 U t t
 
,
= ( , 0 ) 1 
2  (
+ ( , 0 )  2 
) 0 
1 (
) 0 
  U t t
  a  ϕ  t
U t t
  a  ϕ  t 
+ 2  ( )
=  1 ( ) 
 
a t
a t
 
ϕ1 
ϕ2 

(2.36)

(2.37)

i ( )
This is a reflection of the importance of linearity in quantum systems. While  a t
a ( )
i  0 

equal to 

,

∑

n

2

  = ∑ a t
n ( ) 
n (
a t
n 

)0 

2 

2-8 

 typically not 

(2.38)

Properties of U(t,t0) 

1) 	 Unitary. Note  that  for eq.  (2.38)  to hold and  for probability density  to be conserved, U must 

be unitary 

P =	 ψ( t ) ψ( t ) = ψ( t0 ) U U
†

ψ( t )0 
 

(2.39)

which  holds  only  ifU †  = U −1 .  In  fact,  this  is  the  reason  that  equates  unitary  operators  with 

probability conservation. 

2)  Time continuity: 

( ,  ) = 1 . 
U t t

(2.40) 

3) 	 Composition  property.  If  we  take  the  system  to  be  deterministic,  then  it  stands  to  reason 

that  we  should  get  the  same  wavefunction  whether  we  evolve  to  a  target  time  in  one  step 
( t → t )  or multiple steps ( t → → t
) :
t 
0 
2	
0
1

2 

( 1 ,  0 )	
( 2 ,  0 ) = ( 2 ,  1 )
 t U t
U t
 
 t
U t
t
 

  Note, since U acts to the right, order matters:  

ψ(

)t2 

= ( 2 ,  1 )
( 1 ,  ) ψ( t0 ) 
t U t
t
 
U t
 
0 
 ) ψ(
( 2
) 
 t
U t
 
t1 
,
=	
1

(2.41)

(2.42)

Equation  (2.41)  is  already  very  suggestive  of  an  exponential  form.    Furthermore,  since  time 

is  continuous  and  the  operator  is  linear  it  also  suggests  what  we  will  see  that  the  time 

propagator is only dependent on a time interval 

and 

(  ,
U t
1

t

0

(  1  − )	
) = 
  U t
 
  t
 0 

( − )	
( − t U t
U t( − t ) = U t
) 
 
  t
 
2
0 
2
1
1
0 

2-9 

(2.43)

(2.43

4) 	 Time-reversal.  The inverse of the time-propagator is the time reversal operator.  From eq. 

(2.41): 

(  0 ,  )  1 
(  ,	 0 )
 U t
U t t
t =

) 
(  0 
(
) 
 t
, 0  = U t
∴U −1  t t
 
. 
, 

 

(2.32)

	(2.33)

Finding an equation of motion for U 

Let’s  find  an  equation  of motion  that  describes  the  time-evolution  operator  using  the  change  of 
the system for an infinitesimal time-step,δt : U t(  0  +δ t t
, 0 ) 
 

lim U t(  0  +δt t
, 0 ) = 1	
 
δ t→0 

(2.34)

(  +δt t, 0 )  will be  linear  in 
t )  and 
(  0 ,  0 
U t0 
We expect  that  for  smallδt ,  the difference between  U t
δt  (This is based on analogy to how we think of deterministic motion in classical systems)   

i ˆ 
(  0 ,  ) −  Ω ( t0 )δ t	
,  )
(  0
 0  = U t
U t +δ t t
 t
 0 

(2.35)

We  take  Ωˆ   to  be  a  time-dependent  Hermetian  operator.    We’ll  see  later  why  the  second  term 
must be imaginary.  So, now we can write a differential equation for U.  We know that 

(  +δ t t U t t  
(	 +δ t t, 0 ) = U t  
,  )
(  , 0 ) . 
U t  

(2.36) 

Knowing  the  change  of  U during  the  period  δt allows  us  to write  a  differential  equation  for  the 
(  , 0 ) .  The equation of motion for U is 
time-development of U t t
 

( 
d U t t
, 0 
dt 

) 
 

) = lim 
( 
0 ) 
(
,  − U t t
U t +δt t
 
 
, 0 
δt 
δt→0 
U t(  +δt t
 ) − 1  U t t
( , 0 
, 
= lim  ⎣⎡ 
⎦⎤ 
δt 
δt→0 

 ) 

Where I have substituted eqn. (2.35) in the second step. So we have:   
0 ) = − Ω ˆ 
 
( ,  ) 
i U t t
 0

∂ ( 
U t t
,
∂t 

2-10 

(2.37) 

(2.38)

You  can  now  see  that  the  operator  needed  a  complex  argument,  because  otherwise  probability 
density  would  not  be  conserved  (it  would  rise  or  decay).    Rather  it  oscillates  through  different 
states of the system.   

We note  that  Ωˆ  has units of  frequency.  Since  (1) quantum mechanics  says  E = (cid:61)ω and 
(2) in classical mechanics the Hamiltonian generates time-evolution, we write 

Ωˆ  = 

Hˆ 
(cid:61)

Where  Ωˆ can be a function of time.  Then 

∂
=  ˆ 
( , 0 )  HU t t
, 0 ) 
(
i(cid:61) U t t
 
 
∂t 

(
Multiplying from right by  ψ  t0 

)

gives the TDSE

∂i(cid:61) ψ  = Hˆ ψ 
∂t 

(2.39)

(2.40)

(2.41)

We are also interested in the equation of motion for U † which describes the time-evolution of the 
†  ( ,  0
U t t ) 
conjugate  wavefunctions.  Following  the  same  approach  and  recognizing  that 
  acts  to

the left:   

we get 

ψ( t ) 

= ψ( t0 ) U

†

( , 0 ) , 
t t
 

∂ 
−i(cid:61) U
∂t 

† 

( ,  ) = U
 t t
 
0

†

ˆ
( , 0 ) 
 t t H

 

 

(2.42)

(2.43)

Evaluating U(t,t0) for Time-independent Hamiltonian 

Direct integration of eqn. (2.40) suggests that U can be expressed as: 

) 
(
 
U t t
, 0  = exp

i 
⎡
( − 0 
−  H t
  t
 
⎢ 
⎣  (cid:61)

⎤
 ) 
⎥
⎦ 

Since  H  is an operator, we will define this operator through the expansion: 

iH ( −  ) 
iH 
1  − 
⎤ 
exp ⎡−
t0  ⎥ =  +  (cid:61) 
t
⎢  (cid:61) 
⎦ 
⎣

(

t

( 
−i ⎞ ⎣ H t
2  ⎡
t− 0 ) + ⎛ 
⎜  (cid:61)
⎟ 
⎠ 
⎝

  t
− 
2

2 
0 ) ⎤⎦ 
 

+… 

2-11 

(2.44)

(2.45)

Note  H commutes  at  all t .  You  can  confirm  the  expansion  satisfies  the  equation  of  motion 
forU . 

 

To evaluate U for the time-independent Hamiltonian, we expand in a set of eigenkets: 
∑
n 

H n = E  n  
n 

n n  = 1 

(2.46)

So we have 

and 

(
U t t
, 

) 0  = ∑ exp
( − 0
) (cid:61) ⎤⎦ n n  
 
− H t
  t
⎡⎣ i
 
 
/
n 
= ∑ n 
n ( − 0 ) (cid:61) ⎦⎤
 
exp ⎡−iE
 
 
t
n 
t
/ 
⎣ 
n 

ψ( t )0 
ψ( ) 
( , 0 )
 
t  = U t t
)t0  exp ⎡ −i E  t
( −  )⎤ 
= ∑ n nψ(
 
 t
(cid:8)(cid:11)(cid:9)(cid:11)(cid:10) ⎢⎣ (cid:61) 
0  ⎥⎦ 
n 
n 
n (
)0 
c t
 
= ∑ n c   t
( )
 
n 
n 

Expectation values of operators are given by 

A t( ) 

= ψ( t ) Aψ( t )
) 
, 0  ψ(
) 
= ψ(
(
)0 
(
, 0  U t t
 
 A
t U  t t
†

t0 

)

(2.47) 

(2.48) 

(2.49)

ψ  t0  = ∑ cn  n , we showed in eq. 1.48 that
(
)
For an initial state 
n 

−i n ( t
 0 )ω −
t
  n n cn 

t0 )ω − 
+ i m ( t
  m A n e

A = ∑ cm 
*  m m e
,n m  
( −  ) 
c c A  e  − i 
ωnm t
t0
∑ m n   mn  
* 
= 
,n m  
∑ m
*  ( ) 
( ) 
c
 t A  
t c
= 
n 
mn 
,n m  

which is Tr(ρ(t)A).  The correlation amplitude  βψ( t )  was given in eq. 1.45. 

2-12 

(2.50)

2-13 

Evaluating the time-evolution operator: Time-dependent Hamiltonian 

At  first  glance  it  may  seem  straightforward  to  deal  with.  If  H is  a  function  of  time,  then  the 
(cid:61) ∂ 
formal integration of  i U t H∂ =  U gives

−i ∫t
⎡
⎤
t H t  d
)
(
(
)′ 
t ′ 
U t t
 
exp 
, 0  = 
⎢
⎥ 
⎣ (cid:61) 0 
⎦

(2.51)

We would define  this exponential as an expansion  in a series, and substitute  into  the equation of 
motion to confirm it: 

(
U t ,

)t0

i ∫t
t 
1 
= − 
(cid:61) 
0 

(
)′ 
H t  dt

′

+ 

2 
i ⎞
1 
−
⎛
⎟ 
! ⎜
(cid:61)
2
⎝ 
⎠ 

t 
t 
∫ ∫t 
t
0 
0 

(
) 
(
) 
′ +…
dt dt H t  H t 
′ 
′′
′
′

 

(2.52)

Then if we know the eigenstates of H, we could use eq. (2.46) to express U as 
⎡ −i ∫t
t 
  ∑ n exp ⎢
)
(
U t t
, 0  = 
⎣ (cid:61) 0 
n 

⎤
)′ 
t ′⎥
t d
⎦ 

j (
E 

n 

(2.53)

However,  this  is  dangerous;  we  are  not  treating  H as  an  operator.  We  are  assuming  that  the 
(  ) ⎦⎤ 
( ′ ) 
Hamiltonians  at  different  times  commute! ⎡ H t
  H, 
′′ = 0 .  It  is  only  the  case  for  special
t
⎣ 
Hamiltonians with a high degree of symmetry, in which the eigenstates have the same symmetry 
at all  times.  This holds  for  instance  in  the case of a degenerate system,  i.e., spin ½ system, with 
a time-dependent coupling. Generally speaking this is not the case. 

Now,  let’s  proceed  a  bit more  carefully  assuming  that  the Hamiltonian  at  different  times 
does not commute. Integrate 

To give: 

∂ U t t
( 
, 0 
∂t 

) =

−i H t U t t
( 
( )
 
, 0 
(cid:61)

) 

i 
t d H τ U τ, t )
(
U t t, 0  = − ∫ τ  ( )
)  1 
( 
0 
(cid:61) t0 

(2.54)

(2.55)

This is the solution; however, it’s not very practical since 

( , 0 ) is a function of itself.  But we
U t t
can solve by iteratively substituting U into itself.  First Step: 

(
U t t0 
, 

)

i ∫t 
i ∫t
d H ( )τ  ⎡
t 
τ 
d H′
= −1 
1 
⎢ −
τ 
τ 
(cid:61) 
(cid:61) 
⎣ 
0 
0 
1  ⎛ −i ⎞  t d Hτ  ( ) + ⎛ −i ⎞ 2 
⎟ ∫
⎟ ∫ 
= + 
τ 
⎜
⎜
⎝ (cid:61)  ⎠ t0 
⎝ (cid:61) ⎠ 
t0 

t 

τ′ U τ,  )⎤
(
( 
) 
′ t0 
⎥⎦ 
τ τd H ( ) 
τ  H τ  U τ, t )
)
( 
(
∫ 
d  τ
′ 
′ 
′  0
t0 

2-14 

(2.56) 

Note  in  the  last  term of  this equation,  the  integration variable τ′ preceedsτ.  Pictorally,  the area 
of integration is 

Next Step: 

(
U t t
, 0 

1  ⎛ −i 
⎞  t d H τ
( )
) 
∫t 
  = + ⎜ 
τ
⎟
(cid:61) 
⎝
⎠ 
0
+ ⎛ −i ⎞ 2 
t dτ τd H′ τ 
( )
∫ 
⎟ ∫
τ 
⎜ 
⎝ (cid:61)  ⎠ 
t0 
t0 
+ ⎛ −i ⎞3 
t dτ τdτ′ τ′ d Hτ′′
⎟ ∫
∫ 
∫ 
⎜ 
⎝ (cid:61) ⎠ 
t0 
t0 
t0 

(
)
H τ′ 

τ  H τ′ H τ′′ U τ′′, t )
( ) 
( 
)
(
) 
(
0

(2.57)

From  this  expansion,  you  should  be  aware  that  there  is  a  time-ordering  to  the  interactions.  For 
the third term, τ′′ acts beforeτ′ , which acts beforeτ: t0 ≤τ  τ′ τ
≤ ≤ t . 
′′ ≤

Imagine  you  are  starting  in  state 

ψ0 

= (cid:65)   and  you  are  working  toward  a  target

state ψ = k .  The possible paths and associated time variables are: 

2-15 

(2.58)

The  expression  for  U describes  all  possible  paths  between  initial  and  final  state.   Each  of  these 
paths  interfere  in  ways  dictated  by  the  acquired  phase  of  our  eigenstates  under  the  time-
dependent Hamiltonian.  The solution for U obtained from this iterative substitution is known as 
the (positive) time-ordered exponential 
i ∫t
− 
⎡
t 
⎣⎢
(cid:61) 
0 
⎡ −i ∫t
t 
≡ Tˆ exp ⎢
(cid:61) 
⎣
0
n
= + ∑ −i 
∞ 
⎞
⎛
t dτn 
⎟ ∫ 
1 
⎜ 
(cid:61)
n =1 ⎝
⎠ 
t
0

d H ( )τ ⎤
τ 
⎦⎥
⎤
τ  ( )⎥
d H τ 
⎦ 
t d  Hτ1 
τd n … 
τ ∫t 
∫
t 
0 
0

τn H τn 1  … H (
)1
(
) 
( 
)
τ 
−

(
U t t
, 0 

)
  ≡ exp 
+ 

( Tˆ is known as the Tyson time-ordering operator.)  In this expression the time-ordering is: 

t0  τ1  τ2  →τ3  ....τn → t
→ → 
t0  →  … τ  τ′ τ 
′′ →  → 

(2.59)

So, this expression tells you about how a quantum system evolves over a given time interval, and 
it  allows  for  any  possible  trajectory  from  an  initial  state  to  a  final  state  through  any  number  of 
intermediate  states.  Each  term  in  the  expansion  accounts  for more  possible  transitions  between 
different intermediate quantum states during this trajectory. 

Compare the time-ordered exponential with the traditional expansion of an exponential: 

1 
+

∞  1  −i
⎛
∑ ⎜ 
=  n !  (cid:61)
⎝
n 1 

n
⎞  τ 
t d 
t 
n … ∫ 
⎟ ∫ 
⎠ 
t
t 
0
0

) 
τ  H τ  … H (
τ  (
) 
( 
)
d H 
τ
n
n −1
1 
1 

(2.60)

2-16 

Here  the  time-variables  assume  all  values,  and  therefore  all  orderings  for  H (
)τi  are  calculated. 
The areas are normalized by the  n !  factor.  (There are  n !  time-orderings of the τn   times.) 

( , 0 ) , which  has  the  equation  of
U t t
 
We  are  also  interested  in  the Hermetian  conjugate  of 

motion in eq. (2.43) 

∂	
†  (
U t t
, 
∂t 

) 
 
=

0 

+i U †  ( 
t t
, 0 
(cid:61)

)

( ) H 
 
t	

†  (	 , 0 ) 
If we repeat the method above, remembering that U t t
 acts to the left:   

ψ( t ) = ψ( t0 ) U †  ( t t
, 0 )	

 

then from 

†  (
) 
,	 0  = U †  ( t0 , t0 ) +
U t t	

i  ∫ d U  
t
)
( ) 
†  ( 
,τ H  τ 
τ  t 
(cid:61) t0 

) = exp
 

− 

( 
U t t
, 0 
†	

we obtain a negative-time-ordered exponential: 
i  ∫t
τ ⎤
⎡
t 
  dτH ( )
⎢⎣ (cid:61) 
⎥⎦ 
0 
n
i 
∞ 
⎞ 
⎛
τn 
1	 ∑  (cid:61)
d  ∫t0 
= +
τn
⎜
⎟
n =1 ⎝
⎠ 
Here the  H (
)τi  act to the left.   

t 
∫t
0 

τ2
∫t0 
d  − … 
τn  1 

) 
1  H  τ  … H (
(
dτ1H (
) 
) n 
τ
τ 
2 

(2.61)

(2.62) 

(2.63)

(2.64)

Readings 

This lecture draws from the following: 

1.	 Merzbacher, E. Quantum Mechanics, 3rd ed. (Wiley, New York, 1998), Ch. 14. 
2.	 Mukamel, S. Principles of Nonlinear Optical Spectroscopy (Oxford University Press, New 
York, 1995), Ch. 2. 
3.	 Sakurai, J. J. Modern Quantum Mechanics, Revised Edition (Addison-Wesley, Reading, MA, 
1994), Ch. 2. 

Andrei Tokmakoff, MIT Department of Chemistry, 2/22/2007 

2-17 

2.3.  	 SCHRÖDINGER AND HEISENBERG REPRESENTATIONS 
The  mathematical  formulation  of  the  dynamics  of  a  quantum  system  is  not  unique.    So  far  we 
have  described  the  dynamics  by  propagating  the  wavefunction,  which  encodes  probability 
densities.  This  is  known  as  the  Schrödinger  representation  of  quantum  mechanics.    Ultimately, 
since we can’t measure a wavefunction, we are  interested  in observables (probability amplitudes 
associated with Hermetian operators).  Looking at a time-evolving expectation value suggests an 
alternate interpretation of the quantum observable: 

ˆ 
( ) 
A t  

ˆ 
( ) 
( ) 
( ) 
t   A  
t  
0 
ψ 
ψ  ψ 
= 
= 
( 
( 
) 
ˆ
( )
( )
U A U  
0 
0 
† 
ψ 
ψ 
= 
) 
( ) ( 
ˆ
( ) 
U AU  
0 
0 
† 
ψ 
ψ 

=

ˆ
( ) 
U AU  
0 
† 
ψ 
) 

 

(2.65) 

The  last  two  expressions  here  suggest  alternate  transformation  that  can  describe  the  dynamics. 
These have different physical interpretations:  

1)  Transform the eigenvectors: ψ( t ) → U ψ  .  Leave operators unchanged. 

† ˆ
ˆ 
2)  Transform the operators: A t( ) → U AU .  Leave eigenvectors unchanged.   

(1) 	

(2) 	

Schrödinger  Picture:  Everything  we  have  done  so  far.    Operators  are  stationary. 
( , 0 ) 
Eigenvectors evolve underU t t
  .

Heisenberg Picture:  Use unitary property of  U  to transform operators so they evolve 
 
in  time.   The wavefunction  is stationary.    This  is a physically appealing picture, because 
particles move – there is a time-dependence to position and momentum. 

Let’s look at time-evolution in these two pictures: 

Schrödinger Picture 

We have talked about the time-development of ψ  , which is governed by 
∂i(cid:61) ψ  = H ψ 
∂t 

(2.66)



in  differential  form,  or  alternatively  ψ( t )  = U
( 
0 ) ψ( t )0 
t t
 
 
, 
∂A
= 0 .  What  about  observables?  For  expectation 
Schrödinger  picture,  for  operators  typically 
∂t 
Aˆ ( )t  =  ψ( )t 
Aˆ

  in  an  integral  form.    In  the  

values of operators 

tψ( ) 

:

2-18 

∂ 
i(cid:61) 
∂t 

Aˆ

ψ  + ψ 

+ 

⎡
∂ψ 
∂ψ
Aˆ 
ˆ 
( )  = i(cid:61) ⎢ ψ 
 
A t
∂t 
∂t
⎢
⎣ 
ˆ
= ψ A H ψ  − ψ H A  ˆ ψ 
ˆ
= ψ ⎡ A H, 
⎣
ˆ , 
A H ⎤
⎦

=  ⎡
⎣

⎤ψ
⎦ 

ˆA 
∂ 
t 
∂ 

⎤ 
ψ  ⎥

⎥
⎦ 

(2.67) 

Alternatively, written for the density matrix: 

 

ˆ
A t
( )  = i

∂ 
i(cid:61) 
∂t 

∂ 
( ˆρ)
(cid:61) 
 Tr A
 
t 
∂
⎛ ˆ  ∂
⎞ 
= i T(cid:61) r A   ρ
⎜
⎟
∂t 
⎝
⎠ 
( ˆ 
, ρ])
[ 
Tr  A H 
=
)
= Tr ( ⎣
ˆ
A H ⎤ ρ 
⎡  , 
⎦
If  Aˆ  is independent of time (as we expect in the Schrödinger picture) and if it commutes with H , 
it is referred to as a constant of motion.   

(2.68) 

Heisenberg Picture 

From eq. (2.65) we can distinguish the Schrödinger picture from Heisenberg operators:  

ˆ 
Aˆ 
( ) 
( ) 
A t( )  = ψ  t  ψ  t 

† ˆ
(
) 
(
= ψ  t0  U   AU  ψ  t0 

) 

ˆ
A t  ( )
= ψ  ψ 

H 

S 

S 

(2.69)

where the operator is defined as   

0 ) ˆ 
ˆ 
H  ( ) 
( 
( 
,  A U  t t
 = U †  t t
A t
 
, 
S 
ˆ
ˆ
) = A
A t(
H 
S 

0 

0 ) 
 

(2.70) 

2-19 

Also,  since  the  wavefunction  should  be  time-independent ∂ ψH 
Schrödinger and Heisenberg wavefunctions as 

t  0 
,  we
∂ = 

can
  relate  the 

ψS ( t ) = ( , 0 )
U t t 

ψH 

So, 

ψH 

U t t,  ψS ( t ) =
†  ( 
0 )
= 

ψS ( t0 ) 

 

In either picture the eigenvalues are preserved: 

Aˆ 
S  = ai
ϕi  S 
ϕi 
† ˆ	
U AUU  
= a U † 
†
i  ϕi  S 
ϕi  S
Aˆ 
H  = ai
ϕi 
ϕi  H 
H 

The time-evolution of the operators in the Heisenberg picture is: 

∂Aˆ 
H	
∂t	

=

+ U 
†

(U A U ) = 
† ˆ 
S 

† ˆ  ∂U 
∂U † ˆ 
∂ 
A U  U A 
S  + 
S 
∂t 
∂t 
∂t
ˆ 
A ⎞∂ 
⎛
i 
i 
† ˆ 
ˆ 
=  U H A U −  U A H U + ⎜ 
†
⎟
⎟
⎜
S 
S
(cid:61) 
(cid:61) 
t ⎠ H 
∂⎝
i ˆ 
i H Aˆ  −
A H H 
H  H 
H 
(cid:61)
(cid:61) 
i ⎡
−
⎣ A Hˆ , 
(cid:61)

⎤
⎦ H 

=	

=

The result:  	

i(cid:61) ∂ Aˆ 
ˆ , 
⎡ A H ⎤	
H  = ⎣
⎦ H 
∂t 

(2.71)

(2.72)

(2.73)

(2.74) 

(2.75)

ˆ 
SA 
∂ 
t 
∂ 

U 

is  known  as  the  Heisenberg  equation  of  motion.  Here  I  have  written H H  = U H U .  Generally 
†
, U and H commute, and H H  = H . For 
U e− iHt / (cid:61)
speaking,  for a  time-independent Hamiltonian  = 
a time-dependent Hamiltonian, U and H need not commute. 

Particle in a potential 

Often we want to describe the equations of motion for particles with an arbitrary potential: 

H = 

p 
2 
+ ( )V x
2m 

 

For which the Heisenberg equation gives: 

Here, I’ve made use of 

∂V 
p(cid:5)  = − 
∂x 

. 

x(cid:5) =

p 
m 

⎡ xˆ
⎣ 

ˆp 
(cid:61) xˆ
n ,  ⎤⎦ = i n n −1 

⎡ xˆ ˆ, p n ⎤ = i n(cid:61) pˆ n −1 
⎣
⎦ 

2-20 

(2.76)

(2.77)

(2.78)

(2.79) 

(2.80)

These  equations  indicate  that  the  position  and momentum  operators  follow  equations  of motion 
identical  to  the  classical  variables  in  Hamilton’s  equations.  These  do  not  involve  factors  of (cid:61) . 
Note here that if we integrate eq. (2.78) over a time period t we find: 

x t( ) 

= 

p t
m 

+

x ( )
0 

(2.81)

implying  that  the  expectation  value  for  the  position  of  the  particle  follows  the  classical motion. 
These  equations  also  hold  for  the  expectation  values  for  the  position  and  momentum  operators 
(Ehrenfest’s Theorem) and indicate the nature of the classical correspondence. In correspondence 
to Newton’s equation, we see 

∂ 2  x 
m 
∂t 2 

= −  ∇ V 

(2.82)

2-21 

THE INTERACTION PICTURE 

The  interaction  picture  is  a  hybrid  representation  that  is  useful  in  solving  problems  with  time-
dependent Hamiltonians in which we can partition the Hamiltonian as  

0  + ( ) 
H t( ) 
= H   V t
 

(2.83)

H 0 is a Hamiltonian  for  the degrees of  freedom we are  interested  in, which we  treat exactly, and 
can be (although for us generally won’t be) a function of time.  V t( ) is a time-dependent potential 
which can be complicated. In the interaction picture we will treat each part of the Hamiltonian in 
a  different  representation.  We  will  use  the  eigenstates  of  H 0 as  a  basis  set  to  describe  the 
dynamics  induced  by V t( ) ,  assuming  that  V t( )   is  small  enough  that  eigenstates  of  H 0  are  a 
useful basis  to describe H.  If  H 0   is not a  function of  time,  then  there  is  simple  time-dependence 
to this part of the Hamiltonian, that we may be able to account for easily.

Setting V to zero, we can  see  that  the  time evolution of  the exact part of  the Hamiltonian 
 
H 0  is described by 

where, most generally, 

∂
( , 0 ) =
U t t
 
0
∂t 

−i H  t U  t t
, 0 ) 
( ) 
( 0 
 
0
(cid:61)

0  ( , 0 ) = exp
U t t
 

i ∫t
⎡ 
t 
 
+  ⎢
(cid:61)
⎣
0 

⎤ 
τ  0  ( )⎥
d H t
⎦ 

but for a time-independent H 0 

0  ( , 0 ) = e 0 ( − 0 ) 
t 
t
− iH 
U t t
 

(cid:61)

We define a wavefunction in the interaction picture  ψI 

through:

or 

ψS ( t )  U
≡ 0 

( , 0 ) ψI ( t ) 
 t t
 

ψI 

= U 0
† 

ψS 

(2.84)

(2.85)

(2.86) 

(2.87)

(2.88)

Effectively  the  interaction  representation  defines  wavefunctions  in  such  a  way  that  the  phase 
accumulated  under  e− 
iH t  (cid:61)
is  removed.    For  small  V,  these  are  typically  high  frequency 
0
oscillations relative to the slower amplitude changes in coherences induced by V. 

We  are  after  an  equation  of  motion  that  describes  the  time-evolution  of  the  interaction 
picture wave-functions.  We begin by substituting eq. (2.87) into the TDSE: 

2-22 

∂i(cid:61)
∂t 

ψS 

= H 

ψS

∂ 
0 ) 
0  ( 
U t , t 
ψI 
∂t 

−i
( ) 
0  ( 
=  H t U  t , t
(cid:61) 

0 )

ψI

(2.89)

∂U 0 
∂t 

ψI  + U 0 

∂ ψI 
∂t 

=

−i ( H
(cid:61) 

0  +

) 
( , t
( ) 
V t U t
 
0

0 `

) ψI

 

 

(2.90)

−i H U 0 
0 
(cid:61) 

ψI  + U 0 

∂ ψI 
∂t 

= 

−i ( H 0 
(cid:61) 

( ) ) 
+ V t
 U

0  ψI 

∴  i(cid:61) ∂ ψI  = VI 
∂t 

ψI

where 

I ( ) = 0
†  ( 
0 ) 
( ) 
0  ( 
0 ) 
  U t , t V t U t , t 
V t

(2.91)

(2.92)

satisfies  the  Schrödinger  equation  with  a  new  Hamiltonian:    the  interaction  picture 
I ( )
( ) 
U 0   unitary  transformation of V t
V t
Hamiltonian, 
.  Note:  Matrix  elements  in 
, which  is  the 
l = e− ωlk Vkl where k and l are eigenstates of H0.
 
t
i

VI  = 

ψI 

k VI 

We can now define a time-evolution operator in the interaction picture: 

where 

Now we see that 

ψ ( t )
ψI ( t )  = U t( , t ) 
I 
I 
0 
0 

I ( , 0 ) 
U t t
 = exp

−i ∫t0 
⎡
t 
 
⎢
+ ⎣ (cid:61) 

d V τ ⎤
τ  I ( )
⎥ . 
⎦ 

t  = U t( , t ) ψI ( t )
ψS ( ) 
0
0 
t U t ,  ) 
(  t  ψ (  ) 
U t( ,  )
t 
= 
I 
I 
0 
0 
0 
0
(  t  ψ (  ) 
t U t ,  ) 
U t( ,  )
t
I 
S 
0 
0 
0
0 

=

( 
0 ) 
0  ( 
0 ) 
I ( 
0 ) 
∴  U t , t  = U t , t U   t , t 

(2.93)

(2.94)

(2.95)

(2.96)

2-23 

Using the time ordered exponential in eq. (2.94), U can be written as 

( 
U t t
, 0 

) +
) = U   t t
( 
 
 
, 0 
0
n 
⎛ −i 
∞ 
⎞ ∫t
t 
τn
τ2  τ1
∑ ⎜
(
( ,τ )
n −1 … ∫t 
n ∫t 
dτ  dτ 
 
d U t
n V τn 
⎟
0 
(cid:61)
n =1 ⎝
⎠ 
0 
0
0
( 
)
)
( 
)
(
U  τ τ,  V τ  U  τ , t
0 
2
1 
1 
0
1

0 

( U  τ τ  … 
) 
n ,  n −1 )
0 

(2.97)

( , 0 ) 
where  we  have  used  the  composition  property  of U t t
  .  The  same  positive  time-ordering 
applies.   Note  that  the  interactions V(τi) are not  in  the  interaction representation here.  Rather we 
used the definition in eq. (2.92) and collected terms. 

For  transitions  between  two  eigenstates  of H0 (  l and  k): 
The  system  evolves  in  eigenstates  of  H0 during  the  different 
time periods, with  the  time-dependent  interactions V driving  the 
transitions  between  these  states.  The  time-ordered  exponential 
accounts for all possible intermediate pathways. 

Also,  the  time  evolution  of  conjugate  wavefunction  in 
the interaction picture is expressed as  

(
U t t
, 
† 

0 

) 
(
)
(
= U  t t U t t
 
, 
, 0
† 
†
I 
0 

⎡ +i
t 
− ⎣⎢ (cid:61)  ∫t0 
† = e ( − 0 )  when  H 0  is independent of time. 
(cid:61)
t 
iH t
or U 0

) 
 
= exp

0 

⎤ 
 d V  τ  ( ) exp
I  τ 
⎦⎥ 

⎡ +i
t 
− ⎣⎢ (cid:61) ∫t0 

⎤
 τ  ( ) 
d H  
0  τ 
⎦⎥ 

(2.98)

The expectation value of an operator is:   

ˆ 
A t( ) 

Aˆ
= ψ( )t  ψ  t
( ) 
)  ˆ 
(
) 
†  (
(
) 
(
, 0  ψ  t0
= ψ  t U   t t   A
, 0  U t t  
0 
)t U U Aˆ U U  ψ(
= ψ(
)
†
†
I 
I 
0
0 
0 
t Aˆ 
= ψI ( )  ψI ( ) 
t
I 

t0 

)

where 

A  U A U
≡ †
I 
S
0 

0 

Differentiating  AI  gives: 

(2.99)

(2.100)

also, 

∂  Aˆ 
I  = 
∂t 

i 
(cid:61)

0 ,  ˆ 
⎡ 
⎤ 
H A
I ⎦
⎣

 

∂ 
∂t 

ψI 

−i
I ( )
=  V t
(cid:61)

 
ψI

2-24 

(2.101)

(2.102)

Notice  that  the  interaction  representation  is  a  partition  between  the  Schrödinger  and Heisenberg 
representations.  Wavefunctions evolve under VI , while operators evolve under H0. 

For H 0  =
 

( ) = H  ⇒
0, V t
 

For H 0  = 

( ) = 0  ⇒
H V t
 
, 

∂Aˆ 
∂t 
ˆ

∂A
∂t 

ψS 

= 0;  ∂ 
∂t 
 ⎡ 
i
, ˆ ⎤
=  (cid:61) ⎣H A
⎦ ; 

ψS

−i
=  H 
(cid:61) 
∂ψ 
= 0

∂t 

 

Schrödinger 

Heisenberg 

(2.103)

2-25 

The relationship between UI(t,t0) and bn(t) 

For problems in which we partition a time-dependent Hamiltonian,  
0 + ( ) 
H H  V t
(2.104)
= 
H 0 is  the  time-independent  exact  zero-order  Hamiltonian  and  V t( )   is  a  time-dependent 
potential.  We know the eigenkets and eigenvalues of H 0 : 
H n   E=
n 
n
0 

(2.105)

and we can describe the state of the system as a superposition of these eigenstates: 
c t( )∑ n 
ψ( t ) 
n 
n 

=

k ( )

The expansion coefficients  c t are given by
ψ( t )
c t( ) =
 k ψ( t )  = k U t( , t0 ) 
k
0 

(2.106)

(2.107)

Alternatively  we  can  express  the  expansion  coefficients  in  terms  of  the  interaction  picture 
wavefunctions 

b t( ) =  k ψI ( t )  = k U I ψ( t0 ) 
k 

(2.108)

(This notation follows Cohen-Tannoudji.)  Notice 
 

( ) 
(  ) 
  k U U  
t
 
c t
= 
ψ 
I 
k 
0 
0 
e 
(
) 
k U  
t  
i
t
 
ω 
− 
= 
ψ
k 
I 
0 
e 
( ) 
 
b t
i
 
t
− 
ω 
=
k 
k 

(2.109) 

This is the same identity we used earlier to derive the coupled differential equations that describe 
the change in the time-evolving amplitude of the eigenstates: 
i(cid:61) ∂bk =  V
∑ kn 
∂t
n 

( )  − iωn k t b t
( ) 
 
t e
n

(2.110)

 

 

So, bk   is  the  expansion  coefficient  of  the  interaction  picture  wavefunctions.  Remember 
2 
2  and b 0  = c 0  .  If  necessary  we  can  calculate  b t
b t( )  = c
t( ) 
k ( ) 
k ( ) 
k ( )
k 
k 
extra oscillatory term at the end. 

  and  then  add  in  the

Andrei Tokmakoff, MIT Department of Chemistry, 3/14/2007 

2.4  PERTURBATION THEORY 

2-26 

( ) = 
  H V t( ) 
 where we know the eigenkets for H :
0  H n   E= 
H t
Given a Hamiltonian 
0 +
n
0
can calculate the evolution of the wavefunction that results from V t( ) : 

n , we

ψI ( t )  ∑ b t n
n ( ) 
=
n 

 

(2.111)

• 

using  the  coupled  differential  equations  for  the  amplitudes  of  n .  For  a  complex  time-

dependence  or  a  system  with  many  states  to  be  considered,  solving  these  equations  isn’t 
practical.  Alternatively, we can choose to work directly with U t( , t0 ) , calculate  b t( )  as: 
I
k

where 

bk 

= k U t( , t ) 
ψ( t0 )
I 
0 

U t( , t0 ) = exp
I 

+ 

−i ∫t
⎡
t 
 
⎢
⎣ (cid:61)
0 

VI ( )τ  dτ⎤
⎥ 
⎦ 

(2.112)

(2.113)

Now  we  can  truncate  the  expansion  after  a  few  terms.    This  is  perturbation  theory,  where  the 
dynamics  under  H 0  are  treated  exactly,  but  the  influence  of  V t( ) on  b   is  truncated.    This
n
works  well  for  small  changes  in  amplitude  of  the  quantum  states  with  small  coupling  matrix 
elements relative to the energy splittings involved  ( b t ≈ bk ( 0 ;) V (cid:19)  E
k ( ) 
E  
) As we’ll see,
− 
k
n 
the  results  we  obtain  from  perturbation  theory  are  widely  used  for  spectroscopy,  condensed 
phase dynamics, and relaxation. 

Transition Probability 

Let’s take the specific case where we have a system prepared in  (cid:65)  , and we want to know the 
probability of observing the system in  k  at time t , due toV t( ) . 

2
k ( ) 
k ( ) = 
P t
 
  b t

k ( ) = 
I (  t ) 
  k U t , 0  (cid:65)  
b t

k ( ) = 
b t
  k exp + 

i
t d V ( )τ ⎤ (cid:65)
⎡
⎣  (cid:61) ∫t0 
τ  I 
⎢−
⎥⎦ 

(2.114)

(2.115)

b t( ) = k (cid:65)  − 
k 

i ∫ t d  kτ  VI ( )τ  (cid:65)
0t(cid:61)
⎞2 
⎛ −i 
t dτ2  ∫t 
τ2  d
∫t
kτ1 
+ ⎜
⎟
(cid:61)
⎝
⎠ 
0
0

V (
) 
(
) 
τ  V τ  (cid:65) 
I 
I 
1 
2 

+ …

k V t  ( ) (cid:65)  =  k U V t U   (cid:65) = e− ω(cid:65)k V  
( ) 
i
t
 
† 
k (cid:65) 
I 
0 
0

t  ( ) 	

2-27 

(2.116) 

(2.117)

i
t dτ e− iω τV (
b t( ) = δ 
)	
k (cid:65)  − ∫ 
k (cid:65)  τ1   
(cid:65)k 1 
k
1 
(cid:61) t0 

“first order” 

(2.118) 

+	

⎛ −i ⎞ 2 
t 
m ⎝ (cid:61) ⎠∑ ⎜
∫t
⎟ 
0 

dτ2 

τ 
∫t 
2 
0

dτ e mk 2  V  τ  e (cid:65)m 1  Vm(cid:65)  τ1 
km (
)2 
(
) 
− iω τ 
− iω τ 
1 

+ … 

(2.119) 

“second order” 

using 

So, 

The  first-order  term  allows only direct  transitions between  (cid:65)   and  k , as allowed by  the matrix 

element  in  V,  whereas  the  second-order  term  accounts  for  transitions  occuring  through  all 
possible intermediate states  m . For perturbation theory, the time ordered integral is truncated at 

the  appropriate  order.  Including  only  the  first  integral  is  first-order  perturbation  theory.    The 
order of perturbation  theory  that one would  extend a calculation  should be evaluated  initially by 
which  allowed  pathways  between  (cid:65)   and  k   you  need  to  account  for  and  which  ones  are 

allowed by the matrix elements.  

For  first  order  perturbation  theory,  the  expression  in  eq.  (2.118)  is  the  solution  to  the 
differential equation that you get for direct coupling between  (cid:65)  and  k	
: 

∂ b =
k 
∂t

−i 
(cid:61)

e

( ) 
 V t b
 ω(cid:65)k
− i
t
k (cid:65)
(cid:65) 

( )0	

 

(2.120)

This indicates that the solution doesn’t allow for the feedback between  (cid:65)  and  k that accounts 

for changing populations.  This is the reason we say that validity dictates 

b t( )
k 

≈ bk ( )0  .

If 

ψ0 

 is not an eigenstate, we only need to express it as a superposition of eigenstates,  

ψ0 

=

∑ n ( ) 
b 0  n and 
n	

k ( )  ∑
b t =
n 

bn ( 0 ) k

U I 

n . 

	(2.121)

2-28 

Now there may be interference effects between the pathways initiating from different states:  

2
2 
( )  = b t
P t( ) = c t
( )  =
 
 
k 
k 
k 

k

b t( )
n 

n

∑
n 

2 
 

(2.122)

Also  note  that  if  the  system  is  initially  prepared  in  a  state  (cid:65)  ,  and  a  time-dependent 

perturbation  is  turned  on  and  then  turned  off  over  the  time  interval  t = −∞   to +∞ ,  then  the 
complex  amplitude  in  the  target  state  k   is  just  the  Fourier  transform  of  V(t)  evaluated  at  the 

energy gapω(cid:65)k . 

k ( ) 
b t = − 

i ∫ +∞ 
(cid:61) −∞ 

dτe

k (cid:65)  ( )
− iω τ 
(cid:65)k V  τ 

(2.123)

If the Fourier transform is defined as  

(cid:4)  ⎣
V(cid:4)  ω 
) ≡ F ⎡V t
(
( ) ⎤ = 
⎦ 

1 
+∞ 
2π ∫−∞ 
 

( ) 
exp ( ω ) , 
 
dt V t
t
i

 

(2.124) 

then 

Pk (cid:65)  = V(cid:4) (ωk (cid:65) )

2

. 

(2.125) 

Example:  First-order Perturbation Theory 

Vibrational excitation on compression of harmonic oscillator.  Let’s subject a harmonic oscillator 
to a Gaussian compression pulse, which increases its force constant. 

2-29 

First write the Hamiltonian:  

( ) = 
H t( ) =  + 
T  V t
 

p 2 
2m 

+

1 k t x  2 
( )
2 

(2.126)

Now partition it according to H H= 

( ) : 
0  + V t

 

k t( ) = k0  +δk t
( ) 
 

k0  = mΩ 2 

( −  )2  ⎞ 
⎛
t
t0 
δk t( ) = δk0  exp ⎜ − 
⎟ 
⎜ 
⎟
2σ2 
⎠
⎝

H =

2

t0 )2  ⎞ 
( t
⎛
p 2
1 
1
−
+  k x
+ δk x
 
 
exp ⎜ − 
⎟ 
⎜
⎟
2 0 
0 
2m 
2
2σ2 
⎠
⎝ 
(cid:8)(cid:11)(cid:11)(cid:9)(cid:11)(cid:11)(cid:10)  (cid:8)(cid:11)(cid:11)(cid:11)(cid:11)(cid:9)(cid:11)(cid:11)(cid:11)(cid:11)(cid:10)
V t( )  
H0 

2 

H n = E  n 
n 
0 

⎛  †
(cid:61)
H 0  = Ω ⎜ a a
⎝ 

1 ⎞
+ ⎟ 
2 ⎠

 

1 ⎞
⎛ 
(cid:61)
En = Ω ⎜ n + ⎟ 
2 ⎠ 
⎝ 

If the system is in  0  at t0  = −∞ , what is the probability of finding it in  n  at t = ∞ ? 

(2.127)

(2.128)

(2.129)

For n ≠ 0 :  

b t( ) = 
n 

−i  ∫t
t 
2(cid:61)
0 

dτ Vn 0  ( )τ 

eiωn 0τ

Using ωn 0  = ( En − E0 )  (cid:61) = nΩ : 

b t( ) =
n 

−i 
δk  n  x  0 
2 
0 
2(cid:61)

+∞ dτ  einΩτe−τ2
∫−∞

2σ2 

b t( ) =
n 

−i 
2(cid:61)

δk  2πσ  n  x  0
2
0

e− n σ Ω2 / 2  
2 2  

So, 

Here we used: 

2-30 

(2.130)

(2.131)

(2.132)

What about the matrix element? 

x  =
2 

(cid:61) 
( a + a  ) = 
† 2 
2mΩ 

(cid:61)
( aa + a a + aa  + a a  ) 
†
†
†
† 
2mΩ 

(2.133)

First-order perturbation theory won’t allow transitions to n = 1 , only  n = 0  and n = 2 . 

Generally this wouldn’t be realistic, because you would certainly expect excitation to v=1 
would dominate over excitation to v=2.  A real system would also be anharmonic, in which case, 
the  leading  term  in  the  expansion of  the potential V(x),  that  is  linear  in  x, would not vanish  as  it 
does  for  a  harmonic  oscillator,  and  this  would  lead  to  matrix  elements  that  raise  and  lower  the 
excitation by one quantum.   

However for the present case, 

22  x  0  =  2 

(cid:61)
2mΩ 

b2  = 

−i  πδk 
0 σ e−2σ2
2mΩ

2

Ω

 

P2  = 

b2 

2  = 

πδk0 σ  e−4σ Ω  =σ2Ω 2 π δk0  e−4σ Ω 
2  ⎞ 
2 
2
⎛ 
2
2
 
2
2
2  ⎟
2 ⎜
2m 2Ω 2
⎝  k0
⎠

(2.134)

(2.135)

(2.136)

So, 

and 

2-31 

From  the  exponential  argument,  significant  transfer  of  amplitude  occurs  when  the  compression 
pulse is short compared to the vibrational period. 

σ << 

1 
Ω

(2.137)

Validity:  First  order  perturbation  theory  doesn’t  allow  for  bn  to  change  much  from  its  initial 
value. For  P2 << 1 

σ 2Ω 2 

π ⎛δ k  2  ⎞
2  ⎟ << 1 
0
⎜ 
2 ⎝  k0 
⎠

(2.138)

Generally,  the perturbation δk(t) must be small compared  to k0,  i.e. 

H 0 

>> V  , but  it should also

work well for the impulsive shock limit (σΩ<<1). 

FIRST-ORDER PERTURBATION THEORY 

A  number  of  important  relationships  in  quantum  mechanics  that  describe  rate  processes  come 
from  1st  order  perturbation  theory.  For  that,  there  are  a  couple  of model  problems  that we want 
to work through: 

2-32 

Constant Perturbation  

(Step-Function Perturbation) 

ψ( −∞ )  =  (cid:65)  .  A constant perturbation of amplitude V  is applied to t0  .  What is Pk ? 

V t(  ) =θ( t − t0 ) V 
t < 0 
⎧ 0 
= ⎨ 
⎩V t
 ≥ 0 

To first order, we have: 

k U  V U   (cid:65)
†
0
0 

= V eiωk (cid:65) ( t − t0 )

i
bk  =δk (cid:65)  − ∫ t 
(cid:61)  t0 

τe k(cid:65) ( −t0 )Vk (cid:65)  ( ) 
iω τ
d 
τ 

Here Vk (cid:65)  is independent of time. Now, assuming  k  ≠ (cid:65) and setting t0 = 0 we have 
i Vk (cid:65) ∫0 
t
bk  = − 
(cid:61) 
V 
= − 
k (cid:65) 
Ek
E(cid:65) 
− 

⎡⎣exp  i ( ωk (cid:65) t ) − 1⎤⎦ 

dτeiωk(cid:65)τ 

= −

2i Vk (cid:65)  eiωk(cid:65)t /
Ek  − E(cid:65) 

 2 
sin (ωk (cid:65) t /  2 ) 

Where I used eiθ − =1 2i eiθ 
2  sin

(θ 2 ) .  Now
 

Pk  =


bk 

2

= 

2 

4 Vk
(cid:65)
Ek  − E(cid:65)

sin

2 

2  1
2 ω t 
 
k (cid:65)

(2.139)

(2.140) 

(2.141) 

(2.142)

(2.143)

Writing this as we did in Lecture 1: 

V 
2 
Pk  = 
2
Δ 

sin 2  ( Δt / (cid:61) ) 

2-33 

(2.144)

where Δ = ( E
k 

E−
(cid:65) 

)  2 . Compare this with the exact result we have for the two-level problem: 
)
2  ( 
Δ + V t / (cid:61)  
sin 
2
2 

V 2
P = 
k V 2  + Δ 2 

(2.145)

Clearly the perturbation theory result works for V << Δ. 

We can also write the first-order result as 

V t  
2 2  
2  sinc 2  ( Δt / 2 (cid:61) ) 
Pk  = 
(cid:61)

where sinc (

) = 
( ) x
x 
sin 

x .  Since lim sinc ( x ) = 1 , 
x→0 

lim P V= 
k
Δ→0 

t (cid:61) 2 
2 2

(2.146)

(2.147)

The probability of transfer from  (cid:65)  to  k  as a function of the energy level splitting ( E

E )
− 
(cid:65) 

:

k

Area scales linearly 
with time. 

Since  the  energy  spread  of  states  to  which  transfer  is  efficient  scales  approximately 
(cid:65)  < 2  (cid:61)  t ,  this  observation  is  sometimes  referred  to  as  an  uncertainty  relation 
as E
E
 
π
−
k
2π(cid:61) .  However, remember that this is really just an observation of the principles of 
E t
with Δ ⋅ Δ ≥
Fourier  transforms,  that  frequency  can  only  be  determined  by  the  length  of  the  time  period  over 
which you observe oscillations.  Since time is not an operator, it is not a true uncertainly relation 
2π(cid:61) . 
p
x
like Δ ⋅ Δ  ≥

Now turning to the time-dependence: 

2-34 

The quadratic growth  for Δ=0  is certainly unrealistic  (at  least  for  long  times), but  the expression 
shouldn’t hold for what is a “strong coupling” case Δ=0.  However, let’s continue looking at this 
behavior.  In  the  long  time  limit,  the  sinc2(x)  function  narrows  rapidly  with  time  giving  a  delta 
function: 

sin 2  ( ax  2 ) π (
)
= δ  x 
lim 
ax 2
2 
→∞t 

lim P k  ( )t  = 
t →∞ 

2 

2πVk (cid:65) 
(cid:61)

δ( E  − E  ) t 
(cid:65)
k 

(2.148)

(2.149)

The delta function enforces energy conservation, saying  that  the energies of  the  initial and  target 
state must be the same in the long time limit.   

What  is  interesting  in  eq.  (2.149)  is  that  we  see  a  probability  growing  linearly  in  time. 
This suggests a transfer rate that is independent of time, as expected for simple kinetics: 

w t( ) =
k

2 

∂P t( ) = 
k 
∂t 

2πVk (cid:65)
(cid:61)

δ( E  − E  ) 
(cid:65)
k 

(2.150)

This  is  one  statement  of  Fermi’s  Golden  Rule  −the  state-to-state  form−  which  describes 
relaxation  rates  from  first  order  perturbation  theory.    We  will  show  that  this  rate  properly 
describes  long  time  exponential  relaxation  rates  that  you  would  expect  from  the  solution 
to dP  dt = −wP . 

2-35 

Slowly Applied (Adiabatic) Perturbation 

Our perturbation was applied suddenly at  t

>

t0  (step function) 

( − )
( ) 
( )
  t V t
V t =θ  t
0 

 

This  leads  to  unphysical  consequences—you  generally  can’t  turn  on  a  perturbation  fast  enough 
to appear  instantaneous.  Since  first-order P.T. says  that  the  transition amplitude  is  related  to  the 
Fourier Transform of the perturbation, this leads to additional Fourier components in the spectral 
dependence of the perturbation—even for a monochromatic perturbation! 

So, let’s apply a perturbation slowly . . . 

V t( ) = V eηt 

here η  is  a  small  positive  number. η−1 is  the 
effective  turn-on  time  of  the  perturbation. 
The system is prepared in state  (cid:65)  at t = −∞ .  Find P t( ) .
k
−i ∫  dτ eiω τ  k V
t 
k (cid:65)
(cid:61)  −∞ 

bk  =  k U

I  (cid:65)  =
 

(cid:65) 

eητ
 

b = 
k


−iV  exp [ηt
+ ω  ]
  t
i
k
(cid:65)
k (cid:65) 
(cid:61)  η+ iωk (cid:65) 

 

= Vk (cid:65) 

η + (  − E t
)  / (cid:61) ⎤
 
exp ⎡⎣  t
i E  
⎦
(cid:65) 
k 
Ek − E(cid:65)  + iη(cid:61) 

Pk  = 

bk 

2 

= 

2 

[ ηt ] 
Vk (cid:65) 
exp 2  
(cid:61) 2  η2  +ωk 
2 
(cid:65) 

=

[ η ]
2 
Vk (cid:65)  exp 2  t
( Ek − E(cid:65)  )2  + (η(cid:61) )2 

This is a Lorentzian lineshape in ωk (cid:65)  with width 2η(cid:61) . 

Gradually Applied Perturbation 

Step Response Perturbation 

2-36 

The  gradually  turned  on  perturbation  has  a  width  dependent  on  the  turn-on  rate,  and  is 
independent  of  time.    (The  amplitude  grows  exponentially  in  time.)    Notice,  there  are  no  nodes 
in Pk . 

Now, let’s calculate the transition rate:   

2 2ηe2ηt
Vk (cid:65)
=  (cid:61) 2  η2  +ωk 
2 
(cid:65) 
Look at the adiabatic limit;η→ 0 .  Setting  e2ηt  → 1  and using 

∂Pk 
∂t 

wkl  =

lim  η  = πδ ω( 
k (cid:65) 
η→ 0 η2  +ωk 
2 
(cid:65) 
)  2 
2π 
π 
(
2 
wk (cid:65)  =  (cid:61) 2  V 
Vk (cid:65) 
k (cid:65)  δ ωk (cid:65)  = 
(cid:61) 
We get Fermi’s Golden Rule—independent of how perturbation is introduced!   

δ( Ek  − E(cid:65)  )
2 

) 

Harmonic Perturbation 

Interaction of a system with an oscillating perturbation 
turned  on  at  time t0  = 0 .  This  describes  how  a  light 
field  (monochromatic)  induces  transitions  in  a  system 
through dipole  interactions.  Again, we are  looking  to 
calculate  the  transition  probability  between  states  (cid:65) 
and k: 

V t( ) = V cosωt = −μE0  cos ωt 

V t( ) = V cosωt
k (cid:65) 
k (cid:65) 
V 
⎣⎡e ω + e 
− i
tω 
 
t
i
k (cid:65)
= 
2 

⎦⎤ 

bk  =  k ψI ( )t  =

−i ∫t
t d V
τ  k (cid:65)  ( )τ  eiωk(cid:65)τ 
 
(cid:61) 
0 

To first order, we have: 

2-37 

(2.151) 

(2.152) 

= 

−iV 
t dτ ⎣
⎡e (ωk(cid:65) +  ) − e i ωk(cid:65) −  )
( ωτ 
⎤ 
i  ωτ 
k (cid:65)  ∫0 
⎦
2(cid:61) 

setting t0  → 0  (2.153)

=

−Vk (cid:65)  ⎡ ei (ωk(cid:65) +ω)t −1  ei (ωk(cid:65) −ω)t −1⎤ 
+ 
⎥
⎢ 
2(cid:61) ⎣ ωk (cid:65)  +ω  ωk (cid:65)  −ω  ⎦ 

Now, using  eiθ  1 2i
− =

iθ
e 

2

sin (θ 2 ) as before: 

bk  =

⎡ ei (ωk(cid:65) −ω)t / 2   sin ⎣⎡(ωk (cid:65)  −ω) t / 2 ⎦⎤  ei (ωk(cid:65) +ω)t / 2   sin ⎣⎡(ωk (cid:65)  +ω) t / 2 ⎦⎤
−iVk (cid:65)  ⎢
+ 
(cid:61)
ωk (cid:65)  +ω 
ωk (cid:65)  −ω 
⎢ 
⎣

⎤ 
⎥
⎥ 
⎦

(2.154)

Notice  that  these  terms  are  only  significant  when ω≈ωk (cid:65) .  As  we  learned  before,  resonance  is 
required to gain significant transfer of amplitude. 

2-38 

 

 

First Term 

max at : ω= +ωk (cid:65) 

Ek > E(cid:65) 

Ek = E(cid:65)  + (cid:61)ω 

Absorption  

(resonant term) 

Second Term

ω= −ωk (cid:65) 

Ek < E(cid:65) 

Ek = E(cid:65)  − (cid:61)ω 

Stimulated Emission 

(anti-resonant term) 

For the case where only absorption contributes,  Ek > E(cid:65) , we have: 

Pk (cid:65)  =  bk 

2 

= 

or 

2 

Vk (cid:65)
(cid:61) 2  (ωk (cid:65)  −ω) 
2 
2
E0
2  μk (cid:65)
2  sin 2 
(cid:61) (ωk (cid:65)  −ω) 

2  (ωk (cid:65)  −ω) t ⎤⎦
sin 2  ⎡⎣ 1

2  (ωk (cid:65)  −ω) t ⎦⎤ 
⎣⎡ 1

(2.155)

We can compare this with the exact expression: 

Pk (cid:65)  =  bk 

2  = 

2 

Vk (cid:65) 
(cid:61) 2  (ωk (cid:65)  −ω)2  + Vk (cid:65) 

2 

1  V  2  + (ωk (cid:65)  −ω)2  t ⎥
sin 2  ⎡
⎤ 
⎢ 
k (cid:65)
⎣ 2(cid:61) 
⎦

(2.156)

which  points  out  that  this  is  valid  for  couplings  Vk (cid:65)   that  are  small  relative  to  the 
(cid:65)  −ω) . The maximum probability for transfer is on resonance ω(cid:65)  =ω
detuning  ω ( 
Δ = ωk
k

Limitations of this formula:  

x
x
By expanding  sin  = −

x
3 
+…  , we see that on resonance  Δω=ωk (cid:65)
3! 

−ω→ 0 

lim 
Δ → 0
ω 

k ( ) 
P t = 

2
Vk (cid:65) 
2  t 2 
(cid:61)
4

2-39 

(2.157)

This clearly will not describe long-time behavior.  This is a result of 1st order perturbation theory 
not treating the depletion of  (cid:65)  . However, it will hold for small Pk , so we require 

2(cid:61)
t << 
Vk (cid:65) 

(2.158)

At  the  same  time,  we  can’t  observe  the  system  on  too  short  a  time  scale.   We  need  the  field  to 
make several oscillations for it to be a harmonic perturbation.   

 These relationships imply that 

t >

1
1
≈ 
ω ωk (cid:65) 

(2.159)

Vk (cid:65)  << (cid:61)ωk (cid:65) (2.160) 

2-40 

Adiabatic Harmonic Perturbation 

What happens if we slowly turn on the harmonic interaction? 

V t( ) = V eηt cosωt 

iω τ+ητ ⎡ eiωτ  + e− iωτ ⎤ 
b = −i  t dτ V e
 
(cid:61)  ∫−∞ 
k (cid:65) 
⎢ 
⎥ 
k (cid:65) 
k 
2 
⎦
⎣
ei (ωk(cid:65) −ω)t 
ei (ωk(cid:65) +ω)t 
⎤ 
Vk (cid:65)  eηt ⎡ 
= 
+ 
⎢ − (ωk (cid:65)  +ω) + iη  − (ωk (cid:65)  −ω) + iη ⎦
⎥ 
2(cid:61) 
⎣
Again, we  have  a  resonant  and  anti-resonant  term, which  are  now  broadened  byη . 
consider absorption: 

 

If we  only 

Pk  = 

bk 

2 
2  Vk (cid:65)  e2ηt 
=
4(cid:61) 2 

1
(ωk (cid:65)  −ω)2  +η2 

which  is  the  Lorentzian  lineshape  centered  at  ωk (cid:65) =ω  with  width Δω = 2η .  Again,  we  can 
calculate the adiabatic limit, setting η→ 0 . We will calculate the rate of transitions ωk (cid:65)  = ∂Pk / ∂t . 
But  let’s  restrict ourselves  to  long enough  times  that  the harmonic perturbation has cycled a  few 
times (this allows us to neglect cross terms)  → resonances sharpen. 

wk (cid:65)  = 

π 
2  Vk (cid:65) 
2(cid:61) 

2  ⎡  ( 
⎣δ ωk (cid:65) 

−ω) + 
( 
δ ω k (cid:65) 

+ω)⎤
⎦

Andrei Tokmakoff, MIT Department of Chemistry, 3/1/2007 

2.5  FERMI’S GOLDEN RULE 

2-41 

The  transition  rate  and  probability  of  observing  the  system  in  a  state  k

after  applying  a 

perturbation  to  (cid:65)   from  the  constant  first-order  perturbation  doesn’t  allow  for  the  feedback 

between quantum states, so it turns out to be most useful in cases where we are interested just the 
rate  of  leaving  a  state.      This  question  shows  up  commonly  when  we  calculate  the  transition 
probability  not  to  an  individual  eigenstate,  but  a  distribution  of  eigenstates.    Often  the  set  of 
eigenstates  form  a  continuum  of  accepting  states,  for  instance,  vibrational  relaxation  or 
ionization. 

Transfer to a set of continuum (or bath) states forms the basis for a describing irreversible 
relaxation.  You can think of the material Hamiltonian for our problem being partitioned into two 
B +  SB ( ) 
,  where  you  are  interested  in  the  loss  of  amplitude  in  the  H 
H H  H V
t
portions, 
= 
S + 
S
states  as  it  leaks  into H B .  Qualitatively,  you  expect  deterministic,  oscillatory  feedback  between 
discrete  quantum  states.    However,  the  amplitude  of  one  discrete  state  coupled  to  a  continuum 
will  decay  due  to  destructive  interferences  between  the  oscillating  frequencies  for  each member 
of the continuum. 

So, using  the  same  ideas as before,  let’s  calculate  the  transition probability  from  (cid:65)   to a 

distribution of final states: Pk . 

Pk  = bk 

2

(
)k
ρ  E


: 

Probability of observing amplitude in discrete eigenstate of  H 0 

Density  of  states—units  in1  Ek ,  describes  distribution  of  final
states—all eigenstates of  H 0


If we start in a state  (cid:65)  , the total transition probability is a sum of probabilities 

Pk  = ∑ Pk . 
k 

(2.161) 

We are  just  interested  in  the rate of  leaving  (cid:65)  and occupying any state  k or for a continuous 

distribution: 

For a constant perturbation: 

P = ∫ dEk 
k 

(  k )  k 
ρ  E P

 

P k = ∫ dEk ρ( Ek ) 4 Vk (cid:65) 

2  sin  (  E
  ) 
(cid:65)  )  / 2 (cid:61)
(  k − 
 E t
2 
2
E
E
 
−k 
(cid:65) 

Now, let’s make two assumptions to evaluate this expression: 

1)  ρ( Ek ) varies  slowly  with  frequency  and  there  is  a  

continuum  of  final  states.  (By  slow what we  are  saying  is  

that the observation point t is relatively long). 


2)  The  matrix  element  Vk (cid:65)   is  invariant  across  the  final 
states. 

These assumptions allow those variables to be factored out of integral  
sin 2  ( E
)  / 2 (cid:61)
 E t
 
(cid:65) 
k 
(
)
2 
E
E
 
(cid:65) 
k 

+∞ 
2 
Pk  = ρ Vk (cid:65)  ∫−∞ 

dEk 4 

−
−

2-42 

(2.162)

(2.163)

(2.164)

Here,  we  have  chosen  the  limits  −∞ → + ∞   since  ρ( Ek )  is  broad  relative  to Pk .  Using  the 
identity 

with  a

t / (cid:61)  we have
= 

+∞ 
∫−∞ 

d Δ

sin 2  aΔ
Δ 2 

= aπ 

2π 
Pk  = ρ Vk (cid:65) 
(cid:61)

2  t 

(2.165) 

(2.166)

The total transition probability is linearly proportional to time.  For relaxation processes, we will 
be concerned with the transition rate, wk (cid:65) : 

wk (cid:65)  = 

∂ P k (cid:65) 
∂t 
2π 
wk (cid:65)  = ρ Vk (cid:65) 
(cid:61)

2 

2-43 

(2.167)

Remember  that  Pk   is  centered  sharply  at Ek = E(cid:65) .  So  although ρ  is  a  constant, we  usually write 
eq. (2.167) in terms of ρ( Ek = E(cid:65) )  or more commonly in terms of δ( Ek − E(cid:65)  ) : 

wk (cid:65)  = 

2π ρ( Ek  = E(cid:65)  ) Vk (cid:65) 
(cid:61)

2 

wk (cid:65)  = 

2π 
Vk (cid:65) 
(cid:61) 

2 δ( Ek  − E(cid:65) ) 

k  ρ( Ek  ) wk (cid:65)  
wk (cid:65)  = ∫ dE
 

(2.168)

(2.169)

This  expression  is  known  as  Fermi’s Golden Rule.   Note  the  rates  are  independent  of  time.   As 
we  will  see  going  forward,  this  first-order  perturbation  theory  expression  involving  the  matrix 
element  squared  and  the  density  of  states  is  very  common  in  the  calculation  of  chemical  rate 
processes. 

Range of validity 

For  discrete  states  we  saw  that  the  first  order  expression  held  for Vk (cid:65)  << (cid:61)ωk (cid:65)  ,  and  for 
times such that  Pk  never varies from initial values.  

Pk  = wk (cid:65)  ( t − t0 ) 

t << 

1 
wk (cid:65)

(2.170)

However, transition probability must also be sharp compared to ρ( Ek  ) , which implies  

t >> (cid:61) / ΔEk 

So, this expression is useful where 

wk (cid:65) (cid:61) 
E 
Δ >> 
. 

Δωk  >> wk (cid:65) 

(2.171) 

(2.172) 

