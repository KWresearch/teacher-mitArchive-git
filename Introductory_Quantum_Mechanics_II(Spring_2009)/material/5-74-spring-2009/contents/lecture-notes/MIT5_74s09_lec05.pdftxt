MIT OpenCourseWare
http://ocw.mit.edu 

5.74 Introductory Quantum Mechanics II

Spring 2009 


For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

5-1 

5.1.  TIME-CORRELATION FUNCTIONS 

Time-correlation  functions  are  an  effective  and  intuitive  way  of  representing  the  dynamics  of  a 
system,  and  are  one  of  the  most  common  tools  of  time-dependent  quantum  mechanics.  They 
provide  a  statistical  description  of  the  time-evolution  of  a  variable  for  an  ensemble  at  thermal 
equilibrium.    They  are  generally  applicable  to  any  time-dependent  process  for  an  ensemble,  but 
are  commonly  used  to  describe  random  (or  stochastic)  and  irreversible  processes  in  condensed 
phases. We will use them in a description of spectroscopy and relaxation phenomena.   
This work  is motivated  by  finding  a  general  tool  that will  help  us  deal with  the  inherent 
randomness  of molecular  systems  at  thermal  equilibrium.  The  quantum  equations  of motion  are 
deterministic,  but  this  only  applies  when  we  can  specify  the  positions  and  momenta  of  all  the 
particles in our system.  More generally, we observe a small subset of all degrees of freedom (the 
“system”),  and  the  time-dependent  properties  that  we  observe  have  random  fluctuations  and 
irreversible  relaxation  as  a  result  of  interactions  with  the  surroundings.    It  is  useful  to  treat  the 
environment  (or  “bath”)  with  the  minimum  number  of  variables  and  incorporate  it  into  our 
problems in a statistical sense – for instance in terms of temperature.  Time-correlation functions 
are generally applied  to describe  the  time-dependent statistics of systems at  thermal equilibrium, 
rather than pure states described by a single wavefunction. 

Statistics 

Commonly  you  would  describe  the  statistics  of  a  measurement  on  a  variable  A  in  terms  of  the 
moments  of  the  distribution  function,  P(A),  which  characterizes  the  probability  of  observing  A 
between A and A+dA

Average: 
Mean Square Value: 

) 
(
= ∫
dA A P  A 
(
)  . 
= ∫ dA
 
A
2  P A
 
Similarly,  this  can  be  written  as  a  determination  from  a  large  number  of  measurements  of  the 
value of the variable A: 

(5.1) 
(5.2) 

A 
A2

 

A  = 

1  ∑ Ai 
N 
N i =1 

A2 

1  N 
= ∑ Ai  . 
2
N i =1 

(5.3)

(5.4)

Andrei Tokmakoff, MIT Department of Chemistry, 2/24/2009 

5-2 

The ability to specify a value for A is captured in the 
variance of the distribution 

σ 2  = 

A2

2

−  A 

(5.5) 

The observation of an internal variable in a statistical  
sense  is  also  intrinsic  to  quantum  mechanics.  A 
fundamental  postulate  is  that  the  expectation  value 
= ψ  Aˆ ψ    is  the  mean  value  of  A  obtained  over  many  observations.    The 
Aˆ
of  an  operator 

2
probability distribution function is associated with ψ  dr . 

To  take  this  a  step  further  and  characterize  the  statistical  relationship  between  two 
variables,  one  can  define  a  joint  probability  distribution,  P(A,B),  which  characterizes  the 
probability  of  observing  A  between  A  and  A+dA  and  B  between  B  and  B+dB.  The  statistical 
relationship  between  the  variables  can  also  emerges  from  moments  of  P(A,B).  The  most 
important measure is a correlation function 
C AB  =  AB

 
− A  B 

(5.6) 

You  can  see  that  this  is  the  covariance  –  the  variance  for  a  bivariate  distribution.   This  is  a 
measure  of  the  correlation  between  the  variables A  and B,  that  is,  if  you  choose  a  specific  value 
of  A,  does  that  imply  that  the  associated  values  of  B  have  different  statistics  from  those  for  all 
values. To interpret this it helps to define a correlation coefficient  
C AB 
r = 
. 
σσA B  
ρ  can  take  on  values  from  +1  to  −1.  If  r =  1  then  there  is  perfect  correlation  between  the  two 
distributions.  If  the variables A and B depend  the same way on a common  internal variable,  then 
they  are  correlated.  If  no  statistical  relationship  exists  between  the  two  distributions,  then  they 
are uncorrelated, r = 0, and  AB  =  A  B  .  It is also possible that the distributions depend in an 

(5.7)

equal  and  opposite  manner  on  an  internal  variable,  in  which  case  we  call  them  anti-correlated 
with r = −1. 
Equation  (5.6)  can  be  applied  to  any  two  different  continuous  variables,  but  most 
commonly these are used to describe variables in time and space. For the case of time-correlation 

5-3 

functions  that  we  will  be  investigating,  rather  than  two  different  internal  variables,  we  will  be 
interested in the value of the same internal variable, although at different points in time. 

Equilibrium systems 
For  the  case  of  a  system  at  thermal  equilibrium,  we  describe  the  probability  of  observing  a 
variable A through an equilibrium ensemble average  A  .  Classically this is  

,  ) 
; t ) ρ( p q
dq  A (  ,
A  = ∫  p ∫ 
p q  
d

where ρ is the canonical probability distribution for an equilibrium system at temperature T 
e 
−βH 
Z 
Z is the partition function and β=kBT.  In the quantum mechanical case, we can write  
A  = ∑ pn  n A n 
n 
pn = e−βEn  / Z 

where 

ρ=

(5.8)

(5.9)

(5.10) 

(5.11) 

Equation  (5.10)  may  not  seem  obvious,  since 
than  our  earlier 
is  different 
it 
∑  n 
a a A   = Tr (ρA) .  The  difference  is  that  in  the  present  case,  we  are 
expression  A  = 
* 
m  mn 
,n m  
dealing with a statistical mixture or mixed state, in which no coherences (phase relationships) 
are present in the sample.  To look at it a bit more closely, the expectation value for a mixture 
A  = ∑ pk  ψk  A 
(5.12)
ψk 
k 
can  be  written  somewhat  differently  as  an  explicit  sum  over  N  statistically  independent 
molecules  

1  N 
A  =  ∑ ∑ ( an  ) am  n A m 
* 
( )i
( )i 
N 
 
i =1
n m
,
By  statistically  independent,  we  mean  that  the  molecules  interact  only  with  their 
surroundings and not with each other.  They have no knowledge of each other. Then, the sum 
over molecules is just the ensemble averaged value of the expansion coefficients 
= ∑

 a a
A
 n A m
 
*

n m 
,n m  

(5.13) 

(5.14)

5-4 

We  can  evaluate  this  average  recognizing  that  these  are  complex  numbers,  and  that  the 
equilibrium  ensemble  average  of  the  expansion  coefficients  is  equivalent  to  phase  averaging 
over the expansion coefficients.  Since at equilibrium all phases are equally probable   
1
1
a  a  ∫ 2π e− iφnm dφnm 
2π  *
∫ 
a a d  φ= 
n m  
n
  m
2π 
2π 
0 
0

* a a   = 
n m 

(5.15)

where  a = a  eiφn andφnm  =φn −φm . The  integral  in (5.15)  is quite clearly zero unless φn  =φm ,
n 
n 
giving 

* a a   =  pn  =
n m 

e

−βE 
n
Z 

 

(5.16)

Of course, even at equilibrium the expectation value of A for a member of ensemble as a function 
i ( )
( )
.  Although  the  behavior  of  A t
of  time A t
  may  be  well-defined  and  periodic,  for  mixed 
i
states it generally is observed to fluctuate randomly: 

The  fluctuations  are  about  a mean  value  A .  Given  enough  time, we  expect  that  one molecule 

will be  able  to  sample  all of phase  space,  and  therefore  the  sum over  all  instantaneous values of 
A  for  one  molecule  should  represent  the  equilibrium  probability  distribution  for  that  variable, 
P(A).  This is then related to the free energy projected onto A as 
(
) 
(
) 
P A  
F A = −βln 
If we  look at  this behavior  there seems  to be  little  information  in  the random fluctuations 
of  A,  but  there  are  characteristic  time  scales  and  amplitudes  to  these  changes.    We  can 
characterize these by comparing the value of A at time t with the value of A at time t’ later.  With 

(5.17)

that  in  mind  we  define  a  time-correlation  function  (TCF)  as  a  time-dependent  quantity,  A t( ) , 
multiplied  by  that  quantity  at  some  later  time,  A ( t ′ ) ,  and  averaged  over  an  equilibrium 
ensemble: 

5-5 

,  ′ ) ≡ A t
( ) A t
C AA  ( t t
( ′ ) 
 
 
Technically  this  is an auto-correlation  function, which correlates  the same variable at  two points 
in  time,  whereas  the  correlation  of  two  different  variables  in  time  is  described  through  a  cross-
correlation function 

 

(5.18) 

(5.19) 

(5.20) 

(5.21) 

 

,  ′ ) ≡ A t
( ) B t
C AB  ( t t
( ′ ) 
 
 
Following (5.8), the classical correlation function is 
)  ∫ p ∫
(p q   )ρ(  ,  ) 
(p q   )
C AA  ( 
dq  A 
p q  
; t A 
 
; t ' 
t t
,  ′ = d
,
,
while from (5.10) we can see that the quantum correlation function can be evaluated as 
,  ′ ) = ∑ pn 
C AA  ( t t
( ) A t
( ′ ) n  . 
 
 
 A t
n
 
n 
So,  what  does  a  time-correlation  function  tell  us?  Qualitatively,  a  TCF  describes  how 
long  a  given  property  of  a  system  persists  until  it  is  averaged  out  by  microscopic  motions  and 
interactions  with  its  surroundings.    It  describes  how  and  when  a  statistical  relationship  has 
vanished.  We  can  use  correlation  functions  to  describe  various  time-dependent  chemical 
( )  ( )
processes. We will use  μ t  μ 0 
-the  dynamics  of  the molecular  dipole moment-  to  describe 
spectroscopy. We will also use  is  for  relaxation processes  induced by  the  interaction of a system 
( ) 
SB  ( )
and  bath:  H SB  t  H 
0 
.  Classically,  you  can  use  if  to  characterize  transport  processes.    For 
instance  a  diffusion  coefficient 
1  ∞ 
3 ∫0 

the  velocity  correlation 

( )  (  ) 
dt v  t v  0

function: 

D = 

is 

related 

to 

Properties of Correlation Functions 

A typical correlation function for random fluctuations in the variable A might look like: 

5-6 

A 2 
') 

 

C AA  ( t t
,

and is described by a number of properties: 

2A 

t 

1.  	

2.  	

3.  	

 

When evaluated at t = t’, we obtain the maximum amplitude, the mean square value of A, 
which is positive for an autocorrelation function and independent of time.  
C AA  ( t t
,	 ) = 
( ) A t
( ) 
 
 
A t
 
A2
≥ 0	
= 

(5.22)

For long time separations, the values of A become uncorrelated 
( ) 
)'  = A 
(
( t t
') = 
2
A t
A t
 
 
 
,

AA 

lim C	
t→∞	

(5.23)

Since  it’s  an  equilibrium  quantity,  correlation  functions  are  stationary.  That  means  they 
do not depend on  the  absolute point of observation  (t  and  t’), but  rather  the  time-interval 
between observations.  A stationary random process means that the reference point can be 
shifted by a value T 

(  T t
′ ) = C AA  t + 
C AA  ( t t
,  ′ + T ) 
 
 
. 
, 
So, choosing T  = −t ′ , we see that only the time interval  t
t−  ′ ≡τ  matters 
) = C AA  (τ) 
C AA  ( t t
,  ′ ) = C AA  ( t − t ′, 0
 
 
Implicit  in  this statement  is an understanding  that we  take  the  time-average value of A  to 
be equal  to  the equilibrium ensemble average value of A.  This  is  the property of ergodic 
systems. 

	(5.24)

(5.25) 

More on Stationary Processes1 

5-7 

The  ensemble  average  value  of  A   can  be  expressed  as  a  time-average  or  an  ensemble 
average.  For an equilibrium system, the time average is 
A =  lim  1 
T
T →∞ T ∫0 
∑ e−βEn
Z 
n

and the ensemble average is  

n A n . 

	(5.27) 

(5.26)

dt A
i

A  =

( )	
t

 

 

These quantities are equal for an ergodic system  A = A .  A system is ergodic if the 

evolution of one member of the ensemble has evolved long enough to sample the 
equilibrium probability distribution. We assume this property for our correlation 
functions.  So, the correlation of fluctuations can be expressed as either a time-average 
over a trajectory 

( )  ( ) =  lim  1  ∫ T 
A t  A  
0 
T →∞ T  0 
or an equilibrium ensemble average 
= ∑ e
n

( )  ( ) 
A t  A	 0 

−βE 
n
Z 

τ  i ( +τ  Ai  τ	
) 
( ) 
d   A t  

( )  ( ) 
n A t  A	 0  n 

(5.28)

(5.29)

4. 	

Classical correlation functions are real and even in time: 
( )  (	 ′ ) 
( ′ )  (	 ) 
A t  A t   =  A t   A t  
( )τ  = C 
(
) 
C AA 
AA  −τ 
5.  	 When  we  observe  fluctuations  about  an  average,  we  often  redefine  the  correlation 
function in terms of the deviation from average   
δA A≡ − A 

(5.31) 

(5.30)

C A A ( )t  = 
δ δ 

( ) δ  ( )  C 
δA t
A 0  =  AA	
 

( ) −
t 

2

A

(5.32)

A A ( )
Now we see that the long time limit when correlation is lost lim Cδ δ 
t  = 0 , and the zero
t→∞ 
time value is just the variance 
Cδ δ  ( ) = δA2  = 
A A   0 

(5.33)

− A 

A2

2

5-8 

6. 

The  characteristic  time-scale  of  a  random  process  is  the  correlation  time, τc .  This 
characterizes the time scale for TCF to decay to zero. We can obtain τc   from 
1 
∞ 
∫ dt 
τ = 
c  δA2 
0 
−t /τ ) .
which should be apparent if you have an exponential form C t( ) = C 0 exp  (
( ) 
c 

( ) 
( ) 
δA t  δA 0

(5.34)

Examples of Time-Correlation Functions 

EXAMPLE 1:  Velocity autocorrelation function for gas.   

Vx :  xˆ  Component of molecular velocity 

Vx = 0 

CV V   ( )t  =  V
x
x x

( ) 
 t V
x 

( )
 0 

Ideal gas: 
•  No collisions.   
•  Velocities are unchanged over t. 

CV V   ( ) =  V 2  ( )0
0 
x
x x

=

kT
m 

kT / m 

CV V   ( )t 
x
x

Dilute gas:  Infrequent collisions 

( ) = V  0 
( ) 
V t
 
for
 t
x 
x
( ) = V  0  ±δ  for
( ) 
V t
 
x 
x

 <τ 
c 
 >τ 
 t
c 
%
τc is related to mean time between collisions.  
•
•  After collisions, correlation is lost. 

CV V   ( )t
x
x
 

kT / m 

t 

τc

t 

5-9 

EXAMPLE 2:  Dipole moment for diatomic molecule in dilute gas: μi . 

μi


= 0 (all angles are equally likely in an isotropic system)

μi  = μ0  ⋅ uˆ (the dipole has a magnitude and direction) 


( )0 
t  μμ( ) 
Cμμ ( )t  = 
( ) 
( ) 
ˆ 
⋅ ˆ 0
2  u t   u
= μ0

μ 2
0 

The correlation function 
projects the time-dependent 
orientation onto the initial 
orientation 

collisional damping 

oscillation frequency gives 
moment of inertia 

EXAMPLE 3:  Displacement of harmonic oscillator. 

mq&& κq  →  q&& = ω2 q 
= −
− 

q t( ) = q  0 cosωt
( )

kT
Since  q 2  ( )  mω2 
0  =

qq ( ) 
( )  ( ) 
2  ( ) 
 =  q t q  0  =  q  0  cosωt
C t
⎛  kT 
⎞ cosωt 
= ⎜
2  ⎟
⎝ mω ⎠ 

kT / mω2 

damping will cause Cqq  to decay 

5-10 

5.2. QUANTUM CORRELATION FUNCTIONS 

Quantum  correlation  functions  involve  the  equilibrium  (thermal)  average  over  a  product  of 
Hermetian  operators  evaluated 
two 
times.  The 
thermal  average 
is 
implicit 
in 
) 
( )  (
) 
writing C AA  (
 
,  ′ =  A t
 
 
t t
A t
.  Naturally,  this  also  invokes  a Heisenberg  representation  of  the 
′ 
operators,  although  in  almost  all  cases,  we  will  be  writing  correlation  functions  as  interaction 
picture operators A t( ) =  iH  t Ae− iH  t 
e  0 
0 .
I
To emphasize the thermal average, the quantum correlation function can also be written 

as 

e

AA  (
) 
C  t t
 
,  ′ =

−βH 
Z 
n  ,  inserting  a  projection  operator  leads  to  our  previous 

( )  (
A t
 A t

) 
′ 

 

(5.35) 

If  we  evaluate  this  in  a  basis  set 

expression 

,  ′ ) = ∑ pn  n
C AA  ( t t
 
n 
Z  .  Given  the  case  of  a  time-independent  Hamiltonian  for  which  we  have 

( ′ ) n 
( ) A t
 
 
 A t

(5.36) 

with pn = e−βEn
knowledge of the eigenstates, we can also express this in the Schrödinger picture  
,  ′  = ∑ 
) 
) 
( ) 
C AA  (
) 
( ) 
(
(
 U   AU   A
AU  t
p
 U  t
 
t t
 
n
 
t
 
t
  n
† 
† 
′ 
′ 
uuuuuuuuuur 
n 
suuuuuuuu
n 
) 
( 
i 
t  t 
= ∑ 
( 
ω 
− ′ 
 AU  t
 t
n
 e
 
p
′− 
n 
n 
n 
= ∑ 
p
n 
,n m  
(
= ∑ 
i 
2 
− 
ω 
p A   e  
mn 
n
 
 mn
,n m  

 A  m  m  A  n

) 
( 
i 
t  t 
− ′ 
− 
ω 
 e
 
mn 

) 
 A  n

) 
t  t 
− ′ 

n

 

 

 

(5.37) 

Properties of Quantum Correlation Functions 

There  are  a  few  properties  of  quantum  correlation  functions  that  can  be  obtained  using  the 
properties of  the  time-evolution operator.   First, we can  show  the property of  stationarity, which 
we have come to expect: 

A t( )  (
)A t ′ 

=  U †  ( t ) A ( 0 )U ( t U) 
†  ( t ′ ) A ( 0 )U ( t ′ )
( ) 
)U †  ( ) AU  t U †  (  ) ′  A 
(
=  U t ′ 
t
t 
=  U †  ( t − t AU)
( t 
)− t A  
′
′
=  A t( − t ′ )  ( )A  0 

(
)
( ) 
A t A  0
− 

* 
=  A t( )  ( )A  0  =
*  ( t ) = C AA  ( −t ) 
C AA 

A ( )  ( )A t 
0 

A ( )0  A t( )  =  A ( 0 )U †  AU  =  U  AU †  A 
−(
)
( ) 
=  A t A  0

Also, we can show that 

or 

This follows from 

5-11 

(5.38)

(5.39)

(5.40) 

(5.41) 

A t( )  ( )A  0 

*
*  =  U †  AU  A  =  U  AU †  A
0A ( )  ( )A t 
=
Note  that  the  quantum  C AA  ( t )  is  complex.  You  cannot  directly  measure  a  quantum 
correlation function, but observables are often related  to  the real or  imaginary part of correlation 
functions, or other combinations of correlation functions. 
( t ) = C ′ ( t ) + i C ′′  ( t ) 
C 
AA
AA 
AA 
1 
( )  ( ) 
( )  ( ) 
⎡  A t  A  0  +  A  0  A t
⎣ 
2 

AA  ( )  1 
⎣  AA  ( ) 
*  ( ) ⎦ 
t  = ⎡C t  + C t  ⎤ = 
C ′ 
AA 
2
1 
( )0  ⎤⎦ +
⎡ A t( ) 
, A
⎣ 
2 
1  ⎡C 
( )t  − C * 
AA  ( ) ⎤⎦ = 
t 
2i ⎣  AA 
1 
( )0  ⎤ 
⎡ A t( ) 
, A 
⎦
⎣ 
2i 
 and  C ′′  are directly proportional
We will see  later  in our discussion of  linear  response  that  C ′
AA 
AA 
to  the  step  response  function  S  and  the  impulse  response  function  R,  respectively.  R  describes 
how  a  system  is driven  away  from  equilibrium by  an  external potential, whereas S describes  the 
relaxation  of  the  system  to  equilibrium  when  a  force  holding  it  away  from  equilibrium  is 
released. The two are related by R 
S t
∝ ∂  ∂  . 

1  A t( )  ( )A  0  + 
⎡⎣ 
2i 

0A ( )  ( )A t

⎤
⎦ 

= 

= 

C ′′ ( )t  = 
AA 

(5.42) 

(5.43)

(5.44) 

(5.45)

⎤ 
⎦ 

We  can  also  define  a  spectral  or  frequency-domain  correlation  function  by  Fourier 
transforming the TCF. 

5-12 

+∞ 
) = F ⎣C AA  (  ) ⎦ = ∫−∞ 
AA  (
( ) 
C%  ω  % ⎡ 
t  ⎤ 
e ω  C AA  t 
i
t
 
For  a  time-independent  Hamiltonian,  as  we  might  have  in  an  interaction  picture  problem,  the 
TCF in eq. (5.37) gives 

dt

(5.46)

 

2

) . 

(5.47)

( − 
δ ω  ω
mn 

) = ∑  n 
AA  (
C% 
p  A 
ω 
mn 
,n m  
This expression  looks very similar  to the Golden rule transition rate from first order perturbation 
theory.  In  fact,  the  Fourier  transform  of  time  correlation  functions  evaluated  at  the  energy  gap 
gives  the  transition  rate  between  states  that  we  obtain  from  1st  order  perturbation  theory.  Note 
that  this  expression  is  valid  whether  the  initial  states  n  are  higher  or  lower  in  energy  than  final 
states m,  and  accounts  for upward  and downward  transitions.  If we  compare  the  ratio of upward 
and downward transition rates between two states i and j, we have 
AA  (ωij  ) = 
%C 
p j  = eβ Eij  . 
C AA  (ω ji  ) 
% 
pi 
This is one way of showing the principle of detailed balance, which relates upward and 
downward transition rates at equilibrium to the difference in thermal occupation between states: 
AA  (ω) = eβ hω C% 
AA  ( −ω) . 
C% 
(5.49) 

(5.48)

5.3. TRANSITION RATES FROM CORRELATION FUNCTIONS 
We  have  already  seen  that  the  rates  obtained  from  first-order  perturbation  theory  are  related  to 
the  Fourier  transform  of  the  time-dependent  external  potential  evaluated  at  the  energy  gap 
between the initial and final state. Here we will show that the rate of leaving an initially prepared 
state,  typically  expressed  by  Fermi’s  Golden  Rule  through  a  resonance  condition  in  the 
frequency  domain,  can  be  expressed  in  the  time-domain  picture  in  terms  of  a  time-correlation 
function for the interaction of the initial state with others.  
The state-to-state form of Fermi’s Golden Rule is  
2π 
Vk l

2 δ( Ek  − E
l  ) 
h
We  will  look  specifically  at  the  case  of  a  system  at  thermal  equilibrium  in  which  the  initially 
populated  states  l   are  coupled  to  all  states  k.  Time-correlation  functions  are  expressions  that 
apply to systems at thermal equilibrium, so we will thermally average this expression.   
2π∑  l
p
h k ,l 
l  / Z .  The  energy  conservation  statement  expressed  in  terms  of  E  or ω  can  be 

k l  δ( Ek  − E
l ) 
2 
 
V
 

wk l  = 

w  = 
k l 

(5.50)

(5.51)

where  p
l  = e−β E
converted to the time-domain using the definition of the delta function   
1 
+∞
∫−∞ 
2π 

δ ω(
) = 

dt ei
tω  , 

giving 

w  = 
k l 

1
2  ∑  l
p
h k ,l 

V
k l 

+∞ dt
∫−∞ 
 

e

(
i Ek − E
 
l

)t / h 

 

 

Writing the matrix elements explicitly and recognizing that  eiH  t 
0
1  ∑ p
2 
l 
h k ,l 
1
2  ∑ p
l 
h k ,l 

 
l V  k  k  e  0  Ve
iH t 

+∞ dt
∫−∞ 

+∞ dt
∫−∞

wmn  = 

( 
l )t / h 
i Ek − E

= 

e

Then, since  ∑ 
k 

k

k

 
= 1 

wmn  = 

1
+∞ 
2  ∑  p
l ∫−∞ 
h l =m n, 

dt

VI 

( )0  V  ( ) 
 
t 
I

l 

l 

l  = e  l  l  , we have 
iE  t 

 
 
l V  k  k  V  l 

 
iH t 
− 
0  l 

5-13 

(5.52)

(5.53)

(5.54)

(5.55)

(5.56)

5-14 

 

 

− iH t 
0

( ) 0 

wmn  = 

1
2  ∫ +∞ dt V
I
−∞ 
h
.  The  final  expression  indicates  that  integrating  over  a  correlation 

(5.57)

( ) 
t V
I

As  before  V t( ) = e  Ve
iH t 
0
I
function  for  the  time-dependent  interaction  of  the  initial  state  with  its  surroundings  gives  the 
relaxation  or  transfer  rate.  This  is  a  general  expression.    Although  the  derivation  emphasized 
specific  eigenstates,  eq.  (5.57)  say  that  with  a  knowledge  of  a  time-dependent  interaction 
potential of any  sort, we can calculate  transition  rates  from  the  time-correlation  function  for  that 
potential. 
The  same  approach  can  be  taken  using  the  rates  of  transition  in  a  equilibrium  system 
induced by a harmonic perturbation 
π 
∑ 
+ω) ⎤ , 
−ω) +  ( 
2  ⎡  ( 
wk l  = 
 
p V
⎣δ ωk l 
δ ω k l 
⎦
k l
2h l , k m= 
2 
l 
, n 
giving  a  similar  expression  for  the  transition  rate  in  terms  of  a  interaction  potential  time-
correlation function 

(5.58)

 

 

wk l  = 

( )V
I ( ) 
t
t VI  0 
dt e − i
ω

1
+∞ 
2  ∫−∞ 
h 
1 
+∞ 
2  ∫−∞ 
h
Note  that  here  and  in  eq.  (5.54)  the  transfer  rate  is  expressed  in  terms  of  a  Fourier  transform 
evaluated  either  at  the  resonance  frequency ω or  at  the  energy gap  Ek − E
l  . Although  eq.  (5.57) 
is  not  a  Fourier  transform,  it  is  in  practice  the  value  of  the  Fourier  transform  evaluated  at  zero 
frequency. 

( )  I ( ) 
t V  0

dt e ω  V 
t
i
I

(5.59) 

= 

