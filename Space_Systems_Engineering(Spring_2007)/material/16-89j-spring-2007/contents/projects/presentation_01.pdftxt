MIT OpenCourseWare 
http://ocw.mit.edu 

16.89J / ESD.352J Space Systems Engineering
Spring 2007

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

BB --Terrestrial Observer Swarm 
Terrestrial Observer Swarm 
(B(B --TOS)
TOS)

16.89 Architecture Review
16.89 Architecture Review
May 16, 2001
May 16, 2001

BB --TOS Project Participants
TOS Project Participants

• Students
– Mirna Daouk
– Nathan Diller
– Qi Dong
– Carole Joppin
– Sandra Kassin-Deardorff
– Scott Kimbrel
– Daniel Kirk
– Michelle McVey
– Brian Peck
– Adam Ross
– Brandon Wood

• Faculty and Staff
– Daniel Hastings 
– Hugh McManus 
– Joyce Warmkessel
– Bill Kaliardos
• Aggregate Customers
– Bill Borer (AFRL)
– Kevin Ray (AFRL)

16.89 Architecture Review - 2 May 16, 2001       

Massachusetts Institute of Technology

Overview
Overview
• What is 16.89 Space Systems Engineering?
– Project-oriented class in which students work as a team to develop 
system architectures and preliminary design of a space system
• What did the class do?
– Employed new design process to determine user needs, and explore
large design space rather than focusing on point design
– Applied process to B-TOS space system architecture study 
• What is B-TOS?
– Iteration B of Terrestrial Observer Swarm design
– For mapping of the Earth’s ionosphere using swarms of satellites
– Sponsored by Air Force Research Laboratory

16.89 Architecture Review - 3 May 16, 2001       

Massachusetts Institute of Technology

Presentation Outline
Presentation Outline

• Introduction (Chapter 2)
• Process Development (Chapter 3, 4, 5)
• Results (Chapter 6)
• B-TOS Requirements (Appendix C)
• Spacecraft Design (Appendix E)
• Review and Concluding Remarks

16.89 Architecture Review - 4 May 16, 2001       

Massachusetts Institute of Technology

Accomplishments
Accomplishments

• B-TOS mission characterized and defined
• Key attributes of swarm architectures determined
• Thousands of architectures traded
• Optimal architectures identified
• Sensitivities and design studies point to challenges, 
but basically validate design
• Requirements derived for a potential architecture

Completed process for architecture study
Completed process for architecture study
Selected and assessed a potential architecture
Selected and assessed a potential architecture
16.89 Architecture Review - 5 May 16, 2001       
Massachusetts Institute of Technology

Section Outline
Section Outline
• Introduction
– Motivation
– Project scope
– Objective
• Process Development
• Results
• B-TOS Requirements
• Spacecraft Design
• Review and Concluding Remarks

16.89 Architecture Review - 6 May 16, 2001       

Massachusetts Institute of Technology

User Driven Motivation and Needs
User Driven Motivation and Needs

• Ionosphere disturbs propagation of EM waves
• Need to model ionospheric variations for predictive purposes
• AFRL is primarily interested in two missions:
1. Studying global behavior of ionosphere
2. Characterize ionospheric turbulent regions (near equator)
• AFRL model inputs:
– Vertical Total Electron Content (TEC)
– Electron Density Profile (EDP)
– Beacon Angle of Arrival (AOA)

16.89 Architecture Review - 7 May 16, 2001       

Massachusetts Institute of Technology

Pedagogy Driven Motivation
Pedagogy Driven Motivation

• Measurable Outcomes
(cid:57)Organize and plan development of integrated space 
system architecture to meet customers’ needs
(cid:57)Establish functional and high level systems 
requirements
(cid:57)Interactively work in teams to conduct systems 
engineering trades across multiple system elements

“The process is as important as the final product”
“The process is as important as the final product”

16.89 Architecture Review - 8 May 16, 2001       

Massachusetts Institute of Technology

Constraints and Scope
Constraints and Scope
• Space-based data collection platform
• Swarm configuration
• Use top-side sounder 
– Minimum altitude
– Available instrument capabilities
• Frozen orbit (inclination = 63.4 degrees)
• Mission Life Fixed to 5 Years
• Use TDRSS for communication with the ground
• Bill Borer and Kevin Ray are aggregate customers 
representing all end users
• Scheduling constraints

Topside Sounding

16.89 Architecture Review - 9 May 16, 2001       

Massachusetts Institute of Technology

BB --TOS Information Network
TOS Information Network
B-TOS 
Swarms
scope

Ionosphere

Initial Processing

output data

“Blackbox”
Ground Processing
Hanscom Model

“Scientist”
User Set

Database

“Space Weather”
User Set

Other 
Data Sources
(Various assets)

Physics Model
Instrument -> Local Ionosphere
Ionospheric characteristics

Global Ionospheric Model
Current State

Global Ionospheric Model
Predict Future State

User-Specific
System Integration

“Knowledgeable”
User Set

16.89 Architecture Review - 10 May 16, 2001       

Massachusetts Institute of Technology

Mission Statement
Mission Statement

Design a conceptual swarm-based space 
system to characterize the ionosphere. 
Building upon lessons learned from A-TOS, 
develop a deliverable, by May 16, 2001, with 
the prospect for further application.  
Learn about engineering design process and 
space systems.

16.89 Architecture Review - 11 May 16, 2001       

Massachusetts Institute of Technology

Payload Mission Overview
Payload Mission Overview

Electron Density Profile (EDP)
Electron Density Profile (EDP)

Beacon Angle of Arrival (AOA)
Beacon Angle of Arrival (AOA)

F2 Peak

e
d
u
t
i
t
l
A

Electron Density

Ionosphere Turbulence
Ionosphere Turbulence

Payload ““BB””
Payload 

?

16.89 Architecture Review - 12 May 16, 2001       

Massachusetts Institute of Technology

Process Summary
Process Summary

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

Design 
space

Constants 
space

Design
Vector
Constants 
Vector

Section Outline
Section Outline
• Introduction
• Process Development
– Overview of Design Process
– Utility Attributes
– Design Vector
– Module Overview
• Results
• B-TOS Requirements
• Spacecraft Design
• Review and Concluding Remarks

16.89 Architecture Review - 14 May 16, 2001       

Massachusetts Institute of Technology

Process/Tools Levels
Process/Tools Levels

• Process: The whole SSPARC* process, including 
gather user needs, scoping the problem, Multi-
Attribute Utility Analysis (MAUA)
• Simulation: Design Vector to Utility and Cost
• Modeling: What the Code Does
• Tools: Matlab, N-Squared, QFD

* Space Systems, Policy, and Architecture Research Center 

16.89 Architecture Review - 15 May 16, 2001       

Massachusetts Institute of Technology

BB --TOS Process
TOS Process

Scope Design 
Space

Model 
Physics

Define User 
Utility

Design 
space

Constants 
space

Design 
Vector
Constants 
Vector

Model/
simulation

Attributes

Utility 
Function

Utility

Cost

Assess 
Archi-
tectures

Simulate Performance

Many tasks done simultaneously with high level of interaction

16.89 Architecture Review - 16 May 16, 2001       

Massachusetts Institute of Technology

BB --TOS Simulation Notional Flow
TOS Simulation Notional Flow

Design 
space

Constants 
space

Design 
Vector
Constants 
Vector

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

• Inputs: 
– Design vector (architecture)
– Constants vector (engineering constants, fixed design parameters)
• Outputs:
– Utility
– Cost
• Simulation developed using Matlab modules integrated with 
Satellite Tool Kit (STK)

16.89 Architecture Review - 17 May 16, 2001       

Massachusetts Institute of Technology

MultiMulti --Attribute Utility Analysis
Attribute Utility Analysis

Design 
space

Constants 
space

Design 
Vector
Constants 
Vector

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

Ut ility of  Ins tant Global Cove r age

1

0.8

0.6

0.4

0.2

y
t
i
l
i
t
U

0
5%

25%

45%
65%
% Cove r age

85%

•Process overview
•Definition of attributes
•Customer preferences

16.89 Architecture Review - 18 May 16, 2001       

Massachusetts Institute of Technology

MultiMulti --Attribute Utility Analysis (MAUA)
Attribute Utility Analysis (MAUA)
Description
A process to capture complex 
customer preferences for 
attributes of architectures.

Application in B-TOS
Assisted generating output 
metric for architecture 
comparison (utility).

Strengths
• Defines customer-perceived 
attributes of architectures  
• Captures trade-offs among 
preferences for different attributes
• Interactive process with customer 
helps refine customer needs
• Changes hard requirements to more 
flexible wants, resulting in better 
overall solutions
16.89 Architecture Review - 19 May 16, 2001       

Limitations
• Lengthy interview process
• Difficulty thinking probabilistically
• More than 6 attributes at a time is 
infeasible for single interview

Massachusetts Institute of Technology

MAUA Process
MAUA Process
(cid:57) 1. Define attributes
(cid:57) 2. Define attribute ranges (worst(cid:198)best case)
(cid:57) 3. Compose utility questionnaire
(cid:57) 4. Conduct utility interview with Customer/User
• Approx.  4 hours
• Customers = Bill Borer, Kevin Ray (AFRL/VSB)
(cid:57) 5. Conduct validation interview
• Approx. 3 hours

16.89 Architecture Review - 20 May 16, 2001       

Massachusetts Institute of Technology

Utility Attributes: MAUA Results
Utility Attributes: MAUA Results

1. Mission Completeness: Sub-set of missions performed
2. Spatial Resolution: Arc length of Earth between measurements
3. Revisit Time: Time between subsequent measurements of the same 
point above the Earth
4. Latency: Time delay from measurement to end user
5. Accuracy: Measurement error in angle of arrival data
Instantaneous Global Coverage: % of Earth’s surface in 
6.
view between subsequent measurements

16.89 Architecture Review - 21 May 16, 2001       

Massachusetts Institute of Technology

Converting Attributes to Utility
Converting Attributes to Utility

Good

1

0.8

y
t
i
l
i
t
U

0.6

0.4

0.2

0

Utility of  Accur acy (AOA)

y
t
i
l
i
t
U

1

0.8

0.6

0.4

0.2

0

Attributes

0

0.1

0.3
0.2
Accur acy (de gr e e s )

0.4

0.5

• Utility interview results in quantified relationship between 
attribute and usefulness of system to user (utility)
• Different curve for each attribute
• Mathematical combination of attribute values produces 
system utility

16.89 Architecture Review - 22 May 16, 2001       

Massachusetts Institute of Technology

Design Vector
Design Vector

Design 
space

Constants 
space

Design 
Vector
Constants 
Vector

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

E
G
N
A
R

s
t
i
n
U

S
E
T
U
B
I
R
T
T
A

m
k
 
,
.
g
e
% % d
s
s
e
n
e
t
e
l
p
m
o
C
 
n
o
i
s
s
i
M
 
y
e
v
r
u
S
 
l
a
b
o
l
G

s
s
e
n
e
t
e
l
p
m
o
C
 
n
o
i
s
s
i
M
 
e
c
n
e
l
u
b
r
u
T

 
n
o
i
t
u
l
o
s
e
R
 
l
a
i
t
a
p
S

z
H

B
t d

M
0
0
1
% $

 
e
g
a
r
e
v
o
C
 
l
a
b
o
l
G
 
s
u
o
e
n
a
t
n
a
t
s
n
I

T
S
O
C
 
/
w
 
L
A
T
O
T

 
t
s
o
C
 
e
l
c
y
c
e
f
i
L

L
A
T
O
T

 
n
o
i
t
u
l
o
s
e
R
 
e
m
i
T

y
c
n
e
t
a
L

y
c
a
r
u
c
c
A

VARIABLES
1 Apogee Altitude
2 Perigee Altitude
3 Number of Planes
4 Swarm per Plane
5 Satellites per Swarm
6 Sub-Orbits per Swarm
7 Size of Swarm
8 Sounding, [4]
9 Number of Sounding Antennas
10 Short Range Communications, [4]
11 Long Range Communications, [4]
12 On-Board Processing, [2]
13 Autonomy
TOTAL

Units
km
km
Integer
Integer
Integer
Integer
m
Y/N
Integer
Y/N
Y/N
Y/N

CONSTRAINTS W eight
a > p
a > p

concentric orbits

3 or 6

1 2 3 4 5 6 7 8

9
9
3
3
3

3
0
3

0
0

9
9
3
3
3

3
0
3

0
0

9
9
3
3
9

9
0
?

0
0

33 33 42

0
0
?
?
1

0
3
?

0
0

4

3
3
0
0
0

1
3
0

3
3

3
3
0
0
0

3
0
9

3
3

1
1
9
9
1

9
0
0

0
0

16 24 30

34
34
18
18
17
0
28
6
15
0
6
6
0

1
1
9
9
9

0
0
3

0
0

32

35
35
27
27
26
0
28
6
18
0
6
6
0

•Overview
•Tools employed
•Design vector

16.89 Architecture Review - 23 May 16, 2001       

Massachusetts Institute of Technology

Design Vector Overview
Design Vector Overview

• Design vector provides fundamental (independent) 
variables that define architecture trade space
– Focuses on variables that have significant impact on 
attributes
– Design vector excludes model constants
– Geometric growth of design space motivates curtailed list 
of design variables

• Provides a means for considering multitude of system 
architectures

16.89 Architecture Review - 24 May 16, 2001       

Massachusetts Institute of Technology

Quality Function Deployment (QFD)
Quality Function Deployment (QFD)
Description
Application in B-TOS
•Assisted generating design vector list.
A matrix to capture the relationship 
Prioritize technical requirements
between attributes and design vector 
•Provide requirement and attribute trace 
inputs.
ability and booking keeping
Mechanism to weigh design vector 
•Provide a simple easy to understand 
options against each others.
communication mechanism
Limitations
•Requires substantial technical 
knowledge and iteration to 
maximize usefulness
•Must be re-scaled when new 
customer requirements are added

Strengths
•Expedite correlation of variables 
with attributes
•Rank order most critical variables 
and influence on attributes
•Reduce variable list to minimize 
trade space dimensionality
•Minimize human biases

16.89 Architecture Review - 25 May 16, 2001       

Massachusetts Institute of Technology

Large 
Scale 
Arch.
Swarm 
Arch.

Design Vector Variables
Design Vector Variables
Rationale
Variable
Specifies  o rb it /relat ions h ip  to  ionos phere
Apogee A lt itude
Perigee A lt itude
Specifies  o rb it /relat ions h ip  to  ionos phere
Key  to  meet ing  g lobal coverage need s
Number o f Planes
Key  to  meet ing  g lobal coverage need s
Swarm per Plane
Satellites  per Swarm
Local coverage res o lu t ion
Size o f Swarm
Local coverage res o lu t ion
Number o f Sound ing  An tennas Cap tu res  funct ionality  trade
Cap tu res  funct ionality  trade
Sound ing
Sho rt  Range Commun icat ions
Cap tu res  funct ionality  trade
Cap tu res  funct ionality  trade
Long  Range Commun icat ions
On -Board  Proces s ing
Cap tu res  funct ionality  trade
•Payload, four choices available:
•Communication and processing, two 
choices available:
– 0 = none
– 0 = none
– 1 = send
– 1 = yes (all)
– 2 = receive
– 3 = both
16.89 Architecture Review - 26 May 16, 2001       

Vehicle 
Arch.

Massachusetts Institute of Technology

Modeling
Modeling

Design 
space

Constants 
space

Design 
Vector
Constants 
Vector

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

•Code overview
•Tools employed
•Module descriptions

s
t
n
a
t
s
n
o
C

m
r
a
w
S

n
g
i
s
e
D

W
D C S

y
t
i
l
i
b
a
i
l
e
R

t
i
b
r
O

p
o
r
p
t
i
b
r
O

h
c
n
u
a
L

s
n
o
i
t
a
r
e
p
O

g
n
i
t
s
o
C

P
R
R O O

S
P
L O

t
s
o
C

l
e
r
m
r
a
w
S

R
W
S

s
e
t
u
b
i
r
t
t
A
_
e
t
a
l
u
c
l
a
C

e
m
i
T

n
o
i
t
c
n
u
F
 
y
t
i
l
i
t
U

S
O
T
B
_
t
u
p
t
u
o

t
f
a
r
c
e
c
a
p
S

C
T A S

t
u
U o

x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x

x

x

x

x
x
x
x

x

x

x

x

x

x

x
x

x

x

x

x

Module Name
D
Design
C
Constants
SW Swarm
SWR Swarmrel
R
Reliability
O
Orbit
ORP Orbitprop
L
Launch
OPS Operat ions
Cost Cost ing
T
Time
A
Calculate_Attributes
SC
Spacecraft
U
Ut ility Funct ion
out
output_BTOS

16.89 Architecture Review - 27 May 16, 2001       

Massachusetts Institute of Technology

Organization Rationale
Organization Rationale

MAIN

• Swarm
• Time
• Orbit
• Reliability
• Launch
• Operations

Attributes 
Calculation

Costing

Utility 
Function

Utility

Cost

•Attribute calculation separated from space system parameters 
– Attributes are mission specific
– Enhances code generality and reusability

16.89 Architecture Review - 28 May 16, 2001       

Massachusetts Institute of Technology

Teams and Responsibilities
Teams and Responsibilities

Teams are organized based on software modules
S econd a ry  R ep .
P rima ry  R ep .
Modu le
M a in
A dam  Ros s
Q i Dong
BTOS  S he l l A dam  Ros s
Q i Dong
O rb i t
S c ot t  K im brel
S andra K as s in-Deardorff
Sw a rm
B randon W ood
Nathan Di l ler
S pa ce cra ft
Nathan Di l ler
B rian P ec k
La unch
Dan K irk
B rian P ec k
Ope ra tions B randon W ood
Nathan Di l ler
Re l ia b i l i ty
Dan K irk
M ic hel le M c V ey
Costing
Dan K irk
M ic hel le M c V ey
Attribu te
Carole  Joppin
B randon W ood
Uti l i ty
Carole Joppin
Carol  Joppin
A dam  Ros s
Q i Dong
A dam  Ros s

In te g ra tion

16.89 Architecture Review - 29 May 16, 2001       

Massachusetts Institute of Technology

Unified Modeling Language (UML)
Unified Modeling Language (UML)
Description
Application in B-TOS
Assisted designing high level 
A set of software design 
software modules and 
diagramming tools.
visualizing module 
interactions.

Strengths
• Stresses the importance of user 
needs
• Shows the interactions among 
modules
• Facilitates system architecture 
design

Limitations
• Difficult to implement at 
detailed coding level when the 
programming language is not 
Object-oriented.

16.89 Architecture Review - 30 May 16, 2001       

Massachusetts Institute of Technology

Software I/O Management Workbook
Software I/O Management Workbook
Description
Application in B-TOS
Assisted the interface 
A set of Microsoft Excel 
management of software 
spreadsheets to record the 
modules.
interface variables of each 
software module.
Strengths
• Excel is easy to use and to program  
• Embedded Visual Basic program 
automatically checks the consistency 
of the software I/O.
• Enabled communication among 
module development teams for 
integration purpose.

Limitations
• Accuracy depends on how up-
to-date the module I/O sheets are.

16.89 Architecture Review - 31 May 16, 2001       

Massachusetts Institute of Technology

NN22 Diagram
Diagram
Description
A square matrix that captures 
the information flow among 
system elements.

Strengths
• Exposes the iteration loops among 
the modules and facilitates design 
simplifications.
• Assisted the integration of the 
modules.

Application in B-TOS
Assisted the system interface 
management and integration of 
the software modules.

Limitations
• Good system analysis tool, but 
limited in predicting system 
interactions.  

16.89 Architecture Review - 32 May 16, 2001       

Massachusetts Institute of Technology

Module Descriptions
Module Descriptions
• Swarm: Calls on the spacecraft module to define the 
spacecraft parameters for the entire swarm
• Reliability: Determines probability that a particular 
number of satellites are operational in any swarm at 
a given time
• Time: Determines mission, accuracy, and latency
• Orbit: Propagates orbital trajectories from initial 
conditions
• Attributes: Calculates value of 6 attributes at three 
different times (BOF, mid-mission, EOF) for utility 
function
16.89 Architecture Review - 33 May 16, 2001       

Massachusetts Institute of Technology

Module Descriptions
Module Descriptions

• Utility: Calculates “value” tradeoffs of the attributes 
(metrics) for a particular architecture
• Operations: Calculates operations personnel and 
facilities costs
• Launch: Selects lowest cost launch vehicle(s) that can 
deploy all satellites in a swarm
• Costing: Calculates spacecraft, operations, launch, 
and program level costs, incorporates learning curve 
for different spacecraft types

16.89 Architecture Review - 34 May 16, 2001       

Massachusetts Institute of Technology

Example Module: Launch
Example Module: Launch

Description
Description
•Selects lowest cost launch vehicle(s) 
that can deploy all satellites for a single 
swarm.
•Once a launch vehicle is selected, total 
cost for initial deployment is computed.

Key Assumptions
Key Assumptions
•Launch vehicle and cost is function of: 
number of satellites/swarm, stowed 
dimensions of satellite, orbital altitude, 
launch vehicle mass capacity, and 
launch vehicle payload dimensions
•Assumes 100% launch success rate

Fidelity Assessment
Fidelity Assessment
•First iteration makes use of average 
satellite mass
•Considers 6 different launch vehicle 
possibilities and 14 altitudes

Verification
Verification
•Tested over range of satellite numbers, 
satellite masses and swarm sizes
•Fully integrated into B-TOS master 
design code

16.89 Architecture Review - 35 May 16, 2001       

Massachusetts Institute of Technology

Section Summary
Section Summary

• Review
– Motivation
– Project scope
– Objective
• Process Development
– Overview of Design Process
– Utility Attributes
– Design Vector
– Module Overview

16.89 Architecture Review - 36 May 16, 2001       

Massachusetts Institute of Technology

Results
Results

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

Design 
space

Constants 
space

Design 
Vector
Constants 
Vector

Section Outline
Section Outline

• Introduction
• Process Development
• Results
– Architecture Survey Results
– Sensitivity Analysis
• B-TOS Requirements
• Spacecraft Design
• Review and Concluding Remarks

16.89 Architecture Review - 38 May 16, 2001       

Massachusetts Institute of Technology

BB --TOS Model Analytical Capability
TOS Model Analytical Capability

• Variation of orbital geometries 
• Multiple swarm size and density options
• Satellites have individually varying 
functionality

Model currently produces a focused tradespace,
Model currently produces a focused tradespace,
not a single-point architecture
not a single-point architecture

16.89 Architecture Review - 39 May 16, 2001       

Massachusetts Institute of Technology

Tradespace Enumeration
Tradespace Enumeration

• Circular orbit altitude (km)
• Number of Planes
• Number of Swarms/Plane
• Number of Satellites/Swarm
• Radius of Swarm (km)
• 5 Configuration Studies

1100, 1300
1, 2, 3, 4, 5
1, 2, 3, 4, 5
4, 7, 10, 13
0.18, 1.5, 8.75, 50
Trades payload, 
communication, and 
processing capability

4,033 Architectures
4,033 Architectures
73 Hrs total computation time with 8 Pentium IIIs
73 Hrs total computation time with 8 Pentium IIIs

16.89 Architecture Review - 40 May 16, 2001       

Massachusetts Institute of Technology

Swarm Geometry
Swarm Geometry
• Max baseline length is defined 
by desired angle of arrival 
accuracy (.0005 degrees)
• Minimum baseline length 
limited by beacon frequency 
(100 MHz)
• Swarm suborbit spacing is a 
factor of 5.7 and defined by:
• Phase error of the swarm
• Frequency of the beacons
• Filling the baselines ensures no 
ambiguity in the angle of 
arrival measurement
Massachusetts Institute of Technology

Mothership
Mothership
Daughterships
Daughterships
Swarm Suborbits
Suborbits
Swarm 

MaxMax Baseline Length
Baseline Length

16.89 Architecture Review - 41 May 16, 2001       

Configuration Studies
Configuration Studies

Study
Type
Number
Payload (Tx)
Payload (Rx)
Processing
TDRSS Link 
Intra-Swarm Link

1

M
4+
Yes
Yes
Yes
Yes
No

D
0
n/a
n/a
n/a
n/a
n/a

2

M
1
Yes
Yes
Yes
Yes
Yes

D
3+
Yes
Yes
No
No
Yes

3

M
1
Yes
Yes
Yes
Yes
Yes

4

D
M
D
3+
1
3+
No
Yes
Yes
No
Yes
Yes
Yes
No
Yes
No
Yes
No
Yes
Yes
Yes
M = Mothership

5

D
M
3+
1
No
Yes
Yes
Yes
No
Yes
No
Yes
Yes
Yes
D = Daughter

• Study 1:  All spacecraft are independent
• Study 2:  Mothership processes and downlinks
• Study 3:  Distributed processing
• Study 4:  Mothership dedicated to processing and downlink (no payload)
• Study 5:  Mothership processes, downlinks, and has payload transmitter

16.89 Architecture Review - 42 May 16, 2001       

Massachusetts Institute of Technology

Lifecycle Costs vs. Utility
Lifecycle Costs vs. Utility
(Entire Tradespace
Tradespace : 4,033 Architectures)
: 4,033 Architectures)
(Entire 

(next slide)

Architectures not 
completing beacon 
AOA mission

1

0.95

0.9

0.85

0.8

y
t
i
l
i
t
U

0.75
100

1000
Lifecycle Cost ($M)
Completing AOA mission is main driver for utility
Completing AOA mission is main driver for utility
16.89 Architecture Review - 43 May 16, 2001       
Massachusetts Institute of Technology

10000

Lifecycle Costs vs. Utility
Lifecycle Costs vs. Utility
(Utility > 0.98)
(Utility > 0.98)

1

0.995

y
t
i
l
i
t
U

0.99

0.985

Swarm Radius = 50 km

Swarm Radius = 8.75 km

Swarm Radius = 1.5 km

0.98
100

(next slide)
1000
Lifecycle Cost ($M)
Radius of the swarm is the main differentiator between architectures of high utility
Radius of the swarm is the main differentiator between architectures of high utility
16.89 Architecture Review - 44 May 16, 2001       
Massachusetts Institute of Technology

Swarm Radius = 0.18 km

10000

Lifecycle Costs vs. Utility
Lifecycle Costs vs. Utility
(Frontier Architectures)
(Frontier Architectures)

D

C

E

B

1

0.995

y
t
i
l
i
t
U

0.99

0.985

A

0.98
100

1000

Lifecycle Cost ($M)
Frontier architectures are the most desirable
Frontier architectures are the most desirable
16.89 Architecture Review - 45 May 16, 2001       
Massachusetts Institute of Technology

Frontier Architectures
Frontier Architectures

Po in t
A lt itude (km)
Num o f Planes
Swarms /Plane
Satellites /Swarm
Swarm Rad ius  (km)
Funct ionality  Study

Recall:

A

1
4
0.18

B

1
7
1.5

C
<--  1100   -->
<-- 1 -->
1
10
8.75
<--   #5  -->

D

1
13
50

Study
Type
Number
Pay load  (Tx)
Pay load  (Rx)
Proces s ing
TDRSS Link 
In tra-Swarm Link

5

M
1
Yes
Yes
Yes
Yes
Yes

E

2
13
50

D
3+
No
Yes
No
No
Yes

16.89 Architecture Review - 46 May 16, 2001       

Massachusetts Institute of Technology

Frontier Attributes, Utility, & Cost
Frontier Attributes, Utility, & Cost

Po in t
Sp a t ia l Re s o lu t io n  (d eg )
Rev is it  T ime  (min )
La t en cy  (min )
A c c u ra cy  (d e g )
In s t . Glo b a l Co v e rag e

Ut ilit y
IOC Co s t  ($M )
Life c y c le  Co s t  ($M )

A
4.36
805
3.40
0.15
0.29%

0.9835
90
148

B
5.25
708
3.69
0.018
0.29%

0.9914
119
194

C
7.34
508
4.36
0.0031
1.15%

0.9973
174
263

D
9.44
352
5.04
0.00054
2.28%

0.9992
191
287

E
9.44
195
5.04
0.00054
4.55%

0.9994
347
494

Frontier architectures can be evaluated using 
Frontier architectures can be evaluated using 
attributes in place of nondimensional utility values
attributes in place of nondimensional utility values

16.89 Architecture Review - 47 May 16, 2001       

Massachusetts Institute of Technology

Cost Breakdown: Point C
Cost Breakdown: Point C

All 10 Spacecraft
$101M

Launch
$54M
(2 Athena IIs)

Operations
$99M

16.89 Architecture Review - 48 May 16, 2001       

Massachusetts Institute of Technology

Total Lifecycle:  $263M

Architecture Analysis Summary
Architecture Analysis Summary

•

• Architecture must collect beacon angle of arrival 
data to be in best part of tradespace
Swarm radii become key differentiator between 
optimum architectures
• Most promising trades revolve around
Simple orbit geometry 
–
Single swarm missions
–
– Consolidating functionality on mothership
Complicated mothership (payload processing, payload 
•
transmitter, and TDRSS link)
Simple daughterships

•

16.89 Architecture Review - 49 May 16, 2001       

Massachusetts Institute of Technology

Sensitivity Analysis Rationale
Sensitivity Analysis Rationale

• Study dependence of cost and utility on the 
main constants 
• Test sensitivity to the main assumptions used 
in the code

Sensitivity analysis validates results and 
Sensitivity analysis validates results and 
optimum architectures
optimum architectures

16.89 Architecture Review - 50 May 16, 2001       

Massachusetts Institute of Technology

Parameters Studied 
Parameters Studied 

• Focused analysis of Multi-Attribute Utility function
• Varied 12 previously constant parameters by ±5% and  ±10%
– Spacecraft mass
– Flight software cost
– Instrument phase error
– EDP data collection time 
– Beacon wavelength
– Beacon data collection time
– GPS time error
– Maintenance time factor
– GPS position error
– No TDRSS time factor
– Assumed bearing
– Ops scale factor
• Varied 4 previously constant parameters
– Dataset delay
– MTTF
– Turbulence data collection time
– Mission life
• Swarm geometry and Delta V implications

16.89 Architecture Review - 51 May 16, 2001       

Massachusetts Institute of Technology

Cost Sensitivity
Cost Sensitivity

Cost Sensitivity
$280

n
spacecraft mass
o
i
l
l
i
M
flight software cost
no tdrss time
ops scale factor

$275

$270

$265

$260

$255

$250

$245

"Point C" Cost
$263M

)
$
 
n
o
i
l
l
i
M
(
 
t
s
o
C

-5%

-10%

0%
Constant % Change 
• Cost is most sensitive to S/C mass  
–10 % change in S/C mass results in $15 M shift
• Cost is less sensitive to ops scale factor
16.89 Architecture Review - 52 May 16, 2001       

5%

10%

Massachusetts Institute of Technology

Utility Sensitivity
Utility Sensitivity
Utility Sensitivity
"Point C" 
Utility 
0.997274

y
t
i
l
i
t
U

0.9975
0.99745
0.9974
0.99735
0.9973
0.99725
0.9972
0.99715
0.9971
0.99705
0.997

instrument
phase error
beacon
wavelength
gps time
error
gps position
error
bearing
edp time
beacon time

-10%

5%
0%
-5%
Constant % Change
Even largest error maintains same architecture choice
Even largest error maintains same architecture choice

10%

16.89 Architecture Review - 53 May 16, 2001       

Massachusetts Institute of Technology

Frontier Architecture Sensitivity Summary
Frontier Architecture Sensitivity Summary

D

C

E

Worst case 
Worst case 
sensitivity 
sensitivity 
ellipse
ellipse

B

A

1

0.995

y
t
i
l
i
t
U

0.99

0.985

0.98
100

1000

Lifecycle Cost ($M)
Even largest error maintains same architecture choice
Even largest error maintains same architecture choice
16.89 Architecture Review - 54 May 16, 2001       
Massachusetts Institute of Technology

System Level Requirements
System Level Requirements

Presentation Outline
Presentation Outline
• Introduction
• Process Development
• Results
• B-TOS Requirements
– System Level
– Segment Level
– Element Level
• Spacecraft Design
• Review and Concluding Remarks

16.89 Architecture Review - 56 May 16, 2001       

Massachusetts Institute of Technology

Requirements Hierarchy
Requirements Hierarchy

m
l
e
e
v
t
s
e
y
L
S

l
e
v
e
L
 
t
n
e
m
g
e
S

 
t
n
l
e
e
v
m
e
e
L
l
E

B-TOS
B-TOS
System (B)
System (B)

External 
External 
Interface (E)
Interface (E)

Ground 
Ground 
Segment (G)
Segment (G)

Space (Constellation) 
Space (Constellation) 
Segment (C)
Segment (C)

Space (Swarm) 
Space (Swarm) 
Segment (S)
Segment (S)

Mothership 
Mothership 
Element (M)
Element (M)

Daughtership 
Daughtership 
Element (D)
Element (D)

Refer to appendix C of design document for complete B-TOS requirement document

16.89 Architecture Review - 57 May 16, 2001       

Massachusetts Institute of Technology

System Level Requirements
System Level Requirements

• B-TOS system level
– Contents: Mission characterization, payload B, US launch 
vehicle, lifetime, TDRSS
– Example: The B-TOS system shall have the capability to collect data 
from the topside of the ionosphere below 1100 km to produce an 
Electron Density Profile (EDP).
• External requirements
– Contents: Constrained to interface with external systems 
(TDRSS, beacons, US launch vehicle) and compatibility 
with the AFRL model
– Example: The B-TOS space system will be capable of communicating 
with TDRSS

16.89 Architecture Review - 58 May 16, 2001       

Massachusetts Institute of Technology

Segment Level Requirements
Segment Level Requirements

• Constellation
– Contents: Constellation orbital parameters, revisit time 
and global coverage
– Example: The constellation shall have one plane.
• Swarm
– Contents: Swarm configuration and geometry, 
communication, accuracy and spatial resolution
– Example: Each swarm shall have ten satellites consisting of 1 mothership and 9 
daughterships.
• Ground
– Contents: Scheduling, communication, telemetry, payload 
data processing, command and control
– Example: The operations center shall perform mission scheduling.

16.89 Architecture Review - 59 May 16, 2001       

Massachusetts Institute of Technology

Element Level Requirements
Element Level Requirements

• Mothership
– Contents: Mission capability, functionalities, 
communication, data compression
– Example: The mothership shall have a communication subsystem 
capable of sending data at 5 Mbps and receiving data at 100 kbps with 
the ground via TDRSS’ S-band single access antennas at 10-6 bit error 
rate.
• Daughtership
– Contents: Mission capability, functionalities, 
communication
– Example: The daughtership shall have a communication subsystem 
capable of sending data at 1.2 Mbps and receiving data at 10 kbps with 
the mothership.

16.89 Architecture Review - 60 May 16, 2001       

Massachusetts Institute of Technology

Spacecraft Design
Spacecraft Design

Spacecraft Design Overview
Spacecraft Design Overview

Designed mothership for architecture “C”

• B-TOS Spacecraft Design Process

• Preliminary Mothership Design Results

16.89 Architecture Review - 62 May 16, 2001       

Massachusetts Institute of Technology

Mothership Design Process
BB --TOS 
TOS Mothership
Design Process

• Utilized simplified Integrated Concurrent 
Engineering (ICE) design method
– ICE method developed at Cal Tech
• Each individual assigned a subsystem 
• Excel spreadsheets created to spec each subsystem 
using SMAD equations 
• N2 diagram created to determine subsystem 
dependencies and flow of calculations
• One iteration completed and a first-order 
mothership design specified

16.89 Architecture Review - 63 May 16, 2001       

Massachusetts Institute of Technology

Subsystem Breakup and Descriptions
Subsystem Breakup and Descriptions
Sub-system
Requirement
Approach
Power
Size battery and solar cell
Full ops at end of life, peak 
and avg
Acceptable temp range at 
eol, temp range

Energy balance

Thermal

Payload

Comm

Attitude

Structure 

C.D.H

Propulsion

Configuration

Mass
Reliability

Cost

List from customer

Set requirements for other systems

Comm through TDRSS and 
with all daughters

Link budget

Set by payload

Select and size sensors, wheels, and motors

Not fail or resonate

15% mass fraction budget

Support operations, survive 
environment

Recall ops scenarios, develop link budget inputs, 
select and size computers and recorders

Provide deltaV and max 
impulse to support ops 
scenarios
Fit in launch vehicle and 
config in 3D
Launchable
No single-point failures of 
vulnerable systems

Select and size motors, possibly combined with 
attitude, consider drag, deorbit, margin, NOT 
differentials
Sketch or CAD

Sum up systems’ masses
Check batteries, computers, sensors, thrusters, 
thermal

Not exceed reasonable cost

SMAD cost estimating relationships

Who
Carole

Adam

Scott, Brandon

Nathan

Hugh

Scott, Brandon

Brian, Hugh

Sandra

Hugh
Dan

Michelle

16.89 Architecture Review - 64 May 16, 2001       

Massachusetts Institute of Technology

NN22 Diagram 
Diagram –– Subsystem Info Flow
Subsystem Info Flow
Payload
Struct.
Power Mass
Config.
Prop.
Therm.
Comm.
C.D.H.
Attitude
X
R
R
R

X

Payload

Attitude

C.D.H.

Comm.

Reliab.

Cost

f
f
f

f

f

X

f

f
f
f

f

X

f
f
f
I
I
B
X
B

I
I

f
f
f
f
f

f
X
I

I

X

I

R
R
X
R

X
I
R

I
B
B

I
I

B
B

I
I

I
I
I
I
B
B

I
I

I
I
I
X

X

I
B
B

I

R
X
I
B
B

I
I

Therm.

Prop.

Config.

Power

Mass

Struct.

Reliab.

Cost

R
R
R

I

I = Input
R = Input from Requirements
B = Budget
f = Possible feedback
16.89 Architecture Review - 65 May 16, 2001       

Info flows from columns
Into rows
Massachusetts Institute of Technology

Attitude

Preliminary Mothership
Mothership Design Results
Design Results
Preliminary 
Cost
Mass
Power
Spec
Sub-system
Payload
6 omni antenna plus 
64W
36kg
N/A
transceivers
3-axis momentum 
wheels
Computers plus data 
storage
0.5m diameter 
antenna
0.32m2 radiator plus 
radiative paint
12 PPT thrusters

4.5% dry mass

Propulsion

7kg

5kg

10W

1.3W

20W

14W

C.D.H.

Comm

Thermal

20kg

40W

Configuration

Cylinder (D=H=1.5m)

N/A

Power

Mass

2.5m2 Si body 
mounted solar arrays 
4 NiCd batteries

Sum of all systems

Reliability
Cost

N/A
SMAD cost est. 
relationships (CERs)
16.89 Architecture Review - 66 May 16, 2001       

Total Power Req: 
150W

N/A

N/A
N/A

N/A
N/A

N/A
S/C Total:
$45M  (±19)
Massachusetts Institute of Technology

$9.8M (±4.4)

$6M (±2.4)

$3M (±0.6)

$8M (±1.4)

$6.5M (±1.5)

$1.6 (±1)

$16.7M (±7.1)

N/A

20kg dry plus 7.30kg 
fuel
27kg (structure plus 
thermal)
33.5kg

Totals: 185kg dry
193kg w/ fuel
208kg boosted

Mothership
Mothership

Omni antenna
for swarm comm

High gain antenna
for data relay (D ~ 0.5m)

6 omni “whip”
antennae for payload

Body mounted
Si solar cells

H = 1.5m

Basic shape can be changed, 
assumed cylinder for first iteration

D = 1.5m

16.89 Architecture Review - 67 May 16, 2001       

Massachusetts Institute of Technology

Mothership Design Results
Preliminary Mothership
Design Results
Preliminary 

• Spacecraft for architecture “C” appears to be 
feasible.
• Mass was up 17%, and power down 21%, from 
estimates made as part of the architecture study
• Mothership cost (~$45M) is a significant fraction of 
the total spacecraft budget (from the architecture 
study, ~$101M)
• Comm. requirements were severe for TDRSS relay 
(~10Mbps) and would compete with ISS and Shuttle 
• Body mounted solar cell area approaching limit for 
power needs (~150W)

16.89 Architecture Review - 68 May 16, 2001       

Massachusetts Institute of Technology

Summary
Summary

Model/
simulation

Attributes

Utility 
Function

Utility
Cost

Design 
space

Constants 
space

Design
Vector
Constants 
Vector

Strategy and Process (1)
Strategy and Process (1)

1. Collect stakeholder value propositions
(cid:57) Professors
(cid:57) Customer
(cid:57) Students
2. Develop mission statement
3. Develop utility function
(cid:57) Create list of system attributes
(cid:57) Conduct utility function interview
(cid:57) Create utility function based upon customer responses

16.89 Architecture Review - 70 May 16, 2001       

Massachusetts Institute of Technology

Strategy and Process (2)
Strategy and Process (2)
4. Define design space
(cid:57) Create list of design variables (design vector)
(cid:57) Map design variables to system attributes using QFD to 
determine which variables will be important
(cid:57) Eliminate extraneous variables to make a design vector of 
manageable size
(cid:57) Define design space by determining appropriate ranges 
for design vector variables, using available technologies, 
physical and system constraints

16.89 Architecture Review - 71 May 16, 2001       

Massachusetts Institute of Technology

Strategy and Process (3)
Strategy and Process (3)

5. Develop model of the system
(cid:57) Define metrics to be evaluated
(cid:57) Partition the problem into modules that calculates system 
attributes based upon design vector inputs
(cid:57) Integrate modules into a single model
6. Evaluate all possible meaningful architectures with 
respect to the utility function
(cid:57) Use model to iterate across design space and evaluate 
utility of all architectures
(cid:57) Select architecture(s) that best fit customer needs
7. Design space system based upon selected 
architecture

16.89 Architecture Review - 72 May 16, 2001       

Massachusetts Institute of Technology

Accomplishments
Accomplishments
• B-TOS mission characterized and defined
• Key attributes of swarm architectures determined
• Thousands of architectures traded
– Captured “goodness” of architecture through utility analysis
• Code is robust and modular:
– Easy to upgrade
– Can accommodate distinct satellite types with different functionality 
combinations
• Optimal architectures identified
• Narrowed tradespace facilitates future analysis and direction
• Sensitivities and design studies point to challenges, but 
basically validate design
• Requirements derived for a potential architecture

16.89 Architecture Review - 73 May 16, 2001       

Massachusetts Institute of Technology

Lessons Learned
Lessons Learned
• Process validated
– Helps to surface issues early 
– Forces solution with traceable decision rationale
• Communication was key!
– Iteration with customer was vital because of mission 
complexity—learning process for us and AFRL
– Facilitated by web-based tools and early emphasis on 
integration of code
– Hindered by lack of suitable lexicon and evolving definitions

Consistent and clear communication 
Consistent and clear communication 
proved indispensable
proved indispensable
16.89 Architecture Review - 74 May 16, 2001       

Massachusetts Institute of Technology

Backup Slides
Backup Slides

16.89 Architecture Review - 75 May 16, 2001       

Massachusetts Institute of Technology

Appendix Slides
Appendix Slides

• Integration Process and Tools

16.89 Architecture Review - 76 May 16, 2001       

Massachusetts Institute of Technology

Integration Process
Integration Process

• Started coding process with A-TOS modules
• Developed and maintained I/O sheets to 
manage interface consistency between modules
– Facilitated communication between teams through 
I/O sheets
• Constructed N2 diagram to show information 
flow between modules

16.89 Architecture Review - 77 May 16, 2001       

Massachusetts Institute of Technology

I/O Sheets
I/O Sheets

Checked the interface variable 
Checked the interface variable 
consistency using an embedded macro
consistency using an embedded macro

16.89 Architecture Review - 78 May 16, 2001       

Massachusetts Institute of Technology

NN22 Diagram
Diagram

s
t
n
a
t
s
n
o
C

m
r
a
w
S

n
g
i
s
e
D

W
D C S

y
t
i
l
i
b
a
i
l
e
R

t
i
b
r
O

p
o
r
p
t
i
b
r
O

h
c
n
u
a
L

s
n
o
i
t
a
r
e
p
O

g
n
i
t
s
o
C

P
R
R O O

S
P
L O

t
s
o
C

l
e
r
m
r
a
w
S

R
W
S

s
e
t
u
b
i
r
t
t
A
_
e
t
a
l
u
c
l
a
C

e
m
i
T

n
o
i
t
c
n
u
F
 
y
t
i
l
i
t
U

S
O
T
B
_
t
u
p
t
u
o

t
f
a
r
c
e
c
a
p
S

C
T A S

t
u
U o

Information Flow
Direction

x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x

x

x

x

x
x
x
x

x

x

x

x

x

x

x
x

x

x

x

x

Module Name
D
Design
C
Constants
SW Swarm
SWR Swarmrel
R
Reliability
O
Orbit
ORP Orbitprop
L
Launch
OPS Operations
Cost Cost ing
T
Time
A
Calculate_Attributes
SC
Spacecraft
U
Utility Function
out
output_BTOS

16.89 Architecture Review - 79 May 16, 2001       

Massachusetts Institute of Technology

Valuable Lessons from N22 Diagram
Diagram
Valuable Lessons from N

• N2 diagram shows waterfall process
• Coding process is highly iterative
• N2 diagram is good at capturing stable 
processes and improving it
– N2 diagram can be used to direct action for C-TOS 
if codes are similar and reduce design iterations
• Process of learning about the relationship 
between modules is highly iterative

16.89 Architecture Review - 80 May 16, 2001       

Massachusetts Institute of Technology

Valuable Lessons from Integration
Valuable Lessons from Integration

• Process showed that accurate and routinely 
updated I/O sheets were important
• Individual module verification can reduce 
integration workload 
• Adding functionality (error trapping) at mid-
point in code development was helpful but 
problematic
• Spring Break added difficulty to 
communication at a crucial time in process

16.89 Architecture Review - 81 May 16, 2001       

Massachusetts Institute of Technology

Generalized Information Network Analysis 
Generalized Information Network Analysis 
(GINA)
(GINA)
Description

A process to model space 
systems as an information 
network.

Application in B-TOS
Assisted generating code 
structure as per A-TOS 
code. Identified major 
module areas.

Strengths
• Streamlines modeling process by 
identifying major code components
• Provides framework for 
comparing thousands (or more) of 
architectures using common metrics

Limitations
• Strict GINA process has 
information metrics that may not 
relate to customer preferences
• Difficulty thinking in terms of 
information flow

16.89 Architecture Review - 82 May 16, 2001       

Massachusetts Institute of Technology

Evolution of B --TOS Utility Attributes
TOS Utility Attributes
Evolution of B

•

•

Time resolution changed to revisit time during utility 
interview
Accuracy defined by two attributes with different 
metrics and relative importance 
Electron Density Profile (EDP) accuracy
•
Beacon Angle of Arrival (AOA) accuracy
•
• Discussions with customer to understand candidate 
attributes and resolve misunderstandings
• Understand tasking issues for mission completeness

16.89 Architecture Review - 83 May 16, 2001       

Massachusetts Institute of Technology

Mission Completeness
Mission Completeness

Ut ility o f  In s tan t  M is s io n  Com p le te n e s s

y
t
i
l
i
t
U

1

0.8

0.6

0.4

0.2

0

0

1
2
M is s io n s  com p le te d

3

• Mission Completeness is a step function representing the 
combinations of measurement missions performed. 
0,1,2,3: EDP, EDP/Turb, EDP/AOA, EDP/AOA/Turb

•

16.89 Architecture Review - 84 May 16, 2001       

Massachusetts Institute of Technology

Spatial Resolution
Spatial Resolution

Ut ility of  Spat ial Re s olut ion

y
t
i
l
i
t
U

1

0.8

0.6

0.4

0.2

0

0

10

30
20
Re s olut ion (de gr e e xde gr e e )

40

50

•

The spatial resolution is the size of a measurement 
pixel (as determined by the time between data sets).

16.89 Architecture Review - 85 May 16, 2001       

Massachusetts Institute of Technology

Revisit Time
Revisit Time

Ut ilit y o f  Re v is it  T im e

y
t
i
l
i
t
U

1

0.8

0.6

0.4

0.2

0

5

205

405
Re vis it  (m in u t e s )

605

•

Revisit time is the time elapsed between measurement sets at 
the same point.  The points are represented by a grid based 
upon spatial resolution which is projected upon the Earth.

16.89 Architecture Review - 86 May 16, 2001       

Massachusetts Institute of Technology

Latency
Latency

Ut ility of Late ncy

y
t
i
l
i
t
U

1

0.8

0.6

0.4

0.2

0

0

20

40
80
60
Late ncy (m inute s )

100

120

•

Latency is the time elapsed between data collection and 
reception of processed data by the user.

16.89 Architecture Review - 87 May 16, 2001       

Massachusetts Institute of Technology

Accuracy (EDP)
Accuracy (EDP)

Ut ility of  Accur acy (EDP)

y
t
i
l
i
t
U

1

0.8

0.6

0.4

0.2

0

0.7

0.75

0.9
0.85
0.8
Accur acy (% ce r tainty)

0.95

1

•

EDP accuracy represents the size of the error bars on the 
EDP measurement.

16.89 Architecture Review - 88 May 16, 2001       

Massachusetts Institute of Technology

Instantaneous Global Coverage
Instantaneous Global Coverage

Ut ility of  Ins tant  Global Cove r age

1

0.8

0.6

0.4

0.2

y
t
i
l
i
t
U

0
5%

25%

45%
65%
% Cove r age

85%

•

Instantaneous global coverage is the percentage of the globe 
over which measurements are taken within the time 
resolution of the system.

16.89 Architecture Review - 89 May 16, 2001       

Massachusetts Institute of Technology

Design Vector Evolution
Design Vector Evolution

(cid:57) Method for developing design vector employed
(cid:57) Eliminated binary mothership design trade but 
maintained concept through selectable satellite 
functionality
(cid:57) Design vector rigid enough to define unique 
architectures through model development, yet 
flexible enough to allow honing:
– With weighting of attribute importance
– Range of attributes

16.89 Architecture Review - 90 May 16, 2001       

Massachusetts Institute of Technology

Launch
Launch

Description
Description
•Selects the lowest cost launch vehicle 
that can deploy all of the satellites for a 
single swarm.
•Once a launch vehicle is selected, total 
cost for initial deployment is computed.

Key Assumptions
Key Assumptions
•Launch vehicle and cost is function of: 
number of satellites/swarm, stowed 
dimensions of satellite, orbital altitude, 
launch vehicle mass capacity, and 
launch vehicle payload dimensions
•Assumes 100% launch success rate

Fidelity Assessment
Fidelity Assessment
•First iteration makes use of average 
satellite mass
•Considers 6 different launch vehicle 
possibilities and 14 altitudes

Verification
Verification
•Tested over range of satellite numbers, 
satellite masses and swarm sizes
•Fully integrated into B-TOS master 
design code

16.89 Architecture Review - 91 May 16, 2001       

Massachusetts Institute of Technology

OrbitOrbit
Description
Description
•Propagates orbital trajectories from 
initial conditions using Satellite Tool Kit 
(STK)
•Calculates coverage and revisit time 
statistics
•Determines satellite distribution within 
the swarm

Fidelity Assessment
Fidelity Assessment
•STK used to ensure high fidelity of 
orbit trajectories at the expense of 
developing a MATLAB-STK interface

Key Assumptions
Key Assumptions
•Orbit maintenance assumed;  used two-
body propagation over one day
•Walker constellation of swarms
•One sub-plane per swarm and log 
spacing between sub-orbits
•Horizontal circular projection of 
swarm
•Effective FOV of swarm based on 
spatial resolution
Verification
Verification
•Visual inspection of swarm geometry in 
3-D
•Examined extreme cases for errors

16.89 Architecture Review - 92 May 16, 2001       

Massachusetts Institute of Technology

Swarm
Swarm

Description
Description
•This function, by calling on the 
spacecraft module, outputs vectors 
defining the following parameters for 
the entire swarm:
•Mass, cost, reliability, dimensions

Fidelity
Fidelity
•This module’s depends almost entirely 
on the accuracy of the spacecraft 
module
•One variable somewhat independent of 
spacecraft that must be improved upon 
is the software cost as a result of a 
swarm configuration

Assumptions
Assumptions
•Assumes that the every possible 
configuration of swarms can be built
•Again it assumes that spacecraft 
calculations are correct

Verification
Verification
•Code was fairly simple to test, creating 
a list of output variables from spacecraft 
one can examine each of the swarms 
outputted matrices.  

16.89 Architecture Review - 93 May 16, 2001       

Massachusetts Institute of Technology

TimeTime
Description
Description
• Check which missions the system can do taking 
into account degradation of the system over time: 
calculate the new mission_to_task
• Calculate the minimum number of receivers 
necessary to fill the swarm for ambiguity and check 
if the architecture tested eliminate ambiguity
• Calculate time delays for latency and time 
resolution at three different times
Fidelity
Fidelity
• New mission to task takes into account 
degradation, functionnalities needed to complete the 
mission and minimum altitude for edp measurement
• Algorithm for ambiguity has been improved
• Time resolution can be improved with data on 
processing delays and autonomy

Assumptions
Assumptions
• Algorithm to calculate the minimum number of 
receivers needed to eliminate ambiguity. We don’t 
take into account radial baselines for ambiguity
• No processing delay
• Time resolution is based on time of measurement
• Divide the frequencies over all sounders

Verification
Verification
• New_mission_to_task has been tested with a case 
study (various combinations of functionnalities, 
degraded satellites and initial mission_to_task)
• Ambiguity calculation has been tested using a 
spreadsheet to see the effect of different swarm radii 
and instrument phase errors (study of the effect on 
accuracy and number of suborbits)

16.89 Architecture Review - 94 May 16, 2001       

Massachusetts Institute of Technology

Operations
Operations

Description
Description
•Calculates operations personnel and 
facilities
•Workload calculations account for 
complexity/reliability of spacecraft
•Calculates recurring and non-recurring 
operations costs
Fidelity Assessment
Fidelity Assessment
•Impact of swarm autonomy, or lack 
thereof, not included
•TDRSS access costs were guess 
($500k/beam)
•Ground software development not 
included

Key Assumptions
Key Assumptions
•Uses 7 different types of personnel
•Costs account for new facility 
construction
•Ops personnel capability adjusted with 
learning curves

Verification
Verification
•Code closely derived from a previously 
used operations module

16.89 Architecture Review - 95 May 16, 2001       

Massachusetts Institute of Technology

Reliability
Reliability

Description
Description
•Determines the probability that a 
particular number of satellites are 
operational in any swarm at a given 
time

Fidelity Assessment
Fidelity Assessment
•Able to accept mean time to failure for 
each different satellite type
•Computes steady state reliability 
matrix for any specified time during the 
mission

Key Assumptions
Key Assumptions
•Mean time to failure for each satellite 
type is properly specified
•‘Rounding’ of number of operational 
satellites is done to nearest whole 
number
•Markov model is appropriate
Verification
Verification
•Module tested over wide range of mean 
time to failure for different satellite types
•Able to accept any number of satellite 
types and give system state for beginning, 
middle and end of 5 year mission

16.89 Architecture Review - 96 May 16, 2001       

Massachusetts Institute of Technology

Attributes
Attributes
Description
Description
• Calculates the value of the 6 attributes at 
three different times (BOF, mid-mission, 
EOF) for utility function
• Calculation takes reliability into account
• Error flags indicate if the attributes are out 
of range

Fidelity Assessment
Fidelity Assessment
• Coverage and revisit time calculated by 
STK
•Mission completeness considers the number 
of satellites down
• Latency can be improved by taking 
processing delay and autonomy into account
• Main issue: accuracy (EDP and beacon 
accuracy)  has to be modified

Key Assumptions
Key Assumptions
• EDP accuracy: based on time resolution
• Beacon accuracy: determined with an 
interferometric relation based on the maximum 
baseline
• Latency: based on communication delay 
(calculated with an estimation of the data rates), 
Processing delay set to 0
Verification
Verification
• Tested with a sample module simulating 
the inputs of other modules
• Tested with runs (fixed problems of units 
compatibility and attribute ranges)
• Check for consistency with outputs of 
other modules and inputs needed by utility

16.89 Architecture Review - 97 May 16, 2001       

Massachusetts Institute of Technology

Utility function
Utility function

Description
Description
•Module captures the relative “value”
tradeoffs of the customer for various 
combined sets of attributes (metrics) of 
the architecture

Assumptions
Assumptions
•Utility independence
•Preferential independence
•Customer can perceive gradation of 
value for different levels of attributes

Fidelity
Fidelity
•Validation interview matched model 
fairly well, especially for showing 
preference. Absolute level of utility may 
not “be right”, but utility is on a relative 
scale anyway, so this problem is 
minimal.

Verification
Verification
•Held a validation interview with 
customer and checked output. 
•Verified code with interview responses.
•Checked out of bounds errors.

16.89 Architecture Review - 98 May 16, 2001       

Massachusetts Institute of Technology

Costing
Costing
Description
Description
•Includes spacecraft, operations, launch, 
and program level costs
•Uses CER for spacecraft/program level 
costs (including error bars)
•Incorporates learning curve for 
different spacecraft types

Fidelity Assessment
Fidelity Assessment
•Error bars are ~20-40% of spacecraft 
costs
•Error increases with decreasing 
satellite mass and increased learning 
curve affect

Key Assumptions
Key Assumptions
•Cost model assumes small satellites (20-
400 kg)
•No replenished satellites

Verification
Verification
•Spacecraft and program level costs 
were checked by hand calculation

16.89 Architecture Review - 99 May 16, 2001       

Massachusetts Institute of Technology

MultiMulti --Attribute Utility Function
Attribute Utility Function

XKU
(

1)
=+

(

6
∏
i
1
=

XUKk
(
i

i

)
1)
+

Multi-attribute 
utility function

Single attribute 
utility

Normalization 
constant

Relative “weight”

16.89 Architecture Review - 100 May 16, 2001       

Massachusetts Institute of Technology

Spacecraft Characteristics
Spacecraft Characteristics

Spacecraft mass (kg)
Subsystem mass breakdown:
ADACS:
CDH:
Payload:
Power:
Propulsion:
Structures:
Telecom:
Thermal:
Downlink data rate (bps)
Average power required (W)

Mothership Daughter
165
72

8
10
32
33
11
33
29
8
30000
191

8
4
17
13
11
14
1
4
15000
73

All 5 frontier architectures have similar spacecraft
All 5 frontier architectures have similar spacecraft

16.89 Architecture Review - 101 May 16, 2001       

Massachusetts Institute of Technology

Swarm Radius vs. Utility
Swarm Radius vs. Utility

1

0.995

y
t
i
l
i
t
U

0.99

0.985

A

0.98

0.1

C

E

D

B

No utility gained from 
swarms larger than 50 km

No beacon angle utility from 
swarms less than 0.18 km

1

10

100

Swarm Radius (km)

16.89 Architecture Review - 102 May 16, 2001       

Massachusetts Institute of Technology

Swarms per Plane vs. Coverage
Swarms per Plane vs. Coverage

0.6

0.5

0.4

e
g
a
r
e
v
o
C

0.3

0.2

0.1

0

0

1

2

3
Swarms per Plane

4

5

6

16.89 Architecture Review - 103 May 16, 2001       

Massachusetts Institute of Technology

Revisit Time vs. Utility
Revisit Time vs. Utility

1

0.995

y
t
i
l
i
t
U

0.99

0.985

0.98

0

200

400

600
Revisit T ime (sec)

800

1000

1200

16.89 Architecture Review - 104 May 16, 2001       

Massachusetts Institute of Technology

Launch Cost Trend
Launch Cost Trend

350

300

250

200

150

100

50

s
e
t
i
l
l
e
t
a
S
 
f
o
 
r
e
b
m
u
N
 
l
a
t
o
T

0

0

200

400

600

800
Launch Cost ($M)

1000

1200

1400

1600

16.89 Architecture Review - 105 May 16, 2001       

Massachusetts Institute of Technology

Operations Cost Trend
Operations Cost Trend

350

300

250

200

150

100

50

s
e
t
i
l
l
e
t
a
S
 
f
o
 
r
e
b
m
u
N
 
l
a
t
o
T

0

0

200

400

800
600
Operations Costs ($M)

1000

1200

1400

16.89 Architecture Review - 106 May 16, 2001       

Massachusetts Institute of Technology

Utility Function Sensitivity 
Utility Function Sensitivity 

• Uncertainties in the 
relative weight of the 
attributes in the utility
• For a 10% change in ??? 
we get a change in utility 
of 0.005
Utility sensitivity is 
Utility sensitivity is 
low enough to validate 
low enough to validate 
architecture results
architecture results

e
g
n
a
h
c
 
U
A
M

0.04

0.03

0.02

0.01

0

-0.15

-0.1

0

- 0.05
-0.01

0 .05

0.1

0.15

ut i l  s hift
k  s hift

-0.02

-0.03

-0.04
S h i ft va lue

16.89 Architecture Review - 107 May 16, 2001       

Massachusetts Institute of Technology

Reliability Sensitivity
Reliability Sensitivity

1

0.95

y
t
i
l
i
t
U

0.9

0.85

0.8

0.75

0.0207

0.0286

0.0395

0.0546

0.0754
0.0887
MTTF

0.1042

0.1225

0.1439

0.1988

BOL
MOL
EOF

0.2337

0.2747

16.89 Architecture Review - 108 May 16, 2001       

Massachusetts Institute of Technology

Integrated Concurrent Engineering (ICE)
Integrated Concurrent Engineering (ICE)
• Simplified ICE design method used in B-TOS
• ICE is real-time concurrent design that eliminates 
communication/information bottlenecks and increases 
productivity
• Subsystem groups use design tools to model 
subsystems and information is shared via central 
database with other groups in real-time
• Data flow between groups is streamlined using an N2
diagram analysis
• Facilitator guides teams through design iterations and 
works out design issues with all groups present in a 
design room

16.89 Architecture Review - 109 May 16, 2001       

Massachusetts Institute of Technology

Facility Requirements & Characteristics
Facility Requirements & Characteristics

• Enough room for the team
• Work stations for each team member 
• Work stations arranged around 
periphery to enhance communications
• LAN connections between stations
• A projection system that can monitor 
any station
– Multiple projectors are preferable
• The brand new Aero/Astro 33-218 
design room is setup exactly like this 
and was designed with ICE in mind

16.89 Architecture Review - 110 May 16, 2001       

Massachusetts Institute of Technology

Benefits of ICE
Benefits of ICE
• It is a definable, repeatable, measurable process
• Design iteration is managed, not chaotic
• Data entry is distributed around the room 
eliminating bottlenecks
• Team members can link their tools directly through 
the system eliminating the need for excessive data re-
entry
• It can be applied predictably to many different 
processes
– Requirements definition, cost estimation, proposal preparation, 
schedule planning, system design, IRAD investment planning and more 
16.89 Architecture Review - 111 May 16, 2001       
Massachusetts Institute of Technology

Lessons Learned
Lessons Learned

• Careful application of past experience:
– A-TOS modules: late realizations of necessary changes
• Need to consider if and how changes affect all 
other sections of the code
• Divided modules before all equations or 
requirements were known
• Appropriate architecture selection: limited by 
model fidelity and customer-provided utility 
function

16.89 Architecture Review - 112 May 16, 2001       

Massachusetts Institute of Technology

