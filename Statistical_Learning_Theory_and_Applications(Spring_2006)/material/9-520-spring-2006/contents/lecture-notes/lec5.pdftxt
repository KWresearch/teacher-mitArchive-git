Lecture 5: Support Vector Machines for 
Classification  
Ryan Rifkin  

Description 
We derive SVMs from a geometric perspective as well as the regularization perspective. 
Optimality and duality is introduced to demonstrate how large SVMs can be solved. A 
comparison is made between SVMs and RLSC. We introduce Regularized Least Squares 
regression and classification.  

Suggested Reading 
•  Rifkin. Everything Old Is New Again: A Fresh Look at Historical 
Approaches in Machine Learning. MIT Ph.D. Thesis, 2002. <  
•  Evgeniou, Pontil and Poggio. Regularization Networks and Support 
Vector Machines Advances in Computational Mathematics, 2000.  
•  V. N. Vapnik. The Nature of Statistical Learning Theory. Springer, 
1995.  

 

 

 

