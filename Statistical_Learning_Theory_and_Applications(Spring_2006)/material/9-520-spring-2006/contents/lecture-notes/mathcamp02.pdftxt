Math  Camp  2:  Probability  Theory

Sasha  Rakhlin


σ-algebra


A  σ-algebra  Σ  over  a  set  Ω  is  a  collection  of  subsets  of  Ω 
that  is  closed  under  countable  set  operations: 

1.	 ∅ ∈ Σ. 

2.	 E  ∈ Σ  then  so  is  the  complement  of  E .


3.  If	 F  is  any  countable  collection  of  sets  in  Σ,  then  the 
union  of  all  the  sets  E  in  F  is  also  in  Σ. 

Measure


A  measure  µ  is  a  function  deﬁned  on  a  σ-algebra  Σ  over  a 
set  Ω  with  values  in  [0, ∞]  such  that 

1.  The  empty  set  has  measure  zero:  µ(∅) = 0


2.  Countable  additivity:	
if  E1,  E2,  E3,  ...  is  a  countable 
⎛⎝

⎞⎠

� 
∞
 
sequence  of  pairwise  disjoint  sets  in  Σ, 
∞
µ(Ei) 
Ei 
i=1 
i=1 

= 

µ


The  triple  (Ω, Σ, µ)  is  called  a  measure  space. 

Lebesgue  measure


The Lebesgue measure λ  is the unique complete translation-
invariant  measure  on  a  σ-algebra  containing  the  intervals 
in  IR  such  that  λ([0, 1]) = 1. 

Probability  measure


Probability  measure  is  a  positive  measure  µ  on  the  mea­ 

surable  space  (Ω, Σ)  such  that  µ(Ω) = 1. 


(Ω, Σ, µ)  is  called  a  probability  space.


A  random  variable  is  a  measurable  function  X  : Ω  �→  IR. 

�
� 
We  can  now  deﬁne  probability  of  an  event

{x  : IA(x) = 1} . 
P (event  A) = µ 

Expectation  and  variance

� 
Given  a  random  variable  X  ∼ µ  the  expectation  is

IEX  ≡  X dµ. 

Similarly  the  variance  of  the  random  variable  σ2(X )  is 
var(X ) ≡  IE(X − IEX )2 . 

Convergence


Recall  that  a  sequence  xn  converges  to  the  limit  x 
x → 
xn 
if  for  any  � > 0  there  exists  an  N  such  that  xn − x <  �  for 
|
|
n > N .


We  say  that  the  sequence  of  random  variables  Xn  con­
verges  to  X  in  probability 
Xn  − X → 
P

if 

for  every  � > 0. 

P  ( Xn − X
|

| 

≥ ε) →

0

Convergence  in  probability  and  almost

surely


Any  event  with  probability  1  is  said  to  happen  almost 
surely.  A  sequence  of  real  random  variables  Xn  converges 
� 
� 
almost  surely  to  a  random  variable  X  iﬀ 
lim  Xn  = X
n→∞ 

= 1. 

P 

Convergence  almost  surely  implies  convergence  in  proba­
bility. 

Law  of  Large  Numbers.  Central  Limit

Theorem


X n  = 

= 0. 

Weak  LLN:  if  X1, X2, X3, ...  is  an  inﬁnite  sequence  of  i.i.d. 
random  variables  with  ﬁnite  variance  σ2,  then 
· · · 
X1 +  + Xn  P
→ 
− IEX1 
n 
����X n − IEX1
��� ≥ ε
� 
In  other  words,  for  any  positive  number  �,  we  have 
lim  P 
n→∞ 
� 
�
≤ z  = Φ(z) 
lim  Pr 
n→∞ 

X n − µ 
√
n 
σ/
where  Φ  is  the  cdf  of  N (0, 1). 

CLT: 

Useful  Probability  Inequalities


Jensen’s  inequality:  if  φ  is  a  convex  function,  then 
φ(IE(X )) ≤  IE(φ(X )). 
�  ∞ 
Pr(X  ≥  t)dt. 
0 

For  X  ≥ 0, 

IE(X ) = 

Markov’s  inequality:  if  X  ≥ 0,  then 
IE(X )
Pr(X  ≥  t) ≤ 
t 

where  t ≥ 0. 

,


Useful  Probability  Inequalities


Chebyshev’s  inequality  (second  moment):  if  X  is  arbitrary 
random  variable  and  t > 0, 

Pr( X − IE(X )
|
| ≥  t) ≤ 

var(X )

t2 

.

Cauchy-Schwarz  inequality:  if  IE(X 2)  and  IE(Y 2)  are  ﬁnite, 
�
then 
IE(X 2)IE(Y 2).

|IE(X Y )

| ≤ 

Useful  Probability  Inequalities


If  X  is  a  sum  of  independent  variables,  then  X  is  better 
approximated  by  IE(X )  than  predicted  by  Chebyshev’s  in­
equality.  In  fact,  it’s  exponentially  close! 

Hoeﬀding’s  inequality:


�n 
Let  X1, ..., Xn  be  independent  bounded  random  variables, 
ai  ≤  Xi  ≤  bi  for  any  i  ∈  1...n.  Let  Sn  = 
i=1 Xi, 
then  for 
� 
� 
any  t > 0, 
Pr( Sn − IE(Sn) ≥  t) ≤ 2exp  �
|
| 

−2t2 
=1(bi − ai)2
n 
i

Remark  about  sup 

Note  that  the  statement 
with  prob.  at  least  1 − δ  ,  ∀f  ∈ F ,  IEf  −
|

is  diﬀerent  from  the  statement 
∀f  ∈ F ,
 with  prob.  at  least  1 − δ  ,  IEf  −
|

1
 n�

f (zi) ≤ �
|
n i=1 
1  n�

f (zi)| ≤ �. 
n i=1 

The second statement  is an  instance of CLT, while  the ﬁrst 
statement  is  more  complicated  to  prove  and  only  holds  for 
some  certain  function  classes. 

Playing  with  Expectations

�n
Fix  a  function  f ,  loss  V ,  and  dataset  S  =  {z1, ..., zn}.  The 
1
i=1 V (f , zi). 
empirical  loss  of  f  on  this  data  is  IS [f ] =  n 
The  expected  error  of  f  is  I [f ]  =  IEzV (f , z).  What  is  the 
expected  empirical  error  with  respect  to  a  draw  of  a  set  S 
� 
of  size  n? 
1  n
IES V (f , zi) =  IES V (f , z1) 
n i=1 

IES IS [f ] = 

