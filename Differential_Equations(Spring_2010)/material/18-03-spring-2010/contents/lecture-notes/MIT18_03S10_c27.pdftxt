18.03 Class 27, April 12, 2010
 
Laplace Transform II 
 
1. Delta signal 
2. t-derivative rule 
3. Inverse transform 
4. Unit impulse response 
5. Partial fractions 
6. L[f'_r] 
 
Laplace Transform:   F(s) = int_0^\infty f(t) e^{-st} dt 
 
We saw that this improper integral may only converge for  Re(s) > a, 
for some  a  depending upon  f(t) .  The smallest such  a  gives the 
"region of convergence." 
 
Computations so far: 
 
L[1] = 1/s  
 
L[t^n] = n!/s^{n+1}             
 
L[e^{rt}] = 1/(s-r)             
 
L[cos(t)] = s / (s^2 + omega^2) 
 
L[sin(t)] = omega / (s^2 + omega^2)  
 
 
We also have  
 
Rule 1 (Linearity):  af(t) + bg(t) ----->  aF(s) + bG(s). 
 
Rule 2 (s-shift):    L[e^{rt}f(t)] = F(s-r)  
 
 
Warm-up: What is the Laplace transform of  f(t) = e^{-t} cos(3t) ? 
 
We could do this by writing it as  (1/2)( e^{(-1+3i)t} + e^{(-1-3i)t} ) 
 
but it's a bit easier to use the s-shift :  cos(3t) ----> s / (s^2 + 9)  
 
so   e^{-t} cos(3t) ----> (s+1)/( (s+1)^2 + 9 )  
 
If you like you can "uncomplete the square" and write this as  
 
                          = (s+1) / (s^2 + 2s + 10) 
 
 
[1]  The delta function:  For  b > 0 ,   
 
      L[delta(t-b)]  =  integral_0^infty delta(t-b) e^{-st} dt 
 
What could this mean?  
 
If  f(t)  is continuous at  t = b ,  delta(t-b) f(t) = f(b) delta(t-b) . 

 
so              integral delta(t-b) f(t) dt = f(b) u(t-b) + const 
 
or, if  a < b < c , integral_a^c delta(t-b) f(t) dt = f(b) .  
 
In some accounts, this is the DEFINITION of the delta function. 
 
In our situation, you get  
 
      L[delta(t-b)]  =  e^{-bs} 
 
In this case, the region of convergence is the entire complex plane: 
the limit you take to get the improper integral is constant as soon as  t > b.  
 
There is a problem when  b = 0 .  delta(t) e^{-st} = delta(t)  for any  s , 
but  int_0^infty delta(t) dt = u(infty) - u(0)  and  u(0)  is  
indeterminate. 
 
We want the formula that worked for  b > 0  to work for  b = 0  as well: 
 
     L[delta(t)] = 1 
 
To be sure this  happens, we should refine the definition of the LT  
integral so the lower limit (as well as the upper limit) occurs as a  
limit:  
 
Refinement #2: 
    
     L[f(t)] = lim_{c increasing to infty, a increasing to 0} 
 
                     int_a^c f(t) e^{-st} dt  
 
and then we have the new computation 
 
     L[delta(t-b)] = e^{-bs}   for   b  greater or equal to  0  
                               region of convergence: the whole plane. 
 
 
[2] To use LT in understanding differential equations, we will need: 
 
      L[f'(t)]  =  integral_{0-}^infty f'(t) e^{-st} dt 
 
Parts:       u  =  e^{-st}         du  =  -s e^{-st} dt 
 
            dv  =  f'(t) dt         v  =  f(t)  
 
          ...   =  e^{-st} f(t) |_{0-}^infty + s integral f(t) e^{-st} dt 
 
                =  s F(s)  
 
Now, what is  f'(t) ? If  f(t)  has discontinuities, we must mean the 
generalized derivative; that's the only way to make the integral of the 
derivative work right. Even if  f(t)  has no breaks in its graph for   
t > 0 , it probably will have one when  t = 0  since we are assuming 
that  f(0-) = 0  but have not assumed that  f(0+) = 0 . We have to expect  
a discontinuity at  t = 0 , and so a delta function in  f'(t)  at  t = 0 .  
 

 
For example,  u(t) = f(t)  ------> 1/s   
and       delta(t) = f'(t) ------> s (1/s) = 1 
 
or             t^n = f(t)  ------> n!/s^{n+1} 
and      n t^{n-1} = f'(t) ------> s n!/s^{n+1} = n (n-1)!/s^n  
 
or          cos(t) = f(t)  ------> s/(s^2+1) 
 delta(t) - sin(t) = f'(t) ------> s^2/(s^2+1) = 1 - 1/(s^2+1)  
 
 
[3]  In summary the use of Laplace transform in solving initial value problems 
goes like this: 
 
                          L 
      IVP for  x(t)   --------->  Alg equation for  X(s) 
                                           | 
                                           | solve 
                                           |  
                         L^{-1}            V 
      x(t) = ...      <---------      X(s) = ... 
 
 
For this to work we have to recover information about  f(t)  from  F(s).  
There isn't a formula for  L^{-1};  what one does is look for parts of 
F(s)  in our table of computations.  It's an art, like integration.  
There is no free lunch. 
 
We can't expect to recover  f(t)  exactly, if  f(t)  isn't required 
to be continuous, since  F(s)  is defined by an integral, which is left  
unchanged if we alter any individual value of  f(t) . What we have is: 
 
 
Theorem: If  f(t)  and  g(t)  are generalized functions with the same  
Laplace transform, then for every  a  greater or equal to  0  
f(a+) = g(a+),  f(a-) = g(a-) ,  and any 
occurrences of delta functions are the same in  f(t)  as in  g(t). 
 
So if  f(t)  and  g(t)  are continuous at  t = a,  then  f(a) = g(a). 
 
 
[4]  Example: Find the unit impulse response for the operator  D + 3I  
 
ie  solve   w' + 3w = delta(t)  with rest initial conditions.  
 
Step 1:  Apply  L :  sW + 3W = 1 
 
Step 2:  Solve for  W :   W = 1/(s+3)  
 
Step 3:  Find  w(t)  with this as Laplace transform:   e^{-3t}  
 
or more precisely,  u(t) e^{-3t} .   
 
Laplace transform is a good way to find unit impulse responses. 
 
"Unit impulse response" = "weight function" 
 

Its Laplace transform is called the "transfer function."  
 
 
[5] Example:  Solve  x' + 3x = e^{-t},  with initial condition  x(0+) = 0 . 
 
Step 1:  Apply  L :  sX + 3X = 1/(s+1) ,  using linearity, the  
s-shift rule, and the t-derivative rule.  
 
Step 2:  Solve for  X:  (s+3)X = 1/(s+1) 
 
so  X = 1/((s+1)(s+3)) 
 
Step 3:  Massage the result into a linear combination of recognizable forms. 
 
Here the technique is: 
 
Partial Fractions:  1/((s+1)(s+3)) = a/(s+1) + b/(s+3) . 
 
Old method: cross multiply and identify coefficients.   
 
This works fine, but for excitement let me offer: 
 
The Cover-up Method:  Step (i)  Multiply through by  (s+1) : 
 
      1/(s+3)  =  a + (s+1)(a/(s+3)) 
 
Step (ii)  Set  s + 1 = 0 ,  or  s = -1 : 
 
          1/(3-1)  =  a + 0 :   a  =  1/2 . 
 
This process "covers up" occurrences of the factor  (s+1),  and also 
all unwanted unknown coefficients.  The same method gives  b : 
 
        1/(-3+1)  =  0 + b :    b  =  -1/2. 
 
So              X =  (1/2)/(s+1) - (1/2)/(s+3) 
 
Step 4:  Apply  L^{-1}:  we can now recognize both terms: 
 
      x  =  (1/2) e^{-t} - (1/2) e^{-3t} .         (times u(t)) 
 
Of course, this is very easy to do by our earlier methods: The ERF gives 
the first term, the general solution to the homogeneous equation is  ce^{-3t} , 
and the transient needed for initial condition  x(0) = 0  is  c = -1/2 .  
 
 
[5] Consider the equation  
 
     x' + 3x = e^{-t}   ,    x(0) = 5 
 
Since we have the standing agreement that  x(t) = 0  for  t < 0,  x(t)  has  
a jump, apparently, at  t = 0 , and perhaps what is intended is  
 
     x' + 3x = e^{-t}   ,   x(0+) = 5 
 
But this equation does not have a solution! Since  x(0-) = 0 , x'  contains  

the singular part  5 delta(t) ; but there's no  5 delta(t)  on the right hand 
side.   
 
What is really intended in a problem like this is, in connection with LT is:    
 
     x'_r + 3x = e^{-t} ,  x(0+) = 0 .  
 
Just to keep the notation in bounds, let's suppose that  f(t)  is  
continuous for  t > 0.  Then the only singular part of the generalized 
derivative occurs at  t = 0 : 
 
      (f')_s(t)  =  f(0+) delta (t) 
 
The generalized derivative is the sum of this and the ordinary  
derivative   (f')_r(t) .  By linearity and our value  L[delta(t)] = 1 , 
 
       L[f'(t)]  =  f(0+) + L[f'_r(t)] 
 
and so  
 
     L[f'_r(t)]  =  s F(s) - f(0+) . 
 
This is what you always see in books and most of the time it's what 
is used in practice. Let's use it: 
 
     x'_r + 3x = e^{-t} 
 
Then  (sX - 5) + 3X = 1/(s+1)  
 
       X = 1 / (s+1)(s+3) + 5/(s+3) 
 
so we add  L^{-1}[5/(s+3)] = 5 e^{-3t}  to the earlier solution -- this 
corrects the transient.  
 
 
  
 
 
 
 
Current list of Rules:   
 
L  is linear:  L(af+bg)  =  aF + bG 
 
s-shift:    e^{at}f(t) -----> F(s-a) 
 
t-derivative:  f'(t) -----> s F(s)  
 
               f'_r(t) -----> s F(s) - f(0+)   
               if  f(t) has continuous derivative for  t > 0 . 
 
 
Computations: 
 
1            ----> 1/s 
 
e^{as}       ----> 1/(s-a) 

 
cos(omega t) ----> s/(s^2+omega^2) 
 
sin(omega t) ----> omega/(s^2+omega^2) 
 
delta(t-a)   ----> e^{as} 
 
 
 
 
 
 
 
 
 
 
 

MIT OpenCourseWare 
http://ocw.mit.edu 

18.03 Differential Equations(cid:13)(cid:10)�� 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

