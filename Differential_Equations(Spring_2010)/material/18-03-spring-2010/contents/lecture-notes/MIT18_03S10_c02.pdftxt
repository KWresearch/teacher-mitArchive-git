18.03 Class 2, Feb 3, 2010 
 
Numerical Methods 
 
[1] How do you know the value of e? 
[2] Euler's method 
[3] Sources of error 
[4] Higher order methods 
 
 
[1] The study of differential equations has three parts: 
 
. Analytic, exact, symbolic methods 
 
. Quantitative methods (direction fields, isoclines ....) 
 
. Numerical methods 
 
Even if we can solve symbolically, the question of computing values  
remains. The number  e  is the value  y(1)  of the solution to 
y' = y  with  y(0) = 1. But how do you find that in fact  
e = 2.718282828459045.... ? The answer is: numerical methods. 
(Euler already computed  e  to at least 18 decimal places. It is 
now known to some 200 billion places, but I won't write them all out here.) 
 
As an example, take the first order ODE   
 
y' = y^2 - x = F(x,y)  with initial condition  y(0) = -1 
 
-- an Initial Value Problem, IVP. 
 
For example:  what is  y(1) ? 
 
I invoked the Euler's Method Mathlet, and selected  F(x,y) = y^2 - x . 
The slope field appears. I selected the initial condition  (0,-1) , 
and then invoked "actual."  
 
This solution is one of those trapped in the funnel, 
so for large  x ,  the graph of  y(x)  is close to  the graph of  
- \sqrt(x) :  y(100) is very close to  -10 . 
   
But what about  y(1) ? 
 
The listing says  y(1) = -.83 .  How did the computer know this?  
 
 
[2] The tangent line approximation gives one approach. 
 
Recall:  We have a function  y(x), and a point  (a,y0) on its graph 
(so y(a) = y0 ). The tangent line to the graph at this point has slope 
y'(a), which I will denote  m_0 .  The tangent line approximation is 
 
y(a+h) ~ y0 + m0 h  
 
The right hand side is the  y-coordinate of a point on the tangent line 
directly above or below (a+h , y(a+h)). 
 

In our case, we do know the derivative of  y  at  x = 0 : 
 
y'(0) = F(0,-1) = (-1)^2 + 0 = 1  
 
So the tangent line at  (0,-1)  has slope  1 , and we find the tangent line 
approximation  y(1) ~ -1 + 1 = 0. I showed this on the applet. 
 
Of course this is a really bad appromation, because we took such a big hop. 
The tangent line approximation works much better if  h  is small.  
 
The idea then is to take a *small* hop, and then use the direction field 
at the end point of that line segment to decide where to go next.  
Keep it up till you get where you want to go. 
 
Let's set this up more generally. You have an initial value problem 
 
y' = F(x,y) ,  y(a) = y0 . 
 
You want to estimate  y(b)  where  b > a . Divide the interval from   
a  to  b  into small hops each of width  h . Give names to the hash marks: 
 
x0 = a ,  x1 = a+h , ... , xk = a+kh , ...    b 
 
Then we build a polygon starting at (x0,y0). The first segment 
ends at  (x1,y1)  where  y1 = y0 + m0 h ,  m_0 = F(x0,y0) .  
The second ends at  (x2,y2)  where  y2 = y1 + m1 h ,  m1 = F(x1,y1) . 
And so on.  
 
I call the line segments "Euler struts" and the whole thing the 
Euler polygon. It's supposed to be an approximation to the graph of  y.  
 
Notes: (1)  x_1, ... and y1, ... depend on  h . 
(2)  y0 = y(x0)  , but  y1 is not y(x1); it is only an approxiation to it. 
 
Let's do this for our example, with  h = 1/2 : so two steps.  
 
 
Keep this calculation organized in a table.   
 
 
h = .5 
 
k 
  mk h 
mk = yk^2 - xk 
 
yk 
 
xk 
 
__________________________________________________________________________ 
 
   .5 
1 
-1 
 
0 
 
0 
 
 
 
-.5   
.5 
 
1 
 
-.25   
  -.125 
 
2 
 
1.0   
-.625  
 
 
I checked this on the applet and then showed some more Euler polygons for this 
equation.  
 
h = 1  
h = .5 

estimate of y(1)  is  0.00 
                      -.62 

 

h = .25                       -.75               
h = .125                      -.80 
"actual"                      -.83 
 
 
 
[3] Euler's method is rarely exact. Let's identify some sources for error. 
Much of numerical analysis is understanding and bounding potential error. 
 
(1) Round off accumulation.  Each computation involves a small error,  
from round off, and these errors accumulate. So you want to use the fewest 
number of steps possible. On the other hand making the stepsize small 
keeps the polygonal approximation close to the actual solution. There is 
a tension here. 
 
Usually more important than this is: 
 
(2) The Euler polygon is not an exact solution, and the direction field 
at its vertices differs more and more from the direction field under the 
actual solution. At places where the direction field is changing rapidly, 
this produces very bad approximations quickly. 
 
The variation of the direction field causes the integral curves to bend 
away from the Euler strut. 
 
Can we predict whether the Euler approximation is too big or too small? 
In this example they are too big. This is because the solution if curving 
down and leaving the polygons above it.  
 
How would we know without a picture whether the solution is  
 
convex = bending up       or 
concave = bending down ? 
 
Well there's  y"(0) > 0  convex  at (0,-1) 
              y"(0) < 0  concave   at (0,-1) 
 
How to find  y" ?  well,  y' = y^2 - x  
                          y" = 2yy' - 1  
 
so  y"(0) = 2(-1)(1) - 1 = -3 :  concave : as we see in the picture. 
 
If y"(x_0) < 0 ,  Euler's estimate is too high 
if y"(x_0) > 0 ,  Euler's estimate is too low. 
 
 
[4] Theory shows that for small  h ,  the error in Euler's method is  
at most  C1 h  for some constant  C1 . It is a "first order method"  
(no relation with "first order equation.") Of course if you knew in 
advance exactly what the error was, you'd be rich and famous. 
 
Making  h  smaller is one way to decrease the error caused by the  
variability of the direction field. But there are more clever ways which  
turn out to be even better.  
 
Here is one: RK2 = improved Euler = Heun: 
Poll the slope field at the end of the Euler strut and use the average.  

 
Q2.1 What is the first slope for the RK2 polygon for  y' = y^2 - x  
with  h = 1/2  and initial condition  y(0) = -1 ? 
 
1. 1 
2. 1/2 
3. -1/4 
4. 3/8 
5. 5/8 
6. Don't know 
 
The needed data is present in the h = 1/2 Euler table: 
F(0,-1) = 1. The end of this Euler strut is (1/2,-1/2). 
F(1/2,-1/2) = -1/4 . The average is  3/8 :  [4] is correct. 
 
[Almost everyone offering an answer got this right.] 
 
This brings us down closer to the actual solution curve.  
 
RK2 is *second order*:  for small  h  the error is at most  C2 h^2  for  
some constant  C2 . 
 
Each evaluation of the direction field costs money - it takes time. 
Euler polls once per step, RK2  polls twice per step.  
 
So if we want to compare efficiencies, we should compare Euler with  h 
and RK2 with  2h .  The error with Euler is around  C1 h .   
The error with RK2  is around  C2 (2h)^2 = 4C2 h^2 .  If h  is small enough, 
the the RK2 error will definitely be smaller than the Euler error, 
even if C2 is larger than C1. In fact, C2 tends to be smaller than C1, 
so RK2 wins for two reasons.  
 
There is an RK4 method too, which polls the direction field 4 times before 
deciding which way to head out. It's a "fourth order method," and its error 
is approximately  C4 h^4. To make a comparison with Euler(h) you should use 
RK4(4h), but again  C4 (4h)^4 = 64 C4 h^4  will be less than  4C2 h^2 
or C1 h  for  h  small enough; and in fact  C4 itself is usually smaller 
than  C2  and  C1.  
 
 
Here's some data using the ODE  y' = y,  y(0) = 1;  the solution is   
y = e^x,  and we study  y(1) = e. Number of evaluations of the  
direction field = 1000. 
 
 
Stepsize    Error  
Method  
 
 
 
 
 1.3 x 10^{-3} 
RK1 = Euler  .001  
 
 
 
RK2 = Heun   .002   
 
 1.8 x 10^{-6} 
 
 
 8.0 x 10^{-15} 
 
 .004  
 
RK4    
 
 
From this you can conclude that the constants (for this particular IVP)  
are about 
 

 

 

C1 ~ 1.3          C2 ~ 0.45            C4 ~ .00012 
 
 
The moral is that for good accuracy Euler is essentially useless, 
and RK4 will always win. There are still higher order methods, 
but they involve more overhead as well and experience has shown  
that RK4 is a good compromise. 
 
Further note: The initial value problem  y' = f(x) , y(a) = y0  has solution 
 
     y(x) = y0 + int_a^x f(t) dt 
 
When you apply these methods to approximate  y(x), 
 
Euler's method is the left end-point Riemann sum 
RK2            is the trapezoidal rule 
RK4            is Simpson's rule. 
 
 
 
Here's an example of how bad the errors can get: Catastrophic overshoot. 
 
I selected Euler 1.00 again and followed the Euler polygon. The very fact  
that the slope field is funnelling causes catastrophic overshoot. 
 
ODE solvers are tricky and avoid things like this. One trick: 
when the direction field is steep, use smaller stepsizes. 
 
 
Please complete and hand in the Muddy Cards! 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 

MIT OpenCourseWare 
http://ocw.mit.edu 

18.03 Differential Equations(cid:13)(cid:10)�� 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

