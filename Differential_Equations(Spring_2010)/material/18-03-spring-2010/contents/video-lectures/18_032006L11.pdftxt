MIT OpenCourseWare 
http://ocw.mit.edu 

18.03 Differentia l Equations, Spring 2006 

Please use the following citation format: 

Arthur Mattuck and Haynes Miller, 18.03 Differentia l Equations, Spring 
2006. (Massachusetts Institute of Technology: MIT OpenCourseWare). 
http://ocw.mit.edu (accessed MM DD, YYYY). License: Creative 
Commons Attribution-Noncommercia l-Share Alike. 

Note: P lease use the actua l date you accessed this materia l in your citation. 

For more information about citing these materia ls or our Terms of Use, visit: 
http://ocw.mit.edu/terms 

MIT OpenCourseWare 
http://ocw.mit.edu 

18.03 Differentia l Equations, Spring 2006 
Transcript â€“ Lecture 11 

y' and y''. So, q(x)*y equa l zero. The linearity of the equation, that is,  the form in 
which it appears is going to be the key idea today. Today is going to be theoretical, 
but some of the ideas in it are the most important in the course. So, I don't have to 
apologize for the theory. Remember, the solution method was to find two 
independent y1, y2 independent solutions. And now, I'll formally write out what 
independent means. 

There are d ifferent ways to say it. But for you, I think the simp lest and most 
intellig ible will be to say that y2 is not to be a constant multiple of y1. And, 
unfortunately, it's necessary to add, nor is y1 to be a constant multiple. I have to call 
it by different constants. So, let's call this one c prime of y2. Well, I mean, the most 
obvious question is, well, look. If this is not a constant times that, this can't be there 
because I would just use one over c if it was. Unfortunately, the reason I have to 
write it this way is to take account of the possibility that y1 might be zero. If y1 is 
zero, so, the bad case that must be excluded is that y1 equals zero, y2 nonzero. 

I don't want to call those independent. But nonetheless, it is true that y2 is not a 
constant multiple of y1. However, y1 is a constant multiple of y2, namely, the 
multip le zero. It's just to exclude that case that I have to say both of those things. 
And, one would not be sufficed. That's a fine point that I'm not going to  fuss over. 
But I just have, of course. Now, why do you do that? That's because, then, all 
solutions, and this is what concerns us today, are what? The linear comb ination w ith 
constant coefficients of these two, and the fundamenta l question we have to answer 
today is, why? 

Now, there are really two statements involved in that. On the one hand, I'm claiming 
there is an easier statement, which is that they are a ll solutions. So,  that's question 
one, or statement one. Why are all of these guys solutions? That, I could trust you to 
answer yourself. I could not trust you to answer it elegantly. And, it's the elegance 
that's the most important thing today because you have to answer it elegantly. 
Otherw ise, you can't go on and do more complicated things. If you answer it in an ad 
hoc basis just by hacking out a computation, you don't rea lly see what's going on. 
And you can't do more difficult things later. 

So, we have to answer this, and answer it nicely. The second question is, so, if that 
answers why there are solutions at all, why are they all the solutions? Why all the 
solutions? In other words, to say it as badly as possib le, why are a ll solutions, why 
all the solutions-- Never mind. Why are a ll the solutions. This is a harder question to 
answer, but that should make you happy because that means it depends upon a 
theorem which I'm not going to prove. 

I'll just quote to you. Let's attack there for problem one first. q1 is answered by 
what's ca lled the superposition. The superposition principle says exactly that. It says 
exactly that, that if y1 and y2 are solutions to a linear equation, to a linear 
homogeneous ODE, in  fact it can be of higher order, too, a lthough I won't stress 

that. In other words, you don't have to stop w ith the second derivative. You could 
add a third derivative and a  fourth derivative. As long as the former makes the 
same, but that  implies automatica lly that c1 y1 plus c2 y2 is a solution. 

Now, the way to do that nicely  is to take a little detour and talk a  little bit about 
linear operators. And, since we are going to be using these for the rest of the term, 
this is the natural place for you to learn a little b it about what they are. So, I'm going 
to do it. Ultimately, I am aimed at a proof of this statement, but there are going to 
be certa in side excursions I have to make. The first side side excursion is to write the 
differentia l equation in a different way. So, I'm going to just write its 
transformations. The first, I'll simply recopy what you know it to be, q y equals zero. 
That's the first form. The second  form, I'm going to replace this by the d ifferentiation 
operator. 

So, I'm going  to write this as D^2(y). That means differentiate it twice. D it, and 
then D it again. This one I only have to differentiate once, so I'll write that as p D(y), 
p times the derivative of Y. The last one isn't differentiated at a ll. I just recopy it. 
Now, I'm going to forma lly factor out the y. So this, I'm going to turn into D^2 + pD 
+ q. 

Now, everybody reads this as times y equa ls zero. But, what it means is this guy, it 
means this is shorthand for that. I'm not multip lying. I'm multip lying q times y. But, 
I'm not multiplying D times y. I'm applying D to y. Nonetheless,  the notation 
suggests this is very suggestive of that. And this, in turn, implies that. I'm just 
transforming it. And now, I'll take the final step. I'm going to view this thing in 
parentheses as a guy a ll by itself, a linear operator. This  is a linear operator, called a 
linear operator. And, I'm going to simply abbreviate it by the letter L. And so, the 
fina l version of this equation has been reduced to nothing but Ly = 0. 

Now, what's L? You can think of L as, well, formally, L you would write as D^2 + pD 
+ q. But, you can think of L, the way to think of it is as a b lack box, a  function of 
what goes into  the b lack box, well, if this were a function box, what would go it 
would be a number, and what would come out with the number. But it's not that kind 
of a b lack box. It's an operator box, and therefore, what goes in is a function of x. 
And, what comes out is another function of x, the result of app lying this operator to 
that. So, from this point of view, d ifferential equations, trying to solve the d ifferential 
equation means, what should come out you want to come out zero, and the question 
is, what should you put in? 

That's what it means solving differential equations in an inverse prob lem. The easy 
thing is to put it a function, and see what comes out. You just calculate. The hard 
thing is to ask, you say, I want such and such a  thing to come out, for example, 
zero; what should I put in? That's a difficult question, and that's what we're spend ing 
the term answering. Now,  the key thing about this  is that this is a linear operator. 

And, what that means  is that it behaves in a certain way w ith respect to functions. 
The easiest way to say it is, I like to make two laws of it, that L of u1, if you have 
two functions, I'm not going to put up the parentheses, x, because that just makes 
things look longer and not any clearer, actually. What does L do to  the sum of two 
functions? If that's a linear operator, if you put in the sum of two functions, what you 
must get out is the corresponding L 's,  the sum of the correspond ing L's of each. So, 
that's a law. And, the other law, linearity law, and this goes for anything in 

mathematics and its applications, which is ca lled linear, basica lly anything is linear if 
it does the follow ing thing to functions or numbers or whatever. 

The other one is of a constant times any function, I don't have to give it a number 
now because I'm only using one of them, should be equa l to c times L of u. So, here, 
c is a constant, and here, of course, the u is a function, functions of x. These are the 
two laws of linearity. An operator is linear if it satisfies these two laws. Now, for 
example, the d ifferentiation operator is such an operator. D is linear, why? Well, 
because of the very first things you verify after you learn what the derivative is 
because the derivative of, well, I w ill write it  in the D form. I'll write it in the form  in 
which you know it. It would be D(u1 + u2). How does one write that in ordinary 
calculus? Well, like that. 

Or, maybe you write d by dx out front. Let's write it this way,  is equal to u1' + u2'. 
That's a law. You prove  it when you first study what a derivative is. It's a property. 
From our point of view, it's a property of the differentiation operator. It has this 
property. The D of u1 plus u2 is D(u1 + u2) = D(u1) + D(u2). And, it also has the 
property that c u', you can pull out the constant. 

That's not affected by the differentiation. So, these two familiar laws from  the 
beginning of calculus say, in our language, that D is a linear operator. What about 
the multip lication of law? That's even more important, that u1 times u2 prime, I 
have nothing whatever to say about that in here. In this context, it's an important 
law, but it's not important with respect to the study of linearity. 

So, there's an examp le. Here's a more complicated one that I'm cla iming is the linear 
operator. And, since I don't want to have to work in this lecture, the work  is left to 
you. So, the proof, prove that L is linear, is this particular operator. L is linear. That's 
in your part one homework to verify that. And you w ill do some simple exercises in 
recitation tomorrow to sort of warm you up for that if you haven't done it a lready. 

Well, you shouldn't have because this only goes with this lecture, actua lly. It's 
forbidden to work ahead in this class. All right, where are we? Well, all that was a 
prelude to proving this simp le theorem, superposition principle. So, finally, what's 
the proof? The proof of the superposition princip le: if you believe that the operator is 
linear, then L of c1, in other words, the ODE  is L. L = D^2 + pD + q. 

So, the ODE is Ly = 0. And, what am I being asked to prove? I'm being asked to 
prove that if y1 and y2 are solutions, then so is that thing. By the way, that's ca lled 
a linear combination. Put that  in your notes. Maybe I better write it even on the 
board because it's something people say all the time without rea liz ing they haven't 
defined it. This  is called a linear combination. 

This expression is ca lled a linear comb ination of y1 and y2. It means that particular 
sum w ith constant coefficients. Okay, so, the ODE is Ly equals zero. And, I'm trying 
to prove that fact about it,  that if y1 and y2 are solutions, so is a linear combination 
of them. So, the proof, then, I start w ith apply L(c1y1 + c2y2). Now, because this 
operator is linear, it takes the sum of two functions into  the corresponding sum up 
what the operator would be. So, it would be L(c1y1) + L(c2y2). That's because L is a 
linear operator. But, I don't have to stop there. Because L is a linear operator, I can 
pull the c out front. So, it's c1*L(y1) + c2*L(y2). 

Now, where am I? Trying to prove that this is zero. Well, what  is L of y1? At this 
point, I use the fact that y1 is a solution. Because it's a solution, this is zero. That's 
what it means to solve that differentia l equation. It means, when you apply the 
linear operator, L, to the function, you get zero. In the same way, y2 is a solution. 
So, that's zero. And, the sum of c1*0 + c2*0 = 0. That's the argument. Now, you 
could make the same argument just by plugg ing c1 y1, p lugg ing it into  the equation 
and calculating, and ca lculating, and calculating, grouping the terms and so on and 
so forth. But, that's just calculation. It doesn't show you why  it's so. Why  it's so is 
because the operator, this differentia l equation is expressed as a linear operator 
applied to y is zero. 

And, the only properties that are really been used as the fact that this operator is 
linear. That's the key point. L is linear. It's a linear operator. Well, that's all there is 
to the superposition princip le. As a prelude to answering the more d ifficult question, 
why are these all the solutions? Why are there no other solutions? We need a few 
definitions, and a few more ideas. And, they are going to occur in connection with, so 
I'm now addressing, ultimately, question two. But, it's not going to be addressed 
directly for quite awhile. Instead, I'm going to phrase it in terms of solving the initial 
value problem. 

So far, we've only talked about the general solution with those two arb itrary 
constants. But, how do you solve the initial value prob lem, in other words, fit initial 
cond itions, find the solution with given initial values for the function and its 
derivatives. Now, -- -- the theorem is that this collection of functions w ith these 
arbitrary constants, these are a ll the solutions we have so far. In fact, they are a ll 
the solutions there are, but we don't know that yet. However, if we just focus on the 
big class of solutions, there might be others lurking out there somewhere lurking out 
there. 

I don't know. But let's use what we have, that just from this family is enough to 
satisfy any initial cond ition,  to satisfy any initia l values. In other words, if you give 
me any initial values, I will be ab le to find the c1 and c2 which work. Now, why is 
that? Well, I'd have to do a song and dance at this point, if you hadn't been softened 
up by actually calculating for specific differentia l equations. You've had exercises and 
actually how to ca lculate the values of c1 and c2. So, I'm going to do  it now in 
general what you have done so far for particular equations using particular va lues of 
the initia l conditions. 

So, I'm relying on that experience that you've had in doing the homework to make 
intellig ible what I'm going to do now in the abstract using just letters. So, why is this 
so? Why is that so? Well, we are going to need it, by the way, here, too. I'll have to, 
again, open up parentheses. But let's go as far as we can. Well, you just try to do it. 
Suppose the initial conditions are, how w ill we write them? 

So, they're going to be at some initial point, x0. You can take it to be zero if you 
want, but I'd like to be, just for a little while, a little more general. So, let's say the 
initia l conditions, the initia l values are being g iven at the point x0, a ll right, that's 
going to be some number. Let's just ca ll it a. And, the initia l value a lso has to specify 
the velocity or the value of the derivative there. 

Let's say these are the initia l va lues. So, the problem is to find the c which work. 
Now, how do you do that? Well, you know from calculation. You write y equals c1 y1 
plus c2 y2. And you write y prime, and you take the derivative underneath that, 

which is easy to do. And now, you plug in x equals zero. And, what happens? Well, 
these now turn into a set of equations. What will they look like? Well, y of x0 is a, 
and this is b. So, what I get is let me flop it over onto the other side because that's 
the way you're used to looking at systems of equations. So, what we get is c1 y1(x0) 
+ c2 y2(x0). 

What's that supposed to be equal to? Well, that's supposed to be equal to y(x0). It's 
supposed to be equa l to the given number, a. And, in the same way, c1 y1'(x0) + c2 
y2'(x0) = b. In the calculations you've done up to this point, y1 and y2 were a lways 
specific functions like e^x or cos(22x), stuff like that. 

Now I'm doing it in the abstract, just calling them y1 and y2, so as to include all 
those possib le cases. Now, what am I supposed  to do? I'm supposed to find c1 and 
c2. What kind of things are they? This is what you studied in high school, right? The 
letters are around us, but it's a pair of simultaneous linear equations. What are the 
variables? What are the variab les? What are the variables? Somebody ra ise their 
hand. 

If you have a pair of simultaneous linear equations, you've got variables and you've 
got constants, right? And you are trying to find the answer. What are the variab les? 
Yeah? c1 and c2. Very good. I mean, it's extremely confusing because in the first 
place, how can they be the variab les if they occur on the wrong side? They're on the 
wrong side; they are constants. How can constants be variab les? Everything about 
this is wrong. Nonetheless, the c1 and the c2 are the unknowns, if you like the high 
school terminology. c1 and c2 are the unknowns. These messes are just numbers. 
After you've p lugged in x0, this is some number. You've got four numbers here. So, 
c1 and c2 are the variables. The two find, in other words, to find the va lues of. 

All right, now you know general theorems from 18.02 about when can you solve such 
a system of equations. I'm claiming that you can always find c1 and c2 that work. 
But, you know  that's not always the case that a pair of simultaneous linear equations 
can be solved. There's a condition. There's a condition which guarantees their 
solution, which is what? What has to be true about the coefficients? These are the 
coefficients. What has to be true? The matrix of coefficients must be invertible. The 
determinant of coefficients must be nonzero. So, they are solvable if, for the c1 and 
c2, if this thing, I'm going to write it. Since all of these are eva luated at x0, I'm 
going to write it in this way. 

y1, the determinant, whose entries are |y1, y2; y1', y2'|, evaluated at zero, x0, that 
means that I evaluate each of the functions in the determinant at x0. I'll write it this 
way. That should be not zero. So, in other words, the key thing which makes this 
possible, makes it possible for us to solve the  initial value problem, is that this funny 
determinant should not be zero at the point at which we are interested. Now, this 
determinant is important in 18.03. It has a name, and this is when you're going to 
learn it, if you don't know it already. That determinant is ca lled the Wronskian. 

The Wronskian of what? If you want to be pompous, you say this with a V sound 
instead of a W. But, nobody does except peop le trying to be pompous. The 
Wronskian, we'll write a W. Now, notice, you can only ca lculate it when you know 
what the two functions are. So,  the Wronskian of the two  functions, y1 and y2, 
what's the variable? It's not a  function of two variab les, y1 and y2. These are just 
the names of functions of x. 

So, when you do it, put it in, calculate out that determinant. This is a  function of x, a 
function of the independent variable after you've done the ca lculation. Anyway, let's 
write its definition, |y1, y2; y1', y2'|. Now, in order to do this, the point is we must 
know that that Wronskian is not zero, that the Wronskian of these two functions  is 
not zero at the point x0. 

Now, enter a theorem which you're going to prove for homework, but this is harder. 
So, it's part two homework. It's not part one homework. In other words, I didn't give 
you the answer. You've got to  find it yourself, alone or in the company of good 
friends. So, anyway, here's the Wronskian. Now, what can we say for sure? Note, 
suppose y1 and y, just to get you a  feeling  for it a little bit, suppose they were not 
independent. The word for not independent is dependent. Suppose they were 
dependent. In other words, suppose that y2 were a constant multip le of y1. 

We know that's not the case because our functions are supposed to be  independent. 
But suppose they weren't. What would the value of the Wronskian be? If y2 is a 
constant times y1, then y2 prime is that same constant times y1 prime. What's the 
value of the determinant? Zero. For what va lues of x is it zero for all values of x? And 
now, that's the theorem that you're going to prove, that  if y1 and y2 are solutions to 
the ODE, I won't keep, say, it's the ODE we've been ta lking about, y'' + py. 

But the linear homogeneous w ith not constant coefficients, just linear homogeneous 
second order. Our solutions, as there are only two possibilities, either-or. Either the 
Wronskian of y, there are only two possib ilities. Either the Wronskian of y1 and y2 is 
always zero,  identica lly zero, zero for all values of x. This is redundant. When I say 
identica lly, I mean  for a ll values of x. But, I am  just making assurance doubly sure. 

Or, or the Wronskian is never zero. Now, there is no notation as for that. I'd better 
just write it out, is never zero, i.e. for no x is it,  i.e. for all x. There's no way to say 
that. I mean, for a ll va lues of x, it's not zero. That means, there is not a single point 
for which it's zero. In particular, it's not zero here. So, this is your homework: 
problem five, part two. I'll g ive you a method of proving it, which was d iscovered by 
the famous Norwegian mathematician, Abel, who is, I guess, the centenary of his 
birth, I guess, was just celebrated last year. 

He has one of the truly tragic stories in mathematics, which I think you can read. It 
must be a Simmons book, if you have that. Simmons is very good on b iographies. 
Look up Abel. He'll have a b iography of Abel, and you can weep if you're feeling sad. 
He died at the age of 26 of tuberculosis, having done a number of sensational things, 
none of which was recognized in his lifetime because people buried his papers under 
big piles of papers. So, he died unknown, uncelebrated, and now he's Norway's 
greatest culture hero. In the middle of a park in Oslo, there's a huge statue. 

And, since nobody knows what Abel looked like, the statue is way up high so you 
can't see very well. But, the inscription on the bottom says N iels Henrik Abel, 1801-
1826 or something like that. Now, -- -- the choice, I'm still, believe it or not, a iming 
at question two, but I have another b ig parentheses to open. And, when I closed it, 
the answer to question two will be simple. But, I think it's very desirab le that you get 
this second big parentheses. It w ill help you to understand something important. 

It will help you on your problem set tomorrow night. I don't have to apolog ize. I'm 
just going to do it. So, the question is, the thing you have to understand is that 
when I write this combination, I'm claiming that these are all the solutions. I haven't 

proved  that yet. But, they are going to be a ll the so lutions The point is, there's 
nothing sacrosanct about the y1 and y2. This is exactly the same collection as a 
collection which I would write using other constants. Let's call them u1 and u2. They 
are exactly the same, where u1 and u2 are any other pa ir of linearly independent 
solutions. 

Any other pa ir of independent solutions, they must be independent, either a constant 
multip le of each other. In other words, u1 is some comb ination, now I'm rea lly stuck 
because I don't know how to, c1 bar, let's say, that means a special value of c1, and 
a specia l value of c2, and u2 is some other special value, oh my God, c1 double bar, 
how's that? The notation is getting worse and worse. I apologize for it. In other 
words, I could p ick y1 and y2 and make up all of these. And, I'd get a bunch of 
solutions. But, I could also pick some other family, some other two guys in this 
family, and just as well express the solutions in terms of u1 and u2. Now, well, why 
is he telling us that? 

Well, the point is that the y1 and the y2 are typically the ones you get easily from 
solving the equations, like e^x and e^(2x). That's what you've gotten, or cos(x) and 
sin(x), something like that. But, for certain ways, they might not be the best way of 
writing the solutions. There is another way of writing those that you should learn, 
and that's ca lled find ing normalized, the normalized. They are okay, but they are not 
normalized. 

For some things, the normalized solutions are the best. I'll expla in to you what they 
are, and I'll explain to you what they're good for. You'll see immediately what they're 
good for. Norma lized solutions, now, you have to specify the point at which you're 
normalizing. In general, it would be x0, but let's, at this point, since I don't have an 
infinity of time, to simplify things, let's say zero. 

It could be x0, any point would do just as well. But, zero is the most common choice. 
What are the norma lized solutions? Well, first of all, I have to g ive them names. I 
want to still call them y. So, I'll call them capital Y1 and Y2. And, what they are, are 
the solutions which satisfy certa in, special, very special, initial cond itions. And, what 
are those? So, they're the ones which satisfy, the initial conditions for Y1 are, of 
course there are going to be guys that look like this. The only thing that's going to 
make them d istinctive is the initial conditions they satisfy. Y1 has to satisfy at zero. 
Its value should be one, and the value of its derivative should be zero. 

For Y2, it's just the opposite. Here, the value of the function should be zero at zero. 
But,  the value of its derivative, now, I want to be one. Let me give you a trivial 
example of this, and then one, which is a little less trivial, so you'll have some feeling 
for what I'm asking for. Suppose the equation,  for example, is y doub le prime p lus, 
well, let's rea lly make it simp le. Okay, you know the standard solutions are y1 = 
cos(x), and y2 = sin(x). These are functions, which, when you take the second 
derivative, they turn into their negative. You know, you could go the comp lex roots 
are i and minus i, and blah, b lah, blah, b lah, blah, b lah. If you do it that way, fine. 
But at some point  in the course you have to be able to write down and, right away, 
oh, yeah, cos(x), sin(x). 

Okay, what are the normalized things? Well, what's the value of this at zero? It  is 
one. What's the value of its derivative at zero? Zero. This is Y1. This is the only case 
in which you locked on immediately to the normalized solutions. In the same way, 
this guy is Y2 because its value at zero is zero. It's value of its derivative at zero is 

one. So, this is Y2. Okay, now let's look at a case where you don't immediately lock 
on to the normalized solutions. Very simple: all I have to do is change the sign. 
Here, you know, think through r^2 -1 = 0. The characteristic roots are p lus one and 
minus one, right? 

And therefore, the solution  is e^x, and e^(-x). So, the solutions you find by the 
usua l way of solving it is y1 = e^x, and y2 = e^(-x). Those are the standard 
solution. So, the general solution is of the form. So, the general solution is of the 
form c1 e^x + c2 e^(-x). Now, what I want to find out  is what is Y1 and Y2? 

How do I find out what Y1 is? Well, I have to satisfy  initia l conditions. So, if this is y, 
let's write down here, if you can still see that, y' = c1 e^x - c2 e^(-x). So, if I p lug 
in, I want y of zero to be one, I want this guy at the point zero to be one. What 
equation does that give me? That gives me c1 + c2, c1 p lus c2, plugg ing in x equals 
zero, equals the va lue of this thing at zero. So, that's supposed to be one. How 
about the other guy? The value of its derivative is supposed to come out to be zero. 
And, what  is its derivative? Well, p lug into this expression. It's c1 - c2. 

Okay, what's the solution to those pa ir of equations? c2 has to be equa l to c1. The 
sum of the two of them has to be one. Each one, therefore, is equa l to one ha lf. And 
so, what's the va lue of Y1? Y1, therefore, is the function where c1 and c2 are one 
half. It's the function Y1 = (e^x + e^(-x))/2. In the same way, I won't repeat the 
calculation. You can do yourself. Same ca lculation shows that Y2, so, put in the initial 
cond itions. The answer will be that Y2 = (e^x - e^(-x))/2. These are the special 
functions. For this equation, these are the normalized solutions. They are better than 
the original solutions because their initial values are nicer. 

Just check it. The  initia l value, when x is equal to zero, the initial value, this has is 
zero. Here, when x is equal to zero, the value of the function  is zero. But, the value 
of its derivative, these cancel, is one. So, these are the good guys. Okay, there's no 
colored chalk this period. Okay, there was colored chalk. There's one. So, for this 
equation, these are the good guys. These are our best solutions. e^x and e^(-x) are 
good solutions. But, these are our better solutions. And, this one, of course, is the 
function which is ca lled hyperbolic sine of x, and this is the one which is ca lled 
hyperbolic cosine of x. This is one of the most  important ways in which they enter 
into mathematics. And, this is why the engineers want them. Now, why do the 
eng ineers want norma lized solutions? 

Well, I didn't exp lain that. So, what's so good about normalized solutions? Very 
simple: if Y1 and Y2 are normalized at zero, let's say, then the solution to the IVP, in 
other words, the ODE plus the initia l va lues, y(0) = a and y'(0) = b. So, the ODE I'm 
not repeating. It's the one we've been ta lking about all term since the beginning of 
the period. It's the one w ith the p(x) and q(x). And, here are the initial va lues. I'm 
going to call them a and b. You can a lso call them, if you like, maybe that's better to 
call them y0, as they are ind ividua l in the homework. 

They are ca lled, I'm using the, let's use those. What is the solution? I say the 
solution is, if you use y1 and y2, the solution is y0 Y1 + y0' Y2. In other words, you 
can write down instantly the solution to the initial value problem, if instead of using 
the functions, you started out with the little Y1 and Y2, you use these better 
functions. 

The thing that's better about them is that they instantly solve for you the  initia l value 
problem. All you do is use this number, initial condition as the coefficient of Y1, and 
use this number as the coefficient of Y2. Now, just check that by  looking at it. Why is 
that so? Well,  for examp le, let's check. What is its va lue of this function at zero? 
Well, the value of this guy at zero  is one. So, the answer is y0 times one, and the 
value of this guy at zero is zero. So,  this term disappears. And, it's exactly the same 
with the derivative. What's the va lue of the derivative at zero? The value of the 
derivative of this thing is zero. So, this term disappears. The va lue of this derivative 
at zero is one. 

And so, the answer is y0'. So, check, check, this works. So, these better solutions 
have the property, what's good about them, and why scientists and engineers like 
them, is that they enable you immediately to write down the answer to the initial 
value problem w ithout having to go through this business, which I buried down here, 
of solving simultaneous  linear equations. Okay, now, believe  it or not, that's all the 
work. We are ready to answer question number two: why are these a ll the solutions? 
Of course, I have to invoke a big theorem. A big theorem: where shall I invoke a big 
theorem? Let's see if we can do it here. 

The b ig theorem says, it's ca lled the existence and uniqueness theorem. It's the last 
thing that's proved at the end of an ana lysis course, at which rea l analysis courses, 
over which students sweat for one whole semester, and their reward at the end is, if 
they are very lucky, and if they have been very good students, they get to see the 
proof of the existence and uniqueness theorem  for differential equations. But, I can 
at least say what it is for the linear equation because it's so simp le. 

It says, so, the equation we are ta lking about is the usual one, homogeneous 
equation, and I'm going to assume, you have to have assumptions that p and q are 
continuous for a ll x. So, they're good-looking  functions. Coefficients aren't a llowed to 
blow up anywhere. They've got to look nice. Then, the theorem says there is one and 
only one solution, one and only solution satisfying, g iven initia l values such that y of 
zero, let's say y(0) = A, and y, let's make y0, and y'(0) = B. 

The initial va lue problem has one and only one solution. The existence is, it has a 
solution. The uniqueness  is, it only has one solution. If you specify the initial 
cond itions, there's only one function which satisfies them and at the same time 
satisfies that d ifferential equation. Now, this answers our question. This answers our 
question, because, look, what I want is all solutions. What we want are a ll solutions 
to the ODE. And now, here's what I say: a cla im that this collection of functions, 
c1Y1 + c2Y2 are all solutions. 

Of course, I began a period by saying  I'd show you that c1 little y1 c little y2 are a ll 
the solutions. But, it's the case that these two families are the same. So, the family 
that I started with would be exactly the same as the family c1' Y1 because, after all, 
these are two specia l guys from that collection. So, it doesn't matter whether I talk 
about the orig ina l ones, or these. The theorem is still the same. The fina l step, 
therefore, if you g ive me one more minute, I think that will be quite enough. Why 
are these all the solutions? 

Well, I have to take an arbitrary solution and show you that it's one of these. So, the 
proof is, given a solution, u(x), what are its va lues? Well, u(x0) = u0, and u'(x0), 
zero, let's say, is equal to u(0), is equal to some other number. Now, what's the 
solution? Write down what's the solution of these using the Y1's? Then, I know I've 

just shown you that u0Y1 + u0' Y2 satisfies the same initial cond itions, satisfies 
these initial cond itions, initial values. In other words, I started with my little solution. 
u(x) walks up to and says, hi there. Hi there, and the differentia l equation looks at it 
and says, who are you? 

You say, oh, I satisfy you and my initial, and then it says what are your initial 
values? It says, my initial values are u0 and *u0'. And, it said, sorry, but we've got 
one of ours who satisfies the same initia l conditions. We don't need you because the 
existence and uniqueness theorem says that there can only be one function which 
does that. And therefore, you must be equal to this guy by the uniqueness theorem. 

Okay, we'll talk more about stuff next time, linear equation next time. 

