5 Homework Solutions
18.335 - Fall 2004

5.1 Trefethen 20.1
)If A has an LU factorization, then all diagonal elements of U are not zero.
Since A = LU implies that A1:k;1:k = L1:k;1:kU1:k;1:k we get that A1:k;1:k is
invertible.
(We prove by induction that A1:k;1:k = L1:k;1:kU1:k;1:k with
1 (cid:19) and U1:k+1;1:k+1 = (cid:18) U1:k;1:k
L1:k+1;1:k+1 = (cid:18) L1:k;1:k
uk+1 (cid:19)
0
(cid:3)
0
(cid:3) (cid:3) (cid:3)
with all the elements on the diagonal of U1:k;1:k are non-zero for any k :

with

Step 1 For k = 1 we have A1:1;1:1 = L1:1;1:1U1:1;1:1 with L1:1;1:1 = 1; U1:1;1:1 =
A1:1;1:1 6= 0:
Step 2 If that is true for k (cid:20) m we prove it for m + 1: Simply choose:
(cid:18) U1:m;1:m
A1:m+1;1:m+1 = (cid:18) L1:m;1:m 0
1 (cid:19)
um+1 (cid:19)
Ym
Xm
0
{z
}
}
{z
|
|
U1:m+1;1:m+1
L1:m+1;1:m+1
Xm = [am+1;1 :::am+1;m ]U (cid:0)1
1:m;1:m
1:m;1:m 264
375
a1;m+1
...
Ym = L(cid:0)1
am;m+1
um+1 = (cid:0)XmYm
Now we have um+1 6= 0 since det(A1:m+1;1:m+1 ) = det (U1:m;1:m ) um+1 6=
0: Now since A = A1:n;1:n = L1:n;1:nU1:n;1:n and L1:n;1:n is unit lower
diagonal, U1:n;1:n is upper diagonal and we complete the proof.

5.2 Trefethen 21.6
Write

A = (cid:18) a11 A12
A21 A22 (cid:19)
Proceed with the (cid:133)rst step of Gaussian elimination:
A12 1A
0@

A12
a11
A21
0 A22 (cid:0)
a11

11

A21
Now for A22 (cid:0)
A12 we show that it has the property of strictly diagonally
a11
dominant matrices.
A12(cid:19)jk (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:20) Xj 6=k (cid:12)(cid:12)(cid:12)(A22 )jk (cid:12)(cid:12)(cid:12) + Xj 6=k (cid:12)(cid:12)(cid:12)(cid:12)
Xj 6=k (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(A21 )j (A12 )k (cid:12)(cid:12)(cid:12)(cid:12)
(cid:18)A22 (cid:0)
A21
1
a11
a11
A is strictly diagonally dominant, so we may write
Xj 6=k (cid:12)(cid:12)(cid:12)(A22 )jk (cid:12)(cid:12)(cid:12) < j(A22 )kk j (cid:0) j(A12 )k j and Xj 6=k (cid:12)(cid:12)(cid:12)(A21 )j (cid:12)(cid:12)(cid:12) < ja11 j (cid:0) j(A21 )k j
so that in the end we get:
A12(cid:19)jk (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xj 6=k (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:18)A22 (cid:0)
< j(A22 )kk j (cid:0) j(A12 )k j + j(A12 )k j
A21
(ja11 j (cid:0) j(A21 )k j)
ja11 j
a11
(cid:20) (cid:12)(cid:12)(cid:12)(cid:12)(A22 )kk (cid:0)
(A21 )k (A12 )k
< j(A22 )kk j (cid:0) j(A12 )k j j(A21 )k j
ja11 j
a11
(cid:20) (cid:12)(cid:12)(cid:12)(cid:12)(cid:18)A22 (cid:0)
a11 (cid:19)kk (cid:12)(cid:12)(cid:12)(cid:12)
A21A12
Hence by induction if the property is true for any matrix of dimension (cid:20) m (cid:0) 1
then it is true for any matrix A of dim A = n: This means that the submatrices
that are created by successive steps of Gaussian elimination are also strictly
diagonally dominant and hence we have no need for row swappings.

(cid:12)(cid:12)(cid:12)(cid:12)

a1m
a2m
...
amm

a12
a11
a22
a21
...
...
am1 am2

5.3 Trefethen 22.1
Apply 1 step of Gaussian elimination to A :
0BBB@
1CCCA
(cid:0)(cid:0)(cid:0)!of GE 0BBB@
1CCCA
a11
a12
a1m
(cid:1) (cid:1) (cid:1)
(cid:1) (cid:1) (cid:1)
a(1)
a(1)
1 S t e p
0
(cid:1) (cid:1) (cid:1)
(cid:1) (cid:1) (cid:1)
2m
22
...
...
...
. . .
. . .
a(1)
a(1)
(cid:1) (cid:1) (cid:1)
0
(cid:1) (cid:1) (cid:1)
mm
m2
, where the entries a(1)
ij = aij (cid:0) lik akj : Since we used partial pivoting in our
calculation, we must have jlik j (cid:20) 1;
jai;j j
j~aij j = jaij (cid:0) lik akj j (cid:20) jaij j + jlik j jakj j (cid:20) jaij j + jakj j (cid:20) 2max
i;j
In order to form A we need m (cid:0) 1 such steps, so in the end we have:
(cid:12)(cid:12)(cid:12) (cid:20) 2max
(cid:12)(cid:12)(cid:12) (cid:20) ::: (cid:20) 2max
(cid:12)(cid:12)(cid:12)a(m(cid:0)3)
(cid:12)(cid:12)(cid:12)a(m(cid:0)2)
jai;j j
juij j (cid:20) 2max
i;j
i;j
i;j
i;j
i;j
so that we obtain juij j (cid:20) 2m(cid:0)1max
jai;j j : Therefore
i;j
jui;j j
max
i;j
jai;j j (cid:20) 2m(cid:0)1
(cid:26) =
max
i;j

12

5.4

Let A be symmetric and positive de(cid:133)nite. Show that jaij j2 < aii
aj j .
Since A is symmetric and positive de(cid:133)nite, it has all aii positive and for any
vector x we have xT Ax > 0: Choose x such that xk = (cid:14) jk aj j (cid:0) (cid:14) ik aij ; where (cid:14) lm
is the Kronecker delta, meaning that all the entries of x are zero except the i-th
and the j -th entries which equal to (cid:0)aij and aj j respectively . Carrying out the
calculation gives xT Ax = aii (cid:0)aiiaj j (cid:0) a2
ij (cid:1) > 0 thus completing the proof.
5.5 Let A and A(cid:0)1 be given real n-by-n matrices. Let B = A + xyT
be a rank-one perturbation of A. Find an O(n2 ) algorithm for
computing B(cid:0)1 . Hint: B(cid:0)1 is a rank-one perturbation of A(cid:0)1 .
Since B(cid:0)1 is a rank-one perturbation of A(cid:0)1 we may write B(cid:0)1 = A(cid:0)1 + uvT :
Then
BB(cid:0)1 = (cid:0)A + xyT (cid:1) (cid:0)A(cid:0)1 + uvT (cid:1)
I = I + AuvT + xyT A(cid:0)1 + xyT uvT
0 = AuvT + xyT A(cid:0)1 + xyT uvT

Choosing u = A(cid:0)1x; allows us to write:

0 = xvT + xyT A(cid:0)1 + xyT uvT
0 = vT + yT A(cid:0)1 + yT uvT
0 = vT (1 + yT u) + yT A(cid:0)1
yT A(cid:0)1
vT = (cid:0)
1 + yT A(cid:0)1x
Hence B(cid:0)1 is given by:

B(cid:0)1 = A(cid:0)1 (cid:0)
It is easy to see that the inverse can be computed in O(n2 ) operations

A(cid:0)1xyT A(cid:0)1
1 + yT A(cid:0)1x

13

