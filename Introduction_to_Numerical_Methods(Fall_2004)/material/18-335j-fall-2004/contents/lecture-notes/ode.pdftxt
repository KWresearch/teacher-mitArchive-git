Ordinary  Diﬀerential   Equations,  part  of  Math  18.335,  Fall  2004 

Plamen  Koev 

December  8,  2004 

1 

Introduction 

We  study  

y(0)  =  y0 , 

y˙ (t) =  f (y(t)),
where  f  is   a  nice  diﬀerentiable,   vector­valued  function. 
Consider  the  scalar   case   ﬁrst.  To  solve  this  equation,  discretize  ti  =  ih  for  a  given  h  and  use 
y(t  +  h) − y(t)  ≈ y �  =  f (y(t))
h 
to  obtain   y(t  +  h) ≈ y(t) +  hf  (y(t)),  which  yields  the  Euler’s  method  (yi  approximates  y(ti )): 
yn+1  =  yn  +  hf  (yn ). 

Truncation  error  (τn ): 

where  (Taylor) 

Let 

Then  the  error   satisﬁes 

y(tn+1 ) =  y(tn ) +  hf  (y(tn ))  +  hτn , 

τn  =

2 y �� (tn  +  θnh). 
h 
en  =  error  =  yn  − y(tn ) =  computed  − exact. 

en+1  =  en  +  h[f (yn ) − f (y(tn ))]  − hτn . 

After  some  manipulation   we  get 

LTe − 1  h 
· 
| ≤ 
|
en
2 
L 
where  T  =  nh,  L  is  a  bound   on  f � ,  and   M  is  a  bound   on  y �� . 
For  systems  the  story  is  a  little  more  complicated  to  derive,  but  the   answer  is  the   same  
LTe − 1  h  · M , 
�en � ≤ 
· 
2 
L 
but we  have  to  use  norms  instead   (1,  2,  ∞ norms  are  all  OK). 
Consider  the  error  more  carefully  now.  We   will  show  that  there   exists  a  function   e(t) such   that 

· M , 

Consider  two  calculations—one   with  mesh   size  h  and  another  with  mesh  size  h/2.  Write 

yn  =  y(tn ) +  he(tn ) +  O(h2 ). 

Subtract: 

comph yn  = 
comph/2 y2n  = 

y(nh) +  he(nh) +  O(h2 ) 
y(2nh/2)  +  (h/2)e(2nh/2)  +  O(h2 ) 

comph yn  − comph/2 y2n  = (h  − h/2)e(nh) +  O(h2 ). 

1 

So  we  can   ﬁgure  out  what  the  error  is.  Alternatively  we  can   eliminate  the  error 
2 · comph yn  − comph/2 y2n  = (2  − 1)y(tn ) +  O(h2 ). 
A  combination  between   the  computed   values  is  a   more   accurate  estimate  of  the   exact   solution  than  either  
calculation.   We  obtained  a  second   order  method,  instead   of  Euler’s  ﬁrst  order  method.  What   did  we  lose? 
We  lost  our   ability  to  tell  what  the   new  error  is.  This  is  typical.  If  you  know   what   the   error  is  you  can 
improve  the  calculation,  but  then  you   don’t  know  what  the  error  is. 
To   obtain   information   about  the  error  we  insert  yn  =  y(tn ) +  he(tn )  in  Euler’s  method  (yn+1  =  yn  + 
hf (yn )),  use   Taylor  series   and   obtain: 
� 
� 
� 
� 
y(t  +  h) +  he(t  +  h) +  .  .  .  =  y(t) +  he(t) +  hf  (y(t) +  he(t) +  · · · ) +  · · · 
1 
h3 
h2 
3!  y ��� + .  .  .  + h e   +  he�  + 
e��  +  .  .  .  =  y + he  + h f (y) +  f � (y)he  +  f �� (y)(he)2  +  .  .  . 
y �� + 
y + hy � + 
2
2
� 
� 
Now  use  that  y �  =  f (y)  to  obtain  
1 
2 y ��  +  e�  − f � (y)e) =  O(h3 ). 
0.  It  is  natural   to  deﬁne 
e� (t) =  f � (y(t))  e(t) − 
·

1 
2 y � (t),
This   is  called   the  variational  equation.   Now  after  some   additional  work  we  can   prove  that  

Divide  by  h2  and   let  h 

e(0)  = 0.

h2 
2 

→ 

h2 

comp  yn  = exact  y(t) +  he(t) +  O(h2 ). 

2 

Runge­Kutta   Methods 

We  begin   with  

qn  = 
yn+1  = 

h 
f (yn )
yn  + 
2
yn  +  hf (qn ), 

which  is  called  Heun’s  method  by  some,  Runge’s  Second   Order  by  others  or  Improved  Euler  by  still  others. 
It  is  explicit  because 

h 
2
so  to  compute  yn+1  we  only need  yn  and  f .  What  is  the  truncation   error  of  the   scheme? 

yn+1  =  yn  +  hf  (yn  + 

f (yn )),

f (y(tn )))  +  hτn

y(t) + hy � (t) + 

Using  Taylor  series  we  get 

y(tn+1  =  y(tn ) +  hf  (y(tn ) + 
� 
1 
h2 
h3 
3!  y ��� (t  + θh) =  y(t) +  h f (y(t))  +  f � (y(t)) f (y) +  f �� (y(t)) 
2  y �� (t) + 
h 
h 
2
2
2
� 
� 
·
Since  y �  =  f (y) we  see  that  y ��  =  f � (y)y �  =  f � (y) f (y) and  we   can  cancel  all  terms  up  to  h2  to  get 
1
1 
3! y ��� (t  +  θh) −  f �� (y(t) +  θ
,
8
where  the  two  θ ’s  are  not  the  same.  Therefore   τn  =  O(h2 ). 

f (y))(f (y))2 

τn  =  h2 

�

�2 � 
f (θ)
+ hτn

h 
2

h
2

2 

Heun’s   method   became  very  popular   because  it  required  very  little  storage   (an  important  consideration 
at  the  time).   We  can   forget  all   about  f (yn )  once  we  have  qn .  This  is  not  the  case  for  the   Improved  Euler 
method 

We  derive  it  as   follows: 

qn  = 

yn+1  = 

yn  +

yn  +	 f (yn ) 
h 
(f (yn ) +  f (qn )) 
2
�  t+h 
t 

f (y(z ))dz , 

y(t  +  h) − y(t) = 

then  using   the  trapezoidal  rule   we   get 

y(t  +  h) − y(t) =

h 
2

(f (y(t))  +  f (y(t  +  h))), 

we  don’t  have  y(t  + h) available  in   order  to  get  f (y(t  +  h)),  but  we   can  replace   f (y(t  +  h))  by  the  result   we 
get  from  Euler’s  method   f (y(t) +  hf  (y(t))).  We  can  show  that  the  truncation  error  for  modiﬁed  Euler 

h 
2

(f (yn ) +  f (yn  +  hf  (yn ))) 

yn+1  =  yn  +
�	

1 
1
3! y ��� (t  +  θh) −  f �� (y(t) +  θhf  (y))  · (f (y))2 
4

�

is  

τn  =  h2 

3 

Stiﬀ  ODEs 

Consider 

y �  =  −λ(y  − 1) 
for  large  λ,  e.g.  λ  = 100,  or  λ  =  1000,   or  λ  = 106 .  The   solution   is 
y(t) =  e−λt (y(0)  − 1)  +  1. 
All   solutions   start  oﬀ   at  y(0)  and  “seek”  y  ≡ 1  and  the  change  for  small  t  is  very  rapid. 
To   be  speciﬁc,  take  λ  =  1000  and  use  Euler’s  method  with  h  = 
1000  and  h  =  10000 .
100 ,  h  = 
1	
1
2 
un+1  =  un  − hλ(un  − 1)  =  un  − h  · 1000(un  − 1)  = (1  − 1000h)un  +  1000h. 
Try   h  =  100  with   u0  = 1 +  ε.   Then 
1

u1  = 1 − 9ε 
u2  = 
1 +  92 ε 
u3  = 1 − 93 ε, 
and  in  general  un  = 1 +  (−9)n ε.   This  is  terrible  with   wild   growth   no  matter  how  tiny  ε  is. 
Try  h  =  1000	 with   u0  = 1 +  ε.   Then  from  the   equation  
2
un+1  =  −un  +  2 

and  we  have 

u1  = 1 − ε 
u2  = 
1 +  ε 
u3  = 1 − ε, 

3 

and  in  general  un  = 1  +  (−1)n ε.   Our  numerical  solution  still  does  not   tend  to   the   correct   solution,  but   at 
least  the  wild  oscillations   are  gone. 
Try   h  =  10000  with   u0  = 1 +  ε.   Then  from  the   equation 
1
9
un+1  =  − 
10

un  +

1 
10  

and  we   have 

1 + 

1 + 

u2  = 

u1  = 

ε10� �2
9 
9 
10  � �3
9 
�n9
�
10  
ε  and  the  numerical  solution  will  ﬁnally   converge  to  the   correct   solution   y  ≡ 1. 
and  in  general   un  = 1 +  10 
It  seems   fair  to  use  small  step  size  when   the   solution   is  changing   rapidly,  but  it   seems  unfair  to  take  small 
steps  past  t  = 1/10.  For  example  if  y(0)  =  2,  then  y(t) =  e−1000t  +  1  and  
=  e−100  +  1  = 1  in 
e−1000/10  +  1 
double  precision  ﬂoating  point  arithmetic. 
The  problem  has  nothing  to  do   with  Euler’s  method.  Al l  explicit  methods  suﬀer  from   the   same   problem. 
The  choice  of  y �  =  −λ(y  − 1)  was  somewhat  arbitrary,  we  could  have   had  the  solution   approaching   any 
function  by   choosing   to  solve   instead 

u3  = 

ε

ε

1 + 

y �  =  −λ(y  − φ(t))  +  φ� (t), 

which  has  a  solution  

y(t) =  φ(t) +  e−λt (y(0)  − φ(0)). 
So  let’s  look   at  the  simplest  case   φ(t) ≡ 0 

y �  =  −λy . 
There   is   an   interesting  way  out  of  this  trouble,  namely  to  use  implicit  methods.  Implicit  Euler: 

un+1  =  un  +  hf  (un+1 ). 
The  trouble,  of   course,  is   computing  un+1  from   here,  but  we  will  worry  about  this  later.  Attack  y �  =  −λy : 
un+1  =  un  +  h(−λ)un+1 
(1  +  hλ)un+1  =  un 

u0  → 0  pretty  slowly.

4 

So  h  =  10   ,  100 ,  1000  ,  10000 
1 
1
1
1 

un . 

u0  → 0  rapidly 

1 
un+1  = 
1 +  hλ
�n 
�n
�
1 
�n 
� �n
u0  = 
101 
1 
� �n
�n 
u0  → 0  rapidly 
u0  = 
11  
1 
�n 
� �n
u0  → 0  sort  of 
u0  =
2 
10  
11  

u0  = 

�
gives 
1
� 
1 +  1  1000 
10 
1
� 
1 +  1  1000  
100
1
� 
1 + 
1  1000 
1000 
1 
1 + 
1 
10000

1000

un  = 

un  = 

un  = 

un  = 

y(tn )  = 

Only  the  last  case  follows  the  accurate  solution   accurately.  For  h  =  10000 
1
e−λt  y(0)  =  e−(1/10)n  y(0) 
 
( 10  )2 
1
10  − 
1 
2 

−n 
e−n  ln(1+1/10)u0  ∼ e 
Does  the  implicit  Euler’s  method   converge? 

e n  ln(10/11)u0 

un 

= 

= 

( 10  )3 
1 
3  +...

+ 

! 
u0 

y(tn+1 ) =  y(tn ) +  hf  (y(tn+1 ))  +  hτn . 

h2 
2 

C

≤ 

h 
2

and 

y  +  hf  (y  +  hy � (t  +  θh))  +  hτ
y  +  h (f (y) +  f � (y  +  θhy � (t  +  θh) h  · y � (t  +  θh))  +  hτ
· 
� 

τn  =  h 

Therefore 

y  +  hy �  + 

y �� (t  +  θh)  = 
= 
� 
1 
2 y �� (t  +  θh) − f � (y  +  θhy � (t  +  θh))  · y � (t  +  θh)
� �� � 
� �� �
1 
τn | ≤ h  − 
|
2 y �� (t) +  O(h) 
Then  we  can  repeat  the  proof  for  the  explicit  Euler: 
yn  +  hf  (yn+1 ) 
yn+1  = 
� 
� 
y(tn ) +  hf  (y( tn+1 ))  +  hτn 
y(tn+1 )  = 
yn  − y(tn ) +  h f (yn+1 ) − f (y( tn+1 )  − hτn 
yn+1  − y(tn+1 )  = 
en | +  hL en+1 +  h τn
en+1 | 
≤ |
|
|
|
|
| 
en+1 | ≤  (1  − hL)−1 en +  h τn
| 
|
|
|
| 
2 .  Then   (1  − hL)−1  ≤ 1 +  2hL  and 
Assume  hL  <  1 
|en | ≤  (1  +  2hL) en−1 +  h2C
|
| 
� � 
� 
≤ 
.  .  . 
n−1
(1  +  2Lh)n |e0 + 
≤
| 
(1   +  2Lh)i  h2C
i=0 
(1  +  2Lh)n  − 1 
1 +  2Lh  − 1 
− 1 
2LT
e
2L 

h2C

= 

≤ 

hC. 

5 

