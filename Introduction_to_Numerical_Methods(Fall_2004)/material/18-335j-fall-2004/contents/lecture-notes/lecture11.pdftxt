Chapter  8


8.1  Gaussian  Elimination  

The   process  of  Gaussian  elimination  is  a   fundamental  tool  in  solving  linear   systems  of  equations. 
Example  1:  Consider  the  linear   system: 

x1  +  x2  +  x3  = 

x1  +  2x2  +  4x3  = 

3 

7 

x1  +  3x2  +  9x3  = 

13 

(8.1) 

(8.2) 

(8.3) 

The   traditional  way  of  solving  this  system  is  to  subtract   the  ﬁrst   equation  from  the  second  and 
the   third  to  obtain 

x1  +  x2  +  x3  = 

x2  +  3x3  = 

3 

4 

2x2  +  8x3  = 

12 

Now  subtract  2  times  the   second  equation  from  the   third  to  obtain 

x1  +  x2  +  x3  = 

3 

x2  +  3x3  =  4 

2x3  =  2 

Now  we  can  perform  back  substitution: 

x3  = 

1 

(8.4) 

(8.5) 

(8.6) 

(8.7) 

(8.8) 

(8.9) 

(8.10) 

24 

8.1.  GAUSSIAN  ELIMINATION 

x2  = 3  −  3x3  = 4  −  3  ·  1  = 1 

x1  = 3  −  x2  −  x3  = 3  −  1  −  1  = 1. 

25 

(8.11) 

(8.12) 

Instead  of  performing  the  same  process  for  every  right   hand  side,  it   is  more  advantageous  to  use 
matrix  factorizations  instead.  Write   the  System  8.1-8.3  as 
⎤
⎡⎤
⎡⎤
⎡  1
x1 
3 
1 
= ⎢⎣ 7 ⎥⎦
· ⎢⎣ x2 ⎥⎦ 
4 ⎥⎦ 
⎢⎣ 1
x3 
13 
1
9 
In  general  linear  systems  are  written  as 

(8.13) 

1
2
3

or 

Ax =  b 

(8.14) 

a11 
a12 
a21 
a22 
.
.
. 
.
.
. 
an1  an2 

⎡⎤
⎡⎤
⎤b1
⎡
x1
. . .  a1n 
.  ⎥⎥⎥⎥⎦ 
·  ⎢⎢⎢⎢⎣ 
. . .  ⎥⎥⎥⎥⎦ 
=  ⎢⎢⎢⎢⎣ 
⎥⎥⎥⎥⎦ 
⎢⎢⎢⎢⎣ 
x2 
b2 
. . .  a2n
. 
. . . 
. 
.
. 
. . .  ann  
xn 
bn 
where  we  assume  that  leading  principal  minors  A(1  :  k , 1  :  k),  k  = 1, 2, . . . , n,  of  the   n-by-n  
matrix  A = [aij ]n 
i,j=1  are  nonzero. 
Some  linear   systems  are  easy  to  solve.  For  example  if  A is  triangular  or  diagonal. 

(8.15) 

.

If  A  is  (lower  or  upper)  triangular  nonsingular  matrix   then  Ax  =  b  can  be  solved  via  back  
substitution.  The  system 

⎤b1
⎡⎤
⎡⎤
⎡
x1 
⎥⎥⎥⎥⎦ 
=  ⎢⎢⎢⎢⎣ 
. . .  ⎥⎥⎥⎥⎦ 
·  ⎢⎢⎢⎢⎣ 
⎥⎥⎥⎥⎦ 
⎢⎢⎢⎢⎣ 
b2 
x2 
. . . 
bn 
xn 
(the  zero  entries  of  the  upper  triangular  part  have  been  omitted)  is  equivalent   to 

a11 
a22 
a21 
. 
.
.
. 
.
. 
an1  an2 

. . .  ann  

. 

. 

. 

a11x1  = 

a21x1  +  a22x2  = 

b1 

b2 

. . . 

an1x1  +  an2x2  +  . . . +  annxn  = 

bn 

(8.16) 

(8.17) 

(8.18) 

(8.19) 

and  is  solved  by  computing  x1  from  the  ﬁrst  equation,  substituting  into  the  second  and  so  on:  

26 

CHAPTER  8. 

x1  = 

x2  = 

. . . 

xn  = 

b1 
a11 
1 
a21 

(b2  −  a21x1 ) 

1 
ann 

(bn  −  an1x1  −  an2x2  −  . . .  −  an,n−1xn−1 ) 

(8.20) 

(8.21) 

(8.22) 

.  .  . 

dn 

d1 

d2 

x1 
x2 
. . . 
xn 

The  solution  to  a  diagonal  linear  system  is  trivial: 
⎤
⎡⎤
⎡⎤
⎡
⎥⎥⎥⎥⎦ 
=  ⎢⎢⎢⎢⎣ 
⎥⎥⎥⎥⎦ 
·  ⎢⎢⎢⎢⎣ 
⎥⎥⎥⎥⎦ 
⎢⎢⎢⎢⎣ 
implies   xi  =  bi  ,  i = 1, 2, . . . , n.
di 
Deﬁnition:  A  matrix  A  is  called   unit  lower  triangular  if  aij  = 0,  1  ≤  i  <   j  ≤  n  and  aii  =  1, 
1  ≤  i ≤  n. 
An   unit  upper  triangular  matrix  is  deﬁned  analogously.  
Example:  The  following  4-by-4  matrix  is  unit  lower  triangular  
⎡ 
⎤ 
⎢⎢⎢⎣ 
⎥⎥⎥⎦ 
Exercise:  Prove  that  if  A  and  B  are  unit  lower  triangular  matrices,  then  so  are  A−1  and  AB . 
Deﬁnition:  Let   A  be  a  nonsingular  matrix,  then  a  decomposition  of   A  as  a  product  of  a  unit 
lower  triangular  matrix   L,  a  diagonal  matrix  D  and  a  unit  upper  triangular  matrix  U : 

1 
2 1 
3 5 1 
4 6 7

(8.23)

(8.24) 

b1
b2 
. . . 
bn 

1 

A =  LDU  

(8.25) 

is  called  an  LDU  decomposition  of  A. 
The   main  idea  in  what  follows  is  to   use   Gaussian  elimination  to  compute  the  LDU  decomposition 
of  A. 
Once  we  have  the  LDU  decomposition  of   A,  the  equation  Ax  =  b  becomes   LDU x  =  b,  which  is 
easy  to  solve.  First   compute   the   solution  y  to  the  lower  triangular  system  Ly  =  b,  then  the  solution 
z  to  the  diagonal  system   Dz   =  y ,  and  ﬁnally  the  solution  x  to  the  upper  triangular   system  U x  =  z . 
Finally, 

Ax  =  LDU x  =  LD(U x) =  L(Dz ) =   Ly   =  b 

(8.26) 

as  desired.

So  how  does  one   compute  the  LDU  decomposition  of  a  nonsingular   matrix  A?


8.1.  GAUSSIAN  ELIMINATION 

27 

First  we  represent   a  subtraction  of  a  multiple  of  one  row  from  another  in  matrix   form.  Consider  
the   matrix: 

1 
2 
9 

1
1
3 

1 
4 
27 

⎤
⎡
⎥⎦
⎢⎣ 
In  order  to  introduce   a  zero  in  position  (3,  1)   we   need  to  subtract   3  times  the  ﬁrst   row  from  the 
third.  This  is  equivalent  to  multiplication  by   the  matrix  
⎡  1 
⎤
⎢⎣ 
⎥⎦
0
−3

(8.28) 

(8.27) 

1 
0

1  

namely 

⎡  1 
⎢⎣ 0
−3

1
0

1  

⎡⎤
1
· ⎢⎣ 1
⎥⎦ 
3

1
2 
9

⎡⎤
1
1  
= ⎢⎣ 1
4 ⎥⎦ 
27 
0

1
2 
6

⎤
1 
4 ⎥⎦
24 

Since 

1 
0
−3

1 
0

1  

⎡
⎢⎣ 

−1
⎤
⎥⎦ 

= 

⎡
⎢⎣ 

1 
0
3

1
0

1 

⎤
⎥⎦

1
2  
9

1 
2 
6

1
2 
6

the  equality 8.29  implies 
⎡  1
⎡⎤
⎡⎤
⎤
1 
1  
1  
1
⎢⎣ 1
4 ⎥⎦ 
= ⎢⎣ 0
⎥⎦ 
· ⎢⎣ 1
4 ⎥⎦
3
27  
3
0
24 
Next,  subtract  the   ﬁrst   row  from  the  second  to  analogously   obtain 
⎡
⎡⎤
⎡⎤
⎤
⎢⎣ 
⎥⎦ 
= ⎢⎣ 
⎥⎦ 
· ⎢⎣ 
⎥⎦
Now  observe  that   the  matrices  used  for  elimination  combine  very  nicely: 
⎡
⎡⎤
⎡⎤
⎤
⎢⎣ 
· ⎢⎣ 
⎥⎦ 
= ⎢⎣ 
⎥⎦ 
⎥⎦

1 
4 
24 

1  
3  
24 

1 
1
3

1
0
0

1 
1 
6

1 
1
0

1 
1
0

1
0

1 
0

1 
0

1 

1 
0

1 

1 
0

1 

1 

1 

1
1
0

1 
0
3

therefore 

(8.29) 

(8.30) 

(8.31) 

(8.32) 

(8.33) 

28 

⎡
⎡⎤
⎤
⎡⎤
⎥⎦ 
⎢⎣ 
⎥⎦ 
= ⎢⎣ 
⎥⎦
· ⎢⎣ 
Then  continue  by  induction–subtract   6  times  the  second  row   from  the  third,  obtaining  the  de­
composition  

1 1 
0 1 
0 6

1 
1 1 
3 0

1  
4  
27 

1 
3 
24 

1
1
3

1 
2 
9

1 

(8.34)

⎡  1
⎢⎣ 0
0

1
1 
6 

⎡⎤
1 
1 
= ⎢⎣ 0 1
3 ⎥⎦ 
24 
0 6

⎤
⎡⎤
1 1 1 
· ⎢⎣ 0 1 3 ⎥⎦
⎥⎦ 
0 0 6 

1 

(8.35) 

Therefore 

1 

·

1 
1
3

1 
0

1
1
3

1 
2 
9 

1
0
0

(8.36)

⎡
⎢⎣ 

⎤
⎥⎦ 

1  
4  
27 

1 1 
1 3 
0 6 

⎡
= ⎢⎣ 
� 
= 

⎡⎤
⎤
⎡⎤
1 
⎥⎦ 
⎥⎦ 
· ⎢⎣ 
⎥⎦
· ⎢⎣ 
0 1 
0 6
1 
��  
� 
⎡  1 
⎤
⎡
⎤
1 1 1 
⎢⎣ 1 1
⎥⎦ 
⎢⎣ 0 1 3 ⎥⎦
3 6
0 0 6 
�⎡
�⎤
��  
⎡⎤  
⎤
⎡ 
1
1 1 
1 
1 3 ⎥⎦
· ⎢⎣
⎥⎦ 
· ⎢⎣
⎢⎣ 1 1
⎥⎦ 
1 
3 6
�� 
�� 
�  �  
� 
�  
�� 
� 
� 
U 
D
L
Algorithm:  [Gaussian  Elimination]  The  following  algorithm  computes  the  LDU  decomposition 
of  a   matrix   A  whose   leading  principal  minors   are  nonzero. 

(8.38)

(8.37)

1 

1 

1 

1

= 

6 

U  =  A,  L  =  I ,  D  =  I

for  i  =  1 : n  −  1

for  j  =  i  + 1 : n

l
j i  =  uj i /uii

uj,i:n  =  uj,i:n  −  lj iui,i:n 
endfor

dii  =  uii 
ui,i:n  =  ui,i:n /dii 
endfor


8.2  Pivoting,  Partial  and  Complete 

P1A  =  L1A1 

(8.39) 

8.3.  STABILITY  OF   GE 

P2A2  =  L2A2 

· · · 
A  =  P T 
1  L1A1 
=  P T 
1  L1P T 
2  L2A2 
2  L2P T 
1  L1P T 
=  P T 
3  L3U 
3  )(P3L2P T 
2  P T 
3  )−1L1P T 
2  P T 
3  ((P T 
2  P T 
1  P T 
=  P T 
3  )L3U 
=  P T 
1  P T 
2  P T 
3  L1L2L3U 
=  P T  LU  

Complete  pivoting:  two  sided 

Operation   count:  2 
3 n3  for  GENP   and  GEPP,  for  complete  pivoting 

A  =  P T  LU QT 

n 2  +  (n  − 1)2  +  · · ·  = 

= 

n(n  +  1)(2n  +  1) 
6 
n 3  additional 

2 
3 

8.3  Stability  of  GE 

Example: 

0  � �  10−16 
1 
0 

1 
1  − 1016 

� 

�  10−16 
1 

= 

A  =  LU  
1  � 
� 
1 
�A�  =  O(1) 
�L� ,  �U �  =  O(1016 ) 

1 
1016 

Ax  = 

b 

LU x  =  x 

Ly   = 

b 

U x  =  y 

b 

(L  +  δL) ˆy  = 
�δL� 
�L� 
�δL�  =  O(1) 

=  O(�) 

(U  +  δU ) ˆx  = 

y 

29  

(8.40) 

(8.41) 

(8.42) 

(8.43) 

(8.44) 

(8.45) 

(8.46) 

(8.47) 

(8.48) 

(8.49) 

(8.50) 

(8.51) 

(8.52) 

(8.53) 

(8.54) 

(8.55) 

30 

CHAPTER  8. 

=  O(�) 

�δU � 
�U � 
�δU �  =  O(1) 

(L  +  δL)(U  +  δU ) ˆx  = 
b 
A  +  δLU  +  U δL +  δLδU  =  O(1  · 1016  +  1  · 1016  +  1  · 1) 
� 
�� 
� 
δA 
�δA� 
�A� 

=  O(1016 ), 

=  O(1016 ) 

(8.56) 

(8.57) 

(8.58) 

(8.59) 

(8.60) 

while   we  expected  �. 
Theorem:  A:  nonsingular.  Let  A  =  LU  be  computed  by   GENP  in  ﬂoating  point arithmetic. If  A 
has   an  LU  factorization,  then  for  suﬃciently small  �machine ,  the  factorization  completes  successfully 
and  

where, 

for  some  δA  ∈ C n×n  .

Backward  Stability?

Need


then 

L ˜˜U  =  A +  δA 

�δA� 
�L� · �U �


=  O(�machine ) 

�δA� 
�A� 

=  O(�machine ) 

(8.61) 

(8.62) 

(8.63) 

backward  stability  ⇔ �L� · �U � =  O(�A�) 

? 

(8.64) 

�L�·�U �
Need   to  measure 
�A� 
No  pivoting:  unstable.

Partial  pivoting:


and   make  sure  it  is  O(�machine ). 

since 

�L�∞  ≤ n 

|lij | <  1 

so  the   question  moves  down  to  the  size  of 

�U �  max  |uij |
�
�A�  max  |aij | 

≡ ρ 

(8.65) 

(8.66) 

(8.67) 

where  ρ  is  called  growth  factor. 
Therefore, 

˜L ˜U  =  A +  δA 
�δA� 
�A� 

=  O(ρ�machine ) 

stable  if  ρ  =  O(1). 
Partial  Pivoting:  ρ  ≤  2n ,  attainable,  but  never  happens.  Usually  ≤  n 
Complete  Pivoting:  ρ  =  O(1),  but  cost  n4 
3 
,  same  as   QR. 
3

1 
2 .

31  

(8.68) 

(8.69) 

