Chapter  5


5.1  Least  Square  Problems  

Ax  =  b,  Am×n ,  m  ≥  n,  rank(A) =  n,  minimize  �Ax  −  b�2 . 
Minimized  ⇔  gradient  =  0: 

lim 
e→0 

2


= 

≤ 

≤ 

= 

lim  
e→0 

2
�Ax  −  b�2  = (Ax  −  b)T  (Ax  −  b) 
2 
eT  AT  Ae 
�Ae�2
lim 
e→0  �e�2

�e�2 
2
�A� �e�
�e� 
2
lim   �A� �e� 
e→0 
�� 
� 
� 
→0 
0 
(A(x  +  e) −  b)T  (A(x  +  e) −  b) −  (Ax  −  b)T  (Ax  −  b)
lim 
�e�2 
e→0 
eT  AT  Ae 
�e�2 
�� 
� 
=0 

2eT  (AT  Ax  −  AT  b) 
�e�2 

+  lim 
e→0 
� 

lim  
e→0 

0  = 

= 

= 

lim  
e→0 

2eT  (AT  Ax  −  AT  b) 
�e�2 

For  all  e  →  0: 

2

Te
�e�

(AT  Ax  −  AT  b)  =   0 

AT  Ax  =  AT  b 

14 

(5.1) 

(5.2) 

(5.3) 

(5.4)

(5.5) 

5.1.  LEAST  SQUARE  PROBLEMS 

15 

Why  does  x  = (AT  A)−1AT  b  minimize   �Ax  −  b�
Let  x�  =  x  +  e 

2
2 ?

(Ax �  −  b)T  (Ax �  −  b)  = (Ae  +  Ax  −  b)T  (Ae  +  Ax  −  b)  
= (Ae)T  Ae  +  (Ax  −  b)T  (Ax  −  b) +  2(Ae)T  (Ax  −  b)  
2
2
T  (AT  Ax  −  AT  b)
�Ae� +  �Ax  −  b� +  2e
2 
2 
2
2
�Ae� +  �Ax  −  b�
2
2 

= 

= 

Minimized  for   Ae  = 0. 
In  practice  we  never  solve  AT  Ax  =  AT  b  (called  normal  equations),  instead  we  solve: 

A  =  QR 
(QR)T  (QR)x  = (QR)T  b 
RT  Rx  =  RT  QT  b 
Rx  =  QT  b 
x  =  R−1QT  b 

(5.6) 

(5.7)


(5.8)


(5.9)


(5.10)


(5.11)


