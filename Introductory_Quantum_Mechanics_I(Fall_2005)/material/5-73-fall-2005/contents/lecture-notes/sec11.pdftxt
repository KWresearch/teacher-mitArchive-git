XI.  Identical Particles 
 

a. The Product Basis 

 
We have already dealt with multiple particles implicitly. For example, 
when we were doing inelastic scattering calculations, our basis states 
n;ψ .  
involved specifying the state of the electron and the molecule, 
Although we did not stress it at the time, these basis states are 
equivalent to products: a state for the electron times a state for the 
molecule: 

+

1
2

 

n

0

n

=

2

k
2

+

≡Ψ

+∇−=
2
1
2

ψψψψ
DCB
A

ψψψψ
A
B
C
D

n ψψ =
 
;
n
To verify this, we act on the right hand state with the zeroth order 
Hamiltonian: 
)
(
)
(
)
(
ˆ
ψ
ψ
ω
ψ
ω
ˆ
H
n
n
n
ˆH  as 
and we see that these are, indeed, eigenfunctions of 
0
advertised.  This is a general rule: one can conveniently build a many 
particle wavefunction that describes the state of particles A, B, C, 
D,… by considering a product of states for A, B, C, D,…  individually: 
 
=
 
 
 
where from here on out we will use capitol Greek letters to denote 
many particle states and lower case Greek letters when representing 
one-particle states. The particles A, B, C, D,… can be any set of 
distinct particles (e.g. A=H2O, B=He+, C= H2O+, D=He,…).  Then 
Aψ  would be a wavefunction that represents the state of the water 
Bψ  would represent the state of the He+, etc. 
molecule, 
 
What do these product states mean? To look at this question, lets 
assume the Hamiltonian can be decomposed into a Hamiltonian that 
acts just on A plus one for B plus one for C …: 
ˆ
ˆ
ˆ
ˆ
ˆ
=
+
+
+
+
 
...
hH
h
h
h
D
C
B

Single Particle ψ’s 

Many Particle ψ 

...

 

+

1
2

...

A

e

e

. 

...

This Hamiltonian describes independent particles (because it lacks 
coupling terms  ABhˆ
that depend on A and B simultaneously). Now, the 
eigenstates of this independent particle Hamiltonian can always be 
chosen to be product states, for which: 
(
)
ˆ
ˆ
ˆ
ˆ
ˆ
=Ψ
+
+
+
+
ψψψψ
h
h
h
H
h
...
A
A
B
C
D
D
C
B
)
(
ψψψψ
Ψ=
+
+
+
+
=
e
E
e
A
B
C
D
B
A
D
C
Thus, product states describe particles that are independent of, or 
uncorrelated with, one another.  One consequence of this fact is that 
a measurement on A will not affect the state of B and vice versa. For 
this reason, product states are also sometimes called “independent 
particle” states, which is appropriate since they describe the state of 
each particle independently. 
 
Note that just because product states happen to describe many 
particles, it does not follow that every many particle wavefunction can 
be written in this form.  In fact, it is easy to build a many particle 
wavefunction that is not of product form. For example: 
ψψψψ
ψψψψ
≡Ψ
+
 
c
c
C
A
B
A
B
C
D
D
2
1
1
1
2
2
2
2
1
1
2
cannot be written as a product of one particle wavefunctions. In 
particular, for this state, a measurement on A influences the outcome 
of measurements on B, C and D: if we find that A is in state 1, B,C 
and D must collapse to state 1, while A in state 2 implies B, C and D 
will collapse to state 2.  This strange correlation between different 
particles is called entanglement and plays a very important role in 
many-particle quantum mechanics. Meanwhile, the state 
(
)(
)(
)(
ψ
ψ
ψ
ψ
ψ
ψ
ψ
≡Ψ
+
+
+
c
c
c
c
'
c
c
c
C
1
2
1
2
1
2
1
1
1
1
1

ψ
2

+

c

D

C

B

B

A

A

2

)D

2

2

2

 
 
 
Particle A 
Particle B 
Particle C 
Particle D 
is of product form by construction, but if we expand it out, we find: 
4
ψψψψ
≡Ψ
'
1
1
A
B
1
C
1
D
ψψψψψψψψ
+


A
B
D
A
B
C
C
1
1
1
2
1
1
2
1

ψψψψψψψψ
+

A
B
C
D
A
B
C
1
1
1
2
1
1
1
2
(
)
2
...

3
cc
1






c
1

...

+

+

+

+

 

D

D

2

2
cc
1

2

This looks very complicated in the many particle space, and it clearly 
2Ψ  could not be written in product form: it lacks the 
points out why 
necessary cross terms!  The important property that distinguishes 
2Ψ  as describing independent particles is that measurements on A 
will not influence the state of B, C or D. 
 
'Ψ  looks very complicated in our many particle basis, 
Now, while 
this is really a symptom of the fact that we have chosen the wrong 
one particle basis for this product state.  If we instead define the 
basis functions 
ψ
ψ
ψ
+
=
'
1
2
A
ψ
ψ
ψ
=
+
c
c
'
C
C
1
C
1
2
2
'Ψ  takes the simple form 
ψψψψ=Ψ
. 
'
'
'
'
'
A
B
C
D
Thus, a change in our one particle basis states (e.g. from the 
ψψψ
A ψψ
 basis to the 
 basis) has a very 
,
...
,
,'
...
'
B
A
A
B
1
2
1
complicated effect on our many particle product space.  In general if 
we change our basis so that  
ψ
A

ψ
2
B
ψ
2

ψ
1
B
ψ
1

ψ
B
ψ
D

+
c
+

Then, 

=
=

ψ
iA

c
2

c
1

c
1

c
1

=

a

 

c

2

'

'

D

D

A

A

'

2

i

∑
i
∑
i

ψ
B

'

=

b
i

ψ
iB

 

then we can write 
 

...
'Ψ  in the new basis as: 

=Ψ
'

'

...

ψψψψ
'
'
'
C
A
B
D




∑
j

ψ
iA





a

i

j

b





ψ
jB




ψψψψ
...
iA
jB
kC
lD

∑
k

c
k

ψ
kC

...

=

=


∑


i
∑
...
ijkl

dcba
k
i
j

l

Coefficients 

 
 
 
 
 

Old Many-
Particle Basis 
function 









∑
l

d

l

ψ
lD



...


. 

New Many-
Particle Basis 
function 

'Ψ  is still a product state.  This is true in 
Note that in either basis, 
general; changing our one particle basis cannot turn a product state 
into a non-product state (or vice versa) – it only makes the structure 
of a given product state more or less simple. 
 
The most important thing about product states is that they form a 
complete many-particle basis.  Thus, assume we have complete 
iAψ , so that any one-particle wavefunction for A can be 
basis, 
written as a linear combination of the basis functions: 
ψ ∑=
a ψ
 
A
iA
i
i
and similarly for B, C, D,…. Then any many particle state for A, B, C, 
D… can be written as a linear combination of products of these basis 
functions: 

ijklC

...

. 

...

ψψψψ
iA
jB
kC
lD

∑=Ψ
...
ijkl
Note that in the case of a single particle transformation, the 
coefficients always decomposed as products; that is 
=
. 
...
...
dcba
C
kj
i
ijkl
l
Finally, we should stress that the many particle basis will be much 
bigger than the single particle basis.  For example, suppose we 
require 100 basis functions to make a “complete” basis (within 
numerical precision) for A and similarly for B,C and D. The number of 
4 particle basis states we can specify is the product of the numbers 
of single particle functions.  Hence the many particle basis will have 
100x100x100x100=100,000,000 basis functions!  Hence we 
immediately see the need for physical approximations for many-
particle systems. 

b. Symmetry Under Exchange 

 
Up to now, we have been dealing with several particles that are all of 
different character.  In many cases, we want to deal with the situation 
where some or all of the particles are identical (e.g. to describe the 
many electrons in an atom or molecule).  For simplicity, in what 
follows we will assume all the particles are identical; if there are 
several classes of identical particles (e.g. some electrons, some 
protons and some neutrons) one can always build an appropriate 

wavefunction as the product of a wavefunction for the electrons times 
a wavefunction for the protons times…. 
 
What do we mean when we say that particles are identical?  Notice 
that in order to keep track of the particles, I need to put labels on 
them: so, one of the electrons will be particle “1” and the other 
particle “2.”  If the particles are identical, these labels are completely 
arbitrary, and if I switch them it must not change any experimental 
observable.  Hence, if I swap “1” and “2”, I better get the same 
wavefunction back (up to, perhaps, a constant factor).   For two 
particles, I can put an equation to this by defining an operator, P , that 
permutes the two labels; for example if I have a product state: 
( )
( )
( )
( )1
ψψ
ψψ
=
 
2
1
2
P
1
2
1
2
( )j
iψ  indicates that the jth electron is in the ith state.  For 
where 
identical particles, we concluded that we must have 
Ψ=Ψ c
 
P
which means that the wavefunction for identical particles must be an 
1=2P
eigenstate of  P . Now, it is clear that 
 (i.e. if we switch the 
particles and then switch them back, we get the same state).  As a 
result, the eigenvalues of  P  must be  1±  and so for identical particles, 
we have the restriction that 

Ψ±=ΨP
 
The two signs relate to a wavefunction that is symmetric (+) or 
antisymmetric (-) with respect to the interchange of the particles. 
 
Now, there is a rather deep result, called the spin statistics theorem 
that proves two things: 
 

1)  All particles fall into two classes; Fermions, which are 
always antisymmetric under exchange and Bosons, which are  
always symmetric under exchange. 

 
 

2) Fermions always have half-integer spin (e.g. electrons, 
protons, He3, etc.).  Bosons always have integer spin (e.g. 
photons, He4,etc.). 
 
Proving this theorem is definitely beyond the scope of this course, so 
we will just take it as a given.  We will primarily be interested in 

electrons (Fermions) and photons (Bosons) in this course, but it is 
important to realize that composite particles (like a proton or a helium 
atom) also obey the spin statistics theorem. 
 
How do we construct functions that obey the appropriate exchange 
symmetry?  First, notice that product functions do not work because, 
as we showed above 
( )
( )
( )
( )
ψψ
ψψ
=
±≠
1
2
2
1
P
1
2
1
2
However, it is easy to see that the states 
(
1
( )
( )
ψψ
1
2
1
2

( )
ψψ
2
1
2

( )
ψψ
1
1
2

)1
( )

=Ψ

( )2

±

. 

 

2
have the proper symmetry, since 
(
1
( )
( )
ψψ
1
2
P
1
2

=Ψ

P

2

±

P

( )
ψψ
2
1
2

( )
1

)

=

1

(
( )
ψψ
2
1
2

( )
1

±

( )
ψψ
1
1
2

( )
2

)

Ψ±=

 

2
Hence, these states are the appropriate product basis functions for 
two identical particles.  We can generalize this concept to arbitrary 
numbers of particles as follows: for Fermions, we define the Slater 
Determinant by: 

ψψψ
j
i
k

...

=

1

N

!

ψ
i
ψ
j
ψ
k

( )
1
( )
1
( )
1
.

ψ
i
ψ
j
ψ
k

( )
2
( )
2
( )
2
.

ψ
i
ψ
j

( )
3
( )
3
.

.

.

.

.

 

.

.

.

.

.
.
.
It is easy to verify that this wavefunction is antisymmetric – permuting 
two of the ψ’s corresponds to interchanging two of the rows, which 
our linear algebra textbook tells us multiplies the whole Determinant 
by -1.  Further, we note no two of the ψ’s can be the same because 
this would make two of the rows equal, which would make the whole 
determinant zero.  This is the Pauli Exclusion Principle. 
   
The nice thing about determinants is that they play the same role for 
Fermions that product states play for distinguishable particles; they 
form a complete basis for the many-particle space.  Thus, if we have 

a complete one particle basis iφ  then any many particle function can 
be written 

...

 

ijklc

φφφφ
k
i
j
l

∑=Ψ
...
ijkl
In fact, because the particles are identical, we can always permute 
the indices in the determinant so that they are in increasing order 
without changing the physical state, which means we can write 
∑
=Ψ
φφφφ
 
ijklc
j
i
k
l
≤≤≤
...
lkj
i
Since we have the Pauli Exclusion principle, we can even go one 
step further and note that none of the indices can be equal, so 
∑
=Ψ
φφφφ
. 
i
j
k
l
<<<
lkj

ijklc

...

...

i

...

...

...

...

 
For Bosons, the appropriate many-particle basis functions are a bit 
more obtuse.  Intuitively, we can tell that the right state will look just 
like a Slater determinant, except that everywhere there is a minus 
sign in the former, we to replace it with a plus sign.  In order to 
accomplish this, what is typically done is to simply define an object (a 
“permanent”) that is just a determinant with plus signs.  We will 
denote this by 

. 

=Ψ

Nψψψ ...
1
2
+
Clearly, a permanent is symmetric, by construction.  However, note 
that it does not obey any kind of exclusion principle; one can put as 
many Bosons into a given state as you like.  As an example: 
ψψψ
ψψψ
=Ψ
=
 
...
...
1
1
1
1
1
1
+
is manifestly symmetric under exchange, and it describes a state 
where all the Bosons are piled into the same one particle state.  This 
is actually the wavefunction that describes a Bose-Einstein 
condensate. 
 
Similar to determinants, permanents form a complete many-particle 
basis.  So we can write any many-Boson wavefunction as 
∑=Ψ
φφφφ
. 
ijklc
k
i
j
l
+
≤≤≤
i
...
lkj
k =  kinds of terms in this 
i =  and 
Note that we must include the 
l
j
sum specifically because Bosons do not obey any exclusion principle. 
 

...

...

 

ˆ
H

=

ˆ
H

=

and 

Finally, we note that determinants and permanents share one other 
important feature in common with product states: the eigenfunctions 
of a Hamiltonian that describes many independent Fermions 
(Bosons) can always be written as a determinant (permanent).  To 
see this, we first note that because the particles are identical, the 
Hamiltonian for particle  i  must be the same as that for j . Thus, an 
independent particle  Hˆ for  N  identical particles must take the form: 
N
( )ih
∑
ˆ
=
i
1
where  ( )ihˆ
 is just the Hamiltonian for the ith particle and clearly each 
particle “feels” the same Hamiltonian.  Now, if we expand out the 
φφφ
state  
, we find a sum that contains the state 
...
i
j
k
±
( )
 plus (or minus) other states like ( )
( )
( )
( ) ...
φφφ
φφφ
1
3
2
1
2
j
j
k
i
k
i
( )
( )
( ) ...
φφφ
3
1
2
i
j
k
in a different order.  However, these are all eigenfunctions of our 
Hamiltonian with the same eigenvalue: 
)
(
( )
( )
( )
( )
( )
( )
( )
( )
2ˆ
...3ˆ
1ˆ
ˆ
φφφ
φφφ
=
+
+
H
h
h
h
...
2
1
2
1
3
i
j
k
i
j
k
)
(
( )
( )
( ) ...
=
+
+
φφφ
e
e
e
...
1
2
3
i
i
j
k
j
k
)
(
( )
( )
( )
( )
( )
( )
( )
( )
2ˆ
...3ˆ
1ˆ
φφφ
φφφ
+
=
+
h
h
h
1
2
3
2
1
i
k
i
j
k
j
)
(
( )
( )
( ) ...
++
φφφ
e
e
e
2
1
3
i
i
j
k
j
k
Thus, since a determinant or permanent is a sum of degenerate 
eigenstates of  Hˆ , we conclude that it is, itself, an eigenstate with the 
same eigenvalue: 
ˆ
φφφ
H
i
j
k

(
)
e
i
±
±
Hence, we see that determinants and permanents are the functional 
analogs of product states when we are dealing with many identical 
particles. 
 

 that involve the same one particle states, but 

φφφ
j
i
k

( ) ...
3

 

e
k

...

+

e

j

+

...

 

( )
3

...

( )
3

...

...

=

...

...

 

…. 

c. Two Electron Atoms 

 
As an application of the formalism we have just developed, we 
consider Helium-like atoms (i.e. He, Li+ …). Assuming the nucleus is 
infinitely massive, the Hamiltonian for the two electrons is given by 

ˆ
H

−∇−∇−=
2
2
1
1
2
1
2
2

Z

r
1

−

Z

r
2

+

1
r −
1

r
2

 

Kinetic Energy 

 
 
 
 
where “1” and “2” denote the two different electrons.  It is convenient 
to separate the parts Hamiltonian that depend only on particle “1” or 
“2”, independently: 
( )
1ˆ
h

Electron-Electron 
Repulsion 

Electron-Nuclear 
Attraction 

( )
2ˆ
h

−∇−=
2
1
2
2

−∇−≡
2
1
2
1

r
r
1
2
note that, as advertised, these operators are identical.  It is then 
conventional to then separate the Hamiltonian into a zeroth order part 
that describes the electrons moving independently in the field of the 
nucleus and a perturbation that consists of the electron-electron 
interaction: 

Z

Z

 

+

1

 

≡

0

=

≡

ˆ
H

ˆ
V
12

( )
1ˆ
h

( )
2ˆ
h

1
−
r
r
r
2
1
12
Note that the electron-electron repulsion is typically of the same order 
of magnitude as the independent particle energy, and so this will not 
generally be a good approximation.  However, it is convenient 
ˆH  and we can therefore do 
because we know the eigenstates of 
0
perturbation theory. 
 
In accordance with the previous section, we conclude that the 
ˆH  are determinants: 
eigenfunctions of 
0
(
)1
1
ψψψψ
−
1
2
2

2
The one electron functions in this expression are generically called 
orbitals.  First of all, we note that our orbitals certainly cannot neglect 
the spin of the electron; the Pauli exclusion principle tells us that we 
cannot have more than one electron in the same overall state, but we 
can effectively fit two electrons in each spatial orbital – one with spin 
“up” and one with spin “down”.  This is most easily dealt with by 
writing the determinant in terms of spin orbitals, which are products 
of a space part and a spin part, i.e. 
≡↑
s
1

=Ψ
)0(

s
1

↑

. 

. 

We will also use the shorthand notation 
ψψ
ψψ
≡
≡
↑

↓

. 

 
ˆH ; one merely puts two 
We can easily guess the ground state of 
0
electrons in the  s1  orbital.  We can write this wavefunction in three 
ways 

=Ψ
)0(

11
s
s
(

1
s

1

2

1

)

 

↑

=

=

11
s
s

−↓
↓
↑
1
1
1
s
s
s
)↑↓−↓↑
(
2
The first representation is the most economical and stresses that this 
is a determinant.  The last expression is interesting because it 
space Ψ
Ψ
factorizes into the form 
, which allows us to make several 
spin
observations.  First, note that for this case, this spin part is just the 
wavefunction for a singlet (S=0) state.  This is encouraging, because 
(in the absence of spin-orbit coupling) the true electronic states can 
always be chosen to be spin eigenfunctions because  [
] 0
ˆ,ˆ
2 =SH
. The 
fact that the zeroth order eigenfunction is also a spin eigenfunction 
therefore makes it a convenient starting point.  Second, we notice 
that the space part is symmetric and the spin part is antisymmetric, 
giving an overall antisymmetric state.  In general, the exchange 
symmetry of spin eigenfunctions is  (
) 11
+
− S
, so singlets have 
symmetric spatial parts, triplets have antisymmetric spatial parts… 
 
Now, this determinant should in no way be confused with the true 
ground state of the Hamiltonian; it is merely a convenient 
approximation that has the right symmetry properties (i.e. it is a 
singlet with no angular momentum,…) but completely neglects the 
interaction between the electrons.  To see how good or bad this state 
is, we compute its zero-order eigenvalue: 




−∇−+



2
2
−∇−=Ψ
)0(
1
1
2
2
1
2








)
Ψ−=↑↓−↓↑
2
Z



−+




↑↓−↓↑



−=


11
s
s

s
s
11

Z

r
2

ˆ
H

0

Z

r
1

2

Z

2

2

Z

2

1

2

(

1

2

(

)

 

Now, for Helium, this corresponds to an energy of -22 = -4 Eh =           
-108.8 eV, which compares to the experimental value of -78.86 eV! 
This is terrible! There are three primary ways to improve this result. 
 

1) Hartree-Fock 

 
The first approach still uses a single determinant state, but 
recognizes that the zeroth order orbitals will not generally be the 
optimal choice.  One realizes physically that each electron will not 
“see” the bare Coulomb field of the nucleus, but it will be “shielded” 
from the core because it will be repelled by the other electron.  This 
will of course cause some distortion of the wavefunction, even at the 
independent particle level.  In order to find the best possible one 
particle functions, we have to do a variational calculation that 
minimizes: 

 

1

=

ˆ
ψψψψ
H

)
ˆ
ψψψψ
H

)(
↓↑−↑↓↑↓−↓↑

(
2
ˆ
ψψψψ
=
H
where in the second line we have noted that overlap of the spin 
functions is 1.  To minimize this, we can expand the orbitals in a 
complete basis of, say, hydrogenic  eigenstates: 
ψ ∑=
ic φ
 
i
i
We can then write out the variational condition: 
ψ
∂
∂
*
c
i
ψψψψ

ψ
∂
∂
*
c
i
ψψψψ

ˆ
ψψψψ
H
ψψψψ

ˆ
ψψψ
H

ψ

ˆ
H

ψψ

0

=

=

+

∂
∂
*
c
i

−

ψ
∂
∂
*
c
i

−

ψ

. 

ψψψ

ˆ
ψψψψ
H
(
)
2
ψψψψ
ˆ
∂
ψ
ψψψψ
H
(
)2
∂
*
ψψψψ
c
i
1=ψψψψ
) and define the 

ψψ

) which allows us to simplify: 

We now enforce normalization (
ˆ
ψψψψ H
ψψψψ

energy (

=

E

0

=

ψ
∂
∂
*
c
i

ˆ
ψψψψ
+
H

ψ
∂
∂
*
c
i

ˆ
H

ψψ

−

ψ
∂
∂
*
c
i

ψψψψ
−
E

ψ
∂
∂
*
c
i

ψψ

E

ψ

ˆ
−
EH

ψψψ
+

ˆ
−
EH

ψψ

ψ
∂
∂
*
c
i
ψφ
i

=

=

ˆ
−
EH

+
φψψψ
i

ψ
∂
∂
*
c
i
ˆ
−
EH
ˆ,ˆ hh
1
2

ψψ
ˆV , so consider the first 
 and  12

=

We want to write this in terms of 
term on the right hand side: 
ˆ
ˆ
−
=
−
ψφ
ψφψψ
Eh
EH
i
1
i
ˆ
−
ψ
Eh
1

ˆ
ˆ
+
+
ψψψφψψψφψψ
h
V
i
i
12
2
ˆ
ˆ
+
+
ψψψφψψψφψφψ
h
V
i
i
i
12
2
(
)
∑
ˆ
ˆ
+
+
φψψφφφ
h
V
i
j
i
j
12
2
j
At this point we make two definitions.  First, we define an effective 
2ε , as the difference between the total energy 
energy for electron “2”, 
ˆh
ˆh : 
E −≡
ψψ
ε
and the average value of  1
.  Second, we define the 
1
2
Fock matrix as: 

ˆ
−
Eh
1

ψ

ψ

c
i

=

c

 

j

(
)
ˆ
ˆ
=
+
φψψφφφψ
h
V
i
j
i
j
12
2

F
ij

 

Hamiltonian for 
electron “2” by itself 

 
 
Repulsion of electron 
 
“2” by the average field 
 
from electron “1” 
)ψ ” to remind ourselves that this operator for 
We include the “ (
electron “2” depends implicitly upon the state of the other electron; 
electron “2” moves in the average field produced by electron “1” and 
vice versa.  If we write the second term in real space, this becomes 
more clear 

ˆ
φψψφ
V
12
i
j

=

(
( )
)
∫∫
ψφ
*
r
r
i
2
1

*

1

( )
φψ
r
j
1

(
)
3
3
rdrdr
2
1
2

=

r
12
(
)
(
(
)
)
∫
φ
φ
3
Vr
r
rdr
*
i
j
2
2
2
2
avg
where in the second line we have identified the average potential 
( )
2
ψ
r
1
r
12
which is literally the classical expression for the potential exerted by a 
( )
( ) 2
r ψρ =
.   
charge density 
r
1
1

3
rd
1

∫≡

Vavg

(
r
2

)

 

 

 
)ψijF
(
2ε  and 
 we can write 
In any case, in terms of 
(
)
∑
ˆ
−
=
−
εψ
ψψ
EH
c
2
j
j

ψφ
i

F
ij

c
i

 

−ˆ
φψ
ψψ
The second term in the variational equation (
) turns 
EHi
out to be identical to the first, because we have constrained the 
spatial wavefunctions for electrons “1” and “2” to be equal.  As a 
result, the full variational equation implies the above expression is 
zero, which is equivalent to the matrix equation 
(
)
εψ =⋅
 
F
c
c
where we have dropped the subscript “2” on ε because the 
equations for electrons “1” and “2” are identical.  These are known as 
the Hartree-Fock (HF) equations.  They determine the unknown  ic ’s 
that describe the optimal one particle orbitals, which take into 
account all of the screening effects discussed above.  It is clear from 
the matrix form that the correct  ic ’s are an eigenvector of the Fock 
(
)ψF
matrix 
, which describes the motion of each electron in the 
average (or mean) field produced by the other electron.  Solving 
these equations is complicated by the fact that  F  depends on the 
(
)ψF
 depends on the form of ψ.  In practice, this equation 
ic ’s, since 
must be solved iteratively; one guesses ψ (for example a 1s orbital) 
(
)ψF
and then computes 
, which is diagonalized to give a new set of 
ic ’s which are used to build a new ψ, which is then used to compute 
(
)ψF
a new 
, which is diagonalized to give a new set of  ic ’s….  These 
iterations are known as self-consistent field iterations, because one is 
looking for the orbital ψ that is consistent with (i.e. is an eigenstate 
(
)ψF
of) its own Fock matrix 
. 
 
For helium, HF results in a ground state energy of -77.8 eV, which is 
still too far away from the experimental result, but much better than 
the independent particle answer.  Time permitting, we will discuss 
Hartree-Fock theory in more detail later, but for now suffice it to say 
that the residual error results from the fact that our wavefunction still 
describes independent particles (albeit in modified orbitals).  In 
practice, the electrons are not independent because they repel one 
another. 
 

2) Perturbation Theory 

 
Another approach is to really apply the perturbation expansion we 
have set up; i.e. to use the zeroth order eigenfunction as our starting 
point and include corrections due to the electron-electron interaction 
ˆV .  If we want to 
that will look like first, second, third,… powers of  12
treat this interaction to first order, we need to compute: 
( )
11ˆ
1 =
 
11
Vss
ss
12

E

This is a fairly complicated 6 dimensional integral, but it can be 
evaluated, and the resulting first order correction is +5/2 Eh = 34 eV 
(note that the sign is positive, as it should be for electron repulsion). 
Thus, at first order the total energy is -108.8+34=-74.8 eV, which is 
worse than Hartree-Fock.  However, one can continue to second, 
third, fourth… orders to more closely approximate the experimental 
results.  For example, the second order correction looks like 
 

ˆ
1;1
Vss
12

;
nlm

1;1ˆ'
'
Vmln
'
ss
12

'

'
mln
'
+

E

n

nlm
;
+

Z

n

'

2

 

E

E

( ) ∑
=
2
nlm
'
'
mln
'
which can be numerically evaluated to give a second order correction 
of -3.8 eV. This yields an approximate ground state energy of             
-74.8-3.8=-78.6 eV, which is starting to look respectable. What we 
are doing physically when we do these calculations is accounting for 
the fact that the electrons are not independent but rather they tend 
to avoid each other to minimize the  Coulombic repulsion.  In practice, 
perturbation theory works quite well for the ground state of Helium-
like systems. 
 

3) Configuration Interaction 

 
There is one final deficiency of a single determinant as an 
approximate eigenstate; it sometimes lacks the proper symmetry 
possessed by the true eigenstate.  As an example, consider not the 
ground state but the first excited singlet state of a two electron atom.  
The independent particle eigenstate can be written
.  [Aside: 
ss21

note that 

ps21

 is technically degenerate with this state if we neglect 

the interaction, but we know that once the electron-electron repulsion 

is included the  s2  orbital will be less shielded than  p2  and so this will 
be the lower Hartree-Fock state.]  Now, this state is not a spin 
eigenfunction: 

1

s

)

1
s

 

2

s

+

21
ss

2

=

2

21
ss

=

2

s

1
s

1

=

−

21
ss

1
s

↑

2

s

2

s

↑

s
1

↑

s
1

↓

s
1

↓

2

s

↓

−↓

−↑

+↑

−↓

21
s

s

12
s
s

Ψ
spin

Ψ
spin

)
(
Ψ≠↑
space
2
In order to get a state that is a spin eigenfunction, we need to add two 
different determinants: 
(
)
(
1
1

↓
2
)
)(
(
Ψ=↑↓−↓↑
space
2
Likewise, in order to get a wavefunction that is an eigenfunction of the 
2ˆJ ) we will need to take a linear 
total angular momentum (
combination of different determinants as well.  In atomic 
spectroscopy, these determinants are called microstates and the 
correct linear combinations that make eigenfunctions are called 
macrostates.  In electronic structure theory, these determinants are 
called configurations and the process of obtaining the best linear 
combination of these determinants is called configuration 
interaction (CI).   
 
In practice, CI can be used not only to get the correct symmetry, but 
also the energy shift due to the Coulomb repulsions, in like manner to 
perturbation theory.  To do this, we use the complete expansion: 
mlnmln∑=Ψ
. 
C
mlnmln
;
1
11
22
2
222111
mln
111
mln
222
The problem of finding the optimal coefficients

mlnmlnC
222111
equivalent to finding the eigenvectors and eigenvalues of the matrix 
ˆ
≡
 
H
mlnmlnHmlnmln
'
'
;'
'
'
'
;
;
'
'
'
'
'
'
1
1
1
2
2
2
11
1
22
2
mlnmlnmlnmln
222111
11
1
2
22
By definition, this is an exact eigenfunction of  Hˆ .  However, even for 
this simple two electron problem, the difficulty of doing full CI 
calculations is apparent. 

is then 

