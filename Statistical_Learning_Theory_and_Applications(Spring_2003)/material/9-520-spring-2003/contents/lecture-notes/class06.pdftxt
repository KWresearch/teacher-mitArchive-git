Generalization Bounds and Stability
9.520 Class 06, 26 February 2003

Alex Rakhlin

Plan

(cid:15) Generalization Bounds
(cid:15) Stability
(cid:15) Generalization Bounds Using Stability

Algorithms

We de(cid:12)ne an algorithm A to be a mapping from a training
set S = fz1; : : : ; z‘g to a function fS . Here, zi (cid:17) (xi; yi).

Throughout the next several lectures, we assume that A is
deterministic, and that A does not depend on the ordering
of the points in the training set. These assumptions are
not very restrictive, but greatly simplify the math.

How can we measure \goodness" of fS ?

Risks

Recall that in Lecture 2 we’ve de(cid:12)ned the true (expected)
risk:

I [fS ] = IE(x;y) [V (fS (x); y)] = Z V (fS (x); y)d(cid:22)(x; y)
and the empirical risk:

IS [fS ] =

1
‘

‘
Xi=1

V (fS (xi); yi):

Note: the true and empirical risks are denoted in Bous-
quet & Elissee(cid:11) as R(A; S ) and ^R(A; S ), respectively, to
emphasize the algorithm that produced fS .

Note: the loss is sometimes written as c(f ; z) = V (f (x); y),
where z = (x; y).

Generalization Bounds

Our goal is to choose an algorithm A so that I [fS ] will be
small. This is di(cid:14)cult because we can’t measure I [fS ].

We can, however, measure IS [fS ]. A generalization bound
is a (probabilistic) bound on how big the defect

D[fS ] = I [fS ] (cid:0) IS [fS ]
If we can bound the defect and we can observe
can be.
that IS [fS ] is small, then I [fS ] must be small.

Note that this is consistency, as we’ve de(cid:12)ned in Lect. 2:
D[fS ] ! 0, as ‘ ! 1.

Properties of Generalization Bounds, I

What will a generalization bound depend on? A gener-
alization bound is a way of saying that the performance
of a function on the training set has to be similar to its
performance on future examples. For this reason, gener-
alization bounds are always probabilistic: they hold with
some (high) probability, to take into account the (low)
chance that you’ll see a very unrepresentative training set.

Properties of Generalization Bounds, I I

Generalization bounds depend on some measure of the size
of the hypothesis space we allow ourselves to choose from.
As the hypothesis space gets smaller, the generalization
bound will get tighter (but the empirical performance will
often go down). As the hypothesis space gets bigger, the
generalization bound will get looser.

The bound will depend on the number of samples we have.
In general, we would like the bounds to get tighter at least
as fast as 1p‘
.

Properties of Generalization Bounds, I I I

A good generalization bound will not depend on the prob-
ability distribution P from which the examples are drawn.
If it did, we couldn’t measure it, since P is unknown.

Generalization Bounds By Bounding the
Hypothesis Space

In 9.520, we discuss two di(cid:11)erent ways to obtain general-
ization bounds:

One way is to explicitly bound the size of the hypothesis
space H. For example, functions in an RKHS with jjf jj2
K (cid:20)
M form a bounded hypothesis space whose \size" can be
measured and used to obtain generalization bounds (recall
uGC classes of functions).

IPS   sup
f 2H jIS [f ] (cid:0) I [f ]j > (cid:15)! < (cid:14)
This approach will be discussed in future lectures.

Generalization Bounds By Stability

The other approach is to use stability of algorithms. Here,
the basic idea is that we bound how much the function
produced by an algorithm can change when we modify
the training set slightly.
In this class and the next class,
we will explain and develop this approach to generalization
bounds, and show that Tikhonov reguarization in an RKHS
exhibits the necessary stability.

Note that in this approach we are not concerned with
\good performance" of all functions, but only the one
produced by our algorithm:

IPS (jIS [fS ] (cid:0) I [fS ]j > (cid:15)) < (cid:14)

Uniform Stability

Given a training set S , we de(cid:12)ne S i;z to be the new training
set obtained when point i of S is replaced by the new point
z 2 Z . Given this de(cid:12)nition, we say that an algorithm A
has uniform stability (cid:12) (is (cid:12) -stable) if
8(S; z) 2 Z ‘+1; 8i; sup
u jc(fS ; u) (cid:0) c(fS i;z ; u)j (cid:20) (cid:12) :

An algorithm is (cid:12) -stable if, for any possible training set, we
can replace an arbitrary training point with any other pos-
sible training point, and the loss at any point will change
by no more than (cid:12) .

Uniform Stability Cont’d

Uniform stability is a strong requirement, because it ig-
nores the fact that the points are drawn from a probability
distribution. For uniform stability, the function still has
to change very little even when a very unlikely (\bad")
training set is drawn.

In general, the stability (cid:12) is a function of ‘, and should
perhaps be written (cid:12)‘.

Stability and Concentration Inequalities

Question: Given that an algorithm A has stability (cid:12) , how
can we get bounds on its performance?

Answer: Concentration Inequalities.
use McDiarmid’s Inequality.

In particular, we will

Concentration Inequalities show how a variable is concen-
trated around its mean.

Michel Talagrand:

A random variable that depends (in a \smooth" way) on
the in(cid:13)uence of many independent variables (but not too
much on any of them) is essentially constant.

McDiarmid’s Inequality

Given random variables v1; : : : ; v‘, and a function F : v ‘ ! IR
satisfying
jF (v1; : : : ; v‘) (cid:0) F (v1; : : : ; vi(cid:0)1; v 0i; vi+1; : : : ; v‘)j (cid:20) ci;
sup
v1;:::;v‘;v 0i
the following statement holds:
IP (jF (v1; : : : ; v‘) (cid:0) IES (F (v1; : : : ; v‘))j > (cid:15)) (cid:20) 2 exp  (cid:0)

2(cid:15)2
i ! :
P‘
i=1 c2

This is an example of the law of large numbers.

Example: Hoe(cid:11)ding’s Inequality

Suppose each vi 2 [a; b], and we de(cid:12)ne F (v1; : : : ; v‘) =
i=1 vi, the average of the vi. Then, ci = 1
1
‘ P‘
‘ (b (cid:0) a).
Applying McDiarmid’s Inequality, we have that
2(cid:15)2
i !
IP (jF (v) (cid:0) IE(F (v))j > (cid:15)) (cid:20) 2 exp  (cid:0)
P‘
i=1 c2
‘ (b (cid:0) a))2 1
= 2 exp 0
2(cid:15)2
@(cid:0)
A
i=1( 1
P‘
2‘(cid:15)2
(b (cid:0) a)2 ! :
= 2 exp  (cid:0)
We have easily recovered the famous \Hoe(cid:11)ding’s Inequal-
ity". (Of course, we did not prove McDiarmid’s Inequality.)

Generalization Bounds via McDiarmid’s
Inequality

We will use (cid:12) -stability to apply McDiarmid’s inequality to
the defect D[fS ] = I [fS ] (cid:0) IS [fS ]. To do this, we will need
two things:

1. the expectation of the defect (we can’t measure it, but
we can bound its expectation) and

2. a bound on how much the defect can change when we
replace a point.

In order to bound the deviation (the second quantity), we
require that there exist an upper bound M on the loss.

Bounding The Expectation of The Defect

IESD[fS ] = IES [IS [fS ] (cid:0) I [fS ]]
V (fS (xi); yi) (cid:0) V (fS (x); y)3
= IES;z 2
‘
1
Xi=1
4
5
‘
V (fS i;z (x); y) (cid:0) V (fS (x); y)3
= IES;z 2
‘
Xi=1
5
4
(cid:20) (cid:12)

1
‘

The second equality follows by exploiting the \symmetry"
of expectation: The expected value of a training set on
a training point doesn’t change when we \rename" the
points.

Bounding The Deviation of The Defect

jD[fS ] (cid:0) D[fS i;z ]j = jIS [fS ] (cid:0) I [fS ] (cid:0) IS i;z [fS i;z ] + I [fS i;z ]j
(cid:20) jI [fS ] (cid:0) I [fS i;z ]j + jIS [fS ] (cid:0) IS i;z [fS i;z ]j
1
‘ jV (fS (xi); yi) (cid:0) V (fS i;z (x); y)j
(cid:20) (cid:12) +
1
‘ Xj 6=i
+
jV (fS (xj ); yj ) (cid:0) V (fS i;z (xj ); yj )j
M
(cid:20) (cid:12) +
‘
M
= 2(cid:12) +
‘

+ (cid:12)

Applying McDiarmid’s Inequality

By McDiarmid’s Inequality, for any (cid:15),
‘ ))2 1
IP (jD[fS ] (cid:0) IED[fS ]j > (cid:15)) (cid:20) 2 exp 0
2(cid:15)2
@(cid:0)
A
i=1(2((cid:12) + M
P‘
= 2 exp 0
‘ )2 1
(cid:15)2
‘(cid:15)2
2(‘(cid:12) + M )2 !
= 2 exp  (cid:0)
@(cid:0)
A
2‘((cid:12) + M
Note that
IP(D[fS ] > (cid:12) + (cid:15)) = IP(D[fS ] (cid:0) IED[fS ] > (cid:15))
(cid:20) IP(jD[fS ] (cid:0) IED[fS ]j > (cid:15))

=

Hence,
IP(IS [fS ] (cid:0) I [fS ] > (cid:12) + (cid:15)) (cid:20) 2 exp  (cid:0)

‘(cid:15)2
2(‘(cid:12) + M )2 !

A Di(cid:11)erent Form Of The Bound

If we de(cid:12)ne

(cid:14) (cid:17) 2 exp  (cid:0)

‘(cid:15)2
2(‘(cid:12) + M )2 ! :

Solving for (cid:15) in terms of (cid:14) , we (cid:12)nd that
(cid:15) = (‘(cid:12) + M )s2 ln(2=(cid:14))
‘

:

By varying (cid:14) (and (cid:15)), we can say that for any (cid:14) 2 (0; 1),
with probability 1 (cid:0) (cid:14) ,
I [fS ] (cid:20) IS [fS ] + (cid:12) + (‘(cid:12) + M )s2 ln(2=(cid:14))
‘

:

Fast Convergence

Note that if (cid:12) = k
‘ for some k, we can restate our bounds
as

+ (cid:15)(cid:19) (cid:20) 2 exp  (cid:0)
k
P (cid:18)jI [fS ] (cid:0) IS [fS ]j (cid:21)
‘
and with probability 1 (cid:0) (cid:14) ,
k
‘

I [fS ] (cid:20) IS [fS ] +

‘(cid:15)2
2(k + M )2 ! ;

+ (2k + M )s2 ln(2=(cid:14))
‘

:

Fast Convergence, Cont’d

For the uniform stability approach we’ve described, (cid:12) = k
‘
(for some constant k) is \good enough". Obviously, the
best possible stability would be (cid:12) = 0 | the function
can’t change at all when you change the training set. An
algorithm that always picks the same function, regardless
of its training set, is maximally stable and has (cid:12) = 0. Using
(cid:12) = 0 in the last bound, with probability 1 (cid:0) (cid:14) ,
I [fS ] (cid:20) IS [fS ] + M s2 ln(2=(cid:14))
:
‘
The convergence is still O (cid:18) 1p‘(cid:19). So once (cid:12) = O( 1
‘ ), further
increases in stability don’t change the rate of convergence.

Other kinds of stabilities

Notation: c(f ; z) = V (f (x); y) for z = (x; y). 8(cid:14) means \for all except
a set of measure (cid:14) .

An algorithm A : Z ‘ ! F is
uniformly (cid:12) hypothesis stable:
8i; (S; u) 2 Z ‘+1; sup
z2Z fjc(fS ; z) (cid:0) c(fS i;u ; z)jg (cid:20) (cid:12) :
((cid:12) ; (cid:14)) leave-one-out stable:
8(cid:14)S; 8i; (cid:12)(cid:12)(cid:12)
c(fS ; zi) (cid:0) c(fS i ; zi)(cid:12)(cid:12)(cid:12) (cid:20) (cid:12) :
((cid:12) ; (cid:14)) error stable:
I [fS ] (cid:0) I [fS i;u ](cid:12)(cid:12)(cid:12) (cid:20) (cid:12) :
8(cid:14) (S; u); 8i; (cid:12)(cid:12)(cid:12)
((cid:12) ; (cid:14)) cross-validation stable:
c(fS ; u) (cid:0) c(fS i;u ; u)(cid:12)(cid:12)(cid:12) (cid:20) (cid:12) :
(cid:12)(cid:12)(cid:12)
8(cid:14)S 2 Z ‘; 8i; u 2 Z ;

Thoughts on stability and open questions

Stability is a new research area { many things to be done.

The \right" de(cid:12)nition of stability is still an open question.

Good generalization bounds can be proved for speci(cid:12)c al-
gorithms if certain types of stabilities can be shown.

There might be a way to apply other concentration in-
equalities to get O (cid:16) 1
‘ (cid:17) convergence.

Summary

We used McDiarmid’s inequality to prove a generalization
bound for a uniformly (cid:12) -stable algorithm. Note that this
bound cannot tell us that the expected error will be low
a priori, it can only tell us that with high probability, the
expected error will be close to the empirical error. We have
to actually observe a low empirical error to conclude that
we have a low expected error.

Uniform stability of O (cid:16) 1
‘ (cid:17) seems to be a strong require-
ment. Next time, we will show that Tikhonov regulariza-
tion possesses this property.

