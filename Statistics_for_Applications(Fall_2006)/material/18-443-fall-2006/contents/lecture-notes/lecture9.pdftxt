Section  8 

Testing  simple  hypotheses.  Bayes 
decision  rules. 

 

H1  :  P = P1

H2  :  P = P2

.
. . 
Hk  :  P = Pk . 

Let us consider an i.i.d. sample X1 , . . . , Xn  ≤ X  with unknown distribution P on X . Suppose 
that  the  distribution  P  belongs  to  a  set  of  k  speciﬁed  distributions,  P ≤ {P1 , . . . , Pk }.  Then, 
given  a  sample  X,  . . . , Xn  we  have  to  decide  among  k  simple  hypotheses: 
 
�
⎧⎧⎧�
⎧⎧⎧�
In  other  words,  we  need  to  construct  a  decision  rule 
α  : X n  � {H1 , . . . , Hk }. 
Let  us  note  that  sometimes  this  function  α  will  be  random  because when  several  hypotheses 
are ’equally likely’ it will make sense to pick among them randomly. This idea of a randomized 
decision  rule  will  be  explained  more  precisely  in  the  following  lectures,  but  for  now  we  will 
simply  think  of  α  as  a  function  of  the  sample. 
Suppose  that the ith hypothesis  is true,  i.e. P = Pi . Then  the probability  that a decision 
rule  α  will  make  an  error  is 

P(α = Hi Hi ) = Pi (α = Hi ),
|
which is called the error of type i or type i error. When k = 2, i.e. we consider two hypotheses 
H1  and H2 ,  the  error  of  type  1 

�1  = P1 (α = H1 )
is  also  called  the  size  or  level  of  signiﬁcance  of  the  decision  rule  α  and 
�  = 1 − �2  = 1 − P2 (α =∞ H2 ) = P2 (α = H2 ) 
is  called  the  power  of  α . 
In  order  to  construct  a  good  decision  rule,  we  need  to  decide  how  to  compare  decision 
rules.  Ideally,  we  would  like  to  make  the  errors  of  all  types  as  small  as  possible.  However, 

51




∞
∞
∞
typically  there  is  a  trade-oﬀ  among  errors  and  it  is  impossible  to minimize  them  simultane­
ously. A  decision  rule  α  will  create  a partition  of  space  X n  into  k  disjoint  subsets A1 , . . . , Ak 
such  that 
α (X1 , . . . , Xn ) = Hj 
if  and  only  if  (X1 , . . . , Xn ) ≤ Aj . 
Increasing  a  set  Aj  will  decrease  the  error  of  type  j  since 

c ) = 1 − P(Aj ) 
�j  = P(Aj
and,  therefore,  in  this  sense  k  simple  hypotheses  compete  with  each  other.  Of  course,  it  is 
possible  to  give  an  example  in  which  all  errors  are  zero.  For  example,  if  all  distributions 
P1 , . . . , Pk  concentrate on disjoint  subsets  of X  then one observation  is enough to predict  the 
correct  hypothesis  with  no  error. 
One  way  to  compare  decision  rules  would  be  to  assign  weights  � (1), . . . , � (k)  to  the 
hypotheses  and  consider  a  weighted  error 

� (1)�1  + . . . � (k)�k  = � (1)P(α = H1 H1 ) + . . . + � (k)P(α = Hk Hk ).
|
|
In  the  next  section  we  will  construct  decision  rules  that minimize  this  weighted  error. 
In  the  case  of  two  simple  hypotheses  H1  and H2  it  is more  common  to  construct  ’good’ 
decision  rules  based  on  a  diﬀerent  criterion.  Before  we  describe  this  criterion,  let  us  ﬁrst  see 
that  in many  practical  problems  diﬀerent  types  of  errors  have  very  diﬀerent  meanings. 
Example.  Suppose  that  a  medical  test  is  done  to  determine  if  a  patient  is  sick.  Then 
based  on  the  data  from  the  test  we  have  to  decide  between  two  hypotheses: 

H1  :  positive; H2  :  negative. 

Then  the  error  of  type  one  P(α  = H2 H1 )  means  that  we  determine  that  the  patient  is  sick 
|
when  he  is  not  and  the  error  of  type  two  P(α  =  H1 H2 )  means  that  we  determine  that  a 
|
patient  is  not  sick  when  he  is. Clearly,  these  errors  are  of  a very  diﬀerent  nature.  In  the ﬁrst 
case  a  patient  will  not  get  a  necessary  treatment.  In  the  second  case  a  patient  might  get 
unnecessary  and potentially harmful  treatment. However,  in the  second  case additional  tests 
can be done whereas  in  the ﬁrst case the  sickness may be completely  overlooked. This means 
that  it may  be more  important  to  control  the  error  of  type  1  in  this  case. 
Example.  Radar  missile  detection/recognition.  Suppose  that  based  on  a  radar  image 
we  decide  between  a missile  and  a  passenger  plane: 

H1  :  missile, H2  :  not missile. 

Then  the  error  of  type  one  P(α  = H2 H1 ),  means  that  we  will  ignore  a  missile  and  error  of 
|
type  two  P(α  = H2 H1 ),  means  that  we  will  possibly  shoot  down  a  passenger  plane  (which 
|
happened  before).  It  depends  on  the  situation  to  decide  which  error  is  more  important  to 
control. 
Another  example  could be when  ’guilty’  or  ’not  guilty’ verdict  in  court  is decided  based 
on  some  data. Presumption  of  innocence means  that  ’no  guilty’  hypothesis  is  a more  impor­
tant nul l  hypothesis  and  the  error  of  type P(’guilty’ ’not  guilty’)  should  be  controlled. When 
|

52 


∞
∞
a  drug  company  comes  up  with  a  new  drug,  it  is  their  responsibility  to  prove  that  a  drug 
works signiﬁcantly better than a sugar pill, so a ’more important’ null hypothesis  in this case 
is  that  a  drug  does  not  work  better. 
These  examples  illustrate  that  in  many  situations  a  particular  hypothesis  is  more  im­
portant  in  a  sense  that  the  error  corresponding  to  this  hypothesis  should  be  controlled.  We 
will  assume  that  H1  is  this  hypothesis.  Let  �  ≤  [0, 1]  be  the  largest  possible  error  of  type 
one  that  we  are  willing  to  accept,  which  means  that  we  will  only  consider  decision  rules  in 
the  class 

K�  = {α  : �1  = P1 (α =∞ H1 ) � �}. 
It now makes  sense  that among all decision  rules  in this class we  should try to ﬁnd a decision 
rule  that  makes  the  error  of  type  two,  �2  = P2 (α  = H2 ),  as  small  as  possible.  We  will  show 
how  to  construct  such  decision  rules  in  the  following  lectures  but,  ﬁrst,  we  will  construct 
decision  rules  that minimize  the  weighted  error. 
Bayes  decision  rules. 
Given  hypotheses  H1 , . . . , Hk  let  us  consider  k  nonnegative  weights  � (1), . . . , � (k)  that 
add  up  to  one  �k
i=1  � (i) = 1.  We  can  think  of  weights  �  as  a  priori  probability  on  the  set 
of k  hypotheses  that  represent  their  relative  importance.  Then  the Bayes  error  of  a decision 
rule  α  is  deﬁned  as 
k 
k
�
�
i=1 
i=1 
which  is simply a weighted error. We would  like  to make the Bayes error as small as possible. 

 
� (i)Pi (α = Hi ),

 
� (i)�i  = 

�(� ) = 

Deﬁnition:  Decision  rule  α  that  minimizes  �(� )  is  cal led  a  Bayes  decision  rule. 
Next  theorem  constructs  Bayes  decision  rules  in  terms  of  p.d.f.  or  p.f.  of  P i , 1 � i � k . 
Theorem.  Assume  that  each  distribution  Pi  has  p.d.f  or  p.f.  fi (x).  A  decision  rule  α 
that  predicts  Hj  when 

� (j )fj (X1 ) . . . fj (Xn ) =  max  � (i)fi (X1 ) . . . fi (Xn ) 
1�i�k 

is  a  Bayes  decision  rule. 
In other words, we choose hypotheses Hj  if it maximizes the weighted likelihood function 

� (i)fi(X1 ) . . . fi (Xn) 

among all hypotheses.  If  this maximum  is  achieved  simultaneously  on  several  hypotheses  we 
can  pick  any  one  of  them,  or  at  random. 
Proof.  Let  us  rewrite  the  Bayes  error  as  follows: 
k 
�
i=1 
k
�
i=1 

� (i)Pi(α = Hi )
⎩
� (i) 

I (α = Hi )fi (x1 ) . . . fi (xn )dx1  . . . dxn

�(� ) = 

= 

53 





∞
∞
∞


∞
= 

= 

 
 
k
⎩
�
⎪
�
� (i)fi (x1 ) . . . fi (xn ) 1 − I (α = Hi )  dx1  . . . dxn 
i=1 
k
⎩
�
fi (x1 ) . . . fi (xn )dx1  . . . dxn 
� (i) 
i=1
�
��
⎨
this  joint  density  integrates  to  1  and �
k
⎩
�
� (i)fi (x1 ) . . . fi (xn )I (α = Hi )dx1  . . . dxn 
− 
i=1 
k 
⎩
�
= 1 − 
i=1 
To  minimize  this  Bayes  error  we  need  to  maximize  this  last  integral,  but  we  can  actually 
maximize  the  sum  inside  the  integral 

� (i)fi (x1 ) . . . fi (xn )I (α = Hi )dx1  . . . dxn . 

 
� (i) = 1 

� (1)f1 (x1 ) . . . f1 (xn )I (α = H1 ) + . . . + � (k)fk (x1 ) . . . fk (xn )I (α = Hk ) 

by  choosing  α  appropriately.  For  each  (x1 , . . . , xn )  decision  rule  α  picks  only  one  hypothesis 
which  means  that  only  one  term  in  this  sum  will  be  non  zero,  because  if  α  picks  Hj  then 
only  one  indicator  I (α = Hj )  will  be  non  zero  and  the  sum  will  be  equal  to 

� (j )fj (x1 ) . . . fj (xn ). 

Therefore,  to maximize  the  integral α  should  simply  pick  the hypothesis  that maximizes  this 
expression,  exactly  as  in  the  statement  of  the  Theorem.  This  ﬁnishes  the  proof. 

Let  us  write  down  a  Bayes  decision  rule  in  the  case  of  two  simple  hypotheses  H1 , H2 . 
For  simplicity  of  notations,  given  a  sample  X  = (X1 , . . . , Xn )  we  will  denote  the  joint  p.d.f. 
or  p.f.  by 

fi (X ) = fi (X1 ) . . . fi (Xn ). 
Then  the  Bayes  decision  rule  that minimizes  the  weighted  error 

� = � (1)P1 (α = H1 ) + � (2)P2(α = H2 )

is  given  by


Equivalently,


 
�
� (1)f1 (X ) > � (2)f2 (X ) 
H1  : 
 
�
α =  H2  : 
� (2)f2 (X ) > � (1)f1 (X ) 
H1  or H2  :  � (1)f1 (X ) = � (2)f2 (X ). 
�
α =
 �
⎧⎧�
⎧⎧�

f1 (X ) 
� (2)
f2 (X )  >  � (1) 
f1 (X )  <  � (2) 
f2 (X ) 
� (1) 
f1 (X )  =  � (2) .
f2 (X ) 
� (1) 

H1  : 
H2  : 
H1  or H2  : 

 
 

54 

(8.0.1)


























∞
∞


0  +�,  0
(Here  1
= 
1  =  0.)  This  type  of  test  is  often  called  a  likelihood  ratio  test  because  it  is 
expressed  in  terms  of  the  ratio  f1 (X )/f2 (X )  of  likelihood  functions. 
Example.  Suppose  we  have  one  observation X1  and  two  simple  hypotheses 

H1  : P = N (0, 1)  and  H2  : P = N (1, 1). 

Take  equal  weights 

1
2
Then  a  Bayes  decision  rule  α  that minimizes 

� (1) = 

and  � (2) = 

1 
. 
2 

is  given  by


1 
1
P1 (α = H1 ) +  P2 (α = H2 )
2 
2 
α (X1 ) = �
f1 (X )
f2 (X )  > 1 
⎧⎧�
f1 (X )  < 1
f2 (X ) 
⎧⎧�
f1 (X )
= 1.

f2 (X ) 
This decision  rule has a very  intuitive  interpretation.  If we  look at the graphs of these p.d.f.s 
(ﬁgure  8.1)  the decision  rule picks  the ﬁrst hypothesis  when  the ﬁrst p.d.f.  is  larger, x � 0.5, 
and  otherwise  picks  the  second  hypothesis,  x > 0.5 

H1  : 
H2  : 
H1  or H2  : 

 
 

0.6 

0.5 

0.4 

0.3 

0.2 

0.1 

PSfrag replacements

f1 (x) 

f2 (x) 

0 
−4 

−3 

−2 

−1 

0 

1 
H1H2 

2 

3 

4 

Figure  8.1:  Bayes  decision  rule. 

55 

∞
∞


Example.  Let  us  a  general  example  case  of  n  observations  X  = (X1 , . . . , Xn ),  two 
simple  hypotheses  H1  :  P  =  N (0, 1)  and  H2  :  P  =  N (1, 1),  and  arbitrary  a  priori  weights 
� (1), � (2). Then Bayes decision rule is given by (8.0.1). The likelihood ratio can be simpliﬁed: 
 
1 
1 
2 �
i=1 (Xi−1)2 
e− 1
e− 1
2  Pn
2  Pn
i=1 Xi 
(→2ξ )n 
(→2ξ )n 
=  e 1  Pn  ((Xi −1)2−X 2 )  = e n 
2 −Pn 
2 
i=1
i=1
i

f1 (X )
f2 (X )

= 

. 

Xi

e n 
2 −P

 
Xi  >

� (2) 
� (1) 

Therefore,  the  decision  rule  picks  the  ﬁrst  hypothesis  H1  when 
 
or,  equivalently,  �
Xi  <
Similarly,  we  pick  the  second  hypothesis  H2  when 
 
n
�
2  − log 
Xi  > 
In  case  of  equality,  we  pick  either  H1  or H2 . 

� (2)
. 
� (1) 

n 
2  − log 

� (2) 
. 
� (1) 

56


