18.335  Problem  Set  2 

Problem  1:  Floating-point 
(a) Trefethen, probem 13.2.  (For part c, you 
can use Matlab, which employs IEEE double 
precision by default.) 

(b) A generalization of Trefethen, problem 14.2: 
given a function g(x)  that is analytic (i.e., 
has a Taylor series) for |x| suﬃciently small, 
and g � (0)  �= 0, show that g(O(�))  =  g(0) + 
g � (0)O(�). 

Problem  2:  Addition 
volved in summing n�numbers, i.e. in computing 
This problem is about the ﬂoating-point error in­
=1 xi  for x ∈ Fn  (F being 
n 
the function f (x) = 
i
the set of ﬂoating-point numbers), where the sum 
is done in the most obvious way, in sequence. In 
pseudocode: 

sum  =  0

for  i  =  1  to  n

sum  =  sum  +  xi

f (x)  =  sum


For analysis, it is a bit more convenient to deﬁne 
the process inductively: 

s0	 = 0 
sk	 =  sk−1  + xk  for 0 < k ≤ n, 

with f (x) =  sn .  When we implement this in 
ﬂoating-point, we get the function f˜(x) =  s˜n , 
where s˜k  = ˜sk−1 ⊕xk , with ⊕ denoting (correctly 
(a) Show that f˜(x) = (x1 + x2 ) � (1 + �k ) + 
rounded) ﬂoating-point addition. 
�
�	
n
k=2
n 
n
k=i (1 + �k ), where the numbers �k 
i=3 xi
�
satisfy |�k | ≤ �machine . 
|
n 
=i (1+ �k ) = 1+ δi  where δi
(b) Show that  k
(n − i + 1)�machine + O(�2 
machine ). 
�
(c) Show  that  the  error  can  be  bounded  as: 
|f˜(x)  −  f (x)| ≤  n�machine 
i=1  |xi |  + 
n 
machine ). 
O(�2 

| ≤ 

(d) Suppose	 that  the  �k  values  are 
uniformly 
distributed 
in 
randomly 
i=1  |xi | � 
|f˜(x) − f (x)|  =  O �√
[−�machine , +�machine ]. 
�
Show  that 
the  mean  error  can  be  bounded  by 
n 
. 
n�machine 
(Hint:  google  “random  walk”...you  can 
just  quote  standard  statistical  results  for 
random walks, no need to copy the proofs.) 

(e) Compare  your	 error  bounds  above  to 
numerical  experiments  in Matlab.  Here, 
we will  use  an  old  trick  to  compute  the 
ﬂoating-point errors:  compare the results 
computed  in one precision to the  “exact” 
results  computed  in  a  higher  precision. 
In  particular,  we  will  use  the  Matlab 
single()  function to accumulate the sum 
|f˜(x) − f (x)|/ �  |xi | as a function of n on a 
in  single  precision,  rather  than  Matlab’s 
default  double  precision.  Plot  the  error 
i 
log-log scale (Matlab’s loglog  command), 
and explain your observation  in  terms of 
your results above.1 

This  is  implemented  in  the  example 
ﬁle loopsum.m, posted on the course page, 
which computes the sum f (x) =loopsum(x) 
via the above algorithm in single precision. 
For  your  numerical  experiment,  compute 
the sum of n  random  inputs x  ∈  [0, 1)n 
then compute |f˜(x)  −  f (x)|/ �  |xi |  for a 
via Matlab’s rand(1,n)  function. You can 
i 
given n  via 

x  =  rand(1,n); 
err  =  abs(loopsum(x)  - sum(x))  / 
sum(abs(x)); 

�
Problem  3:  Addition,  another  way 
n 
Here you will analyze f (x) = 
=1 xi  as in prob­
i
lem 2, but this time you will compute f˜(x)  in a 
diﬀerent way.  In particular, compute f˜(x)  by 
a recursive divide-and-conquer approach, recur­
sively dividing the set of values to be summed in 

1Use  enough  n  values  to  get  a  clear  result.  e.g.  the 
command  n  =  round(logspace(2,6,100))  gives  100  log­
arithmically  spaced  n  values  from  102  to  106 . 

1 

function of n  as in problem 2.  Are your 
results consistent with your error estimates 
above? 
(e) Suppose we now multiply two m × m  ran-
dom matrices A  and B  (∈  [0, 1)m×m , uni­
formly distributed) to form C  = AB . If you 
look at any given entry cij  of C , how quickly 
do you expect the errors to grow with m  if 
you compute AB  via the simple 3-loop row­
column algorithm? What if you use the op­
timal cache-oblivious algorithm from class? 

Problem  4:  Stability 
(a) Trefethen, exercise 15.1.  [In parts (e) and 
!  can  be  computed  to 
(f ),  assume  that  k
1
O(�machine )  and concentrate on the accu­
mulation of errors in the summations.] 

(b) Trefethen, exercise 16.1. 

f˜(x) = 

⎧ ⎪⎨ ⎪⎩ 
two halves and then summing the halves: 
if n = 0 
0 
if n = 1  , 
x1	
f˜(x1:�n/2� ) ⊕ f˜(x�n/2�+1:n ) 
if n > 1 
where �y�  denotes the greatest integer ≤  y  (i.e. 
y  rounded down). In exact arithmetic, this com­
putes f (x)  exactly, but in ﬂoating-point arith­
metic this will have very diﬀerent error charac­
teristics than the simple loop-based summation 
in problem 2. 

(a) For simplicity,  assume n  is a power of 2 
(so that the set of numbers to add divides 
evenly in two at each stage of the recur­
�
sion).  With  an  analysis  similar  to  that 
|
−
f (x)| ≤ 
f˜(x
of problem 2, prove that 
)
i=1  |xi |
n 
machine ).
�machine log2 (n) 
+ 
(�
2 
O
That  is,  show  that  the  worst-case  error 
bound grows logarithmical ly  rather than lin­
early  with n! 

(b) If the ﬂoating-point rounding errors are ran­
domly distributed as in problem 2, estimate 
the average-case error bound. 

(c) Pete R. Stunt, a Microsoft employee, com­
plains, “While doing this kind of recursion 
may have nice error characteristics in the­
ory, it is ridiculous in the real world because 
it will be insanely slow—I’m proud of my 
eﬃcient software and can’t aﬀord to have 
a function-call overhead for every number I 
want to add!”  Explain to Pete how to im­
plement a slight variation of this algorithm 
with  the  same  logarithmic  error  bounds 
(possibly with a worse constant factor) but 
roughly the same performance as a simple 
loop (hint:  look at how I implemented re­
cursive matrix multiplication in my cache­
oblivious handout from lecture 3).2 

(d) On  the	 course  web  page,  I’ve  posted 
a 
computes 
that 
div2sum.m 
ﬁle 
f˜(x) =div2sum(x)  by  the  above  algo­
rithm.  Modify it to not be horrendously 
slow via your suggestion in (c), and then 
plot  its  errors  for  random  inputs  as  a 

2 In  fact,  there  is  a  common  real-world  algorithm  that 
does  summation  in  precisely  this  recursive  way:  the 
Cooley-Tukey  fast  Fourier  transform. 

2 

MIT OpenCourseWare
http://ocw.mit.edu 

18.335J / 6.337J Introduction to Numerical Methods

 
Fal l 2010 
 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

