Lecture 15

The QR Algorithm I 


MIT 18.335J / 6.337J


Introduction to Numerical Methods


Per-Olof Persson


October 31, 2006


1


Real Symmetric Matrices


•	 We will only consider eigenvalue problems for real symmetric matrices 
, x  = xT , and �x� = √xT x 
Rm 
Rm×m 
•  Then A  = AT  ∈
∗ 
, x  ∈
A then also has 
• 

real eigenvalues: λ1 , . . . , λm 
or thonormal eigenvectors:  q1 , . . . , qm 

•	 Eigenvectors are normalized �qj � = 1, and sometimes the eigenvalues 
are ordered in a par ticular way 

•	 Initial reduction to tridiagonal form assumed 
	 Brings cost for typical steps down from O(m3 ) to O(m) 

2


–
Rayleigh Quotient


•	 The Rayleigh quotient  of x  ∈ Rm : 
r(x) = 

xT Ax 
xT x 
•	 For an eigenvector x, the corresponding eigenvalue is r(x) = λ 
•	 For general x, r(x) = α that minimizes �Ax − αx�2 
x  eigenvector of A ⇐⇒ ∇r(x) = 0 with x  = 0 
•	
•	 r(x) is smooth and ∇r(qj ) = 0, therefore quadratically accurate: 
r(x) − r(qJ ) = O(�x  − qJ � 2 )  as x  → qJ 

3 

�
Power Iteration 

Simple power iteration for largest eigenvalue: 

Algorithm: Power Iteration 

v (0)  = some vector with �v (0)� = 1 
for k  = 1, 2, . . . 
w  = Av (k−1) 
v (k)  = w/�w� 
λ(k)  = (v (k) )T Av (k) 

Termination conditions usually omitted 

• 

• 

4


apply A 

normalize 

Rayleigh quotient 

Convergence of Power Iteration


Expand initial v (0)  in or thonormal eigenvectors qi , and apply Ak :

• 

· · · 

, 

1

•	

+ amqm

v (0)	 = a1q1  + a2q2  +
v (k)	 = ckAk v (0)

= ck (a1λk 
k q2  +
k  qm )

+ amλm
1 q1  + a2λ2
· · · 
k (a1q1  + a2 (λ2/λ1 )k q2  +
+ am (λm/λ1 )k qm )
= ck λ1
· · · 
T v (0)  = 0, this gives: 
λm ≥ 0	 and q1 
If  λ1 > λ2
| ≥ · · · ≥  |
|
|
|
|
 
 
(cid:12)k	
(cid:12)2k 
 
!
 
!
 
 
(cid:12)
(cid:12)
λ
 
 
2 
2 
�v (k)  − (±q1 )� = O 
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)
(cid:12)(cid:12)
(cid:12)
(cid:12)
λ
•  Finds the largest eigenvalue (unless eigenvector or thogonal to v (0) ) 
•  Linear convergence, factor ≈ λ2/λ1  at each iteration 
5 

|λ(k)  − λ1 | = O 

 
λ
 
λ

1

 

	
�
Inverse Iteration 

• 

Apply power iteration on (A − µI )−1 , with eigenvalues (λj  − µ)−1 
Algorithm:  Inverse Iteration 

v (0)	 = some vector with �v (0)� = 1 
for k	 = 1, 2, . . . 
Solve (A − µI )w   = v (k−1)  for w 
v (k)  = w/�w� 
λ(k)  = (v (k) )T Av (k) 

apply (A − µI )−1 
normalize 

Rayleigh quotient 

• 
�v (k)  − (±qj )� = O 

Converges to eigenvector qJ  if the parameter µ is close to λJ :
 
 
(cid:12)2k 
(cid:12)k	
 
!
 
!
 µ − λJ  (cid:12)
 
 µ −	 λJ  (cid:12)
(cid:12)
(cid:12)
 
 
 
 
(cid:12)
(cid:12)
 
(cid:12)(cid:12)
(cid:12) µ − λK (cid:12)(cid:12)
(cid:12)
(cid:12)
µ − λK (cid:12)

|λ(k)  − λJ | = O 

, 

6


 

	
Rayleigh Quotient Iteration 


Parameter µ is constant in inverse iteration, but convergence is better for 
µ close to the eigenvalue 

Improvement: At each iteration, set µ to last computed Rayleigh quotient 

• 

• 

Algorithm: Rayleigh Quotient Iteration 

v (0)  = some vector with �v (0)� = 1 
λ(0)  = (v (0) )T Av (0)  = corresponding Rayleigh quotient 

for k  = 1, 2, . . . 
Solve (A − λ(k−1)I )w   = v (k−1)  for w 
v (k)  = w/�w� 
λ(k)  = (v (k) )T Av (k) 

apply matrix 

normalize 

Rayleigh quotient 

7


Convergence of Rayleigh Quotient Iteration


•	 Cubic convergence in Rayleigh quotient iteration: 
�v (k+1)  − (±qJ )� = O(�v (k)  − (±qJ )� 3 ) 

and 

|λ(k+1)  − λJ | = O(|λ(k)  − λJ | 3 ) 
Proof idea:  If v (k)  is close to an eigenvector, �v (k)  − qJ � ≤ ǫ, then the 
accurate of the Rayleigh quotient estimate λ(k)  is |λ(k)  − λJ | = O(ǫ2 ). 
One step of inverse iteration then gives 

• 

�v (k+1)  − qJ � = O(|λ(k)  − λJ | �v (k)  − qJ �) = O(ǫ3 ) 

8 

The QR Algorithm


• 

• 

• 

Remarkably simple algorithm: QR factorize and multiply in reverse order : 

Algorithm:  “Pure” QR Algorithm 

A(0)  = A


for k  = 1, 2, . . .

Q(k)R(k)  = A(k−1) 
A(k)  = R(k)Q(k) 

QR factorization of A(k−1)


Recombine factors in reverse order 


With some assumptions, A(k)  converge to a Schur form for A (diagonal if 
A symmetric)


Similarity transformations of A:


A(k)  = R(k)Q(k)  = (Q(k) )T A(k−1)Q(k) 

9 

Unnormalized Simultaneous Iteration


•	 To understand the QR algorithm,  ﬁrst consider  a simpler algorithm 
•	 Simultaneous Iteration is power iteration applied to several vectors 
Star t with linearly independent v (0) , . . . , v (0) 
•	
n 
1 
(0)  converges to q1
We know from power iteration that Ak v1
• 
With some assumptions, the space �Ak v (0) , . . . , Ak vn 
(0) � should 
•	
1 
converge to q1 , . . . , qn


• 

V (0)	

Notation: Deﬁne  initial matrix V (0)  and matrix V (k)  at step k :




  v (k) 
= 



  1 






 , V (k)  = Ak V (0)  = 

(0) 
vn 

(0) 
  v1 

· · ·


· · ·


(k) 
vn 

 






10










	




Unnormalized Simultaneous Iteration


De ﬁne w ell-behaved basis for column space of V (k)  by Qˆ (k)Rˆ (k)  = V (k) 

• 
•  Make the assumptions: 
–  The leading n  + 1 eigenvalues are distinct 
–  All principal leading principal submatrices of Qˆ T V (0)  are nonsingular, 
where columns of Qˆ are q1 , . . . , qn 
We then have that the columns of Qˆ (k)  converge to eigenvectors of A: 

(k) 
�qj 
− ±qj �

where C  = max1≤k≤n  λk+1 / λk

| 
|
| |
•  Proof.  Textbook / Black board 

= O(C k )

11


Simultaneous Iteration 

• 
• 

The matrices V (k)  = Ak V (0)  are highly ill-conditioned 

Or thonormalize at each step rather than at the end: 

Algorithm: Simultaneous Iteration 

Pick Qˆ (0)  Rm×n
∈
for k  = 1, 2, . . . 
Z  = AQˆ (k−1) 
Qˆ (k)Rˆ (k)  = Z 

Reduced QR factorization of Z 

• 

The column spaces of Qˆ (k)  and Z (k)  are both equal to the column space 
of AkQˆ (0) , therefore same convergence as before 

12


Simultaneous Iteration 
⇐⇒
The QR algorithm is equivalent to simultaneous iteration with Qˆ (0)  = I

QR Algorithm


Notation: Replace Rˆ (k)  by R(k) , and Qˆ (k)  by Q(k) 

• 
• 
Simultaneous Iteration: 

Q(0) 
= I 
Z  = AQ(k−1) 
Z  = Q(k)R(k) 
A(k)  = (Q(k) )T AQ(k) 

Unshifted QR Algorithm: 

A(0) 
= A 
A(k−1)  = Q(k)R(k)
A(k)  = R(k)Q(k)
Q(k)  = Q(1)Q(2)  Q(k)
· · · 

Also deﬁne  R(k)  = R(k)R(k−1)  R(1) 
· · ·

Now show that the two processes generate same sequences of matrices 

• 
• 

13


QR Algorithm 

• 

Simultaneous Iteration	

⇐⇒
Both schemes generate the QR factorization Ak  = Q(k)R(k)  and the 
projection A(k)  = (Q(k) )T AQ(k) 
•  Proof.  k  = 0 trivial for both algorithms. 
For k  ≥ 1 with simultaneous iteration, A(k)  is given by de ﬁnition, and 
Ak  = AQ(k−1)R(k−1)  = Q(k)R(k)R(k−1)  = Q(k)R(k) 

For k	 ≥ 1 with unshifted QR, we have 
Ak  = AQ(k−1)R(k−1)  = Q(k−1)A(k−1)R(k−1)  = Q(k)R(k) 

and 

A(k)  = (Q(k) )T A(k−1)Q(k)  = (Q(k) )T AQ(k) 

14 

MIT OpenCourseWare
http://ocw.mit.edu 

18.335J / 6.337J Introduction to Numerical Methods
Fall 2010
 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

