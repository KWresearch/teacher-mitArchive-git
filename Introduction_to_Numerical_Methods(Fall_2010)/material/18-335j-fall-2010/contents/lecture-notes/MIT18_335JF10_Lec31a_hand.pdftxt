Notes on the convergence of trapezoidal-rule 
quadrature 

Steven G. Johnson 

Created Fall 2007; last updated March 10, 2010 

1  Introduction 
´ 
Numerical  quadrature  is  another  name  for  numerical  integration,  which  refers  to  the 
f (x)d x of some function  f (x) by a discrete summation 
approximation of an integral 
∑ wi f (xi ) over points xi  with some weights wi .  There are many methods of numerical 
quadrature corresponding  to different choices of points xi  and weights wi ,  from Euler 
integration to sophisticated methods such as Gaussian quadrature, with varying degrees 
of accuracy for various types of functions  f (x).  In this note, we examine the accuracy 
of one of  the simplest methods:  the  trapezoidal  rule with uniformly spaced points.  In 
particular,  we  discuss  how  the  convergence  rate  of  this  method  is  determined  by  the 
smoothness properties of  f (x)—and, in practice, usually by the smoothness at the end­
points.  (This  behavior  is  the  basis  of  a more  sophisticated method,  Clenshaw-Curtis 
quadrature,  which  is  essentially  trapezoidal  integration  plus  a  coordinate  transforma­
tion to remove the endpoint problem.) 
For  simplicity,  without  loss  of  generality,  we  can  take  the  integral  to  be  for  x ∈
ˆ  2π 
[0, 2π ], i.e.  the integral 
I = 
0 
which is approximated in the trapezoidal rule1  by the summation: 
−1 
N
f (0)Δx + 
∑
2 
n=1

f (2π )Δx 
,
2 

f (x)d x, 

IN  = 

f (nΔx)Δx + 

π . 
where Δx =  2
N 
We now want to analyze how fast the error EN  = |I − IN | decreases with N .  Many 
books  estimate  the  error  as  being  O(Δx2 ) = O(N −2 ),  assuming  f (x)  is  twice  differ­
entiable  on  (0, 2π )—this  estimate  is  correct,  but  only  as  an  upper  bound.  For  many 
interesting functions, the error can decrease much, much faster than that, as discussed 
below. 
1 Technically, this is the “composite” trapezoidal rule, where the “trapezoidal rule” by itself refers to the 
approximation [ f (x) +  f (x + Δx)]Δx/2 for a single Δx interval. 

1 

2  A Simple, Pessimistic Upper Bound 
A simple, but perhaps too pessimistic, upper bound is as follows.  The trapezoidal rule 
corresponds to approximating  f (x) by a straight line on each interval Δx, which means 
that  the  error  is  the  integral  of  a  quadratic  remainder  (to  lowest  order).  The  integral 
of  a  quadratic  over  a Δx  is O(Δx3 ):  this  is  the  local  truncation  error  over  each  inter­
val.  There  are N − 1 = O(Δx−1 )  intervals,  so  the  total  error  is O(NΔx3 ) = O(Δx2 ) = 
O(N −2 ).  (The  same  bound  can  be  derived  in  a  number  of  ways,  more  formally  via 
integration by parts.)  However,  it  is  important  to emphasize  that  this  is only an upper 
bound: we didn’t take into account the possibility of cancellations in the errors between 
different intervals. 

3  Quadrature error via Fourier analysis 
One way to analyze the error more thoroughly is to consider the Fourier-series expan­
sion of the function  f (x). 

with 

f (x)e−imx d x. 

∞ 
1  ∑
cm eimx 
f (x) = 
2π  m=−∞ 
ˆ  2π 
cm  = 
0 
Obviously, I = c0 . But now IN  is easy to evaluate. 
−1 
−1 1  ∑
∞ 
∞ 
1  N
N
2π i mn . 
∑
cm eimnΔxΔx =  ∑
∑
IN  = 
cm 
e 
N
n=0 2π  m=−∞ 
m=−∞  N n=0 
´
We have assumed  that  f (x) has a convergent Fourier series at  the points xn  = 2π n/N , 
2π  | f (x)| p d x < ∞  for  some  p > 1  and  if  the  periodic  extension  of 
which  is  true  if 
0
f (x)  is continuous at  those points xn .  At  the endpoints x = 0 and x = 2π ,  the Fourier 
series  will  converge  to  [ f (0) +  f (2π )]/2  (i.e.  we  generally  have  an  effective  jump 
discontinuity at the endpoints), but this exactly matches how the endpoints are handled 
in the trapezoidal rule, which is why we were able to replace this term with the Fourier 
series  at  x = 0  in  the  above  expression.  The  ﬁnal  summation  simpliﬁes  enormously 
because ∑n e2π imn/N  is zero unless m is an integer multiple of N , in which case the sum 
is N . Therefore 
∞ 
IN  =  ∑  ckN , 
k=−∞ 
����� �
����� 
����� 
�����
and the error in the trapezoidal rule is 
∞ 
EN  = |I − IN | = 
∑ (ckN + c
∑

=ckN 
−kN ) 
k=1 
k=0 
which transforms the question of error analysis into a question of the convergence rate 
of the Fourier series expansion of  f (x). But the convergence rate of the Fourier series is 

, 

2 

determined by the smoothness of the function  f (x)...or rather, of its periodic extension, 
so we have to include the periodicity of  f (x) and its derivatives at the endpoints of the 
integration interval. 
For  example,  suppose  that  the  periodic  extension  of  f (x)  is  �  times  differentiable 
and  f (�) (x)  is piecewise continuous with some  jump discontinuities.  In  this case,  it  is 
straighforward to show via integration by parts that cm  goes asymptotically as 1/m�+1 . 
1 
In  this  case,  EN  is  O( N �
+1 ),  since  we  can  just  (asymptotically,  for  large  N )  pull  out 
the  1/N �+1  factor  from  each  term  in  the  sum  (which  then  becomes  some  convergent 
series independent of N ).  However,  it turns out that even this is an overestimate if the 
discontinuity occurs precisely at  the endpoints  f (�) (0) =�
f (�) (2π ).  In  this case, as we 
shall see below, when � is even we get an additional cancellation and the convergence 
is O(1/N �+2 ); when � is odd the convergence is still O(1/N �+1 ). 
.As  another  example,  suppose  that  the  periodic  extension  of  f (x)  is  an  analytic 
function  (inﬁnitely  differentiable) with  poles  a  nonzero  distance  from  the  real  axis— 
in  this  case,  the  Fourier  series  converges  exponentially  fast,  and  hence  EN  decreases 
exponentially with N .  In general, it follows from above that any inﬁnitely differentiable 
periodic  f (x)  will  have  error  that  vanishes  faster  than  any  polynomial  in  1/N ,  but 
exactly how much faster will depend upon the nature of  f (x) and its singularities. 
How  does  this  error  analysis  compare with  our O(N −2 )  estimate  from  earlier?  If 
f (x) is an arbitrary differentiable function on (0, 2π ), then we must in general assume 
f (0) =�
f (2π ),  and  so  the periodic  extension of  f (x)  is  discontinuous.  Hence we  can 
apply our analysis from above, conclude that � = 0, and hence the error is O(N −1 ) ...or 
rather,  O(N −2 ),  as  long  as  we  apply  the  correction  alluded  to  above,  that  we  always 
round up  the exponent � + 1  to  the next even  integer when  the discontinuity occurs at 
the endpoints of the integration interval. 

3.1  Convergence rate from the Fourier series 
To obtain the convergence rate of the quadrature error, we need to ﬁnd the asymptotic 
convergence rate of the Fourier series coefﬁcients cm . This is a rather standard analysis, 
but we repeate it here both as a review and because something interesting occurs when 
the ﬁrst discontinuity occurs at the endpoints, as we alluded to above. 
The most common case is where  f (x) [or rather, its periodic extension] has its ﬁrst 
discontinuities  in  its  �-th derivative,  and countably many  jump discontinuities  in gen­
eral.  That is, the periodic extension of  f (�) (x) exists but is only piecewise continuous, 
with  countably  many  jump  discontinuities  [most  often  a  mismatch  in  the  endpoints 
f (�) (0) =�
f (�) (2π )],  while  all  lower  derivatives  are  continuous  and  periodic.  In  this 
case, we simply integrate by parts � + 1 times, until we obtain delta functions from the 
jump discontinuities. Let 

f (�+1) (x) = ∑ a j δ (x − x j ) + g(x) 
j 

for some bounded piecewise-continuous function g(x) and delta functions correspond­
ing to jump discontinuities at x j  in the periodic extension of  f (�) (x).  Then, integrating 

3 

���� 
by parts in the Fourier integral for cm  (for m =� 0), we obtain: 
ˆ  2π 
ˆ  2π 
i f (x)e−imx 
2π
⎤ ⎦ 
0⎡ 
i 
f (x)e−imx d x = 
f � (x)e−imx d x = 
− 
· · · 
��+1 
��+1 ˆ  2π 
� 
� 
cm  = 
m
m 
ˆ  2π 
⎣
0 
0 
i − 
i 
g(x)e−imx d x 
∑  a j e−imx j  + 
f (�+1) (x)e−imx d x = 
=  −
⎤ 
⎡
��+1 
� 
� 
� 
m 
m 
x j ∈[0,2π ) 
��
0 
0 
ˆ  2π 
⎦
⎣
i 
i 
g (x)e−imx d x 
�
g(x)e−imx
a j e−imx j  +
=  − 
− 
2π 
∑

,
0
m 
m 
x j ∈[0,2π ) 
0 
where all of  the boundary  terms  from  integration by parts �  times are zero because of 
the  assumed  periodicity  of  the  derivatives < �.  If  f (�) (0) =�
f (�) (2π ),  then  there will 
be a boundary term from the (� + 1)-st integration by parts, but this is included above 
from the a j  term at x j  = 0. 
We have also integrated by parts one last time on the g(x) term; the g� (x) integrand 
may include delta functions since g(x) is only piecewise continuous, but the important 
point  is  that  the  {· · · }  integral  has  a  bounded magnitude.  In  particular,  we  can write 
g� (x) = ∑ j b j δ (x − y j ) + h(x)  for  some  bounded  piecewise  continuous  function  h(x), 
������ 
������ 
����
���� 
and then 
��
ˆ  2π 
ˆ  2π 
h(x)e−imx d x 
b j e−imy j  + 
g (x)e−imx d x  = 
g(x)e−imx 2π 
�
0  − 
∑

��
��
ˆ  2π 
y j ∈[0,2π ) 
0 
0 
≤ 
|
|d x.
∑

h(x)
+ 
b j 
y j ∈[0,2π ) 
0 
Therefore, when we look at the asymptotic behavior as m grows large, we immediately 
������
������ 
⎡⎣
⎤⎦ 
⎡
⎤ 
� 
��+1
ﬁnd 
��
��
⎦
⎣
i 
∑  a j e−imx j  + O(1/m) 
|
| 
− 
∑

cm = 
+ O(1/m)
m 
x j ∈[0,2π ) 
x j ∈[0,2π ) 
= O(1/m�+1 ). 
We  thus obtain an upper bound for  the quadrature error EN  = O(1/N �+1 ), as given  in 
the previous section. 
However, as mentioned in the previous section, this bound is too pessimistic in one 
especially common case:  suppose all of the discontinuities (or at least, the lowest-order 
discontinuities)  are  at  the  endpoints,  i.e.  the  only  x j  ∈ [0, 2π )  is  x0  = 0.  In  that  case, 
we can exploit  the  fact  that we are not  interested  in cm  alone, but  rather our error  is a 
summation of terms of the form cm + c−m .  We therefore obtain, in this special case of 
⎧⎨ 
� 
� 
����� 
������ 
� 
�� 
� 
� 
��+1 
��+1 
endpoint discontinuities: 
� 
� 
⎩
1 
O 
i 
i 
1 
|cm + c−m | = 
− 
m�+2 
+ +
= 
a0 + O
m�+2 
m 
m
1 
O 
m�+1 

� even 
. 
� odd

a j

≤ 

1 
m�+1

4 

That  is,  in  this  special  case  the  1/m�+1  terms  exactly  cancel when  �  is  even,  and we 
increase the order of convergence by one! 
An  equivalent  result  states  that,  if  f (x)  is  inﬁnitely  differentiable  on  the  interval 
(0, 2π ),  then  the error EN  can be expanded as an explicit power  series  in Δx  in which 
only even powers of Δx are present.  A proof (not using Fourier series) is given in, for 
example An Introduction to Numerical Analysis by Suli and Mayers.2  However, I ﬁnd 
the Fourier series approach much nicer—the convergence analysis of the Fourier series 
is very standard, straightforward (at least if you avoid the really pathological functions), 
and well known, including many more situations than the ones I have discussed above. 
(The  analysis  of  Suli  and  Mayers  involves  a  relatively  unfamiliar  set  of  polynomial 
basis  functions.)  See e.g.  J. P. Boyd, Chebyshev and Fourier Spectral Methods,  for a 
discussion of the Fourier-based approach. 

f (cos θ ) sin θ dθ . 

4  Clenshaw-Curtis quadrature 
Even  if  f (x)  is  a  nice,  smooth  function  inside  the  integration  interval,  it  is  often  not 
periodic at its endpoints, which is what commonly reduces the error of the trapezoidal 
rule  to  the  pessimistic  O(N −2 )  bound.  However,  this  can  be  ﬁxed  by  performing  a 
change of variables, which is the basic idea behind Clenshaw-Curtis quadrature. 
For  simplicity  let  us  assume we  are  integrating  for  x ∈ [−1, 1]  rather  than  [0, 2π ]. 
In this case, we make the substitution x = cos θ , and obtain the integral: 
ˆ  π 
ˆ  1 
I = 
f (x)d x = 
−1
0 
Now,  f (cos θ )  is  by  construction  nice  and  periodic,  so  we  would  like  to  extend  this 
integral to [−π , π ] and use trapezoidal integration as above. However, this is spoiled by 
the sin θ  term, which would make the integral on [−π , π ] zero, so we use one additional 
trick:  we replace  f (cos θ ) by  its cosine series,  integrate each cosine  term against sine 
analytically, and obtain  the coefﬁcients  in  the cosine series by  trapezoidal quadrature. 
That is: 

∞
∑ a,m cos(mθ ), 
+ 
ˆ  π 
m=1 
1 
π  −π 
∞
2a2k

∑ 
I = a0 + 
1 − (2k)2 .

k=1 
Here, the integral to obtain am  is over [−π , π ] of a periodic function  f (cos θ ) cos(mθ ) 
whose smoothness is determined by that of  f (x) on x ∈ (−1, 1), regardless of whether 
f (x)  itself  is  periodic.  Therefore,  if  f (x)  is  sufﬁciently  smooth,  the  coefﬁcients  am 
converge quite rapidly to zero as discussed above (even exponentially fast if  f (x) is an­
alytic), and can be computed by  trapezoidal-rule  integration with error  that converges 

ˆ  π 
2 
π  0 

am  = 

f (cos θ ) cos(mθ )dθ  = 

f (cos θ ) cos(mθ )dθ ,

f (cos θ ) = 

a0 
2 

2 See  also  the  online  course  notes  by  Patch  Kessler  at http://www.mechanicaldust.com/ 

5 

to  zero  at  the  same  rate.  Moreover,  it  turns  out  that  the  trapezoidal-rule  integration 
with 2N − 1 points is equivalent to a type-I discrete cosine transform, and can be eval­
uated very rapidly for m = 0, . . . , N  simultaneously via fast Fourier transform methods. 
[Clenshaw-Curtis  quadrature  can  also  be  viewed  as  expansion  of  f (x)  in  Chebyshev 
polynomials Tm (x), since by deﬁnition Tm (x) = cos(m cos−1 x).] 

6 

MIT OpenCourseWare
http://ocw.mit.edu 

18.335J / 6.337J Introduction to Numerical Methods 
Fall 2010
 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

