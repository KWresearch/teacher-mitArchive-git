Lecture 27

27.1 Test of homogeneity.

Suppose that the population is divided into R groups and each group (or the entire
population) is divided into C categories. We would like to test whether the distribu-
tion of categories in each group is the same.

Table 27.1: Test of homogeneity
Category 1 (cid:1) (cid:1) (cid:1) Category C P
(cid:1) (cid:1) (cid:1)
N11
N1C
N1+
...
...
...
...
(cid:1) (cid:1) (cid:1)
NR+
NRC
NR1
(cid:1) (cid:1) (cid:1)
N+1
N+C
n

Group 1
...
Group R
P

If we denote

(Categoryj jGroupi ) = pij
so that for each group i (cid:20) R we have
C
Xj=1
then we want to test the following hypotheses:
(cid:26) H1 : pij = pj for all groups i (cid:20) R
H2 :
otherwise
If the observations X1 ; : : : ; Xn are sampled independently from the entire popu-
lation then the homogeneity over groups is the same as independence of groups and

pij = 1

107


LECTURE 27.

108

categories. Indeed, if have homogeneity

(Categoryj jGroupi ) =

(Categoryj )

then we have

(Groupi ; Categoryj ) =

(Categoryj jGroupi )
which means the groups and categories are independent. Alternatively, if we have
independence:

(Groupi ) =

(Categoryj )

(Groupi )

(Categoryj jGroupi ) = 

= 

(Groupi ; Categoryj )
(Groupi )
(Categoryj )
(Groupi )
(Groupi )

=

(Categoryj )

which is homogeneity. This means that to test homogeneity we can use the indepen-
dence test from previous lecture.
Interestingly, the same test can be used in the case when the sampling is done
not from the entire population but from each group separately which means that we
decide apriori about the sample size in each group - N1+ ; : : : ; NR+ : When we sample
from the entire population these numbers are random and by the LLN Ni+=n will
approximate the probability
(Groupi ); i.e. Ni+ re(cid:13)ects the proportion of group j in
the population. When we pick these numbers apriori one can simply think that we
arti(cid:12)cially renormalize the proportion of each group in the population and test for
homogeneity among groups as independence in this new arti(cid:12)cial population. Another
way to argue that the test will be the same is as follows.
Assume that

(Categoryj jGroupi ) = pj
where the probabilities pj are all given. Then by Pearsonâ€™s theorem we have the
convergence in distribution

(Nij (cid:0) Ni+pj )2
Ni+pj

C
Xj=1
for each group i (cid:20) R which implies that
C
R
(Nij (cid:0) Ni+pj )2
Xj=1
Xi=1
Ni+pj

! (cid:31)2
C(cid:0)1

! (cid:31)2
R(C(cid:0)1)















LECTURE 27.

109

since the samples in di(cid:11)erent groups are independent. If now we assume that prob-
abilities p1 ; : : : ; pC are unknown and we use the maximum likelihood estimates p(cid:3)j =
N+j =n instead then
R
C
Xi=1
Xj=1
because we have C (cid:0) 1 free parameters p1 ; : : : ; pC(cid:0)1 and estimating each unknown
parameter results in losing one degree of freedom.

R(C(cid:0)1)(cid:0)(C(cid:0)1) = (cid:31)2
! (cid:31)2
(R(cid:0)1)(C(cid:0)1)

(Nij (cid:0) Ni+N+j =n)2
Ni+N+j =n

