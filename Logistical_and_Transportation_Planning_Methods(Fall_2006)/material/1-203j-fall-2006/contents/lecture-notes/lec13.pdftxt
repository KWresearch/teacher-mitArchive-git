Spatially Distributed 
Queues II

M/G/1
2 Servers
N servers: Hypercube Queueing Model
Approximations

Setup:  Hypercube 
Queueing Model

(cid:97)Region comprised of geographical atoms 
or nodes
(cid:97)Each node j is an independent Poisson 
generator, with rate λj
(cid:97)Travel times: τil = travel time from node i
to node j
(cid:97)N servers
(cid:97)Server locations are random:  lnj

Setup:  Hypercube 
Queueing Model - con't.

(cid:97)Server assignment:  one assigned
(cid:97)State dependent dispatching
(cid:97)Service times:  mean = 1/μn ; negative 
exponential density
(cid:97)Service time dependence on travel time
(cid:97)We allow a queue (FCFS, infinite 
capacity)

Fixed Preference Dispatch 
Policies for the Model

(cid:97)Idea:  for each atom, say Atom 12, there 
exists a vector of length N that is the 
preference-ordered list of servers to 
assign to a customer from that atom
(cid:97)Example:  {3,1,7,5,6,4,2}, for N=7.
(cid:97)Dispatcher always will assign the most 
preferred available server to the customer
(cid:97)Usually order this list in terms of some 
travel time criterion.

Example Dispatch Policies
(cid:97)SCM:  Strict Center of Mass
(cid:96)Place server at its center of mass
(cid:96)Place customer at its center of mass
(cid:96)Estimate travel times:  center of mass to 
center of mass
(cid:97)MCM:  Modified Center of Mass
(cid:96)Place server at its center of mass
(cid:96)Keep customer at centroid of atom
(cid:96)Estimate travel times:  center of mass to 
centroid of atom

Example Dispatch Policies

(cid:97)EMCM:  Expected Modified Center of 
Mass
(cid:96)Do the conditional expected travel time 
calculation correctly, conditioned on the 
centroid of the atom containing the customer

Are fixed preference 
policies optimal?

(cid:97)AVL:  Automatic Vehicle Location:  
dispatch the real time nearest server
(cid:96)This can be incorporated into the Hypercube 
framework, but very carefully!
(cid:96)Consider two servers:

Customer
X

RA1

RA2

X

Customer in square
marked X.  Place an
asterisk in each square
that could have the 
closest server.
Assume each server is available
and is located 'somewhere' in
his/her square "police beat."

*
*
*

*
*
X* *
*
*

*
*
*

*
*
*
*
*

*
*
*
*
X* *
*
*
*
*

*
*
*

What to know about the 
Hypercube Queueing Model

(cid:97)Know the 2-server setup
(cid:97)Be able to work with a 3-server model
(cid:96)Read in the text the formulas to apply
(cid:97)Forget the cases for N>3 servers.
(cid:97)Know Hypercube Approximation 
Procedure (still to come -- fasten your seat 
belts!)

1,0

0,0

1,1

0,1

1,0

0,0

1,1

0,1

1,1,0

1,1,1

0,1,0

0,1,1

1,0,0

1,0,1

0,0,0

0,0,1

Hypercube Approximation 
Hypercube Approximation 
Procedure:  A General Technique
Procedure:  A General Technique

(cid:97)Want to reduce dramatically the number 
of simultaneous equations to solve
(cid:97)The procedure reduces the number of 
equations from 2N simultaneous linear 
equations to N simultaneous nonlinear 
equations.
(cid:97)We look at only those performance 
measures we need, not at micro-structure 
of the binary state space

Hypercube Approximation Procedure
Hypercube Approximation Procedure
A General Technique
A General Technique

Theory:  Sampling Servers Without 
Replacement from M/M/N Queue

we know the aggregate 

M / M / N / ∞
From 
state probabilities:
P{Sk} ≡ Pk = N kρk P0 / k!      k = 0,1, 2, ..., N − 1
P{SN} ≡ PN = N NρN P0 /(N![1 − ρ])
N −1∑
+ N NρN /( N!{1 − ρ})]−1
N iρi / i!
P{S0} ≡ P0 = [
i= 0

The Hypercube Model, 
when the state space is 
compressed from its cube 
in Ndimensions to a 'line' 
birth and death process, 
always reduces to an 
M/M/Nqueue (assuming 
service times are not 
server-specific)

P{B1, B2 , ..., Bj , Fj +1}
Key expression:
For our applications, we do not need to know the fine grained
binary state probabilities.  Rather we need dispatch probabilities and 
server workloads.  
What about 'B-' probability reasoning?
"Flips coins" until first Heads is obtained:
ρj (1 − ρ)     j = 0,1, 2,..., N − 1
⎧ 
P{B1, B2 , ..., Bj , Fj +1} ≈
⎨ 
ρN                        j = N
⎩ 
Incompatible with known state probability PN
Doesn't include biases.

⎫ 
⎬ 
⎭ 

Let's "Divide and conquer":
k = N
∑
k = 0

P{B1, B2 , ..., Bj , Fj +1} =

P{B1 , B2 ,..., Bj , Fj +1 | Sk}
Pk      (*)

Working carefully and slowly to find the state-conditioned 
dispatch probabilities:

P{B1, B2 , ..., Bj , Fj +1 | Sk } = P{Fj +1 | B1 , B2 , ..., Bj , Sk }...P{B2 | B1Sk}P{B1 | Sk}
...... k
...                       ... k − 1
P{B1, B2 , ..., Bj , Fj +1 | Sk } =         N − k
N
N − 1
N − j

  (**)

Can plug (**) back into (*) and obtain an exact expression.
Manipulate it to obtain a convenient form as "B-" probability 
reasoning with an 'A+" correction term:
P{B1, B2 , ..., Bj , Fj +1} = Q( N ,ρ, j )ρj (1 − ρ)      (* * *)

"Correction factor"

Explore properties of Correction Factor

The desired dispatch probabilities can be written as a telescoped expression:
P{B1, B2 , ..., Bj , Fj +1} = P{Fj +1 | B1B2 ... Bj}P{Bj | B1B2 ... Bj −1}...P{B1}

Use above in Eq.(***) to obtain:

Q( N, r , j ) = [

P{Fj +1 | B1 ...B j}
1 − ρ

][

P{Bj | B1 ...B j −1}
ρ

]...[

P{B1}
ρ

]

≤ 1           ≥ 1            = 1

Gn
k ≡ set of geographical atoms for which unit n is 
         the k th  preferred dispatch alternative
nlj ≡ id #  of the j th  preferred unit for atom  l
Set μ= 1

∑
+ λj P{Bn j 1 Bn j 2 Fn}
3
j∈Gn

∑
} + λj P{Bn j 1 Fn}
2
j ∈G n

∑
ρn = λj P{Fn
1
j∈Gn
2∑
1∑
) + λj Q( N ,ρ,1)ρn j 1
ρn = λj (1 − ρn
j∈Gn
j∈Gn
3∑
              λjQ( N,ρ, 2 )ρn j 1
j ∈Gn

ρn j 2

(1 − ρn )

+ ... + λPN / N

+ ... + λPN / N

(1 − ρn )

+

The last equation gives N nonlinear simultaneous equations in 
the unknown workloads, ρn, subject to the constraint that
N
∑ = λ     " normalization"
ρn
n =1

Typically converges in 3 to 5 iterations, within 1 to 2% of 
'exact Hypercube' results

Response patterns:
λk
λ

f nkj k =

j −1
∏ }(1 − ρn kj )
Q( N ,ρ, j − 1){ ρn kl
l=1

id # of jth preferred
unit for atom k

j-1 more 
preferred
units

jth preferred
unit

Square Root Laws (approximations)
In Chapter 3 we found
E[ D] = C

Area of service region

A
N 0

Number of mobile servers

depended on distance metric
and location strategy

Assumes all N0 servers are available or free (not busy)

Now consider Nto be a R.V.

Might we expect the following to be true?
A
k

E[ D | N = k ] = C

       k = 1, 2,..., N0

What if the locations of servers were determined by a homogenous
spatial Poisson process, with busy servers selected by "random erasers"?

E[ D] = P0 D0 +

Getting to Expected Travel Distance
N 0∑ C
A
Pk
k
k =1
From M/M/N0
queueing model
where Pk = Probability of k servers available (M/M/N0)

Moving to E[D]
≅
Since P0 0, we can write
E[ D] ≅ C AE states of
M / M / N 0

[1 / N ]

We now apply "B-" probability reasoning, to get
A
E[ N ]

E[ D] ≅ C

(Jensen's Inequality shows that this Eq. is a lower bound to true E[D].)

Finishing
E[ N ] ≈ N0 − N 0ρ= N0 (1 − ρ)
A
N0 (1 − ρ)
A
N0 (1 − ρ)

E[ D] ≈ C

E[T ] ≈

C
v

+

v
a

Great results in practice

Acceleration term

Jensen's Inequality

If g(X) is a convex function over the region of non-zero probability,
then E[g( X )] ≥ g( E[ X ])

(Problem 5.5 explores this further.)

Jensen's Inequality
1.2

1 / N

1

0.8

0.6

0.4

0.2

0

Series1

N

1

2

3

4

5

6

7

8

9

10

E[          ]=0.5*(1) + 0.5*(10)-0.5 = 0.5*(1 + 0.316) = 0.658
1 / N
1/E[N]-0.5 = 1/(1*0.5 + 10*0.5)-0.5 =1/(5.5)-0.5 = 1/2.345 = 0.426

1 / N

1.2

1

0.8

0.6

0.4

0.2

0

True mean (0.658)

Series1

1
2
Suppose 50% of
probability
mass here

3

4

5

6

7

8

9

10

"B-" mean (0.426)

And suppose 50% 
of probability 
mass here

