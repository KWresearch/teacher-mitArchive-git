5.73 Lecture #27
Wigner-Eckart Theorem
CTDL, pages 999 - 1085, esp. 1048-1053

Last lecture on 1e– Angular Part
Next:  2 lectures on 1e– radial part
Many-e– problems
What do we know about 1 particle angular momentum?

27 - 1

1.

  
2
.

j

J

k

ijk

→

definition 

 Basis set
JM
[
] =
∑h
ε
J J
i
,
i
k
+
=
J
J
J
 Coupling of 2 angular momenta
2
1
↔
 uncoupled basis sets
coupled 
+
=
S
L
J
transformation via 
 plus orthogonality.  Also more general methods.
−
Zeeman
SO
H
H
 example
  +  

 all matrix elements in  JM  basis set.
J

−
−
* easy vs. hard basis sets
* limiting cases, correlation diagram
* pert. theory – patterns at both limits plus distortion

TODAY:
1. Define Scalar, Vector, Tensor Operators via Commutation
Rules.  Classification of an operator tells us how it
transforms under coordinate rotation.
2. Statement of the Wigner-Eckart Theorem
3. Derive some matrix elements from Commutation Rules

Scalar
Vector

S
V

∆J = ∆M = 0, M independent
∆J = 0,±1, ∆M = 0, ±1, explicit M dependences of
matrix elements

These commutation rule derivations of matrix elements are tedious.  There
is a more direct but abstract derivation via rotation matrices.  The goal
here is to learn how to use 3-j coefficients.

updated November 4, 2002

5.73 Lecture #27
27 - 2
Classification of Operators via Commutation Rules with CLASSIFYING
ANGULAR MOMENTUM

ω
0
1

c o m p o n e n t s (µ )
µ   =  0
µ = ↔
0
z
+ ↔ −
1 2
/
2
1
↔ +
–
2
1
+2,  …,  –2

+(
)
x iy
−(
)
−
1 2
/
x iy

L ike
J  =  0
J  =  1

2

3

s c a l a r
v e c t o r

" c o n s t a n t "
3   c om p o n e n t s

t e n s o r

( 2 ω   +  1)
c o m p o n e n t s
[ω   is  "rank"]

2 n d

3 r d

2

3

Spherical Tensor Components [CTDL, page 1089 #8] …
] =
[
[
ω ωh
(
] = µ
[
(
(
J T
T
,
h
µ
µ
z
  

+ − µ µ ±
)
(
1

Definition:

]
/
1 1 2
)

(
J T
,
µ
±

ω
)
(
T
µ ±
1

ω

)

ω

)

ω

)

common sense ?
(vector analysis)

 in 

JM

 basis set.

)ω
(
        This classification is useful for matrix elements of 
Tµ
Example:  J = L + S
] = ∴
[
r r
 
.
  &  act as scalar operators with respect to each other.
,
  
1
0
L S
L S
r
r

2.
 
 act as vectors 
 and 
wrt
J
L
S

r r
⋅

 acts as scalar 
 
3.
wrt
L S
J
r
r

×

 gives components of a vector 
.
.
 
4
wrt
L S
J
×
[Because 
 
 is composed of products of components of two vectors,
 
S
L
it could act as a second rank tensor.  But it does not !]
[Nonlecture:  given 1 and 2, prove 3]

Once operators are classified (classifications of same operator are
different wrt different angular momenta), Wigner-Eckart Theorem
provides angular factor of all matrix elements in any basis set!

′ ′
N J M

′

ω
(
T
µ

)

NJM

=

specifies
everything
else

δ

′
ω
J J
A
[
]
′
µ
123
M M
vector coupling
coefficient

′
M M
,

+µ

′ ′
ω
)
(
T
N J
NJ
1 244
344
reduced matrix element
′
µ
M M
,
,  no 
no 

redundant-
usually omitted

updated November 4, 2002

5.73 Lecture #27

triangle rule

−

ω

J

≤ ′ ≤ +
J
J

ω

:

*

*

rank of tensor – like an
angular momentum
ω
ω
∆ = ±
(
)
 selection rule for 
,
T
J
µ

ω
(

±

,

27 - 3

− …
),
1

.
0

reduced matrix element contains all radial dependence – when there is no radial
factor in the operator, then the J′,J dependence can often be evaluated as well

* vector coupling coefficients are tabulated – lots of convenient symmetry properties:
A.R. Edmonds, “Ang. Mom. in Q.M.”, Princeton  Univ. Press (1974).

•
•

Nonlecture:  L & S act as vectors wrt J but scalars wrt each other
[
] =
L, S
[
] =
J, L

scalars wrt each other
0
] ∴
+[
] = [
 vector wrt. 
 if 
 is an angular momentum
 
J L
L S, L
L, L
( )
1
 definition
components of 
 satisfy the 
T
L
µ
]
+
L
i
−
L
i

[

−
2

,

J

z

−
/
1 2

[

•

( )
1
T
+
1
+

[
L
h

L
i

L
i

−
/
1 2

L

+

]

x

y

x

y

x

y

y

−
/
1 2

−
/
1 2

] = −
2

[
[ ] = −
L
2
L
x
] = −
[
]
L
2
i
h
[ ]
= +
( )
1
T
L
h
+
1
] =
[ ]
[ ]
+(
)
( )
1
T
L
L
1
h
+
1
] = [
]∴
S
S S
JJ S
J
 
 is vector wrt 
,
,
+
=
J L S

[

( )
1
J T
,
+
z
1
[

etc.

•

  

This notation means:   construct
(1)
an operator classified as T  
+1
r
L.
out of components of 
  

+

y

+

⋅
,
J L S
±

••• Show that L•S acts as scalar wrt J
[
[
] =
J , L S
L S
y
x
x
x
=
 four terms
        
[
] =
[
⋅
+
L S
L L S
J L S
,
,
±
y
x
x
x
y
[
±
+
L S
L L S
,
i
y
x
y
x
[
(
)
−
=
L S
i
h
z
(
±
L S
ii
h
x
=
] =
⋅
J L S
,
z
=
=

0
[
L L S
,
z
x
(
L S
i
h
y

+
L S
y
y
) +
L S
x

L S
y
−

L S
z

x
−

+

[

–

y

x

y

x

z

z

  

0

] ±

[
i

L S
z

z

J , L S
x
y

x

+

L S
y

y

+

L S
z

z

]

] +
[
+
L S
S L S
,
z
z
x
x
x
[
] ±
+
L S
S L S
,
i
z
y
y
x
h((
)
+
−
L S
L S
i
y
z
(
) ±
+
L S
ii
h
z

L S
x

–

y

z

z

z

+

x

L S
y
y
+
L S
y

]
L S
z
z
+
L S
z

z

+

y

]

)]

x

] +
L S
z
z
(
L S
i
h
x

y

+

x

L S
y

y

+

L S
z

z

]

[
S L S
,
z
x
)
−
L S
y

x

      ∴ ⋅L S
0(
 acts as  0
T

)

[

] =
A B
,

( )
0
T
0

ω
∑
= −
ω
k

−
1
(
)

k

ω
(
T
k

[

)

]
ω
(
T
A
−
k

)

[ ]
B

This notation means:
construct an operator
(0)
 classified as T  
0
out of the 
A
components of 
 
B.
and 
updated November 4, 2002

5.73 Lecture #27

27 - 4

all serve
same
function


Vector Coupling Coefficients


Clebsch - Gordan Coefficients


3 - J coefficients


all related to what you already know how to obtain by ladders and orthogonality for
+∑
J
2
=
−
M M M
2
1
= −
 
M
J
2
2
p. 46 Edmonds (1974) general formula


 = −(
)

1

J M J M J M J M JJ J M
2444
1
3444
1
1 2
2
1
1 2
2
1 2
v.c. coefficient

−

J M J M J J J M
1
1 2 3
2
1 2

completeness

JJ J M
1 2

− −
J M
2

3

J
1

J
J
J
3
2
1
M M M
2
1

)
1

−

1
2

(
2

−

3

J
:

)

3

=

+

J

3

(

3

+
+
Constraint:   M M M
1
2
3

=

0

This constraint is imposed in (|) notation but not
in 〈|〉 notation.]

W-E Theorem is an extension of V-C idea because we think of operators as
“like angular momenta” and we couple them to angular momenta to make new
angular momentum eigenstates.

What is so great about W-E Theorem?

vast reduction of independent matrix elements
e.g.  J = 10, ω = 1 (vector operator)
possible values of J′ limited to 9, 10, 11 by triangle rule

′

′
J M
   

JMT( )1
µ

Total # of M. E.
J′  = 9 (2•9+1)(2•10+1)

10 (2•10+1)(2•10+1)

11 (2•11+1)(2•10+1)

399

441

483

1323

#R.M.E.
1

1

1

3

9

10

11

T(1)
µ
T(1)
µ
T(1)
µ

10

10

10

updated November 4, 2002

5.73 Lecture #27

27 - 5

CTD-L, pages 1048-1053
Outline proof of various parts of W-E Theorem
Scalar Operators S

[Ji,S] = 0

Definition (for all i)

[
] =
∆ =
2J S
 selection rule from 
0
0
,
J
[
] =
∆
=
 selection rule from 
,
0
0
J S
M
] =
[
z
M - independence from 
,
0
J S
±
′ ≠
=

′
J M JMS

 if J

0

J

1
.
2
.
3
.
  

1

.

show 
[
0

∆ =
0
:   
J
] =
2
,
J S
=
′
J M

0
′

(

−
2
J S SJ

2

)

JM

[

(
′
J J

) −
1

+(
J J

′ +

]
)
1

=

2

h

′
′
S
J M JM

direction of
 operation by J2
      

′ =

either 
J
(
∆ =
only 
J

 or 
J

′
′
S
J M JM

=

0

)
 matrix elements of 
 can be nonzero
S

0

2
.
     

∆
show 
M
[
] =
,
J S
z
=
0
JM

0
(
′

=

0
:   

′
JM JMS

=

′ ≠
 if M M

0

−
J S SJ
z

z

)

JM

(

)
′ −
′
S
M M JM JM

h

=

′ =
either 
 or 
M M

′
S
JM JM

=

0

  

3

show M - Independence of matrix elements

[

] =
,
J S±

0 =

JM

0
(

′

direction of
 operation
by S

uses ∆J = ∆M = 0 for S

−
J S SJ
±

±

)

JM

(

=

s

JM

−

s
JM

=

−
)

′

s
JM

′
J
JM JM
±

s

′

JM

′
J
JM JM
±
′
J
JM JM
±

we already
know that S is
diagonal in M.

[Should skip pages 27-6,7,8 and go directly to recursion relationship on page 27-10.]

updated November 4, 2002

5.73 Lecture #27

27 - 6

Thus either 
s
JM
Thus 
s
JM

′

 

=

or 

′
J
JM JM
±

s
JM
 is independent of M

=

0

Putting all results for 
 together
S
δ δ
=
′
′
S
S
J M JM
J
′
′
J J M M

 

J

Vector Operators V
] = ∑h
[
,
J V
i
i
k

j

  

ε
ijk

V
k

[
]
r
M selection rules from 
,
J V
[
]
[
]
z
r
2
2
J selection rules from 
,
,
J J V
M - dependence of matrix elements of 
 from double commutator
V

1
.

2
.
3
.
          

1.

=

0

JM
=

0

updated November 4, 2002

M selection rules
[
] =
,J V
z
z
=
′
′
0
J M

a

.

0
(
)
−
J V V J
z
z
z
=
′
either 
 or 
M M ME

JM

z

=

h

(

)
′ −
′
′
V
M M J M JM
z

=

0

      

            

[

,
J V
±
z

] = [

,
J V
z
x

] ± [
i

,
J V
z

.
b

′

h

)

z

′
J M
(
(

(
−
J V V J
±
±
z
)
′ −
′
′
M M J M
)
′ −
m 1
M M
′ =
±±
M M

1

′
J M

V
±
′

h

  or  ME

JM

JM

V
±

(

V

] =
i
h
y
= ±
V
h
±
= ±
′
J M

h

± −(
i

V
x

)

)

V
±

JM

y

′

= ±

h

′
J M

′

V
±

JM

5.73 Lecture #27
Thus we have selection rules:

V
z
V
±

 acts like 
 on 
J
z M
 on 
 acts like 
J
M

±

27 - 7

  

2.

M selection rules

need to use a result that requires lengthy derivation
[
] =

[
]
[
]
(
) +
−
⋅

2
2
2
2
2
,
,
2
2
J V
J J V
J V J VJ
h


see proof in Condon and Shortley,  pages 59 - 60
  

Take 
    

′
J M

′

JM

 Matrix elements of both sides of above Eq.

2

′

(
) −
−
+
′
2
2
2
2
2
2
J VJ VJ J
J J V J VJ
J M
[
) −
(
) +
)
+(
)
(
(
2
′
′
1
2
1
1
J J
J J
J J
]
[
)
+(
(
) +
′
4
1
1
J J
J J

′ +
r
′
′
V
J M JM

′ +

′ +

h

−

4

h

2

2

JM
+(
2
J J

4

4

h

=

=

=

LHS

RHS
      

2

)
1

]
′
J M

r
′
′
V
J M JM
((
)J JM
scalar

⋅
J V

′

′
J M

′

(

)
⋅
J V J

JM

   

=

=

=

∑
′′
J M
′
J

′′
⋅
J V

J

⋅
J V

′
J M

′

(

)
⋅
′′
′′
′′
′′
J V
J
J M J M JM
′ = ′′
′ =
′′
,
J M M
J
′
′
′
J
J J M JM
1 244
344
′ =
J
J
′
J
J JM JM

δ
′
J J

two cases for overall matrix element
′ ≠
A.
J
J
′ =
B.
J
J

updated November 4, 2002

5.73 Lecture #27
′ ≠J
A.
J

27 - 8

=

=

2

h

4

h

RHS

LHS
  

[

(
′
J J
(
′
2
J J

4
[

′ +

′ +

]
)
) +
+(
1
1
J J
) −
+(
2
1
J J

2

=

−
LHS RHS

=

algebra

=

4

h

  0

r
′
′
V
J M JM
) +
)
(
′
1
1
J J

+(
2
J J
[
′ −(
′
′
V
J M JM J

′ +

]

2

)
1

′
′
V
J M JM
]
[
(
1

J

) −
2

J

′ + +
J

) −
2
1

]
1

ME = 0 unless J′ = J ± 1 or J′ = –J

r
 ∴ ∆ = ±
1 selection rule for 
V
J

(J ′ = –J is impossible
except for J′ = –J = 0,
but this violates J′ ≠ J
assumption)

B.

′ =J

J

LHS
0

  

=
=

0
RHS

[
2
h h

=

4

+(
J J

)
1

2

−
′
V
JM JM J

⋅
J V

′
J
J JM JM

]

r
′
V
JM JM

=

      

J

J

⋅
J V
+(
)
h 2
1
J J
1 244 344
0 (
)
C J

r
′
J
JM JM

∆ =
A WONDERFUL AND MEMORABLE RESULT.  It says that all 
 matrix
J 0
r
r
∝
 corresponding matrix element of  !   A simplified form of 
elements of 
 are 
V
J
W - E Theorem for vector operators.
          

updated November 4, 2002

5.73 Lecture #27
27 - 9
Lots of (NONLECTURE) algebra needed to generate all ∆J = ±1 matrix
r
V.
elements of
  

SUMMARY OF C.R. RESULTS:  Wigner-Eckart Theorem for Vector Operator

∆ =
J

0

∆ = +
J
1

∆ = −
1
J

=
V
JM JM C J M
( )
z
o
±

JM

1

V

±

[
+(
=
JM C J J J
( )
o

) −
1

(
M M

±

]
)
1 2
/
1






special case:  These are exactly
the same form as corresponding
matrix element of Ji.

1

±

V

+
J M
1
+
V
J M JM
1
z

±

JM
= +

m

=

[
(
C J
( )
+
[
(
+
C J
J M
( )
+

) ±
(
+
±
+
J M
2
J M
]
))
) −
(
+
+
1 2
/
1
1
J M

]
)
1 2
/
1

1

±

V

−
1
J M
−
V
J M JM
1
z

±

JM
= +

= ±

[
) ±
(
(
m
J M J M
( )
C J
−
[
]
) +(
−(
)
1 2
/
J M J M
( )
C J
−

]
)
1 2
/
1

+

only Co(J), C+(J), C–(J) : 3 unknown J-dependent constants for each J.

∆
M

NONLECTURE (to end of notes).  Example of how recursion relationships (reduced
matrix elements) are derived for each possible ∆J.
r
∆ = ±
 matrix elements of 
1
V
J
[
] =
= +
 using 
,
0
1
J V
+
+
∆
∆
 selection rule for 
 is 
V
M
M
+
∆
∆
 selection rule for 
 is 
J V
M
+
+
(
)

= +
1
= +
2
M

          

+

= =
0

+
1
J M

CR

0

=

−

+
1
J M
+
1
J M

      

+

1

J

+

+

1

V
+

1

+

1

−

JM

−
J V V J
+
+
+
−
+
+
1
1
1
V
J M J M JM
+
expand using
−
completeness

J
JM JM JM
+

1

(arrow denotes J+
operates to right)

(J+ operates to left)

+
V
J M JM
1
+
−
J
JM JM
+
[
) −
+(
(
J M J M
h
  

−

1

1
+

]
)
1 2
/
1

=

[
(
h

+

+
J M
1
+
+
J M
1
+
+
J M

V
1
JM
+
+
J
J M
1
1
+
]
)
) −
(
+
1 2
/
J M
1
2

The matrix elements in the
denominator are to be
replaced by their values,
and a common factor is
cancelled

updated November 4, 2002

5.73 Lecture #27
[
J M+
multiply both sides by 
−
+
V
1
J M JM
+
+(
)
(
+
+
1 2
/
J M
J M

+

]−1 1 2/

1
)
1 2
/
1

=

 to display symmetry
+
+
1
J M
)
(
+
+
1 2
/
1
J M

(

V
1
JM
+
+
+
J M

M M→ + 1 recursion relationship

ratio is independent of M
α1
′ +
≡
α
V
( )
J
C J
J
+
[
(
+
= −
+
C J M
+

+
1
J M

JM

V
+

+

1

)
(
1

+
J M

+

]
)
2 1 2
/

27 - 10

≡ − ( )
C J
+

)
1 2
/

2

sign chosen so
that Vz matrix
elements will be
+C+(J)











       

[

B.

∆ = ±
Remaining to do for 
 matrix elements
1
J
[
] = −
∆
 gives 
 matrix element when we take 
A.
,
2
J V
V
V
M
h
−
+
z
z
matrix element of both sides
] =
∆
 gives 
 matrix element when we take 
,
V
J V
V
M
h
−
−
−
z
matrix element of both sides
] = −
[
2
= −
2

 selection rule for both sides

,
J V
−
+

RHS

∆
M

  A.

=

0

h

=

0

= −
1

 

JM

)

−

1

 

V
h z
+
1
V
J M JM
z
(

+

+
1
J M

−
J V V J
−
+
+
+
+
1
1
J
J M J M
−
+
−
1
V
J M JM
+
[
) −
+(
+(
)
1
2
J
J
h
[
) −
+(
(
1
M M
J J
h

1

JM

+

(
M M
]]
)
/
1 2
1

−

=

=

−

=

−

LHS

  

+

1

V
+

JM

+
1
J M
−
1
]
)
1 2
/
1

J

−

JM

+
1
J M

+

1

V
+

JM

+
1
J M JMV
+

−

1

    rearrange this and use 
V+

 recursion rule from above

[
(
=
( )
C J
h
+
= −
2

+
J M
[
(
+
( )
C J
J M
+

+

h

+

) −
(
1
J M
) −
(
+
1
J M

]
[
)
+(
/
1 2
1
J M
]
)
+
/
1 2
1

LHS

  

) −

(

+
J M

+

2

]
)
1

updated November 4, 2002

5.73 Lecture #27
RHS = LHS
[
(
+
=
V
( )
1
J M JM C J
+
z

+
J M

+

) −
(
1
J M

+

]
)
1 1 2
/

27 - 11

[

B.
            

RHS

] =
,
J V
−
z
=
=
−

LHS

h

=

  

h

+
  J M
1

h

 
V
−
−
+
1
J M
−
+
1
J M
−
+
1
J M
[
(
( )
C J
+
−

JM

V
−

1

take 

+
1
J M

−

1L

JM

1

J

1

−

V
−

JM
+
+
V
1
1
J M J M JM
z
−
−
1
JM
) −
(
2
J M
[
(
+
−
( )
C J
J M
+

J
1
−
]
)
1 1 2
/
) −
(
J M

JM
+

JM

+

+

2

V
1
z
−
J M
= +

]
)
1 1 2
/

VERY COMPLICATED AND TEDIOUS ALGEBRA

updated November 4, 2002

