5.73 Lecture #18

18 - 1

Variational Method
(See CTDL 1148-1155, [Variational Method]
252-263, 295-307[Density Matrices])

Last time:

Quasi-Degeneracy → Diagonalize a part of infinite H
* sub-matrix : H(0) + H(1)
* corrections for effects of out-of-block elements:  H(2)
(the Van Vleck transformation)
*diagonalize Heff =H(0) + H(1) + H(2)
coupled H-O’s 2 : 1 (ω1≈2ω2) Fermi resonance example: polyads
1. Perturbation Theory vs. Variational Method
2. Variational Theorem
3. Stupid nonlinear variation
4. Linear Variation → new kind of secular Equation
5. Linear combined with nonlinear variation
6. Strategies for criteria of goodness — various kinds of variational
calculations

1. Perturbation Theory vs. Variational Method

Perturbation Theory in effect uses ∞ basis set
goals:  parametrically parsimonious fit model, Heff
fit parameters (molecular constants) ↔ parameters that define V(x)
(1)
H nk
< 1 — errors less than this “mixing
(0 ) − E k
(0 )
angle” times the  previous order
E n
non–zero correction term
(n is in-block, k is out-of block) because diagonalization is ∞ order
(within block).

order - sorting

Variational Method

best possible estimate for lowest few En, ψn (and properties derivable from
these) using finite basis set and exact form of H.

modified 10/9/02 10:21 AM

5.73 Lecture #18

18 - 2

Vast majority of computer time in Chemistry is spent in variational calculations
Goal is numbers.  Insight is secondary.
“Ab Initio” vs. “semi-empirical” or  “fitting”
[intentionally bad basis set:  Hückel, tight binding –
qualitative behavior obtained by a fit to a few microscopic–like
control parameters]

α≡

φA φ =

the variational Theorem

2. Variational Theorem
not necessarily
any observable
normalized
If φ is approximation to eigenfunction of  ˆA
belonging to lowest eigenvalue a0 ,  then
φA φ
≥ a 0
φ φ
PROOF:  eigenbasis (which we do not know – but know it must exist)
A n = a n n
expand φ in eigenbasis of A, exploiting completeness
∑
n n φ
φ =
n
completeness
∑
n A ′n
′n
an δ
n ,
nn′
eigenbasis
∑
∑
φ φ = φ n n φ
φ n
=
n
n
a n n φ 2
∑
φA φ
n
′n φ 2
φ φ
∑
′n
subtract a 0  from both sides
(
) n φ 2
∑
a n − a 0
n
′n φ 2
∑
′n

α− a 0 =

φ n

2

a n

∑
n

2

′n φ =

φ n

α≡

=

all terms in both sums are ≥ 0

≥ 0

again, all terms in
both sums are ≥ 0

modified 10/9/02 10:21 AM

5.73 Lecture #18
18 - 3
because, by definition of a0, an ≥ a0 for all n and all terms in sum are ∴ ≥ 0.


 ∴ α ≥ a0.
but useless because we
 QED
can' t know a n  or  n φ


It is possible to perform a variational calculation for any A, not limited to H.

3. Stupid Nonlinear Variation
Use the wrong functional form or the wrong variational criterion to get poor
results — illustrates that the variational function must have sufficient
flexibility and the variational criterion must be as it is specified in the
variational  theorem, as opposed to a clever shortcut.

The H atom Schr. Eq. (l = 0)
H = − 1
− 1
1
∂
2 ∂
2
2
∂r
∂r
r
r

r

T

V

and we know 






ψ

1
s

E
1
s

but try 

r

φ

=

r

( )
r
= −
1 2
/

= π

−
1 2
/

−

r

e

1
s

au

[
1

=

 

au

219475

cm

]

−
1

=

3

2

(

ξ

π

)
ξ
r e

]
[
normalized
1 2
/
for all ξ
 ξ is a scale factor that controls overall size of φ(r)

ξ
r

−

[actually this is the form of ψ2p(r)] which is necessarily orthogonal to ψ1s!
)
(

φ
( )
0

−
1 2
/

= π

but

ψ

=

0

01
( )
s

 STUPID!

ε=

φH φ
φ φ

= 4
3




ξ2 − 3ξ


8

skipped a lot
of algebra

minimize  :ε

ε
ξ

d
d

=

0

ξ

min

=

3 2
/

→

ε

min

= −
3 8
/

 

au

FAILURE!



c f
. .  

t
E
he true values:    1

s

= −
/
1 2

au E
,  

2

s

= −




au

1
8

modified 10/9/02 10:21 AM

5.73 Lecture #18
Try somethng clever (but lazy):
What is the value of ξ that maximizes 〈φ1s〉?
)
=(
φ ξ
3 2 1
/
s
→ =
0 9826
.
C
1
s

ξ
for the best variational 

3 2
,  
/
C
1
s
=
ξ
ξ
5 3
/

 
if we maximize 
C wrt
1
s

 :  

≡

=

.  

18 - 4

=

0 9775
.
better?

but ε  = –0.370 results, a poorer bound than ξ = 3/2 → ε = –0.375
φ
*  need flexibility in 
ε
d
ξ
d
This was stupid anyway because we would never use the
variational method when we already know the answer!

 by employing an alternative variational strategy

* can©t improve on 

φ=

4. Linear Variation → Secular Equation
N∑
c nχn
n =1
χn H χ ′n
χn χ ′n

= H n ′n
= Sn ′n

KEY
TOPIC for
this lecture

overlap integrals
(non-orthogonal basis sets are often
convenient)

ε

=

φ
φ
H
φ φ

=

∑
′
,
n n
∑
,
m m

′

c c H
′
n n

′

nn

c c S
′
m m mm

′

rearrange this equation

∑
ε cm c ′m Sm ′m
′m
m,

=

∑
c n c ′n H n ′n
′n
n,

ε
to find minimum value of  ,
∂
∂
c

take 

 for each   and require that
j

∂ε
∂c j

= 0  for each j

j
linear variation!

because we are seeking to minimize ε with respect to each cj.
Find the global minimum of the ε(c1,c2,…cN) hypersurface.
∂
∂
c

 are those that include c

j

.

the only terms that survive 

j

modified 10/9/02 10:21 AM

5.73 Lecture #18
(
) =
(
)
∑ H jn + H nj
∑
ε cm
Smj + S jm
c n
n
m
} are real
if  χn{
Sij = S ji ,   H ij = H ji
(
N∑ H jn − εS jn
0 =
c n
n =1
one such equation for each j (same set of unknown {cn})

)

18 - 5

These are all of the surviving terms
(i.e. those that include j).  Each j term
appears twice in both sums, once as a
bra and once as a ket.

N linear homogeneous equations in N unknown cn’s
Non trivial {cn} only if |H – εS| = 0
(Not same form as |H – 1E| = 0)

The result is N special values of ε that satisfy this equation.
CTDL show:  all N εn values are upper bounds to the lowest N En’s
(provided that
  and all {φn}’s are othogonal!
they belong to
different
values of En)

How to solve |H – εS| = 0

1. Diagonalize S
=
˜
†
U SU S

ijδ
=S
˜
s
ij
i
(orthogonalize {χ} basis)

2. Normalize  ˜S
˜S ˜S( )−1/ 2 = 1 ≡ S
˜S( )−1/ 2
≈
= T†ST
−1/ 2
where   T = US
3 diagonal
matrices

(
) =
/ ≤
−
ƒ
1 2
S

−
ƒ
/
1 2
S

=







−
/
1 2
s
1
0
0

0
−
/
1 2
s
2
0


0


0

O


unitary
This is not an orthogonal transformation, but it does not destroy
orthogonality because each function is only being multiplied by a
constant.

modified 10/9/02 10:21 AM

5.73 Lecture #18

18 - 6

3. Transform H to orthonormalized basis set
)
(
≈
=
ƒ
ƒ
≤
U U S
H S
H
T

−
/
1 2

−
/
1 2

T†

U diagonalizes S
not H

new secular equation

≈
H

≈
H

= 0

≈
− εS
− ε1 = 0

but

≈
S

= 1

≈
usual H

diagonalized by
usual  procedure!

5. Combine Linear and Nonlinear Variation

Basis set:

typically done in ab initio electronic structure calculations
(
)
χ ξ
r
n
n
∑
ψ
=
c
n
(
ξ ξ
,
n

linear variation where εn is a radial scale factor
)
(
χ ξ
n n
)
,

nonlinear variation
)
ξ ξ
,
n

H

(

S
nn

nn

r

n

′

n

′

n

′

′

0.
1.
2.

)

pick arbitrary set of  ξi{ }
)  &   Sij ξi , ξj
(
(
calculate all H ij ξi , ξj
Solve  H - εS = 0
→
˜
S
S
( )
−
/
1 2
˜
S
≈
→
H H

S
diagonalize 

(normalize)

b.

.
a

.
c

(orthogonalize)

d

.

diagonalize 

≈
H

nonlinear variation begins – find global minimum of εlowest
with respect to each ξi

modified 10/9/02 10:21 AM

18 - 7

3
.
4
.
5
.

5.73 Lecture #18
→ =
ξ
ξ
ξ
ξ
+
δ
0
( )
0
( )
1
( )
 
 
change 
from
1
1
1
1
χ
H
S
recalculate all integrals in 
 and 
 involving 
1
{ }
ε
=
ε
H S
.
 to obtain a new set of 
0
Solve
 
-
i
ε
Pick lowest 
.
∂
ε
lowest
∂
ξ

calculate

6
.

=

ε

old
lowest
ξ
0
( )
1

−
−

ε
new
lowest
ξ
1
( )
1

i

1

 

7.

repeat #3 – 6 for each ξi (always looking only at lowest εi)
This defines a gradient on a multidimensional ε(ξ1,…ξN) surface.  We
seek the minimum of this hypersurface. Take a step in direction of
steepest descent by an amount determined by |∂ε/∂ξsteepest| (small slope,
small step; large slope, large step).

This completes 1st iteration.  All values of {ξi}are improved.

8.

Return to #3, iterate #3-7 until convergence is obtained.

Nonlinear variations are much slower than linear variations.
Typically use ENORMOUS LINEAR {χ} basis set.
Contract this basis set by optimizing nonlinear parameters (exponential scale
factors) in a SMALL BASIS SET to match the lowest {φ}’s that had initially
been expressed in large basis set.

modified 10/9/02 10:21 AM

5.73 Lecture #18

6. Alternative Strategies

18 - 8

* rigorous variational minimization of Elowest: “ab initio”
* constrain variational function to be orthogonal to specific subset of functions
e.g. orthogonal to ground state – to get variational convergence.
Applies only to higher members of specific symmetry class
orthogonal to core:  frozen-core approximation.
“Pseudopotentials” (use some observed energy levels to
determine Zeff(r) of frozen core)

or

* least squares fitting

minimize differences between a set of measured energy levels (or other
properties) and a set of computed variational eigen-energies (or other
properties computed from variational wavefunctions).
{
}
{
} ↔ parameters in Heff
observed E n
molecular constants
⇓
experimental ψ ‘s in finite
variational basis set

* semi-empirical model

ˆH
replace exact     by a grossly simplified form and restrict basis set to a simple
form too.
Then adjust parameters in H to match some observed pattern of energy
splittings.  Use parameters to predict unobserved properties or use values of
fit parameters to build insight.

modified 10/9/02 10:21 AM

