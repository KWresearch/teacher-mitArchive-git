5.73 Lecture #11

11 - 1
Eigenvalues, Eigenvectors, and Discrete Variable Representation (DVR)

Last time:
bra

should have read CDTL pages 94-144
…(
*
a
1


a
1


M





ket

a

)
φ

a

*
N

ψ
 in 

=

1

{ }
φ
 basis set



0



M















0
ψ
φ ψ
j

a
a
2
M
M

1
M

=

a

N

i

φ









φ

ψ

i

=

a

j

φ

φ

N
×
 matrix
N N
)
(

 #

0

complex










O

= ∑
k

k k

=

1

1











1

1

0

at end of lectu re
φ i AB φ j =

∑
φ i A φ k φ k
1 24 34 B φ j
k
1
= AB(
)
∑
= A ikBkj
k

ij

 

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 2

What is the connection between the Schrödinger and Heisenberg representations?

ψ

i

x

0

=
x
( )
= (
δ

ψ

x

x x
,

0

i
)

eigenfunction of x with eigenvalue x0

Using this formulation for ψi(x), you can go freely (and rigorously) between the
Schrödinger and Heisenberg approaches.
∑
∫
1 =
k

x x dx

k k

=

Today:

eigenvalues of a matrix – what are they?  how do we get them? 
(secular equation).  Why do we need them?

eigenvectors – how do we get them?

Arbitrary V(x) in Harmonic Oscillator Basis Set (DVR)

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

Schr. Eq. is an eigenvalue equation
Âψ = aψ

11 - 3

in matrix language
A ψ

i

=

ψ

i

a

i

=

A








a

1

0

a

2

O

0

a

N








ψ

ψ

1

=









1

0


0


M

ψ

1A ψ
satisfies 

= a 1

ψ

1

but that is the eigen-basis representation – a special representation!
What about an arbitrary representation?  Call it the φ representation.

* * *  







c i
i





∑
∑
N
 =



A
a




=
i
i
1
A
 as transformation on each 

c i
i

φ

φ

* * *

φ

i

Eigenvalue equation

{ }
N unknown coefficients  c
i
{ }
 and a ?
How to determine  c
i

=

 to N
1
i
Secular Eqn.  derive it.

first,  left multiply by 

jφ

∑
i

A

=

    0

=

c

φ
c
ji
i
∑
N
=
i
1

∑
i

a
[
A

i

]

φ
ji

−

δ
a

ij

c j i
i

=

a

∑
i

δ
i

c

ij

one equation

N unknowns

next,  multiply original equation by  kφ
[
]
∑ c A
N
i
=
i
1
etc. for all 

δ
a

φ
ki

   

=

−

0

ik

.

a

nother
 equation

φ
N linear homogeneous equations in N unknowns – Condition that a nontrivial
(i.e. not all 0’s) solution exists is that determinant of coefficients = 0.

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11
A11 − a
A 21

0 =

11 - 4

A12 … A1N
A 22 − a

O

ANN − a

Nth order equation – as many as N different values of a satisfy this equation (if
fewer than N, some values of a are “degenerate”). Does everyone know how to
expand a determinant?

{ai} are the eigenvalues of A

(same as what we would have obtained by
solving differential operator eigenvalue
equation)

} such that
{
If we know the eigenvalues,  then we can find the N  ψ i
∑
expand the eigenbasis in
(computationally convenient) basis
j

c j
j

=

ψ

i

φ

ψ

ψ

A

j

=

δ
j

a

ij

ψ

ψ

A

=

i






0
a

N

O







1
0
0
M

a
1
0







ψ

A

ψ

1

=

a
1

But we generally start with Aφ in nondiagonal form

computer


1.


2.

3.




φ
=
≤T A T A
transform to diagonal form by 
the diagonal elements are eigenvalues
the diagonalizing transformation is composed of eigenvectors,  
column by column of  ≤
.
T

ψ

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

Hermitian Matrices

11 - 5

† = A ji
A = A†
*
A ij
(can use this property to show that all expectation values of A are real)

These matrices can be “diagonalized” (i.e. the set of all eigenvalues can be
found) by a unitary transformation.

− =
1

T

≤

T

diagonalization

≤A

T

φ

T

=

not diagonal

a








a

1

0

unitary matrix

0






O

≡

2

A

a N

ψ

≤

φ

φ
≤
T A TT
diagonal Aψ
Eigenvector
expressed in
φ basis set

j

ψ

diagonal

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 6

eigenvector

≤

T

φ

i

=

≤

T

i-th
position

















0
M
1
M
0

φ

=















≤
T
1
i
≤
T
2
i
M
≤
T
Ni

φ

=

ψ

i

=

















0
M
1
M
0

ψ

i-th column
 of T†

←

i - th position

suppose we apply

ψ

A

ψ

i

=

ψ

A

i-th

















0
M
1
M
0

ψ

=

















0
M
a
i
M
0

ψ

=

a

i

















0
M
1
M
0

ψ

RECAPITULATE:
Start with arbitrary basis set 
φ
A
 :  Not Diagonal,  but basis set was computationally convenient.
Construct 


a
0
0
1


 =
O



≤

φ
≤
T A T
T
 (computer) that causes 
Find 

T
Eigenstates (eigenkets) are columns of 

a
0
N
φ
 in 
 basis set.

φ

=

ψ

A

Columns of T are the linear c ombination of eigenvectors that
correspond to ea ch basis state.  U seful for “brigh t state” calculations .

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 7

Can now solve many difficult appearing problems!
Start with a matrix representation of any operator that is expressable as a
function of a matrix.

e g
.

.

−

h
)/

−H(
i
t

t

0

e
propagator

,

x
( )
f
potential curve

prescription example

f

x
( )

=

†

)x123
(
†
T T T T
f
diagonalize x – so f( ) is
applied to each diagonal
element

0






O

x

2

x
1

x

N

0

O

(
f x

N






)















†
T xT

=

) =

†
T xT

(

f

  

0
(
f x
1

)

(
f x

2

)

0

Then perform inverse transformation T f(T† x T)T† – undiagonalizes matrix, to
give matrix representation of desired function of a matrix.
Show that this actually is valid for simple example

f (x) = x N
[
(
f (x ) = T T†xT
[
1
= T T†x NT

)L T†xT
) T†xT
(
(
]T† = x N
2
N

]T†
)

apply prescription

get expected result

general proof for arbitrary f(x) → expand in power series.  Use previous result
for each integer power.

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 8

John Light:  Discrete Variable Representation (DVR)
General V(x) evaluated in Harmonic Oscillator Basis Set.
we did not do H-O yet, but the general formula for all of the nonzero matrix
elements of x is:

n x n + 1 =





h
2ωµ

1/ 2




(

)1/ 2
n + 1

ω = k µ(

)1/ 2

(

infinite dimension matrix

)

x =





h
2ωµ

1/ 2




2 =

x






h

2ωµ

















1
0
2
0
0
0
0
0
0

0
3
0
6
0
0
0
0
0

2
0
5
0
12
0
0
0
0
























0
1
0
M
M
0
6
0
7
0

0
0
0

1
0
2
M
M

0
0
12
0
9
0

0
0

0
11
0

0

0
13
0









=

0 L L
2 L L
0
3
0
3
0
4
0
4
M
0
0
0
0
0
0
0
0
0

0
0
0

0
0
0
0
0
0











0

15 O



O O

0 0 0 0 0




0 0 0 0 0


0 0 0 0 0




0 0 0 0 0


0 0 0 0 0


[CARTOON]















etc. matrix multiplication
to get matrix for f(x) diagonalize e.g., 1000 × 1000 (truncated) x matrix that was
expressed in harmonic oscillator basis set.

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 9

x =
†
T T








V
( )
x

x

=

x
1
0
0
0







0
x
2
0
0

0
0
O

0

x

0
0
0

(
V x
0
0
0

)

1

2

0
(
V x
0
0








0

x

1000
0
0
O

)

0
0
0
(
V x





)



x

1000







full
complicated
matrix

×
1000
1000
1000
 
 
H O−

V
( )
x

−
H O

=

TV
( )
x

x

†
T

=








2
H = p
2µ

+ V(x)

diagonalized-x basis
{xi} are eigenvalues.
They have no
obvious physical
significance.

next transform back
from x-basis to
H-O basis set

T was determined
when x was
diagonalized

need matrix for p2, get it from p (the general formula for all non-zero
matrix elements of p)

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 10

same structure as x

n p n + 1 = − i




p = − i

h(ωµ )
2




1/ 2



1/ 2



(

0
− 1
0
0
0

h(ωµ )
)1/ 2
n + 1
2


0
0
0
1


0
0
0
2


− 2
0
0
0




0 O O O


0 O O O



2
0
−1
0
0

0 O 0
−3
0

2
0 O
−5
0


0 O O O O


0 O O O











p2 = − h(ωµ )


2




if

H =

p2
2µ
H = hω
4

+ 1
2

kx2





0
2 0
0 6
0
0 0 10
0 0
0




0
0
0
14

1
2




k = 1
2





= hω

ω 2µ




1 / 2
0
0
0

0
3 / 2
0
0


0
0

0
0
5 / 2
0


0 O

but for arbitrary V(x), express H in HO basis set,

=

H

HO

2
p
HO
µ
2

+

V x
( )
HO
TV(x)xT†

†
eigenvalues obtained by S H S
HO

  

=






E
1
0
0

0
O

0






0
0
E

N

columns of S† are eigenvectors  in HO basis  set!

updated 10/1/0 2 1 1:00  AM

5.73 Lecture #11

11 - 11

1. Express matrix of x in H-O basis (automatic; easy to program a
computer to do this), get xHO.
2. Diagonalize xHO.  Get xx and T.
3. Trivial to write V(x)x as V(x i) = V(x)x in x basis
4. Transform V(x)x back to V(x)HO
5. Diagonalize HHO.

Solve many V(x) problems in this basis set.

1000 × 1000 T matrix diagonalizes x ⇒ 1000 xi’s
Save the T and the {xi} for future use on all V(x) problems.

To verify convergence, repeat for new x matrix of dimension 1100 x 1100.  There
{ }
{ }
will be no resemblance between
x
x
 and 
.
i
i

1000

1100

If the lowest eigenvalues of H (i.e. the ones you care about) do not change (by
measurement accuracy), converged!

Next:  Matrix solution of HO (no wave functions at all)
Start from Commutation Rule!

Then Perturbation Theory.

updated 10/1/0 2 1 1:00  AM

