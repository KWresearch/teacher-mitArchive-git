6.042/18.062J Mathematics for Computer Science 
Srini Devadas and Eric Lehman 

April 28, 2005 

Lecture Notes


Random Variables 
We’ve used probablity to model a variety of experiments, games, and tests.  Through­
out, we have tried to compute probabilities of events.  We asked, for example, what is the 
probability  of  the  event  that  you win  the Monty Hall  game?  What  is  the  probability  of 
the event that it rains, given that the weatherman carried his umbrella today? What is the 
probability of the event that you have a rare disease, given that you tested positive? 
But  one  can  ask more  general  questions  about  an  experiment.  How  hard will  it  rain? 
How  long will  this  illness  last?  How much will  I  lose playing 6.042 games all day?  These 
questions  are  fundamentally  different  and  not  easily  phrased  in  terms  of  events.  The 
problem  is  that  an  event  either  does  or  does  not  happen:  you  win  or  lose,  it  rains  or 
doesn’t,  you’re  sick  or  not.  But  these  new  questions  are  about  matters  of  degree:  how 
much, how hard, how  long?  To approach  these questions, we need a new mathematical 
tool. 

1  Random Variables 

Let’s begin with an example.  Consider the experiment of tossing three independent, un­
biased  coins.  Let  C  be  the  number  of  heads  that  appear.  Let  M  = 1 if  the  three  coins 
come up all heads or all tails, and let M  = 0 otherwise.  Now every outcome of the three 
coin ﬂips uniquely determines the values of C  and M . For example, if we ﬂip heads, tails, 
heads, then C  = 2 and M  = 0.  If we ﬂip tails, tails, tails, then C  = 0 and M  = 1.  In effect, 
C  counts the number of heads, and M  indicates whether all the coins match. 
Since  each outcome uniquely determines C  and M , we  can  regard  them  as  functions 
mapping outcomes to numbers.  For this experiment, the sample space is: 
S  = {HHH,  HH T ,  H T H,  H T T ,  T HH,  T H T ,  T T H,  T T T } 
Now C  is a function that maps each outcome in the sample space to a number as follows: 

C (HHH ) = 3 
C (T HH ) = 2 
C (HH T ) = 2 
C (T H T ) = 1 
C (H T H ) = 2 
C (T T H ) = 1 
C (H T T ) = 1 
C (T T T ) = 0 
Similarly, M  is a function mapping each outcome another way: 

M (HHH ) = 1 
M (HH T ) = 0 
M (H T H ) = 0 
M (H T T ) = 0 

M (T HH ) = 0 
M (T H T ) = 0 
M (T T H ) = 0 
M (T T T ) = 1 

2 

Random Variables 

The functions C and M  are examples of random variables.  In general, a random variable 
is  a  function  whose  domain  is  the  sample  space.  (The  codomain  can  be  anything,  but 
we’ll usually use a subset of the real numbers.)  Notice that the name “random variable” 
is a misnomer; random variables are actually functions! 

1.1  Indicator Random Variables 

An indicator random variable (or simply an indicator or a Bernoulli random variable) is 
a  random variable  that maps  every outcome  to  either  0 or  1.  The  random variable M  is 
an example.  If all three coins match, then M  = 1; otherwise, M  = 0. 
Indicator  random  variables  are  closely  related  to  events.  In  particular,  an  indicator 
partitions the sample space into those outcomes mapped to 1 and those outcomes mapped 
to 0.  For example, the indicator M  partitions the sample space into two blocks as follows: 
HHH ��  T T T  HH T  H T H  H T T  �� T HH  T H T  T T H � 
� 
� 
� 
M  = 1 
M  = 0 
In  the  same way,  an  event  partitions  the  sample  space  into  those  outcomes  in  the  event 
and  those  outcomes not  in  the  event.  Therefore,  each  event  is naturally  associated with 
a  certain  indicator  random  variable  and  vice  versa:  an  indicator  for  an  event  E  is  an 
indicator random variable that is 1 for all outcomes in E and 0  for all outcomes not in E . 
Thus, M  is an indicator random variable for the event that all three coins match. 

1.2  Random Variables and Events 

There is a strong relationship between events and more general random variables as well. 
A  random variable  that  takes  on  several values partitions  the  sample  space  into  several 
blocks.  For example, C partitions the sample space as follows: 
T T H  T H T  H T T �  T HH  H T H  HH T �  HHH 
� �� �
� 
�� 
� 
�� 
� �� � 
T T T 
C  = 1 
C  = 2 
C  = 3 
C  = 0 
Each block is a subset of the sample space and is therefore an event.  Thus, we can regard 
an equation or inequality involving a random variable as an event. For example, the event 
that C  = 2  consists of the outcomes T HH , H T H , and HH T .  The event C  ≤  1  consists of 
the outcomes T T T , T T H , T H T , and H T T . 
Naturally  enough,  we  can  talk  about  the  probability  of  events  deﬁned  by  equations 
and inequalities involving random variables.  For example: 

Pr  (M  = 1)   = Pr   (T T T ) +  Pr  (HHH ) 
1
1 
= + 
8
8 
1 
4 

= 

Random Variables 

3 

As another example: 
Pr (C  ≥ 2) =  Pr (T HH ) + Pr (H T H ) + Pr (HH T ) + Pr (HHH ) 
1
1
1
1 
= + + +  
8
8 
8
8
1 
2 
This  is  pretty  wild;  one  normally  thinks  of  equations  and  inequalities  as  either  true  or 
false.  But when variables are replaced by random variables, there is a probability that the 
relationship holds! 

= 

1.3  Conditional Probability 

Mixing  conditional probabilities  and  events  involving  random variables  creates no new 
difﬁculties.  For example, Pr (C  ≥ 2 M  =  0) is  the probability  that at  least  two coins are 
|
heads (C  ≥  2), given that not all three coins are the same (M  =  0).  We can compute this 
probability using the deﬁnition of conditional probability: 
Pr (C  ≥ 2 ∩ M  =  0) 
Pr (C  ≥ 2 M  =  0) = 
| 
Pr (M  =  0) 
Pr ({T HH, H T H, HH T }) 
Pr ({T HH, H T H, HH T , H T T , T H T , T T H }) 
3/8 
6/8 
1 
= 
2 
The expression C  ≥ 2 ∩ M  =  0 on the ﬁrst line may look odd; what is the set operation ∩
doing between an  inequality and an equality?  But recall  that,  in  this context, C  ≥  2 and 
M  =  0 are events, which sets of outcomes.  So taking their intersection is perfectly valid! 

= 

= 

1.4  Independence 

The notion of  independence  carries over  from  events  to  random variables as well.  Ran­
dom variables R1  and R2  are independent if 
Pr (R1  =  x1  ∩ R2  =  x2 ) =  Pr (R1  =  x1 ) · Pr (R2  =  x2 ) 
for all x1  in the codomain of R1  and x2  in the codomain of R2 . 
As with events, we can formulate independence for random variables in an equivalent 
and perhaps more intuitive way: random variables R1  and R2  are independent if and only 
if 
Pr (R1  =  x1  | R2  =  x2 ) =  Pr (R1  =  x1 ) or  Pr (R2  =  x2 ) =  0 

4 

Random Variables 

for all x1  in  the codomain of R1  and x2  in  the codomain of R2 .  In words,  the probability 
that R1  takes on a particular value is unaffected by the value of R2 . 
As  an  example,  are  C  and  M  independent?  Intuitively,  the  answer  should  be  “no”. 
The  number  of  heads,  C ,  completely  determines whether  all  three  coins match;  that  is, 
whether M   = 1. But to verify this intuition we must ﬁnd some x1 , x2  ∈ R such that: 
Pr  (C =  x1  ∩ M  =  x2 )  = Pr   (C =  x1 ) · Pr  (M  =  x2 ) 
One appropriate choice of values is x1  = 2  and x2  = 1.  In that case, we have: 
· 
Pr  (C = 2   ∩ M  = 1)  = 0 
Pr  (C = 2)  · Pr  (M  = 1) = 
3 1 
4 
8 

but 

= 0 

The notion of independence generalizes to a set of random variables as follows.  Ran­
dom variables R1 , R2 , . . . , Rn  are mutually independent if 
Pr  (R1  =  x1  ∩ R2  = 
x2  ∩ · · · ∩ R
n  =  xn )
= Pr  (R1  =  x1 ) · Pr  (R2  =  x2 ) · · · Pr  (Rn  =  xn ) 
for all x1 , . . . , xn  in the codomains of R1 , . . . , Rn . 
A consequence of this deﬁnition of mutual  independence  is that the probability of an 
assignment  to  a  subset  of  the  variables  is  equal  to  the  product  of  the  probabilites  of  the 
individual assignments.  Thus,  for example,  if R1 , R2 , . . . , R100  are mutually independent 
random variables with codomain N, then it follows that: 
Pr  (R1  = 9   ∩ R7  =  84  ∩ R23   =  13)  = Pr   (R1  = 9)  · Pr  (R7  =  84)   · Pr  (R23  =  13)  
(This follows by summing over all possible values of the other random variables; we omit 
the details.) 

1.5  An Example with Dice 

Suppose  that we  roll  two  fair,  independent  dice.  The  sample  space  for  this  experiment 
consists of all pairs (r1 , r2 ) where r1 , r2  ∈  {1, 2, 3, 4, 5, 6}.  Thus, for example, the outcome 
(3, 5)  corresponds to rolling a 3 on the ﬁrst die and a 5 on the second.  The probability of 
·
each outcome in the sample space is 1/6 1/6  = 1/36  since the dice are fair and indepen­
dent. 
We can regard  the numbers  that come up on  the  individual dice as random variables 
D1  and  D2 .  So  D1 (3, 5)  = 3   and  D2 (3, 5)  = 5.  Then  the  expression  D1  +  D2  is  another 
random variable; let’s call it T  for “total”. More precisely, we’ve deﬁned: 

T (w) =  D1 (w) +  D2 (w) 

for every outcome w 
√
Thus,  T (3, 5)  =  D1 (3, 5)  +  D2 (3, 5)  = 3 +  5  = 8.  In  general,  any  function  of  random 
variables  is  itself a  random variable.  For example, 
D1  +  cos(D2 )  is a strange, but well­
deﬁned random variable. 

�
�
Random Variables 

5 

S (w) = 

� 
Let’s also deﬁne an indicator random variable S for the event that the total of the two 
dice is seven: 
if T (w)  = 7 
1 
if T (w) =�
7 
0 
So  S  is  equal  to  1  when  the  sum  is  seven  and  is  equal  to  0  otherwise.  For  example, 
S (4, 3)  = 1, but S (5, 3)  = 0. 
Now  let’s consider a couple questions about  independence.  First, are D1  and T  inde­
pendent?  Intuitively, the answer would seem to be “no” since the number that comes up 
on  the ﬁrst die strongly affects  the  total of  the  two dice.  But  to prove  this, we must ﬁnd 
integers x1  and x2  such that: 
Pr  (D1  =  x1  ∩ T  =  x2 )  = Pr   (D1  =  x1 ) · Pr  (T  =  x2 ) 
For example, we might choose x1  = 2  and x2  = 3.  In this case, we have 
Pr  (T  = 2  | D1  = 3)  = 0 
since the total can not be only 2 when one die alone is 3. On the other hand, we have: 
Pr  (T  = 2)  · Pr  (D1  = 3)  = Pr   ({1, 1}) · Pr  ({(3, 1),  (3, 2),  . . . ,   (3, 6)}) 
·
1
6 
36 
36 
So, as we suspected, these random variables are not independent. 
Are  S  and  D1  independent?  Once  again,  intuition  suggests  that  the  answer  is  “no”. 
The  number  on  the  ﬁrst  die  ought  to  affect  whether  or  not  the  sum  is  equal  to  seven. 
But  this  time  intuition  turns  out  to  be wrong!  These  two  random  variables  actually  are 
independent. 
Proving  that  two  random  variables  are  independent  takes  some  work.  (Fortunately, 
this is an uncommon task; usually independence is a modeling assumption.  Only rarely 
do  random  variables  unexpectedly  turn  out  to  be  independent.)  In  this  case,  we  must 
show that 
Pr  (S =  x1  ∩ D1  =  x2 )  = Pr   (S =  x1 ) · Pr  (D1  =  x2 )	
(1) 
for all x1  ∈ {0, 1} and all x2  ∈ {1, 2, 3, 4, 5, 6}.  We can work through all these possibilities 
in two batches: 

= 

= 0 

•	 Suppose that x1  = 1. Then for every value of x2  we have: 


Pr  (S = 1)   = Pr   ((1, 6),  (2, 5),  . . . ,   (6, 1))   = 

1

6 

Pr  (D1  =  x2 ) = Pr   ((x2 , 1),  (x2 , 2),  . . . ,   (x2 , 6))   = 
Pr  (S = 1  ∩ D1  =  x2 ) = Pr   ((x2 , 7  − x2 ))   = 

1 
36

·
Since 1/6 1/6  = 1/36, the independence condition is satisﬁed.


1 
6 

�
�
6	

Random Variables 
•	 Otherwise,  suppose  that  x1  = 0.  Then we have Pr  (S = 0)  = 1  − Pr  (S = 1)  = 5/6 
and Pr  (D1  =  x2 ) = 1/6   as before. Now the event 
S = 0  ∩ D1  =  x2 
consists of 5 outcomes: all of (x2 , 1),  (x2 , 2),  . . . ,  (x2 , 6)  except for (x2 , 7 − x2 ). There­
· 
fore,  the probability of  this event  is 5/36.  Since 5/6 1/6  = 5/36,  the  independence 
condition is again satisﬁed. 

Thus, the outcome of the ﬁrst die roll is independent of the fact that the sum is 7.  This 
is a strange, isolated result; for example, the ﬁrst roll is not independent of the fact that the 
sum is 6 or 8 or any number other than 7.  But this example shows that the mathematical 
notion of independent random variables— while closely related to the intutive notion of 
“unrelated quantities”— is not exactly the same thing. 

2  Probability Distributions 

A  random  variable  is  deﬁned  to  be  a  function whose  domain  is  the  sample  space  of  an 
experiment. Often, however, random variables with essentially the same properties show 
up in completely different experiments. For example, some random variable that come up 
in  polling,  in  primality  testing,  and  in  coin  ﬂipping  all  share  some  common  properties. 
If we  could  study  such  random  variables  in  the  abstract,  divorced  from  the  details  any 
particular  experiment,  then  our  conclusions  would  apply  to  all  the  experiments  where 
that  sort  of  random  variable  turned up.  Such  general  conclusions  could  be  very useful. 
There  are  a  couple  tools  that  capture  the  essential  properties  of  a  random  variable,  but 
leave other details of the associated experiment behind. 
The probability density function (pdf) for a random variable R with codomain V  is a 
function PDFR  :  V  →  [0, 1]   deﬁned by: 

PDFR (x)  = Pr  (R =  x)  
� 
A consequence of this deﬁnition is that 
PDFR (x) = 1 
x∈V 

since the random variable always takes on exactly one value in the set V . 

As an example, let’s return to the experiment of rolling two fair, independent dice. As 
before, let T  be the total of the two rolls.  This random variable takes on values in the set 
V  =  {2, 3, . . . , 12}. A plot of the probability density function is shown below: 

Random Variables


7 

6/36  6 

PDFR (x)

3/36 

2  3  4  5  6  7  8  9 10 11 12 
x ∈ V 

-

The  lump  in  the middle  indicates  that sums close  to 7 are  the most  likely.  The  total area 
of  all  the  rectangles  is  1  since  the  dice  must  take  on  exactly  one  of  the  sums  in  V  = 
{2, 3, . . . , 12}. 
A closely­related idea is the cumulative distribution function (cdf) for a random vari­
able R. This is a function CDFR  :  V  →  [0, 1]  deﬁned by: 
CDFR (x)  = Pr  (R ≤ x)  

As an example, the cumulative distribution function for the random variable T  is shown 
below: 

1  6 

CDFR (x) 

1/2  

0 

2  3  4  5  6  7  8  9  10  11  12 
x ∈ V 

-

The height of the i­th bar in the cumulative distribution function is equal to the sum of the 
heights  of  the  leftmost  i bars  in  the  probability  density  function.  This  follows  from  the 
deﬁnitions of pdf and cdf: 
� � 
CDFR (x) = Pr  (R ≤ x)  
= 
Pr  (R =  y) 
y≤x 
PDFR (y) 
y≤x 
In  summary,  PDFR (x)  measures  the  probability  that  R  =  x  and  CDFR (x)  measures 
the  probability  that  R  ≤  x.  Both  the  PDFR  and  CDFR  capture  the  same  information 

= 

8 

Random Variables 

about the random variable R— you can derive one from the other— but sometimes one is 
more convenient.  The key point here  is  that neither  the probability density  function nor 
the cumulative distribution  function  involves  the sample space of an experiment.  Thus, 
through these functions, we can study random variables without reference to a particular 
experiment. 
For  the  remainder  of  today, we’ll  look  at  three  important  distributions  and  some  ap­
plications. 

2.1  Bernoulli Distribution 

Indicator  random  variables  are  perhaps  the  most  common  type  because  of  their  close 
association with events. The probability density function of an indicator random variable 
B is always 

PDFB (0)   =  p 
PDFB (1)   = 1  − p 

where 0   ≤ p ≤ 1. The corresponding cumulative ditribution function is: 

CDFB (0) =  p 
CDFB (1) = 1 

This  is  called  the  Bernoulli  distribution.  The  number  of  heads  ﬂipped  on  a  (possibly 
biased) coin has a Bernoulli distribution. 

2.2  Uniform Distribution 

A random variable that takes on each possible values with the same probability is called 
uniform.  For  example,  the  probability  density  function  of  a  random  variable  U  that  is 
uniform on the set {1, 2, . . . , N } is: 

PDFU (k) = 

And the cumulative distribution function is: 

CDFU (k) = 

1
N 

k
N 

Uniform distributions come up all the time.  For example, the number rolled on a fair die 
is uniform on the set {1, 2, . . . , 6}. 

Random Variables 

2.3  The Numbers Game 

9 

Let’s play a game!  I have two envelopes. Each contains an integer in the range 0, 1, . . . , 100, 
and the numbers are distinct. To win the game, you must determine which envelope con­
tains the larger number.  To give you a ﬁghting chance, I’ll let you peek at the number in 
one envelope selected at random.  Can you devise a strategy that gives you a better than 
50% chance of winning? 
For example, you could  just pick an evelope at random and guess that  it contains the 
larger number. But this strategy wins only 50% of the time. Your challenge is to do better. 
So you might try to be more clever.  Suppose you peek in the left envelope and see the 
number 12.  Since 12 is a small number, you might guess that that other number is larger. 
But perhaps I’m sort of tricky and put small numbers in both envelopes. Then your guess 
might not be so good! 
An  important  point  here  is  that  the  numbers  in  the  envelopes  may  not  be  random. 
I’m  picking  the  numbers  and  I’m  choosing  them  in  a  way  that  I  think  will  defeat  your 
guessing  strategy.  I’ll  only  use  randomization  to  choose  the  numbers  if  that  serves  my 
end: making you lose! 

2.3.1  Intuition Behind the Winning Strategy 

Amazingly,  there  is  a  strategy  that wins more  than  50%  of  the  time,  regardless  of what 
numbers I put in the envelopes! 
Suppose  that  you  somehow  knew  a  number  x  between my  lower  number  and  higher 
numbers.  Now you peek  in  an  envelope  and  see  one  or  the  other.  If  it  is bigger  than x, 
then you know you’re peeking at  the higher number.  If  it  is  smaller  than x,  then you’re 
peeking  at  the  lower  number.  In  other  words,  if  you  know  an  number  x  between  my 
lower and higher numbers, then you are certain to win the game. 
The only ﬂaw with this brilliant strategy is that you do not know x. Oh well. 
But what  if you  try  to guess x?  There  is  some probability  that you guess  correctly.  In 
this  case,  you  win  100%  of  the  time.  On  the  other  hand,  if  you  guess  incorrectly,  then 
you’re  no worse  off  than  before;  your  chance  of winning  is  still  50%.  Combining  these 
two cases, your overall chance of winning is better than 50%! 
Informal arguments about probability, like this one, often sound plausible, but do not 
hold up under close scrutiny.  In contrast, this argument sounds completely implausible— 
but is actually correct! 

2.3.2  Analysis of the Winning Strategy 
For generality, suppose that I can choose numbers from the set {0, 1, . . . , n}. Call the lower 
number L and the higher number H . 

10 

Random Variables 

Your goal is to guess a number x between L and H . To avoid confusing equality cases, 
� 
� 
you select x at random from among the half­integers: 
1
2

, . . . , n −

1 
2

1 
2 

, 1 

, 2 

1
2

But what probability distribution should you use? 
The uniform distribution turns out to be your best bet. An informal justiﬁcation is that 
2  — then I’d always

if I ﬁgured out that you were unlikely to pick some number— say 50
 1 
put 50 and 51 in the evelopes.  Then you’d be unlikely to pick an x between L and H and 
would have less chance of winning. 
After you’ve selected the number x, you peek into an envelope and see some number 
p.  If  p > x,  then you guess  that you’re  looking  at  the  larger number.  If  p < x,  then you 
guess that the other number is larger. 
All that remains is to determine the probability that this strategy succeeds. We can do 
this with the usual four­step method and a tree diagram. 
Step  1:  Find  the  sample  space.  You  either  choose  x too  low  (< L),  too  high  (> H ),  or 
just right  (L < x < H ).  Then you either peek at  the  lower number  (p =  L) or  the higher 
number (p =  H ). This gives a total of six possible outcomes. 

Step  2:  Deﬁne  events  of  interest.  The  four  outcomes  in  the  event  that  you  win  are 
marked in the tree diagram. 
Step 3:  Assign outcome probabilities.  First, we assign edge probabilities.  Your guess x 
is too low with probability L/n, too high with probability (n − H )/n, and just right with 
probability  (H − L)/n.  Next,  you peek at either  the  lower or higher number with equal 
probability. Multiplying along root­to­leaf paths gives the outcome probabilities. 
Step  4:  Compute  event probabilities.  The probability of  the  event  that you win  is  the 

x just right1/21/21/21/21/21/2L/n(H−L)/n(n−H)/nchoice of x# peeked atresultprobabilitywinwinx too highx too lowwinlosewinloseL/2nL/2n(H−L)/2n(H−L)/2n(n−H)/2n(n−H)/2np=Hp=Lp=Hp=Lp=Hp=LRandom Variables 

11 

sum of the probabilities of the four outcomes in that event: 

H  − L
2n 

n  − H 
2n 

+ 

+

Pr  (win) = 

H  − L 
L
+  
2n 
2n 
1  H  − L 
= + 
2
2n 
+≥ 
1
2

1 
2n 

The ﬁnal  inequality  relies on  the  fact  that  the higher number H  is at  least 1 greater  than 
the lower number L  since they are required to be distinct. 

Sure  enough,  you  win  with  this  strategy  more  than  half  the  time,  regardless  of  the 
numbers  in  the  envelopes!  For  example,  if  I  choose  numbers  in  the  range  0,  1, .  .  .  ,   100, 
then you win with probability at  least  1  + 
= 50.5%.  Even better,  if  I’m allowed only 
1
200 
2 
numbers  in  the  range  range 0, .  .  .  ,  10,  then your probability of winning  rises  to 55%!  By 
Las Vegas standards, those are great odds! 

2.4  Binomial Distribution 

Of  the more  complex  distributions,  the  binomial  distribution  is  surely  the most  impor­
tant  in  computer  science.  The  standard  example  of  a  random  variable  with  a  binomial 
distribution is the number of heads that come up in n  independent ﬂips of a coin; call this 
random variable H .  If the coin is fair, then H  has an unbiased binomial density function: 
�  � 
n
2−n 
k 

PDFH (k) = 
�  � 
n
sequences  of  n  coin  tosses with  exactly  k  heads,  and 
This  follows  because  there  are 
k 
each such sequence has probability 2−n  . 

Here is a plot of the unbiased probability density function PDFH (k) corresponding to 
n  =  20  coins ﬂips.  The most likely outcome  is k  =  10  heads, and the probability falls off 
rapidly for larger and smaller values of k . These falloff regions to the left and right of the 
main hump are usually called the tails of the distribution. 

12 

Random Variables


0.18 

0.16 

0.14 

0.12 

0.1 

0.08 

0.06 

0.04 

0.02


0


0

5 

10

15

20  

An  enormous  number  of  analyses  in  computer  science  come  down  to  proving  that  the 
tails  of  the  binomial  and  similar  distributions  are  very  small.  In  the  context  of  a  prob­
lem, this typically means that there is very small probability that something bad happens, 
which could be a server or communication  link overloading or a  randomized algorithm 
running for an exceptionally long time or producing the wrong result. 

2.4.1  The General Binomial Distribution 

Now let J  be the number of heads that come up on n  independent coins, each of which is 
heads with probability p. Then J  has a general binomial density function: 
�  � 
p  (1  − p)n−k 
n
k
k 

�  � 
As before, there are  k  sequences with k  heads and n  − k  tails, but now the probability of 
n
each such sequence is pk (1  − p)n−k  . 

PDFJ (k) = 

As an example, the plot below shows the probability density function PDFJ (k) corre­
sponding  to ﬂipping n  = 20   independent  coins  that are heads with probabilty p  = 0.75. 
The graph shows that we are most likely to get around k  =  15  heads, as you might expect. 
Once again, the probability falls off quickly for larger and smaller values of k . 

Random Variables


13 

0.25 

0.2 

0.15 

0.1 

0.05 

0 

0

5 

10

15

20  

2.4.2  Approximating the Binomial Density Function 
�  � 
There  is an approximate  closed­form  formula  for  the general binomial density  function, 
though  it  is a bit unwieldy.  First, we need an approximation  for a key  term  in  the  exact 
n
formula,  k  .  For convenience,  let’s replace k  by αn  where α  is a number between 0 and 
�  � 
1. Then, from Stirling’s formula, we ﬁnd that: 
≤  � 
2nH (α) 
n 
2πα(1  − α)n 
αn 
where H (α) is the famous entropy function: 
�  � 
H (α) =  α log2  +  (1  − α) log2
1 
1
1  − α 
α 
n
is very tight and serves as an excellent approximation. 
This upper bound on 
αn 
Now let’s plug this formula into the general binomial density function. The probability 
of ﬂipping αn  heads in n  tosses of a coin that comes up heads with probability p  is: 
PDFJ (αn) ≤  � 
2nH (α) 
αn (1  − p)(1−α)n 
· p 
2πα(1  − α)n  
This formula is ugly as a bowling shoe, but quite useful.  For example, suppose we ﬂip a 
fair  coin n  times.  What  is  the probability of getting  exactly  1  n  heads?  Plugging α  = 1/2
2
and p  = 1/2   into this formula gives: 
PDFJ (αn) ≤  � 
� 
2nH (1/2) 
2π(1/2)(1  − (1/2))n 
2 
= 
πn 

· 
2−n

(2)

14 

Random Variables 

√
Thus,  for  example,  if  we  ﬂip  a  fair  coin  100  times,  the  probability  of  getting  exactly  50 
50π  ≈ 0.079  or around 8%. 
heads is about 1/

2.5  Approximating the Cumulative Binomial Distribution Function 

Suppose  a  coin  comes  up  heads  with  probability  p.  As  before,  let  the  random  variable 
J  be  the number of heads  that  come up on n  independent ﬂips.  Then  the probability of 
getting at most k  heads is given by the cumulative binomial distribution function: 
� 
CDFJ (k)  = Pr   (J  ≤ k) 
k
k � ��  n 
PDFJ (i)  
i=0 
p  (1  − p)n−i 
i
i 
i=0 

= 

= 

≤ 

· p

αn (1  − p)(1−α)n 

Evaluating  this  expression  directly would  be  a  lot  of work  for  large  k  and  n,  so  now 
an approximation would be really helpful. Once again, we can let k  =  αn; that is, instead 
of thinking of the absolute number of heads (k ), we consider the fraction of ﬂips that are 
heads (α). The following approximation holds provided α <  p: 
1  − α 
CDFJ (αn)  ≤ 
1  − α/p 
1  − α 
1  − α/p 

·

PDFJ (αn)
· � 
2nH (α)

2πα(1  − α)n  
In  the ﬁrst step, we upper bound  the summmation with a geometric sum and apply  the 
formula  for  the  sum  of  a  geometric  series.  (The  details  are  dull  and  omitted.)  Then we 
insert the approximate formula (2) for PDFJ (αn) from the preceding section. 
You have to press a lot of buttons on a calculator to evaluate this formula for a speciﬁc 
choice  of  α,  p,  and  n.  (Even  computing  H (α)  is  a  fair  amount  of  work!)  But  for  large 
n, evaluating  the cumulative distribution  function exactly requires vastly more work!  So 
don’t look gift blessings in the mouth before they hatch. Or something. 
As an example, the probability of ﬂiping at most 25 heads in 100 tosses of a fair coin is 
obtained by setting α  = 1/4, p  = 1/2  and n  =  100: 
1  − (1/4)  
1  − (1/4)/(1/2)  

CDFJ (n/4)  ≤ 

· PDFJ (n/4) 

· 1.913  · 10−7 

≤ 

3
2 

This  says  that ﬂipping 25 or  fewer heads  is  extremely unlikely, which  is  consistent with

our earlier claim  that  the  tails of  the binomial distribution are very small.  In  fact, notice

that the probability of ﬂipping 25 or fewer heads is only 50% more than the probability of 


Random Variables 

15 

ﬂipping exactly 25 heads. Thus, ﬂipping exactly 25 heads is twice as likely as ﬂipping any 
number between 0 and 24! 
Caveat: The upper bound on CDFJ (αn) holds only if α <  p.  If this is not the case in your 
problem,  then  try  thinking  in  complementary  terms;  that  is,  look  at  the  number  of  tails 
ﬂipped instead of the number of heads. 

3  Philosophy of Polling 

On  place  where  the  binomial  distribution  comes  up  is  in  polling.  Polling  involves  not 
only some tricky mathematics, but also some philosophical issues. 
The  difﬁculty  is  that  polling  tries  to  apply  probabilty  theory  to  resolve  a  question  of 
fact.  Let’s ﬁrst consider a slightly different problem where the issue is more stark.  What 
is the probability that 
N  = 26972607  − 1 
is a prime number?  One might guess 1/10  or 1/100.  Or one might get sophisticated and 
point out that the Prime Number Theorem implies that only about 1  in 5 million numbers 
in  this  range  are  prime.  But  these  answers  are  all  wrong.  There  is  no  random  process 
here.  The  number N  is  either prime  or  composite.  You  can  conduct  as many  “repeated 
trials”  as  you  like;  the  answer will  always  be  the  same.  Thus,  it  seems probability does 
not touch upon this question. 
However,  there  is  a probabilistic primality  test due  to Rabin  and Miller.  If N  is  com­
posite, there is at least a 3/4  chance that the test will discover this.  (In the remaining 1/4 
of the time, the test is inconclusive; it never produces a wrong answer.) Moreover, the test 
can be run again and again and the results are independent. So if N  actually is composite, 
� �100 
then the probability that k  = 100  repetitions of the Rabin­Miller do not discover this is at 
most: 
1 
4 
So 100 consecutive inconclusive answers would be extremely convincing evidence that N 
is prime!  But we  still couldn’t  say anything about  the probability  that N  is prime:  that  is 
still either 0 or 1 and we don’t know which. 
A similar situation arises in the context of polling: we can make a convincing argument 
that a statement about public opinion is true, but can not actually say that the statement 
is true with any particular probability.  Suppose we’re conducting a yes/no poll on some 
question.  Then we  assume  that  some  fraction  p  of  the  population would  answer  “yes” 
to the question and the remaining 1  − p  fraction would answer “no”.  (Let’s forget about 
the  people  who  hang  up  on  pollsters  or  launch  into  long  stories  about  their  little  dog 
Fi­Fi—  real  pollsters  have  no  such  luxury!)  Now,  p  is  a  ﬁxed  number,  not  a  randomly­
determined  quantity.  So  trying  to determine  p  by  a  random  experiment  is  analogous  to 
trying to determine whether N  is prime or composite using a probabilistic primality test. 

16 

Random Variables 

Probability slips into a poll since the pollster samples the opinions of a people selected 
uniformly and  independently at  random.  The  results are qualiﬁed by saying something 
like this: 

“One can say with 95% conﬁdence that the maximum margin of sampling 
error is ±3  percentage points.” 

This means that either the number reported in the poll is within 3% of the actual fraction 
p  or else an unlucky 1­in­20 event happened during  the polling process;  speciﬁcally,  the 
pollster ’s  random  sample was  not  representative  of  the  population  at  large.  This  is  not 
the same thing as saying that there is a 95% chance that the poll is correct; it either is or it 
isn’t, just as N  is either prime or composite regardless of the Rabin­Miller test results. 

