18.034  SOLUTIONS  TO  PROBLEM   SET  7  

Due  date:  Friday,  April  16  in  lecture.   Late  work  will  be   accepted  only  with   a   medical  note   or  for 
another  Institute­approved reason. You  are  strongly  encouraged to  work  with  others,  but   the  ﬁnal 
write­up  should  be  entirely  your  own  and   based  on  your   own  understanding. 
Each  of  the  following  problems  is  from  the   textbook.  The  point  value  of   the   problem  is   next  to  the 
problem. 
(1)(5  points)  p.  439,   Problem  6  
⎤ 
⎡ 
Solution:  To  answer  all  such  questions,  the  simplest  method  is  to   apply  Gaussian   elimination  to 
the  augmented  matrix,  
�
0  1  0  0  ⎦
A1  =  ⎣	 −1
1  −1
3  −2 
0  1  0 
3  −4 
0  0  1 
1
Taking  R� =  R2  +  R1 ,  R� =  R3  − R1 ,  i.e.,   subtracting  the   ﬁrst  row  from  the  second   row  and  
⎡ 
⎤ 
2
3 
adding   the  ﬁrst  row  to  the  third  row,  gives, 
�
A2  =  ⎣	 0
1  0  0  ⎦
1  −1
0 
2  −2 
1  1  0 
−1  0  1 
4  −4 
0
⎤ 
⎡ 
Next,  taking  R� = (1/2)R3 ,  R� =  R3  − 2R2 ,
�
⎦0
A3  =  ⎣	 0
3 
2
1  −1
0  0 
1 
0 
1  −1 
1 
1
−3  −2  1  ⎤
2 
2
0
0
0 
⎡ 
Finally,  R� =  R1  +  R2 ,
�
A4  =  ⎣	 0  1  −1 
⎦0
1	
1  0  −1 
0
3
1 
2
2 
1 
1
Deﬁne  A4  to  be  the   matrix  formed  by  the  ﬁrst  3  columns  of  �A4 .  First  of  all,  the  nullspace  of   A  equals 
−3  −2  1 
2
2 
0  0 
0 
the  nullspace  of  A4 .  Visibly,  the  nullspace  of  A4  is   spanned  by  [1,   1,  1]T  .  Therefore  the  nullspace 
of  A  is  spanned  by  [1,   1,  1]T  .  Also  the   column  space   of  A4  is   spanned  by  the  same  columns   as  the 
column  space  of   A,  i.e.,   the  ﬁrst  2  columns.  So  the   column   space  of  A  is   spanned  by  [1,  −1,  1]T  and 
[−1,  3,  3]T  . 
⎡
⎤ 
⎡
⎤ 
(a)   Therefore   Ax  = [1,  −1,  1]T  does  have  a  solution,  and  the   general  solution   is, 
x  =  ⎣  0  ⎦ +  C  ⎣  1  ⎦ , C  ∈ R. 
1
1 
0
1 
⎡
⎤ 
(b)  The  general  solution  of  Ax  = 0  is, 
x  =  C  ⎣  1  ⎦ , C  ∈ R. 
1 
1 
1 

⎡
⎤ 
⎡
⎤ 
(c)  The  system  Ax  =  y  has  a  solution  iﬀ   y  is  in  the  column   space,  i.e.,   iﬀ 
y  =  C1  ⎣  −1  ⎦ +  C2  ⎣  3 
−1  ⎦
1 
, 
1
3 

iﬀ  −3y1  − 2y2  +  y3  = 0. 
(2)(5  points)  p.  439,   Problem  12 
Solution:  We   use  cofactor  expansion   along   the  third  row, ⎡
⎤ 
det(A) =  −2det(B1 ), B1  =  ⎣  4  1  1  ⎦ . 
5  7  2 
1  3  4 
⎡
⎤ 
To   compute  the  determinant  of  this   matrix,   we  use  row  operations,  keeping  track  of  how  the   deter­
minant  changes.   First  take  R3  =  R1 ,  R1  =  R3 , 
det(B1 ) =  −det(B2 ), B2  =  ⎣  4  1  1  ⎦ . 
1  3  4 
5  7  2 
⎤ 
⎡	
Next,  R� =  R2  − 4R1 ,  R� =  R3  − 5R1 ,
det(B2 ) =  det(B3 ), B3  =  ⎣	 0  −11  −15 
4  ⎦
2	
3 
1
3
. 
0  −8  −18 
⎤ 
⎡
4  ⎦
det(B3 ) =  det(B4 ), B4  =  ⎣	 0  −3
3 
1
3 
. 
0  −8  −18 
⎤ 
⎡
4  ⎦
det(B4 ) =  det(B5 ), B5  =  ⎣	 0  −3
3 
1
3  
. 
0  −2  −24 
⎤ 
⎡
det(B5 ) =  det(B6 ), B6  =  ⎣  0
51  ⎦ . 
4 
1
3 
1 
0  −2  −24 
⎡
⎤ 
det(B6 ) =  det(B7 ), B7  =  ⎣  0  1  51  ⎦ . 
4 
1  3 
0  0  78 
· 
·	
Because this  is  an  upper  triangular  matrix,  det(B7 )  =  1  1  78  =  78.   Therefore  det(B2 ) = 
det(B7 ) =   78.  So   det(B1 ) =  −78.  So, 
det(A) = (−2)(−78)  =  156. 

Next,  R� =  R3  − 2R2 ,
3	

2  − 2R3 , 
Next,  R2  =  R�

· · · 

= 

Next,  R� =  R2  − R3 ,
2	

Finally,  R3  =  R3  +  2R2 , 

(3)(5  points) p.  439,  Problem  16 
Solution:  As   shown  above,   the  nullspace  has  dimension  1.  And  the  column  space   has  dimension  2. 
Therefore  R(L) +  N (L) = 2 +  1,  which  is  3  as  required.  
(4)(5  points) p.  362,   Problem  13 

2 

Visibly,  the  only  nullvector  is, 

⎡
⎤ 
Solution:  The   characteristic   polynomial  is  the  determinant  of   the  matrix, 
λI3×3  − A =  ⎣ 
.⎦ 
λ +  1  −36  −100 
0  λ +  1  −27 
0  λ − 5 
0
Because  this   is  an  upper  triangular  matrix,  the  determinant  is  simply  (λ +  1)(λ +  1)(λ −  5)  = 
(λ + 1)2 (λ − 5).  Therefore  λ1  =  −1  is  an  eigenvalue  with  multiplicity  2,  and  λ2  = 5  is  an  eigenvalue 
with  multiplicity   1. 
⎤ 
⎡ 
For  λ1  =  −1,  the   eigenspace  is  the  nullspace  of   the  matrix, 
⎦ . 
−I − A =  ⎣ 
−100 
0  −36 
−27 
0 
0 
−6 
⎡  ⎤ 
0 
0 
v1  =  ⎣  0  ⎦ , 
1 
0 
(since  the  last  2   columns  are   linearly  independent,  the  rank  nullity  theorem  says  the   nullspace  has  
dimension  1).  Since  the  multiplicity  is  2  but  the   eigenspace  has  dimension  1,  the   eigenspace  for  
λ =  −1  is  deﬁcient. 
⎤ 
⎡
For  λ2  = 5,  the  eigenspace   is   the   nullspace  of  the  matrix, 
5I − A =  ⎣  0
.⎦ 
6  −36  −100 
6  −27 
0
0 
0 
⎡
⎤ 
Notice  that   6[−100, −27]T  + 27[−36, 6]T  + 262[6, 0]T  = [0, 0]T  .  Therefore  the  eigenspace  for  λ =  −5 
is  spanned  by, 
v2  =  ⎣  27  ⎦ . 
262 
6 

(5)(5  points)  p.  362,  Problem  18 
This  can  be  proved   rigorously   by  induction,   but  essentially  it  is  obvious  by  inspection. 
(6)(5  points)  p.  362,  Problem  19 
Solution:  Let  v  be  an  eigenvector  for  λ,  i.e.  Av  =  λv .  Then,  by   induction,  for  every  integer  k ≥ 1, 
Ak (v) =  λk v .  Therefore   v  is  an  eigenvector   for  Ak  with  eigenvalue   λk .  This  proves  the  ﬁrst  part. 
The  second  part  is  a  bit  vague  –  it  is  not  stated   over   what  ﬁeld   we  are   working  or   which  root  of 
µ  we  are  taking.   Suppose   that  λk  is  an  eigenvalue  of  Ak  .  It  is   not  necessarily  true   that  λ  is  an 
eigenvalue  of  A.  For  instance,  let  A =  In×n .  Then  (−1)2  = 1  is   an  eigenvalue  of  A2 .  But  −1  is  not 
an  eigenvalue  of  A. 
Another  reasonable   interpretation  of   this  part  of   the  problem  is   this:  For   every  eigenvalue  µ  of 
Ak ,  does  there   exist  an  eigenvalue   λ  of  A  such  that  µ =  λk ?  The  answer  to  this  is  “yes”,  at  least 
over  C.  Let  λ1 , . . . , λr  be  the  distinct  complex  eigenvalues  of   A.  Then  the  generalized  eigenspace 
V gen , . . . , V gen  give   a  direct  sum  decomposition  of  V .  Denote  by  Ai  the  restriction  of   A  to  V gen  .
λr 
λi 
λ1 
Then  Ai  =  λi I +  N ,  where  N  is  a  nilpotent  matrix.  Therefore,  Ak  is   λk I +  BN  where  B  is  the 
i
i 
matrix, 
B =  kλk−1 I +  k(k − 1)/2λk−2N +
· · ·
+  kλiN k−2  +  N k−1  .
i
i 
3 

In  particular,   B  commutes  with  N .  So  if   N e  =  0,  then  (BN )e  =  B eN e  =  B e0  =  0.  It  follows  that 
k  − λi
k I )e  =  0.  Therefore   V gen  is  contained  in  the  generalized   eigenspace  of  Ak  for  the  eigenvalue 
(Ai
λi 
k .  Because  every  vector  in  V  can  be  written  as  a   sum  of  vectors   in  V gen  , . . . , V gen ,  the  generalized 
λi
λ1 
λr 
eigenspaces  for   λk 
r  already   give  a  direct  sum  decomposition   of   V .  By  our  basic  theorem  that 
1 , . . . , λk
al l  of  the  nontrivial  generalized  eigenspaces  for  Ak  give  a  direct  sum  decomposition  of   V ,  it  follows 
r  .  Therefore  every  eigenvalue  of  Ak  is   the  k th   power  of 
that  the  only  eigenvalues   of  Ak  are  λk 
1 , . . . , λk
an  eigenvalue  of  A. 
(7)(5  points)  p.  362,  Problem  21 
Solution:  This   follows  immediately  by  expanding  and  comparing  to  Formula   (12)  on  p.  357. 
(8)(5  points)  p.  362,  Problem  22 
Solution:  Part  (a)  follows   immediately  by  expanding  and  comparing   to   Formula   (12).  For  Part 
(b),  notice  that  the   trance  is  −5.  Since  this  is  a  negative  real  number,  the  sum  of   the  real  parts  of 
the  eigenvalues  is  negative.   Therefore,  at  least  one  of   the  eigenvalues  has  a  negative   real  part.  
(9)(5  points)  p.  362,  Problem  23 
Solution:  The  matrix   A is  nonsingular  iﬀ  it  has  only  the  trivial  nullvector.  A  nontrivial  nullvector 
is  the  same  thing   as   an  eigenvector  for  the  eigenvalue  λ =  0.   Therefore  A is  nonsingular   iﬀ   0   is  not 
an  eigenvalue  of  A. 
(10)(5  points)  p.  363,   Problem  25 
Solution:  The  trace  is  4  and   the   determinant  is  4.   Therefore  the  characteristic   polynomial  is 
pA (λ) =   λ2  − 4λ +  4  = (λ − 2)2 .  Therefore  λ = 2  is   an  eigenvalue  with  multiplicity  2.  Because  the 
� 
� 
matrix  is  not  diagonal,  clearly  the  eigenspace   is  deﬁcient.  Choose  a   random   vector,   say 
1 
v2  = 
. 
� 
� 
� 
� � 
� 
0 
0  =  −2 
v1  =  (2I − A)v  =  −2  2 
1 
−2 
−2  2 
, 
� 
�
is  an  eigenvector.   Therefore  a   generalized  eigenbasis  consists  of   (v1 , v2 ).  With  respect  to  this  ordered 
basis,  the  matrix   is,  
. 

Then, 

2  1 
0  2 

4 

