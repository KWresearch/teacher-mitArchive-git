18.034  PROBLEM  SET  8 

Due  date:  Friday,  April   23  in  lecture.  Late   work  will  be  accepted   only  with   a  medical  note   or  for 
another  Institute­approved reason. You  are   strongly  encouraged to  work  with  others,  but   the  ﬁnal  
write­up  should  be   entirely  your  own  and  based  on   your   own  understanding. 
This  problem  set  is  essentially  a  reading  assignment.  I had  originally  intended to  present  the   material 
in  the  problem  set  in  lecture.  However,  this  material  is  less  relevant  to  other   topics  in  this  course, 
and  there  is  no   time  to  present  it  in  lecture.  Each  student  will  receive  10  points  simply  for   reading 
through  this  problem  set.  At  several  places,  you  are  asked   to   work­through  and  write­up  details  in 
the  derivation.  You  will  turn  in  this  write­up  to  be  graded. 
· · · 
Problem  1(30  points)  A  collection   of  N 
identical   particles   of  mass  m0  =
=  mN −1  =  m
are  allowed  to  oscillate   about  their  equilibrium  positions.  Denote  by  x0 (t), x1 (t), . . . , xN −1 (t)  the 
displacement  of  the   masses  from  equilibrium.  The  mass   m0  is  connected  to  a  motionless   base  by  a 
spring.  It   is  also  connected  to  mass  m1  by  a  spring.  For  i  = 1, . . . , N  − 2,   mass   mi  is  connected 
� 
to   mass  mi−1  and  mass  mi+1   by  springs.  Finally,  mass   mN −1  is   connected  to  mass  mN −2  and  to  a 
motionless  base   by  a  spring.  Each  spring  is  identical   and  has   spring  constant  κ.  Time  is  measured 
⎡ 
⎤
κ/m  equals   1.  The  equations   of   motion  for   this  system  are,

in  units  so   that  the   frequency  
⎥⎥⎥⎦

⎢⎢⎢⎣


, 

x0 
x1 
. . . 
xN −1 

(AN )i,j  = 

In  other  words, 

⎧ ⎪⎪⎨ ⎪⎪⎩

1,
j =  i +  1, 
−2,
j =  i, 
j =  i − 1,

1, 
0, 

otherwise

In  this  problem,   you  will   determine   the   general  solution  of  this  system  of   linear   diﬀerential  equa­
tions.  Because   of  the  special  nature  of  this  problem  (namely,  every  eigenvalue   of  A has   multiplicity 
1),  it  is  not  necessary  to  reduce   to  a  system  of   ﬁrst­order  linear   diﬀerential  equations. 
(a),  Step  1(10  points)  In  this   step,  you   will  ﬁnd,  for  each  integer  n,  all   the  roots   of   a  polynomial 
pn  that   is  deﬁned  inductively  below.   Please  read  the  whole  derivation.   In  your   writeup,  only  ﬁl l   in 
the  missing  steps  in  the   third  paragraph  below.  You   do  not  need  to  ﬁll  in   the   missing  steps  in   the 
other  paragraphs  (but  you  are  encouraged  to  work  them  out  for   yourself ). 
1 

where  AN  is  the  N × N  matrix,  

AN  = 

x��  =  AN x,   x  = 
⎡  −2
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

0 
0
1
1  −2
0 
1
1  −2
1 
0
1  −2 
0
0
.
.

.
.  
. 
.
.
.
.
.
.
. 
0
0
0
0 
0 
0
0
0

⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦


0
0 
. . . 
0
0 
. . . 
0
0 
. . . 
0
0 
. . . 
.
. 

.
.
.
.
.
. 
. 
. . .  −2
1

1  −2

. . . 

⎧⎨ ⎩

Let  u  be  an  indeterminate.  Let  p0 , p1 , . . . , pn , . . .   be   a  sequence  of  real  polynomials  in  u  that  satisfy 
the  linear  diﬀerence   equation, 

pn+2  − 2upn+1  +  pn  = 0, 
p0  = 1, 
p1  = 2u 
− 1,  and  p3 
− 4u.   (In 
where  n  varies  among   all  nonnegative   integers.  In  particular,  p2 
= 8u
= 4u2 
3
n  is  a  polynomial   with  integer  coeﬃcients.)  In   this  step,  you  will  prove  that  a  closed 
fact,  each  p
� 
formula  for  pn  is, 
n
(u − cos(kπ/(n +  1))). 
k=1 

pn  = 2n 

(1) 

Conclude  that, 

As  a   reality  check,  observe  this   gives,  
2(u − cos(π/2))  = 2u 
p1  = 
4(u − cos(π/3))(u − cos(2π/3))  = 4(u − 1/2)(u +  1/2)  = 4u − 1, 
√
√
p2  = 
2
p3  =  8(u − cos(π/4))(u − cos(2π/4))(u − cos(3π/4))  = 8(u − 1/
2)  = 8u − 4u 
2)(u)(u +  1/
3
Write   up  a  careful  proof  of  the  missing  steps   in   the  next  paragraph.  To  prove   the  formula,  
observe  that  it  suﬃces   to   check  when  |u|  >  1;   two  polynomials  in  u  that  agree  for  inﬁnitely  many 
values  of
are  equal  (you  don’t  have  to  write  a  proof   of   this).  Assume   that
=
+
r ,
−
n
n 
−
C
u
p
r
C
n 
+
+ 
where
,
.
=
=
on
For 
that  do  not  depend
are  continuous  functions   in
−
−
−
r , r
, r , r
C , C
r
r
n
u
+
+
+
prove  that  r  satisﬁes  the  characteristic  polynomial, 
2 r  − 2ur  +  1  = 0. 
�

r =  a ± b,  a =  u,  b = 
u − 1.
± 
2
� 
Plugging this  in  to  the  equations  for  p0  and  p1 ,  conclude  that,  
C+  +  C
= 1,
−
(C+  +  C− )a +  (C+  − C− )b  = 2a, 
� 
Solve  this  system  of  linear  equations  to  get, 
C+  = (a +  b)/2b, 
=  −(a − b)/2b
− 
C
�

Therefore  one  solution  of  Equation  1   for  |u| > 1  is, 
(a +  b)n+1  − (a − b)n+1
u − 1. 
]/2b,  a =  u,  b = 
pn  = [
2
But,  of  course,   there   is  a  unique   solution:  for   each  n ≥ 2,   pn  can  be   determined  recursively  in  terms 
of  pn−1  and  pn−2 .  Therefore,   this   is  the  solution  of  Equation  1. 
√
For  the  rest  of  this  part,   do   not  write  up  the  missing  details.  The  equation  above  also 
|
|
u2  − 1  is  interpreted  as  a  complex  number.  Let 
makes  sense  and  is   correct  if  u <  1,  where   b = 
|u| < 1.  Then  pn (u) = 0   iﬀ  (a
b)n+1  = (a − b)n+1 .  Both  a + b and  a − b are   nonzero  (because  the 
+
imaginary  part  of  each  complex  number  is  nonzero).  Therefore  (a + b)n+1  = (a − b)n+1  iﬀ  one  of  the 
following   equations   holds,  
(a +  b) =  ζk (a − b),  ζ =  e
i2πk/(n+1)
,  
as  k varies  among  the  integers  0, . . . , n.   Of   course  for  k = 0,   the  equation  is   a + b =  a − b,   i.e.  b = 0. 
Since  b = 0,  this  case  is  ruled  out. 
Let  k = 1, . . . , n.  If  (a +  b) =  ζk (a − b),  then 
(ζk  − 1)a = (ζk  +  1)b.  
2 

�
Squaring  both sides, 

i.e., 

Solving  for  u2  gives, 

i.e., 

(ζk  − 1)2 a  = (ζk  +  1)2 b2  , 
2

(ζk  − 1)2 u  = (ζk  +  1)2 (u  − 1). 
2
2

2(2ζk )u  =  ζ 2  +  2ζk  +  1,
2
k 

2 u  = (ζk  +  ζ −1  +  2)/4.
k 

Simplifying, 

x(k)  = 

3 

pn  = 2n 

−1  =  e 
i2πk/(n+1)  +  e−i2πk/(n+1)  
= 2 cos(2πk/(n +  1)). 
ζk  +  ζk
Also,  2 +  2 cos(θ) = 4 cos2 (θ/2).   Therefore,  u2  =  cos2 (πk/(n +  1)).  So  u =  ± cos(πk/(n +  1)).   But 
of  course   − cos(πk/(n +  1))  =  cos(π(n +  1   − k)/(n +  1)).  Therefore,  every  root  of   pn (u)  = 0  with 
|u| < 1  is  of  the   form  cos(πk/(n +  1))  for  some  integer   k = 1, . . . , n. 
Reversing  the  steps  above,  cos(πk/(n + 1))  is  a  root  of  pn  for  every  k = 1, . . . , n.   Also,   for  0  < θ < π , 
the  function  cos(θ) is  strictly  decreasing.  Therefore  the   real  numbers   cos(πk/(n + 1))  are  all  distinct.  
This  gives  n  distinct  real  roots   of  the   degree   n  polynomial  pn .  Since  a  polynomial  of  degree   n  has 
at   most  n  real  roots,  counted  with   multiplicity,   every  root  of  pn  is   of  the  form  cos(πk/(n + 1)),   and  
each  of  these  roots  has  multiplicity  1.  It  is  straightforward  to  compute  that  the   leading  coeﬃcient 
� 
of  pn  is  2n .  Therefore, 
n
(u − cos(πk/(n +  1))). 
k=1 
(b),  Step   2(10  points)  For  each  integer  N  ≥  1,  deﬁne   PN (λ)  to  be   the  characteristic  polynomial 
det(λIN ×N  − AN ).  Deﬁne  P0 (λ)  = 1.  Using  cofactor   expansion  along   the  ﬁrst  row,  prove 
that  the  sequence  of  polynomials   P0 , P1 , P2 , . . .  satisﬁes  Equation   1  where  u =  +  1. 
λ
2 
N� 
It  then  follows  that  the   characteristic   polynomial  of  AN  is, 
(λ +  2(1  − ck )),  ck  =  cos(πk/(N +  1)). 
k=1 
Therefore  the  eigenvalues  of   AN  are  λk  =  −2 +  2ck  =  −(2  sin(πk/(N +  1)))2 ,  for  k = 1, . . . , N . 
(c),  Step  3(10  points)  Let  the  integer  N  ≥ 1  be   ﬁxed.  For   each   integer  k = 1, . . . , N ,  consider  the 
⎡ 
⎤
eigenvalue  λk .  Denote, 
⎢⎢⎢⎣

⎥⎥⎥⎦

x(k),0 
x(k),1 
. . . 
x(k),N −1 
the  eigenvector  of   AN  with  eigenvalue   λk  that  is   normalized  by  the   condition  x(k),0  =  1. 
Prove  that  the   sequence  x(k),0 , x(k),1 , . . .  satisﬁes  Equation  1   where  u =  ck .  It  then   follows 
that  for  each  n = 0, . . . , N − 1,  the  entry  x(k),n  is  given  by,  
� 
n
(cos(πk/(N +  1))  − cos(π l/(n +  1)))  . 
l=1 

x(k),n  = 2n 

PN (λ) =

(d),  Step   4( 0  points)  Having   computed  the  eigenvalues  λk  and  an  eigenvector  x(k) ,  it  is  now 
straightforward  to  solve  the  linear  system  of   diﬀerential  equations.  Let  k be   an  integer,  k = 1, . . . , N . 
Let  zk (t) be  a  real­valued   function.  Then   zk (t)x(k)  is   a  solution  of   the   linear   system  iﬀ, 
�
zk (t)x(k)  =  A(zk (t)x(k) ) =  zk (t)Ax(k)  =  zk (t)λk x(k) . 
Therefore  zk (t)x(k)  is  a  solution  iﬀ, 
zk (t) =  λk zk (t) =  −(2 sin(πk/(N +  1)))2 zk (t). 
�
Denote  ωk  = 2 sin(πk/(N +  1)).  The  general  solution  of  this   diﬀerential  equation  is, 
zk (t) =  Ak  cos(ωk t) +  Bk  sin(ωk t). 
� 
Therefore  the   general  solution  of   the  linear   system  of  diﬀerential  equations  is, 
N
(Ak  cos(ωk t) +  Bk  sin(ωk t))x(k) ,  ωk  = 2 sin(πk/(N +  1)), 
� 
� 
k=1  �T 
n
(cos(πk/(N +  1))  − cos(π l/(n +  1)))  . 
x(k)  =  x(k),0 , . . . , x(k),N −1 
l=1 

,  x(k),n  = 2n 

x(t) =

Problem  2(10  points)  The  general   linear  system  of   ﬁrst  order   diﬀerential   equations  not  necessarily 
with  constant  coeﬃcients   is, 
x� (t) =  A(t)x(t). 
Apart   from  the   existence   and  uniqueness  theorem   proved   in  the  beginning   of  the   semester,  there  is 
little  we  can  say  about  the  solution  of  this  diﬀerential  equation.  However,  if  A(t) has   a  special  form, 
sometimes  we  can  get  an  equation  for  the  solution   that  is  a  bit  more  explicit.  In  this  problem  you 
will  deduce  such  a  result. 
(a),  Step   1(5  points).   Let  g(λ, t) be  a  C∞  function  deﬁned  on  the   (λ, t)­plane.  Let  S  be   an  n × n 
real  matrix.  Assume   that  the   eigenvalues  of  S ,  λ1 , . . . , λk  are   all  real   and  that  none  of   the   eigenspace 
is  deﬁcient,  i.e.  for  i = 1, . . . , k ,  the   generalized  eigenspace   V gen   equals  the  usual   eigenspace   Vλi .
λi 
Deﬁne  g(S, t) to  be  the  unique   matrix  such  that  for   each  i = 1, . . . , k ,  g(S, t) preserves   the  eigenspace 
Vλi  and  the  restriction  of  g(S, t) to  this  subspace  equals   g(λi , t) times  the  identity matrix. 
� 
� 
Let  v  be  an  n­vector  and  consider  g(S, t)v.  Write  up   the   proof   of   the  following  fact.  The 
function  of  t,  g(S, t)v   is  C∞  and  for  every  nonnegative  integer  r , 
∂ r
r 
d (g(S, t)v) = 
(S, t)v. 
∂ tr
r 
dt
(b),  Step  2(5  points)  Next,   let  A be  an  n × n  real  matrix  whose  eigenvalues  are  all  real,  but  such 
that  the  eigenspaces   of  A  might  be   deﬁcient.  Denote  by  λ1 , . . . , λk  the  eigenvalues  of   A. For  each 
i = 1, . . . , k ,  denote   by  V gen  the  generalized  eigenspace  of  A.  Deﬁne  S  to  be  the  unique   matrix  such 
λi 
that   for  each  i = 1, . . . , k ,  S  preserves   V gen  and  the  restriction  of  S  to  V gen  is  λi  times   the  identity 
matrix.  Deﬁne  N  =  A − S .  Then  S  commutes  with  N ,  the  matrix  S  is  diagonalizable,  and  the 
λi 
λi 
matrix  N  is  nilpotent,  i.e.  N e+1  = 0  for  some  integer  e. 
�
�
�  1 
Deﬁne  g(A, t)  to  be  the   matrix, 
e
m!
m=0 
Let  v  be  an  n­vector  and  consider  g(A, t)v.  Write   up  the  proof  of  the  following   fact.  The

4 

∂m 
m  g 
∂λ

(S, t). 

g 

g(A, t) = 

N m

� 
� 
function  of  t,  g(A, t)v  is  C∞  and  for  every  nonnegative   integer   r , 
dr 
∂ r 
(A, t)v. 
∂ tr 
dtr 
(Hint:  Use  the   equality   of  mixed   partial  derivatives,  and   reduce  to  part  (a)  ). 
(c),  Step   3( 0   points)  Let  g(λ, t) and   h(λ, t) be  C∞  functions  on  the  (λ, t)­plane.  Let  A  be   an  n × n 
matrix  all   of  whose  eigenvalues  are   real.  Then  g(S, t),  g(A, t),  h(S, t) and  h(A, t) all  commute  with  
each  other.  Moreover,  
·
·
g(S, t)h(S, t) = (g h)(S, t),  and  g(A, t)h(A, t) = (g h)(A, t).

(g(A, t)v) = 

g 

(S, t)i . 

To   prove  that  g(S, t)  and  h(S, t)  commute   with  each   other,  that  they  commute  with  g(A, t)  and 
· 
h(A, t),  and  that  g(S, t)h(S, t)  = (g h)(S, t),  it  suﬃces  to  prove  this  after   restricting   to  V gen  for
λi
every  i  = 1, .  .  .  , k .  But  for  any C∞  function  f (λ, t),  the  restriction  of  f (S, t) to  V gen   is   simply  f (λi , t)
λi 
times  the  identity  matrix.  Denote  this   by  f (S, t)i .  Therefore  f (S, t)i  commutes  with  every  linear 
operator  on  V gen  .  In  particular,  g(S, t)i  and  h(S, t)i  commute   with  each  other   and  with  g(A, t)i  and
λi 
·
·
h(A, t)i .  Also,  g(S, t)i  h(S, t)i  is  simply  g(λi , t) h(λi , t) times  the  identity matrix.   This  is   the  same 
·
· · ·
·
as  (g h)(S, t)i .  Therefore   g(S, t)
h(S, t) = (g h)(S, t).
· 
To   prove  that  g(A, t)  and  h(A, t)  commute  with  each  other  and  that  g(A, t)h(A, t)  = (g h)(A, t),
it  suﬃces  to  prove  this  after  restricting  to  V gen  for  every  i  = 1, .  .   .  , k .  Denote   by  Si  and  Ni  the 
� 
�
�
�
λi 
�  1 
�  1 
restrictions  of  S  and  N  respectively  to   V gen .  By  deﬁnition,  
λi 
e
e
∂ l 
· 
(S, t)i 
g(A, t)ih(A, t)i  = 
N l 
∂λl  g 
i 
m!
l!
m=0 
l=0 
All  of  the  matrices  in  this  last  sum  commute.  Therefore   we  may  rearrange   the   (ﬁnite)  sum  in 
g(A, t)ih(A, t)i  =  � �  1 1 
whatever  order   we  wish, 
e
e
N l+m ( ∂ l g 
∂λl  · 
l! m!
i 
�  p � � 
l=0  m=0 
N p  �  p
g(A, t)ih(A, t)i  =  �  1 
Deﬁne  p  =  l +  m.  For  p  > e,   N p  =  0.  Therefore  the  sum  equals, 
∂ p−mg ∂mh 
e
m  ∂λp−m  · 
p!
i 
∂λm 
p � 
p  � 
m=0 
p=0 
� 
∂ p−mg ∂mh 
∂ p (gh)
m  ∂λp−m  · 
= 
�
�
∂λm 
∂λp 
�  1 
m=0 
e
∂ p (gh) 
·
(S, t)i  = (g h)(A, t)i . 
g(A, t)ih(A, t)i  = 
N p 
p!
∂λp 
p=0 
Therefore  g(A, t) h(A, t) = (g h)(A, t).   Because  g h  =  h · g ,  it  follows   that  g(A, t) commutes  with 
·
·
·
h(A, t). 
(d),  Step  4(0  points)  Let  Lλ  be  a  linear  diﬀerential   operator  of  order  n  +  1  in  t, 
∂ n+1 
∂ n 
Lλ  =
∂ tn  +  · · · +  a1 (λ, t) +  a0 (λ, t),
∂ 
+  an (λ, t)
∂ tn+1 
∂ t 
where  each  of  the  functions  aj (λ, t) is  a  C∞  function.  Let  y(λ, t) be  a  C∞  function  that  is   a  solution 
of  Lλy(λ, t) = 0. 

)(S, t)i . 
� 
(S, t)i . 

But  of  course, 

∂mh 
∂λm 

Hence, 

N m 
i 

∂m 
∂λm 

h 

. 

5 

Let  A  be  a   real  n  × n  matrix   all  of   whose   eigenvalues   are  real.  Let  v  be   any  n­vector.  Then  the 
function  y(t) =  y(A,  t)v  is  a  C∞  function  in  t  that  is  a  solution  of  the  linear  system  of  diﬀerential 
equations, 
LAy(t) = 0, 

i.e., 
dn+1 
dn 
· · ·
+  a0 (A,   t)y(t) = 0. 
y(t) + 
an (A,  t)
dtn+1  y(t) + 
dtn 
(e),  Step   5(0  points)  Let  t0  be  a   real  number. For  s  ≥  t0 ,  let  �
K (λ; s,  t)  be   the  unique  solution  of 
This  follows  immediately  from  Steps  1–3.

⎧⎪⎪⎪⎪⎪⎪⎨

��
the  initial   value   problem,
LλK (λ; s,  t)
= 0,

K (λ; s,  s) = 0,  
⎪⎪⎪⎪⎪⎪⎩

��
. . . 
∂ n−1 
K (λ; s,  s)
= 0, 
∂ tn−1 
�
∂ n 
= 1

K (λ; s,  s)
∂ tn 
C∞  function  in  all  3  variables  λ,   s  and  t. 
K (λ; s,  t) is  a 
Assume  that 
⎧ ⎪⎪⎪⎨ LAy(t) =  f(t),

Let  f (t)   be  an  n­vector  whose   entries  are  continuous  functions  of  t.  By  the  same  arguments  as  in  
the  handout  on  Green’s  functions,  the  unique  solution  of   the  IVP,
⎪⎪⎪⎩

y(t0 ) = 0,

.
. . 
�

y(n) (t0 ) = 0 
�
y(t) = 
K (A; s,  t)f(s)ds, 
t0 
where  the  integration  is   done   entry­by­entry. 
(f ),  Part  6(0  points) This  is  somewhat  beside  the  point,  but  if   g(λ,  t)  is   an  analytic  function  in 
� 
λ  whose  expansion  about  the   origin  is, 
∞
cr (t)λr  , 
g(λ,   t) = 
r=0 
and  if  all  the   eigenvalues  of   A  are  within  the  radius   of  convergence   of  this  power   series,  then  the 
� 
following   series  converges  to  g(A,  t),  
∞
cr (t)Ar  . 
r=0 
In  particular,  this  holds  if  g(λ,  t) is  a  polynomial  in  λ  or  if  g(λ,  t) =  e . 
λt

is  given  by,


t 

6 

