Harvard-MIT Division of Health Sciences and Technology 
HST.951J: Medical Decision Support, Fall 2005 
Instructors: Professor Lucila Ohno-Machado and Professor Staal Vinterbo 

Algorithmic Complexity and Application  to Problem 
Analysis 

Staal A. Vinterbo 

Harvard­MIT Division of Health Science and Technology 

Decision Systems Group, BWH 

Harvard Medical School 

Nov 2005:  HST 951/MIT 6.873 Class


Motivation 

Problem 
We have a new sequence of nucleotides. Which of  the ones we 
already have does  it match  the best? 

How do we address  this problem? 
Has  it been solved? 
Is  there a problem  that  is close enough such  that we can use  it  to 
obtain a solution? 
Is  the problem  feasible? 

How  feasible? 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

1  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

2  / 43 

Introduction 

Introduction 
Algorithms and Computational Model 

Introduction 

Introduction 
Computational Model 

Deﬁnition (Program) 
A ﬁnite sequence of computational  instructions. 

Deﬁnition (Computational Model) 
The abstract representation of a device  that can execute programs. 

Deﬁnition (Algorithm) 
An program  for  the solution of a par ticular problem. 

Convenient:  present programs  in a “Pascal”  like  language. 

Example 
An abstract “Pascal” machine, composed by a control and processing 
unit able  to execute “Pascal” statements, and a set of memory 
locations  identiﬁed by all variable and constant  identiﬁers deﬁned  in 
the algorithm. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

3  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

4  / 43

Introduction 

Introduction 
Computational Model:  Algorithm Example 

Introduction 

Introduction 
Computational Model Cost 

Example 
EXP
(1) 
(2) 
(3) 
(4) 
(5) 

(x , y ) 
r  ← 1 
while y  �= 0 
r  ← r  ∗ x 
y  ← y − 1 
return r 

Uniform Cost 
We also assume  that all memory  locations have  the same size, and 
that all values  involved  in  the computation are not  larger  than  that  they 
can be stored  in a memory  location. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

5  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

6  / 43 

Introduction 

Preliminaries 

Introduction 
Computational Model:  Example 

Example 
Our program 
EXP
+ 3y . 
has cost 2 

(x , y ) 

Example 
Alternative:  logarithmic cost: 
a ← 5 + v 
has a cost propor tional with  the sum of  logarithms of values  involved: 
+ log |v | 
log 5 

Preliminaries 
What quantities  for Algorithms? 

We need  to decide 
Execution cost 
1 
computational steps:  the “dominant” operation 
memory used 
Input size, which characteristic parameter describing  the  input  is  it 
whose growth  towards  inﬁnity gives asymptotic computation cost. 

2 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

7  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

8  / 43

Preliminaries 

Preliminaries 

Preliminaries 
Big O Notation 

O (g (n))  =  {f (n) there exists c  > 0 and n0  > 0 s.t. 
|
0 ≤ f (n) ≤ cg (n)  for all n ≥ n0} 
o(g (n))  =  {f (n) for any c  > 0  there exists n0  > 0 s.t. 
|
0 ≤ f (n) < cg (n)  for all n ≥ n0}
Ω(g (n))  =  {f (n) there exists c  > 0 and n0  > 0 s.t. 
|
0 ≤ cg (n) ≤ f (n)  for all n ≥ n0} 

O (g (n)) –  the set of  functions  that are asymptotically bounded 
from above by g . 
Ω(g (n)) –  the set of  functions  that are asymptotically bounded 
from below by g . 
Staal A. Vinterbo  (HST/DSG/HMS) 

HST 951/MIT 6.873 

Complexity 

Preliminaries 
Big O Notation 

Example 
x 2  − x ? 
What  is 
x 2  − x  ≤ x 2 

for 

x0  > 0 ⇒ x 2  − x  ∈ O (x 2 ) 

cx 2  ≤  x 2  − x  ⇒ 
x 2  − x 
1 
x →∞→  1 ⇒ 
c  ≤ 
x 2  = 1 − 
x 
cx 2  ≤  x 2  − x 
x0  = 2 ⇒ 
2 and 
for 
c  = 1/
x 2  − x  ∈  Ω(x 2 ) 

9  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

10  / 43

Preliminaries 
Big O Notation 

Example 

Preliminaries 

Preliminaries 

Preliminaries 
Big O Notation 

We had  that 

2  − x  ∈ O (x 2 ) ∩ Ω(x 2 ).  In general 
x 
Θ(g (n)) = O (g (n)) ∩ Ω(g (n)). 

The set 
is  then  the set of  functions  for which 
Θ(g (n)) 
asymptotic bound. 
o(g (n)) –  the set of  functions  for which g  is a  lower bound  that  is 
not  tight. 

tight 

g 

is a 

Black – 

x 2  − x 
, blue – 

x 2 
, red – 

x 2/2. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

11  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

12  / 43

Preliminaries 

Preliminaries 

Preliminaries 
Boundedness 

Preliminaries 
Other Useful Equalities 

Fur ther we say  that a  function  f  is polynomially bounded  if 
f (n) ∈ O (nk ) = nO (1) 

for some constant k , and we say that f  is polylogarithmically bounded if 
f (n) ∈ O ((ln n)k ) =  lnO (1) n 

for some constant k .  As we have  that 
(ln n)a  ∈ o(nk ) 

for any constant k  > 0, we have  that polylogarithmically bounded 
functions grow slower  than polynomial  functions. 

Using Stirling’s approximation we have  that 

n! =  o(nn ) 
ln(n!)  =  Θ(n ln n). 

We  fur ther have  that 
O (1) ⊆ O ((ln n)k )) ⊆ O (n ) ⊆ O (2k ) ⊆ O (n!) ⊆ O (n ) 
n
k

for some constant k  > 0. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

13  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

14  / 43 

Analysis of Algorithms 
Analysis of Algorithms 
Merge 

Analysis of Algorithms 
Analysis of Algorithms 
Merge 

Merge  two sor ted  list  l1  and  l2  into a single sor ted  list.  MERGE(l1 , l2 ) 
if  ISEMP TY(l1 ) 
(1) 
return  l2 
(2) 
if  ISEMP TY(l2 ) 
(3) 
return  l1 
(4) 
if  ISLESSEQUA L(F IRS T(l1 ),F IRS T(l2 )) 
(5) 
return (APPEND(L IS T(F IRS T(l1 )),MERGE(RES T(l1 ),l2 ))) 
(6) 
return (APPEND(L IS T(F IRS T(l2 )),MERGE(l1 ,REST(l2 )))) 
(7) 

We assume  that all  these  functions can be done  in a constant number 
of computational steps,  i.e., Θ(1) steps. 

MERGE(l1 , l2 ) 
if  ISEMP TY(l1 ) 
(1) 
return  l2 
(2) 
if  ISEMP TY(l2 ) 
(3) 
return  l1 
(4) 
if  ISLESSEQUA L(F IRS T(l1 ),F IRST(l2 )) 
(5) 
return (APPEND(L IS T(F IRS T(l1 )),MERGE(RES T(l1 ),l2 )))
(6) 
return (APPEND(L IS T(F IRST(l2 )),MERGE(l1 ,REST(l2 ))))
(7) 

|l1 + |l2 | = n, T (n) – number of steps needed  to merge. 
|
� 
n = 1:  all we have  to do  is return non­empty  list, T (1) = Θ(1).
n = 1:  Θ(1) + T (n − 1)
Θ(1) 
T (n − 1) + Θ(1) 

for n = 1,
for n > 1. 

T (n) = 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

15  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

16  / 43

�
Analysis of Algorithms 
Analysis of Algorithms 
Merge 

Analysis of Algorithms 
Analysis of Algorithms 
MergeSor t 

Let us see what happens  if we substitute a number  for n. 

T (3) + Θ(1) 
T (4)  = 
(T (2) + Θ(1)) + Θ(1) 
= 
=  ((T (1) + Θ(1)) + Θ(1)) + Θ(1) 
=  (((Θ(1)) + Θ(1)) + Θ(1)) + Θ(1) 
=  4Θ(1) 

We see  that T (n) = nΘ(1) = Θ(n), meaning  that MERGE(l1 , l2 )  for a 
combined  length of  l1  and  l2  of n  requires Θ(n) steps. 

MERGESORT(l ) 
if  ISEMP TY(l ) 
(1) 
return  l 
(2) 
if  ISS ING LE TON(l ) 
(3) 
return  l 
(4) 
return (MERGE( 
(5) 
MERGESORT(F IRS THA LF(l )), 
(6) 
(7) 
MERGESORT(SECONDHA LF(l )))) 
� 
Θ(1) 
2T (n/2) + Θ(n) 

for n = 1, 
for n > 1. 

T (n) = 

= Θ(n ln n) 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

17  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

18  / 43

Think binary  tree... 

Analysis of Algorithms 
Analysis of Algorithms 
Space Complexity 

Analysis of Algorithms 
Analysis of Algorithms 
Space Complexity:  Merge 

Similarly  to  time complexity, we can analyze algorithms  in  terms of 
space requirements.  For  input size n, S (n) denotes  the number of 
memory  locations we need. 

MERGE(l1 , l2 ) 
if  ISEMP TY(l1 ) 
(1) 
return  l2 
(2) 
if  ISEMP TY(l2 ) 
(3) 
return  l1 
(4) 
if  ISLESSEQUA L(F IRS T(l1 ),F IRST(l2 ))
(5) 
return (APPEND(L IS T(F IRS T(l1 )),MERGE(RES T(l1 ),l2 )))
(6) 
return (APPEND(L IS T(F IRST(l2 )),MERGE(l1 ,REST(l2 )))) 
(7) 
� 
1.  Arguments are given by reference. 
Θ(1) 
S (n − 1) + Θ(1) 

for n = 1,
for n > 1. 

S (n) = 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

19  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

20  / 43

S (n) = Θ(n) 

Analysis of Algorithms 
Analysis of Algorithms 
Space Complexity:  Merge 

Analysis of Problems 
Analysis of Problems 

MERGE(l1 , l2 ) 
if  ISEMP TY(l1 ) 
(1) 
return  l2 
(2) 
if  ISEMP TY(l2 ) 
(3) 
return  l1	
(4) 
if  ISLESSEQUA L(F IRS T(l1 ),F IRST(l2 ))	
(5) 
return (APPEND(L IS T(F IRS T(l1 )),MERGE(RES T(l1 ),l2 ))) 
(6) 
return (APPEND(L IS T(F IRST(l2 )),MERGE(l1 ,REST(l2 )))) 
(7)	
� 
2.  Arguments are given by value (copied). 
Θ(1)	
�
S (n − 1) + Θ(n) + Θ(1) 
⇒
n 
i =1  i  = n(n + 1)/2  S (n) = Θ(n2 )
What does  that do  to T (n)? 
Staal A. Vinterbo  (HST/DSG/HMS) 

for n = 1,
for n > 1. 

S (n) = 

Complexity 

HST 951/MIT 6.873 

The complexity of a problem can be described  in  terms of  the  time and 
space complexity of  the algorithms  that solve  the problem. 
An  impor tant proper ty of an algorithm  is  the worst case  time 
expenditure  for a given problem size,  i.e.,  the maximum  time  the 
algorithm  takes over all problems of at most a given size. 

21  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

22  / 43 

Analysis of Problems 
Analysis of Problems 
Relational View 

P and NP 

Analysis of Problems 
Analysis of Problems 
NP­Relations 

P and NP 

Example 
Binary relation  Sor ted  on  the set of ﬁnite  lists of numbers. 
R
is  in  Sor ted  if and only  if 
is  the sor ted version of 
R
(l , ls )
ls 

l . 

Example 
I  – n × m 
matrices 
M 
n} 
{1,2
– 2
S 
,...,
⊆ I × S  � 
(M , C ) ∈ R
if and only  if 
M [i , j ] > 0 
i =C 

Cover 

for all  ∈ {
j 

1, 2

, . . . ,

m}. 

Deﬁnition (NP­Relation) 
R  ⊆ I × S 
is an NP­relation  if  the characteristic  function 
x  ∈ I . 
|x |
for all 
computable  in polynomial  time  in 

χR  of R  is 

Deﬁnition (P­Relation) 
R  ⊆ I × S 
y  ∈ R (x ) 
is an P­relation  if we can compute 
An NP relation 
∅
x  ∈ I . 
|x |
) = in polynomial  time  in 
or determine  that 
for all 
R (x 

Problems as NP­relations 
– problem  instances 
I 
– solutions 
S 
P­relations are problems  that are solvable  in polynomial  time, 
NP­relations are problems  that are checkable  in polynomial  time. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

23  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

24  / 43

Analysis of Problems 
Analysis of Problems 
Big Question 

P and NP 

Analysis of Problems 
Analysis of Problems 
Sat 

P and NP 

BIG Question 
P = NP? 

Not conclusively answered, although most believe  it not  true. 

Example (SAT) 
Let V  be a ﬁnite set of boolean variables, and  let a  literal be a boolean 
variable or  its negation.  Fur ther  let a be a set of  literals.  A clause  is 
satisﬁed by a variable value assignment (setting)  if at  least one of  the 
literals evaluates  to  true.  If we  let 
I  = 2C  − ∅, where C  is  the set of all clauses over V , 
S  be  the set of all variable value assignments, and 
R  ⊆ I × S  such  that R (x )  is  the set of all variable value 
assignments such  that all clauses  in x  are satisﬁed. 
Then R  is  the SAT NP­relation. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

25  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

26  / 43 

Analysis of Problems 
Analysis of Problems 
Reductions 

P and NP 

Analysis of Problems 
Analysis of Problems 
Reductions 

P and NP 

Let R1  and R2  be  two NP­relations. We deﬁne a reduction  from R1  to 
R2  as a  tuple of  functions (f , g ) such  that 
(x , g (x , y )) ∈ R1  ⇐⇒  (f (x ), y ) ∈ R2 . 
We write R1  ≤ R2 . 

x

g (x , y )  o

f 

g 

f (x ) 
AR2 
y 

AR1 (x ) = g (x , AR2 (f (x ))) 

Example 
Rsor t  is R2 
Rmax  is R1 
Let  f (x ) = x , and g (x , y ) = last(y ),  then 
max(x ) = g (x , sort(x )) = last(sort(x )). We have  that Rmax  ≤ Rsor t . 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

27  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

28  / 43 

/
/


o
Analysis of Problems 
Analysis of Problems 
NP­Completeness 

P and NP 

Analysis of Problems 
Analysis of Problems 
NP­Completeness 

P and NP 

Deﬁnition (Polynomial  time reduction) 
If  f  and g  are both computable  in polynomial  time, we call a reduction 
(f , g ) a polynomial  time reduction, and use R1  ≤p  R2  to  indicate  that 
we have a polynomial  time reduction  from R1  to R2 . 

Deﬁnition (NP­Complete NP­relation) 
If R  ≥p  R �  for all NP­relations R � ,  then R  is NP­Hard.  If R  is an 
NP­relation, R  is NP­Complete. 

NP­Complete NP­relations are  the “hardest” NP­relations.


Transitivity of reductions 
Note  that ≤p  is  transitive. 
This means:  reduction  to one NP­complete relation  is enough. 

Cook’s Theorem 
Need a seed:  Satisﬁability  is NP­complete (Cook 1971) 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

29  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

30  / 43 

Analysis of Problems 
Analysis of Problems 
NP Completeness of 3­Sat 

P and NP 

Example (3­SAT) 
3­SAT  is  the SAT problem where clauses are restricted  to be of 
cardinality 3. 

Theorem (3­SAT  is NP­complete) 
3­SAT  is NP­complete. 
Proof. 
⎧ ⎪⎪⎪⎨ ⎪⎪⎪⎩ 
Each c  = {z1 , . . . , zk }  is  transformed as (using fresh y ): 
{{z1 , y1 , y2}, {z1 , y 1 , y2}, {z1 , y1 , y 2}, {z1 , y 1 , y 2}} 
{{z1 , z2 , y }, {z1 , z2 , y }} 
c 
{z1 , z2 , y } ∪ {{yi , zi +2 , y i +1 }|1 ≤  i  ≤ k − 4} ∪ {y k −3 , zk −1 , zk } 
Staal A. Vinterbo  (HST/DSG/HMS) 

c ⇒ 

Complexity 

Analysis of Problems 
Analysis of Problems 
Optimization problems 

Optimization Problems 

Deﬁnition (Optimization problem) 
An optimization problem  is a  three  tuple (R , m, �), where 
R  ⊆ I × S ,  I  are  instances, S  are solutions, 
m  is a  function m  :  R → N, 
�  is an element of {≤, ≥}. 

Deﬁnition 
For an optimization problem (R , m, �), the set R (x ) is the set of feasible 
solutions  for  the  instance x , m(x , y ) is  the measure of solution y  of 
instance x , m∗ (x ) = z  such  that z  = m(x , y ) for some y  ∈ R (x ) and 
z � m(x , y � ) for all y �  ∈ R (x ).  Also, y (x ) = {y  ∈ R (x )|m(x , y ) = m∗ (x )}. 

if k  = 1 
if k  = 2 
if k  = 3 
if k  > 3 

HST 951/MIT 6.873 

31  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

32  / 43 

Analysis of Problems 
Analysis of Problems 
NPO problems 

Optimization Problems 

Analysis of Problems 
Analysis of Problems 
Ver tex Cover 

Optimization Problems 

This means  that m∗ (x ) is  the optimal measure  for problem  instance x , 
and y (x ) is  the set of optimal solutions  for problem  instance x .  Also, � 
is called  the goal, and  the problem  is a minimization problem  if � =≤, 
and a maximization problem  if � =≥. 
Deﬁnition (NP­Optimization (NPO) Problem) 
, � is an NPO problem  if 
An optimization problem 
(R , m )
R n  = {(x , y ) ∈ R |m(x , y ) � n} 
is an NP­relation, and 
is computable 
m 
in polynomial  time. 

Example (Ver tex Cover) 

If we  let  be a universe of ver tices 
V 
V �  ⊆ V 
V � , E )
be  the set of all graphs  = (
, and 
, where 
I 
G 
E  ⊆ V �  × V � , 
S = 2V 
, and 
R  ⊆ I × S 
S  ∈ R (x )
such  that 
u , v }  �= ∅, 
have  that  ∩ {
S 
|S |, ≤)
Then (R , m(S
is  the Ver tex Cover minimization problem. 
) =

is such  that  for all 

(u , v ) ∈ E 
, we 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

33  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

34  / 43

Analysis of Problems 
Analysis of Problems 
NP­hard NPO problems 

Optimization Problems 

Analysis of Problems 
Analysis of Problems 
Ver tex Cover  is NP­hard 

Optimization Problems 

Deﬁnition (NP­hard NPO problem) 
(R , m ) is NP­hard  if R n 
An NPO problem 
, �

is NP­complete. 
A 
for 
If we could ﬁnd a polynomial time algorithm 
, � , we can ﬁnd 
(R , m )
y  ∈ R n (x )
∅ 
R n (x 
) = in polynomial  time as  follows:  if 
or determine  that 
y  ∈ y (x )
∅
m∗ (x ) > n  then R n (x 
) = , otherwise return 
.  This means  that 
if (R , m )
, � is NP­hard, a polynomial  time algorithm  for  this problem 
= P
would mean NP 
. Hence,  it  is believed  that  there exist no 
polynomial  time algorithm  for NP­hard NPO problems. 

Theorem 
Ver tex Cover  is NP­hard 

Proof. 
Reduction  from 3­SAT: 
U  = {a, b , c , d }, 
C  = {{a, c , d }, {a, b , d }} C  is 
satisﬁable  if and only  if 
in ﬁgure 
G 
has a ver tex cover of size 
K  = |U | + 2 ∗ |C | =
8 or  less 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

35  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

36  / 43

Analysis of Problems 
Analysis of Problems 
Approximation proper ties 

Approximation proper ties 

Analysis of Problems 
Analysis of Problems 
Ver tex Cover Example 

Approximation proper ties 

Deﬁnition (Performance ratio) 
x  and y  ∈ R (x ), 
Let (R , m )
, � be an NPO problem.  Given an  instance 
� 
� 
x  as 
of y 
with respect  to 
we deﬁne  the performance ratio 
m∗ 
R (x ) 
mR (x , y ) 
RR (x , y  max 
, 
. 
) =
m∗ 
R (x ) 
mR (x , y ) 

Deﬁnition (r­approximation algorithm) 
(R , mR , ∗)
A
We say  that a polynomial  time algorithm 
is an 
for problem 
RR (x , A(x )) ≤ r (|x |)
x . 
r (n)
for all instances 
­approximation algorithm if 

Example (Ver tex Cover) 
V , E )
G 
Graph  = (
.  Find minimum cardinality 
(u , v ) ∈ E 
u , v } �= ∅. 
, we have  that  ∩ {
V 

V � ⊆ V 

such  that  for all 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

37  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

38  / 43 

Analysis of Problems 
Analysis of Problems 
Ver tex Cover Example 

Approximation proper ties 

Analysis of Problems 
Analysis of Problems 
Ver tex Cover Example 

Approximation proper ties 

Proof 

Example (Ver tex Cover) 
V , E ) 
VC(
repeat 
choose any edge 
V � ← V �
u , v }
∪ {
remove  from  any 
E 
until E  = ∅
return V � 

(u , v ) ∈ E 

e 

incident  to either 

v  or u 

Remove all edges except  those  in VC(

V , E ) 

Claim:  VC  is a 2­approximation algorithm. 

You need at  least half of  the ver tices  in VC(

V , E ) 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

39  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

40  / 43 

Analysis of Problems 
Analysis of Problems 
Good and Bad News 

Approximation proper ties 

Analysis of Problems 
Analysis of Problems 
Good and bad problems 

Approximation proper ties 

Good News 
Existence of  ­approximation algorithm 
r 

Bad News 
Proof of non­existence of 
(typically P  =P=NP). 

r �

­approximation algorithm, unless 

P 

Good problems 
FPTAS  ­approximation possible  in 
r 
Maximum Knapsack. 

p(|x |)p � (1/(1 − r )) 

time.  Example: 

Bad Problems 
is empty or not  is NP­hard. 
Problems where deciding whether 
R (x ) 
Examples:  Max(min)imum Weighted Satisﬁability, Minumum 
{0, 1}
­integer programming. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

41  / 43 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

42  / 43

Analysis of Problems 
Analysis of Problems 
Prediction of hardness 

Approximation proper ties 

Results given so  far are worst case analysis results. 
non­randomness of  instance hardness? 
Analysis of randomized  instances by statistical mechanics and phase 
transitions between regions of hard and not­so­hard  instances. 

Staal A. Vinterbo  (HST/DSG/HMS) 

Complexity 

HST 951/MIT 6.873 

43  / 43

