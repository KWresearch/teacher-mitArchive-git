Harvard-MIT Division of Health Sciences and Technology 
HST.951J: Medical Decision Support, Fall 2005
Instructors: Professor Lucila Ohno-Machado and Professor Staal Vinterbo 

Motivation 


Putting  it  together :  Learning Fuzzy Rules 

Staal A. Vinterbo 

Harvard­MIT Division of Health Science and Technology 

Decision Systems Group, BWH 

Harvard Medical School 

Nov 9 2005:  HST 951/MIT 6.873 Class 

�  Put our knowledge  into action

�  Show a practical classiﬁer development cycle


Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

1  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

2  / 26 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Background: What  is a rule? 

Background 

Fuzzy rule:  (α → β ) 
�  α  is a conjunction over propositions over a  fuzzy sets,  i.e, contains 
only ∧ and  fuzzy set membership  function names. 
�  β  is a proposition over a  fuzzy set. 
→ 
The result of application of (α
β )  is  I (β , x ) = I (α, x ).

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Background:  Rule Example 

Background 

Example 
a = 1 ∧ b = 0  XOR = 1 applied  to x  ∈ [0, 1]2  results  in 
⇒
I (XOR = 1, (x1 , x2 )) = min(µT (a=1) (x1 ), µT (b=0) (x2 )). 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

3  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

4  / 26 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Background: What  is  it? 

Background 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Background:  De­fuzzyﬁcation 

Background 

A  fuzzy rule classiﬁer  is 
�  a set of rules 
�  a way  to apply  these rules  to a data point 
Let (α1  → β1 ) and (α2  → β2 ) be  two rules.  Applying  these  to a point x 
yields memberships  for β1  and β2 .  If β  = β1  = β2 , we assign  the 
maximal of  the  two memberships  to β ,  justiﬁed by 
(α1  → β ) ∧ (α2  → β ) ↔ ((α1  ∨ α2 ) → β ) 

What  if we after  the application of  two rules have  two memberships  in 
β1  and β2 , respectively, but need  to choose one? 
�  We  take  the Bayesian approach:  choose  the one with  the maximal 
membership. 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

5  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

6  / 26 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Process 

Induction  from Data 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Induction 

Induction  from Data 

Step 3,  learning  fuzzy rules  from data  is a process of  its own: 

The  induction of a  fuzzy rule classiﬁer  from data process has several 
steps: 
1.  Data acquisition 
2.  Data preparation (aka.  preprocessing) 
3.  Learning of rules 
4.  Validation of rules 
For now, we will concentrate on step 3. 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

7  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

8  / 26 

Induction  from Data 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Generating Membership  functions 1 
⎧⎨ ⎩

Let v  < w  and  let ρ be deﬁned as 
if x  ≤ v 
0 
1 
if x  > w 
x −v  otherwise
w −v 
Let s = v0 , v1 , . . . , vn−1  be an  increasing sequence of real numbers of 
size n. We associate n  functions with s  the  following way: 
µ0 (x ) =  1 − ρ(x , v0 , v1 )

µn−1 (x ) =  ρ(x , vn−2 , vn−1 )

µi (x ) =  min(ρ(x , vi −1 , vi ), 1 − ρ(x , v , vi +1 ))
i 

ρ(x , v , w ) =


Induction  from Data 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Generating Membership  functions 2 
How do we select  the sequence? 
�  We use quantiles of  the  input vector x .  For n  levels we use  the 
numbers 
[−∞, x1 , x2 , . . . , xn , ∞]
where xi  is the value at which 100 ∗ (i − 1)/n percent of the values 
found  in x  are smaller  than x

.i 
Example 

If x  consist of 40 uniformly 
sampled reals  from  the unit 
interval, and we want  three 
fuzzy sets, we get: 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

9  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

10  / 26 

Induction  from Data 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Discretizing Data 
Let  fi ,  i  ∈ {1, 2, . . . , m} be m membership  functions.  A discretization of 
a vector x  = (x1 , x2 , . . . , xn ) according  to maximal membership  is  the 
vector (l1 , l2 , . . . , ln ) where  lj  is such  that  flj (xj ) is  the maximal of 
{f1 (xj ), f2 (xj ), . . . , fm (xj )}. 
Example 
A column x  for which we want  three  levels,  i.e., we have  the sequence 
[−∞, min(x ), median(x ), max(x ), ∞] we assign  level  l (v ) to all values 
⎧ ⎪⎨ ⎪⎩

v  like: 
1 
2 
3 
Tables are discretized columnwise, excluding  the class column. 

if v  ≤ t1  = min(x ) +  (median(x )−min(x )) , 
2 
if  t1  < v  ≤ t2  = median(x ) +  (max(x )−median(x ))) ,
2
if v  > t2 . 

(v ) = 
l 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Rule  Induction 

Induction  from Data 

For each row  i  in  the discretized data  table T  we approximate a

minimum set Ai  of non­outcome attributes  that allow us  to discern

between  i  and all rows  j  that have a different outcome  than row  i .

Given  this ordered set Ai , we  instantiate a rule as

((∧a∈Aa = T [i , a]) → c  = T [i , c ] where c  is  the  index of  the outcome

attribute. 

Example 
If A = (a, b), T [i , (a, b , c )] = (1, 1, 5),  then we get  the rule 
((a = 1 ∧ b = 1) → c  = 5) 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

11  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

12  / 26 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Rule  Induction 
Example 

Induction  from Data 

C
g1  g2  g3 
ALL 
3
1 
2 
3
1 
3 
ALL 
3 AML

3 
2 
2 AML 
1 
2 

x1 
x2 
x3 
x4 

:  {{g1 , g3}, {g2 , g3}∗}

:
 {{g1 , g2}, {g2 , g3}∗}
:  {{g2}∗}

{{g3}∗}

:


M [x1 , x3 ] =  {g1 , g2} 
M [x1 , x4 ] =  {g3}

M [x2 , x3 ] =  {g2} 
M [x2 , x4 ] =  {g1 , g3} 

((g2  = 1 ∧ g3  = 3) → C  = ALL)
((g2  = 1 ∧ g3  = 3) → C  = ALL)

→ 
(g2  = 2  C  = AML)
→ 
(g3  = 2  C  = AML)

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Rule Filtering 

Induction  from Data 

The objective of rule ﬁltering  is  to remove redundant rules. We 
determine redundancy relative  to  the combination of a set of rules R , a 
data set T , and a measure of classiﬁcation quality q : 
Deﬁnition 
A rule r  is redundant wr t.  to R , T  and Q  if 
Q ((R ∪ {r })(T ), T ) ≤ Q (R (T ), T ), i.e, if adding rule r  does not improve 
the classiﬁcation of T . 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

13 

/ 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

14  / 26 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Rule Filtering 1 

Induction  from Data 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Rule Filtering 2 

Induction  from Data 

Given a set of rules R  = {ri  =1  and a set of data points T {xi }i =1 , we 
}m
n
i 
can  form a matrix Vm×n  by  letting V [i , j ] = ri (xj ) = I (αi , x )  for  the rule 
� 
ri  = (αi  → βi ).  Fur ther  let J  be  the m × n matrix given by 
if βi  agrees with  the class of xj , and 
1 
−1  otherwise. 
Let W [i , j ] = V [i , j ] ∗ J [i , j ]. 

J [i , j ] = 

Deﬁnition 
Let R , T , W  be deﬁned as above.  Let I  be  the smallest set of  indexes 
� 
�
such  that 
n
n
m 
m
I (max W [i , j ] + min W [i , j ] > 0)
i =1 
i =1 
j =1 
j =1 

I (max W [i , j ] + min W [i , j ] > 0) ≥ 
i ∈I 
∈I 
i

where  I (p) returns  the  truth value of  the proposition p .  The set 
R �  = {ri } ∈I  is a ﬁltering of R  relative  to T .
i 
In other words, a ﬁltering of a rule set  is  the smallest rule set  that does 
not classify T  worse  than R . 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

15 

/ 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

16  / 26 

A Fuzzy Rule Classiﬁer 
Fuzzy Rule Classiﬁer 
Writing Classiﬁer Code 

Induction  from Data	

Tuning our classiﬁer 
Tuning of Filtering Parameter 
Overview 

Once a set of rules has been  found  it  is useful  to be able  to distribute 
this as an applicable package. We approach  this by having a program 
transform our  internal representation of our rules  into a stand­alone 
program text that can be applied to data.  Programming languages that 
�	 allow computing on  the “language”,  i.e.,  let you  treat programs as 
data and vice versa, and 
�	 can deal with higher order  functions,  i.e.,  functions  that return 

functions, 

make  this relatively painless.  Examples of such  languages are 
Scheme, Lisp, and R. 

Standard situation: 
�  One data set 
�  Want  to create a classiﬁer  from  the data set 
�  Have  to  tune  learning parameters, and 
�  Validate our classiﬁer 
How do we deal with  this having one data set? What  follows  is a 
strategy based on a standard way of eliciting model performance: 
cross validation (CV). 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

17  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

18  / 26 

Tuning our classiﬁer 
Tuning of Filtering Parameter 
Cross Validation 

Tuning our classiﬁer 
Tuning of Filtering Parameter 
Cross Validation 

Let Mθ  be a model building process,  i.e, Mθ (T ) = C , where C  is a 
model (classiﬁer)  instance, T  is  training data, and θ  are model building 
parameters.  Also,  let Q  be a classiﬁcation quality measure  function 
such  that Q (C , T )  is  the quality of  the classiﬁcation of T  by model 
instance (classiﬁer) C . 
Deﬁnition 
Let  i  be a positive  integer.  Par tition T  into  i  equally sized sets Ti .  The 
vector (q1 , q2 , . . . , qi ), where qi  = Q (Mθ (∪j =i Tj ), Ti )  is  the result of 
i ­fold crossvalidation. 
We can  then  look at  the sample mean and sample variance of  the 
values qi . 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

19  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

20  / 26 

�
Tuning our classiﬁer 
Tuning of Filtering Parameter 
Comparing Cross Validations 

Tuning our classiﬁer 
Tuning of Filtering Parameter 
Procedure 

Let q  and p  be  the results of  two  i ­fold crossvalidations such  that qj 
and pj  were computed on  the same  training and evaluation data split. 
If we  let di  = qi  − pi , we can  then compare q  and p  in  terms of a  t­test 
for sample mean equality using 
√
d 
sd 
a statistic  that  is T distributed with  i − 1 degrees of  freedom.  Of 
interest  is  the p = P (T  > t ) value.  This value can be  interpreted as  the 
probability  that  the observed differences  in means  is by chance alone. 

t  = 

i 
, 

Recall  that our  fuzzy classiﬁer synthesis process (FCS) had  two 
inputs: 
�  training data, and 
�  ﬁltering data. 
Given a data set T � ,  let θ  be  the  fraction of  this data set  that  is 
randomly split off  into a ﬁltering data set F ,  leaving T �� .  Denote  this 
process by Sθ (T � ) = (T �� , F ). We can now construct our classiﬁer as 
C  = FCS(T �� , F ). We can now empirically compare  two different 
settings of θ , θ1  and θ2 , by  i ­fold crossvalidation by  letting 
qi  =  Q (FCS(Sθ1 (∪j �=i Tj )), Ti ) 
pi  =  Q (FCS(Sθ2 (∪j �=i Tj )), Ti ) 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

21  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

22  / 26 

Validation 
Classiﬁer  Instance 

Validation 

Validation 

Overall Process 

A classiﬁer  instance can only be evaluated on data  that has not been 
seen during  the construction process.  Unlike model performance 
evaluation, cross­validation  is not a strategy we can apply.  Having one 
data set, we cannot but 
�  making a simple split  into  training data T  and validation data V . 
Hence, our evaluation of our classiﬁer C  is 

Q (C , V ). 

Having one data set D  and one classiﬁer  learning method M , we can 
envision at least two ways of producing a tuned and validated classiﬁer. 
They differ  in how we view validation, whether we require  the par ticular 
model  instance  to be validated or  if we accept model evaluation. 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

23  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

24  / 26 

Validation	

Validation 

Overall Process	
Instance Validation 	

Overall Process 
Model Validation 

1.	 Split  the data D  into  training set T  and validation set V . 
2.	 Perform CV parameter  tuning procedure using only T . 
3.	 Compute ﬁnal model  instance C  from T  using  tuned parameters. 
4.	 Validate model  instance C  on V  as q = Q (C , V ). 
Denote  the ﬁnal classiﬁer resulting  from  this process as C  = TII(M , T ) 
(TII = “tuned  instance  induction”). 

The strategy here  is  to validate  the  induction process  instead of  the 
model  instance, allowing  the use of all  the data  for  the construction of 
the ﬁnal model. 
1.	 Perform  i  fold crossvalidation on D where

qi  = Q (TII(M , ∪j �=i Di ), Di )

2.	 Let  the result of  the crossvalidation be  the validation of  the ﬁnal

model C  = TII(M , D ).


Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

25  / 26 

Staal A. Vinterbo  (HST/DSG/HMS) 

More Fuzzy Stuff 

HST 951/MIT 6.873 

26  / 26 

