Fast  Fourier Transform Notes 
18.310, Fall  2005, Prof. Peter  Shor 

1 

Introduction:  Fourier  Series 

y(x) = 

Early in the Nineteenth century, Fourier studied sound and oscillatory motion and conceived 
of the idea of representing periodic functions by their coeﬃcients in an expansion as a sum of 
sines  and  cosines  rather  than  their  values.  He  noticed,  for  example,  that  you  can  represent 
the  shape  of  a  vibrating  string  of  length  L,  ﬁxed  at  its  ends,  as 
� 
 
�
ak  sin(�kx/L) 
x=1 
The  coeﬃcients,  ak ,  contain  important  and  useful  information  about  the  quality  of  the 
sound  that  the  string  produces,  that  is  not  easily  accessible  from  the  ordinary  y  =  f (x) 
description  of  the  shape  of  the  string. 
This kind of representation  is called a Fourier  Series, and there is a tremendous amount 
of  mathematical  lore  about  properties  of  such  series  and  for  what  classes  of  functions  they 
can be shown to exist.  One particularly useful fact about them is the orthogonality property 
of  sines: 
  L 

L 
⎛
. 
sin(�kx/L) sin(�jx/L)dx = �j,k 
2 
x=0 
Here  �j,k  is  the  Kronecker  delta  function,  which  is  0  if  j  =  k  and  1  if  j  =  k .  The  integral 
above,  then,  is  0  unless  j  =  k ,  in  which  case  it  is  L/2.  To  see  this,  you  can  write  the 
product  of  these  sines  as  a  constant  multiple  of  the  diﬀerence  between  cos(�(k + j )x/L) 
and  cos(�(k − j )x/L),  and  realize  that  unless  j  = ±k ,  each  of  these  cosines  integrates  to  0 
over  this  range. 
By multiplying  the  expression  for  y(x)  above  by  sin(�jx/L),  and  integrating  the  result 
from  0  to  L,  by  the  orthogonality  property  everything  cancels  except  the  sin(�jx/L)  term, 
and  we  get  the  expression 

aj  = 

f (x) sin(�jx/L)dx 

  L 
2  ⎛
L  x=0 
Now,  the  above  sum  of  sines  is  a  very  useful  way  to  represent  a  function  which  is  0  at 
both  endpoints.  If  we  are  trying  to  represent  a  function  on  the  real  line  which  is  periodic 
with  period  L,  it  is  not  quite  as  useful.  This  is  because  for  a  periodic  function,  we  need 
f (0) =  f (L)  and  f � (0) =  f �(L).  For  the  sum  of  sines  above,  the  terms  with  odd  k  such  as 
sin �x  are  not  themselves  periodic  with  period  L.  For  periodic  functions,  a  better  Fourier 
expansion  is 

� 
� 
 
 
�
�
bk  sin(2�kx/L). 
aj  cos(2�jx/L) + 
y(x) = a0  + 
j=1 
k=1 

1 

≥
It  is  fairly  easy  to  rewrite  this  as  a  sum  of  exponentials,  using  the  identities
 

−ix

cos x  = 

ix 
e + e
2 
ix 
e − e
2i 
This  results  in  the  expression  (with  a  diﬀerent  set  of  coeﬃcients  a j ) 
� 
aj e 2�ijx/L 
�
j=−� 

sin x  = 

y(x) = 

−ix

. 

 

(1) 

The  orthogonality  relations  are  now 
  L 
⎛
x=0 
This means  that  we  now  can  recover  the  a j  coeﬃcient  from  y  by  performing  the  integral 
⎛1  L 
L  x=0 

e 2�ij /L e 2�ik/L  = �−j,kL 

−2�ijx/L 
y(x)e 

aj  = 

(2)

2 

The  Fourier  transform 

f (x) = 

e ikx g(k)dk 

Given  a  function  f (x)  deﬁned  for  all  real  x, we  can  give  an  alternative  representation  to  it 
as  an  integral  rather  than  as  an  inﬁnite  series,  as  follows 
 
⎛
Here  g(x)  is  called  the Fourier  transform of  f (x),  and f (x)  is  the  inverse  Fourier  transform 
of  g(x).  This  is  a  very  important  tool  used  in  physics. 
One  reason  for  this  is  that  exponential  functions  e ikx ,  which  f  is  written  as  an  integral 
sum  of,  are  eigenfunctions  of  the  derivatives.  That  is,  the  derivative,  acting  on  an  expo­
nential, merely multiplies  the  exponential  by  ik .  This makes  the Fourier  transform a useful 
tool  in  dealing  with  diﬀerential  equations. 
Another  example  of  the  Fourier  transform’s  applications  can  be  found  in  quantum me­
chanics.  We  can  represent  the  state  of  a  particle  in  a  physical  system  as  a  wave  function 
ψ(x),  and  the  probability  that  the  particle  in  this  state  has  a  position  lying  between  x  and 
x + dx  is  |ψ(x)|2 dx. 
The  same  state  can  also  be  represented  by  its  wave  function  in  momentum  space,  and 
that wave  function of  the variable  p  is a  constant multiple  of  the Fourier  transform of ψ(x): 
 
⎛

e ikxψ(x)dx 

�(p) = c

2 

We  can  derive  a  formula  for  computing  the  Fourier  transform  in much  of  the  same way 
we  can  compute  Fourier  series.  The  resulting  formula  is 
 
1  ⎛
2� 
where  the  integration  is  over  all  real  values  of  x. 
The  Fourier  transform  can  be  obtained  by  taking  the  Fourier  series  and  letting  L  go  to 
∗.  This  turns  both  the  function  and  its  Fourier  series  into  functions  deﬁned  over  the  real 
line.  The  ﬁnite  Fourier  transform  arises  by  turning  these  both  into  a  ﬁnite  sequence,  as 
shown  in  the  next  section. 

e −ikxf (x)dx 

g(x) = 

3 

The  Finite  Fourier  Transform 

Suppose  that  we  have  a  function  from  some  real-life  application  which  we want  to  ﬁnd  the 
Fourier  series  of.  In  practice,  we’re  not  going  to  know  the  value  of  the  function  on  every 
point  between  0  and  L,  but  just  on  some  ﬁnite  number  of  points.  Let’s  assume  that  we 
have  the  function  at  n  equally  spaced  points,  and  do  the  best  that  we  can.  This  gives  us 
the  ﬁnite  Fourier  transform. 
We  have  the  function  y(x)  on  points  jL/n,  for  j  = 0, 1, . . . , n − 1.  We  would  like  to 
represent  the  function 
 
ak e 2�ikx/L 
�
y(x) = 
k 
but,  of  course,  we  only  have  knowledge  of  y  at  values  of  x = jL/n.  If we  plug  in  x = jL/n 
for  the  value  of  x,  we  get 
 
ak e 2�ij k/n . 

�
k 
There  is  one  more  thing  to  notice  here.  Namely,  that  adding  n  to  k  doesn’t  change  any 
of  the  values  of  e2�ij k/n  because  e2�i  =  1.  Thus,  if  we  just  have  n  equally  spaced  points, 
we  only  need  the  ﬁrst n  terms  from  the  Fourier  series  to  perfectly match  the  values  of  y  at 
our  points.  This makes  sense —  if  we  start  with  n  complex  numbers  y j ,  we  end  up  with  n 
complex  numbers  ak ,  so  we  keep  the  same  number  of  degrees  of  freedom.  The  a k  here  are 
the  ﬁnite  Fourier  transform  of  the  yj . 
How do we compute the ak , given the yj .  It’s not hard to see  that  it works  in essentially 
the  same  way  that  it  did  for  the  complex  Fourier  series  we  talked  about  earlier,  only  we 
have  to  replace  an  integral  with  a  sum.  Thus,  we  get 
 
1 
yj e
n 

�
j 
Here,  again  the  ak  are  the  ﬁnite  Fourier  transform  of  the  y j .  The  inverse  Fourier 
transform  given  above  (Eq.  3)  is  the  same  as  the  ﬁnite  Fourier  transform,  except  we  have
 

yj  = 

(3) 

ak  = 

−2�ij k/n 
. 

(4) 

3
 

put  a  −  sign  on  the  exponent,  and  left  out  the  factor  of  1/n.  In  fact,  you  will  sometimes 
see  the  factor of 1/n  distributed equally, with a 1/≤n on both the  forwards and the  inverse 
Fourier  transforms. 
How  do  we  prove  that  the  formulas  (4)  and  (3)  are  inverse  transforms  of  each  other? 
The proof works  the  same way  as  it  does  for  the Fourier  series,  and  in  fact  this  formula  can 
be  derived  from  (2)  and  (1).  The  orthogonality  relations  turn  into  the  sum 

n−1 
 
e 2�ij k/n  = n�0,k . 
�
j=0 

I’ll  let  you  ﬁgure  out  the  rest  of  it. 

4 

Computing  the  ﬁnite  Fourier  transform 

It’s  easy  to  compute  the  ﬁnite  Fourier  transform  or  its  inverse  if  you  don’t  mind  using 
O(n2 )  computational  steps.  The  formulas  (3)  and  (4)  above  both  involve  a  sum of  n  terms 
for  each  of  n  coeﬃcients.  However,  there  is  a  beautiful way  of  computing  the  ﬁnite  Fourier 
transform  in  only  O(n log n)  steps. 
One  way  to  understand  this  algorithm  is  to  realize  that  computing  a  ﬁnite  Fourier 
transform  is  equivalent  to  plugging  into  a  degree  n − 1  polynomial  at  all  the  n  roots  of 
unity,  e2�ik/n ,  for  0 � k  � n − 1.  The  Fourier  transform  and  its  inverse  are  essentially  the 
same  for  this  part,  the  only  diﬀerence  being  which  n-th  root  of  unity  you  use.  So,  let’s  be 
consistent  with  Prof.  Kleitman’s  notes  and  do  the  inverse  Fourier  transform. 
Suppose  we  know  the  values  of  ak  and  we  want  to  compute  the  yj  using  the  inverse 
Fourier  transform,  Eq.  (3).  Let  the  polynomial  p(x)  be 

p(x) = 

n−1 
 
ak x k . 
�
k=0 

Now,  let  z = e2�i/n .  Then,  it  is  easy  to  check  that  we  have 

yj  = p(z j ). 

This  shows  we  can  express  the  problem  of  the  inverse  Fourier  transform  as  evaluating  the 
polynomial  p  at  the  n-th  roots  of  unity. 
What we will  show  is  that  if n  is  even,  say  n = 2s,  it will  be  possible  to  ﬁnd  two  degree 
s − 1  polynomials,  peven  and  podd ,  such  that  we  get  all  n  of  the  values  yj  for  0 � j  � n − 1 
by plugging  in  the s-th  roots of unity  into  p even  and podd .  The  even  powers of  z  will  appear 
in  peven ,  and  the  odd  powers  of  z  will  appear  in  podd .  If  n  is  a  multiple  of  4,  we  can  then 
repeat  this  step  for  each  of  peven  and  podd ,  so  we  now  have  our  n  values  of  yj  appearing  as 

4
 

the  values  of  four  polynomials  of  degree  n/4 − 1,  when we  plug  the  n th  units  of  unity,  i.e., 
4 
the  powers  of  z 4 ,  into  all  of  them.  If  n  is  a  power  of  2,  we  can  continue  in  the  same  way, 
and  eventually  reduce  the  problem  to  evaluating  n  polynomials  of  degree  0.  But  it’s  really 
easy  to  evaluate  a  polynomial  of  degree  0:  the  evaluation  is  the  polynomial  itself,  which 
only  has  a  constant  term.  So  at  this  point  we  will  be  done. 
The  next  question we  address  is:  how  do we  ﬁnd these  two  polynomials  p even  and  podd? 
We  will  do  the  case  of  peven  ﬁrst.  Let  us  consider  an  even  power  of  z ,  say  z 2k .  We  will  look 
at  the  j -th  term  and  the  (j + s)-th  term.  These  are 
aj z 2kj  and  aj+sz 2kj+2ks 
But  since  z 2s  = zn  = 1,  we  have 

2kj 
2kj+2ks 
= z 
z 
.  Thus,  we  can  combine  these  terms  into  a  new  term  in  the  polynomial  p even ,  with  coeﬃ­
cients 

If  we  let 

we  ﬁnd  that 

bj  = aj  + aj+s 

peven  = 

s−1 
 
bj xj 
�
j=0 

p(z 2k ) = peven (z 2k ). 
Now,  let us do the case of the odd powers.  Suppose we are evaluating p at an odd power 
of z , say z 2k+1 .  Again,  let’s consider the contribution  from the j -th and the (j + s)-th terms 
together.  This  contribution  is 

aj z (2k+1)j  + aj+sz (2k+1)(j+s) . 
Here  we  ﬁnd  that  z (2k+1)s  =  −1.  Why?  Again,  z 2ks  =  1,  and  z s  is  a  square  root  of  1, 
because  when we  square  it  we  get  z 2s = zn  = 1.  Since  z  is  a  primitive  n-th  root  of  1,  z s  is 
not  1,  so  it must  be −1.  We  now  have 
aj z (2k+1)j  + aj+sz (2k+1)(j+s)  = (aj z )z 2kj  + (aj+sz )z 2kj (−1) 
= (aj  − aj+s)z z 2kj 

Setting  the  j -th  coeﬃcient  of  podd  to 
˜bj  = (aj  − aj+s )z j 

and  letting 

s−1 
 
˜bj xj 
podd  = �
j=0 

5 

we  see  that 

podd (z 2k ) = p(z 2k+1 ). 
So  now,  we  can  show  how  the  Fast  Fourier  transform  is  done.  Let’s  take  n = 2 t .  Now, 
consider  an  n ×  t  table,  as  we  might  make  in  a  spreadsheet.  Let’s  put  in  our  top  row 
the  numbers  a0  through  an−1 .  In  the  next  row,  we  can,  in  the  ﬁrst  n 
2  places,  put  in  the 
coeﬃcients of peven , and then in the next  n 
2  places, put in the coeﬃcients of podd .  In the next 
row,  we  repeat  the  process,  to  get  four  polynomials,  each  of  degree  n 
4  − 1.  After  we  have 
evaluated  the  second  row, we  treat  each  of  p even  and podd  separately,  so  that  nothing  in  the 
n  columns.  In  the  third  row,  we 
ﬁrst  n
columns  subsequently  aﬀects  anything  in  the  last 
2 
2
will  have  in  the  ﬁrst  n 
4  places  the  coeﬃcients  of  peven,even , which  give  us  the  value  of  p(z 4k ) 
n
when  we  evaluate  peven,even (z 4k ).  Then  in  the  next  4  places,  we  put  in  the  coeﬃcients  of 
peven,odd .  This  polynomial  will  give  the  value  of  p(z 4k+2 )  when  we  evaluate  peven,odd (z 4k ). 
The  third  n  places  will  contain  the  coeﬃcients  of  podd,even ,  which  gives  us  the  values  of 
4 
n 
p(z 4k+1 ).  The  last  4  places  will  be  occupied  by  the  coeﬃcients  of  podd,odd ,  which  gives  the 
n
values of p(z 4k+3 ).  From now on, we treat each of these four blocks of  4  columns separately. 
And  so  on. 
There  are  two  remaining  steps  we  must  remember  to  carry  out.  The  ﬁrst  is  that  the 
values  of  p(z k )  come  out  in  the  last  row  in  a  funny  order.  We  have  to  reshuﬄe  them  so 
that  they  are  in  the  right  order.  I  will  do  the  example  of  n = 8.  Recall  that  in  the  second 
row,  the polynomial po ,  giving  odd powers of  z ,  followed  pe , giving  even powers of  z .  In the 
third  row,  ﬁrst  we  get  the  polynomial  giving  z 4k ,  then  z 4k+2 ,  then  z 4k+1 ,  then  z 4k+3 .  So 
in  the  fourth  row  (which  is  the  last  row  for  n = 8),  we  get  the  values  of  p(z k )  in  the  order 
indicated  below. 
0

7 

6

1

2

3
4
coeﬃcients  of  p 

5

pe (z 2k ) = p(z 2k ) 
po (z 2k ) = p(z 2k+1 ) 
pe,o (z 4k ) = p(z 4k+2 )  po,e (z 4k ) = p(z 4k+1 )  po,o (z 4k ) = p(z 4k+3 ) 
pe,e (z 4k ) = p(z 4k ) 
p(z 0 ) 
p(z 4 ) 
p(z 2 ) 
p(z 6 ) 
p(z 1 ) 
p(z 5 ) 
p(z 3 ) 
p(z 7 ) 
You  can  ﬁgure  out  where  each  entry  is  supposed  to  go  is  by  looking  at  the  numbers  in 
binary,  and  turning  the  bits  around.  For  example,  the  entry  in  the  6  column  is  p(z 3 ).  You 
can  ﬁgure  this  out  by  expressing  6  in  binary:  110.  You  then  read  this  binary  number  from 
right  to  left,  to  get  011,  which  is  3.  Thus,  the  entry  in  the  6  column  is  p(z 3 ).  The  reason 
this works  is  that  in  the  procedure we  used,  putting  in  the  even  powers  of  z  ﬁrst,  and  then 
the  odd  powers  of  z ,  we  were  essentially  sorting  the  powers  of  z  by  the  1’s  bit.  The  next 
row  ends  up  sorting  them  by  the  2’s  bit,  and  the  next  row  the  4’s  bit,  and  so  forth.  If  we 
had  sorted  starting  with  the  leftmost  bit  rather  than  the  rightmost,  this  would  have  put 
the powers  in numerical order.  So, by  reversing the bits and sorting, we get  the right order. 
The  other  thing we  have  to  do  is  to  remember  to  divide  by n  if  it  is  necessary.  We  only 
need  do  this  for  the  Fourier  transform,  and  not  the  inverse  Fourier  transform. 

6 

5  Multiplication  and  Convolution 

Let’s  go  back  to  the  complex  Fourier  series.  Suppose  we  have  two  functions  f  and  g . 
Suppose we  have  the  Fourier  series  for  these  two  functions,  that  is, 

f (x) = 

 

� 
aj e 2�ijx/L 
�
j=−� 

and 

� 
bk e 2�ikx/L 
�
k=−� 
How  do we  ﬁnd the Fourier  series  of  the  sum of  these  two  functions?  It’s  easy.  We  take  the 
sum  of  the  Fourier  coeﬃcients. 

g(x) = 

 

� 
(ak  + bk )e 2�ikx/L 
�
k=−� 
How  about  the  product?  This  requires  some  calculation. 

f (x) + g(x) = 

 

f (x)g(x) = 

 

� 
aj bk e 2�i(j+k)x/L 
�
j,k=−� 

 

 

f (x)g(x) = 

Now,  what  is  the  e2�ilx/L  term  of  this  Fourier  series?  We  get  a  contribution  to  l  exactly 
when  j + k = l.  So, 
 
⎝
�
� 
� 
 e 2�ilx/L 
 
�
�
aj bl−j�
�
j=−� 
l=−� 
 
This  sequence,  cl  = 
j  aj bl−j ,  is  known  as  the  convolution  of  sequences  a j  and  bk .  We 
⎠
recently  saw  how  convolutions  come  up  in  generating  functions.  If  you multiply  two  gener­
ating  functions  together,  you  take  the  convolution  of  their  respective  sequences.  The  same 
thing  is  true  in  the  Fourier  transform,  in  Fourier  series  and  the  ﬁnite  Fourier  transform: 
taking the Fourier transform turns pointwise multiplication turns into convolution,  and vice 
versa. 
I  didn’t  do  this  in  class,  but  I  think  it  might  be  worth  going  through  in  these  notes. 
Let’s  check  that  the  convolution  of  functions  turns  into multiplication  of  the Fourier  series. 
Remember  that  f (x)  and  g(x)  are  both  periodic  with  period  L.  Their  convolution  is 
  L 

⎛
⎛

= 

h(y) = 

f (x)g(y − x)dx 
 
aj e 2�ijx/L 
�
�
k 
j

0 
  L 

0 

 
bk e 2�ik(y−x)/L dx 

7 

  L 

= 

⎛
aj bk e 2�i(ky+(j−k)x)/L dx 
0 
 
ak bk e 2�iky/L 
�
=  L
k 

 
L e2�i(j−k)x/L  is  0  if  j  =≥  k . 
where  we  only  get  the  terms  with  j  = k  because  0 
⎞
Wait  a  minute!  Where  did  that  L  come  from?  We  didn’t  get  it  when  we  multiplied  f 
and  g .  I  don’t  have  any  good  intuitive  explanation  for  it  right  now,  but  if  you  look  at  the 
equations,  you  can  see  it’s  really  there.  Remember  this  extra  L.  We’ll  see  it  again  in  a 
couple  of  paragraphs. 
Now,  let’s  work  out  the  details  of  the  fact  that  pointwise  multiplication  turns  into 
convolution  for ﬁnite Fourier series.  Suppose we have  two  sequences and their ﬁnite Fourier 
transforms,  i.e., 

fk  = 

gk  = 

 
aj e 2�ij k/n 
 
bj e 2�ij k/n . 

�
j 
�
j 

What  do we get when we  take  the  inverse Fourier  transform of the pointwise  product f k gk ? 
Let 

fk gk  = 

�
j 

 
cj e 2�ij k/n 

Then  taking  the  Fourier  transform,  we  get 

 

 

=

=

cl  = 

−2�ilk/nfk gk
e 

 
bj � e 2�ij � k/n 

1 
�
n 
k 
 
1 
aj e 2�ij k/n �
e −2�ilk/n �
�
n 
j � 
j 
k
 
 
1 
e 2�ik(j+j �−l)/n 
aj bj � �
� �
n 
j � 
k 
j
 
�
aj bl−j
 
j
 
where  the  last  equality  holds because  the  sum over  k  is  0  unless  l = j + j � .  Thus, pointwise 
multiplication  turns  into  convolutions  for  the  ﬁnite  Fourier  transform  as  well. 
We  can  use  this  fact  that  pointwise  multiplication  turns  into  convolution  to  multiply 
polynomials eﬃciently.  Suppose we have two degree d polynomials, and we want to multiply 
them.  This  corresponds  to  convolution  of  the  two  series  that  make  up  the  coeﬃcients  of 

= 

8
 

the polynomials.  If we do this the obvious way,  it takes O(d 2 ) steps.  However,  if we use the 
Fourier transform, multiply them pointwise, and transform back, we use O(d log d) steps for 
the  Fourier  transforms  and  O(d)  steps  for  the  multiplication.  This  gives  O(d log d)  total, 
a  great  savings.  We  must  choose  the  n  for  the  Fourier  series  carefully.  If  we  multiply  two 
degree  d  polynomials,  the  resulting  polynomial  has  degree  2d,  or 2d + 1  terms.  We  must 
choose n � 2d + 1,  because we need  to have  room  in our sequence a 0 , a1 ,  . . . an−1  for all  the 
coeﬃcients  of the polynomial;  if we  choose n too  small,  the  convolution will “wrap around” 
and  we’ll  end  up  adding  the  last  terms  of  our  polynomial  to  earlier  terms. 
One  can  ask  the  question:  when  you multiply  polynomials  by  taking  the  Fourier  trans­
forms  and  multiplying  pointwise,  how  many  times  do  you  have  to  divide  by  n?  At  ﬁrst 
sight,  it  seems  like  the  answer  should  be  inconsistent.  If  we  ﬁrst  take  the  inverse  Fourier 
transform,  Eq.  (3),  of  each  of  the  polynomials,  multiply  then,  and  then  take  the  Fourier 
transform,  we  end  up  dividing  by  n  when  we  take  the  forwards  Fourier  transform,  so  we 
divide by n once.  On the other hand,  if we  take  the  forwards Fourier  transform of  the poly­
nomials  ﬁrst,  we  have  to  divide  each  of  these  polynomials  by  n.  Then,  when  we  multiply 
them  together,  we  have  divided  each  of  these  by n,  so we’ve  ended  up dividing  by  n 2  total. 
Sot  it  seems  like,  when  we  take  the  inverse  Fourier  transform,  we  should  end  up  with  an 
extra division by n than we did if we  took  the  inverse Fourier  transform ﬁrst.  Both of  these 
methods  can’t  be  right,  since  the  two  answers  diﬀer  by  a  factor  of  n.  What’s  going  on? 
The  correct  answer,  as  you  should  be  able  to  ﬁgure  out  if  you  sit  down  and  write 
everything  out,  is  that  you  only  divide  by  n  once.  This  is  related  to  the  extra  L  term  we 
mentioned  above,  which  turns  into  an  n  when  you  turn  Fourier  series  into  ﬁnite  Fourier 
transforms,  and  cancels  out  one  of  the  extra  factors  of  n. 

6 

Fourier  transforms  modulo  p  and  fast  integer  multiplica­
tion 

So  far,  we’ve  been  doing  ﬁnite  Fourier  transforms  over  the  complex  numbers.  We  can 
actually generalize  them to work over any ﬁeld with a primitive n-th root of unity.  Suppose 
z  is  our  n-th  root  of  unity.  The  main  fact  we  need  to  have  the  ﬁnite  Fourier  transforms 
work  is  that  if  z = 0  and  z n  = 1,  then 
≥ 

n−1 
 
z k  = 0 
�
k=0 
This  holds  for  any  ﬁeld with  a  primitive  n-th  root  of  unity.  The  transforms work  the  same 
way  as  in  Eqs.  (3)  and  (4).  The  inverse  Fourier  transform  is 

yj  = 

n−1 
 
j k 
�
ak z 
k=0 

9 

and  the  forward  Fourier  transform  is 

ak  = 

1 
n 

 
n−1
�
j=0 

−j k 
yj z 

If  we  take  a  prime  p,  then  the  ﬁeld  of  integers  mod  p  has  an  n-th  root  of  unity  if 
p  =  mn +  1  for  some  integer  m.  In  this  case,  we  can  take  the  Fourier  transform  over 
the  integers  mod  p.  Thus,  17  has  16th  roots  of  unity,  one  of  which  can  be  seen  to  be 
3.  So if we use  z  =  3  in  our  fast  Fourier  transform  algorithm,  and  take  all  arithmetic 
modulo  17,  we  get  a  ﬁnite Fourier  transform.  We  can  use  this  for multiplying  polynomials. 
Suppose we  have  two  degree  d  polynomials,  each  of which  has  integer  coeﬃcients  of  size  at 
most  B .  The  largest  possible  coeﬃcient  in  the  product  is  (B − 1) 2 (d + 1).  If  we  want  to 
distinguish between positive and negative coeﬃcients of this size, we need to make sure that 
p > 4(B − 1)2 (d+ 1).  We also need to choose n � 2d+ 1, so as to have at least as many terms 
as there are coeﬃcients  in the product.  We can then use the Fast Fourier transform (mod p) 
to  multiply  these  polynomials,  with  only  O(d log d)  operations  (additions,  multiplications, 
taking  remainders modulus  p),  where we  would  have  needed  d 2  originally. 
Now,  suppose you want  to multiply  two  very  large  integers.  Our  regular  representation 
 
k dkxk 
k dk 10k ,  where  dk  are  the  digits.  We  can  replace  this  by 
of  these  integers  is  as 
⎠
⎠
to  turn  it  into  a  polynomial,  then  multiply  the  two  polynomials  using  the  fast  Fourier 
transform. 
How  many  steps  does  this  take?  To  make  things  easier,  let’s  assume  that  our  large 
integers  are  given  in  binary,  and  that  we  use  a  base  B  which  is  a  power  of  2.  Let’s  assume 
the large integers have m bits each and that we use a base B  (e.g., 10 in the decimal system, 
2  in binary) that has b bits.  We then have our number broken up into m/b “digits” of b bits 
each.  How  large  does  our  prime  have  to  be?  It  has  to  be  larger  than  the  largest  possible 
coeﬃcient  in  the  product  of  our  two  polynomials.  This  coeﬃcient  comes  from  the  sum  of 
at  most  m/b + 1  terms,  each  of  which  has  size  at  most  (2 b  − 1)2  <  22b  This  means  that 
we’re  safe  if  we  take  p  at  least 
m 
+ 1)22b 
( 
b 
m
b  bits. 
or  taking  logs,  p must  have  around  2b + log 2 
Rather  than  optimizing  this  perfectly,  let’s  set  b =  log 2 m;  this  is  simpler  and  will  give 
us  the  right  asymptotic  growth  rate.  We  thus  get  that  p  has  around  3 log 2 m  bits.  We 
then  set  n  = 2 m  +  1,  so  that  our  ﬁnite  Fourier  transform  involves  O(n log n) =  O(m)
b 
operations,  each  of  which  may  be  an  operation  on  a  (3 log 2 m)-bit  number.  If  we  use 
longhand multiplication  and division  (taking O(b 2 )  time)  to  do  these  operations, we  get  an 
O(m log 2 m)-time  algorithm. 
There’s  no  reason  that  we  need  to  stop  there.  We  could  always  use  recursion  and 
perform  these  operations  on  the  3b-bit  numbers  using  fast  integer  multiplication  as  well. 

10 
 

If  we  use   two  levels  of  recu rs ion ,   we  ge t   a n  O ( l ~ ~ n ( l o ~ l o ~ n ) ~ )  
If  we  use  
t im e   a lgo r i thm .  
t h r e e   levels  of  recu rs ion ,  we  g e t   a n  O(1og n(1og log n )  (log log log n ) '   t im e   a lgo r i thm ,  a n d  so  
fo r th .  
I t   t u r n s  o u t ,  a l though   I won ' t  go  in to  t h e  d e t a i l s ,  t h a t  if  you  work  h a r d  enough  you  c an  
g e t   a  O ( n  log n  log log n )   t im e   a lgo r i thm .   T h e  d e t a i l s   c an   b e  found   i n   Aho ,   Hopc ro f t   a n d  
U l lman 's   book   "Design  a n d   Analysis  of  C om p u t e r   Algorithms."  T h i s   a lgo r i thm   uses  t h e  
Ch inese  rema inde r   th eo r em   t o  g e t  a  recursion  t h a t  p roduces   a  r u n n i n g  t im e  ju s t   a  l i t t l e  b i t  
mo r e   efficient  t h a n  w h a t  you  ge t   us ing   recursion  w i th   t h e  m e t h o d   above. 

7 

Details  of  making  a  spreadshee t  

I t   seems  a t  f i rs t   like  t h e  FFT  is  pe r fec t ly   su i t ed   for  a  sp r e ad sh e e t .   I t   c a n   b e   i l lu s t r a t ed  
beau t i fu l ly   by  a  two-dimensional  d iag ram .   However,  once  you  s t a r t  looking  a t  t h e  d e t a i l s ,  
i t  g e t s  fairly  tricky.  T h e  d i ag r am   i l lu s t r a t ing   t h e  FFT  is: 

FFT F igu r e  

H e r e ,   t h e   ou t l ined   boxes  in  t h e   t o p   row  con ta in   ou r   i n p u t .   In   every  black  box  we  p u t  
ai + ai+,  whe re   ai  a n d   ai+,  a r e   t h e   en t r ies   in  t h e   two  boxes  in  t h e  row  connec ted   t o   t h i s  
black  box  by  black  lines.  In   each  yellow  box ,   we  p u t   (a i  - a i+ , ) z z ,  whe re   now  ai  a n d   ai+, 
a r e  t h e  boxes  in  t h e  row  above   connec ted   t o   t h i s  yellow  box  by  b rown   lines.  O n e  t h i n g   t o  
r em emb e r   is  t h a t  z  ( a s  well  a s  s) changes   from  row  t o  row.  In   ca lcu la t ing   t h e  boxes  in  t h e  
second  row, we  use   ou r   original  z .   In   t h e  t h i r d   row, we  use   z 2 .   (So  i n  t e rm s   of  ou r   original 
z ,  we  a r e  really  mu l t ip ly ing   by  zZi he re   a n d  n o t   z i . )   In  t h e  f o u r t h   row,  we  use   z4 .   In   t h e  
f i f th   row,  i t  t u r n s  o u t  we  d o n ' t  need  t o   use  z  a t  a l l ,  since  in  all  th e s e   yellow  boxes  we  have 
i = 0. 
On e  t r icky   t h i n g  a b o u t  t h i s  is  t h a t  we  have  t o  s t a r t  coun t ing  i from  t h e  f i rs t   box  of  t h e  
con t iguous   row  of  yellow  boxes  i t ' s  i n ,  a n d  n o t   from  t h e  column.  So ,  for  examp le ,   i n  row  3 
you  need  t o  g e t  i by  t ak ing   t h e  co lumn   numb e r   mod   4  a n d  n o t  ju s t   t h e  co lumn   numb e r .  

After  row  5, we’re  done with  all  the  addition  steps,  and  have  only  one  or  two  steps  left. 
In  row  6,  we  shuﬄe  all  the  numbers  into  the  red  boxes  according  to  the  reversal-of-binary­
digits  permutation.  If  you’re  constructing  the  spreadsheet  according  to  the  instructions  in 
Prof.  Kleitman’s  lecture  notes,  you  don’t  actually  need  row  6,  because  he  folds  this  shuﬄe 
into  rows  2  through  5.  However,  you  haven’t  really  gotten  rid  of  any  complexity,  because 
he  has made  constructing  rows  2  through  5  are  a  little  more  complicated. 
Finally,  depending  on  whether  we’re  doing  the  FFT  or  the  inverse  FFT,  we  may  need 
to  make  a  row  7  where  we  divide  row  6  by  n,  which  in  this  case  is  16. 
If  we’re  doing  an  FFT  mod  p  for  some  prime  p,  all  of  these  arithmetic  operations  are 
going  to  have  to  be  done  mod  p,  and  in  the  last  step,  we  will  have  to  multiply  by  n −1 , 
which  is  the  integer  satisfying 

n n −1  = 1  mod  p
· 
This  inverse  can  be  found  by  Euclid’s  gcd  algorithm. 
There  are  a  number of  issues  that  can  arise when you  construct  the  spreadsheet  for  the 
homework.  The  ﬁrst  is  the  issue  of  copying  formulas  in  spreadsheets.  Suppose  you  want 
to  give  a  spreadsheet  for  the  FFT  in  which  you  can  easily  change  the  prime  p  and/or  the 
root  of  unity  z .  If  you  put  z  or  p  into  the  formulas,  then  when  you  copy  the  spreadsheet 
you’ll  have  to  change  them  all  by hand.  Furthermore,  if you  get  them by  using  an absolute 
reference  like  $A$3  (say  to  a  cell  containing  p  or  z )  then  when  you  copy  this  cell,  the 
reference  in  the  copy  will  still  points  to  A3.  If  you  want  to  change  the  values  of  p  and  z , 
you  will  need  to  replace  all  these  references. 
Of  course,  you  can  argue  that  this  is  what  the  ﬁnd-and-replace  tool  in  the  spreadsheet 
editor  is  intended  for.  But  Prof.  Kleitman  has  also  ﬁgured  out  how  to  construct  a  spread­
sheet  cleverly  so  that we don’t have  to use this tool.  Suppose we  start our spreadsheet with 
the  three  rows 

A  B  C  D  E  F  G  H  I  J  K  L 
1  0  1  2 
3 
4  5  6 
7  8  9  10  11 
2  p  p  p  p  p  p  p  p  p  p  p  p 
3  z 
z 
z 
z 
z 
z 
z 
z  z  z 
z 
z 

. . . 
. . . 
. . . 

Then  if  we  want  to  make  a  reference  to  p,  we  can  use  a  reference  like  C$2.  This  uses 
the  value  in  the  same  column,  but  the  second  row.  Now,  we  can  copy  our  spreadsheet 
horizontally.  This  changes  C  to  column  farther  to  the  right,  and  we  can  put  a  new  prime 
p  in  the  second  row  of  our  copy.  As  long  as  we  don’t  change  the  rows  our  spreadsheet 
occupies,  but  just move  it  horizontally,  we’re  ﬁne. 
We  now  need  to  calculate  the  values  of  b i  using  the  equations 

bi  =  ai  + ai+s 
˜ 
i
bi  = (ai  − ai+s )z 

12 

The  ﬁrst  case  (bi )  is  easy.  The  second  case  (˜bi )  is  trickier,  because  of  the  z i  term.  The 
obvious  way  is  to  calculate  it  is  to  use  a  statement  like 
= MOD(  (J5  −  N5)  �  z (2�i) ,  p). 
to  calculate  N6  in  row  6,  where  s  =  4  and  we  multiply  by  (z 2 )i .  There  are  two  problems 
with  something  like  this.  The  ﬁrst  is  that,  if  row  2  is  all  p’s and row  3  is all  z ’s, we  can  get 
p  and  z  by N$2  and N$3,  but where  do we  get  the  i  from?  In  row  3,  we  have  two  stretches 
of  four yellow  cells,  and we want  i  to  start  counting  from 0  each  time.  If we  just  reference  i 
up  in  the  ﬁrst  stretch,  we’ll  have  to  change  the  formula  if we  copy  it  to  the  second  stretch. 
This  can  be  solved  by  using MOD(i,  4)  in  the  formula. 
The  second  problem  is  somewhat  more  serious.  This  is  that  using  the  spreadsheet’s 
arithmetic  to  compute  z 2i  is  very  likely  to  give  you  an  integer  overﬂow,  if  z  or  i  is  large. 
What  we  could  do  is  to  create  an  extra  row  that  contains  powers  of  z  mod  p,  and  use  the 
OFFSET  function  to  ﬁnd  the  right  cell  in  it.  This  works  ﬁne,  but  it’s  kind  of  complicated 
and messy,  and  it’s  easy  for mistakes  to  sneak  in. 
Here’s  what  I  think  might  be  the  easiest  solution:  create  another  (n × log 2 n)  array  in 
your  spreadsheet  that  contains  the  numbers  z i  that  you  need  to  multiply  by  ai  − ai+s  in 
the  ˜b  cells.  For  n = 16,  the  numbers  you  need  to  multiply  them  by  look  like 

6  z 
5  z 
z 2  z 3  z 4  z 
7 
1 
− − − − − −2  −4  −6 
z
2
4
6
z 
4  − − −  −4 
1  z
z 
1  z
− − − −4 
z
z
4
− −  1  z  − −  1  z  − −  1  z  − −  1  z 
−  1  −  1  −  1  −  1  −  1  −  1  −  1  −  1 
where  all  of  the  powers  are  performed mod  p.  Here − means  that we  have  b  instead  of  ˜b  in 
the  corresponding  cell,  so  there’s  no  z i  term  needed  for  that  cell. 
How  can  we  constrct  this  second  array?  Since  we’ll  never  actually  be  looking  at  the  −
cells,  we  can  ﬁll  them  in  anyway  we  want,  and  it’s  easiest  to  ﬁll  them  in  with  the  same 
sequence  we  ﬁnd  in  ˜b  cells. 
For  example,  for  n = 16,  if  p = 193,  and  z  = 3  is  our  16th  root  of  1,  we  get 

1  3 
1
9
1 81
1
1

9  27 81 50 150 64 1  3 
9 
1 
50 1
81
81 50
9
81 
1 
1
81
1
81 1 81
1 
1 
1
1
1
1
1
1

9  27 81 50 150 64 
50 
9 
1 
81
81 50
81 
1 
81 
1
81
1
1 
1 
1 
1
1
1

How do we create  this table?  It’s easy.  We get the ﬁrst eight cells  in the top row by sticking 
in  a  1  on  the  left,  and  then  repeatedly  multiplying  by  3  mod  193.  We  can  get  the  rest  of 
the  cells  by  copying  the  cell  8  positions  to  the  left.  In  the  second  row,  we  can  get  the  ﬁrst 
four  cells  by  squaring  the  cells  above  them mod  193,  and  the  rest  by  looking  4  positions  to 

13 
 

the  left.  In  the  third  row,  we  can  get  the  ﬁrst  two  cells  by  squaring  the  celle  above  them, 
and  the  rest  by  looking  2  positions  to  the  left.  Larger  FFT’s  will  work  similarly. 
Unless  you  want  to  use  a  search-and-replace  function,  you  should  remember  to  get  3 
and  193  by  referencing  cells  that  contain  them,  rather  than  coding  them  into  the  formulas. 
Finally, we need to shuﬄe all the entries around, by copying the entry  in each cell to the 
column  obtained  by  reversing  the  digits  of  the  column’s  number  in  binary.  For  example, 
if  n  =  16,  you  would  move  the  entry  in  the  5th  (=  0101)  position  to  the  10th  (=  1010) 
position.  I  didn’t  ﬁnd  it  too  painful  to  construct  this  shuﬄe  by  hand.  I  also  don’t  see 
any  easy  way  of  making  the  spreadsheet  do  it  for  you,  but  I  wouldn’t  be  too  surprised  if 
someone  thinks  of  a  clever  way. 
You  also  need  to  remember  to divide by n.  You  do  this by multiplying  by n−1  (mod p). 
Calculating  n−1  can  be  done  using  the  Euclidean  algorithm,  which  you  should  have  gone 
over  earlier  in  18.310. 
There  are  a  lot  of  ways  to  make  errors  in  this  process.  One  thing  you  can  do  to  make 
it  easier  is  to  start  out  by  making  a  spreadsheet  which  uses  z  = 3  and  p =  17  or  193,  and 
change  the  numbers  to  be  bigger  later.  You  can  also  put  in  test  sequences  where  you  can 
easily  ﬁgure  out  what  the  FFT  should  be,  such  as  putting  in  one  1  and  the  rest  0’s.  I  ﬁnd 
it  useful  to  color  the  cells  using  the  b  formula  one  color  and  those  using  the  ˜b  formula  a 
diﬀerent  color,  so  that  I  could  visually  see  if  I  stuck  these  formulas  in  the  wrong  columns 
by  mistake. 
I’ve  explained  how  to  do  the  FFT  on  a  spreadsheet  using  two  diﬀerent  types  of  cells 
in  each  row:  one  type  that  computes  b  and  another  that  computes  ˜b.  If  you  use  slightly 
more  complicated  formulas, you might be able  to use  just two  formulas  total  for all of  these 
rows,  again,  one  for ˜b and one  for  b, but where these  two  types don’t need to be customized 
for  each  rows.  Here,  I  don’t  see  any  way  to  do  it  without  using  use  the  OFFSET  function 
(which generally makes things more complicated),  and you also need some way to ﬁgure out 
which  row  you’re  in  (which  also  makes  things  more  complicated,  although  not  by  much), 
so  unless you  can  ﬁgure out  some  clever way  of doing  it without  the OFFSET  function,  it’s 
probably  not  worth  the  extra  trouble. 

14 
 

