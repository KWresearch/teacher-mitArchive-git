23. The Finite Fourier Transform and the Fast Fourier Transform 
Algorithm 

23.1 Introduction: Fourier Series 

Early in the Nineteenth Century, Fourier studied sound and oscillatory motion and 
conceived of the idea of representing periodic functions by their coefficients in an 
expansion as a sum of sines and cosines rather than their values. 

He noticed that for example, you can represent the shape of a vibrating string of 
length L, fixed at its ends as 
y(x) = ΣΣΣΣκ = 1,
κκκ = 1,= 1,= 1,∞ ak sin (2ππππkx/L) 

The coefficients, ak, contain important and useful information about the quality of the 
sound that the string produces that is not easily accessible from the ordinary y = f(x) 
representation of the shape of the string. 

This kind of representation of a function is called a Fourier Series, and there is a 
tremendous amount of mathematical lore about properties of such series and for what 
classes of functions they can be shown to exist. 

One particularly useful fact about them is how we can obtain the coefficients ak 
from the function following from the orthogonality property of sines: 
∫∫∫∫ x= 0,L  sin (2πkx/L) sin (2πjx/L) dx = 

To see this notice that the product of these sines can be written as a constant 
multiple of the difference between cos(2π(k+j)x/L) and cos(2π(k-j)x/L), and each of 
these cosines integrates to 0 over this range. 

By multiplying the expression for y(x) above by 2πjx/L and integrating the result 
from 0 to L we get then the expression 
aj  = (1/π)∫∫∫∫x= 0,000,,,L  f(x) sin (2πjx/L) dx. 

Fourier series represent only one of many alternate ways we can represent a 
function. We can derive formulae for coefficients in a series by introducing an 
appropriate weight function in the integral and obtaining an orthogonality relation 
among the functions. 

23.2 The Fourier Transform 

Given a function f(x) defined for all real x, we can give an alternative represent to 
it as an integral rather than as an infinite series, as follows. 

f(x) = ∫∫∫∫ eikx  g(k) dk 

where the integral is over all real values of k. 

The representation of f by the function g is called a Fourier transform of f, and it 
is very important tool used in physics. 

One reason for this is that exponential functions eikx, which f is written as an 
integral sum of, are eigenfunctions of the derivative. That is, the derivative, acting on an 
exponential, merely multiplies the exponential by ik. This makes the Fourier transform a 
useful tool in investigating differential equations. 

Another example of the Fourier transform’ s applications can be found in quantum 
mechanics. We can represent the state of a particle in a physical system as a wave 
function ϕ(x), and the probability that the particle in this state has a position lying 
between x and x+dx is |ϕ(x)|2  dx. 

The same state can also be represented by its wave function in momentum space, 
and that wave function of the variable p, is a constant multiple of the Fourier transform of 
ϕ(x): 

ψψψψ(p) = c ∫∫∫∫ eikx  ϕϕϕϕ(x)dx. 

We can invert the Fourier Transform in much the same way that we can invert 
Fourier Series. The resulting formula is 
g(k) = (1/2π) ∫∫∫∫ e-ikx  f(x) dx 

The integration is over all real values of x. 

23.3 The Finite Fourier Transform 

Given a finite sequence consisting of n numbers, for example the coefficients of a 
polynomial of degree n-1, we can define a Finite Fourier Transform that produces a 

different set of n numbers, in a way that has a close relationship to the Fourier Transform 
just mentioned. 

I like to look at it backwards. 

Suppose we have a polynomial p of degree n-1. It can be described by its 
coefficients, {aj} with 

p(x) = ΣΣΣΣj=  0 to n-1  aj xj . 

We can also represent p by giving its values at any n arguments {p(xk)}. 

This can be done as follows. Observe first that the polynomial of degree n-1 

f(xj)((x-x1) /(xj-x1))*. . .(exclude (x-xj) /(xj-xj)) . . . *((x-xn)/ (xj-xn)) 

takes the value f(xj) at x=xj  and is 0 at all other of our arguments xk. 

We can recover p from its values by summing similar terms over all j. 

To evaluate a polynomial of degree n-1 at n values requires an order of n2  actions: 
n evaluations each of n terms. Similarly the procedure just described for recovering p 
from its values requires at least n2 operations to obtain all the coefficients of p. 

When you evaluate a polynomial at an argument x whose magnitude is not close 
to 1, the powers of x that are big dominate those that are small by overwhelming them so 
much that you have to worry about losing the smaller terms entirely from round off errors. 

The finite Fourier transform can be defined as the act of evaluating a polynomial 
of degree n-1 at n roots of unity, that is, at n solutions to the equation xn=1. 

This transform can be performed upon polynomials with coefficients in any field 
in which this equation has n solutions, which will happen when there is a primitive n-th 
root of unity in the field. (This means a number such that xn = 1 but xk  is not 1 for any k 
between 1 and n-1.) The n roots of unity are then the various powers of the primitive root. 

When does this happen? It does for complex numbers, in which case we have 
e2ππππi/n which is cos(2ππππ/n)+isin(2ππππ/n) 

as primitive n-th root of unity. 

But it also happens for remainders on dividing by a prime number of the form 
kn+1. In such fields there is a primitive kn-th root of unity and hence a primitive n-th root 
of unity (such as the k-th power of the former.) 

The analogy between this finite transform and the Fourier transform is most 
apparent when we use complex numbers. Then, if the coefficients of the polynomial are 
{aj}, the evaluations become 
p e2ππππik/n  = Σj  aj  (cos(2πjk/n)) + iΣj  aj  (sin(2πjk/n)). 

(This is why we say that we are doing things backwards. It is the aj  which are analogous 
to the Fourier coefficients for the function p.) 

Let z be our primitive n-th root of unity. 

Transforms of this kind can be defined for any value of n. And there is a 
symmetric form for the inverse transformation which takes the values, {p(zk)}, which we 
shall abbreviate as {pk}, and produces the aj, so there is no significant difference between 
defining this transform forward or backward. 

We can obtain the inverse transformation by multiplying each pk  by z-sk, and 
summing over the n values of k. We get … 
ΣΣΣΣj,k  aj  zjk*z-sk or ΣΣΣΣj  aj  (ΣΣΣΣk  z(j-s)k) or ΣΣΣΣj  aj  ts-j, 

where tr  is our old friend the sum of the r-th powers of the n roots, zk, of the equation zn  – 
1. 

Recall that this equation, zn  –  1 = 0 has the form Σk  zksk  = 0, where sk is the k-th 
elementary symmetric function of the roots of the equation. 

This implies that the sk  are all 0, for k=1 up to n-1 for our equation, while s0  is 1. 

Recall also that the t ’ s and the s ’ s are linearly dependent according to the relations, 
for each k 

ΣΣΣΣj=0 to k-1 sjtk-j(- 1)j  + ksk(-1)k  =0, 

from which we can deduce that the ts-j  here are all 0, unless s=j. 

When s=j, the sum that forms t0, or tn, which is n, so that we get 
ΣΣΣΣk  pk z-k  =  ΣΣΣΣj,k  aj  zjk*z-sk = nas, 

and 
as  = (1/n) ΣΣΣΣ k  pkz-k . 

Since z-1 is another primitive n-th root of 1 the only difference in this equation, 
and the inverse equation for evaluations is in the factor 1/n. 

23.4 The Cooley-Tukey Fast Fourier Transform Algorithm 

Suppose n is even, so that n can be written as powers of 2. Then this algorithm is 
a procedure for reducing 2s evaluations of polynomials of degree 2s to 2s evaluations of 
polynomials of degree s, upon making a total of s additions, s subtractions and s 
multiplications. Moreover the evaluations consist of evaluating the FFT’ s of two 
polynomials, each of degree s-1, at primitive s-th roots of unity. 

To keep things straight let us describe the evaluations of a polynomial of degree at 
most n-1 at n n-th roots of unity as an n FFT. 

If n is a power of 2, we can iterate this procedure n times, until we reduce the 
problem to n evaluations of polynomials of degree 0, which is a weird way to say that we 
will have obtained our n evaluations. 

The reduction that is the heart of this algorithm is based upon the following 
observations. To perform an n FFT requires evaluating our polynomial of degree up to n ­
1 at the n powers of a primitive n-th root of unity, z. 

1. If we consider the evaluations we seek at the even powers of z, (1, z2, z4, . . . ), these 
powers are the powers 0 to s-1 of the s-th root of unity z2. 

Thus, these evaluations are exactly what is involved in an s FFT; the only 
difference being that we are evaluating a polynomial of degree up to n-1, not up to s-1. 

2. In every even power evaluation, say at z2k, the term in our polynomial ajxj  contributes 
ajz2kj. Thus, the contribution from the j-th and (s+j)-th terms together are 

ajz2kj  + aj+sz2kj+2sk . 

But, z2sk  is znk  which is 1, so that the aj+s contribution here is multiplied by the 
same power of z as the aj  contribution, and can be added to it instead of being treated as a 
separate term. 

3. But this means that the z2k  evaluations here are exactly those of sFFT({aj+aj+s}). 

4. The odd power evaluations, (at z, z3, . . .) each gets a contribution from aj of the form 
ajz(2k+1)j  which we can write as (ajzj)z2jk. Notice that these evaluations can be considered 
evaluations at even roots of unity of a polynomial whose coefficients are given by the 
products (ajzj). 

5.  In every odd power evaluation, say at z2k+1, the term in our polynomial ajxj  contributes 
ajzjz2kj  while the term aj+sxj+s contributes aj+szjzsz2kj +2ks. As in our second observation we 

have z2ks=1, but now we have an additional factor of zs, which is a primitive square root 
of 1, which is  – 1. In other words the contributions from aj  and ( – aj+s) are the same here. 

6. We conclude that we can combine the j and s + j terms by subtraction in the odd power 
evaluations and these become exactly those of sFFT({(aj-aj+s)zj}). 

You will notice that we make an addition for each of our even power evaluations 
in making these reductions, and a subtraction and a multiplication for each of the odd 
powers reductions, and this means that we must perform s of each of these operations to 
reduce the problem by a factor of two. 

The remaining task in completing our evaluations after this reduction consists of 
repeating it in parallel for the even and odd evaluations. After a second reduction, we 
perform 4 reductions in parallel for the even-even, odd-even even-odd and odd-odd 
evaluations (starting in positions z0,z1, z2,z4), and so on. 

23.5 Example 

The following example is just a quick outline that doesn ’ t delve too deeply into 
the actual implementation of the FFT. We will see how to find primitive roots of unity 
and the nuances of each step of completing an FFT in course note 24. 

We illustrate it by starting with 4 coefficients 1,3,2,5 (of powers 0 through 3) and 
do our calculations mod 17. 4 is a primitive 4th  root of 1 whose inverse is – 4 or 13. 

In the first step we replace the even power entries, which are the first and third 
here, by 1+2 and 3+5 respectively, and the second and fourth entries by (1-2)*40  and (3­
5)*41  which produces the sequence 3,16,8,9 mod 17. 

In the second step we replace the first and second entries by 3+8 or 11 and 16+9 
or 8, and the third and fourth by 3-8 or 12 and 16-9 or 7, for an answer of (11,8,12,7) as 
the result of evaluating the polynomial 1+3x+2x2+5x3  at x= 1,4,16 and 13 mod 17. 

It is instructive to see what happens when we apply the same procedure again to 
the sequence obtained here, namely (11,8,12,7). 

In the first step this becomes (6,16,15,4) (the last value comes from (8-7)*4 mod 
17). And in the last step we get (4,3,8,12). 

Notice that if we divide this result by 4 we get (1,5,2,3) (to divide 3 by 4 you can 
add 17 to the 3, divide 20 by 4 and get 5). 

These are the original coefficients of our polynomial, in the order 0,3,2,1. 

The reason for this is that the formula for the inverse of our transformation 
requires dividing by n and also using z-1  in place of z as the primitive n-th root of unity at 
whose powers the evaluations are made. 

And of course evaluating at z-k  is the same thing as evaluating at z(n-k), which 
means the k-th power evaluation for z-1  is the n-k-th for z. 

- Jonathan Lii 

