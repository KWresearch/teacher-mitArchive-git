Labor Supply of Taxi Drivers: 
 
Camerer, Babock, Lowenstein, and Thaler, QJE 97 
 
Recall from the intertemporal model, first order conditions are: 
 
XHCu
,
,
(
t
c
t
t
XHCu
,
,
(
t
H
t
t
++
βλ
=
r
1(
t
t
1

λ=)
 
t
λ−=)
 
w
t
t
λ
 
E
)
+
t
1

)

(

 
where 

tλ is the marginal utility of (expected) wealth at time t. 

)

 

+

w
t

=

A
t

H

t

)

 

t

log

H

+

η
log

∆+∆=
η
A
t

λγ
 
log
t
[
λγ
)
log(
t

 
Can use first order conditions to solve implicitly: 
 
λ=
CC
Xw
,
,
(
t
t
t
t
λ=
HH
Xw
(
,
,
t
t
t
 
A log linear version of this is: 
 
 
log
 
∆
 
 
From first order conditions: 
 
βλ
+
=
Er
1(
)
−
t
t
1
λ
λ
−
log(
log(
)
−
t
t
1
 
so: 
 
∆
 
∆
 
if 
 

λ
 
(
)
t
λ
=
)
log(
t

∆+∆=
η
A
t

∆+∆=
η
A
t

λγ
)
[log(
t

λγ
[log(
)
t

βγ
log
1(

1/(1 ρ
+
)

λ
log(
1−
t

ργ
−
(

 and 

log(
1

x ≈
+ )

log

H

β
1(

+

log

H

])

 

log

w
t

log

w
t

log

w
t

log

E
t

β
=

−

r

)

+

r

)

log

+

+

r

)

x

. 

−

+

t

t

t

−
1
)

+

−

−

(

λ
)
t

−
1

 

log

E
t

−
1

(

λ
)]
t

 

−

−

log

E
t

−
1

(

λ
)]
t

  

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

1 

1 log
−

E
t

−
1

 

−
1

t

 

log

=

λ
t

−

log

log

H

t

log

w
t

log

E
t

+

ργ
−
(

r

)

+

λ
=
t E
t

ϕ
]
exp[
t

E λ
(
)
−
t
t
1

ϕλ
+
 
−
t
t
1

log
E
t
E
t

−
1

−
1

γγϕ
−
log
t

∆+∆=
η
A
t

tϕ is log normal, 

ϕλ
+
 and we’re done.  If not, 
−
−
t
t
1
1

  is  not  the  forecast  error  in  the marginal  utility 

ϕ
λ
 
exp[
]
]
−
t
t
1
ϕ
λ
 
E
exp[
log
]
]
−
−
t
t
t
1
1
λ
ϕ
+
E
]
exp[
log
]
log
−
t
t
1

The  time  preference  component  does  not  vanish  if  ρ  and  r   are  not  equal.    If  relatively  impatient, 
work more and consume less over time.  Vice versa. 
 
λ
We’re not  quite done  yet  because 
)
log(
t
tϕ, where 
of wealth.  Let’s define that as 
 
log
 
If 
 
λ
=
E
exp[
−
t
t
1
λ
=
E
exp[
−
t
t
1
λ
=
E
log(
)
−
t
t
1
 
subbing in: 
 
∆
 
 
Estimating  η  has  proven  difficult.    Of  those  that  are  out  there,  estimates  have  generally  been  low 
and  insignificant,  but  estimation  difficulties  and  the  possibility  that  the  wage  shocks  were  more 
permanent have led to doubt in these results. 
 
Many  jobs  do  not  allow  much  flexibility  in  labor  supply.    To  adjust  labor  supply  most  must  change 
jobs.  But a number of recent papers have used data where workers can control  their hours and are 
subject to transitory shocks. 
 
One of  those  jobs  is  the  taxi driver.   Colin Camerer et al.  suggest New York  cab drivers have good 
days and bad days.   On good days,  there’s a big  conference going on,  the weather  is bad,  subway 
breakdown,  or  some  other  factor  leads  to  an  increase  in  the  demand  for  cabs.   Other  days  there’s 
no  action.    Rates  are  the  same  for  every  cabbie,  but  on  busier  days,  the  driver  spends  less  time 
searching for customers and thus earns a higher hourly wage. 
 
So plausibly, if we can measure good and bad days, we can use this potentially exogenous variation 
as  capturing  wage  shocks  and  estimate  labor  supply  responses.    One  beauty  of  this  approach  is 
that  it  shouldn’t  matter  whether  the  wage  changes  are  expected  or  unexpected,  because  in  either 
case, the change in wealth from a change in daily wage is zero or close to zero. 
 
The  data  come  from  ‘trip  sheets’  of New  York City  cabdrivers.   Colin Camerer  once  drove  a  cab  in 
new  york  for  a  summer,  so  I  presume  this  helped  obtaining  the  data.    Farber  had  a  much  harder 
time.    A  trip  sheet  records  the  list  of  trips  that  drivers  took  on  a  given  day,  including  the  fare  (not 
including tip) and time picked up and dropped off.  12 hour shifts. 
 
3 trip sheet samples 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

2 

−1

=

+

e
th

 

+
0 ββ
w
th
1

 
1) 70 cleaned up trip sheets in 1994 from a fleet company that rent the cabs out 
 
The  fleet  company  rents  out  the  caps  for  about  $80  per  12  hour  shift  +  gas.   Driver  can  return  cab 
anytime  within  the  12  hour  period.  8  drivers  on  more  than  one  day:  allows  the  authors  to  create  a 
panel dataset of labor supply and wages. 
 
Smaller of the 3 datasets, but contains info within days. 
 
hours worked is between first passenger and last passenger dropped off. 
 
Average hourly wage is total revenue dived by hours worked. 
 
Important to show that days that start off as good, stay good.  So cabbies know they face a positive, 
unexpected  shock,  (or  negative).    The  trip  sheet  data  allows  the  authors  to  look  at  the  hourly 
earnings autocorrelation within days 
 
They calculated median hourly wage for all drivers for each hour, and regressed  
 
w
th
 
b1hat is .5.  Correlation between first half and last half is .4. 
 
Also, wages across days appear uncorrelated: 
 
w
t
 
b1hat is -.07 
 
Thus, wages virtually uncorrelated across days and fairly stable within days.   
 
Datasets 2 and 3 have larger panel, but no info on hour to hour. 
 
Sample characteristics: table 1 
 
Average hours worked, = 9, stdev 1.4,  
 
 
Main regression is log daily hours worked on log hourly wage: 
 
log

+
0 ββ
w
t
1

H

=

e
t

, 

=

δβ
+
X
log
t

+

e
i

+

e
it

 

+

−1

W
it
H

it

it

 
where 
 

itH  is hours worked for  i  in day  t .  

itW  is total revenue in the day. 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

3 

it

, 

=*
it

+
uH
it

Any  problems  with  this?    The  dependent  variable  is  included  in  the  right  hand  side!    This  is  not  a 
problem  is hours  in  the day  is measured correctly, because  then we measure hourly wage correctly 
and this is the relationship we want to measure.  But suppose instead we use:  
 
H
 
in  the  regression,  where 
itH   (classical 
itu   is  measurement  error  that  is  uncorrelated  with 
itH   and 
  Now  whenever  daily  hours  are  overestimated,  average  wages 
measurement  error). 
is 
underestimated,  and  vice  versa.    This  downward  biases  the  coefficient  estimate  for  δ.    This  is 
clearly  a  problem.    There  may  be  recording  errors  on  the  trip  sheet,  or  time  spend  talking  with 
friends or lunch may be incorrectly counted in 
itH . 
 
Measurement  error  of  independent  variables  is  a  general  problem  is  well.    If  the  independent 
variable  of  interest has classical measurement error, the OLS coefficient estimate will be downward 
biased. 
 
Consider first the single variable case: 
 
Suppose that the true model of schooling is: 
 
H

0 ββ
+
+
eW
*
i
i
1

, 

=

i

 
but we use another measure of schooling that is inaccurate: 

=
+
uWW
*
i
i

i

 

 
Assuming no omitted variables problem, our least squares estimate for B1 is: 
 

)

 

,

β
1

W
cov(
i

ββ
+
+
eW
*
i
i
1
0
W
var(
)
i
WW
)
,
cov(
*
i
i
W
var(
)
i
+
WuW
cov(
,
*
i
i
i
+
uW
var(
)
*
i
W
var(
)
*
i
+
W
u
var(
var(
)
*
i
β
R
2
WW
1
*,

β
1

β
1

)

)

i

*

i

HW
cov(
,
i
W
)
var(
i

)

i

=

=

=

=

=

 

 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

4 

where 

  is  the correlation coefficient between H* and H.    If  the correlation  is not 1  (they are not 

*,WWR
2
identical), B1 will be biased downward.   
 
The  attenuation  bias  is  towards  zero.    This  is  different  from  the  measurement  error  bias  in 
Camerer’s paper because the the m.e. is uncorrelated with the dependent variable. 
 
For the multivariate case: 
ββ
β
+
=
+
+
 
W
e
H
X
i
i
0
2
1

i

i

 
the attenuation bias will be: 
 

p

lim

ˆ
= ββ
1
1

r
var(
*)
i
+
u
r
var(
*)
i

)

i

 

var(

 
where  *ir
 is residual from the linear projection: 
=
+
+
δδ
W
X
*
i
1
0

r
i

*

 

i

 
The more  collinear 

iW   with  other  explanatory  variables,  the worse  the  bias  (Woodridge’s  grad  text 
*
gives more discussion).  The coefficient for B2 will also be biased, but in an unknown direction.  It is 
difficult  to  determine  the  direction  and  size  of  the  bias  if    X  and  W  have  measurement  error  (see 
Greene). 
 
If we have classical measurement error in the dependent variable (on the left hand side), there is no 
bias in the OLS estimate.  This can easily be verified with a similar approach above. 
 
A  general  solution  to  measurement  error  concerns  is  to  instrument  the  variable  with  another 
variable,  even  if  that  variable  itself  has measurement error.  Lagged  variables  often work, but  in  our 
case it’s not good because we’re trying to measure day to day fluctuations in wages. 
 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

5 

Instead, Camerer  et  al.  instrument with  cabbie’s  daily  average  revenue with  the  25th,  50th,  and  75th 
percentile daily  revenue  for  other  cabbies.   My  own  concern with  this  is  if  ‘leisure  time while  on  the 
job’  is  correlated across  other  cabbies.   Authors  suggest  removing  breaks more  than 30 minutes  in 
TRIP data lead to similar results. 
 
What might be going on?  Authors suggest ‘targeting’: quite when income target reached. 
Phone  survey  of  14  owners  and  managers.    Asked  to  choose  one  of  three  sentences  that  best 
describe how many hours cab drivers drive each day.  6 said drive until they make certain amount of 
money, 5 said fixed hours, 1 said work more when doing well, quite early on a bad day. 
 
In the context of the intertemporal model, targeting can be described by big drop in marginal utility of 
income after the target. 
 
Farber: Is tomorrow another day? 
 
Farber criticizes this approach. 
 
1) Instrument of daily wage is invalid if measurement error in hours day specific across all drivers. 
 
2)  Farber’s  cab  data  shows  no  correlation  in  hourly  wages  within  days,  suggesting  no  ability  to 
determine  ‘good  days  and  bad  days’  from  early  on.   He  does  not  attempt  to  reconcile  this  opposite 
finding with Camerer et al.  The two opposite findings are perplexing. 
 
Variation  in  average  hourly  wages  across  days,  therefore,  is  not  likely  interpreted  as  transitory 
fluctuations.    More  likely  random.    Such  wage  fluctuations  are  not  likely  predictable  and  are  not 
associated  with  the  intertemporal  model.    Faber  finds  similar  negative  wage  coefficients  with  his 
data but attributes them likely to measurement error.   
 
Farber  instead  tries  to  test  the  intertemproal  model,  relative  to  the  target  theory  with  predictions 
about quit decisions within a day. 
 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

6 

The budget constraint is modified in the intertemporal model: 
 
W
t

+
HyWr
)(
(
t
t

+=+
1(
1

C

, 

−

)

)

t

t

  represents  daily  earnings  as  a  function  of hours worked.   Wages  are  allowed  to  vary 

 
where 

)

t Hy
(
t
throughout the day.  This leads to more flexible first order conditions: 
 
−
u =
h
u
c

Hy
('
t

)

 

t

 
 
W ithin a one day setting, income effects are likely to be small, so smoothed consumption is not likely 
to change  from daily  labor supply decisions.    If  this  is approximately  true, we can assign a constant 
to marginal utility of consumption.  Let’s normalize it to one. 
 
−

=

Hu
(
h

t

)

Hy
(
'
t

t

)

 

 
If  we  consider  changes  to  daily  income,  we  get  the  usual  substitution  effect:  when  daily  income  is 
high, , a cabbie should work longer hours, whether the higher wage is anticipated or transitory.   
 
But  this  is not what Farber wants  to  test.   He wants  to consider  labor supply decisions within a day, 
ty  fluctuates  throughout  the day.   After every ride, for example, a cabbie makes a 
with  the  idea  that 
'
decision  of  whether  to  stop  or  not.    The  intertemporal  model  emphasizes  that  the  quit  rate  will  be 
mostly  a  function  of  hours  worked,  while  the  target  model  emphasizes  it  mostly  depends  on 
cumulative income. 
 
Prediction 1: 
 
Intertemporal model 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

7 

Conditional  on  cumulated  income,  marginal  disutility  of  working  is  increasing  every  hour.    Hours 
worked  will  be  positively  related  to  quitting.    It  shouldn’t matter  whether  we  condition  on  income  or 
not, but This is what Farber does to contrast it with the Target model. 
 
Target model 
It  doesn’t  matter  how  many  hours  worked,  only  whether  income  target  achieved.    Conditional  on 
cumulated income, marginal disutility of working is constant over hours.  Working 7 or 10 hours does 
not determine whether a cabbie quits. 
 
 
Prediction 2: 
 
Intertemporal model 
Conditional or wage opportunities  later  in  the day, or  if previous early shift wage  fluctuations cannot 
be  used  to  predict  future  wage  fluctuations,  then  cumulated  income  will  not  be  related  to  quit 
decisions.   
  only  depends  on  current  and  future  opportunities  in  the  day.    It  is  not  clear 
t Hy
('
)
t
whether  Farber  assumes  he  adequately  controls  for  future  opportunities  in  his  regressions  or  he 
relies on his data that shows early shift wage changes are poor predictors of  later shift changes, but 
he needs on of them to make this claim. 
 
Target model 
Cumulated  income determines  the decision  to quit.   So  it will clearly be positively  related  to  the quit 
rate. 
 
Thus,  Faber  focuses  on  testing  whether  cumulated  income  in  the  day  predicts  quit  rates  better  or 
worse than cumulated hours. 
 
Farber’s data: 
 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

8 

After  much  inquiry,  obtains  584  trip  sheets  for  21  drivers  over  various  days  throughout  a  2  year 
period.    Not  much  overlap  in  days  and  drivers,  which  limits  the  creation  of  an  instrument  for  daily 
wages like Camerer et al. do. 
 
Data issues: cannot match self reported trip sheets with printed meter.  When you read the clean up 
procedure, you get an sense that the sheets were very messy (e.g. a ride ending before it started). 
 
Note,  problem  if  participation  itself  is  correlated  with  the  hours  worked,  had  the  cabbie  instead 
decided to work.  Individual fixed effects help mitigate this (cabbies less likely to work and less likely 
to  work many  hours  controlled  for).    In  addition,  cabbies  are  supposed  to  work  on  scheduled  days 
and may have to pay a fee if they do not. 
 
Table 1: 
 
Costs $575 a week to rent cab + fuel.  Tips are not included in the table.  R-squared from regressing 
daily  income on driver  fixed effects  is  .169.   Under  target model, we might expect  this  to be higher.  
Check out driver 15.  Hard life being a cabbie. 
 
Table  3:  no  autocorrelation,  opposite  of  what  camerer  et  al  find.    “predicting  hours  of  work  with  a 
model that assumes a fixed hourly wage rate during the day does not seem appropriate’ 
 
Test target model directly: 
 
T

++
= β
e
X
it
i

it

e
it

, 

 
where T is the average between total shift income and total shift income minus the last fare. 
 
Table 5 shows Rsquared is low, not consistent with target model. 
 
Table 7 main results.  After including fixed effects hours significant, income insignificant. 
 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

9 

For  flexible  form  in  table  8.    Hours  matter  to  quid  decisions,  income  doesn’t  when  conditioning  on 
both.  
 
Discussion: what do you think of the two papers? 
 
Cluster Analysis: both papers cluster by driver.  What does this mean? 
 
A note on the need to ‘cluster’ standard errors 
 
OLS  assumes  no  serial  correlation  or  autocorrelation  in  the  error  terms  when  estimating  the 
variance  (and  standard  errors)  of  the  coefficients.    This  can  lead  to  downward  bias  in  the  standard 
errors  if,  instead,  the  errors,  or  at  least  some  of  them,  are  positively  correlated.    The  bias  can 
sometimes be severe. 
 
pn ×   design matrix 
Consider  the  variance  of  the  ordinary  least  squares  regression.    Let    X   be  the 
=
1×n
+
and  y   be  the 
,  so  any  fixed 
  vector  of  dependent  values.    The  regression  model  is: 
eXβ
y
effects  are  defined  as  dummy  variables  contained  in  the  X   matrix,  and  y   and  X   are  deviations 
−
yXXX
'
1)
'

, and the variance is: 

(

, (the variance-covariance matrix for all i and j observations) 

 

The standard OLS assumption to estimate the variance is 

I2σ=Ω

, and 

ˆσ
2

1
N
∑=
N 1

ie
2

: 

 
b
var(

 

)

=

εσ
(ˆ
2

XX
'

)

−

1

 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

10 

=

'

E
[(

y

yy
E
)(

−
XXX
'
)
1

from their means.  The ordinary linear regression estimates are 
 
b
var(
 
b
var(
 
where 

− Ω
XXXXXX
'
)
(
'
'
1

XXXy
E
(
])'
'

Ω=)

 and 

=

−

1

)

 

−

1

)

 

=iE ε
(
)

0

iE εε
(
j

)

)

−

−

(

(

OLS  assumes  that  the  variance  matrix  for  the  error  term  is  diagonal  while  in  practice  it  might  be 
block  diagonal,  with  a  constant  correlation  coefficient  within  each  group  and  time  cell.    When  we 
want  to  identify an aggregate group/time effect, within  group/time  correlation  can be  substantial.    In 
practice, the correlation is often positive, which leads the OLS results to underestimate the standard 
error, making  it more  likely to reject the null hypothesis.  It  is reasonable to expect that units sharing 
observable  characteristics  such  as  being  from  the  same  industry,  state, marital  status,  time  period 
and location, also share unobservable characteristics that would lead the regression disturbances to 
be  positively  correlated.    W ith  Monte  Carlo  experiments,  several  recent  papers  have  suggested 
using OLS  standard  error  estimates  can  bias  standard  errors  downwards  and  lead  to  rejection  that 
the coefficient is zero, when in fact, it is. 
 
Here,  the  possibility  that 

ite   is  correlated  across  time  is  clear:  unobservable  driver  factors  may  be 
related to the outcomes, and this may occur whether or not those unobservables are correlated with 
the independent variable of interest (the issue arises regardless of omitted variables bias). 
 
Fortunately, White  (and  earlier  Eicher  and  Huber)  found  a  way  to  estimate  robust  standard  errors, 
regardless of  the  form  Ω   takes  (provided  that  Ω   is well defined).   White pointed out  that we do not 
need  to estimate every component  in  the n x n  Ω  matrix, an obviously  impossible  task when only n 
observations  are  available.    But  this  way  of  looking  at  the  problem  is misleading.   What  is  actually 
required is to estimate 
 
 
b
var(
 
(White, 84, Aymptotic Theory for econometricians) 
 
The robust variance-covariance matrix estimator is: 
 

XXXeeX
'
](
'
'

E
[

(

XX
'

)

=

−
1

)

 

)

−
1

b
var(

)

=

(

XX
'

)

−
1





N
∑
1

−

[(

y

i

)ˆ
y
i

x

i

[(]'

y

i

−

)ˆ
y
i

x

i

XX
'

)

−

1

 


(]



 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

11 

where 

iyˆ   is  the  estimated  error  term,  and  the  sum  is  over  all  observations.    This  variance  is 
computed  when  the  ‘robust’  option  is  specified  in  STATA.    When  prior  knowledge  leads  the 
researcher  to  believe  the  error  terms  may  be  serially  correlated  within  groups,  but  independent 
across groups, the variance can be calculated as: 
 

b
var(

)

=

(

XX
'

)

−
1





G
∑
1

k uu
'

k





(

XX
'

)

−
1

=
, where  ∑
u
k
∈
kj

[(

y

j

−

)ˆ
y
j

x

j

[(]'

y

j

−

)ˆ
y
j

x

j

]

 

 
This variance estimate is computed with STATA’s ‘cluster’ command, specifying groups G. 
 
This  estimator  is  consistent  for  any  arbitrary  heteroskedasticity  or  serial  correlation,  but  it  is  not 
efficient when prior information about the form of the matrix is known. 
 
 
To give you a little intuition for the need to cluster, consider the following example.  Suppose we are 
evaluating the relationship between education attainment and state compulsory school laws.  Let 
isS  
be years of schooling  for  individual  i   in state  S , and 
SZ   is  the dropout age  that an  individual  faced 
when  in high  school,  from  state S.   So  the  independent  variable  is  the  same  for everyone  from  that 
state.  The OLS regression equation is: 
 
S
 
It’s  certainly  plausible  that  individuals  from  the  same  state  are  related  in  other  ways.    There  could 
=iS
still  be  no  omitted  variables  bias: 
,  but  the  error  terms  are  serially  correlated  among 
S eZE
0)
(
,
≠
= S
eE
e
S
(
,
|
iS

individuals from the same state: 

= β
Z

e
iS

0

.  

)

jS

is

+

S

, 

 
One extreme example  is we  have  100  individuals, 2  from  each  state.   

individuals  from  the same state.   Suppose also  that 

SZ   is  the  same  for  each  two 
isS   is  the same  for both.   So what we have  is 2 
( 2 =iSeE
.    If  the 
sets  of  the  same  50  values  for  S  and  Z.    Normalize  the  standard  deviation  to  1: 
1)
IΩ = , as in OLS, the variance of  βˆ  is: 

variance-covariance matrix is 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

12 

 

var(

)ˆ
β

=

1
50
∑
1

2

Z

2
i

2

50
∑
1

Z

2
i

1
50
∑
1

2

Z

2
i

=

1
50
∑
1

2

 

Z

2
i

 
If,  instead, 
iSe   is  perfectly  correlated  within  state, 
Recognizing the, the true variance of  βˆ  is 
 
 
 

var(

)ˆ
β

=

1
50
∑
1

2

Z

2
i

4

50
∑
1

Z

2
i

1
50
∑
1

2

Z

2
i

=

 

1
50
∑
Z
1

2
i

eE
(
iS

,

e

jS

|

S

= S

=
1)

  and  zero  otherwise.  

 
  
If  the  second  covariance  matrix  is  correct,  we  falsely  underestimate  the  variance  of  βˆ   using  OLS.  
The  second  individual  in  each  state  adds  no  new  information.    If 
iSe   was  only  partially  correlated 
within  state,  the  variance  would  be  smaller,  but  still  larger  than  OLS.    Using  White’s  clustering 
approach leads to a consistent estimate of the variance of  βˆ , no matter what shape underlies  Ω . 
 
One  should  note  that  this  estimator  applies  asymptotically  (as  the  sample  size  and  the  number  of 
groups  approaches  infinity).    Monte  carlo  experiments  reveal  that  the  estimator  works  reasonably 
well  when  the  sample  size  within  groups  is  not  especially  large  relative  to  the  number  of  groups.  
Unfortunately,  the  number  of  groups  is  very  small,  relying  on  asymptotics  can  be  very  misleading.  
What  is  small?    The  references  below  suggest  even  groups  as  high  as  40  or  50  can  lead  to  poor 
estimates.    A  conservative  solution  is  to  aggregate  the  data  up  to  the  group  level  and  run  the 
regressions using the grouped means, weighted by the sample size.  In our example, this would be: 
 
S

= β
Z

+

s

e
S

, 

S

 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

13 

which will generate the same estimate for B and the variance of B in our simple example.  If there  is 
no  cluster  effect  (no  serial  correlation  within  groups),  then  aggregating  to  the  group  level  removes 
information and  increases  the variance unnecessarily.    In practice, results are far more convincing  if 
you can produce robust and significant results with this aggregated approach (if it’s applicable). 
 
Note,  in  the  diff-in  diff  example  above,  if we  aggregated, we  only  would  have  4  observations.    And 
indeed,  one  criticism  that  has  been  put  out  by  some  researchers  is  that  the  diff  in  diff  approach  is 
just  in  essence  comparing  2  groups  over  time  and  we  can’t  be  sure  that  any  observed  significant 
difference in means is due entirely to the policy change. 
 
 

Philip Oreopoulos Labor Economics Notes for 14.661 Fall 2004-05 Lecture 6 

14 

