18.06 Problem  Set  5  Solution 
Total:  points 

Section  4.1.  Problem  7.  Every system with no solution is like the one in problem 
6.  There  are  numbers  y1 , . . . , ym  that  multiply  the  m  equations  so  they  add  up  to 
0 = 1.  This  is  called  Fredholm’s  Alternative: 

Exactly  one  of  these  problems  has  a  solution:  Ax = b  OR  AT y = 0  with 
yT b = 1. 

If  b  is  not  in  the  column  space  of  A  it  is  not  orthogonal  to  the  nullspace  of  AT . 
Multiply  the  equations  x1  − x2  =  1  and  x2  − x3  =  1  and  x1  − x3  =  1  by  numbers 
y1 , y2 , y3  chosen  so  that  the  equations  add  up  to  0 = 1. 
Solution  (4 points) Let  y1  = 1,  y2  = 1  and  y3  = −1.  Then  the  left-hand  side of  the 
sum  of  the  equations  is 
(x1  − x2 ) + (x2  − x3 ) − (x1  − x3 ) = x1  − x2  + x2  − x3  + x3  − x1  = 0 

and  the  right-hand  side  is 

1 + 1 − 1 = 1. 

Problem  9.  If  AT Ax =  0  then  Ax =  0.  Reason:  Ax  is  inthe  nullspace  of  AT  and 
.  Conclusion:  AT A 
also  in  the 
of  A  and  those  spaces  are 
has  the  same  nullspace  as  A.  This  key  fact  is  repeated  in  the  next  section. 

Solution  (4 points) Ax  is  in  the nullspace  of AT  and  also  in  the  column  space  of A 
and  those  spaces  are  orthogonal. 

Problem  31.  The  command  N=null(A)  will  produce  a  basis  for  the  nullspace  of 
of  A. 
A.  Then  the  command  B=null(N’)  will  produce  a  basis  for  the 

Solution  (12 points) The matrix N  will have as its columns a basis for the nullspace 
of  A.  Thus  if  a  vector  is  in  the  nullspace  of  N T  it  must  have  dot  product  0  with 
every  vector  in  the  basis  of  N (A),  thus  it must  be  in  the  row  space  of  A.  Thus  the 
command  null(N’)  will  produce  a  basis  for  the  row  space  of  A. 

1 

>>  A  =  rand(6,12) 

A  = 

Columns  1  through  6 

0.8147 
0.9058 
0.1270 
0.9134 
0.6324 
0.0975 

0.2785 
0.5469 
0.9575 
0.9649 
0.1576 
0.9706 

Columns  6  through  12 

0.7655 
0.6948 
0.7952 
0.3171 
0.1869 
0.9502 
0.4898 
0.0344 
0.4456 
0.4387 
0.3816 
0.6463 
>>  N  =  null(A); 
>>  B  =  null(N’) 

B  = 

0.9572 
0.4854 
0.8003 
0.1419 
0.4218 
0.9157 

0.7094 
0.7547 
0.2760 
0.6797 
0.6551 
0.1626 

0.7922 
0.9595 
0.6557 
0.0357 
0.8491 
0.9340 

0.1190 
0.4984 
0.9597 
0.3404 
0.5853 
0.2238 

0.6787 
0.7577 
0.7431 
0.3922 
0.6555 
0.1712 

0.7513 
0.2551 
0.5060 
0.6991 
0.8909 
0.9593 

0.7060 
0.0318 
0.2769 
0.0462 
0.0971 
0.8235 

0.5472 
0.1386 
0.1493 
0.2575 
0.8407 
0.2543 

0.3288 
0.1754 
0.6512 
-0.1000 
0.2124 
0.4380 
0.0094 
-0.0661 
-0.0527 
0.4425 
0.3024 
0.2213 
-0.1323 
0.6724 
0.4083 
-0.0371 
0.1595 
0.1827 
-0.1870 
0.1438 
0.1540 
-0.0887 
0.0533 
-0.2452 
>>  rref(A)  - rref(B’) 

0.6264 
-0.1687 
-0.3137 
-0.2313 
0.2166 
-0.3429 
-0.1677 
0.1074 
0.4375 
0.0025 
-0.0283 
0.1759 

-0.0309 
0.1346 
0.0050 
0.5792 
0.1071 
-0.1149 
-0.0249 
0.0993 
0.0910 
0.4134 
0.5060 
0.4184 

0.0112 
-0.1632 
0.0507 
-0.4208 
-0.2063 
0.3415 
0.0211 
-0.1251 
0.0005 
-0.3188 
0.5600 
0.4506 

-0.0997 
0.5528 
-0.1684 
-0.5029 
0.0525 
-0.2123 
0.1315 
-0.3610 
-0.0581 
0.4256 
0.1444 
-0.0477 

2 

ans  = 

1.0e-13  * 

Columns  1  through  6 

0 
0 
0 
0 
0 
0 

0 
0 
0 
0 
0 
0 

0 
0 
0 
0 
0 
0 

0 
0 
0 
0 
0 
0 

0 
0 
0 
0 
0 
0 

0 
0 
0 
0 
0 
0 

Columns  6  through  12 

-0.0389 
0.0047 
-0.1710 
0.0153 
0.1155 
0.1488 

0.0533 
-0.0022 
0.1843 
-0.0089 
-0.1377 
-0.1643 

-0.0344 
0.0044 
-0.0999 
0.0092 
0.0688 
0.0888 

-0.0888 
0.0089 
-0.3020 
0.0205 
0.2132 
0.2709 

-0.2420 
0.0289 
-0.7816 
0.0444 
0.5596 
0.6928 

-0.2043 
0.0200 
-0.6395 
0.0333 
0.4796 
0.5684 

Note that  if B  has as  its columns a basis  for  the row space of A then the rows of B T 
will  form  a  basis  for  the  row  space  of  A.  Since  the  row  reduced  forms  of  A  and  B T 
agree  (up  to  13  decimal  places,  but  the  numbers  up  there  are  just  rounding  error) 
their  rows must  span  the  same  space,  so  the  columns of B  are  indeed a basis  for  the 
row  space  of  A. 

Problem  32.  Suppose  I  give  you  four  nonzero  vectors  r, n, c, l  in R2 . 

a.	 What  are  the  conditions  for  those  to  be  bases  for  the  four  fundamental  sub­
spaces  C (AT ), N (A), C (A), N (AT )  of  a  2 × 2 matrix? 

b.  What  is  one  possible matrix  A? 

Solution  (12  points) 

· 
a.	 In  order  for  r  and  n  to  be  bases  for  N (A)  and  C (AT )  we  must  have  r n  = 
0,  as  the  row  space  and  null  space  must  be  orthogonal.  Similarly,  in  order 

3 

· 
for  c  and  l  to  form  bases  for  C (A)  and  N (AT )  we  need  c l  =  0,  as  the
column  space  and  the  left  nullspace  are  orthogonal.  In  addition,  we  need 
dim N (A) + dim C (AT ) = n and dim N (AT ) + dim C (A) = m; however,  in this 
case n = m = 1, and as the four vectors we are given are nonzero both of these 
equations  reduce  to  1 + 1 = 2,  which  is  automatically  satisﬁed. 

b.  One  possible  such  matrix  is  A  =  crT .  Note  that  each  column  of  A  will  be 
a  multiple  of  c,  so  it  will  have  the  right  column  space.  On  the  other  hand, 
each  row  of  A  will  be  a  multiple  of  r,  so  A  will  have  the  right  row  space. 
The  nullspaces  don’t  need  to  be  checked,  as  any  matrix  with  the  correct  row 
and  column  space will have  the  right nullspaces  (as  the nullspaces are  just  the 
orthogonal  complements  of  the  row  and  column  spaces). 

Problem  33.  Suppose  I  give  you  four  nonzero  vectors  r1 , r2 , n1 , n2 , c1 , c2 , l1 , l2  in 
R2 . 

a.	 What  are  the  conditions  for  those  to  be  bases  for  the  four  fundamental  sub­
spaces  C (AT ), N (A), C (A), N (AT )  of  a  2 × 2 matrix? 

b.  What  is  one  possible matrix  A? 

Solution  (12  points) 

a.	 Firstly, by the same kind of dimension considerations as before we need the four 
sets {r1 , r2}, {n1 , n2}, {c1 , c2} and {l1 , l2} to each contain linearly independent 
vectors.  (For  example,  if  r1  and  r2  are  linearly  dependent  the  dim C (AT ) = 1 
not  2,  and  then  dim C (AT ) + dim N (A) < 4  which  can’t  happen.) 
·	
· 
Secondly,  for  i  = 1, 2  and  j  = 1, 2  we  need  ri  nj  =  0  and  ci 
lj  =  0.  This 
will  imply  that  the  speciﬁed  row  space and nullspace are orthogonal,  and  that 
the  speciﬁed  column  space  and  left  nullpace  are  also  orthogonal.  (When  we 
are  given  subspaces  in  terms  of  bases  it  suﬃces  to  check  orthogonality  on  the 
basis.) 
b.  One  possible  such matrix  is  � 
� � 
�T 
A = c1  c2 
Note  that  every  column  of  A  is  a  linear  combination  of  c1  and  c2 ,  so  C (A)  is 
at  least  a  subspace  of  the  desired  column  space.  On  the  other  hand,  as  r1  and 

r1  r2 

. 

4 

�T 
�

has  full  row  rank,  so  A 
r2  are  linearly  independent  we  know  that 
r1  r2 
�

�T 
� � 
will  have  rank  2  and  thus  A  has  the  right  column  space. 
On  the  other  hand,

AT  = r1  r2 
c1  c2 
so C (AT )  is  spanned  by  r1  and  r2 ,  as  desired.  Thus A  has  the  right  row  space 
and  column  space,  and  thus  will  have  the  right  nullspace  and  left  nullspace. 

Section  4.2.  Problem  13.  Suppose  A  is  the  4 × 4  identity  matrix  with  its  last 
column  removed.  A  is  4 × 3.  Pro ject  b  =  (1, 2, 3, 4)  onto  the  column  space  of  A. 
What  shape  is  the  pro jection matrix  P  and  what  is  P ? 
Solution  (4 points) P  will be 4 × 4 since we take a 4-dimensional vector and pro ject 
it  to  another  4-dimensional  vector.  We  will  have  ⎞
⎛ 
0 1 0 0
 ⎟⎟⎠
 .

P  =
 ⎜⎜⎝

1 0 0 0

0 0 1 0

0 0 0 0

(This  can  be  seen  by  direct  computation,  or  by  simply  observing  that  the  column 
space of A  is  the wxy -space,  so we  just need  to  remove  the z  coordinate  to pro ject.) 
The  pro jection  of  b  is  (1, 2, 3, 0). 

Problem  16.  What  linear  combination  of  (1, 2, −1)  and  (1, 0, 1)  is  closest  to  b  = 
(2, 1, 1)? 

Solution  (4  points)

Note  that


3 
(1, 2, −1) +  (1, 0, 1) = (2, 1, 1). 
1
2
2
So  this  b  is  actually  in  the  span  of  the  two  given  vectors. 

Problem  17.  If  P 2  =  P  show  that  (I − P )2  =  I − P .  When  P  pro jects  onto  the 
column  space  of  A,  I − P  pro jects  onto  the 
. 

Solution  (4  points) 
(I − P )2  = I 2  − I P  − P I + P 2  = I − 2P  + P 2  = I − 2P  + P  = I − P. 

5 

When P  pro jects onto  the  column  space of A,  I − P  pro jects onto  the  left nullspace 
of  A. 

Problem  30. 

� 
� 
a.  Find  the  pro jection matrix  PC  ontot  he  column  space  of  A. 
. 

3 6 6 
4 8 8 
b.  Find  the  3 × 3  pro jection  matrix  PR  onto  the  row  space  of  A.  Multiply  B  = 
PC APR .  Your  answer  B  should  be  a  little  suprising —  can  you  explain  it? 

PC  = a(a T a)−1 a T  =

Solution  (12  points) 
�
�T 
a.  Note  that  as  A  is  rank  1  its  column  space  is  spanned  by  the  vector  a  = 
� 
� 
3  4 
.  Using  this matrix  we  can  compute 
1 
12 
9
. 
12 16 �
25 
⎞

⎛
1 2 2 
b.  The  row  space  of  A  is  spanned  by  the  vector  a  = 
PR  = a(a T a)−1 a T  =  ⎝  2 4 4  ⎠ . 
compute	
1 2 2

1 
9 
2 4 4 
Then  B  =  PC APR  =  A.  First,  note  that  PC A  =  A,  as  for  every  vector  x, 
Ax ∈ C (A),  so  PC Ax = Ax.  Analogously,  APR  = A,  as  for  every  vector  x  we 
can write it uniquely as x = n + r with n in N (A) and r in C (AT ).  Then Ax = 
An + Ar = Ar by the deﬁnition of nullspace.  But PRx = PRn + PRr = PRr, as 
the  nullspace  is  orthogonal  to  the  row  space,  so  pro jecting  onto  the  row  space 
kills  the  nullspace.  So  APR  =  A.  Thus  PC APR  = (PC A)PR  =  APR  =  A,  as 
desired. 

�T 
. Then we 

Problem  31.  In  Rm ,  suppose  I  give  you  b  and  p,  and  n  linearly  independent 
vectors  a1 , . . . , an .  How  would  you  test  to  see  if  p  is  the  pro jection  of  b  onto  the 
subspace  spanned  by  the  a’s? 

6 

Solution  (12  points) 
The pro jection  of b must  lie  in  the  span  of  the a’s,  and must  also be  the  closest 
vector  in this span, meaning that the error will be orthogonal to this span.  Thus we 
need  to  check  (a)  that  p  is  in  the  span  of  the  a’s,  and  (b)  that  b − p  is  orthogonal 
to  ai  for  each  i = 1, . . . , n.  Note  that  just  checking  (b)  is  not  enough  because  if  we 
set  p = b  then  (b) will  be  satisﬁed  but  (a) will  not  be  if  b  is  not  in  the  span  of  the 
a’s. 

Problem  34.  If  A  has  r  independent  columns  and  B  has  r  independent  rows,  AB

is  invertible.

Proof:  When A is m by r with independent columns, we know that AT A is invertible.

If B  is  r  by n with  independent  rows,  show  that BB T  is  invertible.  (Take A = B T .)

Now  show  that  AB  has  rank  r . 

Solution  (12  points)  Let A = B T .  As B  has  independent  rows, A  has  independent 
columns,  so AT A  is  invertible.  But AT A = (B T )T B T  = BB T ,  so BB T  is  invertible, 
as  desired. 
Note  that AT A  is  r × r  and  is  invertible,  and BB T  is  r × r  and  is  invertible,  so 
AT ABB T  is  r × r  and  invertible,  so  in  particular  has  rank  r .  Thus  we  have  that 
AT (AB )B T  has  rank  r .  We  know  that multiplying AB  by  any matrix  on  the  left  or 
on  the  right  cannot  increase  rank,  but  can  only  decrease  it.  Thus  we  see  that  AB 
has rank at least r .  However, AB  is r × r , so it has rank r and is therefore invertible. 

Section  8.2.  Problem  13.  With  conductances  c1  =  c2  = 2  and  c3  =  c4  =  c5  = 3, 
multiply  the matrices AT CA.  Find a solution  to AT CAx = f  = (1, 0, 0, −1).  Where 
these  potentials  x  and  currents  y  =  −CAx  on  the  nodes  and  edges  of  the  square 
graph. 
⎛  −1
⎞
Solution  (4  points)  For  this  graph  the  incidence matrix  is 
⎜⎜⎜⎜⎝

⎟⎟⎟⎟⎠

1 
0

0
−1
0

0 
1
−1
0

0

1
−1 
0

1

0
0  −1 1 
0
⎛ ⎜⎜⎝

⎞
We  are  told  that  the  conductance matrix  has  diagonal  entries  (2, 2, 3, 3, 3).  Then 
⎟⎟⎠

4  −2  −2
0

8  −3  −3

−2
8  −3 
−2

−3

−3

−3
0

6 

AT CA = 

.


A =


.


7


A solution to the given equation is x = (5/12, 1/6, 1/6, 0); then y = (1/2, 1/2, 0, 1/2, 1/2). 
The  picture  associated  to  this  solution  is 

Problem  17.  Suppose  A  is  a  12  ×  9  incidence  matrix  from  a  connected  (but 
unknown)  graph. 

a.	 How many  columns  of  A  are  independent? 

b.  What  condition  on  f  makes  it  possible  to  solve  AT y = f ? 

c.	 The  diagonal  entries  of  AT A  give  the  number  of  edges  into  each  node.  What 
is  the  sum  of  those  diagonal  entries? 

Solution  (12  points) 
a.	 Note  that  as  A  is  12 × 9  it  is  a  graph  with  9  nodes  and  12  edges.  As  it  is 
connected  elimination  will  produce  a  tree  with  8  edges,  so  the  rank  of  A  is  8, 
and  so  it  has  8  independent  columns. 

b.  In  order  to  solve  AT y  we  need  the  entries  of  f  to add up to 0,  as  f  needs  to 
be  in  C (AT ),  which  is  orthogonal  to N (A)  and  is  generated  by  (1, 1, . . . , 1). 

c.	 The  sum  of  the  entries  of  AT A  is  the  sum  of  the  degrees  of  all  of  the  nodes. 
As  each  edge  hits  exactly  two  nodes  it  will  be  counted  twice,  so  the  sum  of 
the  diagonal  entries  is  24. 

8


1/201/21/21/25/121/61/60MIT OpenCourseWare
http://ocw.mit.edu 

18.06 Linear Algebra 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

