<!DOCTYPE html><html lang="en">
<head>
<meta charset="utf-8">
<meta name="format-detection" content="telephone=no">
<title>Lecture 24: Markov matrices; fourier series | Video Lectures | Linear Algebra | Mathematics | MIT OpenCourseWare</title>
<!-- Begin Automatic Metadata Insertion --><meta content="18-06-linear-algebra-spring-2010" name="WT.cg_n">
<meta content="Lecture 24: Markov matrices; fourier series" name="WT.cg_s">
<meta content="" name="Description">
<meta content="Strang, Gilbert" name="Author">
<meta content="matrix theory,linear algebra,systems of equations,vector spaces,determinants,eigenvalues,similarity,positive definite matrices,least-squares approximations,stability of differential equations,networks,Fourier transforms,Markov processes,Linear Algebra" name="keywords">
<meta content="Lecture 24: Markov matrices; fourier series | MIT OpenCourseWare" name="Search_Display">
<meta content="Linear Algebra" itemprop="about">
<!-- End Automatic Metadata Insertion --><link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/grid.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/base.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/menu.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.bubblepopup.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses_new.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.jscrollpane.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/media_tabs.css">
<link href="http://ocw.mit.edu/xml/ocwcc.rdf" type="application/rdf+xml" rel="metadata">
<link rel="canonical" href="http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-24-markov-matrices-fourier-series">
<link rel="apple-touch-icon" href="../../../common/images/apple-touch-icon.png">
<script type="text/javascript" src="../../../common/scripts/common-utils-offline.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-offline.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.bubblepopup.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery-ui.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.jscrollpane.min.js"></script><script type="text/javascript" src="../../../common/scripts/bubble-popup-offline.js"></script><script type="text/javascript">
      $(document).ready(function() {
        $("#tabs").tabs();
        IpadScroller();
      });
    </script>
</head>
<body itemscope itemtype="http://schema.org/WebPage">
        
	

        <div id="top">
			<div id="grid">
				
				
					
<div id="portletwrapper-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572" class="portletWrapper kssattr-portlethash-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572">
<div class="portletStaticText portlet-static-site-header">
<div id="banner" role="banner" class="grid_6 alpha"><a href="http://ocw.mit.edu/"><img src="../../../common/images/ocw_mast.png" alt="MIT OpenCourseWare, Massachusetts Institute of Technology" class="logo"></a></div>
<form action="http://ocw.mit.edu/subscribe/index.htm?utm_source=header" method="get">
    <div id="subscribe" role="form toolbar" class="grid_6 omega">
    <div class="module">
    <table class="social"><tbody><tr>
<td class="text">Subscribe to the<br>
                OCW Newsletter</td>
                <td class="black"><input type="text" onclick="clearEmailBox()" onblur="fillEmailBox()" value="Enter Email" class="greytext emailField" id="email" name="fromemail"></td>
                <td class="black"><input type="image" src="../../../common/images/button_subscribe.png" alt="Subscribe" class="sub_button"></td>
                <td>
<a href="http://facebook.com/mitocw"><img src="../../../common/images/icon_fb.png" alt="Click to visit our Facebook page."></a><a href="http://twitter.com/mitocw"><img src="../../../common/images/icon_tw.png" alt="Click to visit our Twitter feed."></a>
</td>
            </tr></tbody></table>
</div>
    <p class="helplinks"><a href="http://ocw.mit.edu/help">Help</a>   |   <a href="../../../common/jsp/feedback.htm">Contact Us</a></p>
    </div>
    <div class="clear"> </div>
</form>
</div>

</div>





<div id="mega" role="navigation" class="grid_8 alpha">        
	<ul id="menu">
<li id="menu_home">
            <a href="http://ocw.mit.edu/"><img src="../../../common/images/top-nav_home.png" class="home_icon" alt="Click for site home page."></a><!-- Begin Home Item -->
        </li>
<!-- End Home Item -->        
        <li class="selected">
            <a href="#" class="drop">Courses</a><!-- Begin 5 columns Item -->
            <div class="dropdown_5columns-a mega-courses">                    
                <div class="col_1a">
                    <div class="row_1a">
                        <div class="quart">
                            <h2 class="nav">Find courses by:</h2>
                            <ul class="nav-bullet find_by">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Topic</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-number/">MIT Course Number</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-department/">Department</a></li>
                            </ul>
</div>
                        <div class="quart">
                            <h2 class="nav">Collections</h2>
                            <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Lectures</a></li>
                                <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>
                                <li><a href="http://ocw.mit.edu/resources">Supplemental Resources</a></li>
                            </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="row_1b">
                        <h2 class="nav">Cross-Disciplinary Topic Lists</h2>
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/energy-courses">Energy</a></li>
                            <li><a href="http://ocw.mit.edu/courses/entrepreneurship">Entrepreneurship</a></li>
                            <li><a href="http://ocw.mit.edu/courses/environment-courses">Environment</a></li>
                        </ul>
</div>    
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/intro-programming">Introductory Programming</a></li>
                            <li><a href="http://ocw.mit.edu/courses/life-sciences">Life Sciences</a></li>
                            <li><a href="http://ocw.mit.edu/courses/transportation-courses">Transportation</a></li>
                        </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="clear"> </div>
                </div>
                <div class="col_1b">
                    <h2 class="nav">Translated Courses</h2>
                    <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/translated-courses/traditional-chinese">繁體字 / Traditional Chinese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/simplified-chinese">简体字 / Simplified Chinese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/spanish">Español / Spanish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/portuguese">Português / Portuguese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/thai">ภาษาเขียน / Thai</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/persian">فارسی / Persian</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/turkish">Türkçe / Turkish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/korean">(비디오)한국 / Korean</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses">More...</a></li>
                    </ul>
</div>
            </div>
        </li>
        <li>
            <a href="" class="drop">About</a>
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/">About MIT OpenCourseWare</a></li>
                    </ul>
<ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>
                        <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>
                        <li><a href="http://ocw.mit.edu/about/ocw-consortium/">OpenCourseWare Consortium</a></li>
                    </ul>
<ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>
                        <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>
                        <li><a href="http://ocw.mit.edu/about/media-coverage/press-releases/">Press Releases</a></li>
                    </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/about/next-decade/">OCW's Next Decade</a></li>
                    </ul>
</div>
            </div>  
        </li>    
        <li>
            <a href="" class="drop">Donate</a>        
            <div class="dropdown_1column-a">
                    <div class="col_1">
                        <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/donate/">Make a Donation</a></li>
                            <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>
                            <li><a href="http://ocw.mit.edu/donate/ocw-course-champions-program/">Become a Course Champion</a></li>
                            <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>
                            <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>
                            <li><a href="http://ocw.mit.edu/donate/shop-ocw">Shop OCW</a></li>
                        </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li>
                        </ul>
</div>
            </div>            
        </li>        
        <li>
            <a href="" class="drop">Featured Sites</a>        
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>
                    </ul>
<ul class="nav-bullet mega-div-top">
<li><a href="https://www.edx.org/school/mitx/allcourses">MITx</a></li>
                        <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>
                    </ul>
</div>
            </div>            
        </li>
    </ul>
</div>
<div id="search" role="search" class="grid_4 omega">
    
    <form method="get" action="../../../common/search/AdvancedSearch.htm">
     	 <table class="search"><tbody><tr>
<td class="black"><input type="text" onblur="fillSearchBox()" onfocus="clearSearchBox()" maxlength="255" value="Search" name="q" class="greytext searchField" id="terms"></td> 			 
                    <td class="black"><input type="image" src="../../../common/images/button_search.png" name="btnG" class="sub_button"></td>			 
                    <td class="text2"><a href="../../../common/search/AdvancedSearch.htm">Advanced<br>Search</a></td>
                </tr></tbody></table>
</form>
</div>
<div class="clear"></div>
<!-- *end header* -->  

				
				
			</div>
<!-- top grid end -->
		</div>
<!-- top end -->
			
		<div id="center_media">
      	<div id="grid">
      		<div id="left">
        		<div id="breadcrumb_media">
                	<p>

    <a href="http://ocw.mit.edu/">Home</a>
    
        »
        
    
    
        
            <a href="http://ocw.mit.edu/courses">Courses</a>
            
                »
                
            
            
         
    
    
        
            <a href="http://ocw.mit.edu/courses/mathematics">Mathematics</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/index.htm">Linear Algebra</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/video-lectures/index.htm">Video Lectures</a>
            
                »
                
            
            
         
    
    
        
            
            
            Lecture 24: Markov matrices; fourier series
         
    
</p>

            	</div>
            	<div class="clear"></div>
        		<div id="media_title">
        		<h1 class="title" itemprop="name" property="dct:title">
        <span class="" id="parent-fieldname-title">
            Lecture 24: Markov matrices; fourier series
        </span>
    </h1>
        		</div>
           		<div class="clear"></div>
           		<div id="course_wrapper_media">
           			<div id="course_nav">
           				<script language="javascript" type="text/javascript">
function toggleMenu(objID) {
  if (!document.getElementById) return;
  var ob = document.getElementById(objID);
  ob.className = (ob.className == 'selected')?'': 'selected';
}
function toggleClass(id)
{
  var divtoggleClass= document.getElementById(id);
  divtoggleClass.className = (divtoggleClass.className == 'mO')?'mC': 'mO';
  return false;
}
function changeAlt(id)
{
  id.alt = (id.alt == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
  id.title = (id.title == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
}
</script><!--Left Nav Starts --><ul>
<li class="">
			   			<a href="../../../contents/index.htm">
		                  Course Home  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/syllabus/index.htm">
		                  Syllabus  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/calendar/index.htm">
		                  Calendar  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/readings/index.htm">
		                  Readings  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/assignments/index.htm">
		                  Assignments  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/exams/index.htm">
		                  Exams  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/study-materials/index.htm">
		                  Study Materials  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/tools/index.htm">
		                  Tools  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/related-resources/index.htm">
		                  Related Resources  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="selected">
			   			<a href="../../../contents/video-lectures/index.htm">
		                  Video Lectures  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    
		    
         	
	<!--second tal block close-->  
	
</ul>
<!--Left Nav Ends --><script type="text/javascript" id="openstudy-widget-loader" src="http://widget.openstudy.com/javascripts/load.js?type=feed&amp;color=auto&amp;studygroup=mit%2018.06%20linear%20algebra,%20spring%202010"></script>
</div>
           			<div id="course_inner_media">
      					 
        <div class="" id="parent-fieldname-text">
            
            
        </div>
    
      					 

     <div id="media-embed">
         <div class="attention_message" id="embed_1">
<p>Flash and JavaScript are required for this feature.</p>
<p>Download the video from <a href="http://deimos3.apple.com/WebObjects/Core.woa/Browse/mit.edu.1299892995.01299892999.1336712632?i=1607598969">iTunes U</a> or the <a href="http://www.archive.org/download/MIT18.06S05_MP4/24_512kb.mp4">Internet Archive</a>.</p>
</div>
     </div>
    
     <script type="text/javascript">ocw_embed_chapter_media('embed_1', 'http://www.youtube.com/v/8MF3pz-oYHo', 'youtube', '/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-24-markov-matrices-fourier-series', 'http://img.youtube.com/vi/8MF3pz-oYHo/0.jpg',0,0, 'http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-24-markov-matrices-fourier-series/18.06_L24.srt')</script><div id="media_resource_next_prev_nav" style="margin-top: 1em;">
        <p>
        
            <a href="../../../contents/video-lectures/lecture-23-differential-equations-and-exp-at/index.htm">
                <img src="../../../common/images/btn_previous_resource.png" style="margin: 0 30px 0 50px;" alt="Previous track" title="Previous track"></a>
     	
     	
        
            <a href="../../../contents/video-lectures/lecture-24b-quiz-2-review/index.htm"> 
                <img src="../../../common/images/btn_next_resource.png" alt="Next track" title="Next track"></a>
       
       </p>
     </div>
 


<script type="text/javascript">
		window.onload=function(){
		init();
		
		}
		var tabLinks = new Array();
		var contentDivs = new Array();
		function init() {
		  // Grab the tab links and content divs from the page
		  var tabListItems = document.getElementById('tabs').childNodes;
		  for ( var i = 0; i < tabListItems.length; i++ ) {
			if ( tabListItems[i].nodeName == "LI" ) {
			  var tabLink = getFirstChildWithTagName( tabListItems[i], 'A' );
			  var id = getHash( tabLink.getAttribute('href') );
			  tabLinks[id] = tabLink;
			  contentDivs[id] = document.getElementById( id );
			}
		  }
		  // Assign onclick events to the tab links, and
		  // highlight the first tab
		  var i = 0;
		  for ( var id in tabLinks ) {
			tabLinks[id].onclick = showTab;
			tabLinks[id].onfocus = function() { this.blur() };
			if ( i == 0 ) tabLinks[id].className = 'selected';
			i++;
		  }
		  // Hide all content divs except the first
		  var i = 0;
		  for ( var id in contentDivs ) {
			if ( i != 0 ) contentDivs[id].className = 'tabContent hide';
			i++;
		  }
		}
		function showTab() {
		  var selectedId = getHash( this.getAttribute('href') );
		  // Highlight the selected tab, and dim all others.
		  // Also show the selected content div, and hide all others.
		  for ( var id in contentDivs ) {
			if ( id == selectedId ) {
			  tabLinks[id].className = 'selected';
			  contentDivs[id].className = 'tabContent';
			} else {
			  tabLinks[id].className = '';
			  contentDivs[id].className = 'tabContent hide';
			}
		  }
		  // Stop the browser following the link
		  return false;
		}
		function getFirstChildWithTagName( element, tagName ) {
		  for ( var i = 0; i < element.childNodes.length; i++ ) {
			if ( element.childNodes[i].nodeName == tagName ) return element.childNodes[i];
		  }
		}
		function getHash( url ) {
		  var hashPos = url.lastIndexOf ( '#' );
		  return url.substring( hashPos + 1 );
		}
 </script><div id="media_tabs">
     
        <ul id="tabs">
<li class="first">
                <a href="#vid_about" class="selected">About this Video</a>
            </li>
            <li class="">
                <a href="#vid_index" class="">Playlist</a>
            </li>
            <li class="">
                <a href="#vid_playlist" class="">Related Resources</a>
            </li>
            <li class="">
                <a href="#vid_related" class="">Transcript</a>
            </li>
            <li class="">
                <a href="#vid_transcript" class="">Download this Video</a>
            </li>
        </ul>
<div id="vid_about" itemprop="description" class="tabContent"><div class="vidpad">
<p>These video lectures of Professor Gilbert Strang teaching 18.06 were  recorded in Fall 1999 and do not correspond precisely to the current  edition of the textbook. However, this book is still the best reference  for more information on the topics covered in each lecture.</p>
<p style="margin-bottom: 20px;"><a href="http://www.amazon.com/exec/obidos/ASIN/0980232716/ref=nosim/mitopencourse-20" target="_blank"><img border="0" align="absMiddle" src="http://ocw.mit.edu/images/a_logo_17.gif" alt="Amazon logo"></a> Strang, Gilbert. <a href="http://math.mit.edu/linearalgebra/" target="_blank"><em>Introduction to Linear Algebra</em></a>. 4th ed. Wellesley, MA: <a href="http://www.wellesleycambridge.com/" target="_blank">Wellesley-Cambridge Press</a>, February 2009. ISBN: 9780980232714.</p>
<p><strong>Instructor/speaker:</strong> Prof. Gilbert Strang</p>
</div></div>
        <div id="vid_index" itemprop="description" class="tabContent hide">
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-1-the-geometry-of-linear-equations/index.htm">
<img src="../../../contents/video-lectures/lecture-1-the-geometry-of-linear-equations/18.06_L01.jpg" title="Lecture 1: The geometry of linear equations" alt="Lecture 1: The geometry of linear equations"><p>Lecture 1: The geometry of ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-2-elimination-with-matrices/index.htm">
<img src="../../../contents/video-lectures/lecture-2-elimination-with-matrices/18.06_L02.jpg" title="Lecture 2: Elimination with matrices" alt="Lecture 2: Elimination with matrices"><p>Lecture 2: Elimination with...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-3-multiplication-and-inverse-matrices/index.htm">
<img src="../../../contents/video-lectures/lecture-3-multiplication-and-inverse-matrices/18.06_L03.jpg" title="Lecture 3: Multiplication and inverse matrices" alt="Lecture 3: Multiplication and inverse matrices"><p>Lecture 3: Multiplication a...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-4-factorization-into-a-lu/index.htm">
<img src="../../../contents/video-lectures/lecture-4-factorization-into-a-lu/18.06_L04.jpg" title="Lecture 4: Factorization into A = LU" alt="Lecture 4: Factorization into A = LU"><p>Lecture 4: Factorization in...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-5-transposes-permutations-spaces-r-n/index.htm">
<img src="../../../contents/video-lectures/lecture-5-transposes-permutations-spaces-r-n/18.06_L05.jpg" title="Lecture 5: Transposes, permutations, spaces R^n" alt="Lecture 5: Transposes, permutations, spaces R^n"><p>Lecture 5: Transposes, perm...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-6-column-space-and-nullspace/index.htm">
<img src="../../../contents/video-lectures/lecture-6-column-space-and-nullspace/18.06_L06.jpg" title="Lecture 6: Column space and nullspace" alt="Lecture 6: Column space and nullspace"><p>Lecture 6: Column space and...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-7-solving-ax-0-pivot-variables-special-solutions/index.htm">
<img src="../../../contents/video-lectures/lecture-7-solving-ax-0-pivot-variables-special-solutions/18.06_L07.jpg" title="Lecture 7: Solving Ax = 0: pivot variables, special solutions" alt="Lecture 7: Solving Ax = 0: pivot variables, special solutions"><p>Lecture 7: Solving Ax = 0: ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-8-solving-ax-b-row-reduced-form-r/index.htm">
<img src="../../../contents/video-lectures/lecture-8-solving-ax-b-row-reduced-form-r/18.06_L08.jpg" title="Lecture 8: Solving Ax = b: row reduced form R" alt="Lecture 8: Solving Ax = b: row reduced form R"><p>Lecture 8: Solving Ax = b: ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-9-independence-basis-and-dimension/index.htm">
<img src="../../../contents/video-lectures/lecture-9-independence-basis-and-dimension/18.06_L09.jpg" title="Lecture 9: Independence, basis, and dimension" alt="Lecture 9: Independence, basis, and dimension"><p>Lecture 9: Independence, ba...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-10-the-four-fundamental-subspaces/index.htm">
<img src="../../../contents/video-lectures/lecture-10-the-four-fundamental-subspaces/18.06_L10.jpg" title="Lecture 10: The four fundamental subspaces" alt="Lecture 10: The four fundamental subspaces"><p>Lecture 10: The four fundam...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-11-matrix-spaces-rank-1-small-world-graphs/index.htm">
<img src="../../../contents/video-lectures/lecture-11-matrix-spaces-rank-1-small-world-graphs/18.06_L11.jpg" title="Lecture 11: Matrix spaces; rank 1; small world graphs" alt="Lecture 11: Matrix spaces; rank 1; small world graphs"><p>Lecture 11: Matrix spaces; ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-12-graphs-networks-incidence-matrices/index.htm">
<img src="../../../contents/video-lectures/lecture-12-graphs-networks-incidence-matrices/18.06_L12.jpg" title="Lecture 12: Graphs, networks, incidence matrices" alt="Lecture 12: Graphs, networks, incidence matrices"><p>Lecture 12: Graphs, network...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-13-quiz-1-review/index.htm">
<img src="../../../contents/video-lectures/lecture-13-quiz-1-review/18.06_L13.jpg" title="Lecture 13: Quiz 1 review" alt="Lecture 13: Quiz 1 review"><p>Lecture 13: Quiz 1 review</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-14-orthogonal-vectors-and-subspaces/index.htm">
<img src="../../../contents/video-lectures/lecture-14-orthogonal-vectors-and-subspaces/18.06_L14.jpg" title="Lecture 14: Orthogonal vectors and subspaces" alt="Lecture 14: Orthogonal vectors and subspaces"><p>Lecture 14: Orthogonal vect...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-15-projections-onto-subspaces/index.htm">
<img src="../../../contents/video-lectures/lecture-15-projections-onto-subspaces/18.06_L15.jpg" title="Lecture 15: Projections onto subspaces" alt="Lecture 15: Projections onto subspaces"><p>Lecture 15: Projections ont...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-16-projection-matrices-and-least-squares/index.htm">
<img src="../../../contents/video-lectures/lecture-16-projection-matrices-and-least-squares/18.06_L16.jpg" title="Lecture 16: Projection matrices and least squares" alt="Lecture 16: Projection matrices and least squares"><p>Lecture 16: Projection matr...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-17-orthogonal-matrices-and-gram-schmidt/index.htm">
<img src="../../../contents/video-lectures/lecture-17-orthogonal-matrices-and-gram-schmidt/18.06_L17.jpg" title="Lecture 17: Orthogonal matrices and Gram-Schmidt" alt="Lecture 17: Orthogonal matrices and Gram-Schmidt"><p>Lecture 17: Orthogonal matr...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-18-properties-of-determinants/index.htm">
<img src="../../../contents/video-lectures/lecture-18-properties-of-determinants/18.06_L18.jpg" title="Lecture 18: Properties of determinants" alt="Lecture 18: Properties of determinants"><p>Lecture 18: Properties of d...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-19-determinant-formulas-and-cofactors/index.htm">
<img src="../../../contents/video-lectures/lecture-19-determinant-formulas-and-cofactors/18.06_L19.jpg" title="Lecture 19: Determinant formulas and cofactors" alt="Lecture 19: Determinant formulas and cofactors"><p>Lecture 19: Determinant for...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-20-cramers-rule-inverse-matrix-and-volume/index.htm">
<img src="../../../contents/video-lectures/lecture-20-cramers-rule-inverse-matrix-and-volume/18.06_L20.jpg" title="Lecture 20: Cramer's rule, inverse matrix, and volume" alt="Lecture 20: Cramer's rule, inverse matrix, and volume"><p>Lecture 20: Cramer's rule, ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-21-eigenvalues-and-eigenvectors/index.htm">
<img src="../../../contents/video-lectures/lecture-21-eigenvalues-and-eigenvectors/18.06_L21.jpg" title="Lecture 21: Eigenvalues and eigenvectors" alt="Lecture 21: Eigenvalues and eigenvectors"><p>Lecture 21: Eigenvalues and...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-22-diagonalization-and-powers-of-a/index.htm">
<img src="../../../contents/video-lectures/lecture-22-diagonalization-and-powers-of-a/18.06_L22.jpg" title="Lecture 22: Diagonalization and powers of A" alt="Lecture 22: Diagonalization and powers of A"><p>Lecture 22: Diagonalization...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-23-differential-equations-and-exp-at/index.htm">
<img src="../../../contents/video-lectures/lecture-23-differential-equations-and-exp-at/18.06_L23.jpg" title="Lecture 23: Differential equations and exp(At)" alt="Lecture 23: Differential equations and exp(At)"><p>Lecture 23: Differential eq...</p></a>
</div>
<div class="related-media-thumbnail-nolink">
<div class="now-playing-resource">Now Playing</div>
<img src="../../../contents/video-lectures/lecture-24-markov-matrices-fourier-series/18.06_L24.jpg" title="Lecture 24: Markov matrices; fourier series" alt="Lecture 24: Markov matrices; fourier series"><p>Lecture 24: Markov matrices...</p>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-24b-quiz-2-review/index.htm">
<img src="../../../contents/video-lectures/lecture-24b-quiz-2-review/18.06_L24b.jpg" title="Lecture 24b: Quiz 2 review" alt="Lecture 24b: Quiz 2 review"><p>Lecture 24b: Quiz 2 review</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-25-symmetric-matrices-and-positive-definiteness/index.htm">
<img src="../../../contents/video-lectures/lecture-25-symmetric-matrices-and-positive-definiteness/18.06_L25.jpg" title="Lecture 25: Symmetric matrices and positive definiteness" alt="Lecture 25: Symmetric matrices and positive definiteness"><p>Lecture 25: Symmetric matri...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-26-complex-matrices-fast-fourier-transform/index.htm">
<img src="../../../contents/video-lectures/lecture-26-complex-matrices-fast-fourier-transform/18.06_L26.jpg" title="Lecture 26: Complex matrices; fast fourier transform" alt="Lecture 26: Complex matrices; fast fourier transform"><p>Lecture 26: Complex matrice...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-27-positive-definite-matrices-and-minima/index.htm">
<img src="../../../contents/video-lectures/lecture-27-positive-definite-matrices-and-minima/18.06_L27.jpg" title="Lecture 27: Positive definite matrices and minima" alt="Lecture 27: Positive definite matrices and minima"><p>Lecture 27: Positive defini...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-28-similar-matrices-and-jordan-form/index.htm">
<img src="../../../contents/video-lectures/lecture-28-similar-matrices-and-jordan-form/18.06_L28.jpg" title="Lecture 28: Similar matrices and jordan form" alt="Lecture 28: Similar matrices and jordan form"><p>Lecture 28: Similar matrice...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-29-singular-value-decomposition/index.htm">
<img src="../../../contents/video-lectures/lecture-29-singular-value-decomposition/18.06_L29.jpg" title="Lecture 29: Singular value decomposition" alt="Lecture 29: Singular value decomposition"><p>Lecture 29: Singular value ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-30-linear-transformations-and-their-matrices/index.htm">
<img src="../../../contents/video-lectures/lecture-30-linear-transformations-and-their-matrices/18.06_L30.jpg" title="Lecture 30: Linear transformations and their matrices" alt="Lecture 30: Linear transformations and their matrices"><p>Lecture 30: Linear transfor...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-31-change-of-basis-image-compression/index.htm">
<img src="../../../contents/video-lectures/lecture-31-change-of-basis-image-compression/18.06_L31.jpg" title="Lecture 31: Change of basis; image compression" alt="Lecture 31: Change of basis; image compression"><p>Lecture 31: Change of basis...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-32-quiz-3-review/index.htm">
<img src="../../../contents/video-lectures/lecture-32-quiz-3-review/18.06_L32.jpg" title="Lecture 32: Quiz 3 review" alt="Lecture 32: Quiz 3 review"><p>Lecture 32: Quiz 3 review</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-33-left-and-right-inverses-pseudoinverse/index.htm">
<img src="../../../contents/video-lectures/lecture-33-left-and-right-inverses-pseudoinverse/18.06_L33.jpg" title="Lecture 33: Left and right inverses; pseudoinverse" alt="Lecture 33: Left and right inverses; pseudoinverse"><p>Lecture 33: Left and right ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-34-final-course-review/index.htm">
<img src="../../../contents/video-lectures/lecture-34-final-course-review/18.06_L34.jpg" title="Lecture 34: Final course review" alt="Lecture 34: Final course review"><p>Lecture 34: Final course re...</p></a>
</div>
</div>
        <div id="vid_playlist" itemprop="description" class="tabContent hide">
<h2 class="subhead">Related Resources</h2>
<p><a href="../../../contents/readings/index.htm" target="_blank">Readings</a><br><a href="../../../contents/readings#Table_of_Contents" target="_blank">Table of Contents</a></p>
</div>
        <div id="vid_related" itemprop="description" class="tabContent hide">
<ul><li><a class="transcript-link" title="Open in a new window." alt="Open in a new window." style="text-decoration: none; font-size: 1.0em;" target="_blank" text-decoration: none font-size: href="../../../contents/video-lectures/MIT18_06S10_L24.pdf"> Download this transcript - PDF (English - US)</a></li></ul>
<div class="vidpad">
<p></p> <p>-- two, one and -- okay. Here is a lecture on the applications of  eigenvalues and, if I can -- so that will be Markov matrices. I'll tell  you what a Markov matrix is, so this matrix A will be a Markov matrix  and I'll explain how they come in applications.</p> <p>And -- and then  if I have time, I would like to say a little bit about Fourier series,  which is a fantastic application of the projection chapter.</p> <p>Okay. What's a Markov matrix? Can I just write down a typical Markov matrix, say .1, .2, .7, .01, .99 0, let's say, .3, .3, .4.</p> <p>Okay.  There's a -- a totally just invented Markov matrix. What makes it a  Markov matrix? Two properties that this -- this matrix has.</p> <p>So  two properties are -- one, every entry is greater equal zero. All  entries greater than or equal to zero. And, of course, when I square the  matrix, the entries will still be greater/equal zero. I'm going to be  interested in the powers of this matrix. And this property, of course,  is going to -- stay there.</p> <p>It -- really Markov matrices you'll  see are connected to probability ideas and probabilities are never  negative. The other property -- do you see the other property in there?  If I add down the columns, what answer do I get? One. So all columns add  to one. All columns add to one. And actually when I square the matrix,  that will be true again.</p> <p>So that the powers of my matrix are all  Markov matrices, and I'm interested in, always, the eigenvalues and the  eigenvectors. And this question of steady state will come up. You  remember we had steady state for differential equations last time? When  -- what was the steady state -- what was the eigenvalue? What was the  eigenvalue in the differential equation case that led to a steady state?  It was lambda equals zero. When -- you remember that we did an example  and one of the eigenvalues was lambda equals zero, and that -- so then  we had an E to the zero T, a constant one -- as time went on, there that  thing stayed steady. Now what -- in the powers case, it's not a zero  eigenvalue. Actually with powers of a matrix, a zero eigenvalue, that  part is going to die right away. It's an eigenvalue of one that's all  important. So this steady state will correspond -- will be totally  connected with an eigenvalue of one and its eigenvector. In fact, the  steady state will be the eigenvector for that eigenvalue. Okay.</p> <p>So  that's what's coming. Now, for some reason then that we have to see,  this matrix has an eigenvalue of one. This property, that the columns  all add to one -- turns out -- guarantees that one is an eigenvalue, so  that you can actually find the eigenvalue -- find that eigenvalue of a  Markov matrix without computing any determinants of A minus lambda I --  that matrix will have an eigenvalue of one, and we want to see why. And  then the other thing is -- so the key points -- let me -- let me write  these underneath.</p> <p>The key points are -- the key points are lambda  equal one is an eigenvalue. I'll add in a little -- an additional --  well, a thing about eigenvalues -- key point two, the other eigenval-  values -- all other eigenvalues are, in magnitude, smaller than one --  in absolute value, smaller than one.</p> <p>Well, there could be some exceptional case when -- when an eigen -- another eigenvalue might have magnitude equal one.</p> <p>It never has an eigenvalue larger than one.</p> <p>So  these two facts -- somehow we ought to -- linear algebra ought to tell  us. And then, of course, linear algebra is going to tell us what the --  what's -- what happens if I take -- if -- you remember when I solve --  when I multiply by A time after time the K-th thing is A to the K u0 and  I'm asking what's special about this -- these powers of A, and very  likely the quiz will have a problem to computer s- to computer some  powers of A or -- or applied to an initial vector.</p> <p>So, you  remember the general form? The general form is that there's some amount  of the first eigenvalue to the K-th power times the first eigenvector,  and another amount of the second eigenvalue to the K-th power times the  second eigenvector and so on. A -- just -- my conscience always makes me  say at least once per lecture that this requires a complete set of  eigenvectors, otherwise we might not be able to expand u0 in the  eigenvectors and we couldn't get started. But once we're started with u0  when K is zero, then every A brings in these lambdas. And now you can  see what the steady state is going to be. If lambda one is one -- so  lambda one equals one to the K-th power and these other eigenvalues are  smaller than one -- so I've sort of scratched over the equation there to  -- we had this term, but what happens to this term -- if the lambda's  smaller than one, then the -- when -- as we take powers, as we iterate  as we -- as we go forward in time, this goes to zero, right? Can I just  -- having scratched over it, I might as well scratch further. That term  and all the other terms are going to zero because all the other  eigenvalues are smaller than one and the steady state that we're  approaching is just -- whatever there was -- this was -- this was the --  this is the x1 part of un- of the initial condition u0 -- is the steady  state. This much we know from general -- from -- you know, what we've  already done.</p> <p>So I want to see why -- let's at least see number  one, why one is an eigenvalue. And then there's actually -- in this  chapter we're interested not only in eigenvalues, but also eigenvectors.  And there's something special about the eigenvector. Let me write down  what that is.</p> <p>The eigenvector x1 -- x1 is the eigenvector and all  its components are positive, so the steady state is positive, if the  start was. If the start was -- so -- well, actually, in general, I --  this might have a -- might have some component zero always, but no  negative components in that eigenvector.</p> <p>Okay. Can I come to that point? How can I look at that matrix -- so that was just an example.</p> <p>How  could I be sure -- how can I see that a matrix -- if the columns add to  zero -- add to one, sorry -- if the columns add to one, this property  means that lambda equal one is an eigenvalue. Okay.</p> <p>So let's just think that through.</p> <p>What  I saying about -- let me ca- let me look at A, and if I believe that  one is an eigenvalue, then I should be able to subtract off one times  the identity and then I would get a matrix that's, what, -.9, -.01 and  -.6 -- wh- I took the ones away and the other parts, of course, are  still what they were, and this is still .2 and .7 and -- okay, what's --  what's up with this matrix now? I've shifted the matrix, this Markov  matrix by one, by the identity, and what do I want to prove? I -- what  is it that I believe this matrix -- about this matrix? I believe it's  singular.</p> <p>Singular will -- if A minus I is singular, that tells  me that one is an eigenvalue, right? The eigenvalues are the numbers  that I subtract off -- the shifts -- the numbers that I subtract from  the diagonal -- to make it singular. Now why is that matrix singular? I  -- we could compute its determinant, but we want to see a reason that  would work for every Markov matrix not just this particular random  example.</p> <p>So what is it about that matrix? Well, I guess you could look at its columns now -- what do they add up to? Zero.</p> <p>The  columns add to zero, so all columns -- let me put all columns now of --  of -- of A minus I add to zero, and then I want to realize that this  means A minus I is singular. Okay.</p> <p>Why? So I could I -- you know,  that could be a quiz question, a sort of theoretical quiz question. If I  give you a matrix and I tell you all its columns add to zero, give me a  reason, because it is true, that the matrix is singular.</p> <p>Okay. I  guess actually -- now what -- I think of -- you know, I'm thinking of  two or three ways to see that. How would you do it? We don't want to  take its determinant somehow. For the matrix to be singular, well, it  means that these three columns are dependent, right? The determinant  will be zero when those three columns are dependent. You see, we're --  we're at a point in this course, now, where we have several ways to look  at an idea.</p> <p>We can take the determinant -- here we don't want to.</p> <p>B-  but we met singular before that -- those columns are dependent. So how  do I see that those columns are dependent? They all add to zero.</p> <p>Let's  see, whew -- well, oh, actually, what -- another thing I know is that  the -- I would like to be able to show is that the rows are dependent.</p> <p>Maybe  that's easier. If I know that all the columns add to zero, that's my  information, how do I see that those three rows are linearly dependent?  What -- what combination of those rows gives the zero row? How -- how  could I combine those three rows -- those three row vectors to produce  the zero row vector? And that would tell me those rows are dependent,  therefore the columns are dependent, the matrix is singular, the  determinant is zero -- well, you see it. I just add the rows.</p> <p>One times that row plus one times that row plus one times that row -- it's the zero row. The rows are dependent.</p> <p>In  a way, that one one one, because it's multiplying the rows, is like an  eigenvector in the -- it's in the left null space, right? One one one is  in the left null space.</p> <p>It's singular because the rows are  dependent -- and can I just keep the reasoning going? Because this  vector one one one is -- it's not in the null space of the matrix, but  it's in the null space of the transpose -- is in the null space of the  transpose. And that's good enough.</p> <p>If we have a square matrix --  if we have a square matrix and the rows are dependent, that matrix is  singular. So it turned out that the immediate guy we could identify was  one one one.</p> <p>Of course, the -- there will be somebody in the null  space, too. And actually, who will it be? So what's -- so -- so now I  want to ask about the null space of -- of the matrix itself. What  combination of the columns gives zero? I -- I don't want to compute it  because I just made up this matrix and -- it will -- it would take me a  while -- it looks sort of doable because it's three by three but wh- my  point is, what -- what vector is it if we -- once we've found it, what  have we got that's in the -- in the null space of A? It's the  eigenvector, right? That's where we find X one. Then X one, the  eigenvector, is in the null space of A. That's the eigenvector  corresponding to the eigenvalue one.</p> <p>Right? That's how we find  eigenvectors. So those three columns must be dependent -- some  combination of columns -- of those three columns is the zero column and  that -- the three components in that combination are the eigenvector.</p> <p>And that guy is the steady state.</p> <p>Okay. So I'm happy about the -- the thinking here, but I haven't given -- I haven't completed it because I haven't found x1.</p> <p>But  it's there. Can I -- another thought came to me as I was doing this,  another little comment that -- you -- about eigenvalues and  eigenvectors, because of A and A transpose. What can you tell me about  eigenvalues of A -- of A and eigenvalues of A transpose? Whoops. They're  the same.</p> <p>They're -- so this is a little comment -- we -- it's  useful, since eigenvalues are generally not easy to find -- it's always  useful to know some cases where you've got them, where -- and this is --  if you know the eigenvalues of A, then you know the eigenvalues of A  transpose.</p> <p>eigenvalues of A transpose are the same.</p> <p>And  can I just, like, review why that is? So to find the eigenvalues of A,  this would be determinate of A minus lambda I equals zero, that gives me  an eigenvalue of A -- now how can I get A transpose into the picture  here? I'll use the fact that the determinant of a matrix and the  determinant of its transpose are the same.</p> <p>The determinant of a  matrix equals the determinant of a -- of the transpose. That was  property ten, the very last guy in our determinant list.</p> <p>So I'll  transpose that matrix. This leads to -- I just take the matrix and  transpose it, but now what do I get when I transpose lambda I? I just  get lambda I.</p> <p>So that's -- that's all there was to the reasoning. The reasoning is that the eigenvalues of A solved that equation.</p> <p>The  determinant of a matrix is the determinant of its transpose, so that  gives me this equation and that tells me that the same lambdas are  eigenvalues of A transpose.</p> <p>So that, backing up to the Markov  case, one is an eigenvalue of A transpose and we actually found its  eigenvector, one one one, and that tell us that one is also an  eigenvalue of A -- but, of course, it has a different eigenvector, the  -- the left null space isn't the same as the null space and we would  have to find it.</p> <p>So there's some vector here which is x1 that  produces zero zero zero. Actually, it wouldn't be that hard to find, you  know, I -- as I'm talking I'm thinking, okay, I going to follow through  and actually find it? Well, I can tell from this one -- look, if I put a  point six there and a point seven there, that's what -- then I'll be  okay in the last row, right? Now I only -- remains to find one guy. And  let me take the first row, then. Minus point 54 plus point 21 -- there's  some big number going in there, right? So I have -- just to make the  first row come out zero, I'm getting minus point 54 plus point 21, so  that was minus point 33 and what -- what do I want? Like thirty three  hundred? This is the first time in the history of linear algebra that an  eigenvector has every had a component thirty three hundred.</p> <p>But I guess it's true. Because then I multiply by minus one over a hundred -- oh no, it was point 33.</p> <p>So is this just -- oh, shoot.</p> <p>Only 33. Okay.</p> <p>Only  33. Okay, so there's the eigenvector. Oh, and notice that it -- that it  turned -- did turn out, at least, to be all positive.</p> <p>So that  was, like, the theory -- predicts that part, too. I won't give the proof  of that part. So 30 -- 33 -- point six 33 point seven. Okay.</p> <p>Now those are the ma- that's the linear algebra part.</p> <p>Can  I get to the applications? Where do these Markov matrices come from?  Because that's -- that's part of this course and absolutely part of this  lecture.</p> <p>Okay. So where's -- what's an application of Markov matrices? Okay.</p> <p>Markov  matrices -- so, my equation, then, that I'm solving and studying is  this equation u(k+1)=Auk. And now A is a Markov matrix. A is Markov. And  I want to give an example.</p> <p>Can I just create an example? It'll be two by two.</p> <p>And  it's one I've used before because it seems to me to bring out the idea.  It's -- because we have two by two, we have two states, let's say  California and Massachusetts. And I'm looking at the populations in  those two states, the people in those two states, California and  Massachusetts. And my matrix A is going to tell me in a -- in a year,  some movement has happened.</p> <p>Some people stayed in Massachusetts,  some people moved to California, some smart people moved from California  to Massachusetts, some people stayed in California and made a billion.</p> <p>Okay.  So that -- there's a matrix there with four entries and those tell me  the fractions of my population -- so I'm making -- I'm going to use  fractions, so they won't be negative, of course, because -- because only  positive people are in- involved here -- and they'll add up to one,  because I'm accounting for all people. So that's why I have these two  key properties. The entries are greater equal zero because I'm looking  at probabilities.</p> <p>Do they move, do they stay? Those probabilities are all between zero and one.</p> <p>And  the probabilities add to one because everybody's accounted for. I'm not  losing anybody, gaining anybody in this Markov chain.</p> <p>It's -- it conserves the total population.</p> <p>Okay. So what would be a typical matrix, then? So this would be u, California and u Massachusetts at time t equal k+1.</p> <p>And  it's some matrix, which we'll think of, times u California and u  Massachusetts at time k. And notice this matrix is going to stay the  same, you know, forever. So that's a severe limitation on the example.  The example has a -- the same Markov matrix, the same probabilities act  at every time. Okay.</p> <p>So what's a reasonable, say -- say point nine of the people in California at time k stay there.</p> <p>And  point one of the people in California move to Massachusetts. Notice why  that column added to one, because we've now accounted for all the  people in California at time k. Nine tenths of them are still in  California, one tenth are here at time k+1.</p> <p>Okay. What about the  people who are in Massachusetts? This is going to multiply column two,  right, by our fundamental rule of multiplying matrix by vector, it's the  -- it's the population in Massachusetts.</p> <p>Shall we say that --  that after the Red Sox, fail again, eight -- only 80 percent of the  people in Massachusetts stay and 20 percent move to California.</p> <p>Okay. So again, this adds to one, which accounts for all people in Massachusetts where they are.</p> <p>So  there is a Markov matrix. Non-negative entries adding to one. What's  the steady state? If everybody started in Massachusetts, say, at -- you  know, when the Pilgrims showed up or something. Then where are they now?  Where are they at time 100, let's say, or maybe -- I don't know, how  many years since the Pilgrims? 300 and something. Or -- and actually  where will they be, like, way out a million years from now? I -- I could  multiply -- take the powers of this matrix. In fact, you'll -- you  would -- ought to be able to figure out what is the hundredth power of  that matrix? Why don't we do that? But let me follow the steady state.</p> <p>So  what -- what's my starting -- my starting u Cal, u Mass at time zero  is, shall we say -- shall we put anybody in California? Let's make --  let's make zero there, and say the population of Massachusetts is --  let's say a thousand just to -- okay.</p> <p>So the population is -- so  the populations are zero and a thousand at the start. What can you tell  me about this population after -- after k steps? What will u Cal plus u  Mass add to? A thousand. Those thousand people are always accounted for.  But -- so u Mass will start dropping from a thousand and u Cal will  start growing.</p> <p>Actually, we could see -- why don't we figure out  what it is after one? After one time step, what are the populations at  time one? So what happens in one step? You multiply once by that matrix  and, let's see, zero times this column -- so it's just a thousand times  this column, so I think we're getting 200 and 800. So after the first  step, 200 people have -- are in California.</p> <p>Now at the following step, I'll multiply again by this matrix -- more people will move to California.</p> <p>Some  people will move back. Twenty people will come back and, the -- the net  result will be that the California population will be above 200 and the  Massachusetts below 800 and they'll still add up to a thousand.</p> <p>Okay. I do that a few times.</p> <p>I  do that 100 times. What's the population? Well, okay, to answer any  question like that, I need the eigenvalues and eigenvectors, right? As  soon as I've -- I've created an example, but as soon as I want to solve  anything, I have to find eigenvalues and eigenvectors of that matrix.</p> <p>Okay. So let's do it.</p> <p>So there's the matrix .9, .2, .1, .8 and tell me its eigenvalues. Lambda equals -- so tell me one eigenvalue? One, thanks.</p> <p>And  tell me the other one. What's the other eigenvalue -- from the trace or  the determinant -- from the -- I -- the trace is what -- is, like,  easier.</p> <p>So the trace of that matrix is one point seven.</p> <p>So the other eigenvalue is point seven.</p> <p>And it -- notice that it's less than one.</p> <p>And notice that that determinant is point 72-.02, which is point seven. Right.</p> <p>Okay. Now to find the eigenvectors.</p> <p>This  is -- so that's lambda one and the eigenvector -- I'll subtract one  from the diagonal, right? So can I do that in light let -- in light  here? Subtract one from the diagonal, I have minus point one and minus  point two, and of course these are still there. And I'm looking for its  -- here's -- here's -- this is going to be x1.</p> <p>It's the null space of A minus I.</p> <p>Okay, everybody sees that it's two and one.</p> <p>Okay? And now how about -- so that -- and it -- notice that that eigenvector is positive.</p> <p>And  actually, we can jump to infinity right now. What's the population at  infinity? It's a multiple -- this is -- this eigenvector is giving the  steady state.</p> <p>It's some multiple of this, and how is that  multiple decided? By adding up to a thousand people. So the steady  state, the c1x1 -- this is the x1, but that adds up to three, so I  really want two -- it's going to be two thirds of a thousand and one  third of a thousand, making a total of the thousand people.</p> <p>That'll  be the steady state. That's really all I need to know at infinity. But  if I want to know what's happened after just a finite number like 100  steps, I'd better find this eigenvector.</p> <p>So can I -- can I look  at -- I'll subtract point seven time -- ti- from the diagonal and I'll  get that and I'll look at the null space of that one and I -- and this  is going to give me x2, now, and what is it? So what's in the null space  of -- that's certainly singular, so I know my calculation is right, and  -- one and minus one. One and minus one.</p> <p>So I'm prepared now to  write down the solution after 100 time steps. The -- the populations  after 100 time steps, right? Can -- can we remember the point one -- the  -- the one with this two one eigenvector and the point seven with the  minus one one eigenvector. So I'll -- let me -- I'll just write it above  here. u after k steps is some multiple of one to the k times the two  one eigenvector and some multiple of point seven to the k times the  minus one one eigenvector. Right? That's -- I -- this is how I take --  how powers of a matrix work. When I apply those powers to a u0, what I  -- so it's u0, which was zero a thousand -- that has to be corrected  k=0. So I'm plugging in k=0 and I get c1 times two one and c2 times  minus one one.</p> <p>Two equations, two constants, certainly  independent eigenvectors, so there's a solution and you see what it is?  Let's see, I guess we already figured that c1 was a thousand over three,  I think -- did we think that had to be a thousand over three? And maybe  c2 would be -- excuse me, let -- get an eraser -- we can -- I just -- I  think we've -- get it here. c2, we want to get a zero here, so maybe we  need plus two thousand over three.</p> <p>I think that has to work. Two  times a thousand over three minus two thousand over three, that'll give  us the zero and a thousand over three and the two thousand over three  will give us three thousand over three, the thousand.</p> <p>So this is  what we approach -- this part, with the point seven to the k-th power is  the part that's disappearing. Okay. That's -- that's Markov matrices.  That's an example of where they come from, from modeling movement of  people with no gain or loss, with total -- total count conserved.</p> <p>Okay.  I -- just if I can add one more comment, because you'll see Markov  matrices in electrical engineering courses and often you'll see them --  sorry, here's my little comment.</p> <p>Sometimes -- in a lot of  applications they prefer to work with row vectors. So they -- instead of  -- this was natural for us, right? For all the eigenvectors to be  column vectors.</p> <p>So our columns added to one in the Markov matrix.</p> <p>Just  so you don't think, well, what -- what's going on? If we work with row  vectors and we multiply vector times matrix -- so we're multiplying from  the left -- then it'll be the then we'll be using the transpose of --  of this matrix and it'll be the rows that add to one.</p> <p>So in other textbooks, you'll see -- instead of col- columns adding to one, you'll see rows add to one.</p> <p>Okay. Fine.</p> <p>Okay,  that's what I wanted to say about Markov, now I want to say something  about projections and even leading in -- a little into Fourier series.</p> <p>Because  -- but before any Fourier stuff, let me make a comment about  projections. This -- so this is a comment about projections onto -- with  an orthonormal basis. So, of course, the basis vectors are q1 up to qn.</p> <p>Okay. I have a vector b. Let -- let me imagine -- let me imagine this is a basis.</p> <p>Let  -- let's say I'm in n by n. I'm -- I've got, eh, n orthonormal vectors,  I'm in n dimensional space so they're a complete -- they're a basis --  any vector v could be expanded in this basis.</p> <p>So any vector v is some combination, some amount of q1 plus some amount of q2 plus some amount of qn.</p> <p>So  -- so any v. I just want you to tell me what those amounts are. What  are x1 -- what's x1, for example? So I'm looking for the expansion. This  is -- this is really our projection. I could -- I could really use the  word expansion. I'm expanding the vector in the basis. And the special  thing about the basis is that it's orthonormal. So that should give me a  special formula for the answer, for the coefficients.</p> <p>So how do I  get x1? What -- what's a formula for x1? I could -- I can go through  the projection -- the Q transpose Q, all that -- normal equations, but  -- and I'll get -- I'll come out with this nice answer that I think I  can see right away.</p> <p>How can I pick -- get a hold of x1 and get  these other x-s out of the equation? So how can I get a nice, simple  formula for x1? And then we want to see, sure, we knew that all the  time. Okay.</p> <p>So what's x1? The good way is take the inner product  of everything with q1. Take the inner product of that whole equation,  every term, with q1.</p> <p>What will happen to that last term? The  inner product -- when -- if I take the dot product with q1 I get zero,  right? Because this basis was orthonormal.</p> <p>If I take the dot product with q2 I get zero.</p> <p>If I take the dot product with q1 I get one.</p> <p>So  that tells me what x1 is. q1 transpose v, that's taking the dot  product, is x1 times q1 transpose q1 plus a bunch of zeroes. And this is  a one, so I can forget that. I get x1 immediately.</p> <p>So -- do you  see what I'm saying -- is that I have an orthonormal basis, then the  coefficient that I need for each basis vector is a cinch to find. Let me  -- let me just -- I have to put this into matrix language, too, so  you'll see it there also. If I write that first equation in matrix  language, what -- what is it? I'm writing -- in matrix language, this  equation says I'm taking these columns -- are -- are you guys good at  this now? I'm taking those columns times the Xs and getting V, right?  That's the matrix form. Okay, that's the matrix Q.</p> <p>Qx is v.  What's the solution to that equation? It's -- of course, it's x equal Q  inverse v. So x is Q inverse v, but what's the point? Q inverse in this  case is going to -- is simple. I don't have to work to invert this  matrix Q, because of the fact that the -- these columns are orthonormal,  I know the inverse to that. And it is Q transpose. When you see a Q, a  square matrix with that letter Q, the -- that just triggers -- Q inverse  is the same as Q transpose.</p> <p>So the first component, then -- the  first component of x is the first row times v, and what's that? The  first component of this answer is the first row of Q transpose. That's  just -- that's just q1 transpose times v. So that's what we concluded  here, too. Okay.</p> <p>So -- so nothing Fourier here. The -- the key  ingredient here was that the q-s are orthonormal. And now that's what  Fourier series are built on.</p> <p>So now, in the remaining time, let me say something about Fourier series. Okay.</p> <p>So Fourier series is -- well, we've got a function f of x.</p> <p>And  we want to write it as a combination of -- maybe it has a constant  term. And then it has some cos(x) in it. And it has some sin(x) in it.</p> <p>And  it has some cos(2x) in it. And a -- and some sin(2x), and forever. So  what's -- what's the difference between this type problem and the one  above it? This one's infinite, but the key property of things being  orthogonal is still true for sines and cosines, so it's the property  that makes Fourier series work. So that's called a Fourier series.</p> <p>Better write his name up. Fourier series.</p> <p>So it was Joseph Fourier who realized that, hey, I could work in function space.</p> <p>Instead of a vector v, I could have a function f of x.</p> <p>Instead  of orthogonal vectors, q1, q2 , q3, I could have orthogonal functions,  the constant, the cos(x), the sin(x), the s- cos(2x), but infinitely  many of them. I need infinitely many, because my space is infinite  dimensional.</p> <p>So this is, like, the moment in which we leave  finite dimensional vector spaces and go to infinite dimensional vector  spaces and our basis -- so the vectors are now functions -- and of  course, there are so many functions that it's -- that we've got an  infin- infinite dimensional space -- and the basis vectors are  functions, too. a0, the constant function one -- so my basis is one  cos(x), sin(x), cos(2x), sin(2x) and so on. And the reason Fourier  series is a success is that those are orthogonal.</p> <p>Okay. Now what  do I mean by orthogonal? I know what it means for two vectors to be  orthogonal -- y transpose x equals zero, right? Dot product equals zero.</p> <p>But  what's the dot product of functions? I'm claiming that whatever it is,  the dot product -- or we would more likely use the word inner product  of, say, cos(x) with sin(x) is zero.</p> <p>And cos(x) with cos(2x), also zero.</p> <p>So  I -- let me tell you what I mean by that, by that dot product. Well,  how do I compute a dot product? So, let's just remember for vectors v  trans- v transpose w for vectors, so this was vectors, v transpose w was  v1w1 +...+vnwn. Okay. Now functions.</p> <p>Now I have two functions, let's call them f and g.</p> <p>What's with them now? The vectors had n components, but the functions have a whole, like, continuum.</p> <p>To  graph the function, I just don't have n points, I've got this whole  graph. So I have functions -- I'm really trying to ask you what's the  inner product of this function f with another function g? And I want to  make it parallel to this the best I can.</p> <p>So the best parallel is  to multiply f (x) times g(x) at every x -- and here I just had n  multiplications, but here I'm going to have a whole range of x-s, and  here I added the results.</p> <p>What do I do here? So what's the analog  of addition when you have -- when you're in a continuum? It's  integration. So that the -- the dot product of two functions will be the  integral of those functions, dx. Now I have to say -- say, well, what  are the limits of integration? And for this Fourier series, this  function f(x) -- if I'm going to have -- if that right hand side is  going to be f(x), that function that I'm seeing on the right, all those  sines and cosines, they're all periodic, with -- with period two pi.</p> <p>So -- so that's what f(x) had better be.</p> <p>So I'll integrate from zero to two pi.</p> <p>My  -- all -- everything -- is on the interval zero two pi now, because if  I'm going to use these sines and cosines, then f(x) is equal to  f(x+2pi). This is periodic -- periodic functions. Okay.</p> <p>So now I know what -- I've got all the right words now.</p> <p>I've got a vector space, but the vectors are functions.</p> <p>I've  got inner products and -- and the inner product gives a number, all  right. It just happens to be an integral instead of a sum. I've got --  and that -- then I have the idea of orthogonality -- because, actually,  just -- let's just check. Orthogonality -- if I take the integral -- s- I  -- let me do sin(x) times cos(x) -- sin(x) times cos(x) dx from zero to  two pi -- I think we get zero.</p> <p>That's the differential of that,  so it would be one half sine x squared, was that right? Between zero and  two pi -- and, of course, we get zero. And the same would be true with a  little more -- some trig identities to help us out -- of every other  pair. So we have now an orthonormal infinite basis for function space,  and all we want to do is express a function in that basis.</p> <p>And so  I -- the end of my lecture is, okay, what is a1? What's the coefficient  -- how much cos(x) is there in a function compared to the other  harmonics? How much constant is in that function? That'll -- that would  be an easy question. The answer a0 will come out to be the average value  of f. That's the amount of the constant that's in there, its average  value.</p> <p>But let's take a1 as more typical.</p> <p>How will I get -- here's the end of the lecture, then -- how do I get a1? The first Fourier coefficient.</p> <p>Okay.  I do just as I did in the vector case. I take the inner product of  everything with cos(x) Take the inner product of everything with cos(x).  Then on the left -- on the left I have -- the inner product is the  integral of f(x) times cos(x) cx. And on the right, what do I have? When  I -- so what I -- when I say take the inner product with cos(x), let me  put it in ordinary calculus words. Multiply by cos(x) and integrate.  That's what inner products are.</p> <p>So if I multiply that whole thing by cos(x) and I integrate, I get a whole lot of zeroes.</p> <p>The only thing that survives is that term.</p> <p>All  the others disappear. So -- and that term is a1 times the integral of  cos(x) squared dx zero to 2pi equals -- so this was the left side and  this is all that's left on the right-hand side. And this is not zero of  course, because it's the length of the function squared, it's the inner  product with itself, and -- and a simple calculation gives that answer  to be pi.</p> <p>So that's an easy integral and it turns out to be pi, so that a1 is one over pi times there -- times this integral.</p> <p>So  there is, actually -- that's Euler's famous formula for the -- or maybe  Fourier found it -- for the coefficients in a Fourier series.</p> <p>And you see that it's exactly an expansion in an orthonormal basis. Okay, thanks.</p> <p>So I'll do a quiz review on Monday and then the quiz itself in Walker on Wednesday. Okay, see you Monday.</p> <p>Thanks.</p>
</div>
</div>
        <div id="vid_transcript" itemprop="description" class="tabContent hide">
<h2 class="subhead">Free Downloads</h2>
<h3 class="subsubhead">Video</h3>
<ul>
<li>iTunes U (<a href="http://deimos3.apple.com/WebObjects/Core.woa/Browse/mit.edu.1299892995.01299892999.1336712632?i=1607598969">MP4 - 110MB</a>)</li>
<li>Internet Archive (<a href="http://www.archive.org/download/MIT18.06S05_MP4/24_512kb.mp4">MP4 - 204MB</a>)</li>
</ul>
<br><h3 class="subsubhead">Free Streaming</h3>
<ul><li><a href="http://videolectures.net/mit1806s05_linear_algebra/">VideoLectures.net</a></li></ul>
<br><h3 class="subsubhead">Subtitle</h3>
<ul><li>English - US (<a href="../../../contents/video-lectures/lecture-24-markov-matrices-fourier-series/18.06_L24.srt">SRT</a>)</li></ul>
<br>
</div>
    
   </div>  


      					 
        <div class="" id="parent-fieldname-bottom_html_area">
            
            
        </div>
    
                    </div>
<!--Course_inner_chip tag close -->
           		</div>
<!--Course_wrapper tag close --> 
            </div>
<!--left tag close -->
            <div id="right">
                <!--Begin Right Portion -->
                    <div>
    
<div id="portletwrapper-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465" class="portletWrapper kssattr-portlethash-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465">
<div class="portletStaticText portlet-static-donate"><p class="zero"><a href="http://ocw.mit.edu/donate"><img src="../../../common/images/button_donate-now.png" alt="Donate Now." class="donate"></a></p></div>

</div>




</div>

                	<div>
    



</div>


        <div class="" id="parent-fieldname-rsi_top_html_area">
            
            
        </div>
    

<!-- RSI google ad space-->


<div id="google_ads">    
    <script type="text/javascript" src="http://partner.googleadservices.com/gampad/google_service.js"></script><script type="text/javascript">GS_googleAddAdSenseService("ca-pub-6588555046597237");GS_googleEnableAllServices();</script><script type="text/javascript">GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_A_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_B_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_C_DL");</script><script type="text/javascript">GA_googleFetchAds();</script><script language="javascript" type="text/javascript">
GA_googleAddAttr("TYPE","HOUSE");
GA_googleAddAttr("DEPARTMENT","18");
GA_googleAddAttr("CRS_BEG2","06");
GA_googleAddAttr("CRS_END","");
GA_googleAddAttr("SESSION","S");
GA_googleAddAttr("YEAR","10");
</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_A_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_B_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_C_DL");</script>
</div>

<!-- End RSI ads--> 

<div>
    



</div>

            </div>
<!--Right div close -->
            <div class="clear"></div> 
        </div>
<!--grid tag close --> 
      </div>
		
		<div id="bottom">
			<div id="grid">
				
<div id="portletwrapper-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572" class="portletWrapper kssattr-portlethash-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572">
<div class="portletStaticText portlet-static-site-footer"><div id="bottom">
<div id="grid">
<!-- *begin footer* -->
<div id="footer" role="navigation sitemap">
<div id="foot-c1" class="grid_2 alpha">
<h4 class="footer">Courses</h4>
<ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Find by Topic</a></li>
    <li><a href="http://ocw.mit.edu/courses/find-by-number/">Find by Course Number</a></li>
    <li><a href="http://ocw.mit.edu/courses/find-by-department/">Find by Department</a></li>
    <li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Courses</a></li>
    <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>
    <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>
    <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>
    <li><a href="http://ocw.mit.edu/courses/translated-courses/">Translated Courses</a></li>
    <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>
</ul>
</div>
<div id="foot-c2" class="grid_2">
<h4 class="footer">About</h4>
<ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/about/">About OpenCourseWare</a></li>
    <li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>
    <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>
    <li><a href="http://ocw.mit.edu/about/ocw-consortium/">OCW Consortium</a></li>
    <li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>
    <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>
    <li><a href="http://ocw.mit.edu/about/media-coverage/press-releases/">Press Releases</a></li>
    <li><a href="http://ocw.mit.edu/about/next-decade/">OCW's Next Decade</a></li>
</ul>
</div>
<div id="foot-c3" class="grid_2">
<h4 class="footer">Donate</h4>
<ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/donate">Make a Donation</a></li>
    <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>
    <li><a href="http://ocw.mit.edu/donate/ocw-course-champions-program/">Become a Course Champion</a></li>
    <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>
    <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>
    <li><a href="http://ocw.mit.edu/donate/shop-ocw/">Shop OCW</a></li>
    <li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li>
</ul>
</div>
<div id="foot-c4" class="grid_2">
<h4 class="footer">Featured Sites</h4>
<ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>
    <li><a href="https://www.edx.org/school/mitx/allcourses">MITx</a></li>
    <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>
</ul>
<h4 class="footer" style="margin-top: 14px;">Tools</h4>
<ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/help/">Help &amp; FAQs</a></li>
    <li><a href="../../../common/jsp/feedback.htm">Contact Us</a></li>
    <li><a href="../../../common/search/AdvancedSearch.htm">Advanced Search</a></li>
    <li><a href="http://ocw.mit.edu/help/site-map/">Site Map</a></li>
    <li><a href="../../../common/terms/index.htm">Privacy &amp; Terms of Use</a></li>
</ul>
</div>
<div id="foot-c5" class="grid_4 omega" itemprop="publisher" itemscope="" itemtype="http://schema.org/CollegeOrUniversity">
<h4 class="footer">About <span itemprop="name">MIT OpenCourseWare</span>
</h4>
<p class="accent" itemprop="description">MIT OpenCourseWare makes the materials used in the teaching of almost all of MIT's subjects available on the Web, free of charge. With more than 2,000 courses available, OCW is delivering on the promise of open sharing of knowledge.</p>
</div>
<div id="foot-copy" class="grid_8 alpha">
<a href="http://web.mit.edu"><img src="../../../common/images/logo_mit.png" alt="Massachusetts Institute of Technology logo and name." style="width: 195px; height: 44px;"></a>                 <a href="http://www.ocwconsortium.org/"><img src="../../../common/images/logo_ocwc.gif" alt="OpenCourseWare Consortium logo." style="width: 80px; height: 44px;"></a>                 <a rel="license" itemprop="useRightsUrl" href="http://creativecommons.org/licenses/by-nc-sa/3.0/us/deed.en_US"><img src="../../../common/images/cc_by-nc-sa.png" alt="Creative Commons logo with terms BY-NC-SA." style="width: 126px; height: 44px;"></a>
<p class="copyright">© 2001–2013<br>
Massachusetts Institute of Technology</p>
<p style="font-size: 0.9em; margin-bottom: 15px;">Your use of the MIT OpenCourseWare site and materials is subject to our <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/us/deed.en_US" rel="license">Creative Commons License</a> and other <a href="../../../common/terms/index.htm" rel="cc:morePermissions">terms of use</a>.</p>
</div>
<div id="foot-support" class="grid_4 omega"> </div>
</div>
</div>
</div></div>

</div>





                
			</div> <!-- bottom grid end -->
		</div>
<!-- bottom end -->
		
		
   </body>
</html>
