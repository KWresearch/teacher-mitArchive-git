18.06 Linear Algebra, Spring 2010 
Transcript â€“ Lecture 12 

OK. This is lecture twelve. 

We've reached twelve lectures. And this one is more than the others about 
applications of linear a lgebra. 

And I'll confess. When I'm giving you examp les of the null space and the row space, 
I create a little matrix. You probab ly see that I just  invent that matrix as I'm going. 

And I feel a little guilty about it, because the truth is that real linear a lgebra uses 
matrices that come from somewhere. They're not just, like, randomly invented by 
the instructor. 

They come from applications. They have a definite structure. 

And anybody who works with them gets, uses that structure. 

I'll just report, like, this weekend I was at an event w ith chemistry professors. OK, 
those guys are row reducing matrices, and what matrices are they working w ith? 
Well, their little matrices tell them how much of each element goes into the -- or 
each molecule, how many molecules of each go  into a  reaction and what comes out. 

And by row reduction they get a clearer picture of a complicated reaction. And this 
weekend I'm going to -- to a sort of birthday party at Mathworks. So Mathworks is 
out Route 9 in Natick. 

That's where Matlab is created. It's a very, very successful, software, tremendously 
successful. And the conference will be about how linear a lgebra is used. And so I feel 
better today to talk about what I think is the most important model in applied math. 

And the discrete version is a graph. So can I draw a graph? Write down the matrix 
that's associated with it, and that's a great source of matrices. You'll see. So a graph 
is just, so a graph -- to repeat -- has nodes and edges. OK. 

And I'm going to write down the graph, a graph, so I'm just creating a small graph 
here. 

As I mentioned last time, we would be very  interested in the graph of a ll, websites. 

Or the graph of all telephones. I mean -- or the graph of a ll people in the world. Here 
let me take just, maybe nodes one two three -- well, I better put in an -- I'll put in 
that edge and maybe an edge to, to a node four, and another edge to node four. 
How's that? So there's a graph w ith four nodes. 

So n will be four in my -- n equal four nodes. 

And the matrix w ill have m equal the number -- there'll be a  row for every edge, so 
I've got one two three four five edges. So that will be the number of rows. And I 
have to to write down the matrix that I want to, I want to study, I need to give a 
direction to every edge, so I know a p lus and a minus direction. So I'll just do that 
with an arrow. Say from one to two, one to three, two to three, one to  four, three to 
four. 

That just tells me, if I have current flowing on these edges then I know whether it's -
- to count it as positive or negative accord ing as whether it's w ith the arrow or 
against the arrow. But I just drew those arrows arbitrarily. OK. 

Because I -- my examp le is going to come -- the examp le I'll -- the words that I will 
use will be words like potentia l, potentia l d ifference, currents. In other words, I'm 
thinking of an electrica l network. 

But that's just one possib ility. 

My app lied math class builds on this examp le. 

It could be a hydraulic network, so we could be doing, flow of water, flow of oil. 

Other examples, this could be a structure. 

Like the -- a design  for a bridge or a design for a Buckminster Fuller dome. Or many 
other possib ilities, so many. So l- but let's take potentials and currents as, as a basic 
example, and let me create the matrix that tells you exactly what the graph tells 
you. So now I'll call it the  incidence matrix, incidence matrix. OK. So let me write it 
down, and you'll see, what its properties are. 

So every row corresponds to an edge. 

I have five rows from five edges, and let me write down aga in what this graph looks 
like. 

OK, the first edge, edge one, goes from node one to two. So I'm going to put  in a 
minus one and a plus one in th- this corresponds to node one two three and four, the 
four columns. The five rows correspond -- the first row corresponds to edge one. 
Edge one leaves node one and goes into node two, and that -- and it doesn't touch 
three and four. 

Edge two, edge two goes -- oh, I haven't numbered these edges. 

I just figured that was probably edge one, but I didn't say so. Let me take that to be 
edge one. Let me take this to be edge two. Let me take this to be edge three. This is 
edge four. Ho, I'm d iscovering -- no, wa it a minute. 

Did I number that tw ice? Here's edge four. And here's edge five. OK? All right. So, so 
edge one, as I said, goes from node one to two. 

Edge two goes from two to three, node two to three, so minus one and one in the 
second and third columns. 

Edge three goes from one to three. 

I'm, I'm tempted to stop for a moment with those three edges. 

Edges one two three, those form what would we, what do you call the, the little, the 
little, the subgraph formed by edges one, two, and three? That's a loop. And the 
number of loops and the position of the loops w ill be crucial. 

OK. Actua lly, here's a interesting point about loops. If I look at those rows, 
corresponding to edges one two three, and these guys made a loop. You want to tell 
me -- if I just looked at that much of the matrix  it would be natural for me to ask, 
are those rows independent? Are the rows  independent? And can you tell from 
looking at that if they are or are not independent? Do you see a, a relation between 
those three rows? Yes. 

If I add that row to that row, I get this row. 

So, so that's like a hint here that  loops correspond to dependent, linearly dependent 
column -- linearly dependent rows. OK, let me complete the  incidence matrix. 
Number four, edge four is going from node one to node four. 

And the fifth edge is going from node three to node four. 

OK. There's my matrix. 

It came from the five edges and the four nodes. 

And if I had a big graph, I'd have a b ig matrix. 

And what questions do I ask about matrices? Can I ask -- here's the review now. 

There's a matrix that comes from somewhere. 

If, if it was a b ig graph, it would be a large matrix, but a lot of zeros, right? Because 
every row only has two non-zeros. 

So the number of -- it's a very sparse matrix. 

The number of non-zeros is exactly two  times five, it's two m. Every row only has 
two non-zeros. And  that's with a lot of structure. And -- that was the point I wanted 
to beg in with, that graphs, that real graphs from rea l -- rea l matrices from genuine 
problems have structure. OK. 

We can ask, and because of the structure, we can answer, the, the main questions 
about matrices. 

So first question, what about the null space? So what I asking if I ask you for the null 
space of that matrix? I'm asking you  if I'm looking at the columns of the matrix, four 
columns, and I'm asking you, are those columns independent? If the columns are 
independent, then what's  in the null space? Only the zero vector, right? The null 
space contains -- tells us what comb inations of the columns -- it tells us how to 
combine columns to get zero. 

Can -- and is there anything in the null space of this matrix other than just the zero 
vector? In other words, are those four columns independent or dependent? OK. 
That's our question. 

Let me, I don't know if you see the answer. 

Whether there's -- so let's see. 

I guess we could do it properly. We could solve Ax=0. So let me solve Ax=0 to find 
the null space. OK. 

What's Ax? Can I put x in here in, in little letters? x1, x2, x3, x4,  that's -- it's got 
four columns. 

Ax now is that matrix times x. And what do I get for Ax? If the camera can keep that 
matrix multiplication there, I'll put the answer here. Ax equa l -- what's the first 
component of Ax? Can you take that first row, minus one one zero zero, and multip ly 
by the x, and of course you get x2-x1. The second row, I get x3-x2. From  the third 
row, I get x3-x1. From  the fourth row, I get x4-x1. And from the fifth row, I get x4-
x3. And I want to know when is the thing zero. This is my equation, Ax=0. Notice 
what that matrix A is doing, what we've created a matrix that computes the 
differences across every edge, the d ifferences in potentia l. 

Let me even beg in to give this interpretation. 

I'm going to think of this vector x, which is x1 x2 x3 x4, as the potentia ls at the 
nodes. So I'm introducing a word, potentia ls at the nodes. And now if I multiply by 
A, I get these -- I get these five components, x2-x1, et cetera. And what are they? 
They're potential differences. That's what A computes. 

If I have potentia ls at the nodes and  I multip ly by A, it gives me the potentia l 
differences, the differences in potentia l, across the edges. OK. 

When are those differences a ll zero? So I'm looking for the null space. 

Of course, if a ll the (x)s are zero then I get zero. 

That, that just tells me, of course, the zero vector is in the null space. But w- there's 
more in the null space. Those columns are -- of A are dependent, right -- because I 
can find solutions to that equation. Tell me -- the null space. 

Tell me one vector in the null space, so tell me an x, it's got four components, and  it 
makes that thing zero. 

So what's a good x to do that? One one one one, constant potentia l. If the potentia ls 
are constant, then all the potentia l d ifferences are zero, and that x is in the null 
space. 

What else is in the null space? If it -- yeah, let me ask you just a lways, g ive me a 
basis for the null space. A basis for the null space will be just that.1 That's --, that's 
it. 

That's a basis for the null space. 

The null space is actually one d imensional, and it's the line of a ll vectors through that 
one. So there's a basis for it, and here is the whole null space. 

Any multip le of one one one one, it's the whole line in four d imensiona l space. Do 
you see that that's the null space? So the, so the d imension of the null space of A is 
one. And there's a basis for it, and there's everything that's in it. 

Good. And what does that mean physica lly? I mean, what does that mean in the 
application? That guy  in the null space. 

It means that the potentia ls can only be determined up to a constant. Potential 
differences are what make current flow. That's what makes things happen. It's these 
potential differences that w ill make something move in the, in our network, between 
x2- between node two and node one. Nothing w ill move if a ll potentia ls are the 
same. If all potentials are c, c, c, and c, then nothing w ill move. So we're, we have 
this one parameter, this arbitrary constant that raises or drops a ll the potentials. 

It's like ranking footba ll teams, whatever. 

We have a, there's a, there's a constant -- or looking at temperatures, you know, 
there's a flow of heat from higher temperature to lower temperature. If temperatures 
are equa l there's no flow, and therefore we can measure -- we can measure 
temperatures by, Celsius or we can start at absolute zero. 

And that arbitrary -- it's the same arb itrary constant that, that was there in ca lculus. 
In ca lculus, right, when you took the integra l, the indefinite integral, there was a 
plus c, and you had to set a starting point to know what that c was. So here what 
often happens is we fix one of the potentia ls, like the last one. 

So a typ ica l thing would be to ground that node. 

To set its potentia l at zero. And if we do that, if we fix that potential so it's not 
unknown anymore, then that column d isappears and we have three columns, and 
those three columns are independent. 

So I'll leave the column in there, but we'll remember that ground ing a node is the 
way to get it out. 

And ground ing a node is the way to -- setting a node -- setting a potential to zero 
tells us the, the base for a ll potentials. Then we can compute the others. OK. But 
what's the -- now I've talked enough to ask what the rank of the matrix is? What's 
the rank then? The rank of the matrix. 

So we have a  five by four matrix. 

We've located its null space, one d imensional. 

How many independent columns do we have? What's the rank? It's three. 

And the first three columns, or actually any three columns, will be  independent. Any 
three potentials are independent, good variables. The fourth potential is not, we 
need to set, and typically we ground that node. OK. 

Rank is three. Rank equa ls three. 

OK. Let's see, do I want to ask you about the column space? The column space is a ll 
combinations of those columns. I could say more about it and I will. Let me go to the 
null space of A transpose, because the equation A transpose y equa ls zero is 
probably the most fundamental equation of applied mathematics. All right, let's talk 
about that. That deserves our attention. A transpose y equals zero. Let's -- let me 
put it on here. OK. So A transpose y equals zero. 

So now I'm find ing the null space of A transpose. 

Oh, and if I ask you its dimension, you could tell me what it is. What's the d imension 
of the null space of A transpose? We now know enough to answer that question. 
What's the general formula for the dimension of the null space of A transpose? A 
transpose, let me even write out A transpose. This A transpose will be n by m, right? 
n by m. 

In this case, it'll be four by five. 

Those columns will become rows. Minus one zero minus one minus one zero is now 
the first row. The second  row of the matrix, one minus one and three zeros. The 
third column now becomes the third row, zero one one zero minus one. And  the 
fourth column becomes the fourth row. 

OK, good. There's A transpose. 

That multip lies y, y1 y2 y3 y4 and y5. 

OK. Now you've had time to think about this question. What's the dimension of the 
null space, if I set all those -- wow. 

Usually -- sometime during this semester, I'll drop one of these erasers behind there. 
That's a great moment. 

There's no recovery. There's -- centuries of erasers are back there. OK. OK, what's 
the d imension of the null space? Give me the general formula first in terms of r and 
m and n. 

This is like crucial, you -- we struggled to, to decide what dimension meant, and then 
we figured out what it equaled  for an m by n matrix of rank r, and the answer was 
m-r, right? There are m=5 components, m=5 columns of A transpose. And  r of those 
columns are p ivot columns, because it'll have r pivots. 

It has rank r. And m-r are the free ones now  for A transpose, so that's five minus 
three, so that's two. And I would like to find this null space. I know  its d imension. 

Now I want to find out a basis for it. 

And I want to understand what this equation is. 

So let me say what A transpose y actually represents, why I'm interested in that 
equation. 

I'll put it down with those old erasers and continue this. 

Here's the great p icture of applied mathematics. 

So let me comp lete that. There's a matrix that I'll ca ll C that connects potential 
differences to currents. 

So I'll ca ll these -- these are currents on the edges, y1 y2 y3 y4 and y5. Those are 
currents on the edges. And this relation between current and potential difference is 
Ohm's Law. 

This here is Ohm's Law. Ohm's Law says that the current on an edge is some number 
times the potentia l drop. That's -- and that number is the conductance of the edge, 
one over the resistance. This is the old current  is, is, the relation of current, 
resistance, and change in potential. So it's a change in potential that makes some 
current happen, and it's Ohm's Law that says how much current happens. OK. 

And then the final step of this framework is the equation A transpose y equals zero. 
And that's -- what is that saying? It has a famous name. 

It's Kirchoff's Current Law, KCL, Kirchoff's Current Law, A transpose y equals zero. 
So that when I'm solving, and when I go back up with this b lackboard and solve A 
transpose y equa ls zero, it's this pattern of -- that I want you to see. That we had 
rectangular matrices, but -- and real applications, but in those rea l app lications 
comes A and A transpose. 

So our four subspaces are exactly the right things to know about. All right. 

Let's know about that null space of A transpose. 

Wait a minute, where'd it go? There it is. OK. 

OK. Null space of A transpose. 

We know what its d imension should be. 

Let's find out -- tell me a vector in it. 

Tell me -- now, so what I asking you? I'm asking you for five currents that satisfy 
Kirchoff's Current Law. So we better understand what that law says. That, that law, 
A transpose y equa ls zero, what does that say, say in the first row of A transpose? 
That says -- the so the first row of A transpose says minus y1 minus y3 minus y4 is 
zero. Where d id that equation come from? Let me -- I'll redraw the graph. Can I 
redraw  the graph here, so that we -- maybe here, so that we see again -- there was 
node one, node two, node three, node four was off here. That was, that was our 
graph. 

We had currents on those. We had a current y1 going there. We had a current y --
what were the other, what are those edge numbers? y4 here and y3 here. And then 
a y2 and a y5. 

I'm, I'm just copying what was on the other board so it's ea- convenient to see it. 
What is this equation telling me, this first equation of Kirchoff's Current Law? What 
does that mean for that graph? Well, I see y1, y3, and y4 as the currents leaving 
node one. So sure enough, the first equation refers to node one, and what does it 
say? It says that the net flow is zero. 

That, that equation A transpose y, Kirchoff's Current Law,  is a balance equation, a 
conservation law. 

Physicists, be overjoyed, right, by this stuff. 

It, it says that in equa ls out. And in this case, the three arrows are all going out, so 
it says y1, y3, and y4 add to zero. Let's take the next one. 

The second  row is y1-y2, and that's a ll that's in that row. And that must have 
something to do with node two. And sure enough, it says y1=y2, current in equals 
current out. The third one, y2 plus y3 minus y5 equa ls zero. That certa inly will be 
what's up at the third node. y2 coming in, y3 coming in, y5 going out has to balance. 

And finally, y4 plus y5 equals zero says that at this node, y4 p lus y5, the total flow, 
is zero. We don't -- you know, charge doesn't accumulate at the nodes. 

It travels around. OK. 

Now g ive me -- I come back now to the linear algebra question. 

What's a vector y that solves these equations? Can I figure out what the null space is 
for this matrix, A transpose, by looking at the graph? I'm happy if I don't have to do 
elimination. I can do elimination, we know how to do, we know how to find the null 
space basis. 

We can do elimination on this matrix, and we'll get it into a good reduced row 
echelon form, and the specia l solutions w ill pop  right out. But I would like to -- even 
to do it without that. Let me just ask you first, if I did elimination on that, on that, 
matrix, what would the last row become? What would the last row -- if I do 
elimination on that matrix, the last row of R w ill be a ll zeros, right? Why? Because 
the rank is three. We only going to have three p ivots. And the fourth row w ill be all 
zeros when we eliminate. So elimination will tell us what, what we spotted earlier, 
what's the null space -- a ll the, a ll the information, what are the dependencies. We'll 
find those by elimination, but here in a  rea l example, we can find them by thinking. 

OK. Again, my question is, what is a solution y? How could current travel around this 
network w ithout collecting any charge at the nodes? Tell me a y. OK. 

So a basis for the null space of A transpose. 

How many vectors I looking for? Two. 

It's a two dimensiona l space. My basis should have two vectors in it. Give me one. 

One set of currents. Suppose, let me start  it. 

Let me start w ith y1 as one. OK. 

So one unit of -- one amp travels on edge one w ith the arrow. OK, then what? What 
is y2? It's one also, right? And of course what you d id was solve Kirchoff's Current 
Law quickly in the second equation. 

OK. Now we've got one amp leaving node one, coming around to node three. 

What shall we do now? Well, what sha ll I take for y3 in other words? Oh, I've got a 
choice, but why not make it what you sa id, negative one. 

So I have just sent current, one amp, around that loop. 

What shall y4 and y5 be in this case? We could take them to be zero. This satisfies 
Kirchoff's Current Law. We could check it patiently, that minus y1 minus y3 g ives 
zero. 

We know y1 is y2. The others, y4 plus y5 is certainly zero. Any current around a loop 
satisfies -- satisfies the Current Law. OK. Now you know how to get another one. 
Take current around  this loop. So now let y3 be one, y5 be one, and y4 be minus 
one. 

And so, so we have the first basis vector sent current around that  loop, the second 
basis vector sends current around that  loop. And I've -- and those are independent, 
and I've got two solutions -- two vectors  in the null space of A transpose, two 
solutions to Kirchoff's Current Law. 

Of course you would say what about send ing current around the big loop. What 
about that vector? One for y1, one for y2, nothing f- on y3, one for y5, and minus 
one for y4. What about that? Is that, is that in the null space of A transpose? Sure. 

So why don't we now have a  third vector in the basis? Because it's not independent, 
right? It's not independent. This vector is the sum of those two. If I send current 
around that and around that -- then on this edge y3 it's going to cancel out and  I'll 
have altogether current around the whole, the outside loop. That's what this one is, 
but it's a combination of those two. 

Do you see that I've now, I've identified the null space of A transpose -- but more 
than that, we've solved Kirchoff's Current Law. 

And understood it in terms of the network. 

OK. So that's the null space of A transpose. I guess I -- there's a lways one more 
space to ask you about. Let's see, I guess I need the row space of A, the column 
space of A transpose. So what's N, what's its dimension? Yup? What's the dimension 
of the row space of A? If I look at the original A, it had five rows. 

How many were independent? Oh, I guess I'm asking you the rank aga in, right? And 
the answer is three, right? Three independent rows. When I transpose it, there's 
three independent columns. Are those columns independent, those three? The first 
three columns, are they the p ivot columns of the matrix? No. Those three columns 
are not independent. There's a in  fact, this tells me a relation between them. There's 
a vector in the null space that says the first column plus the second column equals 
the third column. 

They're not independent because they come from a loop. So the p ivot columns, the 
pivot columns of this matrix w ill be the first, the second, not the third, but the 
fourth. One, columns one, two, and four are OK. Where are they -- those are the 
columns of A transpose, those correspond to edges. 

So there's edge one, there's edge two, and there's edge four. So there's a -- that's 
like -- is a, sma ller graph. 

If I just look at the part of the graph that I've, that I've, thick -- used with thick 
edges, it has the same four nodes. It only has three edges. 

And the, those edges correspond to the independent guys. And in the graph there --
those three edges have no loop, right? The independent ones are the ones that don't 
have a loop. All the -- dependencies came from  loops. They were the things in the 
null space of A transpose. If I take three pivot columns, there are no dependencies 
among them, and they form a graph without a loop, and I just want to ask you 
what's the name for a graph without a loop? So a graph w ithout a  loop is -- has got 
not very many edges, right? I've got four nodes and it only has three edges, and if I 
put another edge in, I would have a loop. So it's this graph with no loops, and it's 
the one where the rows of A are independent. 

And what's a graph called that has no loops? It's ca lled a tree. So a tree is the name 
for a graph with no loops. And just to take one last step here. Using our formula for 
dimension. Using our formula  for d imension, let's look -- once at this formula. 

The d imension of the null space of A transpose is m-r. 

OK. This is the number of loops, number of independent loops. m is the number of 
edges. 

And what is r? What is r for our -- we'll have to remember way back. The rank came 
-- from looking at the columns of our matrix. So what's the rank? Let's just 
remember. Rank was -- you remember there was one -- we had a one d imensiona l -
- rank was n minus one, that's what I'm strugg ling to say. Because there were n 
columns coming  from the n nodes, so it's minus, the number of nodes minus one, 
because of that C, that one one one one vector in the null space. 

The columns were not independent. 

There was one dependency, so we needed n minus one. 

This is a great formula. This is like the first sha ll I, -- write it slightly d ifferently? The 
number of edges -- let me put things -- have I got it right? Number of edges is m, 
the number -- r- is m-r, OK. So, so I'm getting -- let me put the number of nodes on 
the other side. So I -- the number of nodes -- I'll move that to the other side --
minus the number of edges p lus the number of loops is -- I have minus, minus one is 
one. 

The number of nodes minus the number of edges p lus the number of loops is one. 
These are like zero dimensional guys. They're the points on the graph. The edges are 
like one dimensional things,  they're, they connect nodes. The loops are like two 
dimensional things. They have, like, an area. And this count works for every graph. 

And it's known as Euler's Formula. 

We see Euler again, that guy never stopped. 

OK. And can we just check -- so what I saying? I'm saying that linear algebra proves 
Euler's Formula. Euler's Formula is this great topology fact about any graph. I'll 
draw, let me draw another graph, let me draw a graph w ith more edges and loops. 
Let me put in lots of -- OK. I just drew a graph there. 

So what are the, what are the quantities in that formula? How many nodes have I 
got? Looks like five. How many edges have I got? One two three four five six seven. 

How many loops have I got? One two three. 

And Euler's right, I always get one. 

That, this formula, is extremely useful in understanding the relation of these 
quantities -- the number of nodes, the number of edges, and the number of loops. 
OK. 

Just complete this lecture by completing this picture, this cycle. So let me come to 
the -- so this expresses the equations of app lied math. This, let me call these 
potential differences, say, E. So E is A x. 

That's the equation for this step. 

The currents come from the potential differences. y is C E. The potential -- the 
currents satisfy Kirchoff's Current Law. Those are the equations of -- with no source 
terms. Those are the equations of electrical circuits of many -- those are like the, the 
most basic three equations. Applied math comes in this structure. The only thing I 
haven't got yet in the picture  is an outside source to make something happen. 

I could add a current source here, I could, I could add external currents going in and 
out of nodes. 

I could add batteries in the edges. 

Those are two ways. If I add batteries in the edges, they, they come into here. 

Let me add current sources. If I add current sources, those come in here. So there's 
a, there's where current sources go, because the F is a like a current coming  from 
outside. So we have our edges, we have our graph, and then I send one amp into 
this node and out of this node -- and that gives me, a  right-hand side in Kirchoff's 
Current Law. And can I -- to complete the lecture, I'm just going to put these three 
equations together. 

So I start with x, my unknown. 

I multip ly by A. That gives me the potential differences. That was our matrix A that 
the whole thing started with. I multip ly by C. 

Those are the physical constants in Ohm's Law. 

Now I have y. I multiply y by A transpose, and now I have F. So there is the whole 
thing. 

There's the basic equation of applied math. 

Coming from these three steps, in which the last step is this balance equation. 
There's always a ba lance equation to look for. These are the -- when I say the most 
basic equations of applied mathematics -- I should say, in equilibrium. 

Time  isn't in this problem. I'm not -- and Newton's Law isn't acting here. I'm, I'm 
looking at the -- equations when everything has settled down, how do the currents 
distribute in the network. 

And of course there are b ig codes to solve the -- this is the basic problem of 
numerical  linear algebra for systems of equations, because that's how they come. 
And my final question. What can you tell me about this matrix A transpose C A? Or 
even A transpose A? I'll just close w ith that question. 

What do you know about the matrix A transpose A? It  is always symmetric, right. 

OK, thank. So I'll see you Wednesday for a full review of these chapters, and Friday 
you get to  tell me. 

Thanks. 

MIT OpenCourseWare
http://ocw.mit.edu 

18.06 Linear Algebra
Spring 2010    
 
 
 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

