10.34, Numerical Methods Applied to Chemical Engineering 
Professor William H. Green 
Lecture #15: Differential Algebraic Equations (DAEs). Introduction: Optimization. 
Differential-Algebraic Equations (DAEs) 
(cid:5)
(cid:5)
txtx
xGx
xM
((
*)(
)(
),
(
))
0
=
ℑ
=
        If M is invertible, 

=(cid:5)
)(1
xGxMx
−
)(

. 

 

 

 

 

ode15i  

ode15s 

 

 

ordinary ODE 

Quasi-Steady-State Assumption (QSSA) 
* make stiff equation into algebraic 
⎯→⎯ 1k
OH + CO 
⎯→⎯ 2k
 OH + O 
⎯→⎯ 3k

 H + CO
2 

H + O2 

 2OH 

 

 

O + H2O 
 

O ≈ d[OH]/dt = k2[H][O2] – k1[OH][CO] + 2k3[O][H2O] 

d[H]/dt = k1[OH][CO] – k2[H][O2] 
O ≈ 

•  originally had 6 Differential equations 
•  now have 2 algebraic and 4 differential equations  
• 
takes you from ODE system to a DAE system 
QSSA is not always helpful because ODE is faster and more accurate to solve. Solving a 

D.A.E. is like solving a stiff equation. QSSA has not removed original stiffness. 

Another problem of DAE: 

Consistent Initial Conditions  
(cid:5)
(cid:5)
tx
tx
tx
tx
),
(
)
(
(
),
((
0
))
ℑ
=
 
0
0
0
0
You need both x and  x(cid:5) .  If  x(cid:5)  is not provided, you have to use Newton’s Method. 

0=

High index DAEs 
0=ℑ
DAE 
   
Eventually you will have a normal ODE if you take enough derivatives.   
d
ℑ
dt
d
2
dt
these equations if the index is too high. 

differentiation. MATLAB stiff solvers or D. A. E. solvers cannot solve 

High-index refers to system that requires a high degree of  

ODE 

ℑ
2

=

0

 

 

 
d
ℑ
dt

=

∑

∂ℑ
x
∂

n

dx
n
dt

+

∑

∂ℑ
(cid:5)
x
∂

n

(cid:5)
xd
n
dt

0=

 

Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

v

n

∑

≡

(cid:5)
x

n
∂ℑ
x
∂

n

vx
),(
ℑ

=

0

 

v

n

+

∑

∂ℑ
(cid:5)
x
∂

n

(cid:5)
v

n

=

0

vxM
),(

M

in

=

 

i

∂ℑ
v
∂

n

−

−

2

n

i

n

−

v

n

v

n

v

n

⎛
⎜⎜
⎝

(cid:5)
v
(cid:5)
x

⎛
⎜
⎜⎜
⎝

⎞
⎛
⎟⎟
⎜⎜
⎝
⎠

∑
n

⎞
=⎟⎟
⎠

∂ℑ
x
∂
v

∑
n
∑
n

OM
IO

Identity Matrix = I                    2n entries 
∂ℑ
1
x
∂
n
∂ℑ
x
∂
(cid:35)
v
1
v
v

⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
Eventually, matrix M becomes invertible 
x(cid:5)
-1(x)G(x)  ODE 
 = M
Professor Barton is an expert in the field. 

If M is invertible: 

⎞
⎟
⎟⎟
⎠

=

2

3

 

⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠

Predictor Corrector Method 
x(tk-2), x(tk-1), x(tk)  ∆t  x(tk+1)        Extrapolate (cid:198) “Predictor” = initial guess for implicit solve 
x
x
(
,
)
0
=
ℑ

polynomial fit  

“Corrector”: 

 

 

 

 

k

1
+

k

1
+

This method was developed by Bill Gear “Gear Predictor-Corrector”. 

“BDF polynomials” (Backward Differential Formula)(cid:198) guarantees numerical stability 

 

Predictor is simple to find through extrapolation 

Corrector is difficult and complicated 

DASSL  
DASPK     Linda Petzold                  Another similar to DASSL is DASAC 
                                  (Univ. California, Santa Cruz) 
Make ∆t small in first few steps to minimize error 
 
 

Another package is DASAC at the Univ. of Wisconsin, Madison. For linear equations, use 

MATLAB. Use small Δt on first step, because initial guess is low in information and equations 

take a long time to solve. 

 

10.34, Numerical Methods Applied to Chemical Engineering 
Prof. William Green 
 
 
Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

Lecture 15 
Page 2 of 4 

Optimization 
( )xf
min
 with constraints 
x

( ) 0=xg

 and 

( ) 0≥xh

. 

What derivatives of f(x) can I compute easily? 
1)  None (cid:198) simplex algorithms (cid:198) fminsearch 
2)  Gradient  ∇ f 
a.  Newton-type solvers 
b.  Conjugate-gradient type solvers 

Newton-type 
f(x+p) = f(x) +  ∇ f|x·p + ½pTH·p + O(|p|3) 
f
∂
x
∂
1
f
∂
x
∂
f
∂
x
∂
(cid:35)

⎛
⎞
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎝
⎠
f(x+p) = f(x) +  ∇ f|x·p + ½pTB·p 
 

f
2
∂
x
2
∂
1
f
2
∂
xx
∂∂
1
2

f
2
∂
xx
∂∂
1
f
2
∂
x
2
∂
2

⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝

f
=∇

H

=

2

3

2

3

f
2
∂
xx
∂∂
1
f
2
∂
xx
∂∂
2

(cid:34)

(cid:34)

⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
approximate Hessian; maybe use I 

 

3

1)  What direction is the next step?  downhill 
2)  How far should I step?     
f(xk+1) < f(xk) 
 

 

 

 

 

 

 

 

 

 

 

 

 
10.34, Numerical Methods Applied to Chemical Engineering 
Prof. William Green 
 
 
Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

Lecture 15 
Page 3 of 4 

 

Contour Map 

local maximum 

x 

x 

global minimum 

first step downhill 

xguess (initial guess) 

Figure 1. A contour map. 
 
Choice #1:  downhill 

p

=

c

 

−

⎛
⎜
⎜
⎝

∇
∇

f
f

⎞
⎟
⎟
⎠

 

optimal ‘c’, if f(x+p) = f(x) +  ∇ f|x·p + ½pTB·p is true: Cauchy point 

 

 
Choice #2:  assume 2nd order expansion is exact 
•  Newton step 
o  dangerous when you are far from the solution 

 

Go downhill first to get closer and then apply Newton’s Step. 

10.34, Numerical Methods Applied to Chemical Engineering 
Prof. William Green 
 
 
Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

Lecture 15 
Page 4 of 4 

