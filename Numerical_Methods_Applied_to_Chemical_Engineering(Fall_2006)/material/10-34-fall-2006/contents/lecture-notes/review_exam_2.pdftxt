Quiz-2 Review


November  13,  2006 

•  Singular  Value  Decomposition:  SVD 
Any  rectangular m × n matrix A  can  be  decomposed  into  a  product  of 
√
3  matrices  as  shown  in  Equation  1,  where  Σm×n  is  a  diagonal  matrix 
containing  singular values σi  of matrix A  such  that σi  = 
λi , where λi 
are  the  eigenvalues  of matrix AAT .  U  and V  are  orthonormal matrices 
i.e.  V T  = V −1 , U T  = U −1 .  The  columns of U and V are  called  left  sin­
gular  and  right  singular  vectors  of  A  respectively.  This  decomposition 
is  called  Singular  Value  Decomposition  (SVD)  of matrix  A. 

(1) 

T ×n 
Am×n  = Um×mΣm×nVn
.  In matlab SVD of any matrix A can be performed using the command 
svd. 
The  condition  number  of  matrix  is  deﬁned  as  cond(A) =  σmax/σmin . 
SVD  can be used  to decouple a noisy  signal  into useful  component and 
noise.  Another  useful  application  of  SVD  is  in  the  solution  of  linear 
· 
system  of  equations.  The  solution  of  a  system  of  equation  A x =  b  is
given  in  Equation  2,  where  we  replace  1  with  0  if  σi  ≈ 0.  If  there  are 
σi 
more  equations  than  unknowns  then  the  equation  gives  a  least  squares 
⎛ 
⎞
solution  of  the  overdetermined  set  of  linear  equations. 
⎟⎟⎟⎟⎟⎠ 
⎜⎜⎜⎜⎜⎝ 
· · · 
· · · 
· · · 
· · · 

·
 U T  ·
 b 

x = V
 ·


(2)


0
0

1 
σ1 
0 
.
. . 
0

0 
1 
σ2 

0 

0
0

0

· · ·  σn 
1 

· · · 

Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 
1


•	 Ordinary  Diﬀerential  Equations:  ODE  and  Diﬀerential  Al­
gebraic  Equations:  DAE 
The  general  form  of  ODE  is  given  in  Equation  3,  where  X  is  a  vector 
of  length  n  and  F  is  a  set  of  n  functions. 

dX 
dt 

= F  (X )	

(3) 

If  we  have  an  nth  order  ordinary  diﬀerential  equation,  it  can  be  con­
verted  into  n  ordinary  diﬀerential  equations.  To  do  that  we  deﬁne 
n − 1  new  variables  yi ’s,  where  each  yi  =  di y  To  solve  a  set  of  ODEs 
dti  . 
we  require  the  boundary  conditions  to  be  speciﬁed  at  t = t0 .  If  all  the 
Boundary  conditions  are  not  speciﬁed  at  at  the  same  boundary  then 
we  can  either  use  shooting  method  or  solve  the  system  as  a  boundary 
value  problem. 
The  solution  of  Equation  3  can  be  obtained  by  performing  numerical 
integration  as  shown  in  Equation  4. 
� 
X (t) = X (t0 ) + 
t0 
If  we  are  given  the  value  of  function  F  (X (t� ))  at  discrete  points  t1 , 
t2 ...t3 ,  we  can  use  Trapezoid  rule  or  Simpson’s  rule  to  integrate  the 
function.  The  local  errors  (error  incurred  per  step)  of  Trapezoid  rule 
and  Simpson’s  rule  are  O(Δt3 )  and  O(Δt5 )  respectively.  We  can  in­
crease the accuracy of the integration by using a more accurate method 
or  decreasing  Δt.  Using  too  small  of  a  time  step  leads  to  rounding  oﬀ 
errors.  To  overcome  this  problem  the  concept  of  Richardson  Extrapo­
lation  is  used.  When  applied  to  trapezoid  rule we  get  the  result  shown 
in  Equation  5.  Notice  that  the  error  properties  of  the  result  are  the 
same  as  that  of  Simpson’s  rule. 

F  (X (t� )) dt�	

t 

(4) 

4
X true (tf ) =  X (tf , 
3 

1 
Δt 
) −  X (tf , Δt) + O(Δt4 ) 
3 
2

(5) 

ODEs  can be  solved using  explicit methods.  Euler’s  explicit method  is 
the simplest explicit method but is inaccurate and unstable.  More accu­
rate  methods  include  Runge-Kutta  methods  of  variable  orders.  These 
methods  require  more  number  of  functional  evaluations  per  step  but 
also have higher  order  accuracy.  Adaptive  time  stepping  can be  imple­
mented by using the Runge-Kutta methods.  For example Runge-Kutta 

Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 
2 

method  of  ﬁfth  order  require  six  function  evaluations  and  the  same  six 
function  evaluations  can  be  used  to  get  a  fourth  order  method.  The 
step  size  is  varied  until  the  diﬀerence  between  the  ﬁfth  and  fourth  or­
der Runge-Kutta methods  are  obtained  to within  some desired  level  of 
accuracy. 
The explicit methods don’t perform well when the system of diﬀerential 
equations is stiﬀ.  A system is said to be stiﬀ when there are two or more 
very  diﬀerent  time  scales  involved  in  the  problem.  Chemical  kinetics 
problems  are  very  often  stiﬀ.  The  diﬀerential  equation  has  to  take 
time  steps  which  correspond  to  the  fastest  time  scale  (small  Δt)  but 
the  total  time  that  it  has  to  integrate  to  is  very  large  because  of  the 
presence  of  the  slow  time  scale.  Thus  the  total  number  of  time  steps 
that  the method has  to  take  is high.  If an explicit method  tries  to  take 
time  steps  larger  than  the  one  corresponding  to  the  fastest  time  scale 
then  it  becomes  unstable.  For  example  for  a  set  of  linear  diﬀerential 
equations  given  in  Equation  6,  the  time  step  of  explicit  euler  method 
Δt <  2/λmax ,  where  λmax  is  the  largest  eigenvalue  (fastest  time  scale) 
of  matrix  C.  On  the  other  hand  the  implicit  euler  method  is  always 
stable  for  this  system. 
X �  = −C X 
· 

(6) 

Higher order implicit method generally implement multi-step predictor-
corrector  type  methods.  In  these  methods  we  use  the  solutions  at 
previous  k  steps  (X n ,  X n−1 ,  ...,  X n−k+1 )  to  estimate  a  solution  at  the 
n+1th  step.  This  initial  guess  is  used  to  calculate  an  exact  value  of 
X n+1  using  a  newton’s  type  iterative  method.  Polynomials  relating 
X n+1  to  the  previous  values  of  X  and  their  derivatives  developed  by 
Gear  ensure  stability  for  even  stiﬀ  diﬀerential  equations. 
Diﬀerential  Algebraic  equations  are  of  the  general  form 

M (X )X˙ = F (X ) 

where  M (X )  is  called  the  mass  matrix  and  is  singular.  A  important 
concept  related  to  DAE  is  its  index  number,  which  is  deﬁned  as  the 
number  of  diﬀerentiations  that  is  required  to  convert  it  into  an  ODE. 
Index-1 diﬀerential  equations  can be  solved using  techniques  similar  to 
� 
� 
the  ones  developed  for  ODEs.  ode23s  and  ode23t  can  solve  problems 
with  constant  singular  mass  matrices. 
ode15i  solves  DAEs  which  are 
fully  implicit  F  X , X˙ , t  = 0. 

Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 
3 

•  Numerical  Optimizations 
Optmization  problems  can  in  general  be  posed  as  follows 

min f (x) 
x 
hi (x) ≥ 0 
gi (x) = 0 

s.t. 
· · · 
i = 1 
ni
· · · 
i = 1 
ne 

(7) 

(8)


�f
 =


If the inequality and equality constraints are not present then the prob­
lem  is  called  unconstrained  optimization  problem.  If  gradient  of  the 
method  is  not  provided  then  the  problem  can  be  solved  using  simplex 
method.  This  method  is  usually  much  slower  than  the  gradient  meth­
ods but for some problems is very robust.  Matlab function fminsearch 
implements this algorithm.  The gradient of the cost fuction is deﬁned in 
⎞∂ f 
⎛
Equation 8 and  the negative of  the gradient  is  the direction of  steepest 
⎟⎟⎟⎟⎟⎠
⎜⎜⎜⎜⎜⎝ 
descent.

∂x1 
∂ f 
∂x2 . . . 
∂ f 
∂xn 
method  of  steepest  descent  makes  use  of  this  fact  and  moves  sequqn­
tially  in  the  direction  of  the  negative  of  the  gradient.  The  size  of  the 
step  depends  on  exact  implementation  of  the  algorithm.  The  steepest 
descent  method  makes  fast  progress  initially  but  convergence  of  the 
method  is  slow  when  it  reaches  the  bottom  of  the  valley.  In  conjugate 
gradient  method  the  step  direction  is  not  exactly  the  negative  of  the 
gradient  but  also  has  some  element  from  previous  search  directions. 
This prevents  the  zig-zag  tra jectory which  is  a problem  in  the  steepest 
descent method. 
Newtons method uses of the Hessian matrix which is provided in Equa­
tion  9. 
⎞ 
⎛
⎜⎜⎜⎜⎜⎜⎝ 
⎟⎟⎟⎟⎟⎟⎠ 
∂ 2 f
∂x2
1 
∂ 2 f
∂x2 ∂x1 
. . . 
∂ 2 f
∂ 2 f
∂xn ∂x2 
∂xn ∂x1 
The  newton  step  can  be  written  as 
x k+1  − x k  = Δx k  = −H −1 (x k ) · �f (x k ) 

∂ 2 f
∂x1 ∂x2 
∂ 2 f
∂x2
2 

∂ 2 f 
∂x1 ∂xn 
∂ 2 f 
∂x2 ∂xn 

· · · 
· · · 

· · · 

∂ 2 f 
∂x2 
n 

H
 =


(9)


Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 

4 

The  calculation  of  Hessian  matrix  is  usually  costly  and  in  its  place  a 
approximate  Hessian  is  used.  A  commonly  used  approximation  to  the 
Hessian matrix  is  BFGS  (Broyden-Fletcher-Goldfarb-Shanno)  update. 
Method of Lagrangian multipliers is used for constrained minimizations 
with  equality  constraints.  The  lagrangian  function  L  is  deﬁned  as 
� 
ne
L(x, λ) = f (x) − 
λigi (x) 
� 
i 
At  the  constrained  minimum  the  condition  �f  −  λi�gi  = �xL = 0 
and  g(x) =  �λL  =  0  is  satisﬁed.  Thus  the  problem  of  constrained 
minimization  involves  minimizing  the  lagrangian  with  respect  to  both 
x  and  λ.  Augmented  lagrange  methods  add  a  quadratic  penalty  for 
straying away from the equality constraints.  The augmented lagrangian 
� 
� 
is  deﬁned  as 
ne� 
1 
L(x, λ, µ) = f (x) − 
λigi (x) − 
[gi (x)]2 
2µi 
i 

When  inequality  constraints  are  present  then  we  can  deﬁne  a  new  la­
grangian  which  includes  these  inequality  constraints.  This  lagrangian 
should satisfy the Karush-Kuhn-Tucker (KKT) conditions given in Equa­
tion 10.  These conditions imply that, for active constraints h(xmin ) = 0 
and  for  inactive  constraints  κj  = 0. 
� 
� 
ni
ne
L(x, λ, κ) = f (x) − 
λigi (x) − 
κihi (x) 
i=1 
i=1 

�L(xmin ) = 0 
gi (xmin ) = 0 
hj (xmin ) ≥ 0 
κj  ≥ 0 
κj hj (xmin ) = 0 

(10) 

In Sequential Quadratic Programming we use the concept of slack vari­
ables.  Each  equality  and  inequality  constraint  is  brough  to  a  common 
ground  by  adding  a  slack  variable  to  them. 

Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 
5 

•  Boundary  Value  Problem 
Very  often  we  need  to  solve  a  conservation  equation  for  some  scalar 
quantity (φ) at steady state.  The conservation equation takes the  form 
�  ��  � 
�  ��  � 
� �� � 
c�
− �.(φv) + 
2φ  +
 S (φ)  = 0 
dif f usion 
convection 
generation 
� 
� 
For  cartesian  coordinates  the  above  equation  becomes 
∂ 2φ 
∂ 2φ 
= Di  ∂x2  + 
∂ z 2  + S (φ) 

∂φ 
+ vy ∂ y 

∂φ 
+ vz ∂ z 

∂ 2φ 
∂ y 2  + 

∂φ 
vx ∂x 

∂φ

∂x


(11) 
� 
If  the  velocity  ﬁeld  is  known  at  each  point,  then  this  problem  can  be 
solved  using  a  basis  function  expansion  i.e.  representing  φ  = 
ciψi 
and  then  calculating  the  values  of  ci  that  satisfy  the  above  equation. 
The  ci  are  usually  cleverly  chosen  so  that  they  satisfy  the  boundary 
conditions.  The other approach  is the ﬁnite diﬀerence approach  for the 
solution  of  the  above  equation  which  involves  dividing  the  3-D  space 
of  (x, y , z )  into  discrete  coordinates  (xi , yj , zk )  and  trying  to  calculate 
the  value  of  φ(xi , yj , zk )  at  each  of  those  points.  The  discrete  form  of 
the  partial  diﬀerential  equation  can  be  written  by  using  the  following 
����� 
approximations 
φ(xi , yj , zk ) − φ(xi−1 , yj , zk ) 
Δx
(xi ,yj ,zk ) 
φ(xi−1 , yj , zk ) − 2φ(xi , yj , zk ) + φ(xi+1 , yj , zk ) 
= 
Δx2 

����� 
∂ 2φ 
∂x2 
(xi ,yj ,zk ) 
Similar  approximations  can  be  used  to  for  y  and  z  directions.  Notice 
the ﬁrt order partial derivative is approximated using upwind diﬀerence 
formulation  which  in  many  cases  is  known  to  give  stable  results.  Let 
us assume we divide x, y  and z  directions  in  l, m and n discrete points. 
The  number  of  unknowns  in  this  sytem  will  be  l  × m × n,  but  the 
discretized  form  of  Equation  11  will  provide  us  with  only  (l  −  2) ×
(m − 2) × (n − 2)  set  of  equations.  The  rest  of  the  equations  will  be 
provided  by  the  boundary  conditions  of  the  problem.  The  commonly 
found  boundary  conditions  will  be  of  two  kinds,  namely  Dirichlet  and 
Neumann.  Dirclet  boundary  conditions  are  of  the  form 
φ(x, y , z )|B .C.  = φB .C 

= 

Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 

6 

= 

and directly give the remaining equations to solve the system uniquely. 
In  Neumann  boundary  conditions  the  derivatives  at  the  boundary  are 
given.  When we discretize the derivative at the boundary condition we 
����� 
get  the  following  equation 
−3φ(x1 , y , z ) + 4φ(x2 , y , z ) − φ(x3 , y , z ) 
dφ 
2Δx 
dx  x=x1 
The  system  of  equation  that  results  can  be  solved  using  any  of  the 
non-linear  equation  solvers.  If  the  generation  term  is  linear  then  the 
system of equations becomes linear and can be solved exactly using the 
\  command. 
Method  of  lines  is  a  convenient  method  for  solving  these  equations 
when  we  know  that  there  is  stiﬀness  present  in  one  direction,  say  the 
x  direction.  Then  the  equation  can  be  discretized  in  the  remaining 
directions  and  in  the  x  direction  it  is  solved  using  a  stiﬀ  ODE  solver 
like  ode23s  or  even  ode45  which  is  capable  of  doing  adaptive  time 
stepping.  The  only problem with method  of  lines  is  that  the boundary 
conditions  have  to  be  known  at  the  x  =  x1 ,  if  this  is  not  true  then  a 
shooting method  is  used  in  the  x  direction. 

Cite as: Sandeep Sharma, course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 2006. MIT 
OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD Month YYYY]. 
7


