10.34, Numerical Methods Applied to Chemical Engineering 
Professor William H. Green 
Lecture #22: Introduction: Models vs. Data. 

Models vs. Data 
Engineers think of practical problems and efficient solutions from the top-down. 

Scientists use a micro-view and can neglect the big picture in the bottom-up analysis. 

 

Models are always wrong. 

But experiments also never match. 

 

more important 

p(k)

diffusion 
limit 

prior information 
about θ 

Figure 1. Normal 
distribution. 
seldom have sampling capable of making   

true distribution curve 

 

 
 
 
Ymodel(x(±δx), θ±δθ) 
 
all other           we generally 
                       “knobs” 
parameters       know bounds  
       parameters 
 
 
in model we can  
that affect         on θ 
 
results 
physically adjust 
 
          
 
 
 
(cannot control) 
 
 
 
 
 
 
Ydata
Ydata
 

 
(Ydata(x))
 

(1)(x) 
(2)(x) 

P

 

 

 

 

 

 

 

 

 

 

 

 

 

Ydata

Figure 2. Example of sampling.

Average Value 
<Ydata>Nexpts 

 

 
 
P(<Y>Nexpts) 

σexp.data|Nexpts 

 

 

 

 

 

 

 

P

(<Ydata>,σdata)≈ 
(
⎡
Y
<−
⎢
⎢
⎣

1
2
πσ

exp

>

true

2

)

Y

<−>
2
2
σ
mean

⎤
⎥
⎥
⎦

 

<Y>Nexpts

σ
mean

≈

σ
data

N

exp

ts

Figure 3. Normal distribution curve 
showing 1 standard deviation.

 
Why do we compare the model to data? 
• 
Is The Model Consistent With The Data? 
|<Ydata> - Ymodel |>> σmean  means Inconsistent (akin to confidence interval: 
t
CI
σνα ⋅
≅ ,
mean

) 

Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 
2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD 
 
Month YYYY].

•  Model Discrimination 
Often more than 1 model: If they are consistent, would like to be able to pick one closer 

to the data or say that either model works fine. 
•  Parameter Refinement 
How narrow can you make the range on θ? 
•  Experimental Design 
Identify which {θi} are not determined by data. A few θi often control the fit. Some θi 
cannot be determined well by experiment (poorly conditioned matrices). 

Introduction to Chi-Squared Analysis 
Assume all error is Gaussian. 

<

Y

n

>

(

x

)

n

Y
−
2
σ
n

2

(

x

n

,
)
θ

mod

el

N
action
2 ∑
≡
χ
i

 

DS
exp.
.~σ
  
mean

 

N

exp

ts

~

N

data

 for the “true” model 

parameter refinement:  χ2(θ) (cid:197) minimize χ2 by changing θ
experimental design: derivatives of χ2 with respect to θ. 

Bayesian View 
Prior knowledge  p(θ, σ) (cid:198) posterior  p(θ, σ; Ydata) 
More knowledge after experiment. Use to narrow error bars. 

Conditional Probability 
EP
EEPEP
E
(
)
|
(
)
(
)
=
∩
1
1
2
1

2

: probability of E2 knowing E1 happened (correlation) 

 

 

 

if independent: P(E2) 
 
 
 
model      prior 
Pposterior(θ,σ|Ydata) = P(Ydata|θ,σ)P(θ,σ) 

 

 

       ∫∫dθ dσ P(Y|θ,σ)P(θ,σ) ≈ P(Ydata) 
 
 
 
 
normalize 
P(Ydata|θ,σ): probability of observing Ydata we really observed if θ, σ are true values. 
We do not know θ and σ exactly. 

10.34, Numerical Methods Applied to Chemical Engineering 
Prof. William Green 
 
 
Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical Engineering, Fall 
2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of Technology. Downloaded on [DD 
Month YYYY]. 

Lecture 22 
Page 2 of 2 

