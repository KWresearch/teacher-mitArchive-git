10.34, Numerical Methods Applied to Chemical Engineering 
Professor William H. Green 
Lecture #17: Constrained Optimization. 

fxx 

 
Notation 
 “second derivative of f(x).”: We normally mean 
f
f
2
2
⎛
∂
∂
⎜
xx
x
2
∂∂
∂
⎜
1
1
⎜
f
f
2
2
∂
∂
⎜
xx
x
2
∂∂
∂
⎝
1
2
2
but second derivative can also mean: 
f
2
∂
x
2
∂
1

Hessian Matrix  

Laplacian 

Tr{H} = 

2
∂
x
∂

fxx  

f
2
2

H

+

=

2

⎞
⎟
⎟
⎟
⎟
⎠

 

(cid:86)2f in BEERS 

 - scalar 

(cid:86)2f in Physics Texts 

 

(cid:86)·((cid:86)f) 

Constrained Optimization 
Equality Constraints: minx f(x)  such that g(x) = 0 
May be able to invert this statement as: xN = G(x1, x2, …, xN-1) 
Then we can state min as: min f(x1, x2, …, xN-1,G(x1, x2, …, xN-1)) 
 
 
Notice the xN is gone. Constrained becomes unconstrained. Solve with previous methods. 
Other way to do this: 

0=

Unconstrained 

  at the minimum 

Lagrange Multipliers 
f
∂
mnxnx
∂
constrained problems do not work that way! 
o  BOUNDARIES GET IN THE WAY 
g
f
∂
∂
λ
x
x
∂
∂

Constrained: 

- 

=

 (cid:86)f|const. min = λ(cid:86)g|x const. min 

xn

const

.

min

xn

const

.

min

Gradient of f equals 0 in directions parallel to constraint but not perpendicular 

Create a new function L(x, λ) = f(x) – λg(x)  (λ is unknown before you do the problem) 
(cid:86)xL = 0    
 
∂L/∂λ = g(x)  (cid:198) 0 
Second derivatives not necessarily all positive 

at constrained min 

at constrained min 

Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

Augmented Lagrangian 
1
xg
((
2
(0)μ

LA = f(x) – λg(x) + 

2))

 

minx LA given initial guess λ[0], μ[0] (cid:198) xmin
[0]

[0]  - λ[0] (cid:86)g(xmin
[0], λ[0]) = (cid:86)f|xmin
[0]) - 
(cid:86)xLA(xmin

 

 

As μ[0] shrinks, 

1
(0)μ2

1
(0)μ

g(x)(cid:86)g(x) (cid:206) (cid:86)f – (λ[0] - 

)

minxg
(
]0[
(0)μ

)(cid:86)g(x) 

λ[1] 

 gets large, magnifying (g(x))2 term, and thus holding the constraint 

more strictly. minx LA using λ[1] get a new xmin. In quantum mechanics, λ corresponds to 
orbital energies. Most of the time, λ does not have a physical meaning. μ[0] is a 
mathematical trick. 

g1(x) = 0   make sure these are compatible 
g2(x) = 0 
i.e. there is a “feasible space” – set  
g3(x) = 0 

of x that satisfies all constraints 

More Than One Constraint 
Suppose you have >1 constraints:   

 

 

 

 

L = f(x) - 

 

 

 

 
λ∑
igi(x) 
i

 

 

 

 

(cid:86)L = 0 

(cid:86)f = 

λ∑
i

i(cid:86)gi

Inequality Constraints  
very common 

 

min f(x), s.t. g(x) = 0, h(x) ≥ 0 
Active inequality constraints: h(xmin) = 0 
Inactive inequality constraints: h(xmin) > 0 
Usually, we do not know whether h’s are active or inactive before doing a problem, but must 

 

leave in during optimization process, to allow finding of solution: 

 
(cid:86)f = Kj(cid:86)hj, K ≥ 0  when hj is active; also hj = 0 and kj ≥ 0. 
Kjhj(x const. min) = 0 when hj is inactive 
 
 

 

10.34, Numerical Methods Applied to Chemical Engineering 
Prof. William Green 
 
 
Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

Lecture 17 
Page 2 of 3 

if inactive, hj ≠ 0 and kj = 0. (cid:86)hj can be anything; it does not affect the problem 

 

 

 

 

 

Karash-Kahn-Tucker (KKT) conditions: 
L = f(x) - Σλigi(x) – Σkjhj(x) 
 
h(xmin) ≥ 0
(cid:86)L(xmin) = 0   
 
Kj ≥ 0   
g(xmin) = 0 
 
Kjhj = 0 
 
 
 
 
 
To handle active-inactive constraints, add slack variables: 
hj(x) ≥ 0 (cid:198) hj(x) – Sj = 0,  Sj ≥ 0 
Augmented Method LA:  
Optimal Sj = max{hj(x) – μ[k]Kj
[k]; 0} 
 
2+hj
2+(μ[0]kj)2) 
[k])2 + (1/2μ
 – Σμ[k](kj
 - Σkjhj
[0])(gi
LA = f(x) – Σλigi
F(x) = (cid:86)LA = 0   Use Newton’s Method with Broyden to approximate the Hessian matrix. 
Trying to solve: JLA *Δx = -(cid:86)LA  Use Newton’s method to find x 
Jacobian is messy: 
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝

L
2
∂
xx
∂∂
i
C
∂
x
∂

f
∇−
x
xCS
(
−

x
Δ
⎞
=⎟⎟
Δ
λ
⎠

⎞
⎟
⎟
⎛
⎟
⎜⎜
⎟
⎝
⎟
⎟
⎠

j
⎞
⎟
⎟
⎠

C
∂
x
∂

m

j

⎞
⎟
⎟
⎠

)

T

⎞
⎟
⎟
⎠

−

⎛
⎜
⎜
⎝

old
x
old

 

⎞
⎟
⎟
⎠

old

⎛
⎜
⎜
⎝

⎛
⎜
⎜
⎝

n

j

old

old

0

⎛
⎜
⎜
⎝

If we want to: minpf(p) = (1/2)pT

⎛
⎜
⎜
⎝

L
∂ 2
i xx
∂∂

j

⎞
⎟
⎟
⎠

oldx

p + (cid:86)f|xold·p

such that 

c
∂∑
m
x
∂

j

old

x

p

j

+

c

m

old

(

x

)

=

0

=∀
m

,...,1

N

  

constraint
s

- can easily get p  (same as Δx above) 

“quadratic program” 

Sequential Quadratic Programming (SQP) 
 
 
 
In MATLAB: fmincon 

10.34, Numerical Methods Applied to Chemical Engineering 
Prof. William Green 
 
 
Cite as: William Green, Jr., course materials for 10.34 Numerical Methods Applied to Chemical 
Engineering, Fall 2006. MIT OpenCourseWare (http://ocw.mit.edu), Massachusetts Institute of 
Technology. Downloaded on [DD Month YYYY]. 

Lecture 17 
Page 3 of 3 

