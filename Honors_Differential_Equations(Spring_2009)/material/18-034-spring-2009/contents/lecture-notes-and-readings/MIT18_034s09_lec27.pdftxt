MIT OpenCourseWare
http://ocw.mit.edu 

18.034 Honors Differential Equations 
Spring 2009 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

LECTURE  27.  COMPLEX  SOLUTIONS AND  THE  FUNDAMENTAL MATRIX 

Complex eigenvalues.  We continue studying 
�y �  = A�y , 
(27.1)	
where A = (aij ) is a constant n × n matrix.  In this subsection, further, A is a real matrix. When A 
has a complex eigenvalue, it yields a complex solution of (27.1). The following principle of equating 
real parts then allows us to construct real solutions of (27.1) from the complex solution. 
Lemma 27.1.  If �y(t) =  α� (t) + iβ� (t), where α� (t) and β� (t) are  real vector-valued  functions,  is a  complex 
solution of  (27.1), then both α� (t) and β� (t) are real solutions of  (27.1). 
The proof is nearly the same as that for the scalar equation, and it is omitted. 
Exercise.  If a real matrix A has an eigenvalue λ with an eigenvector �v , then show that A also has 
� 
� 
�	
� 
1  .  Recall  that pA (λ) =  ���1 −
��� has  two 
an eigenvalue λ ¯ with an eigenvector �v¯ . 
−
1
1
1 
λ 
Example 27.2.  We  continue  studying A  =  −
1 − 
�  � 
� 
�	
4 
4 
λ 
complex eigenvalues 1 ± 2i. 
−
If  λ  =  1 + 2i,  then  A −� 
λI  = � 
1 
2
1
i  −
−
2i  has  an  eigenvector  2
i  .  The  result  of  the  above 
4 
1
is an eigenvector of the eigenvalue λ = 1 − 2i. 
exercise then ensures that  −2i 
�  � 
� 
� 
� 
� 
In order to ﬁnd real solutions of (27.1), we write 
cos 2t  + iet 
1 = e t 
sin 2t
� 
� 
� 
� 
−2 sin 2t 
.
2 cos 2t 
2i 
cos 2t 
sin 2t
The  above  lemma  then  asserts  that  et  −2 sin 2t  and  et 
2 cos 2t  are  real  solutions  of  (27.1). 
� 
� 
� 
� 
Moreover, they are linearly independent. Therefore, the general real solution of (27.1) is 
cos 2t 
sin 2t 
c1e t 
+ c2e t 
−2 sin 2t 
. 
2 cos 2t 
The fundamental matrix.  The linear operator T �y  := �y � − A�y has a natural extension from vectors 
�  �  �  � 
�  �  �  � 
to matrices.  For example, when n = 2, let 
y11 
f1 
y12 
g1
= 
= 
. 
T 
,
� 
� �
� 
g2 
y22 
f2 
y21 
y11  y12 
f1  g1
= 
T 
. 
y21  y22 
f2  g2

) is an n × n matrix, whose j -th column is yj ,

In general, if A is an n × n matrix and Y  = (y1 
· · ·  yn
then 
· · · 
· · · 
T Y  = T (y1 
In this sense, �y �  = A�y extends to Y �  = AY . 

yn ) = (T y1 

Then,	

e(1+2i)t	

T 

T yn ).

1 

Exercise.  Show that 
T (U �c) = (T U )�c, 
T (U C ) = (T U )C, 
T (U  + V ) = T U  + T V , 
where U, V  are n × n matrix-valued functions, C  is an n × n matrix, and �c is a column vector. 

That means,  T  is  a  linear operator deﬁned on  the  class of matrix-valued  functions Y  differen­
tiable on an interval I . The following existence and uniqueness result is standard. 

Existence and Uniqueness result. .  If A(t) and F (t) are continuous and bounded (matrix-valued 
functions) on an interval t0  ∈ I , then for any matrix Y0  then initial value problem 
Y �  = A(t)Y  + F (t),
Y (t0 ) = Y0 

has a unique solution on t ∈ I . 

0  implies  that  |U (t)|  =�

0  for all  t  ∈  I .  We use  this  fact  to 

Working  assumption.  A(t),  F (t),  and  f (t)  are  always  continuous  and  bounded  on  an  interval 
t ∈ I . 
Deﬁnition 27.3.  A  fundamental matrix of T Y  = 0  is a solution U (t) for which  |U (t0 )| �= 0 at some 
point t0 . 
We note  that  the  condition  |U (t0 )|  =�
derive solution formulas. 
As an application of U (t), we obtain solution formulas for the initial value problem 
�y �  = A(t)�y + f�(t), 
�y(t0 ) = y�0 . 
Let  U (t)  be  a  fundamental  matrix  of  Y �  =  A(t)Y .  In  the  homogeneous  case  of  f�(t) = 0,  let 
�y(t) = U (t)�c, where �c is an arbitrary column vector. Then, 
�y �  = U ��c = (A(t)U )�c = A(t)(U �c) = A(t)�y , 
that  is,  y  is  a  solution  of  the  homogeneous  system.  The  initial  condition  then  determines �c  and 
�c = U −1 (t0 )�y0 . 
Next,  for a general f�(t), we use  the variation of parameters by seting �y(t) =  U (t)�v(t), where �v 
is a vector-valued function. Then, 
�y �  = (U �v)�  = U ��v + U �v �  = A(t)U �v + U �v �  = A(t)�y + U �v � . 
� 
Hence, U �v �  = f�(t) and 
�y(t) = U (t)  U −1 (t)f�(t) dt. 

Liouville’s equation.  We prove a  theorem of Liouville, which generalizes Abel’s  identity for  the 
Wronskian. 
Theorem 27.4 (Liouville’s Theorem).  If Y � (t) = A(t)Y (t) on an interval t ∈ I , then 
|Y (t)|�  = trA(t)|Y (t)|. 
(27.2) 
Proof.  First,  if  |Y (t0 )|  = 0  at  a  point  t0  ∈  I ,  then  |Y (t)|  = 0  for  all  t  ∈  I ,  and we  are  done.  We 
therefore assume that |Y (t)| = 0 
for all t ∈ I . 
Let Y (t0 ) = I  at a point t0 . That is, 
· · · 
· · · 
En ).
yn (t0 )) = (E1  E2 
Y (t0 ) = (y1 (t0 ) 
Here,  Ej  are  the  unit  coordinate  vectors  in Rn ,  that  is,  the  n-vector Ej  has  1  in  the  j -th  position 
and zero otherwise. 

Lecture 27 

2 

18.034 Spring 2009 

�
We use the derivative formula for the determinant 
d 
|Y (t)|�  =  det(y1 (t) . . . yn (t))
dt 
· · · 
· · · 
· · · 
· · · 
� (t)).
� (t) y2 (t) 
� (t) 
yn (t)) +  + det(y1 (t) 
yn (t)) + det(y1 (t) y2
= det(y1
yn
This formula is based on the Laplace expansion formula for determinant, and we do not prove it 
here.  Since 
� (t0 ) = A(t0 )yj (t0 ) = A(t0 )Ej  = Aj (t0 ), 
yj
where  Aj (t)  is  the  j th  column  of  A(t),  evaluating  the  above  determinant  formula  at  t  =  t0  we 
obtain 
|Y (t0 )|�  = det(A1 (t0 ) E2  · · ·  En ) + det(E1  A2 (t0 )  · · ·  En ) + · · · + det(E1  E2  · · ·  An (t0 )) 
· · · 
= a11 (t0 ) + a22 (t0 ) +  + ann (t0 ) = trA(t0 ).
Thus, (27.2) holds at t0 . 
In general, let C  = Y (t0 )−1 . Then U (t) = Y (t)C  satisﬁes 
U �  = A(t)U, 
U (t0 ) = I . 
Therefore, by the argument above |U (t0 )|�  = trA(t0 )|U (t0 )| = trA(t0 ). Since 
d 
(|Y (t)C |) = 
(|Y (t)||C |) = |Y (t)|� |C |, 
d
at t = t0 , 
dt
dt
it follows that trA(t0 ) = |Y (t0 )|� |Y (t0 )|−1 .  Since t0  is arbitrary, the proof is complete. 

� 

Lecture 27 

3 

18.034 Spring 2009 

