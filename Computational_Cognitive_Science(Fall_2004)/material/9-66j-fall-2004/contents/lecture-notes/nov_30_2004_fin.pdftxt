Outline


•	 Theory-based Bayesian framework for 
property induction 
•	 Causal structure induction 
– Constraint-based (bottom-up) learning 

– Theory-based Bayesian learning 

The origins of causal knowledge 


•	 Question: how do people reliably come to 
true beliefs about the causal structure of 
their world? 
•	 Answer must specify: 
– Prior causal knowledge  

– Causal inference procedure 

Multiple goals 


•  Descriptive:

– Prior knowledge must be psychologically 
realistic. 

–  Inference procedure must generate the same 
beliefs that people do, given the same input. 

•  Explanatory:

– Prior knowledge must be approximately 
correct. 

–  Inference procedure (constrained by prior 
knowledge) must be reliable. 

Analogy with vision

(Pearl, Cheng, Gopnik et al.) 

External world structure 

Vision (inverse 
graphics) 

Graphics

Observed images 

The fundamental problem


Hidden causal structure:

A 

B 

Causal induction 

Observed data:


Case 
1 
2 
3 
4 
. . . . 

C 

D 

E 

Causal structure 
causes observations

A
0
1
0
0

B
1
0
 0
1

C
1
1
0
1

D
1
0
1
0

E
1 
1 
0 
1 

 

Under-constrained problems


In both visual perception and causal induction, many  

world structures could have produced the same data.


Image removed due to copyright considerations. Please see:
Freeman, WT. "The Generic Viewpoint Assumption in a Framework for 

Visual Perception." Nature 368 (7 April 1994): 542-545. 

Image

Possible world structures

Under-constrained problems


In both visual perception and causal induction, many  

world structures could have produced the same data.


) z 
B A P 
(
, 

B P A P 
(
)
( 
)

A 

B

A 

B 

X 

X

B 

A 

B 

B 

A 

A

Correlation 

Possible world structures


Questions in visual perception

•	 How is the external world represented? 

–  3-D models

– 2-D views

–	 Intermediate: 2 1/2-D sketch, layers, intrinsic images, etc.

•	 What kind of knowledge does the mind have 
about the world? 
–	 Structure of objects 
–	 Physics of surfaces 
–	 Statistics of scenes 
•	 How does inference work? 
–	 Bottom-up, modular, context-free 

–	 Top-down, flexible, context-sensitive 

Questions in causal induction

•	 How is the external world represented? 

–	 Associations 
–	 Causal structures 
–	 Intermediate: Causal strength parameters 
•	 What kind of knowledge does the mind have 
about the world? 
–	 Constraints on causal structure (e.g., causal order)

–	 Faithfulness (observed independence relations are real) 
–	 Causal mechanisms 
•	 How does inference work? 
–	 Bottom-up: constraint-based (data mining) approach

–	 Top-down: theory-based Bayesian approach 

Some vocabulary


•  Causal structure 

– What causes what. 

Specifies nothing about
causal mechanisms or 
parameterizations. 

A

B 

A

B 

C 

D 

vs. 

C 

D 

E

E 

Some vocabulary


•  Causal structure 

– What causes what. 

•  Causal mechanism 

– How causes influence effects. 

C 

D 

E 

C 

D 

X 

E 

Some vocabulary


•  Causal structure 

– What causes what. 

•  Causal mechanism 

– How causes influence effects. 

C 

D 

E 

C 

D 

X 

Y 

E 

Some vocabulary


•  Causal structure 

– What causes what. 

•  Causal mechanism 

– How causes influence effects. 

C 

D 

E 

C 

D 

X 

Y 

E 

E 

D C 
f 
(
, 
)

Some vocabulary


•  Causal structure 

– What causes what. 
•  Causal mechanism

– How causes influence effects. 

C 

D 

X 

Y 

E 

C 

D 

E 

, İ)

D C 
f 
E 
(
, 
İ ~ Gaussian(µ, ı) 

Some vocabulary


•  Causal structure 

– What causes what. 

•  Causal mechanism 

– How causes influence effects. 

Knowledge about causal structures and mechanisms can 
be represented at different scales of detail. 

Abstract (“light”) mechanism knowledge will be 

particularly important: e.g., 

- deterministic, quasi-deterministic, semi-deterministic or stochastic?

- strong or weak? 
- generative or preventive influence? 
- independent of or interactive with other causes?


Some vocabulary


•  Causal structure 

– What causes what. 

•  Causal mechanism 

– How causes influence effects. 

•  Parameterization 

– Form of P(effect|causes), e.g. “noisy-OR” 

•  Causal strengths (parameters) 
– Relative contributions of different causes given  

a particular mechanism or parameterization.


Approaches to structure learning

•	 Constraint-based learning (Pearl, Glymour, Gopnik):

–	 Assume structure is unknown, no knowledge of 

parameterization or parameters


•	 Bayesian learning (Heckerman, Friedman/Koller): 
–  Assume structure is unknown, arbitrary parameterization. 

•	 Theory-based Bayesian inference (T & G): 
–	 Assume structure is partially unknown, parameterization is 
known but parameters may not be.  Prior knowledge about 
structure and parameterization depends on domain theories 
(derived from ontology and mechanisms). 

Approaches to structure learning

•	 Constraint-based learning (Pearl, Glymour, Gopnik):

–	 Assume structure is unknown, no knowledge of 

parameterization or parameters


•	 Bayesian learning (Heckerman, Friedman/Koller): 
–  Assume structure is unknown, arbitrary parameterization. 

•	 Theory-based Bayesian inference (T & G): 
–	 Assume structure is partially unknown, parameterization is 
known but parameters may not be. Prior knowledge about 
structure and parameterization depends on domain theories 
(derived from ontology and mechanisms). 

Causal inference in science


•	 Standard question: is X a direct cause of Y?

•	 Standard empirical methodologies in many 
domains: 
– Psychology 

– Medicine 

– Epidemiology

– Economics 

– Biology 
•	 Constraint-based inference attempts to formalize 
this methodology. 

Constraint-based learning


Causal graph:  A 

B 

C 

D 

Faithfulness 
assumption 

E 

Probability distribution: 
 
V P 
(
E D C B A 
,
,
} 
,
, 

E D C B A P 
(
, 
,
,
,
) 

V {

Causal Markov
assumption 

parents V ]) 
| 
[

E D C B A P 
(
, 
,
,
,
) 

C P B P A P 
(
( 
)
(
)

| 

D P B A 
E P B 
)
,
( 
)
| 
|
(

,

)

D C 

Definition of “cause”


•	 Under the causal Markov principle, A is a 
direct cause of B implies that when all other 
potentially relevant variables are held constant, 
the probability of B depends upon the presence 
or absence of A. 

•	 Under the faithfulness assumption, 
(in)dependence and conditional (in)dependence 
relations in the observed data imply constraints 
on the hidden causal structure (see picture). 

Example

•  What is the causal structure relating smoking 

(S), yellow teeth (Y), and lung cancer (L)?

•	 Epidemiological Data: 
Patient  Smoking?  Yellow teeth?  Lung Cancer? 
yes 
yes 
yes 
1 

2 

3 

4 

5 

6 

7 

8 
. . . .  


yes 

yes 

no

yes

yes 

yes 

no

yes 

no 

 no 

 yes 

no 

no 

 no 

no 

yes 

no 

yes 

no 

yes 
no


 
l
l
u
F

t
c
e
f
f
E
 
n
o
m
m
o
C

 
k
n
i
l
 
e
n
O

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

Y 

Y 

S 

L 

S 

Y 

S 

L 

Y 

S 

L 

e
s
u
a
C
 
n
o
m
m
o
C

Y 

L 

Y 

Y 

Y 

Y 

S 

L 

S 

L 

Y 

Y 

S 

L 

S 

L 

S 

L 

Y 

S 

L 

 
n
i
a
h
C

Y 

Y 

S 

L 

S 

L 

Y 

Y 

Y 

Y 

Empty


S 

L 

S 

L 

S 

L 

S 

L

S 

L 

S 

L 

S 

L 

Y 

Y 

Y 

Y 

Y 

Y 

Y 

Inference process 


•  A hypothesis: 

S 

L 

Y 

Inference process 


•	 A hypothesis: 

S 

L 

Y 

•	 What evidence would support this 
hypothesis? 
•	 Would that evidence be consistent with any 
other hypothesis? 

Example


•  What is the causal structure relating smoking 

(S), yellow teeth (Y), and lung cancer (L)?


•  Expected simple correlations: 

–  smoking, yellow teeth: yes 

–  smoking, lung cancer: yes 

–  yellow teeth, lung cancer: yes 
•  Expected partial (conditional) correlations:

–  smoking, yellow teeth | lung cancer: yes 

–  smoking, lung cancer | yellow teeth: yes 

–  yellow teeth, lung cancer | smoking: no 

Example


•  What is the causal structure relating smoking 

(S), yellow teeth (Y), and lung cancer (L)?

•	 Expected simple correlations:

–  smoking, yellow teeth: yes

–  smoking, lung cancer: yes 

–  yellow teeth, lung cancer: yes 
•	 Under faithfulness, two variables that are 
correlated must share a common ancestor. 

–  In this example, each pair of nodes must share a 
common ancestor. 

 
l
l
u
F

t
c
e
f
f
E
 
n
o
m
m
o
C

 
k
n
i
l
 
e
n
O

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

Y 
Y

Y 
Y

S 

L 

S 
S

Y 

S 

L 

Y 

S 

L 

 
e
s
u
a
C
 
n
o
m
m
o
C

Y 
Y

L 
L

Y 
Y

Y 
Y

Y 
Y

Y 
Y

S 
S

L 
L

S 
S

L 
L

Y 
Y

Y 
Y

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

Y 
Y

S 
S

L 
L

n
n
 
i
a
a
h
h
C
C

Y 
Y

Y 
Y

S 
S

L 
L

S 
S

L 
L

Y 

Y 
Y

Y 
Y

Y 
Y

Empty


S 

L 

S 

L 

S 

L 

S 

L

S 

L 

S 

L 

S 

L 

Y 

Y 

Y 

Y 

Y 

Y 

Y 

Global semantics


Joint probability distribution factorizes into product 
of local conditional probabilities: 
n 
 
iV P ( 
i  1 

i V  ])
parents 
[
| 

(   
V P  1 
,
,

n V
)

Burglary 

Earthquake 

Alarm 

JohnCalls 
)

J A E B P 
M 
(
, 
, 
,
, 
E B A P 
E P 
B P 
J P 
(
)  (
)  (
|
,
)  (

MaryCalls 

)  (

P A 

|

M 

| A )

Local semantics


Global factorization is equivalent to a set of constraints 
on pairwise relationships between variables. 

“Markov property”: Each node is conditionally 
independent of its non-descendants given its parents. 

U1

Um

Z1j

X

Znj

Y1

Yn

Image by MIT OCW.



Local semantics


Global factorization is equivalent to a set of constraints 
on pairwise relationships between variables. 

Each node is conditionally independent of all others 
given its “Markov blanket”: parents, children, 
children’s parents. 

U1

Um

Z1j

X

Znj

Y1

Yn

Image by MIT OCW.



Example


•	 What is the causal structure relating smoking, 
yellow teeth, and lung cancer? 
•	 Expected partial (conditional) correlations:

–  smoking, yellow teeth | lung cancer: yes 

–  smoking, lung cancer | yellow teeth: yes 

–  yellow teeth, lung cancer | smoking: no 
•	 Under faithfulness: 
–  If two variables L and Y are conditionally 
independent given S, then L and Y must not be in 
each other’s Markov blanket, and S must be in the 
Markov blanket of both. 

 
l
l
u
F

t
c
e
f
f
E
 
n
o
m
m
o
C

 
k
n
i
l
 
e
n
O

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

Y 
Y

Y 
Y

S 

L 

S 
S

Y 

S 

L 

Y 

S 

L 

 
e
s
u
a
C
 
n
o
m
m
o
C

Y 
Y

L 
L

Y 
Y

Y 
Y

Y 
Y

Y 
Y

S 
S

L 
L

S 
S

L 
L

Y 
Y

Y 
Y

S 
S

L 
L

S 
S

L 
L

S 
S

L 
L

Y 
Y

S 
S

L 
L

n
n
 
i
a
a
h
h
C
C

Y 
Y

Y 
Y

S 
S

L 
L

S 
S

L 
L

Y 

Y 
Y

Y 
Y

Y 
Y

Empty


S 

L 

S 

L 

S 

L 

S 

L

S 

L 

S 

L 

S 

L 

Y 

Y 

Y 

Y 

Y 

Y 

Y 

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

Y 

Y 

S 

L 

S 
S

Y 

S 

L 

Y 

S 

L 

 
e
s
u
a
C
 
n
o
m
m
o
C

 
l
l
u
F

t
c
e
f
f
E
 
n
o
m
m
o
C

 
k
n
i
l
 
e
n
O

Y 

L 
L

Y 
Y

Y 

Y 

Y 

S 
S

L 
L

S 
S

L 
L

Y 
Y

Y 
Y

S 

L 

S 

L 

S

Y 

S 

L 

n
i
a
h
C

Y 

S 

L 

S

L
Can we 
distinguish 
Y
between the 
L
remaining 
structures? 
Y
Empty

Y 

Y 

Y 

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

S 

L 

Y 

Y 

Y 

Y 

Y 

Y 

Y 

The limits of constraint-based 

inference

•	 Markov equivalence class: A set of causal 
graphs that cannot be distinguished based 
on (in)dependence relations. 
•	 With two variables, there are three possible 
causal graphs and two equivalence classes: 

a


b

a 

b

a 

b 

The limits of constraint-based 

inference

•	 Markov equivalence class: A set of causal 
graphs that cannot be distinguished based 
on (in)dependence relations. 
•	 With two variables, there are three possible 
causal graphs and two equivalence classes: 

a 
a

b 
b

a 
a

b 
b

a 
a

b
b

A and B not 
independent. 

A and B 
independent. 

 
l
l
u
F

t
c
e
f
f
E
 
n
o
m
m
o
C

 
k
n
i
l
 
e
n
O

a 

b 

a 

b 

a 

b 

a 

b 

a 

b 

a 

b 

c 

c 

c 

c 

c 

c 

a 

a 

a 

b 

b 

b 

c 

c 

c 

a 

a 

a 

e
s
u
a
C
 
n
o
m
m
o
C

b 

b 

b 

c 

c 

c 

a 

a 

a 

 
n
i
a
h
C

b 

a 

b 

b 

a 

b 

a 

c 

c 

c 

b 

b 

c 

c 

c 

Empty


a 

b 

a 

b 

a 

b 

a 

b

a 

b 

a 

b 

a 

b 

c 

c 

c 

c 

c 

c 

c 

 
l
l
u
F

 
t
c
e
f
f
E
 
n
o
m
m
o
C

 
k
n
i
l
 
e
n
O

a 
a

b 
b

a 
a

b 
b

a 
a

b 
b

a 
a

b 
b

a 
a

b 
b

a 
a

b 
b

c 
c

c 
c

c 
c

c 
c

c 
c

c 
c

a 
a

a 
a

a 
a

b 
b

b 
b

b 
b

c 
c

c 
c

c 
c

a 
a

a 
a

a 
a

 
e
s
u
a
C
 
n
o
m
m
o
C

b 
b

b 
b

b 
b

c 
c

c 
c

c 
c

a 
a

a 
a

a 
a

n
n
i
a
a
h
h
C
C

b 
b

a 
a

b 
b

b 
b

a 
a

b 
b

a 
a

c 
c

c 
c

c 
c

b 
b

b 
b

c 
c

c 
c

c 
c

Empty


a 
a

b 
b

a 
a

b 
b

a 
a

b 
b

a 
a

b
b

a 
a

b 
b

a 
a

b 
b

a 

b 

c 
c

c 
c

c 
c

c 
c

c 
c

c 
c

c 

Additional sources of constraint


•  Prior knowledge about causal structure

– Temporal order 

– Domain-specific constraints 

•  Interventions 

– Exogenously clamp one or more variables to 
some known value, and observe other variables 
over a series of cases. 

Interventions


•	 Example: Force a sample of subjects to 
smoke. 
•	 Ideal interventions block all other direct 
causes of the manipulated variable: 

S 

S 

S 

Y	

L

Y 

L

Y


L 

Interventions


•	 Example: Force a sample of subjects to 
smoke, and another sample to not smoke. 
•	 Ideal interventions block all other direct 
causes of the manipulated variable: 

I 

S	

I 

S

I

S


Y	

L

Y 

L

Y 

L


Interventions


•	 Example: Force a sample of subjects to 
smoke, and another sample to not smoke. 
•	 Non-ideal interventions simply add an extra 
cause that is under the learner’s control: 

I 

S	

I 

S

I

S


Y	

L

Y 

L

Y 

L


Advantages of the constraint-

based approach

•  Deductive 

•  Domain-general 
•  No essential role for domain knowledge:

– Knowledge of possible causal structures not 
needed. 

– Knowledge of possible causal mechanisms not 
used. 

Disadvantages of the constraint-

based approach

•	 Deductive 
•	 Domain-general 
•	 No essential role for domain knowledge:

– Knowledge of possible causal structures not 
needed. 

– Knowledge of possible causal mechanisms not 
used. 
•	 Requires large sample sizes to make reliable 
inferences. 

Example

•	 What is the causal structure relating smoking, 
yellow teeth, and lung cancer? 
•	 Epidemiological Data: 
Patient  Smoking?  Yellow teeth?  Lung Cancer? 
yes 
yes 
yes 
1 

2 

3 

4 

5 

6 

7 

8 
. . . .  


yes 

yes 

no

yes

yes 

yes 

no

yes 

no 

 no 

 yes 

no 

no 

 no 

no 

yes 

no 

yes 

no 

yes 
no


Computing (in)dependence 


•  Standard methods based on F2  test:


V=0 

V=1 

U=0 

U=1 

a 

b 

c 

d 

Ȥ 2

2 
(a  b  c  d )(a u d  b u c) 
(a  b)(c  d )(a  c)(b  d ) 
significantly > 0: not independent 
not significantly > 0: independent 

Computing (in)dependence 


•  Are smoking and yellow teeth independent?


Y=0 

Y=1 

S=0

S=1 

2 

3


0 

3 

F

2  = 1.6, p = 0.21 

Computing (in)dependence 


•  Are smoking and lung cancer independent?


L=0 

L=1 

S=0

S=1 

2 

2


0 

4 

F

2  = 2.67, p = 0.10 

Computing (in)dependence 


•	 Are lung cancer and yellow teeth 
conditionally independent given smoking? 

S=1 

L=0 

L=1 

S=0 

L=0 

L=1 

Y=0

Y=1 

1 

1 

2	

2	

Y=0

Y=1 

2


0

0 

0 

F

2  = 0, p = 1.0 

F2  = undefined 

Disadvantages of the constraint-

based approach

•	 Deductive 
•	 Domain-general 
•	 No essential role for domain knowledge:

– Knowledge of possible causal structures not 
needed. 

– Knowledge of possible causal mechanisms not 
used. 
•	 Requires large sample sizes to make reliable 
inferences. 

The Blicket detector


Image removed due to copyright considerations. Please see:
Gopnick, A., and D. M. Sobel. "Detecting Blickets: How Young Children 
use Information about Novel Causal Powers in Categorization and 
Induction." Child Development 71 (2000): 1205-1222. 

Image removed due to copyright considerations. Please see:
Gopnick, A., and D. M. Sobel. "Detecting Blickets: How Young Children 
use Information about Novel Causal Powers in Categorization and 
Induction." Child Development 71 (2000): 1205-1222. 

The Blicket detector


•	 Can we explain these inferences using 
constraint-based learning? 
•	 What other explanations can we come up 
with? 

