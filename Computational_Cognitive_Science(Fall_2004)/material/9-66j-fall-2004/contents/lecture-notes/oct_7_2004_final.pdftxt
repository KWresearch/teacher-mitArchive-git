Outline

• Bayesian Ockham’s Razor
• Bayes nets (directed graphical models)
– Computational motivation: tractable reasoning
– Cognitive motivation: causal reasoning 
– Sampling methods for approximate inference

Coin flipping

• Comparing two simple hypotheses
– P(H) = 0.5 vs. P(H) = 1.0
• Comparing simple and complex hypotheses
– P(H) = 0.5 vs. P(H) = θ
• Comparing infinitely many hypotheses
– P(H) = θ :  Infer θ

Comparing simple and complex hypotheses

θ

d4
d3
d2
d1
Fair coin, P(H) = 0.5

vs.

d1

d4

d3
d2
P(H) = θ

• Which provides a better account of the data: 
the simple hypothesis of a fair coin, or the 
complex hypothesis that P(H) = θ ?

Comparing simple and complex hypotheses

• P(H) = θis more complex than P(H) = 0.5 in 
two ways:
– P(H) = 0.5 is a special case of P(H) = θ
– for any observed sequence D, we can choose θ
such that D is more probable than if P(H) = 0.5

Bernoulli Distribution:
n = # of heads in D
N = # of flips in D

DP
(

n
)
1(
)
θθθ
=
−

|

nN
−

Comparing simple and complex hypotheses

DP
(

n
)
1(
)
θθθ
=
−

|

nN
−

y
t
i
l
i
b
a
b
o
r
P

θ= 0.5

D = HHHHH

Comparing simple and complex hypotheses

DP
(

n
)
1(
)
=
θθθ
−

|

nN
−

y
t
i
l
i
b
a
b
o
r
P

θ= 0.5

θ= 1.0

D = HHHHH

Comparing simple and complex hypotheses

DP
(

n
)
1(
)
=
θθθ
−

|

nN
−

y
t
i
l
i
b
a
b
o
r
P

θ= 0.5

θ= 0.6

D = HHTHT

Comparing simple and complex hypotheses
• P(H) = θis more complex than P(H) = 0.5 in 
two ways:
– P(H) = 0.5 is a special case of P(H) = θ
– for any observed sequence X, we can choose θ
such that X is more probable than if P(H) = 0.5
• How can we deal with this?
– Some version of Ockham’s razor:?
– Bayes: just the law of conservation of belief!  

Comparing simple and complex hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
Computing P(D|H1) is easy: 
n
HDP
)2/11()2/1(
)
(
|
=
−
1

2/1

nN
−

=

N

Compute P(D|H2) by averaging over θ:
1
∫=
0

HDP
(
|

p
)
(
|
θθ

dH
)
θ
2

DP
(

|

)

2

Comparing simple and complex hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
Computing P(D|H1) is easy: 
n
HDP
)2/11()2/1(
)
(
|
=
−
1

2/1

nN
−

=

N

Compute P(D|H2) by averaging over θ:
1
(assume uniform
∫=
prior on θ)
0

HDP
(
|

θθ d
)

DP
(

)

2

|

Comparing simple and complex hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
Computing P(D|H1) is easy: 
n
HDP
)2/11()2/1(
)
(
|
=
−
1

2/1

nN
−

=

N

Compute P(D|H2) by averaging over θ:
1
n
∫
1(
)
θθ
−
0

HDP
(
|

d
θ

nN
−

=

)

2

Comparing simple and complex hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
Computing P(D|H1) is easy: 
n
HDP
)2/11()2/1(
)
(
|
=
−
1

2/1

nN
−

=

N

Compute P(D|H2) by averaging over θ:
1
nNn
(!
)!
−
n
= ∫
1(
)
−
θθ
N
)!1
(
+
0

HDP
(
|

d
θ

nN
−

=

)

2

(How is this an average?)

HDP
(
|

• Consider a discrete approximation with 11 
values of θ, from 0 to 1 in steps of 1/10:
10
∑
i
0
=
10
2 ∑
)
=
i
0
=

)111()10/

HDP
(
|

DP
(

DP
(

p

(
θ

=

θ

=

|

θ

=

|

i

)10/

=

i

|10/

H

)

2

)

2

i

1
∫=
(c.f.,                                    ) 
DP
θθ d
HDP
|
(
)
(
|
)
2
0

Comparing simple and complex hypotheses

HDP
(
|

)

=

2

1
n
∫
1(
)
θθ
−
0

nN
−

d
θ

HDP
(
|

21)
1 =

N

y
t
i
l
i
b
a
b
o
r
P

D = HHHHH

Comparing simple and complex hypotheses

y
t
i
l
i
b
a
b
o
r
P

HDP
(
|

)

=

2

1
n
∫
1(
)
θθ
−
0

nN
−

d
θ

HDP
(
|

21)
1 =

N

D = HHHHH

Law of conservation of belief
∑
xXP
1)
(
=
=
i
i
• Two different stages
– Prior over model parameter:
1
∫
p
dH
)
θ
2
0
In a model with a wider range of parameter 
values, each setting of the parameters 
contributes less to the model predictions.  

(
|
θ

=

1

Law of conservation of belief
∑
xXP
1)
(
=
=
i
i
• Two different stages
– Prior over model parameter:
1
∫
p
dH
)
θ
2
0
– Likelihood (probability over data):
∑ ∫
HdDP
dDP
p
)|
)
(
|
(
|
(
θθ
=
=
=
d
θ
A model that predicts some data sets very well 
must predict others very poorly.

∑
d

(
|
θ

=

1

2

dH
)
θ
2

=

1

Bayesian Ockham’s Razor

Image removed due to copyright 
considerations.

Two alternative models

• Fudged Newton
– A new planet: Vulcan?
– Matter rings around the sun?
– Sun is slightly lopsided.
– Exponent in  Universal law of gravitation is      
2 + ε instead of 2.
– Each version of this hypothesis has a fudge 
factor, whose most likely value we can estimate 
empirically . . . . 

Image removed due to copyright considerations.

• Simplifying assumption: predictions of 
fudged Newton are Gaussian around 0. 

More formally….

Image removed due to copyright 
considerations.

ε : fudge factor
Mdp
(
|
)

Mdp
,(
ε )
|

∫=
ε

MpMdp
(
|
)
,
|
(
ε
ε

)

∫=
ε

≤

max
ε

Mdp ε
|
(
,

)

Two alternative models

• Fudged Newton
• Einstein: General Relativity + experimental 
error (+/- 2 arc seconds/century). 

Comparing the models

Image removed due to copyright considerations.

Where is Occam’s razor?
• Why not a more “complex” fudge, in which 
the Gaussian can vary in both mean and 
variance?

Image removed due to copyright considerations.

Bayesian Occam’s razor
• Recall: predictions of a model are the 
weighted average over all parameter values.
∫=
Mdp
dp
ddMpMpM
)
|
,
,
(
|
(
(
)
|
()
|
)
σµ
µ
σ
σµ
,
σµ

Image removed due to copyright considerations.

• Only a small set of parameter values fit the 
data well, so average fit is poor. 

Law of conservation of belief
∑
xXP
1)
(
=
=
i
i
• Two different stages
– Priors over model parameters:
∫
p
ddM
)
(
,
|
1
σµ
=
σµ
,
σµ
– Likelihood (probability over data):
∫
= ∫ ∫
ddM
dxMxp
xp
pM
dx
|
(
)
|
(
,
,
()
,
)
|
σµ
σµ
σµ
x
x
,
σµ
A model that can predict many possible data sets 
must assign each of them low probability.

=

1

Bayesian Occam’s Razor 

M1

)
M
 
\
 
d
 
=
 
D
(
 
p

M2

For any model M,

Figure by MIT OCW.
∑
Dd
 all
∈

MdDp
(
|
=

)

=

1

Ockham’s Razor in curve fitting 

20

10

0

-10

-20

0

2

4

6

8

Figure by MIT OCW.

20

10

0

-10

-20

0

20

10

0

-10

-20

0

2

4

6

8

2

4

6

8

20

10

0

-10

-20

0

20

10

0

-10

-20

0

2

4

6

8

2

4

6

8

Figure by MIT OCW.

MdDp
(
|
=

)

=

1

∑
Dd
 all
∈

)
M
 
\
 
d
 
=
 
D
(
 
p

M1

M2

M3

D

Data

Figure by MIT OCW.

M1

M2

M3

20

10

0

-10

-20

0

20

10

0

-10

-20

0

20

10

0

-10

2

4

6

8

2

4

6

8

-20

0

2

4

6

8

Figure by MIT OCW.

A model that can predict many possible data sets must assign each of 
them low probability.

Hierarchical prior

1st order poly

2nd order poly

3rd order poly

. . . .

Likelihood function for regression
• Assume y is a linear function of x plus Gaussian 
noise: 

Image removed due to copyright considerations.

• Linear regression is maximum likelihood: Find the 
function f: x  y that makes the data most likely. 

Likelihood function for regression
• Assume y is a linear function of x plus Gaussian 
noise: 

Image removed due to copyright considerations.

• Linear regression is maximum likelihood: Find the 
function f: x  y that makes the data most likely. 

Likelihood function for regression
• Assume y is a linear function of x plus Gaussian 
noise: 

Image removed due to copyright considerations.

• Not the maximum likelihood function…. 

M1

M2

M3

20

10

0

-10

-20

0

20

10

0

-10

-20

0

20

10

0

-10

2

4

6

8

2

4

6

8

-20

0

2

4

6

8

Figure by MIT OCW.

For best fitting version of each model:
Likelihood
Prior

high

low

medium

high

very very very
very low

very high

Some questions
• Is the Bayesian Ockham’s razor “purely 
objective”? 

Some questions
• Is the Bayesian Ockham’s razor “purely 
objective”? No.
– Priors matter.  (What about uninformative 
priors?)
– Choice of description language/basis 
functions/hypothesis classes matters. 
– Classes of hypotheses + priors = theory. 
(c.f. Martian grue, coin flipping)

• What do we gain from Bayes over 
conventional Ockham’s razor?

• What do we gain from Bayes over 
conventional Ockham’s razor?
– Isolates all the subjectivity in the choice of 
hypothesis space and priors
– Gives a canonical way to measure simplicity. 
– A common currency for trading off simplicity and 
fit to the data: probability.
– A rigorous basis for the intuition that “the 
simplest model that fits is most likely to be true”. 
– Measure of complexity not just # of parameters.
• Depends on functional form of the model

Three one-parameter models for 
10-bit binary sequences
• Model 1:
– Choose parameter αbetween 0 and 1.
– Round(10*α) 0’s followed by [10 - Round(10*α)] 1’s.
• Model 2:
– Choose parameter αbetween 0 and 1.
– Draw 10 samples from Bernoulli distribution (weighted 
coin flips) with parameter α.
• Model 3:
– Choose parameter αbetween 0 and 1.
– Convert-to-binary(Round(2^10*α)).

• What do we gain from Bayes over 
conventional Ockham’s razor?
– Isolates all the subjectivity in the choice of 
hypothesis space and priors
– Gives a canonical way to measure simplicity. 
– A common currency for trading off complexity 
and fit to the data: probability.
– A rigorous basis for the intuition that “the simplest 
model that fits is most likely to be true”. 
– Measure of complexity not just # of parameters.
• Depends on functional form of the model
• Depends on precise shape of priors (e.g., different 
degrees of smoothness)

Two infinite-parameter models 
for regression

M1

M2

p (f   M1)

Smooth f

Bumpy f

p (f   M2)

Smooth f

Bumpy f

M1

)
M
 
\
 
d
 
=
 
D
(
 
p

M2

D

Data

Figure by MIT OCW.

Outline

• Bayesian Ockham’s Razor
• Bayes nets (directed graphical models)
– Computational motivation: tractable reasoning
– Cognitive motivation: causal reasoning 
– Sampling methods for approximate inference

Directed graphical models
X3

X4

X1

X2

• Consist of
– a set of nodes
X5
– a set of edges
– a conditional probability distribution for each 
node, conditioned on its parents, multiplied 
together to yield the distribution over variables
• Constrained to directed acyclic graphs (DAG)
• AKA: Bayesian networks, Bayes nets

Undirected graphical models
X4
X3

X1

X2

• Consist of
– a set of nodes
X5
– a set of edges
– a potential for each clique, multiplied together to 
yield the distribution over variables
• Examples
– statistical physics: Ising model
– early neural networks (e.g. Boltzmann machines)
– low- and mid-level vision

Properties of Bayesian networks

• Efficient representation and inference
– exploiting dependency structure makes it easier 
to work with distributions over many variables
• Causal reasoning
– directed representations elucidates the role of 
causal structure in learning and reasoning 
– model for non-monotonic reasoning (esp. 
“explaining away” or causal discounting). 
– reasoning about effects of interventions 
(exogenous actions on a causal system)

Efficient representation and inference

• Three binary variables: Cavity, Toothache, Catch

Efficient representation and inference

• Three binary variables: Cavity, Toothache, Catch
• Specifying P(Cavity, Toothache, Catch) requires 7 
parameters.
– e.g., 1 for each set of values:
P
cav
ache
catch
,
(
,
)
, ..., minus 1 because it’s a 
cav
P
ache
catch
(
,
,
)
¬
probability distribution
– e.g., chain of conditional probabilities: 

,                      

P
P

(
(

cav
),
catch

ache
P
cav
|
(
ache
cav
|
,
¬

),
),

P
P

(
(

ache
|
catch

catch
P
cav
),
(
¬
ache
cav
P
|
,
),
¬

ache
|
,
catch
(

cav
),
ache
|
,
¬

¬

cav

)

Efficient representation and inference

• Three binary variables: Cavity, Toothache, Catch
• Specifying P(Cavity, Toothache, Catch) requires 7 
parameters.
• With n variables, we need 2n -1 parameters
– Here n=3.  Realistically, many more: X-ray, diet, oral 
hygiene, personality, . . . . 
• Problems:
– Intractable storage, computation, and learning
– Doesn’t really correspond to the world’s structure, or 
what we know of the world’s structure. 

Conditional independence
• Probabilistically: all three variables are dependent, 
but Toothache and Catch are independent given 
the presence or absence of Cavity. 
• Causally: Toothache and Catch are both effects of 
Cavity, via independent causal mechanisms. 

Conditional independence
• Probabilistically: all three variables are dependent, 
but Toothache and Catch are independent given 
the presence or absence of Cavity. 
• Causally: Toothache and Catch are both effects of 
Cavity, via independent causal mechanisms.
• In probabilistic terms: 
[Without conditional independence]
catch
ache
P
cav
P
cav
ache
catch
P
cav
ache
(
(
|
)
|
)
(
|
,
)
∧
=
ache
catch
cav
P
ache
cav
P
catch
ache
cav
(
(
|
)
|
)
(
|
,
)
¬
∧
¬
¬=
[
]
P
ache
cav
catch
ache
cav
P
(
|
)
(
|
,
1
¬
−=

P

)

Conditional independence
• Probabilistically: all three variables are dependent, 
but Toothache and Catch are independent given 
the presence or absence of Cavity.
• Causally: Toothache and Catch are both effects of 
Cavity, via independent causal mechanisms. 
• In probabilistic terms: 
[With conditional independence]
catch
ache
P
cav
P
cav
catch
P
cav
ache
(
(
|
)
|
)
(
|
)
∧
=
ache
catch
cav
P
ache
cav
P
catch
cav
(
(
|
)
|
)
(
|
)
¬
∧
¬=
[
]
catch
cav
P−=
ache
cav
P
1
(
|
)
(
|
)
• With n pieces of evidence, x1, …, xn, we need 2 n
conditional probabilities:
xP
cav
xP
cav
(
|
(
),
|
)
¬
i
i

P

A simple Bayes net
• Graphical representation of relations between a set of 
random variables:
Cavity

Catch
Toothache
• Causal interpretation: independent local mechanisms
• Probabilistic interpretation: factorizing complex terms
∏
CBAP
VP
V
[
(
,
,
)
(
|
parents
])
=
CBAV
},
,{
∈

P

(

Ache

,

Catch

,

Cav

)

P
(
=
P=
(

Ache
Catch
|
,
Ache
Cav
P
|
)

Cav
P
Cav
)
(
)
Catch
Cav
(
|
)

P

(

Cav

)

A more complex system
Battery

Radio

Ignition

Gas

Starts

On time to work

• Joint distribution sufficient for any inference:
SOPGISPGPBIPBRPBPOSGIRBP
)
(
,
,
,
,
,
)
(
(
|
)
(
|
)
(
)
(
|
,
)
(
|
=
∑
OSGIRBP
(
,
,
,
,
,
SIRB
,
,
,

)

)

)

GOP
(
|

)

)

AP
)
(

BAP
,
(

∑=
B
“marginalization”

=

GOP
(
,
GP
(
)

=

GP
(

)

A more complex system
Battery

Radio

Ignition

Gas

Starts

On time to work

• Joint distribution sufficient for any inference:
SOPGISPGPBIPBRPBPOSGIRBP
(
(
,
,
,
,
,
)
)
(
|
)
(
|
)
(
)
(
|
,
)
(
|
=
∑
SOPGISPGPBIPBRPBP
)
(
(
|
)
|(
)
(
)
(
|
,
)
(
|
SIRB
,
,
,

)

)

)

GOP
(
|

)

=

GOP
,
(
GP
(
)

=

GP
(

)

A more complex system
Battery

Radio

Ignition

Gas

Starts

On time to work

• Joint distribution sufficient for any inference:
SOPGISPGPBIPBRPBPOSGIRBP
(
,
,
,
,
,
)
(
)
(
|
)
(
|
)
(
)
(
|
,
)
(
|
=

)

GOP
|
(

)

=

)

GOP
,
(
GP
)
(

=

⎛
⎜
∑ ∑
⎜
⎝
S
IB
,

⎞
⎟
SOPGISPBIPBP
(
(
)
)
|
|
(
)
,
(
|
⎟
⎠

)

A more complex system
Battery

Radio

Ignition

Gas

Starts

On time to work

• Joint distribution sufficient for any inference:
SOPGISPGPBIPBRPBPOSGIRBP
(
,
,
,
,
,
)
(
)
(
|
)
(
|
)
(
)
(
|
,
)
(
|
=

)

• General inference algorithms via local computations
– for graphs without loops: belief propagation 
– in general: variable elimination, junction tree 

More concrete representation

Burglary

Earthquake

Alarm

JohnCalls

MaryCalls

More concrete representation

P(B)
0.001

Burglary

P(E)
0.002

Earthquake

Alarm

B    E     P(A|B,E)
0     0      0.001
0     1      0.29
1     0      0.94
1     1      0.95

“CPT”

JohnCalls

A     P(J|A)
0     0.05
1     0.90

MaryCalls

A    P(M|A)
0     0.01
1     0.70

Parameterizing the CPT

Size of CPT is exponential in number of 
parents.  Often use a simpler parameterization 
based on knowledge of how causes interact. 

Parameterizing the CPT

Size of CPT is exponential in number of 
parents.  Often use a simpler parameterization 
based on knowledge of how causes interact. 
• Logical OR: Independent deterministic causes
Earthquake

Burglary

Alarm

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

Parameterizing the CPT

Size of CPT is exponential in number of 
parents.  Often use a simpler parameterization 
based on knowledge of how causes interact. 
• Noisy OR: Independent probabilistic causes
Earthquake

Burglary

Alarm

B    E     P(A|B,E)
0     0      0
0     1      wB
1     0      wE
1     1      wB +(1-wB )wE

Parameterizing the CPT

Size of CPT is exponential in number of 
parents.  Often use a simpler parameterization 
based on knowledge of how causes interact. 
• AND: cause + enabling condition
Electricity

Burglary

Alarm

B    E     P(A|B,E)
0     0      0
0     1      0
1     0      0
1     1      1 (or wB)

Parameterizing the CPT

Size of CPT is exponential in number of 
parents.  Often use a simpler parameterization 
based on knowledge of how causes interact. 
• Logistic: Independent probabilistic causes 
with varying strengths wi and a threshold θ

Child 1 upset

Child 2 upset

Parent upset

C1   C2     P(Pa|C1,C2)
]
[
0      0       
)
exp(
1/1
+
θ
[
0      1      
exp(
1/1
θ
+
−
[
1      0      
exp(
1/1
θ
+
−
[
1      1      
exp(
1/1
θ
+
−

]
w
)
1
]
w
)
2
ww
−
1
2

])

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

A priori, no correlation between B and E:
∑=
A

AEBP
,
(
)
,

EBP
(
,

)

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

A priori, no correlation between B and E:
∑=
A

EPBPEBAP
(
|
,
)
(
)
(

)

EBP
(
,

)

CBAP
(
,
,

)

=

∏
VP
(
CBAV
},
,{
∈

|

V
[
parents

])

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

A priori, no correlation between B and E:
∑=
A

EPBPEBAP
(
|
,
)
(
)
(

)

EBP
(
,

)

=1, for any values of B and E

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

A priori, no correlation between B and E:

EBP
(
,

)

=

EPBP
(
)
(

)

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

AEBP
,
(
|

After observing A=1 … 
AP
EPBPEB
(
|1
)
)
(
,
(
=
AP
(
)1
=
EPBPEB
)
,
(
)
(

AP
(

=

)1

=

|1

)

)

=

∝

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

Assume 
EP
BP
(
(
)
=

2/1)
=

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

After observing A=1 … 

AEBP
(
,
|

)1
∝=

AP
(

=

|1

EB
,

)

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

After observing A=1 … 

AEBP
(
,
|

)1
∝=

AP
(

=

|1

EB
,

)

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

… P(B|A=1) = 2/3
B and E are anti-correlated

Explaining away

• Logical OR: Independent deterministic causes

Burglary

Earthquake

Alarm

After observing A=1, E=1 … 

ABP
(
|

=

,1

E

)1
∝=

AP
(

=

|1

EB
,

=

)1

B    E     P(A|B,E)
0     0      0
0     1      1
1     0      1
1     1      1

… P(B|A=1) = 1/2
Back to P(B).
“Explaining away” or 
“Causal discounting”

Explaining away

• Depends on the functional form (the 
parameterization) of the CPT
– OR or Noisy-OR: Discounting
– AND: No Discounting 
– Logistic: Discounting or Augmenting 

Spreading activation or recurrent 
neural networks
Sprinkler
Rain

Grass Wet

Wet

• Excitatory links: Rain
Wet, Sprinkler
• Observing rain, Wet becomes more active. 
• Observing grass wet, Rain and Sprinkler become 
more active.
• Observing grass wet and sprinkler, Rain cannot 
become less active.  No explaining away!   

Spreading activation or recurrent 
neural networks
Sprinkler
Rain

Grass Wet

Wet

Wet, Sprinkler
• Excitatory links: Rain
Sprinkler
• Inhibitory link: Rain
• Observing grass wet, Rain and Sprinkler become 
more active.
• Observing grass wet and sprinkler, Rain becomes 
less active: explaining away. 

Spreading activation or recurrent 
neural networks
Rain
Burst pipe

Sprinkler

Grass Wet
• Each new variable requires more inhibitory 
connections.
• Interactions between variables are not causal.
• Not modular.
– Whether a connection exists depends on what other 
connections exist, in non-transparent ways.  
– Combinatorial explosion.

Summary

Bayes nets, or directed graphical models, offer 
a powerful representation for large 
probability distributions:
– Ensure tractable storage, inference, and 
learning
– Capture causal structure in the world and 
canonical patterns of causal reasoning. 
– This combination is not a coincidence.

