Outline

• Theory-based Bayesian causal induction
• On intuitive theories: their structure, 
function, and origins 

Domain theory generates hypothesis 
space of causal models 

• Ontology of types and predicates.
– What is there?  
• Constraints on causal relations between 
predicates.
– What can/must/is likely to cause what? 
• Functional forms of causal relations. 
– How does an effect depend functionally on its 
causes? 

Domain theory generates hypothesis 
space of causal models 

• Ontology of types and predicates.
– What is there?  Nodes.
• Constraints on causal relations between 
predicates.
– What can/must/is likely to cause what? Edges.
• Functional forms of causal relations. 
– How does an effect depend functionally on its 
causes? Parameterizations and parameters.

Theories as probabilistic logic
• Ontology
– Types: Block, Detector, Trial
– Predicates:
Contact(Block, Detector, Trial)
Active(Detector, Trial)
• Constraints on causal relations
– For any Block b and Detector d, with probability q :  
Cause(Contact(b,d,t), Active(d,t))
• Functional form of causal relations
– Causes of Active(d,t) are independent mechanisms, with 
causal strengths wi. A background cause has strength w0. 
Assume a near-deterministic mechanism: wi ~ 1, w0 ~ 0. 

Bayesian inference
• Evaluating causal network hypotheses in 
light of data:

)

=

dhP
(
|
i

hPhdP
(
|
(
)
)
i
i
∑
hPhdP
(
|
(
)
j
Hjh
∈
• Inferring a particular causal relation:   
∑
AP
dE
AP
hPhE
|
(
)
(
|
(
j
Hjh
∈

→

→

)

=

)

j

|

d

)

j

Manipulating the prior
I. Pre-training phase: Blickets are rare . . . . 

II. Backwards blocking phase: 

A
B
Trial 2
Trial 1
After each trial, adults judge the probability that each 
object is a blicket.

Rare condition

Common condition

PEOPLE
 (N = 12)
BAYES

PEOPLE
 (N = 12)
BAYES

7

6

5

4

3

2

1 AB
AB
Baseline

AB
AB
After AB trial

A
B
A B
After A trial

Figure by MIT OCW.

7

6

5

4

3

2

1

AB
AB
Baseline

AB
AB
After AB trial

A
B
A B
   After A trial

Manipulating the priors of 
4-year-olds
(Sobel, Tenenbaum & Gopnik, 2004)
I. Pre-training phase: Blickets are rare.
II. Backwards blocking phase: 

A

B

Rare condition:
A: 100% say “a blicket” 
B: 25% say “a blicket”

Trial 2

Trial 1
Common condition:
A: 100% say “a blicket” 
B: 81% say “a blicket”

Inferences from ambiguous data
I. Pre-training phase: Blickets are rare . . . . 

II. Two trials: A B       detector,   B C      detector 

B

C

A

Trial 1
After each trial, adults judge the probability that each 
object is a blicket.

Trial 2

Same domain theory generates hypothesis 
space for 3 objects: 
B
C
A
• Hypotheses:          h000 =                          h100 = 
E
B
A
C
h010 =                          h001 = 
E
B
A
C
h110 =                          h011 = 
E
B
A
C
h101 =                          h111 = 
E
P(E=1| A, B, C; h) = 1

• Likelihoods:

E
B

E
B

E

B

E
B

C

C

A

A

C

C

A

A

if A = 1 and A
or B = 1 and B
or C = 1 and C
else 0.

E exists,     
E exists, 
E exists, 

• “Rare” condition: First observe 12 objects 
on detector, of which 2 set it off. 

10

9

8

7

6

5

4

3

2

1

0

PEOPLE
 (N = 20)
BAYES

ABC
Baseline

AB
C
After AB trial

BC
A
After AC trial

Figure by MIT OCW.

Ambiguous data with 4-year-olds
I. Pre-training phase: Blickets are rare.

II. Two trials: A B       detector,   B C      detector 

A

B

C

Trial 1

Trial 2

Final judgments:
A: 87% say “a blicket” 
B or C: 56% say “a blicket”

Ambiguous data with 4-year-olds
I. Pre-training phase: Blickets are rare.

II. Two trials: A B       detector,   B C      detector 

A

B

C

Trial 1

Trial 2

Final judgments:
A: 87% say “a blicket” 
B or C: 56% say “a blicket”

Backwards blocking (rare)
A: 100% say “a blicket” 
B: 25% say “a blicket”

The role of causal mechanism 
knowledge
• Is mechanism knowledge necessary?
– Constraint-based learning using χ2 tests of 
conditional independence. 
• How important is the deterministic functional 
form of causal relations?
– Bayes with “probabilistic independent generative 
causes” theory (i.e., noisy-OR parameterization 
with unknown strength parameters; c.f., Cheng’s 
causal power). 

Bayes with correct theory:
PEOPLE (N=12)
BAYES

PEOPLE (N=12)
BAYES

PEOPLE (N=20)
BAYES

7
6

5

4
3

2
1

AB

AB

A

B

7
6

5

4
3

2
1

AB

AB

A

B

10
9
8
7
6
5
4
3
2
1
0

ABC
Baseline

AB
C
After AB trial

A
BC
After AC trial

Figure by MIT OCW.
Independence test with fictional sample sizes:

7
6

5

4
3

2
1

AB

AB

A

B

7
6

5

4
3

2
1

AB

AB

A

B

Figure by MIT OCW.

10
9
8
7
6
5
4
3
2
1
0

ABC

AB

C

A

BC

Baseline

After AB trial

After AC trial

Bayes with correct theory:
PEOPLE (N=12)
PEOPLE (N=12)
BAYES
BAYES

PEOPLE (N=20)
BAYES

7
6

5

4
3

2
1

AB

AB

A

B

7
6

5

4
3

2
1

AB

AB

A

B

10
9
8
7
6
5
4
3
2
1
0

ABC
Baseline

AB
C
After AB trial

A
BC
After AC trial

Figure by MIT OCW.
Bayes with “noisy sufficient causes” theory:

7
6

5

4
3

2
1

AB

AB

A

B

7
6

5

4
3

2
1

AB

AB

A

B

Figure by MIT OCW.

10
9
8
7
6
5
4
3
2
1
0

ABC

Basline

AB

C

A

BC

After AB trial

After AC trial

Blicket studies: summary
• Theory-based Bayesian approach explains 
one-shot causal inferences in physical 
systems.
• Captures a spectrum of inference:
– Unambiguous data: adults and children make 
all-or-none inferences
– Ambiguous data: adults and children make 
more graded inferences
• Extends to more complex cases with hidden 
variables, dynamic systems, ….

Learning a probabilistic 
causal relation
Given a random
sample of mice:

Injected
with X

Not injected
with X

Expressed Y

Did not 
express Y

6

2

3

5

• “To what extent does chemical X cause gene Y 
to be expressed?”
• Or, “What is the probability that X causes Y?”

Theory

• Ontology
– Types: Chemical, Gene, Mouse
– Predicates:
Injected(Mouse, Chemical)
Expressed(Mouse, Gene)
• Constraints on causal relations
– For any Chemical c and Gene g, with prior probability q :  
Cause(Injected(m,c), Expressed(m,g))
• Functional form of causal relations
– Causes of Expressed(m,g) are independent probabilistic 
mechanisms, with causal strengths wi. An independent 
background cause is always present with strength w0.

Judging the probability that C    E 
(Buehner & Cheng, 1997; 2003)

Image removed due to copyright considerations.

Parameter estimation models

Image removed due to 
copyright considerations.

How important is the theory?

Image removed due to copyright considerations.

Learning causal structure without 
causal mechanism knowledge
• Constraint-based: χ2 test of independence.

Image removed due to copyright considerations.

• “Mechanism-free” Bayes: no constraints on 
the functional form of P(E|B,C)

Image removed due to copyright considerations.

Data for inhibitory causes

Image removed due to copyright considerations.

Probabilistic causal relations: 
summary
• Much weaker theory: causes may have any 
degree of strength.
• Thus, inferences about causal structure still 
graded after many observations. 

The stick-ball machine
A B

T. Kushnir, A. Gopnik, L Schulz, and D. Danks. “Inferring Hidden Causes.” 
Proceedings of the Twenty-Fifth Annual Meeting of the Cognitive Science Society.
Boston, MA: Cognitive Science Society, 2003, pp. 699-703.

Inferring hidden causal structure
Common unobserved cause

4 x

2 x

2 x

Independent unobserved causes

Image removed due to copyright considerations. Please see:
T. Kushnir, A. Gopnik, L Schulz, and D. Danks. “Inferring Hidden 
Causes.” Proceedings of the Twenty-Fifth Annual Meeting of the 
Cognitive Science Society. Boston, MA: Cognitive Science 
Society, 2003, pp. 699-703.

1 x

2 x

2 x

2 x

2 x

One observed cause

2 x

4 x

Theory

• Ontology
– Types: Ball, Source, Trial
– Predicates:
Moves(Ball, Trial)
Moves(Source, Trial)
• Constraints on causal relations
– Possible for any Ball or Source x and any Ball b:  
Cause(Moves(x,t), Moves(b,t))
• Functional form of causal relations
– Causes of Moves(b,t) are independent mechanisms, with 
causal strengths β.
– If Moves(x,t) has no causes, it occurs with probability α.

Image removed due to copyright considerations.

c.f., infinite
mixture model

Image removed due to copyright considerations.

Modeling bi-directional 
influences

Image removed due to copyright considerations. Please see:
T. Kushnir, A. Gopnik, L Schulz, and D. Danks. “Inferring Hidden Causes.” In Proceedings of the Twenty-Fifth 
Annual Meeting of the Cognitive Science Society. Boston, MA: Cognitive Science Society, 2003, pp. 699-703.

Common unobserved cause

Image removed due to copyright considerations.

Independent unobserved causes

Image removed due to copyright considerations.

One observed cause

Image removed due to copyright considerations.

Image removed due to copyright considerations. Please see:
T. Kushnir, A. Gopnik, L Schulz, and D. Danks. “Inferring 
HiddenCauses.” In Proceedings of the Twenty-Fifth Annual 
Meeting of the Cognitive Science Society. Boston: Cognitive 
Science Society, 2003, pp. 699-703.

α = 0.3
ω = 0.8

r = 0.94

Stick-ball studies: summary

• More flexible theory: causal mechanisms 
are not deterministic, hidden causes may 
exist. 
• Thus, inferences require more data, and are 
not quite all-or-none.

Nitro X

• More extreme test of ability to infer hidden causes
– single datapoint
– no mention of hidden cause in instructions
• More sophisticated physical theory
• Importance of statistical inference

Nitro X

Test trials

• Show explosions involving multiple cans
– allows inferences about causal structure
• For each trial, choose one of:
– chain reaction
– spontaneous explosions
– other
• No explicit reference to a hidden cause

Image removed due to copyright considerations.

c.f., infinite
mixture model

Image removed due to copyright considerations.

Image removed due to copyright considerations.

People are sensitive to statistical evidence for a hidden cause

Nitro-X studies: summary
• Perceptual inferences about hidden causal 
structure can be explained in the same theory-
based Bayesian framework.
– Perceptual settings are information-rich: a single 
observation is often sufficient to provide strong 
evidence for a hidden cause.

• Some questions:
– What do we gain by describing causal reasoning, causal 
learning, and causal perception in the same framework?
– Are there any kinds of causal inferences that can’t be 
explained in this framework?

Theories + Bayes in causal induction 

• Theory is a logical structure that generates a space 
of probabilistic causal models -- the hypothesis 
space for Bayesian inference. 
• Parallel with theory-based Bayesian models for 
learning about concepts and properties (c.f., Ta’ 
grammars for domain structures).
– Something missing: learning the theory?
• General theme: merging of two major traditions in 
cog sci and AI, previously seen as opposing:
– structured symbolic representations
– probabilistic inference and statistical learning 

Outline

• Theory-based Bayesian causal induction
• On intuitive theories: their structure, 
function, and origins 

Two lines of questioning
• How do we infer networks of causal relations?
– Given only observational data (correlation)?
– Given just a few observations?
– In the presence of hidden causes?
– With dynamic systems?
• How to characterize intuitive causal theories? 
(e.g., theories of physics, biology, mind) 
– What is the content of causal theories?
– How are they used in causal inference?
– How are the theories themselves learned? 

Some background on theories
• A primary motivation comes from cognitive 
development.  (But related to learning in AI...)
• The big question: what develops from 
childhood to adulthood?
– One extreme: basically everything
• Totally new ways of thinking, e.g. logical thinking. 
– The other extreme: basically nothing 
• Just new facts (specific beliefs), e.g., trees can die.
– Intermediate view: something important
• New theories, new ways of organizing beliefs.

Outline
• What are causal theories?  
– Bayes nets
– Probabilistic graph grammars
– Probabilistic logics (TBB, RPMs, BLOG)
• How are theories used in causal inference? 
– Generate constrained, domain-dependent hypothesis 
spaces for domain-general Bayesian inference
• How can theories be learned?
– Bayesian inference in a space of possible theories.  
– Example: Learning concepts based on causal relations. 

Causal networks in cognition 
• Learning networks of causal relations
– e.g., Danks & McKenzie, Griffiths & 
Tenenbaum, Schulz & Gopnik, Sloman & 
Lagnado, Sobel, Steyvers & Tenenbaum, 
Waldmann
• Judging the strength of cause-effect relations
– e.g., Buehner & Cheng, Cheng & Novick, 
Shanks, White
• Categories as causal networks
– e.g., Ahn, Rehder, Waldmann

Causal networks = theories? 
Example: network of diseases, effects, and causes

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.
Theory-like properties:
– Generates hypotheses for causal inference (diagnosis).
– Provides causal explanation of observed correlations. 
– Supports intervention and action planning. 

Causal networks = theories? 
Example: network of diseases, effects, and causes

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.
Missing a key level of abstraction: 
Domain-specific laws that constrain the causal 
network structures considered when learning and 
reasoning in a given domain.

Different causal networks,
Same domain theory

Different domain theories

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Headache

Fever

Coughing

Chest
Pain

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.

Figure by MIT OCW.

The grammar analogy
Different semantic networks,
Different grammars
Same linguistic grammar

Talk

Sleep
Fly

Grow

Talk

Sleep
Fly

Grow

People

Cats

Bees
Trees

People

Cats

Bees
Trees

People

Cats

Bees
Trees

People

Cats

Bees
Trees

Imagine

Sleep
Fly

Grow

Imagine

Sleep
Fly

Grow

The grammar analogy
“The grammar of a language can be viewed as a theory 
of the structure of this language.  Any scientific theory 
is based on a certain finite set of observations and, by 
establishing general laws stated in terms of certain 
hypothetical constructs, it attempts to account for these 
observations, to show how they are interrelated, and to 
predict an indefinite number of new phenomena….  
Similarly, a grammar is based on a finite number of 
observed sentences… and it ‘projects’ this set to an 
infinite set of grammatical sentences by establishing 
general ‘laws’… [framed in terms of] phonemes, words, 
phrases, and so on.…”
Chomsky (1956), “Three models for the description of language” 

Theories in Cognitive 
Development
“A theory consists of three interrelated components: a 
set of phenomena that are in its domain, the causal laws 
and other explanatory mechanisms in terms of which the 
phenomena are accounted for, and the concepts in terms 
of which the phenomena and explanatory apparatus are 
expressed.”
Carey (1985), “Constraints on semantic development”

Theories as graph grammars
Stressful
Working in
Working in
Lifestyle
Factory
Factory

Stressful
Lifestyle

High Fat
Diet

Smoking

Smoking

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.
Classes = {B, D, S}
Laws = {B       D, D      S}
(      : possible causal link)

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.
Classes = {C}
Laws = {C       C}

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.
Classes = {B, D, S}
Laws = {S       D}

Theories as graph grammars
Stronger regularities:
Stressful
High Fat
Lifestyle
Diet

Smoking

Working in
Factory

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Headache

Fever

Coughing

Chest
Pain

Working in
Factory

Smoking

Stressful
Lifestyle

High Fat
Diet

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Flu

Bronchitis

Lung
Cancer

Heart
Disease

Headache

Fever

Coughing

Chest
Pain

Headache

Fever

Coughing

Chest
Pain

Figure by MIT OCW.

Classes = {B, D, S}
Laws = {B       D, D      S}
(      : possible causal link)

Figure by MIT OCW.
Classes = {B, D, S}
Laws = {B       D, D      S}     
(       : necessary causal link)
Also could have probabilistic
link rules.

The grammar analogy

Natural Language Grammar
Abstract classes:   N, V, …. 
Production rules: S       [N  V], ….
(“Nouns precede verbs”)

Causal Theory
Abstract classes:   D, S, …. 
Causal laws: [D      S], ….
(“Diseases cause symptoms”)

N
V

{people, cats, bees, trees, .…} 
{talks, sleep, fly, grow, ….}

D
S

{flu, bronchitis, lung cancer,….} 
{fever, cough, chest pain, ….}

Linguistic Grammar

Causal Theory

Syntactic structures

Causal network structures

Observed sentences 
in the language

Observed data 
in the domain

Specific theories versus 
“framework theories”
Wellman (1990; Gelman & Wellman, 1992)

Causal Theory

Causal network structures

“Specific theories are detailed 
scientific formulations about a 
delimited set of phenomena.”

Observed data

Specific theories versus 
“framework theories”
Wellman (1990; Gelman & Wellman, 1992)

Causal Theory

Causal network structures

Observed data

“Framework theories outline the 
ontology and the basic causal
devices for their specific 
theories, thereby defining a 
coherent form of reasoning 
about a particular set of 
phenomena.”
“Specific theories are detailed 
scientific formulations about a 
delimited set of phenomena.”

