So...
… why do we keep having this debate: 
rules/symbols vs. prototypes/connections?

So...
The real problem: a spurious contest between 
logic and probability.  
– Neither logic nor probability on its own is 
sufficient to account for human cognition: 
• Generativity
• Systematicity
• Recursion and abstraction
• Flexibility
• Effective under great uncertainty (e.g., sparse data)
– What we really need is to understand how logic 
and probability can work together.

So...
The real problem: a spurious contest between 
logic and probability.  
– A confusion between knowledge 
representations and inference processes:
Gradedness or fuzziness doesn’t necessarily mean that 
the knowledge representations lack structure or rules 
-- merely that the inference processes incorporate 
uncertainty. 

– Probabilistic inference over structured 
representations is what we need.

So...
… why do we keep having this debate: 
rules/symbols vs. prototypes/connections?

… why has it taken Cognitive Science much 
longer to get over it than AI?

Introduction to Bayesian 
inference

Representativeness in reasoning

Which sequence is more likely to be produced 
by flipping a fair coin?

HHTHT 

HHHHH  

A reasoning fallacy

Kahneman & Tversky: people judge the 
probability of an outcome based on the 
extent to which it is representative of the 
generating process.  

Not wired for probability?

• Slovic, Fischhoff, and Lichtenstein (1976):
– “It appears that people lack the correct 
programs for many important judgmental 
tasks.... it may be argued that we have not had 
the opportunity to evolve an intellect capable of 
dealing conceptually with uncertainty.”
• Gould (1992): 
– “Our minds are not built (for whatever reason) 
to work by the rules of probability.”

•

Aristotle (4th century B.C.)
In On the heavens, Aristotle asks whether the stars move 
independently or whether they are all fixed to some sphere.
• He observes that stars moving in large circles (near the 
celestial equator) take the same time to rotate as those near the 
polestar, which rotate in small circles. 
Infers a common cause: “If, on the other hand, the 
arrangement was a chance combination, the coincidence in 
every case of a greater circle with a swifter movement of the 
star contained in it is too much to believe.  In one or two 
cases, it might not inconceivably fall out so, but to imagine it
in every case alike is a mere fiction.  Besides, chance has no 
place in that which is natural, and what happens everywhere 
and in every case is no matter of chance.”

•

Image removed due to copyright considerations. Please see:
Halley. "Motuum Cometarum in Orbe Parabolico Elementa Astronomica." 
In "Astronomiae Cometiae Synopsis."  Philisophical Transactions (1705). 

Transcript available at http://www.seds.org/~spider/spider/Comets/halley_p.html
____________________________________________________________________

Image removed due to copyright considerations. Please see:
Halley. "Motuum Cometarum in Orbe Parabolico Elementa Astronomica." 
In "Astronomiae Cometiae Synopsis."  Philisophical Transactions (1705). 

Transcript available at http://www.seds.org/~spider/spider/Comets/halley_p.html
____________________________________________________________________

A reasoning fallacy

Kahneman & Tversky: people judge the 
probability of an outcome based on the 
extent to which it is representative of the 
generating process.  

But how does “representativeness” work?

Predictive versus inductive 
reasoning

Hypothesis

Data

H

D

Predictive versus inductive 
reasoning

Prediction
given

Likelihood:

| HD(P

)

?

H

D

Predictive versus inductive 
reasoning

Prediction
given

Likelihood:

| HD(P

)

?

H

D

Induction
?

Representativeness

given

Bayes’ rule

For data D and a hypothesis H, we have:

DHP
(
|

)

=

HDPHP
(
|
(
)
DP
(
)

)

• “Posterior probability”:
• “Prior probability”:
(HP
• “Likelihood”:
( HDP
|
)

)

DHP
(
|
)

The origin of Bayes’ rule

• A simple consequence of using probability 
to represent degrees of belief
• For any two random variables:
ABPAP
BAP
)
)
(
)
(
(
|
=
∧
BAP
BAPBP
(
)
(
)
(
|
)
=
∧
BAPBP
ABPAP
(
)
(
|
)
)
(
)
(
|
ABPAP
(
|
)
)
(
BP
(
)

BAP
(
|

=

)

=

Why represent degrees of belief 
with probabilities?
• Cox Axioms
– necessary to cohere with common sense
• “Dutch Book” + Survival of the Fittest
– if your beliefs do not accord with the laws of 
probability, then you can always be out-gambled by 
someone whose beliefs do so accord.
• Provides a theory of learning
– a common currency for combining prior knowledge and 
the lessons of experience. 

ABBel
(
|
)]

Cox Axioms (via Jaynes)
• Degrees of belief are represented by real numbers.
• Qualitative correspondence with common sense, 
e.g.:
Bel
f
ABel
A
)
(
[
(
)]
=¬
g
ABel
BABel
(
)
[
),
(
=
∧
• Consistency:
– If a conclusion can be reasoned in more than one way, 
then every possible way must lead to the same result.
– All available evidence should be taken into account when 
inferring a degree of belief.
– Equivalent states of knowledge should be represented with 
equivalent degrees of belief.
• Accepting these axioms implies Bel can be 
represented as a probability measure. 

Probability as propositional logic 
with uncertainty
• All of probability theory can be derived 
from these two laws (plus propositional 
logic):
IAP
|
(
IBAP
(
|
)
∧

1)
=
IBAP
)
(
|
),
=

IAP
|
(
)
¬+
IBAP
(
,
|
≡

×

IBP
(
|

)

• That’s good: simple, elegant principles.
• That’s bad: how to work with structured 
representations?  More on that later….

DHP
(
|

)

)

=

• Bayes’ rule:

Bayesian inference
HDPHP
)
(
(
|
DP
)
(
• What makes a good scientific argument? 
P(H|D) is high if:
– Hypothesis is plausible: P(H) is high 
– Hypothesis strongly predicts the observed data:
P(D|H) is high
– Data are surprising: P(D) is low

A more useful form of Bayes

• Random variable X denotes a set of 
mutually exclusive exhaustive propositions 
(states of the world):
nx
X
x
,{ 1
,
}
K=
∑
xXP
(
1)
=
=
i
i
• A useful rule: conditionalization
∑
j

YxXP
(
|
=
i

YPy
)
(
j

XP
(

x
i

)

=

=

=

=

y

)

j

A more useful form of Bayes

• Random variable X denotes a set of 
mutually exclusive exhaustive propositions 
(states of the world):
nx
X
x
,{ 1
,
}
K=
∑
xXP
(
1)
=
=
i
i
• Bayes’ rule for more than two hypotheses:
hHdDPhHP
(
|
)
)
(
=
=
=
dDP
(
)
=

dDhHP
(
|
=
=

)

=

A more useful form of Bayes

• Random variable X denotes a set of 
mutually exclusive exhaustive propositions 
(states of the world):
nx
X
x
,{ 1
,
}
K=
∑
xXP
(
1)
=
=
i
i
• Bayes’ rule for more than two hypotheses:
hHdDPhHP
(
(
)
|
)
=
=
=
∑
hHdDPhHP
(
)
(
|
=
=
=
i
i
i

dDhHP
(
|
=
=

)

)

=

A more useful form of Bayes

• Random variable X denotes a set of 
mutually exclusive exhaustive propositions 
(states of the world):
nx
X
x
,{ 1
,
}
K=
∑
xXP
(
1)
=
=
i
i
• Bayes’ rule for more than two hypotheses:
hdPhP
)(
|
(
)
∑=
hdPhP
(
)
(
|
i
i
i

dhP
(
|

)

)

Sherlock Holmes

• “How often have I said to you that when you have 
eliminated the impossible whatever remains, 
however improbable, must be the truth?” (The 
Sign of the Four)

dhP
(
|

)

hdPhP
)(
(
|
)
∑=
hdPhP
(
)
(
|
i
i
i

)

Sherlock Holmes

• “How often have I said to you that when you have 
eliminated the impossible whatever remains, 
however improbable, must be the truth?” (The 
Sign of the Four)

dhP
(
|

)

=

hdPhP
(
|
)
)(
∑
hdPhP
hdPhP
)(
)
(
)
(
|
(
|
+
i
i
hh
≠
i

)

Sherlock Holmes

• “How often have I said to you that when you have 
eliminated the impossible whatever remains, 
however improbable, must be the truth?” (The 
Sign of the Four)

dhP
(
|

)

=

hdPhP
(
|
)
)(
∑
hdPhP
hdPhP
)(
)
(
)
(
|
(
|
+
i
i
hh
≠
= 0
i

)

Sherlock Holmes

• “How often have I said to you that when you have 
eliminated the impossible whatever remains, 
however improbable, must be the truth?” (The 
Sign of the Four)
hdPhP
|
(
)(
hdPhP
)(
(
|

dhP
(
|

)
)

=

1

)

=

Sherlock Holmes

• “How often have I said to you that when you have 
eliminated the impossible whatever remains, 
however improbable, must be the truth?” (The 
Sign of the Four)
hdPhP
|
(
)(
hdPhP
)(
(
|
> 0

dhP
(
|

)
)

=

1

)

=

A reasoning fallacy

Kahneman & Tversky: people judge the 
probability of an outcome based on the 
extent to which it is representative of the 
generating process.  

Hypotheses in coin flipping
Describe processes by which D could be generated
D = HHTHT
• Fair coin, P(H) = 0.5
• Coin with P(H) = θ
• Markov model
• Hidden Markov model
• ...

generative
models

Representing generative models

• Graphical model notation
– Pearl (1988), Jordan (1998)
• Variables are nodes, edges 
indicate dependency
• Directed edges show causal 
process of data generation
HHTHT
d1 d2 d3 d4 d5

d4
d3
d2
d1
Fair coin: P(H) = 0.5

d4

d1
d2
d3
Markov model:
P(di+1|di) = 0.7 if di+1 di
≠
= 0.3 if di+1 = di

Models with latent structure

• Not all nodes in a graphical 
model need to be observed
• Some variables reflect latent
structure, used in generating 
D but unobserved
HHTHT
d1 d2 d3 d4 d5

θ

d1

s1

d4

d2
d3
P(H) = θ

s2

s3

s4

d4
d3
d2
d1
Hidden Markov model:
si     {Fair coin, Trick coin}
∈

Coin flipping

• Comparing two simple hypotheses
– P(H) = 0.5 vs. P(H) = 1.0
• Comparing simple and complex hypotheses
– P(H) = 0.5 vs. P(H) = θ
• Comparing infinitely many hypotheses
– P(H) = θ :  Infer θ

Coin flipping

• Comparing two simple hypotheses
– P(H) = 0.5 vs. P(H) = 1.0
• Comparing simple and complex hypotheses
– P(H) = 0.5 vs. P(H) = θ
• Comparing infinitely many hypotheses
– P(H) = θ :  Infer θ

Coin flipping
HHTHT
HHHHH

What process produced these sequences?

Comparing two simple hypotheses

• Contrast simple hypotheses:
– H1: “fair coin”, P(H) = 0.5
– H2:“always heads”, P(H) = 1.0
• Bayes’ rule:

DHP
(
|

HDPHP
(
|
(
)
DP
)
(
• With two hypotheses, use odds form

)

)

=

Bayes’ rule in odds form

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
data
models
posterior probability H1 generated the data 
likelihood of data under model H1
prior probability H1 generated the data 

D: 
H1, H2: 
P(H1|D): 
P(D|H1): 
P(H1): 

Comparing two simple hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
HHTHT
D: 
H1, H2: 
“fair coin”, “always heads”
P(D|H1) = 1/25
P(H1) =
? 
P(H2) =  
P(D|H2) = 0 
1-?

P(H1|D) / P(H2|D) = infinity

Comparing two simple hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
HHTHT
D: 
H1, H2: 
“fair coin”, “always heads”
P(D|H1) = 1/25
P(H1) =
999/1000 
P(H2) =  
P(D|H2) = 0 
1/1000

P(H1|D) / P(H2|D) = infinity

Comparing two simple hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
HHHHH
D: 
H1, H2: 
“fair coin”, “always heads”
P(D|H1) = 1/25 
P(H1) =
999/1000
P(H2) =  
P(D|H2) = 1 
1/1000

P(H1|D) / P(H2|D) ≈ 30

Comparing two simple hypotheses

P(H1|D)           P(D|H1)          P(H1)
=                   x
P(H2|D)           P(D|H2)          P(H2)
HHHHHHHHHH
D: 
H1, H2: 
“fair coin”, “always heads”
P(D|H1) = 1/210
P(H1) =
999/1000
P(H2) =  
P(D|H2) = 1
1/1000

P(H1|D) / P(H2|D) ≈ 1

The role of theories
The fact that HHTHT looks representative of 
a fair coin and HHHHH does not reflects our 
implicit theories of how the world works. 
– Easy to imagine how a trick all-heads coin 
could work: high prior probability.
– Hard to imagine how a trick “HHTHT” coin 
could work: low prior probability.

