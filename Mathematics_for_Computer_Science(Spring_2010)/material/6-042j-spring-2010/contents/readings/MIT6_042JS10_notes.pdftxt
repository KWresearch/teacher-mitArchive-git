1 

Mathematics for Computer Science


revised May 9, 2010, 770 minutes 

Prof. Albert R Meyer 
Massachusets Institute of Technology 

Creative Commons 

2010,  Prof. Albert R. Meyer. 

2


Contents 

.
.
.
.
.
.

1  What is a Proof? 
13

.
.
1.1  Mathematical Proofs 
.
.
. . . . . . . . . . . . . . . . . . . . .  13

.
.
.
.
.
.
1.1.1  Problems  .
.
.
. . . . . . . . . . . . . . . . . . . . . . .  14

.
.
.
.
.
.
1.2  Propositions  .
.
.
. . . . . . . . . . . . . . . . . . . . . . .  15

1.3  Predicates 
.
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  18

1.4  The Axiomatic Method  .
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  18

1.5  Our Axioms  .
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  19

1.5.1  Logical Deductions 
.
.
. . . . . . . . . . . . . . . . . . . . .  19

.
.
1.5.2  Patterns of Proof 
.
.
. . . . . . . . . . . . . . . . . . . . . . .  20

1.6  Proving an Implication  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  20

1.6.1  Method #1  .
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  21

1.6.2  Method #2 - Prove the Contrapositive  .  .  .  .  .  .  .  .  .  .  .  .  .  .  22

. . . . . . . . . . . . . . . . . . . . . . .  23

.
1.6.3  Problems  .
.
.
.
.
.
.
1.7  Proving an “If and Only If ” 
.
.
.
. . . . . . . . . . . . . . . . . . . . .  23

1.7.1  Method #1: Prove Each Statement Implies the Other  .  .  .  .  .  .  23

1.7.2  Method #2: Construct a Chain of Iffs  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  23

. . . . . . . . . . . . . . . . . . . . . . .  24

.
.
.
.
.
.
.
1.8  Proof by Cases  .
.
. . . . . . . . . . . . . . . . . . . . . . .  25

.
.
.
1.8.1  Problems  .
.
.
.
.
1.9  Proof by Contradiction  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  26

. . . . . . . . . . . . . . . . . . . . . . .  27

.
.
.
.
.
.
.
1.9.1  Problems  .
1.10  Good Proofs in Practice  .
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  29


31

2  The Well Ordering Principle 
2.1  Well Ordering Proofs  .
. . . . . . . . . . . . . . . . . . . . .  31

.
.
.
.
.
.
2.2  Template for Well Ordering Proofs  . . . . . . . . . . . . . . . . . . . .  32

. . . . . . . . . . . . . . . . . . . . . . .  33

.
.
.
.
2.2.1  Problems  .
.
.
.
2.3  Summing the Integers 
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  34

. . . . . . . . . . . . . . . . . . . . . . .  35

.
.
.
.
.
.
.
2.3.1  Problems  .
2.4  Factoring into Primes  .
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  35


3  Propositional Formulas 
3.1  Propositions from Propositions  .
3.1.1  “Not”, “And”, and “Or ”  .

37

. . . . . . . . . . . . . . . . . . . . .  38

. . . . . . . . . . . . . . . . . . . . .  38


3 

4 

CONTENTS 

.
.
. . . . . . . . . . . . . . . . . . . . .  39

.
.
.
3.1.2  “Implies” 
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  40

.
.
.
3.1.3  “If and Only If ”  .
. . . . . . . . . . . . . . . . . . . . . . .  40

.
.
.
.
.
.
.
3.1.4  Problems  .
3.2  Propositional Logic in Computer Programs  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  41

3.2.1  Cryptic Notation  .
.
.
. . . . . . . . . . . . . . . . . . . . . . .  42

3.2.2  Logically Equivalent Implications 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  43

. . . . . . . . . . . . . . . . . . . . . . .  46

.
.
.
.
.
.
.
3.2.3  Problems  .

51

4  Mathematical Data Types 
. . . . . . . . . . . . . . . . . . . . .  51

.
.
.
.
.
.
.
4.1  Sets  .
.
.
.
.
.
.
.
.
.
4.1.1  Some Popular Sets 
. . . . . . . . . . . . . . . . . . . . . . .  52

.
.
4.1.2  Comparing and Combining Sets  . . . . . . . . . . . . . . . . .  52

. . . . . . . . . . . . . . . . . . . . .  52

.
.
4.1.3  Complement of a Set  .
4.1.4  Power Set 
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  53

.
4.1.5  Set Builder Notation  .
. . . . . . . . . . . . . . . . . . . . .  53

.
. . . . . . . . . . . . . . . . . . . . . . .  54

4.1.6  Proving Set Equalities 
. . . . . . . . . . . . . . . . . . . . . . .  54

.
.
.
.
.
.
.
4.1.7  Problems  .
4.2  Sequences 
.
.
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  55

4.3  Functions .
.
.
.
.
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  55

4.3.1  Function Composition  . . . . . . . . . . . . . . . . . . . . . . .  57

. . . . . . . . . . . . . . . . . . . . . . .  57

4.4  Binary Relations  .
.
.
.
.
.
.
.
4.5  Binary Relations and Functions  .
. . . . . . . . . . . . . . . . . . . . .  58

4.6 
Images and Inverse Images 
.
.
.
. . . . . . . . . . . . . . . . . . . . .  59

4.7  Surjective and Injective Relations  . . . . . . . . . . . . . . . . . . . . .  60

. . . . . . . . . . . . . . . . . . . . . . .  60

.
4.7.1  Relation Diagrams  .
4.8  The Mapping Rule 
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  61

4.9  The sizes of inﬁnite sets 
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  62

Inﬁnities in Computer Science 
4.9.1 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  65

. . . . . . . . . . . . . . . . . . . . . . .  66

.
.
.
.
.
4.9.2  Problems  .
.
.
4.10 Glossary of Symbols 
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . .  71


73

5  First-Order Logic 
5.1  Quantiﬁers .
. . . . . . . . . . . . . . . . . . . . . . .  73

.
.
.
.
.
.
.
.
.
.
5.1.1  More Cryptic Notation  . . . . . . . . . . . . . . . . . . . . . . .  74

5.1.2  Mixing Quantiﬁers  .
.
. . . . . . . . . . . . . . . . . . . . . . .  75

. . . . . . . . . . . . . . . . . . . . .  75

.
.
5.1.3  Order of Quantiﬁers  .
.
5.1.4  Negating Quantiﬁers  .
.
. . . . . . . . . . . . . . . . . . . . .  76

. . . . . . . . . . . . . . . . . . . . . . .  76

.
.
.
.
.
.
.
5.1.5  Validity .
.
5.1.6  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  78

.
.
.
5.2  The Logic of Sets 
. . . . . . . . . . . . . . . . . . . . .  81

.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  81

5.2.1  Russell’s Paradox  .
.
.
5.2.2  The ZFC Axioms for Sets 
. . . . . . . . . . . . . . . . . . . . .  81

5.2.3  Avoiding Russell’s Paradox  . . . . . . . . . . . . . . . . . . . .  83

5.2.4  Power sets are strictly bigger  . . . . . . . . . . . . . . . . . . .  83

5.2.5  Does All This Really Work?  . . . . . . . . . . . . . . . . . . . .  84


CONTENTS 

5 

5.2.6  Large Inﬁnities in Computer Science  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  85

5.2.7  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  85

. . . . . . . . . . . . . . . . . . . . .  89

.
.
.
.
.
.
.
5.3  Glossary of Symbols 

91

6  Induction 
. . . . . . . . . . . . . . . . . . . . .  92

.
.
.
.
.
.
.
6.1  Ordinary Induction  .
6.1.1  Using Ordinary Induction  . . . . . . . . . . . . . . . . . . . . .  92

6.1.2  A Template for Induction Proofs  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  93

. . . . . . . . . . . . . . . . . . . . . . .  94

.
.
.
6.1.3  A Clean Writeup 
6.1.4  Courtyard Tiling 
.
.
.
. . . . . . . . . . . . . . . . . . . . . . .  94

6.1.5  A Faulty Induction Proof 
. . . . . . . . . . . . . . . . . . . . .  97

. . . . . . . . . . . . . . . . . . . . . . .  98

.
.
.
.
.
.
.
6.1.6  Problems  .
.
.
6.2  Strong Induction 
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 102

6.2.1  Products of Primes  .
.
. . . . . . . . . . . . . . . . . . . . . . . 103

.
.
6.2.2  Making Change  .
. . . . . . . . . . . . . . . . . . . . . 104

.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 104

.
6.2.3  The Stacking Game  .
. . . . . . . . . . . . . . . . . . . . . . . 106

6.2.4  Problems  .
.
.
.
.
.
.
.
Induction versus Well Ordering  .
. . . . . . . . . . . . . . . . . . . . . 107


6.3 

109

7  Partial Orders 
7.1  Axioms for Partial Orders 
. . . . . . . . . . . . . . . . . . . . . . . 109

.
.
7.2  Representing Partial Orders by Set Containment  .  .  .  .  .  .  .  .  .  .  .  .  111

7.2.1  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 112

. . . . . . . . . . . . . . . . . . . . . . . 113

.
.
.
.
.
.
.
7.3  Total Orders  .
.
.
. . . . . . . . . . . . . . . . . . . . . . . 114

.
.
.
.
.
.
.
7.3.1  Problems  .
. . . . . . . . . . . . . . . . . . . . . . . 116

.
.
.
.
.
.
.
7.4  Product Orders 
.
7.4.1  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 117

. . . . . . . . . . . . . . . . . . . . . . . 117

7.5  Scheduling .
.
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 119

7.5.1  Parallel Task Scheduling  .
.
.
.
.
.
.
.
7.6  Dilworth’s Lemma 
.
. . . . . . . . . . . . . . . . . . . . . 121

7.6.1  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 122


129

8  Directed graphs 
.
. . . . . . . . . . . . . . . . . . . . . 129

.
.
.
8.1  Digraphs .
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 130

.
.
8.1.1  Paths in Digraphs  .
8.2  Picturing Relational Properties 
. . . . . . . . . . . . . . . . . . . . . 130

.
. . . . . . . . . . . . . . . . . . . . . . . 131

.
.
8.3  Composition of Relations 
. . . . . . . . . . . . . . . . . . . . . . . 131

.
.
8.4  Directed Acyclic Graphs  .
8.4.1  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 132


135

9  State Machines 
. . . . . . . . . . . . . . . . . . . . . . . 135

.
.
.
9.1  State machines  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 135

.
.
.
9.1.1  Basic deﬁnitions 
9.1.2  Reachability and Preserved Invariants  .  .  .  .  .  .  .  .  .  .  .  .  .  .  137

9.1.3  Sequential algorithm examples  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  140


6 

CONTENTS 

. . . . . . . . . . . . . . . . . . . . . . . 144

9.1.4  Derived Variables  .
.
.
. . . . . . . . . . . . . . . . . . . . . . . 145

9.1.5  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 156

9.2  The Stable Marriage Problem 
.
.
. . . . . . . . . . . . . . . . . . . . . 156

.
.
9.2.1  The Problem  .
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 158

9.2.2  The Mating Ritual 
.
.
9.2.3  A State Machine Model 
.
. . . . . . . . . . . . . . . . . . . . . 158

9.2.4  There is a Marriage Day  .
. . . . . . . . . . . . . . . . . . . . . 159

9.2.5  They All Live Happily Every After...  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  159

. . . . . . . . . . . . . . . . . . . . . 160

.
.
...Especially the Boys  .
9.2.6 
9.2.7  Applications .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 162

. . . . . . . . . . . . . . . . . . . . . . . 163

.
.
.
.
.
.
.
9.2.8  Problems  .

167

10  Simple Graphs 
. . . . . . . . . . . . . . . . . . . . . . . 168

.
.
10.1 Degrees & Isomorphism  .
10.1.1  Deﬁnition of Simple Graph  . . . . . . . . . . . . . . . . . . . . 168

.
10.1.2  Sex in America 
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 169

. . . . . . . . . . . . . . . . . . . . . . . 171

10.1.3  Handshaking Lemma 
10.1.4  Some Common Graphs 
.
. . . . . . . . . . . . . . . . . . . . . 171

10.1.5  Isomorphism 
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 172

.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 174

.
.
.
10.1.6  Problems  .
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 178

10.2  Connectedness  .  .
.
.  .  .
.
10.2.1  Paths and Simple Cycles  .
. . . . . . . . . . . . . . . . . . . . . 178

10.2.2  Connected Components  .
. . . . . . . . . . . . . . . . . . . . . 180

10.2.3  How Well Connected?  . . . . . . . . . . . . . . . . . . . . . . . 181

10.2.4  Connection by Simple Path  . . . . . . . . . . . . . . . . . . . . 181

10.2.5  The Minimum Number of Edges in a Connected Graph  .  .  .  .  182

10.2.6  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 183

. . . . . . . . . . . . . . . . . . . . . 187

.
.
.
.
.
.
10.3 Trees 
.
.
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 188

.
.
.
.
.
10.3.1  Tree Properties 
.
.
.
10.3.2  Spanning Trees  .
.
.
.
. . . . . . . . . . . . . . . . . . . . . 189

10.3.3  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 190

.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 192

10.4  Coloring Graphs .
.
.  .  .
.
10.5  Modelling Scheduling Conﬂicts  .
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 192

10.5.1  Degree-bounded Coloring  . . . . . . . . . . . . . . . . . . . . . 193

10.5.2  Why coloring? .
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 194

. . . . . . . . . . . . . . . . . . . . . . . 195

.
.
.
.
.
.
.
10.5.3  Problems  .
.  .  .
.
10.6  Bipartite Matchings  .  .  .
.
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 198

. . . . . . . . . . . . . . . . . . . . . . . 198

.
10.6.1  Bipartite Graphs 
.
.
10.6.2  Bipartite Matchings  .
.
. . . . . . . . . . . . . . . . . . . . . . . 199

. . . . . . . . . . . . . . . . . . . . . 200

10.6.3  The Matching Condition  .
.
.
10.6.4  A Formal Statement 
.
. . . . . . . . . . . . . . . . . . . . . 202

10.6.5  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 203


11  Recursive Data Types 
11.1 Strings of Brackets 

.

.

.

.

.

.

.

.

207

. . . . . . . . . . . . . . . . . . . . . 207


CONTENTS 

7 

11.2  Arithmetic Expressions  .
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 210

.
.  .  .
.
11.3  Structural Induction on Recursive Data Types  .  .  .  .  .  .  .  .  .  .  .  .  .  .  210

.  .  .  .  .  .  .  .  .  211

11.3.1  Functions on Recursively-deﬁned Data Types 
11.3.2  Recursive Functions on Nonnegative Integers 
.  .  .  .  .  .  .  .  .  212

11.3.3  Evaluation and Substitution with Aexp’s  .  .  .  .  .  .  .  .  .  .  .  .  214

11.3.4  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 218

. . . . . . . . . . . . . . . . . . . . . 223

11.4 Games as a Recursive Data Type 
11.4.1  Tic-Tac-Toe  .
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 224

11.4.2  Inﬁnite Tic-Tac-Toe Games  . . . . . . . . . . . . . . . . . . . . . 227

11.4.3  Two Person Terminating Games 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  227

.
.
.
.
11.4.4  Game Strategies  .
. . . . . . . . . . . . . . . . . . . . . 229

.
. . . . . . . . . . . . . . . . . . . . . . . 230

11.4.5  Problems  .
.
.
.
.
.
.
.
11.5 Induction in Computer Science  .
. . . . . . . . . . . . . . . . . . . . . 231


233

12  Planar Graphs 
. . . . . . . . . . . . . . . . . . . . . . . 233

12.1 Drawing Graphs in the Plane 
. . . . . . . . . . . . . . . . . . . . . . . 235

12.2 Continuous & Discrete Faces 
.  .  .
12.3  Planar Embeddings  .  .  .
.
.
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 237

.
.
.
.
12.4 What outer face? 
. . . . . . . . . . . . . . . . . . . . . 240

.
.
.
.
.
12.5  Euler ’s Formula  .
.
.  .  .
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 240

12.6  Number of Edges versus Vertices  .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 241

. . . . . . . . . . . . . . . . . . . . . 242

.
.
.
.
.
.
12.7 Planar Subgraphs  .
.
.
12.8 Planar 5-Colorability  .
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 243

.
.
.
.
.
12.9 Classifying Polyhedra 
. . . . . . . . . . . . . . . . . . . . . 245

.
12.9.1  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 247


13  Communication Networks 
253

13.1  Communication Networks  .  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 253

.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 253

.
.  .  .
.
13.2  Complete Binary Tree  .  .
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 254

.
.  .  .
.
.  .  .
13.3  Routing Problems  .
13.4 Network Diameter 
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 255

.
.
.
.
.
.
.
13.4.1  Switch Size 
. . . . . . . . . . . . . . . . . . . . . 255

.
. . . . . . . . . . . . . . . . . . . . . . . 255

.
.
.
.
.
.
13.5 Switch Count 
.
.
.
.
.
.
13.6 Network Latency  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 256

13.7  Congestion  .
.
.  .
.
.  .  .
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 256

. . . . . . . . . . . . . . . . . . . . . . . 257

.
.
.
.
.
.
.
.
.
.
.
13.8 2-D Array 
.
.
.
.
.
.
.
.
.
13.9 Butterﬂy 
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 259

13.10Bene ˘s Network 
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 261

13.10.1 Problems  .
.
.  .  .
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 266


273

14  Number Theory 
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 273

14.1  Divisibility  .
.
.  .  .
.
.  .
.
14.1.1  Facts About Divisibility 
.
. . . . . . . . . . . . . . . . . . . . . 274

14.1.2  When Divisibility Goes Bad  . . . . . . . . . . . . . . . . . . . . 276

14.1.3  Die Hard  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 276


8 

CONTENTS 

14.2 The Greatest Common Divisor 
. . . . . . . . . . . . . . . . . . . . . 278

.
14.2.1  Linear Combinations and the GCD  . . . . . . . . . . . . . . . . 278

14.2.2  Properties of the Greatest Common Divisor  .  .  .  .  .  .  .  .  .  .  .  279

14.2.3  One Solution for All Water Jug Problems 
.  .  .  .  .  .  .  .  .  .  .  .  280

14.2.4  The Pulverizer 
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 282

14.2.5  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 283

14.3  The Fundamental Theorem of Arithmetic  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  283

. . . . . . . . . . . . . . . . . . . . . . . 286

.
.
.
.
.
.
.
14.3.1  Problems  .
. . . . . . . . . . . . . . . . . . . . . . . 286

14.4 Alan Turing 
.
.
.
.
.
.
.
.
.
.
14.4.1  Turing’s Code (Version 1.0) 
. . . . . . . . . . . . . . . . . . . . 287

. . . . . . . . . . . . . . . . . . . . . 289

.
14.4.2  Breaking Turing’s Code 
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 289

14.5  Modular Arithmetic .  .  .
.
.  .  .
.
14.5.1  Turing’s Code (Version 2.0) 
. . . . . . . . . . . . . . . . . . . . 291

14.5.2  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 292

14.6 Arithmetic with a Prime Modulus 
. . . . . . . . . . . . . . . . . . . . 293

14.6.1  Multiplicative Inverses  . . . . . . . . . . . . . . . . . . . . . . . 293

. . . . . . . . . . . . . . . . . . . . . 294

14.6.2  Cancellation .
.
.
.
.
.
.
.
14.6.3  Fermat’s Little Theorem  .
. . . . . . . . . . . . . . . . . . . . . 295

14.6.4  Breaking Turing’s Code —Again  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  296

. . . . . . . . . . . . . . . . . . . . . . . 297

.
.
14.6.5  Turing Postscript  .
14.6.6  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 299

14.7  Arithmetic with an Arbitrary Modulus  . .  .  . .  .  . . .  .  . . .  .  . . .  . 299

14.7.1  Relative Primality and Phi  . . . . . . . . . . . . . . . . . . . . . 300

14.7.2  Generalizing to an Arbitrary Modulus  .  .  .  .  .  .  .  .  .  .  .  .  .  .  301

. . . . . . . . . . . . . . . . . . . . . . . 301

.
.
.
14.7.3  Euler ’s Theorem 
. . . . . . . . . . . . . . . . . . . . . . . 303

.
.
.
.
.
.
.
14.7.4  RSA .
.
.
.
14.7.5  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 303


307

15  Sums & Asymptotics 
15.1 The Value of an Annuity  .
. . . . . . . . . . . . . . . . . . . . . . . 307

.
.
15.1.1  The Future Value of Money  . . . . . . . . . . . . . . . . . . . . 308

15.1.2  Closed Form for the Annuity Value 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  309

15.1.3  Inﬁnite Geometric Series  .
. . . . . . . . . . . . . . . . . . . . . 309

. . . . . . . . . . . . . . . . . . . . . . . 310

.
.
.
.
.
.
.
15.1.4  Problems  .
15.2 Book Stacking  .
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 311

15.2.1  Formalizing the Problem 
. . . . . . . . . . . . . . . . . . . . . 311

15.2.2  Evaluating the Sum—The Integral Method  .  .  .  .  .  .  .  .  .  .  .  313

15.2.3  More about Harmonic Numbers  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  315

15.2.4  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 316

15.3  Finding Summation Formulas  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 317

.
15.3.1  Double Sums 
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 319

.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 320

15.4  Stirling’s Approximation  .
15.4.1  Products to Sums  .
.
.
. . . . . . . . . . . . . . . . . . . . . . . 321

.
.
.
.
.
15.5 Asymptotic Notation  .
. . . . . . . . . . . . . . . . . . . . . 322

.
15.5.1  Little Oh  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 322


CONTENTS 

9 

15.5.2  Big Oh  .
.
.
.
.
.
.
.
15.5.3  Theta .
.
.
.
.
.
.
.
.
15.5.4  Pitfalls with Big Oh  .
15.5.5  Problems  .
.
.
.
.
.
.

.
.
.
.

. . . . . . . . . . . . . . . . . . . . . . . 324

. . . . . . . . . . . . . . . . . . . . . . . 325

. . . . . . . . . . . . . . . . . . . . . . . 326

. . . . . . . . . . . . . . . . . . . . . . . 327


331

16  Counting 
. . . . . . . . . . . . . . . . . . . . . . . 331

16.1 Why Count?  .
.
.
.
.
.
.
.
.
.
16.2  Counting One Thing by Counting Another 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  333

. . . . . . . . . . . . . . . . . . . . . . . 333

16.2.1  The Bijection Rule 
.
.
16.2.2  Counting Sequences  .
.
.
. . . . . . . . . . . . . . . . . . . . . 334

.
.
.
16.2.3  The Sum Rule  .
. . . . . . . . . . . . . . . . . . . . . 335

.
.
.
16.2.4  The Product Rule  .
.
.
. . . . . . . . . . . . . . . . . . . . . . . 335

16.2.5  Putting Rules Together  . . . . . . . . . . . . . . . . . . . . . . . 336

16.2.6  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 337

.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 341

16.3  The Pigeonhole Principle  .
16.3.1  Hairs on Heads  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 342

16.3.2  Subsets with the Same Sum  . . . . . . . . . . . . . . . . . . . . 342

16.3.3  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 343

16.4  The Generalized Product Rule  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 344

. . . . . . . . . . . . . . . . . . . . . . . 346

.
.
16.4.1  Defective Dollars  .
. . . . . . . . . . . . . . . . . . . . . . . 346

.
.
16.4.2  A Chess Problem  .
. . . . . . . . . . . . . . . . . . . . . 347

16.4.3  Permutations 
.
.
.
.
.
.
.
16.5  The Division Rule  .
.  .  .
.
.  .  .
.
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 347

16.5.1  Another Chess Problem  .
. . . . . . . . . . . . . . . . . . . . . 348

16.5.2  Knights of the Round Table  . . . . . . . . . . . . . . . . . . . . 349

. . . . . . . . . . . . . . . . . . . . . . . 350

.
.
.
16.5.3  Problems  .
.
.
.
.
16.6 Counting Subsets  .
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 352

. . . . . . . . . . . . . . . . . . . . . 352

.
.
.
.
.
16.6.1  The Subset Rule  .
. . . . . . . . . . . . . . . . . . . . . 353

.
.
.
16.6.2  Bit Sequences  .
.
.
.
. . . . . . . . . . . . . . . . . . . . . 353

.
.
16.7 Sequences with Repetitions 
.
16.7.1  Sequences of Subsets  .
.
.
. . . . . . . . . . . . . . . . . . . . . 353

. . . . . . . . . . . . . . . . . . . . . 354

.
.
16.7.2  The Bookkeeper Rule  .
.
16.7.3  A Word about Words  .
.
. . . . . . . . . . . . . . . . . . . . . 355

.
.
.
.
16.7.4  Problems  .
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 355

16.8  Magic Trick .
.
.  .
.
.  .  .
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 356

. . . . . . . . . . . . . . . . . . . . . 357

.
.
.
.
.
.
16.8.1  The Secret  .
.
.
16.8.2  The Real Secret 
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 359

16.8.3  Same Trick with Four Cards?  . . . . . . . . . . . . . . . . . . . 360

16.8.4  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 361

16.9 Counting Practice: Poker Hands 
. . . . . . . . . . . . . . . . . . . . . 362

16.9.1  Hands with a Four-of-a-Kind  . . . . . . . . . . . . . . . . . . . 362

16.9.2  Hands with a Full House 
. . . . . . . . . . . . . . . . . . . . . 363

16.9.3  Hands with Two Pairs  . . . . . . . . . . . . . . . . . . . . . . . 364

16.9.4  Hands with Every Suit  . . . . . . . . . . . . . . . . . . . . . . . 365

16.9.5  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 366


10 

CONTENTS 

16.10 Inclusion-Exclusion  .  .  .
.
.  .  .
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 368

.
16.10.1 Union of Two Sets 
. . . . . . . . . . . . . . . . . . . . . . . 368

.
.
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 369

.
16.10.2 Union of Three Sets  .  .  .
16.10.3 Union of n Sets 
. . . . . . . . . . . . . . . . . . . . . 371

.
.
.
.
.
.
16.10.4 Computing Euler ’s Function 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  372

16.10.5 Problems  .
.
.  .  .
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 373

.
.
.
16.11Binomial Theorem 
. . . . . . . . . . . . . . . . . . . . . 376

.
.
.
.
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 377

.
.  .  .
16.11.1 Problems  .
.
.
.
.
.
.
.
16.12Combinatorial Proof 
.
. . . . . . . . . . . . . . . . . . . . . 380

16.12.1 Boxing  .
.
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 380

16.12.2 Finding a Combinatorial Proof  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  381

16.12.3 Problems  .
.
.  .  .
.
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 382


385

17  Generating Functions 
17.1  Operations on Generating Functions  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  386

. . . . . . . . . . . . . . . . . . . . . . . 386

.
.
.
.
.
.
.
17.1.1  Scaling .
.
. . . . . . . . . . . . . . . . . . . . . . . 387

.
.
.
.
17.1.2  Addition .
.
.
.
.
.
.
.
.
17.1.3  Right Shifting  .
.
. . . . . . . . . . . . . . . . . . . . . 388

17.1.4  Differentiation .
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 388

. . . . . . . . . . . . . . . . . . . . . . . 390

.
.
.
.
.
.
.
17.1.5  Products  .
17.2 The Fibonacci Sequence 
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 390

17.2.1  Finding a Generating Function  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  391

17.2.2  Finding a Closed Form  . . . . . . . . . . . . . . . . . . . . . . . 392

. . . . . . . . . . . . . . . . . . . . . . . 393

.
.
.
.
.
.
.
17.2.3  Problems  .
17.3  Counting with Generating Functions  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  398

17.3.1  Choosing Distinct Items from a Set  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  398

17.3.2  Building Generating Functions that Count 
.  .  .  .  .  .  .  .  .  .  .  398

17.3.3  Choosing Items with Repetition 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  400

. . . . . . . . . . . . . . . . . . . . . . . 401

17.3.4  Problems  .
.
.
.
.
.
.
.
17.4  An “Impossible” Counting Problem 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  403

17.4.1  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 405


409

18  Introduction to Probability 
18.1  Monty Hall  .
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 409

.
.
.  .
.
.  .  .
18.1.1  The Four Step Method  . . . . . . . . . . . . . . . . . . . . . . . 410

18.1.2  Clarifying the Problem  . . . . . . . . . . . . . . . . . . . . . . . 410

18.1.3  Step 1: Find the Sample Space .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  411

18.1.4  Step 2: Deﬁne Events of Interest 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  413

18.1.5  Step 3: Determine Outcome Probabilities  .  .  .  .  .  .  .  .  .  .  .  .  414

18.1.6  Step 4: Compute Event Probabilities  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  416

18.1.7  An Alternative Interpretation of the Monty Hall Problem  .  .  .  417

18.1.8  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 417

18.2  Set Theory and Probability  .  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 419

. . . . . . . . . . . . . . . . . . . . . . . 420

18.2.1  Probability Spaces 
.
.
18.2.2  An Inﬁnite Sample Space 
. . . . . . . . . . . . . . . . . . . . . 421


CONTENTS 

11 

. . . . . . . . . . . . . . . . . . . . . . . 423

.
.
.
.
18.2.3  Problems  .
.
.
.
18.3  Conditional Probability  .
.
.  .  .
.
.  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 425

18.3.1  The “Halting Problem” 
. . . . . . . . . . . . . . . . . . . . . 426

.
18.3.2  Why Tree Diagrams Work  . . . . . . . . . . . . . . . . . . . . . 428

18.3.3  The Law of Total Probability 
. . . . . . . . . . . . . . . . . . . 429

18.3.4  Medical Testing  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 430

. . . . . . . . . . . . . . . . . . . . . . . 432

18.3.5  Conditional Identities 
18.3.6  Discrimination Lawsuit 
.
. . . . . . . . . . . . . . . . . . . . . 433

18.3.7  A Posteriori Probabilities  . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 434

18.3.8  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 436

. . . . . . . . . . . . . . . . . . . . . . . 438

.
.
.
.
.
.
.
18.4 Independence  .
.
. . . . . . . . . . . . . . . . . . . . . 439

18.4.1  Examples 
.
.
.
.
.
.
.
.
.
18.4.2  Working with Independence 
. . . . . . . . . . . . . . . . . . . 439

18.4.3  Mutual Independence  . . . . . . . . . . . . . . . . . . . . . . . 440

18.4.4  Pairwise Independence 
. . . . . . . . . . . . . . . . . . . . . 440

.
. . . . . . . . . . . . . . . . . . . . . . . 442

.
.
.
18.4.5  Problems  .
.
.
.
.
18.5 The Birthday Principle  .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 442


445

19  Random Processes 
. . . . . . . . . . . . . . . . . . . . . . . 445

19.1 Gamblers’ Ruin  .
.
.
.
.
.
.
.
19.1.1  A Recurrence for the Probability of Winning 
.  .  .  .  .  .  .  .  .  .  447

. . . . . . . . . . . . . . . . . . . . . . . 449

.
19.1.2  Intuition .
.
.
.
.
.
.
19.1.3  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 449

. . . . . . . . . . . . . . . . . . . . . . . 451

19.2 Random Walks on Graphs  .
.
19.2.1  A First Crack at Page Rank 
. . . . . . . . . . . . . . . . . . . . 452

19.2.2  Random Walk on the Web Graph  . . . . . . . . . . . . . . . . . 453

19.2.3  Stationary Distribution & Page Rank  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  454

. . . . . . . . . . . . . . . . . . . . . . . 455

.
.
.
.
.
.
.
19.2.4  Problems  .

459

20  Random Variables 
. . . . . . . . . . . . . . . . . . . . . 459

.
.
20.1 Random Variable Examples  .
20.1.1  Indicator Random Variables  . . . . . . . . . . . . . . . . . . . . 460

20.1.2  Random Variables and Events 
. . . . . . . . . . . . . . . . . . 460

.
20.1.3  Independence .
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 461

20.2  Probability Distributions  .
.  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 462

. . . . . . . . . . . . . . . . . . . . . . . 464

20.2.1  Bernoulli Distribution 
. . . . . . . . . . . . . . . . . . . . . 464

.
.
20.2.2  Uniform Distribution  .
.
20.2.3  The Numbers Game 
.
.
. . . . . . . . . . . . . . . . . . . . . 464

20.2.4  Binomial Distribution 
. . . . . . . . . . . . . . . . . . . . . . . 467

. . . . . . . . . . . . . . . . . . . . . . . 469

.
.
.
.
.
.
.
20.2.5  Problems  .
20.3  Average & Expected Value  .  .  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 471

20.3.1  Expected Value of an Indicator Variable  .  .  .  .  .  .  .  .  .  .  .  .  .  472

20.3.2  Conditional Expectation  .
. . . . . . . . . . . . . . . . . . . . . 473

. . . . . . . . . . . . . . . . . . . . . 474

20.3.3  Mean Time to Failure  .
.
.
20.3.4  Linearity of Expectation  .
. . . . . . . . . . . . . . . . . . . . . 475


12 

CONTENTS 

20.3.5  The Expected Value of a Product  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  479

20.3.6  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 481


489

21  Deviation from the Mean 
. . . . . . . . . . . . . . . . . . . . . . . 489

.
.
.
.
.
.
21.1 Why the Mean?  .
.
.
.
. . . . . . . . . . . . . . . . . . . . . 489

.
.
.
.
.
21.2 Markov’s Theorem 
.
21.2.1  Applying Markov’s Theorem  . . . . . . . . . . . . . . . . . . . 491

21.2.2  Markov’s Theorem for Bounded Variables 
.  .  .  .  .  .  .  .  .  .  .  491

. . . . . . . . . . . . . . . . . . . . . . . 492

.
.
.
.
21.2.3  Problems  .
.
.
.
21.3 Chebyshev’s Theorem 
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 492

21.3.1  Variance in Two Gambling Games  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  493

. . . . . . . . . . . . . . . . . . . . . . . 494

.
21.3.2  Standard Deviation  .
. . . . . . . . . . . . . . . . . . . . . 496

.
21.4 Properties of Variance 
.
.
.
.
.
21.4.1  A Formula for Variance 
.
. . . . . . . . . . . . . . . . . . . . . 496

21.4.2  Variance of Time to Failure 
. . . . . . . . . . . . . . . . . . . . 497

21.4.3  Dealing with Constants 
. . . . . . . . . . . . . . . . . . . . . 498

.
. . . . . . . . . . . . . . . . . . . . . . . 498

.
.
21.4.4  Variance of a Sum  .
21.4.5  Problems  .
.
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . . . 499

21.5  Estimation by Random Sampling  .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 501

. . . . . . . . . . . . . . . . . . . . . . . 502

.
21.5.1  Sampling .
.
.
.
.
.
.
. . . . . . . . . . . . . . . . . . . . . 503

21.5.2  Matching Birthdays 
.
.
.
21.5.3  Pairwise Independent Sampling 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  504

21.6  Conﬁdence versus Probability  . . .  .  . . .  .  . .  .  . . .  .  . . .  .  . . .  . 506

. . . . . . . . . . . . . . . . . . . . . . . 507

.
.
.
.
.
.
.
21.6.1  Problems  .

Index 

512


Chapter 1 

What is a Proof? 

1.1  Mathematical Proofs 

A proof is a method of establishing truth.  What constitutes a proof differs among 
ﬁelds. 

•	 Legal  truth  is  decided  by  a  jury  based  on  allowable  evidence  presented  at 
trial. 

•	 Authoritative truth is speciﬁed by a trusted person or organization. 

•	 Scientiﬁc truth1  is conﬁrmed by experiment. 

•	 Probable truth is established by statistical analysis of sample data. 

•	 Philosophical proof involves careful exposition and persuasion typically based 
on  a  series  of  small,  plausible  arguments.  The  best  example  begins  with 
“Cogito  ergo  sum,”  a  Latin  sentence  that  translates  as  “I  think,  therefore  I 
am.”  It comes from the beginning of a 17th century essay by the mathemati­
cian/philospher, Ren ´e Descartes, and it is one of the most famous quotes in 
the world: do a web search on the phrase and you will be ﬂooded with hits. 
Deducing your existence from the fact that you’re thinking about your exis­
tence  is  a  pretty  cool  and  persuasive-sounding  ﬁrst  axiom.  However,  with 
just a few more lines of argument in this vein, Descartes goes on to conclude 
that  there  is  an  inﬁnitely  beneﬁcent  God.  Whether  or  not  you  believe  in  a 
beneﬁcent God, you’ll probably agree that any very short proof of God’s ex­
istence is bound to be far-fetched.  So even in masterful hands, this approach 
is not reliable. 
1Actually,  only  scientiﬁc  falsehood  can  be  demonstrated  by  an  experiment —when  the  experiment 
fails to behave as predicted.  But no amount of experiment can conﬁrm that the next experiment won’t 
fail.  For  this  reason,  scientists  rarely  speak of  truth,  but  rather of  theories  that  accurately predict past, 
and anticipated future, experiments. 

13 

14 

CHAPTER 1.  WHAT IS A PROOF? 

Mathematics also has a speciﬁc notion of “proof.” 

Deﬁnition.  A formal proof  of a proposition is a chain of logical deductions leading to 
the proposition from a base set of axioms. 

The  three  key  ideas  in  this deﬁnition  are  highlighted:  proposition,  logical de­
duction, and axiom.  In the next sections, we’ll discuss these three ideas along with 
some basic ways of organizing proofs. 

1.1.1  Problems 
Class Problems 

Problem 1.1. 
Identify exactly where the bugs are in each of the following bogus proofs.2 
(a)  Bogus Claim:  1/8 > 1/4. 

Bogus proof. 

3 > 2

3 log10 (1/2) > 2 log10 (1/2)

log10 (1/2)3  >  log10 (1/2)2

(1/2)3  > (1/2)2 ,


and the claim now follows by the rules for multiplying fractions. 

(b)  Bogus proof :  1¢ = $0.01 = ($0.1)2  = (10¢)2  = 100¢ = $1.  � 
(c)  Bogus Claim:  If a and b are two equal real numbers, then a = 0. 

Bogus proof. 

a  =  b

a 2  =  ab

a 2  − b2  =  ab − b2

(a − b)(a + b) = (a − b)b 
a + b  =  b 
a  = 0. 

� 

� 

2 From Stueben, Michael and Diane Sandford. Twenty Years Before the Blackboard, Mathematical Asso­
ciation of America, ©1998. 

1.2.  PROPOSITIONS 

15 

Problem 1.2. 
It’s a fact that the Arithmetic Mean is at least as large the Geometric Mean, namely, 
a + b  √
≥ 
2 

ab

for  all  nonnegative  real  numbers  a  and  b.  But  there’s  something  objectionable 
about  the  following proof  of  this  fact.  What’s  the  objection,  and  how would  you 
ﬁx it? 

Bogus proof. 

a + b  ?  √
≥ 
ab, 
2 
√
a + b ≥ 2
? 
ab, 
a 2  + 2ab + b2  ≥ 4ab, 
? 
a 2  − 2ab + b2  ≥ 0, 
? 
so 
(a − b)2  ≥ 0 
which we know is true. 
The last statement is true because a − b is a real number, and the square of a real 
� 
number is never negative. This proves the claim. 

so 

so

so 

Problem 1.3. 
Albert announces that he plans a surprise 6.042 quiz next week. His students won­
der if the quiz could be next Friday.  The students realize that it obviously cannot, 
because if it hadn’t been given before Friday, everyone would know that there was 
only Friday left on which to give it, so it wouldn’t be a surprise any more. 
So  the  students  ask  whether  Albert  could  give  the  surprise  quiz  Thursday? 
They  observe  that  if  the  quiz  wasn’t  given  before  Thursday,  it  would  have  to  be 
given  on  the  Thursday,  since  they  already  know  it  can’t  be  given  on  Friday.  But 
having  ﬁgured  that  out,  it  wouldn’t  be  a  surprise  if  the  quiz  was  on  Thursday 
either. Similarly, the students reason that the quiz can’t be on Wednesday, Tuesday, 
or Monday.  Namely,  it’s  impossible  for Albert  to give  a  surprise quiz next week. 
All the students now relax, having concluded that Albert must have been blufﬁng. 
And since no one expects the quiz, that’s why, when Albert gives it on Tuesday 
next week, it really is a surprise! 
What do you think is wrong with the students’ reasoning? 

1.2  Propositions 

Deﬁnition.  A proposition is a statement that is either true or false. 

16 

CHAPTER 1.  WHAT IS A PROOF? 

This  deﬁnition  sounds  very  general,  but  it  does  exclude  sentences  such  as, 
“Wherefore art  thou Romeo?”  and “Give me an A!”.  But not all propositions are 
mathematical.  For example, “Albert’s wife’s name  is  ‘Irene’ ” happens  to be  true, 
and could be proved with legal documents and testimony of their children, but it’s 
not a mathematical statement. 
Mathematically  meaningful  propositions  must  be  about  well-deﬁned  mathe­
matical objects like numbers, sets, functions, relations, etc., and they must be stated 
using mathematically precise language. We can illustrate this with a few examples. 
Proposition 1.2.1.  2 + 3 = 5. 

This proposition is true. 
A prime is an integer greater than one that is not divisible by any integer greater 
than 1 besides itself, for example, 2, 3, 5, 7, 11, . . . . 
Proposition 1.2.2.  For every nonnegative integer, n, the value of n2  + n + 41 is prime. 
Let’s try some numerical experimentation to check this proposition. Let 3 

p(n) ::= n 2  + n + 41. 

(1.1) 

We  begin  with  p(0)  =  41  which  is  prime.  p(1)  =  43  which  is  prime.  p(2)  =  47 
which is prime.  p(3) = 53 which is prime.  . . . p(20) = 461 which is prime. Hmmm, 
starts  to  look  like a plausible claim.  In fact we can keep checking  through n  =  39 
and conﬁrm that p(39) = 1601 is prime. 
· 
But p(40) = 402  + 40 + 41 = 41  41, which is not prime.  So it’s not true that the 
expression  is prime  for all nonnegative  integers.  In fact,  it’s not hard to show that 
no nonconstant polynomial with  integer coefﬁcients can map all natural numbers 
into prime numbers.  The point is that in general you can’t check a claim about an 
inﬁnite  set  by  checking  a  ﬁnite  set  of  its  elements,  no matter  how  large  the  ﬁnite 
set. 
By the way, propositions like this about all numbers or other things are so com­
mon  that  there  is  a  special  notation  for  it.  With  this  notation,  Proposition  1.2.2 
would be 
∀n ∈ N. p(n) is prime. 
(1.2) 
Here the symbol ∀ is read “for all”.  The symbol N stands for the set of nonnegative 
integers, namely,  0,  1,  2,  3,  . . . (ask your TA  for  the complete  list).  The symbol “∈ ” 
is  read  as  “is  a member  of ”  or  simply  as  “is  in”.  The  period  after  the  N  is  just  a 
separator between phrases. 
Here are two even more extreme examples: 
Proposition 1.2.3.  a4 + b4 + c4  = d4  has no solution when a, b, c, d are positive integers. 

Euler  (pronounced  “oiler ”)  conjectured  this  in  1769.  But  the  proposition was 
proven  false 218 years  later by Noam Elkies at  a  liberal arts  school up Mass Ave. 
The solution he found was a = 95800, b = 217519, c = 414560, d = 422481. 
3 The symbol ::= means “equal by deﬁnition.”  It’s always ok to simply write “=” instead of ::=, but 
reminding the reader that an equality holds by deﬁnition can be helpful. 

1.2.  PROPOSITIONS 

17 

In logical notation, Proposition 1.2.3 could be written, 
∀a ∈ Z+ ∀b ∈ Z+ ∀c ∈ Z+ ∀d ∈ Z+ 4  + b4  + c 4  = d4 
. a 
. 
Here,  Z+  is  a  symbol  for  the  positive  integers.  Strings  of  ∀’s  like  this  are usually 
abbreviated for easier reading: 
∀a, b, c, d ∈ Z+ . a 4  + b4  + c 4  =�
d4 . 
Proposition 1.2.4.  313(x3  + y3 ) = z 3  has no solution when x, y , z  ∈ Z+ . 
This  proposition  is  also  false,  but  the  smallest  counterexample  has more  than 
1000 digits! 
Proposition 1.2.5.  Every map can be colored with 4 colors so that adjacent4  regions have 
different colors. 
This  proposition  is  true  and  is  known  as  the  “Four-Color  Theorem”.  However, 
there have been many incorrect proofs, including one that stood for 10 years in the 
late 19th century before the mistake was found. An extremely laborious proof was 
ﬁnally  found  in  1976 by mathematicians Appel  and Haken, who used  a  complex 
computer program to categorize the four-colorable maps; the program left a couple 
of thousand maps uncategorized, and these were checked by hand by Haken and 
his assistants—including his 15-year-old daughter. There was a lot of debate about 
whether this was a legitimate proof:  the proof was too big to be checked without a 
computer, and no one could guarantee that the computer calculated correctly, nor 
did  anyone  have  the  energy  to  recheck  the  four-colorings  of  thousands  of  maps 
that were done by hand.  Finally,  about ﬁve years  ago,  a mostly  intelligible proof 
of the Four-Color Theorem was found, though a computer is still needed to check 
colorability of several hundred special maps (see 
http://www.math.gatech.edu/˜thomas/FC/fourcolor.html).  5 
Proposition  1.2.6  (Goldbach).  Every  even  integer  greater  than  2  is  the  sum  of  two 
primes. 
No one knows whether this proposition is true or false.  It is known as Goldbach’s 
Conjecture, and dates back to 1742. 
For  a  computer  scientist,  some  of  the most  important  things  to  prove  are  the 
“correctness”  programs  and  systems —whether  a  program  or  system  does  what 
it’s supposed to.  Programs are notoriously buggy, and there’s a growing commu­
nity of researchers and practitioners trying to ﬁnd ways to prove program correct­
ness. These efforts have been successful enough in the case of CPU chips that they 
are  now  routinely  used  by  leading  chip manufacturers  to  prove  chip  correctness 
and avoid mistakes like the notorious Intel division bug in the 1990’s. 
Developing mathematical methods to verify programs and systems remains an 
active research area. We’ll consider some of these methods later in the course. 
4 Two  regions  are  adjacent  only when  they  share  a  boundary  segment  of positive  length.  They  are 
not considered to be adjacent if their boundaries meet only at a few points. 
5 The  story  of  the  Four-Color Proof  is  told  in  a well-reviewed popular  (non-technical)  book:  “Four 
Colors Sufﬁce.  How the Map Problem was Solved.”  Robin Wilson.  Princeton Univ.  Press, 2003, 276pp. 
ISBN 0-691-11533-8. 

�
18	

CHAPTER 1.  WHAT IS A PROOF? 

1.3  Predicates 

A predicate is a proposition whose truth depends on the value of one or more vari­
ables.  Most  of  the  propostions  above  were  deﬁned  in  terms  of  predicates.  For 
example, 

“n is a perfect square” 

is  a  predicate  whose  truth  depends  on  the  value  of  n.  The  predicate  is  true  for 
n  = 4  since  four  is  a perfect  square,  but  false  for n  = 5  since ﬁve  is not  a perfect 
square. 
Like other propositions, predicates are often named with a letter.  Furthermore, 
a  function-like notation  is used  to denote  a predicate  supplied with  speciﬁc vari­
able values.  For example, we might name our earlier predicate P : 

P (n) ::= “n is a perfect square” 

Now P (4) is true, and P (5) is false. 
This  notation  for  predicates  is  confusingly  similar  to  ordinary  function  nota­
tion.  If  P  is  a  predicate,  then  P (n)  is  either  true  or  false,  depending  on  the  value 
of  n.  On  the  other  hand,  if  p  is  an  ordinary  function,  like  n2  + 1,  then  p(n)  is  a 
numerical quantity. Don’t confuse these two! 

1.4  The Axiomatic Method 

The standard procedure for establishing truth in mathematics was invented by Eu­
clid, a mathematician working in Alexandria, Egypt around 300 BC. His idea was 
to begin with ﬁve assumptions about geometry, which seemed undeniable based on 
direct  experience.  (For  example,  “There  is  a  straight  line  segment  between  every 
pair of points.)  Propositions  like  these  that are simply accepted as  true are called 
axioms. 
Starting  from  these  axioms,  Euclid  established  the  truth  of  many  additional 
propositions  by  providing  “proofs”.  A  proof  is  a  sequence  of  logical  deductions 
from  axioms  and  previously-proved  statements  that  concludes with  the  proposi­
tion  in question.  You probably wrote many proofs  in high school geometry class, 
and you’ll see a lot more in this course. 
There  are  several  common  terms  for  a proposition  that  has  been proved.  The 
different terms hint at the role of the proposition within a larger body of work. 

•	 Important propositions are called theorems. 

•	 A lemma is a preliminary proposition useful for proving later propositions. 

•	 A  corollary  is  a  proposition  that  follows  in  just  a  few  logical  steps  from  a 
theorem. 

1.5.  OUR AXIOMS 

19 

The deﬁnitions  are  not  precise.  In  fact,  sometimes  a  good  lemma  turns  out  to  be 
far more important than the theorem it was originally used to prove. 
Euclid’s  axiom-and-proof  approach,  now  called  the  axiomatic  method,  is  the 
foundation  for  mathematics  today.  In  fact,  just  a  handful  of  axioms,  called  the 
axioms Zermelo-Frankel with Choice (ZFC), together with a few logical deduction 
rules, appear to be sufﬁcient to derive essentially all of mathematics. We’ll examine 
these in Chapter 4. 

1.5  Our Axioms 

The ZFC axioms are important in studying and justifying the foundations of math­
ematics, but for practical purposes, they are much too primitive. Proving theorems 
in ZFC  is a  little  like writing programs  in byte  code  instead of a  full-ﬂedged pro­
gramming  language  —by  one  reckoning,  a  formal  proof  in  ZFC  that  2 + 2  =  4 
requires more  than  20,000  steps!  So  instead  of  starting with  ZFC, we’re  going  to 
take a huge set of axioms as our foundation: we’ll accept all familiar facts from high 
school math! 
This will give us a quick launch, but you may ﬁnd this imprecise speciﬁcation 
of  the  axioms  troubling  at  times.  For  example,  in  the midst  of  a  proof,  you may 
ﬁnd yourself wondering, “Must I prove this little fact or can I take it as an axiom?” 
Feel  free  to  ask  for  guidance,  but  really  there  is  no  absolute  answer.  Just  be  up 
front  about  what  you’re  assuming,  and  don’t  try  to  evade  homework  and  exam 
problems by declaring everything an axiom! 

1.5.1  Logical Deductions 
Logical deductions or inference rules are used to prove new propositions using pre­
viously proved ones. 
A fundamental inference rule is modus ponens.  This rule says that a proof of P 
together with a proof that P  IM P L I E S Q is a proof of Q. 
Inference rules are sometimes written in a funny notation.  For example, modus 
ponens is written: 

Rule. 

P ,  P  IM P L I E S Q

Q


When the statements above the line, called the antecedents, are proved, then we 
can  consider  the  statement  below  the  line,  called  the  conclusion  or  consequent,  to 
also be proved. 
A key requirement of an inference rule is that it must be sound:  any assignment 
of truth values that makes all the antecedents true must also make the consequent 
true.  So  if we  start  off with  true  axioms  and  apply  sound  inference  rules,  every­
thing we prove will also be true. 
There are many other natural, sound inference rules, for example: 

20 

Rule. 

Rule. 

On the other hand, 

Rule. 

CHAPTER 1.  WHAT IS A PROOF? 

P  IM P L I E S Q,  Q IM P L I E S R 
P  IM P L I E S R 

NO T(P ) IM P L I E S  NOT(Q) 
Q IM P L I E S P 

NO T(P ) IM P L I E S  NOT(Q) 
P  IM P L I E S Q 

is  not  sound:  if P  is  assigned T  and Q  is  assigned F,  then  the  antecedent  is  true 
and the consequent is not. 
Note  that  a  propositional  inference  rule  is  sound  precisely when  the  conjunc­
tion (AND) of all its antecedents implies its consequent. 
As with axioms, we will not be too formal about the set of legal inference rules. 
Each step  in a proof should be clear and “logical”;  in particular, you should state 
what previously proved facts are used to derive each new conclusion. 

1.5.2  Patterns of Proof 

In  principle,  a  proof  can  be  any  sequence  of  logical  deductions  from  axioms  and 
previously  proved  statements  that  concludes  with  the  proposition  in  question. 
This  freedom  in  constructing  a  proof  can  seem  overwhelming  at  ﬁrst.  How  do 
you even start a proof? 
Here’s  the good news:  many proofs  follow one of  a handful of  standard  tem­
plates. Each proof has it own details, of course, but these templates at least provide 
you with an outline to ﬁll in.  We’ll go through several of these standard patterns, 
pointing out the basic idea and common pitfalls and giving some examples. Many 
of  these  templates ﬁt  together;  one may give you a  top-level outline while others 
help you at the next level of detail.  And we’ll show you other, more sophisticated 
proof techniques later on. 
The recipes below are very speciﬁc at times, telling you exactly which words to 
write down  on  your piece  of paper.  You’re  certainly  free  to  say  things  your  own 
way instead; we’re just giving you something you could say so that you’re never at 
a complete loss. 

1.6  Proving an Implication 

Propositions of  the  form “If P ,  then Q” are called  implications.  This  implication  is 
often rephrased as “P  IM P L I E S Q.” 
Here are some examples: 

21 

1.6.  PROVING AN IMPLICATION	
� 
� 
� 
•	 (Quadratic Formula) If ax2  + bx + c = 0 and a = 0
, then 
b2  − 4ac  /2a. 
x =  −b ± 
•	 (Goldbach’s Conjecture) If n is an even integer greater than 2, then n is a sum 
of two primes. 
•	 If 0 ≤ x ≤ 2, then −x3  + 4x + 1 > 0. 
There are a couple of standard methods for proving an implication. 

1.6.1  Method #1 
In order to prove that P  IM P L I E S Q: 
1.  Write, “Assume P .” 

2.  Show that Q logically follows. 

Example 
Theorem 1.6.1.  If 0 ≤ x ≤ 2, then −x3  + 4x + 1 > 0. 
Before  we  write  a  proof  of  this  theorem,  we  have  to  do  some  scratchwork  to 
ﬁgure out why it is true. 
The  inequality  certainly  holds  for  x  = 0;  then  the  left  side  is  equal  to  1  and 
1  >  0.  As x grows,  the 4x  term  (which  is positive)  initially seems  to have greater 
magnitude  than  −x3  (which  is  negative).  For  example,  when  x  = 1,  we  have 
4x  = 4,  but −x3  =  −1  only.  In  fact,  it  looks  like −x3  doesn’t  begin  to  dominate 
until x > 2.  So it seems the −x3  + 4x part should be nonnegative for all x between 
0 and 2, which would imply that −x3  + 4x + 1 is positive. 
So far, so good.  But we still have to replace all those “seems like” phrases with 
solid,  logical arguments.  We can get a better handle on  the critical −x3  + 4x part 
by factoring it, which is not too hard: 
−x 3  + 4x = x(2 − x)(2 + x) 
Aha! For x between 0 and 2, all of the terms on the right side are nonnegative. And 
a product of nonnegative terms is also nonnegative. Let’s organize this blizzard of 
observations into a clean proof. 
Proof.  Assume 0 ≤ x ≤ 2.  Then x, 2 − x, and 2 + x are all nonnegative.  Therefore, 
the  product  of  these  terms  is  also  nonnegative.  Adding  1  to  this  product  gives  a 
positive number, so: 
x(2 − x)(2 + x) + 1 > 0 
Multiplying out on the left side proves that 
−x 3  + 4x + 1 > 0 

as claimed.	

� 

�
22	

CHAPTER 1.  WHAT IS A PROOF? 

There are a couple points here that apply to all proofs: 

•	 You’ll  often  need  to  do  some  scratchwork while  you’re  trying  to  ﬁgure  out 
the logical steps of a proof.  Your scratchwork can be as disorganized as you 
like—  full  of  dead-ends,  strange  diagrams,  obscene  words,  whatever.  But 
keep your scratchwork separate from your ﬁnal proof, which should be clear 
and concise. 

•	 Proofs  typically  begin  with  the  word  “Proof ”  and  end  with  some  sort  of 
doohickey  like  �  or  “q.e.d”.  The  only  purpose  for  these  conventions  is  to 
clarify where proofs begin and end. 

1.6.2  Method #2 - Prove the Contrapositive 
An implication (“P  IM P L I E S Q”) is logically equivalent to its contrapositive 

NOT(Q) IM P L I E S  NOT(P ) 

Proving  one  is  as  good  as  proving  the  other,  and  proving  the  contrapositive  is 
sometimes easier than proving the original statement.  If so, then you can proceed 
as follows: 

1.  Write, “We prove the contrapositive:”  and then state the contrapositive. 

2.  Proceed as in Method #1. 

Example

√
Theorem 1.6.2.  If r is irrational, then 
r is also irrational.


√
Recall that rational numbers are equal to a ratio of integers and irrational num­
r is also not 
bers are not.  So we must show that if r is not a ratio of integers, then 
a ratio of integers. That’s pretty convoluted! We can eliminate both not’s and make 
the proof straightforward by considering the contrapositive instead. 
√
√
Proof.  We prove the contrapositive:  if 
r is rational, then r is rational. 
Assume that 
r is rational. Then there exist integers a and b such that: 
√

r = 

a
b 

Squaring both sides gives: 

2a
b2 
Since a2  and b2  are integers, r is also rational.	

r = 

� 

1.7.  PROVING AN “IF AND ONLY IF” 

23 

1.6.3  Problems 
Homework Problems 

Problem 1.4. 
Show  that  log7 n  is  either  an  integer  or  irrational,  where  n  is  a  positive  integer. 
Use  whatever  familiar  facts  about  integers  and  primes  you  need,  but  explicitly 
state such facts.  (This problem will be graded on the clarity and simplicity of your 
proof.  If you can’t ﬁgure out how to prove it, ask the staff for help and they’ll tell 
you how.) 

1.7  Proving an “If and Only If” 

Many mathematical  theorems assert  that  two  statements are  logically equivalent; 
that  is,  one holds  if  and  only  if  the  other does.  Here  is  an  example  that has  been 
known for several thousand years: 

Two triangles have the same side lengths if and only if two side lengths 
and the angle between those sides are the same. 

The phrase “if and only if ” comes up so often that it is often abbreviated “iff ”. 

1.7.1  Method #1: Prove Each Statement Implies the Other 
The  statement  “P  I FF  Q”  is  equivalent  to  the  two  statements  “P  IM P L I E S  Q”  and 
“Q IM P L I E S P ”.  So you can prove an “iff ” by proving two implications: 

1.  Write, “We prove P  implies Q and vice-versa.” 

2.  Write, “First, we show P  implies Q.”  Do  this by one of  the methods  in Sec­
tion 1.6. 

3.  Write,  “Now, we show Q  implies P .”  Again, do  this by one of  the methods 
in Section 1.6. 

1.7.2  Method #2: Construct a Chain of Iffs 
In order to prove that P  is true iff Q is true: 

1.  Write, “We construct a chain of if-and-only-if implications.” 

2.  Prove  P  is  equivalent  to  a  second  statement  which  is  equivalent  to  a  third 
statement and so forth until you reach Q. 

This method  sometimes  requires more  ingenuity  than  the ﬁrst,  but  the  result  can 
be a short, elegant proof. 

24 

CHAPTER 1.  WHAT IS A PROOF? 

Example 
� 
The standard deviation of a sequence of values x1 , x2 , . . . , xn  is deﬁned to be: 
(x1  − µ)2  + (x2  − µ)2  + · · · + (xn  − µ)2 
n 

(1.3) 

where µ is the mean of the values: 

µ ::= 

x1  + x2  + · · · + xn 
n 

Theorem  1.7.1.  The  standard  deviation  of  a  sequence  of  values x1 , . . . , xn  is  zero  iff  all 
the values are equal to the mean. 

For example, the standard deviation of test scores is zero if and only if everyone 
scored exactly the class average. 
Proof.  We  construct  a  chain  of  “iff ”  implications,  starting with  the  statement  that 
� 
the standard deviation (1.3) is zero: 
(x1  − µ)2  + (x2  − µ)2  + · · · + (xn  − µ)2 
n 

(1.4) 

= 0. 

Now since zero is the only number whose square root is zero, equation (1.4) holds 
iff 
(x1  − µ)2  + (x2  − µ)2  +  + (xn  − µ)2  = 0. 
· · · 
(1.5)
Now  squares  of  real  numbers  are  always  nonnegative,  so  every  term  on  the  left 
hand side of equation (1.5) is nonnegative. This means that (1.5) holds iff 

Every term on the left hand side of (1.5) is zero. 
But a term (xi  − µ)2  is zero iff xi  = µ, so (1.6) is true iff 

Every xi  equals the mean. 

(1.6) 

� 

1.8  Proof by Cases 

Breaking a complicated proof into cases and proving each case separately is a use­
ful, common proof strategy. Here’s an amusing example. 
Let’s agree that given any two people, either they have met or not.  If every pair 
of people in a group has met, we’ll call the group a club.  If every pair of people in 
a group has not met, we’ll call it a group of strangers. 

Theorem.  Every collection of 6 people includes a club of 3 people or a group of 3 strangers. 

1.8.  PROOF BY CASES 

25 

Proof.  The proof is by case analysis6 .  Let x denote one of the six people.  There are 
two cases: 

1.  Among 5 other people besides x, at least 3 have met x. 

2.  Among the 5 other people, at least 3 have not met x. 

Now  we  have  to  be  sure  that  at  least  one  of  these  two  cases  must  hold,7  but 
that’s easy: we’ve split the 5 people into two groups, those who have shaken hands 
with  x  and  those  who  have  not,  so  one  the  groups  must  have  at  least  half  the 
people. 
Case 1:  Suppose that at least 3 people did meet x.

This case splits into two subcases:


Case 1.1: No pair among those people met each other.  Then these peo­
ple  are  a  group  of  at  least  3  strangers.  So  the  Theorem  holds  in  this 
subcase. 
Case  1.2:  Some  pair  among  those  people  have  met  each  other.  Then 
that  pair,  together  with  x,  form  a  club  of  3  people.  So  the  Theorem 
holds in this subcase. 

This implies that the Theorem holds in Case 1. 
Case 2:  Suppose that at least 3 people did not meet x. 
This case also splits into two subcases: 

Case  2.1:  Every  pair  among  those  people met  each  other.  Then  these 
people  are  a  club  of  at  least  3  people.  So  the  Theorem  holds  in  this 
subcase. 
Case 2.2: Some pair among those people have not met each other. Then 
that pair,  together with  x,  form  a  group  of  at  least  3  strangers.  So  the 
Theorem holds in this subcase. 

This implies that the Theorem also holds in Case 2, and therefore holds in all cases. 
� 

1.8.1  Problems 
Class Problems 

Problem 1.5. 
If we raise an  irrational number to an  irrational power, can the result be rational? 
√
√
2  and arguing by cases. 
2 
Show that it can by considering 

6Describing your approach at the outset helps orient the reader. 
7 Part of a case analysis argument is showing that you’ve covered all the cases. Often this is obvious, 
because the two cases are of the form “P ” and “not P ”. However, the situation above is not stated quite 
so simply. 

26 

CHAPTER 1.  WHAT IS A PROOF? 

Homework Problems 

Problem 1.6. 
For  n  =  40,  the  value  of  polynomial  p(n)  ::= n2  + n + 41  is  not  prime,  as  noted 
in  Chapter  1  of  the  Course  Text.  But  we  could  have  predicted  based  on  general 
principles that no nonconstant polynomial, q(n), with integer coefﬁcients can map 
each nonnegative integer into a prime number. Prove it. 
Hint:  Let  c  ::=  q(0)  be  the  constant  term  of  q .  Consider  two  cases:  c  is  not 
prime,  and c  is prime.  In  the second case, note  that q(cn)  is a multiple of c  for all 
n  ∈  Z.  You may  assume  the  familiar  fact  that  the magnitude  (absolute  value)  of 
any nonconstant polynomial, q(n), grows unboundedly as n grows. 

1.9  Proof by Contradiction 

In a proof by contradiction or indirect proof, you show that if a proposition were false, 
then some false fact would be true.  Since a false fact can’t be true, the proposition 
had better not be false. That is, the proposition really must be true. 
Proof by contradiction is always a viable approach.  However, as the name sug­
gests,  indirect  proofs  can  be  a  little  convoluted.  So  direct  proofs  are  generally 
preferable as a matter of clarity. 
Method:  In order to prove a proposition P  by contradiction: 

1.  Write, “We use proof by contradiction.” 

2.  Write, “Suppose P  is false.” 

3.  Deduce something known to be false (a logical contradiction). 

4.  Write, “This is a contradiction. Therefore, P  must be true.” 

Theorem 1.9.1. 

Example 
Remember that a number is rational if it is equal to a ratio of integers. For example, 
· · · 
√
3.5 = 7/2  and  0.1111 
= 1/9  are  rational  numbers.  On  the  other  hand,  we’ll 
2 is irrational. 
prove by contradiction that 
√

2 is irrational. 
√
Proof.  We  use  proof  by  contradiction.  Suppose  the  claim  is  false;  that  is, 
2 as a fraction n/d in lowest terms. 
rational. Then we can write 
Squaring both sides gives 2 =  n2/d2  and so 2d2  =  n2 .  This  implies  that n  is a 
multiple of 2.  Therefore n2  must be a multiple of 4.  But since 2d2  =  n2 , we know 
2d2  is a multiple of 4 and so d2  is a multiple of 2.  This implies that d is a multiple 
of 2. 
√
So  the numerator and denominator have 2 as a common  factor, which contra­
� 
2 must be irrational. 
dicts the fact that n/d is in lowest terms.  So 

√

2  is 

1.9.  PROOF BY CONTRADICTION 

27 

1.9.1  Problems 
Class Problems 

√
Problem 1.7. 
√
2 is irrational, for ex­
Generalize the proof from lecture (reproduced below) that 
2?  Remember  that  an  irrational  number  is  a  number  that 
3
ample,  how  about 
cannot be expressed as a ratio of two integers. 

√

Theorem. 

2 is an irrational number. 

√
2 is rational, that is, 
Proof.  The proof is by contradiction:  assume that 
√
n
, 
d 
where  n  and  d  are  integers.  Now  consider  the  smallest  such  positive 
integer denominator, d. We will prove in a moment that the numerator, 
n, and the denominator, d, are both even. This implies that 

(1.7)

2 = 

n/2 
d/2 

is a fraction equal to 
contradiction. 

√
2 with a smaller positive integer denominator, a 
√
√
2  is  rational  leads  to  this  contradic­
Since  the  assumption  that 
2 is indeed irrational. 
tion, the assumption must be false. That is, 
This  italicized  comment on  the  implication of  the  contradic­
tion normally  goes without  saying,  but  since  this  is  the ﬁrst 
6.042 exercise about proof by contradiction, we’ve said it. 

To prove that n and d have 2 as a common factor, we start by squaring 
both sides of (1.7) and get 2 = n2 /d2 , so 

2d2  = n 2 . 

(1.8) 

So 2 is a factor of n2 , which is only possible if 2 is in fact a factor of n. 
This means that n = 2k for some integer, k , so 

n 2  = (2k)2  = 4k2 . 

Combining (1.8) and (1.9) gives 2d2  = 4k2 , so 

d2  = 2k2 . 

(1.9) 

(1.10) 

So  2 is  a factor of  d2 , which  again  is  only  possible  if  2  is  in  fact  also  a 
� 
factor of d, as claimed. 

28 

CHAPTER 1.  WHAT IS A PROOF? 

√
Problem 1.8. 
2 is irrational, taken from the American Mathemat­
Here is a different proof that 
ical Monthly, v.116, #1, Jan.  2009, p.69: 
integer, q >  0, such that �√
2 − 1 � 
q  is a nonnegative integer.  Let q �  ::= �√
2 − 1 � 
√
Clearly 0 < q �  < q .  But an easy computation shows that �√
2 − 1 � 
2 is rational, and choose the least 
Proof.  Suppose for the sake of contradiction that 
q . 
q �  is a nonnega­
� 
tive integer, contradicting the minimality of q . 
(a)  This proof was written for an audience of college teachers, and is a little more 
concise  than  desirable  at  this  point  in  6.042.  Write  out  a  more  complete  version 
which includes an explanation of each step. 

(b)  Now that you have  justiﬁed the steps in this proof, do you have a preference 
for  one  of  these  proofs  over  the  other?  Why?  Discuss  these  questions with  your 
teammates for a few minutes and summarize your team’s answers on your white-
board. 

Problem 1.9. 
Here is a generalization of Problem 1.7 that you may not have thought of: 
· · ·
Lemma 1.9.2.  Let the coefﬁcients of the polynomial a0+a1x+a2x2+ +an−1xm−1+x
m
be integers. Then any real root of the polynomial is either integral or irrational. 
√
(a)  Explain  why  Lemma  1.9.2  immediately  implies  that 
k  is  irrational  when­
m
ever k  is not an mth power of some integer. 

(b)  Collaborate  with  your  tablemates  to  write  a  clear,  textbook  quality  proof  of 
Lemma 1.9.2 on your whiteboard.  (Besides clarity and correctness, textbook qual­
ity  requires  good  English with  proper  punctuation.  When  a  real  textbook writer 
does this, it usually takes multiple revisions; if you’re satisﬁed with your ﬁrst draft, 
you’re probably misjudging.) You may ﬁnd it helpful to appeal to the following: 
Lemma  1.9.3.  If  a prime,  p,  is  a  factor  of  some power  of  an  integer,  then  it  is  a  factor  of 
that integer. 
You may assume Lemma 1.9.3 without writing down  its proof, but see  if you can 
explain why it is true. 

Homework Problems 

Problem 1.10. 
The  fact  that  that  there  are  irrational  numbers  a, b  such  that  ab  is  rational  was 
proved  in  Problem  1.5.  Unfortunately,  that  proof  was  nonconstructive:  it  didn’t 
√
reveal  a  speciﬁc  pair,  a, b,  with  this  property.  But  in  fact,  it’s  easy  to  do  this:  let 
√
2 and b ::= 2 log2 3. 
a ::= 
2  is  irrational, and obviously a = 3.  Finish  the proof  that  this a, b 
We know 
b
pair works, by showing that 2 log2 3 is irrational. 

1.10.  GOOD PROOFS IN PRACTICE 

29 

1.10  Good Proofs in Practice 

One purpose of a proof  is  to  establish  the  truth of an assertion with absolute  cer­
tainty.  Mechanically  checkable  proofs  of  enormous  length  or  complexity  can  ac­
complish this. But humanly intelligible proofs are the only ones that help someone 
understand the subject. Mathematicians generally agree that important mathemat­
ical results can’t be fully understood until their proofs are understood. That is why 
proofs are an important part of the curriculum. 
To be understandable and helpful, more is required of a proof than just logical 
correctness:  a  good  proof must  also  be  clear.  Correctness  and  clarity  usually  go 
together;  a well-written  proof  is more  likely  to  be  a  correct  proof,  since mistakes 
are harder to hide. 
In  practice,  the  notion  of  proof  is  a  moving  target.  Proofs  in  a  professional 
research  journal  are  generally  unintelligible  to  all  but  a  few  experts  who  know 
all  the  terminology  and prior  results used  in  the proof.  Conversely,  proofs  in  the 
ﬁrst weeks of a beginning course  like 6.042 would be regarded as  tediously  long-
winded by a professional mathematician.  In fact, what we accept as a good proof 
later  in  the  term will  be  different  from what we  consider  good  proofs  in  the  ﬁrst 
couple of weeks of  6.042.  But  even  so, we  can offer  some general  tips on writing 
good proofs: 

State your game plan.  A good proof begins by explaining the general line of rea­
soning, for example, “We use case analysis” or “We argue by contradiction.” 

Keep a linear ﬂow.  Sometimes proofs are written like mathematical mosaics, with 
juicy  tidbits  of  independent  reasoning  sprinkled  throughout.  This  is  not 
good.  The  steps  of  an  argument  should  follow  one  another  in  an  intellig­
ble order. 

A proof is an essay, not a calculation.  Many students initially write proofs the way 
they compute integrals. The result is a long sequence of expressions without 
explanation, making it very hard to follow. This is bad. A good proof usually 
looks like an essay with some equations thrown in. Use complete sentences. 

Avoid excessive symbolism.  Your reader is probably good at understanding words, 
but much less skilled at reading arcane mathematical symbols.  So use words 
where you reasonably can. 

Revise and simplify.  Your readers will be grateful. 

Introduce notation thoughtfully.  Sometimes  an  argument  can  be  greatly  simpli­
ﬁed by introducing a variable, devising a special notation, or deﬁning a new 
term. But do this sparingly since you’re requiring the reader to remember all 
that  new  stuff.  And  remember  to  actually  deﬁne  the meanings  of  new  vari­
ables, terms, or notations; don’t just start using them! 

Structure long proofs.  Long programs are usually broken into a hierarchy of smaller 
procedures. Long proofs are much the same. Facts needed in your proof that 

30 

CHAPTER 1.  WHAT IS A PROOF? 

are  easily  stated,  but  not  readily  proved  are  best  pulled  out  and  proved  in 
preliminary  lemmas.  Also,  if  you  are  repeating  essentially  the  same  argu­
ment over and over, try to capture that argument in a general lemma, which 
you can cite repeatedly instead. 

Be wary of the “obvious”.  When  familiar  or  truly  obvious  facts  are  needed  in  a 
proof,  it’s OK  to  label  them  as  such  and  to  not  prove  them.  But  remember 
that what’s  obvious  to  you, may  not  be —and  typically  is  not —obvious  to 
your reader. 
Most especially, don’t use phrases like “clearly” or “obviously” in an attempt 
to bully the reader into accepting something you’re having trouble proving. 
Also, go on the alert whenever you see one of these phrases in someone else’s 
proof. 

Finish.  At  some  point  in  a  proof,  you’ll  have  established  all  the  essential  facts 
you  need.  Resist  the  temptation  to  quit  and  leave  the  reader  to  draw  the 
“obvious” conclusion.  Instead,  tie everything  together yourself and explain 
why the original claim follows. 

The  analogy  between  good  proofs  and  good  programs  extends  beyond  struc­
ture.  The  same  rigorous  thinking  needed  for  proofs  is  essential  in  the  design  of 
critical  computer  systems.  When  algorithms  and  protocols  only  “mostly  work” 
due  to  reliance  on  hand-waving  arguments,  the  results  can  range  from  problem­
atic to catastrophic. An early example was the Therac 25, a machine that provided 
radiation  therapy  to  cancer  victims,  but  occasionally  killed  them  with  massive 
overdoses  due  to  a  software  race  condition.  A more  recent  (August  2004)  exam­
ple  involved  a  single  faulty  command  to  a  computer  system used by United  and 
American Airlines that grounded the entire ﬂeet of both companies— and all their 
passengers! 
It  is a  certainty  that we’ll all one day be at  the mercy of  critical  computer  sys­
tems designed by you and your classmates.  So we really hope that you’ll develop 
the  ability  to  formulate  rock-solid  logical  arguments  that  a  system  actually  does 
what you think it does! 

Chapter 2 

The Well Ordering Principle 

Every nonempty set of nonnegative integers has a smallest element. 

This  statement  is  known  as  The  Well  Ordering  Principle.  Do  you  believe  it? 
Seems  sort  of  obvious,  right?  But  notice  how  tight  it  is:  it  requires  a  nonempty 
set —it’s  false  for  the  empty  set which  has  no  smallest  element  because  it  has  no 
elements  at  all!  And  it  requires  a  set  of  nonnegative  integers  —it’s  false  for  the 
set  of  negative  integers  and  also  false  for  some  sets  of  nonnegative  rationals —for 
example,  the  set  of  positive  rationals.  So,  the  Well  Ordering  Principle  captures 
something special about the nonnegative integers. 

2.1  Well Ordering Proofs 

While the Well Ordering Principle may seem obvious, it’s hard to see offhand why 
it is useful. But in fact, it provides one of the most important proof rules in discrete 
mathematics. 
√
In fact, looking back, we took the Well Ordering Principle for granted in prov­
2 is irrational.  That proof assumed that for any positive integers m and 
ing that 
n, the fraction m/n can be written in lowest terms, that is, in the form m�/n�  where 
m�  and n�  are positive integers with no common factors.  How do we know this is 
always possible? 
Suppose  to  the contrary  that  there were m, n  ∈  Z+  such  that  the  fraction m/n 
cannot be written in lowest terms. Now let C be the set of positive integers that are 
numerators of such  fractions.  Then m  ∈  C ,  so C  is nonempty.  Therefore, by Well 
Ordering, there must be a smallest integer, m0  ∈ C .  So by deﬁnition of C , there is 
an integer n0  > 0 such that 

the fraction 

m0  cannot be written in lowest terms. 
n0 

31 

32 

CHAPTER 2.  THE WELL ORDERING PRINCIPLE 

This means that m0  and n0  must have a common factor, p > 1. But 

m0/p  m0 
= 
, 
n0/p 
n0 

so  any way  of  expressing  the  left hand  fraction  in  lowest  terms would  also work 
for m0 /n0 , which implies 

the fraction 

m0 /p
n0/p 

cannot be in written in lowest terms either. 

So by deﬁnition of C , the numerator, m0/p, is in C .  But m0 /p < m0 , which contra­
dicts the fact that m0  is the smallest element of C . 
Since  the  assumption  that  C  is  nonempty  leads  to  a  contradiction,  it  follows 
that C  must be empty.  That is, that there are no numerators of fractions that can’t 
be written in lowest terms, and hence there are no such fractions at all. 
We’ve been using the Well Ordering Principle on the sly from early on! 

2.2  Template for Well Ordering Proofs 

More  generally,  there  is  a  standard way  to use Well Ordering  to prove  that  some 
property, P (n) holds  for  every nonnegative  integer, n.  Here  is a  standard way  to 
organize such a well ordering proof: 

To prove that “P (n) is true for all n ∈ N” using the Well Ordering Principle: 

•	 Deﬁne the set, C , of counterexamples to P  being true. Namely, deﬁnea 
C  ::= {n ∈ N | P (n) is false} . 

•	 Assume for proof by contradiction that C  is nonempty. 

•	 By the Well Ordering Principle, there will be a smallest element, n, in C . 

•	 Reach  a  contradiction  (somehow) —often  by  showing  how  to  use  n  to  ﬁnd 
another member of C  that is smaller than n.  (This is the open-ended part of 
the proof task.) 

•	 Conclude that C must be empty, that is, no counterexamples exist. QED 

a The notation {n  | P (n)} means “the set of all elements n, for which P (n) is true. 

2.2.  TEMPLATE FOR WELL ORDERING PROOFS 

33 

2.2.1  Problems 
Class Problems 

Problem 2.1. 
The  proof  below  uses  the Well Ordering  Principle  to  prove  that  every  amount  of 
postage that can be paid exactly using only 6 cent and 15 cent stamps, is divisible 
by  3.  Let  the notation  “j  |  k”  indicate  that  integer  j  is  a divisor  of  integer  k ,  and 
let  S (n) mean  that  exactly  n  cents  postage  can  be  paid  using  only  6  and  15  cent 
stamps. Then the proof shows that 
S (n)  IM P L I E S  3  | n, 

for all nonnegative integers n. 

(*) 

Fill in the missing portions (indicated by “. . . ”)  of the following proof of (*). 

Let C  be the set of counterexamples to (*), namely1 

C  ::= {n  | . . . } 

Assume for the purpose of obtaining a contradiction that C is nonempty.

Then by  the WOP, there  is a smallest number, m  ∈  C .  This m must be

positive because. . . .

But if S (m) holds and m is positive, then S (m − 6) or S (m − 15) must

hold, because. . . .

So suppose S (m − 6) holds. Then 3 | (m − 6), because. . .

But if 3  |  (m − 6), then obviously 3  | m, contradicting the fact that m is

a counterexample.

Next  suppose S (m − 15) holds.  Then  the proof  for m − 6 carries over

directly for m − 15 to yield a contradiction in this case as well. Since we

get a contradiction in both cases, we conclude that. . .

which proves that (*) holds.


Problem 2.2. 
Euler ’s  Conjecture  in  1769  was  that  there  are  no  positive  integer  solutions  to  the 
equation 

a 4  + b4  + c 4  = d4 . 
Integer  values  for  a, b, c, d  that  do  satisfy  this  equation,  were  ﬁrst  discovered  in 
1986.  So Euler guessed wrong, but it took more two hundred years to prove it. 
Now let’s consider Lehman’s2  equation, similar to Euler ’s but with some coef­
ﬁcients: 

8a 4  + 4b4  + 2c 4  = d4 
1 The notation “{n  |  . . . }” means “the set of elements, n, such that . . . .”

2 Suggested by Eric Lehman, a former 6.042 Lecturer.


(2.1) 

34	

CHAPTER 2.  THE WELL ORDERING PRINCIPLE 

Prove  that  Lehman’s  equation  (2.1)  really  does  not  have  any  positive  integer 
solutions. 
Hint: Consider the minimum value of a among all possible solutions to (2.1). 

Homework Problems 

Problem 2.3. 
Use the Well Ordering Principle to prove that any integer greater than or equal to 
8 can be represented as the sum of integer multiples of 3 and 5. 

2.3  Summing the Integers 

Let’s use this this template to prove 

Theorem. 

· · · 
1 + 2 + 3 +  + n = n(n + 1)/2	

(2.2)

for all nonnegative integers, n. 

First, we better address of a couple of ambiguous special cases before they trip 
us up: 

· · ·
•	 If n = 1, then there is only one term in the summation, and so 1+ 2+ 3+ +n
is  just  the  term  1.  Don’t  be  misled  by  the  appearance  of  2  and  3  and  the 
suggestion that 1 and n are distinct terms! 
•	 If n ≤  0, then there are no terms at all in the summation.  By convention, the 
sum in this case is 0. 

So while  the dots notation  is  convenient,  you have  to watch  out  for  these  special 
cases where  the  notation  is misleading!  (In  fact, whenever  you  see  the  dots,  you 
should be on the lookout to be sure you understand the pattern, watching out for 
the beginning and the end.) 
We could have eliminated the need for guessing by rewriting the left side of (2.2) 
� 
� 
with summation notation: 
n
i. 
i 
1≤i≤n 
i=1 

or 

Both of  these expressions denote  the sum of all values  taken by  the expression  to 
the right of the sigma as the variable, i, ranges from 1 to n. Both expressions make 
it  clear what  (2.2) means when  n  = 1.  The  second  expression makes  it  clear  that 
when  n  = 0,  there  are  no  terms  in  the  sum,  though  you  still  have  to  know  the 
convention that a sum of no numbers equals 0 (the product of no numbers is 1, by 
the way). 
OK, back to the proof: 

2.4.  FACTORING INTO PRIMES 

35 

Proof.  By contradiction. Assume that the theorem is false. Then, some nonnegative 
� 
� 
integers serve as counterexamples to it. Let’s collect them in a set: 
C  ::=  n ∈ N  | 1 + 2 + 3 + · · · + n =� n(n 
+ 1) 
. 
2

By our assumption that the theorem admits counterexamples, C  is a nonempty set 
of  nonnegative  integers.  So,  by  the  Well  Ordering  Principle,  C  has  a  minimum 
element, call it c. That is, c is the smallest counterexample to the theorem. 
Since c is the smallest counterexample, we know that (2.2) is false for n = c but 
true  for all nonnegative  integers n < c.  But  (2.2)  is  true  for n  = 0,  so  c >  0.  This 
means c − 1 is a nonnegative integer, and since it is less than c, equation (2.2) is true 
for c − 1. That is, 
(c − 1)c
2 

1 + 2 + 3 +  + (c − 1) = 
· · · 

.

1 + 2 + 3 +  + (c − 1) + c =
· · · 

But then, adding c to both sides we get 
c2  − c + 2c  = 
(c − 1)c  + c = 
c(c + 1) 
,
2 
2
2 
which means that (2.2) does hold for c, after all! This is a contradiction, and we are 
� 
done. 

2.3.1  Problems 
Class Problems 

Problem 2.4. 
n� 
Use the Well Ordering Principle to prove that 
k2  = 
k=0 

n(n + 1)(2n + 1) 
. 
6 

for all nonnegative integers, n. 

2.4  Factoring into Primes 

(2.3)

We’ve previously taken for granted the Prime Factorization Theorem that every inte­
ger greater than one has a unique3  expression as a product of prime numbers. This 
is another of those familiar mathematical facts which are not really obvious. We’ll 
prove  the  uniqueness  of  prime  factorization  in  a  later  chapter,  but well  ordering 
gives  an  easy  proof  that  every  integer  greater  than  one  can  be  expressed  as  some 
product of primes. 

Theorem 2.4.1.  Every natural number can be factored as a product of primes. 

3 . . . unique up to the order in which the prime factors appear 

36 

CHAPTER 2.  THE WELL ORDERING PRINCIPLE 

Proof.  The proof is by Well Ordering. 
Let  C  be  the  set  of  all  integers  greater  than  one  that  cannot  be  factored  as  a 
product of primes. We assume C  is not empty and derive a contradiction. 
If C  is not empty, there is a least element, n ∈ C , by Well Ordering.  The n can’t 
be prime, because a prime by itself is considered a (length one) product of primes 
and no such products are in C . 
So n must be a product of two integers a and b where 1 < a, b < n. Since a and b 
are smaller than the smallest element in C , we know that a, b  /∈ C .  In other words, 
a  can  be  written  as  a  product  of  primes  p1p2  · · · pk  and  b  as  a  product  of  primes 
q1  · · · ql .  Therefore,  n  =  p1  · · · pk q1  · · · ql  can  be  written  as  a  product  of  primes, 
∅ must therefore be 
contradicting the claim that n  ∈ C .  Our assumption that C  =�
� 
false. 

Chapter 3 

Propositional Formulas 

It  is  amazing  that  people manage  to  cope with  all  the  ambiguities  in  the  English 
language. Here are some sentences that illustrate the issue: 

1.  “You may have cake, or you may have ice cream.” 

2.  “If pigs can ﬂy, then you can understand the Chebyshev bound.” 

3.  “If  you  can  solve  any problem we  come up with,  then you  get  an A  for  the 
course.” 

4.  “Every American has a dream.” 

What  precisely  do  these  sentences mean?  Can  you  have  both  cake  and  ice  cream 
or  must  you  choose  just  one  dessert?  If  the  second  sentence  is  true,  then  is  the 
Chebyshev  bound  incomprehensible?  If  you  can  solve  some  problems  we  come 
up with but not all, then do you get an A for the course? And can you still get an A 
even  if you can’t solve any of  the problems?  Does  the  last sentence  imply  that all 
Americans have the same dream or might some of them have different dreams? 
Some uncertainty is tolerable in normal conversation. But when we need to for­
mulate  ideas  precisely —as  in mathematics  and  programming —the  ambiguities 
inherent  in  everyday  language  can  be  a  real  problem.  We  can’t  hope  to make  an 
exact argument  if we’re not sure exactly what  the statements mean.  So before we 
start  into mathematics,  we  need  to  investigate  the  problem  of  how  to  talk  about 
mathematics. 
To  get  around  the  ambiguity  of  English,  mathematicians  have  devised  a  spe­
cial  mini-language  for  talking  about  logical  relationships.  This  language  mostly 
uses  ordinary  English  words  and  phrases  such  as  “or ”,  “implies”,  and  “for  all”. 
But mathematicians endow  these words with deﬁnitions more precise  than  those 
found  in  an  ordinary  dictionary.  Without  knowing  these  deﬁnitions,  you  might 
sometimes get the gist of statements in this language, but you would regularly get 
misled about what they really meant. 

37 

38 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

Surprisingly,  in  the midst  of  learning  the  language  of  logic, we’ll  come  across 
the most important open problem in computer science —a problem whose solution 
could change the world. 

3.1  Propositions from Propositions 

In  English,  we  can modify,  combine,  and  relate  propositions with words  such  as 
“not”,  “and”,  “or ”,  “implies”,  and “if-then”.  For  example, we  can  combine  three 
propositions into one like this: 

If all humans are mortal and all Greeks are human, then all Greeks are mortal. 

For  the next while, we won’t be much  concerned with  the  internals of propo­
sitions —whether they involve mathematics or Greek mortality —but rather with 
how propositions are combined and related. So we’ll frequently use variables such 
as P  and Q in place of speciﬁc propositions such as “All humans are mortal” and 
“2 + 3 = 5”.  The understanding is that these variables, like propositions, can take 
on only the values T (true) and F (false).  Such true/false variables are sometimes 
called Boolean variables after their inventor, George —you guessed it —Boole. 

3.1.1  “Not”, “And”, and “Or ” 
We  can  precisely  deﬁne  these  special  words  using  truth  tables.  For  example,  if 
P  denotes  an  arbitrary  proposition,  then  the  truth  of  the  proposition  “NO T P ”  is 
deﬁned by the following truth table: 

P  NO T P 
F 
T 
F 
T 

The ﬁrst row of the table indicates that when proposition P  is true, the proposition 
“NOT P ”  is  false.  The  second  line  indicates  that when P  is  false,  “NO T P ”  is  true. 
This is probably what you would expect. 
In general, a truth table indicates the true/false value of a proposition for each 
possible  setting  of  the  variables.  For  example,  the  truth  table  for  the  proposition 
“P  AND Q” has four lines, since the two variables can be set in four different ways: 

P Q 
T  T 
T  F 
F  T 
F  F 

P  AND Q 
T 
F 
F 
F 

According to this table, the proposition “P  AND Q” is true only when P  and Q are 
both true. This is probably the way you think about the word “and.” 

3.1.  PROPOSITIONS FROM PROPOSITIONS 

39 

There is a subtlety in the truth table for “P  OR Q”: 

P Q 
T  T 
T  F 
F  T 
F  F 

P  OR Q 
T 
T 
T 
F 

The  third  row of  this  table  says  that  “P  OR  Q”  is  true when  even  if  both P  and Q 
are  true.  This  isn’t always  the  intended meaning of “or ”  in everyday speech, but 
this is the standard deﬁnition in mathematical writing.  So if a mathematician says, 
“You may have  cake,  or you may have  ice  cream,”  he means  that you  could have 
both. 
If  you want  to  exclude  the  possibility  of  having  both  having  and  eating,  you 
should use “exclusive-or ” (XOR): 

P Q 
T  T 
T  F 
F  T 
F  F 

P  XOR Q 
F 
T 
T 
F 

3.1.2  “Implies” 
The  least  intuitive  connecting word  is  “implies.”  Here  is  its  truth  table, with  the 
lines labeled so we can refer to them later. 

P Q 
T T 
T F 
F T 
F F 

P  IM P L I E S Q 
T 
F 
T 
T 

(tt) 
(tf) 
(ft) 
(ff) 

Let’s experiment with this deﬁnition. For example, is the following proposition 
true or false? 
“If Goldbach’s Conjecture is true, then x2  ≥ 0 for every real number x.” 
Now, we told you before that no one knows whether Goldbach’s Conjecture is true 
or  false.  But  that  doesn’t  prevent  you  from  answering  the  question!  This  propo­
sition has  the  form P  −→  Q where  the hypothesis, P ,  is “Goldbach’s Conjecture  is 
true” and the conclusion, Q, is “x2  ≥  0 for every real number x”.  Since the conclu­
sion  is deﬁnitely  true, we’re on either  line  (tt) or  line  (ft) of  the  truth  table.  Either 
way, the proposition as a whole is true! 
One  of  our  original  examples  demonstrates  an  even  stranger  side  of  implica­
tions. 

“If pigs ﬂy, then you can understand the Chebyshev bound.” 

40 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

Don’t take this as an  insult; we  just need to ﬁgure out whether this proposition is 
true or false.  Curiously, the answer has nothing to do with whether or not you can 
understand  the  Chebyshev  bound.  Pigs  do  not  ﬂy,  so we’re  on  either  line  (ft)  or 
line (ff) of the truth table.  In both cases, the proposition is true! 
In contrast, here’s an example of a false implication: 

“If the moon shines white, then the moon is made of white cheddar.” 

Yes, the moon shines white. But, no, the moon is not made of white cheddar cheese. 
So we’re on line (tf) of the truth table, and the proposition is false. 
The truth table for implications can be summarized in words as follows: 

An implication is true exactly when the if-part is false or the then-part is true. 

This  sentence  is  worth  remembering;  a  large  fraction  of  all  mathematical  state­
ments are of the if-then form! 

3.1.3  “If and Only If” 
Mathematicians  commonly  join  propositions  in  one  additional  way  that  doesn’t 
arise in ordinary speech. The proposition “P  if and only if Q” asserts that P  and Q 
are logically equivalent; that is, either both are true or both are false. 

P Q 
T  T 
T  F 
F  T 
F  F 

P  I FF Q 
T 
F 
F 
T 

The following if-and-only-if statement is true for every real number x: 
|
− 4 ≥ 0 
| ≥ 2 
iff  x
For  some  values  of  x,  both  inequalities  are  true.  For  other  values  of  x,  neither  in­
equality is true .  In every case, however, the proposition as a whole is true. 

x2 

3.1.4  Problems 
Class Problems 

Problem 3.1. 
When the mathematician says to his student, “If a function is not continuous, then 
it is not differentiable,” then letting D  stand for “differentiable” and C  for contin­
uous, the only proper translation of the mathematician’s statement would be 

or equivalently, 

NO T(C )  IM P L I E S  NO T(D), 

D  IM P L I E S  C. 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

41 

But  when  a  mother  says  to  her  son,  “If  you  don’t  do  your  homework,  then 
you  can’t  watch  TV,”  then  letting  T  stand  for  “watch  TV”  and  H  for  “do  your 
homework,” a reasonable translation of the mother ’s statement would be 

or equivalently, 

NO T(H )  I FF  NOT(T ), 

H  I FF  T . 

Explain why it is reasonable to translate these two IF-THEN statements in dif­
ferent ways into propositional formulas. 

Problem 3.2. 
Prove by truth table that OR  distributes over AND : 

[P  OR  (Q  AND  R)] 

is equivalent to 

[(P  OR  Q)  AND  (P  OR  R)] 

(3.1) 

Homework Problems 

Problem 3.3. 
Describe  a  simple  recursive procedure which,  given  a positive  integer  argument, 
n,  produces  a  truth  table whose  rows  are  all  the  assignments of  truth values  to n 
propositional variables.  For example, for n = 2, the table might look like: 

T  T 
T  F 
F  T 
F  F 

Your description  can be  in English,  or a  simple program  in  some  familiar  lan­
guage (say Scheme or Java), but if you do write a program, be sure to include some 
sample output. 

3.2  Propositional Logic in Computer Programs 

Propositions and logical connectives arise all the time in computer programs.  For 
example, consider the following snippet, which could be either C, C++, or Java: 

if  (  x  >  0  ||  (x  <=  0  &&  y  >  100)  ) 
. . . 
(further instructions) 

The  symbol  ||  denotes  “or ”,  and  the  symbol  &&  denotes  “and”.  The  further  in­
structions are carried out only if the proposition following the word if is true. On 
closer inspection, this big expression is built from two simpler propositions. Let A 

42 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

be  the proposition  that x > 0,  and  let B  be  the proposition  that y  >  100.  Then 
we can rewrite the condition this way: 

A or ((not A) and B ) 

(3.2) 

A truth table reveals that this complicated expression is logically equivalent to 

A or B . 

(3.3) 

A  B  A or ((not A) and B )  A or B 
T 
T 
T  T 
T 
T 
T  F 
T 
T 
F  T 
F  F 
F 
F 

This means that we can simplify the code snippet without changing the program’s 
behavior: 

if  (  x  >  0  ||  y  >  100  ) 
. . . 
(further instructions) 

The equivalence of (3.2) and (3.3) can also be conﬁrmed reasoning by cases: 

A is T.	 Then  an  expression  of  the  form  (A or anything)  will  have  truth  value  T. 
Since  both  expressions  are  of  this  form,  both  have  the  same  truth  value  in 
this case, namely, T. 

A is F.	 Then  (A or P )  will  have  the  same  truth  value  as  P  for  any  proposition,  P . 
So  (3.3)  has  the  same  truth  value  as  B .  Similarly,  (3.2)  has  the  same  truth 
value as ((not F) and B ), which also has the same value as B .  So in this case, 
both expressions will have the same truth value, namely, the value of B . 

Rewriting  a  logical  expression  involving many  variables  in  the  simplest  form 
is both difﬁcult and important.  Simplifying expressions in software might slightly 
increase the speed of your program. But, more signiﬁcantly, chip designers face es­
sentially the same challenge.  However, instead of minimizing && and || symbols 
in a program, their job is to minimize the number of analogous physical devices on 
a  chip.  The payoff  is potentially  enormous:  a  chip with  fewer devices  is  smaller, 
consumes less power, has a lower defect rate, and is cheaper to manufacture. 

3.2.1	 Cryptic Notation 
Programming  languages use  symbols  like &&  and  !  in place  of words  like  “and” 
and  “not”.  Mathematicians  have  devised  their  own  cryptic  symbols  to  represent 
these words, which are summarized in the table below. 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

43 

Cryptic Notation 
English 
¬
(alternatively, P )
not P
P 
P  ∧ Q 
P  and Q
P  ∨ Q 
P  or Q
P  implies Q P  −→ Q 
P  −→ Q 
if P  then Q
Q←→ 
iff  Q
P 
P 

For example, using this notation, “If P  and not Q, then R” would be written: 
(P  ∧ Q) −→ R 

This  symbolic  language  is helpful  for writing  complicated  logical  expressions 
compactly.  But words such as “OR” and “IM P L I E S ,” generally serve just as well as 
the  cryptic  symbols  ∨  and −→,  and  their meaning  is  easy  to  remember.  So we’ll 
use the cryptic notation sparingly, and we advise you to do the same. 

3.2.2  Logically Equivalent Implications 

Do these two sentences say the same thing? 

If I am hungry, then I am grumpy.

If I am not grumpy, then I am not hungry.


We can settle the issue by recasting both sentences in terms of propositional logic. 
Let  P  be  the  proposition  “I  am  hungry”,  and  let  Q  be  “I  am  grumpy”.  The  ﬁrst 
sentence  says  “P  implies Q”  and  the  second  says  “(not Q)  implies  (not  P )”.  We 
can compare these two statements in a truth table: 

Q  P  IM P L I E S Q  Q IM P L I E S P 
P 
T  T 
T 
T 
F 
F 
T  F 
F  T 
T 
T 
T 
T 
F  F 

Sure enough, the columns of truth values under these two statements are the same, 
which precisely means they are equivalent.  In general, “(NOT Q) IM P L I E S (NO T P )” 
is  called  the  contrapositive  of  the  implication  “P  IM P L I E S  Q.”  And,  as  we’ve  just 
shown, the two are just different ways of saying the same thing. 
In  contrast,  the  converse  of  “P  IM P L I E S  Q”  is  the  statement  “Q  IM P L I E S  P ”.  In 
terms of our example, the converse is: 

If I am grumpy, then I am hungry. 

44 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

This sounds like a rather different contention, and a truth table conﬁrms this sus­
picion: 

P  IM P L I E S Q  Q IM P L I E S P 
Q 
P 
T 
T 
T 
T 
T 
F 
F 
T 
T 
F 
T 
F 
T 
T 
F 
F 
Thus, an implication is logically equivalent to its contrapositive but is not equiva­
lent to its converse. 
One ﬁnal relationship:  an implication and its converse together are equivalent 
to an iff statement, speciﬁcally, to these two statements together.  For example, 

If I am grumpy, then I am hungry. 
If I am hungry, then I am grumpy. 

are equivalent to the single statement: 

I am grumpy iff I am hungry. 

Once again, we can verify this with a truth table: 

P  Q  (P 
T  T 
T  F 
F  T 
F  F 

IM P L I E S  Q)  AND 
T 
T 
F 
F 
F 
T 
T 
T 

(Q 

IM P L I E S  P ) 
T 
T 
F 
T 

Q 

I FF  P 
T

F

F

T


The underlined operators have the same column of truth values, proving that the 
corresponding formulas are equivalent. 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

45 

SAT 

A proposition is satisﬁable if some setting of the variables makes the proposition 
true.  For  example,  P  AND  Q  is  satisﬁable  because  the  expression  is  true when P 
is  true  and Q  is  false.  On  the  other  hand,  P  AND  P  is  not  satisﬁable  because  the 
expression as a whole  is  false  for both  settings of P .  But determining whether or 
not  a  more  complicated  proposition  is  satisﬁable  is  not  so  easy.  How  about  this 
one? 

(P  OR Q OR R) AND  (P  OR Q) AND  (P  OR R) AND  (R OR Q) 

The general problem of deciding whether a proposition is satisﬁable is called SAT. 
One  approach  to  SAT  is  to  construct  a  truth  table  and  check whether  or  not  a  T 
ever appears. But this approach is not very efﬁcient; a proposition with n variables 
has a truth table with 2n  lines, so the effort required to decide about a proposition 
grows exponentially with  the number of variables.  For a proposition with  just 30 
variables, that’s already over a billion! 
Is  there  a more  efﬁcient  solution  to  SAT?  In  particular,  is  there  some,  presumably 
very ingenious, procedure that determines in a number of steps that grows polyno­
mially —like n2  of n14  —instead  of  exponentially, whether  any  given proposition 
is satiﬁable or not? No one knows. And an awful lot hangs on the answer. An efﬁ­
cient solution to SAT would immediately imply efﬁcient solutions to many, many 
other important problems involving packing, scheduling, routing, and circuit ver­
iﬁcation,  among other  things.  This would be wonderful,  but  there would also be 
worldwide  chaos.  Decrypting  coded  messages  would  also  become  an  easy  task 
(for most codes).  Online ﬁnancial transactions would be insecure and secret com­
munications could be read by everyone. 
Recently  there  has  been  exciting  progress  on  sat-solvers  for  practical  applications 
like  digital  circuit  veriﬁcation.  These  programs  ﬁnd  satisfying  assignments with 
amazing  efﬁciency  even  for  formulas  with  millions  of  variables.  Unfortunately, 
it’s  hard  to  predict  which  kind  of  formulas  are  amenable  to  sat-solver  methods, 
and  for  formulas  that  are NOT  satisﬁable,  sat-solvers  generally  take  exponential 
time to verify that. 
So no one has a good idea how to solve SAT more efﬁciently or else to prove that no 
efﬁcient solution exists —researchers are completely stuck. This is the outstanding 
unanswered question in theoretical computer science. 

46 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

3.2.3  Problems 
Class Problems 

Problem 3.4. 
This problem1  examines whether the following speciﬁcations are satisﬁable: 

1.  If the ﬁle system is not locked, then 

(a)  new messages will be queued. 
(b)  new messages will be sent to the messages buffer. 
(c)  the system is functioning normally, and conversely, if the system is func­
tioning normally, then the ﬁle system is not locked. 

2.  If new messages are not queued, then they will be sent to the messages buffer. 

3.  New messages will not be sent to the message buffer. 

(a)  Begin by  translating  the ﬁve speciﬁcations  into propositional  formulas using 
four propositional variables: 

L 
Q 
B 
N 

::=  ﬁle system locked,

::=  new messages are queued,

::=  new messages are sent to the message buffer, 

::=  system functioning normally.


(b)  Demonstrate that this set of speciﬁcations is satisﬁable by describing a single 
truth assignment for the variables L, Q, B , N  and verifying that under this assign­
ment, all the speciﬁcations are true. 

(c)  Argue that the assignment determined in part (b) is the only one that does the 
job. 

Problem 3.5. 
Propositional logic comes up in digital circuit design using the convention that T 
corresponds  to  1  and  F  to  0.  A  simple  example  is  a  2-bit  half-adder  circuit.  This 
circuit  has  3  binary  inputs,  a1 , a0  and  b,  and  3  binary  outputs,  c, o1 , o0 .  The  2-bit 
word  a1a0  gives  the binary  representation  of  an  integer,  k ,  between  0  and  3.  The 
3-bit word cs1 s0  gives the binary representation of k + b. The third output bit, c, is 
called the ﬁnal carry bit. 
So if k  and b were both 1, then the value of a1a0  would be 01 and the value of 
the output cs1 s0  would 010, namely, the 3-bit binary representation of 1 + 1. 

1 From Rosen, 5th edition, Exercise 1.1.36 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

47 

In fact, the ﬁnal carry bit equals 1 only when all three binary inputs are 1, that 
is, when k = 3 and b = 1.  In that case, the value of cs1 s0  is 100, namely, the binary 
representation of 3 + 1. 
This 2-bit half-adder could be described by the following formulas: 

c0  = b 
s0  = a0  XOR  c0 
c1  = a0  AND  c0 
s1  = a1  XOR  c1 
c2  = a1  AND  c1 
c = c2 . 

the carry into column 1 

the carry into column 2 

(a)  Generalize  the  above  construction  of  a  2-bit  half-adder  to  an  n + 1  bit  half-
adder  with  inputs  an , . . . , a1 , a0  and  b  for  arbitrary  n  ≥  0.  That  is,  give  simple 
formulas  for  si  and  ci  for  0  ≤  i  ≤  n + 1, where  ci  is  the  carry  into  column  i  and 
c = cn+1 . 

(b)  Write similar deﬁnitions for the digits and carries in the sum of two n + 1-bit 
binary numbers an  . . . a1a0  and bn  . . . b1 b0 . 
Visualized as digital circuits,  the above adders consist of a sequence of single-
digit half-adders or adders strung together in series. These circuits mimic ordinary 
pencil-and-paper addition, where a carry into a column is calculated directly from 
the  carry  into  the  previous  column,  and  the  carries  have  to  ripple  across  all  the 
columns  before  the  carry  into  the  ﬁnal  column  is  determined.  Circuits  with  this 
design  are  called  ripple-carry  adders.  Ripple-carry  adders  are  easy  to understand 
and remember and require a nearly minimal number of operations. But the higher-
order output bits and the ﬁnal carry take time proportional to n to reach their ﬁnal 
values. 
(c)  How  many  of  each  of  the  propositional  operations  does  your  adder  from 
part (b) use to calculate the sum? 

Problem 3.6.  (a)  A propositional formula is valid iff it is equivalent to T. Verify by 
truth table that 

(P  IM P L I E S  Q)  OR  (Q  IM P L I E S  P ) 

is valid. 

(b)  Let  P  and Q  be  propositional  formulas.  Describe  a  single  propositional  for­
mula, R, involving P  and Q such that R is valid iff P  and Q are equivalent. 

(c)  A propositional formula is satisﬁable iff there is an assignment of truth values 
to its variables —an environment —which makes it true. Explain why 

P  is valid iff NO T(P ) is not satisﬁable. 

48 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

(d)  A set of propositional formulas P1 , . . . , Pk  is consistent  iff there  is an environ­
ment in which they are all true. Write a formula, S , so that the set P1 , . . . , Pk  is not 
consistent iff S  is valid. 

Homework Problems 

Problem 3.7. 
Considerably faster adder circuits work by computing the values in later columns 
for  both  a  carry  of  0  and  a  carry  of  1,  in  parallel.  Then,  when  the  carry  from  the 
earlier columns ﬁnally arrives,  the pre-computed answer can be quickly selected. 
We’ll illustrate this idea by working out the equations for an n + 1-bit parallel half-
adder. 
Parallel half-adders are built out of parallel “add1” modules. An n + 1-bit add1 
module takes as input the n + 1-bit binary representation, an  . . . a1a0 , of an integer, 
s, and produces as output the binary representation, c pn  . . . p1 p0 , of s + 1. 
(a)  A  1-bit  add1  module  just  has  input  a0 .  Write  propositional  formulas  for  its 
outputs c and p0 . 

(b)  Explain how  to build an n + 1-bit parallel half-adder  from an n + 1-bit add1 
module  by  writing  a  propositional  formula  for  the  half-adder  output,  oi ,  using 
only the variables ai , pi , and b. 
We can build a double-size add1 module with 2(n + 1) inputs using two single-
size add1 modules with n+1 inputs. Suppose the inputs of the double-size module 
are a2n+1 , . . . , a1 , a0  and the outputs are c, p2n+1 , . . . , p1 , p0 . The setup is illustrated 
in Figure 3.1. 
Namely,  the  ﬁrst  single  size  add1 module  handles  the  ﬁrst  n + 1  inputs.  The 
inputs to this module are the low-order n + 1 input bits an , . . . , a1 , a0 , and its out­
puts will  serve as  the ﬁrst n + 1 outputs pn , . . . , p1 , p0  of  the double-size module. 
Let c(1)  be the remaining carry output from this module. 
The  inputs  to  the  second  single-size module  are  the  higher-order  n + 1  input 
bits a2n+1 , . . . , an+2 , an+1 . Call its ﬁrst n + 1 outputs rn , . . . , r1 , r0  and let c(2)  be its 
carry. 
(c)  Write a formula for the carry, c, in terms of c(1)  and c(2) . 

(d)  Complete the speciﬁcation of the double-size module by writing propositional 
formulas for the remaining outputs, pi , for n + 1 ≤  i ≤  2n + 1.  The formula for pi 
should only involve the variables ai , ri−(n+1) , and c(1) . 

(e)  Parallel half-adders are exponentially faster than ripple-carry half-adders. Con­
ﬁrm  this by determining  the  largest number of propositional operations  required 
to  compute  any  one  output  bit  of  an  n-bit  add module.  (You may  assume  n  is  a 
power of 2.) 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

49


Figure 3.1:  Structure of a Double-size Add1 Module. 

a0a1ana2n+1an+1an+2c(1)c(2)(n+1)‐bit add1module(n+1)‐bit add1dlmodulemoduler0r1rnc2(n+2)‐bit add1 modulepnp1p0p2n+1pn+1pn+2n10n+1n+250 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

Chapter 4 

Mathematical Data Types 

4.1  Sets 

We’ve  been  assuming  that  the  concepts  of  sets,  sequences,  and  functions  are  al­
ready familiar ones, and we’ve mentioned them repeatedly. Now we’ll do a quick 
review of the deﬁnitions. 
Informally,  a  set  is  a  bunch  of  objects, which  are  called  the  elements  of  the  set. 
The elements of a set can be just about anything: numbers, points in space, or even 
other sets.  The conventional way to write down a set is to list the elements inside 
curly-braces.  For example, here are some sets: 
A  =  {Alex, Tippy, Shells, Shadow}  dead pets 
B  =  {red, blue, yellow} 
primary colors 
C  =  {{a, b} , {a, c} , {b, c}} 
a set of sets 
This works ﬁne for small ﬁnite sets. Other sets might be deﬁned by indicating how 
to generate a list of them: 
D = {1, 2, 4, 8, 16, . . . } 
the powers of 2 
The  order  of  elements  is  not  signiﬁcant,  so  {x, y}  and  {y , x}  are  the  same  set 
written  two  different  ways.  Also,  any  object  is,  or  is  not,  an  element  of  a  given 
set  —there  is  no  notion  of  an  element  appearing  more  than  once  in  a  set.1  So 
writing {x, x} is just indicating the same thing twice, namely, that x is in the set.  In 
particular, {x, x} = {x}. 
The expression e ∈ S  asserts that e is an element of set S .  For example, 32 ∈ D 
and blue ∈ B , but Tailspin  �∈ A —yet. 
Sets  are  simple,  ﬂexible,  and  everywhere.  You’ll  ﬁnd  some  set  mentioned  in 
nearly every section of this text. 

1 It’s  not  hard  to  develop  a  notion  of  multisets  in  which  elements  can  occur  more  than  once,  but 
multisets are not ordinary sets. 

51 

52	

CHAPTER 4.  MATHEMATICAL DATA TYPES 

4.1.1  Some Popular Sets 
Mathematicians have devised special symbols to represent some common sets. 

symbol 
∅ 
N 
Z 
Q 
R 
C 

elements 
set	
none 
the empty set 
nonnegative integers  {0, 1, 2, 3, . . .}
{. . . , −3, −2, −1, 0, 1, 2, 3, . . .}
integers 
2 ,  − 5
√
3 ,  16,  etc. 
1
rational numbers 
π ,  e,  −9, 
√
2,  etc. 
real numbers 
2 − 2i,  etc. 
19
complex numbers 
i,  2  , 
A superscript “+” restricts a set  to  its positive elements;  for example, R+  denotes 
the set of positive real numbers.  Similarly, R−  denotes the set of negative reals. 

4.1.2  Comparing and Combining Sets 
The  expression  S  ⊆  T  indicates  that  set  S  is  a  subset  of  set  T ,  which means  that 
every element of S  is also an element of T  (it could be  that S  =  T ).  For example, 
N ⊆ Z and Q ⊆ R (every rational number is a real number), but C  �⊆ Z (not every 
complex number is an integer). 
As a memory trick, notice that the ⊆ points to the smaller set, just like a ≤ sign 
points  to  the smaller number.  Actually,  this connection goes a  little  further:  there 
is a symbol ⊂ analogous to <.  Thus, S  ⊂  T  means that S  is a subset of T , but the 
two are not equal.  So A ⊆ A, but A  �⊂ A, for every set A. 
There are several ways to combine sets.  Let’s deﬁne a couple of sets for use in 
examples: 

X  ::= {1, 2, 3}

Y  ::= {2, 3, 4}

•	 The union of sets X  and Y  (denoted X  ∪ Y ) contains all elements appearing 
in X  or Y  or both. Thus, X ∪ Y  = {1, 2, 3, 4}. 
•	 The  intersection  of  X  and  Y  (denoted  X  ∩  Y )  consists  of  all  elements  that 
appear in both X  and Y .  So X ∩ Y  = {2, 3}. 
•	 The  set  difference  of X  and  Y  (denoted X  −  Y )  consists  of  all  elements  that 
are in X , but not in Y . Therefore, X − Y  = {1} and Y  − X  = {4}. 

4.1.3  Complement of a Set 
Sometimes we are  focused on a particular domain, D .  Then  for any  subset, A,  of 
D , we deﬁne A to be the set of all elements of D not in A. That is, A ::= D − A. The 
set A is called the complement of A. 

4.1.  SETS 

53 

For  example,  when  the  domain  we’re  working  with  is  the  real  numbers,  the 
complement  of  the  positive  real  numbers  is  the  set  of  negative  real  numbers  to­
gether with zero. That is, 
R+  = R−  ∪ {0} . 
It can be helpful  to  rephrase properties of sets using complements.  For exam­
ple, two sets, A and B , are said to be disjoint iff they have no elements in common, 
that is, A ∩ B  = ∅.  This is the same as saying that A is a subset of the complement 
of B , that is, A ⊆ B . 

4.1.4  Power Set 
The set of all the subsets of a set, A, is called the power set, P (A), of A.  So B  ∈ P (A) 
iff B ⊆ A.  For example, the elements of P ({1, 2}) are ∅, {1} , {2} and {1, 2}. 
More  generally,  if  A  has  n  elements,  then  there  are  2n  sets  in  P (A).  For  this 
reason, some authors use the notation 2A  instead of P (A). 

4.1.5  Set Builder Notation 
An  important  use  of  predicates  is  in  set  builder  notation.  We’ll  often  want  to  talk 
about  sets  that cannot be described very well by  listing  the elements explicitly or 
by  taking unions,  intersections,  etc.,  of easily-described  sets.  Set builder notation 
often comes to the rescue. The idea is to deﬁne a set using a predicate; in particular, 
the set consists of all values that make the predicate true. Here are some examples 
of set builder notation: 
� 
� 
A ::= {n ∈ N  | n is a prime and n = 4k + 1 for some integer k} 
x ∈ R  | x 3  − 3x + 1 > 0  � 
B ::= � 
C  ::=  a + bi ∈ C  | a 2  + 2b2  ≤ 1 
The set A consists of all nonnegative integers n for which the predicate 
“n is a prime and n = 4k + 1 for some integer k” 
is true. Thus, the smallest elements of A are: 
5, 13, 17, 29, 37, 41, 53, 57, 61, 73, . . . . 

Trying to indicate the set A by listing these ﬁrst few elements wouldn’t work very 
well; even after ten terms,  the pattern  is not obvious!  Similarly,  the set B  consists 
of all real numbers x for which the predicate 
x 3  − 3x + 1 > 0 
is true.  In this case, an explicit description of the set B  in terms of intervals would 
require  solving  a  cubic  equation.  Finally,  set  C  consists  of  all  complex  numbers 
a + bi such that: 
a 2  + 2b2  ≤ 1 

54 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

This is an oval-shaped region around the origin in the complex plane. 

4.1.6  Proving Set Equalities 
Two sets are deﬁned to be equal if they contain the same elements. That is, X  = Y 
means  that  z  ∈  X  if  and  only  if  z  ∈  Y ,  for  all  elements,  z .  (This  is  actually  the 
ﬁrst  of  the ZFC  axioms.)  So  set  equalities  can  be  formulated  and  proved  as  “iff ” 
theorems.  For example: 
Theorem 4.1.1 (Distributive Law for Sets).  Let A, B , and C  be sets. Then: 
A ∩ (B ∪ C ) = (A ∩ B ) ∪ (A ∩ C ) 
Proof.  The equality (4.1) is equivalent to the assertion that 
z  ∈ A ∩ (B ∪ C ) 
iff  z  ∈ (A ∩ B ) ∪ (A ∩ C ) 
for all z . Now we’ll prove (4.2) by a chain of iff ’s. 
First we need a rule for distributing a propositional AND  operation over an OR 
operation.  It’s easy to verify by truth-table that 
Lemma 4.1.2.  The propositional formula 
P  AND  (Q OR R) 

(4.1) 

(4.2) 

and 

(P  AND Q) OR  (P  AND R) 

are equivalent. 
Now we have 
z  ∈ A ∩ (B ∪ C ) 
iff  (z  ∈ A) AND  (z  ∈ B ∪ C ) 
iff  (z  ∈ A) AND  (z  ∈ B OR z  ∈ C ) 
iff  (z  ∈ A AND  z  ∈ B ) OR  (z  ∈ A AND  z  ∈ C ) 
iff  (z  ∈ A ∩ B ) OR  (z  ∈ A ∩ C ) 
iff  z  ∈ (A ∩ B ) ∪ (A ∩ C ) 

(def of ∩) 
(def of ∪) 
(Lemma 4.1.2) 
(def of ∩) 
(def of ∪) 

4.1.7  Problems 
Homework Problems 

Problem 4.1. 
Let A, B , and C  be sets. Prove that: 
A ∪ B ∪ C  = (A − B ) ∪ (B − C ) ∪ (C − A) ∪ (A ∩ B ∩ C ). 
Hint: P  OR Q OR R is equivalent to 
(P  AND Q) OR  (Q AND R) OR  (R AND P ) OR  (P  AND Q AND R). 

� 

(4.3) 

4.2.  SEQUENCES	

4.2  Sequences 

55 

Sets provide one way to group a collection of objects. Another way is in a sequence, 
which is a list of objects called terms or components.  Short sequences are commonly 
described  by  listing  the  elements  between  parentheses;  for  example,  (a, b, c)  is  a 
sequence with three terms. 
While both sets and  sequences perform a gathering  role,  there are several dif­
ferences. 

•	 The elements of a set are required to be distinct, but terms in a sequence can 
be the same.  Thus, (a, b, a) is a valid sequence of length three, but {a, b, a} is 
a set with two elements —not three. 

•	 The  terms  in a sequence have a speciﬁed order, but  the elements of a set do 
not.  For  example,  (a, b, c)  and  (a, c, b)  are  different  sequences,  but  {a, b, c}
and {a, c, b} are the same set. 
•	 Texts  differ  on  notation  for  the  empty  sequence;  we  use  λ  for  the  empty  se­
quence. 

The product operation is one link between sets and sequences. A product of sets, 
S1 × S2 × · · ·× Sn , is a new set consisting of all sequences where the ﬁrst component 
is drawn from S1 , the second from S2 , and so forth. For example, N×{a, b} is the set 
of all pairs whose ﬁrst element is a nonnegative integer and whose second element 
is an a or a b: 

N × {a, b} = {(0, a), (0, b), (1, a), (1, b), (2, a), (2, b), . . . } 
A product of n copies of a set S  is denoted S n .  For example, {0, 1} 3  is the set of all 
3-bit sequences: 
{0, 1} 3  = {(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)} 

4.3  Functions 

A function assigns an element of one set, called the domain, to elements of another 
set, called the codomain. The notation 

f  : A

B→ 

indicates  that  f  is  a  function  with  domain,  A,  and  codomain,  B .  The  familiar 
notation “f (a) =  b” indicates that f  assigns the element b  ∈ B  to a.  Here b would 
be called the value of f  at argument a. 
Functions are often deﬁned by formulas as in: 

f1 (x) ::= 

1 
x2 

56 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

where x is a real-valued variable, or 

where y and z  range over binary strings, or 

f2 (y , z ) ::= y10yz 

f3 (x, n) ::=  the pair (n, x) 

where n ranges over the nonnegative integers. 
A  function  with  a  ﬁnite  domain  could  be  speciﬁed  by  a  table  that  shows  the 
value  of  the  function  at  each  element  of  the  domain.  For  example,  a  function 
f4 (P , Q) where P  and Q are propositional variables is speciﬁed by: 

P  Q  f4 (P , Q) 
T  T 
T 
F 
T  F 
T 
F  T 
F  F 
T 

Notice that f4  could also have been described by a formula: 

f4 (P , Q) ::= [P  IM P L I E S Q]. 

A function might also be deﬁned by a procedure for computing its value at any 
element of its domain, or by some other kind of speciﬁcation.  For example, deﬁne 
f5 (y) to be the length of a left to right search of the bits in the binary string y until 
a 1 appears, so 

f5 (0010)  =  3, 
f5 (100)  =  1, 
f5 (0000) 
is  undeﬁned. 

Notice  that f5  does not assign a value  to any string of  just 0’s.  This  illustrates 
an important fact about functions:  they need not assign a value to every element in 
the domain.  In fact this came up in our ﬁrst example f1 (x) = 1/x2 , which does not 
assign a value to 0.  So in general, functions may be partial functions, meaning that 
there may be domain elements for which the function is not deﬁned.  If a function 
is deﬁned on every element of its domain, it is called a total function. 
It’s  often useful  to ﬁnd  the  set  of  values  a  function  takes when  applied  to  the 
→
elements in a set of arguments.  So if f  :  A
B , and S  is a subset of A, we deﬁne 
f (S ) to be the set of all the values that f  takes when it is applied to elements of S . 
That is, 
f (S ) ::= {b ∈ B  | f (s) = b for some s ∈ S } . 
For  example,  if  we  let  [r, s]  denote  the  interval  from  r  to  s  on  the  real  line,  then 
f1 ([1, 2]) = [1/4, 1]. 

4.4.  BINARY RELATIONS 

57 

For another example, let’s take the “search for a 1” function, f5 .  If we let X  be 
the  set  of  binary words which  start with  an  even  number  of  0’s  followed  by  a  1, 
then f5 (X ) would be the odd nonnegative integers. 
Applying f  to a set, S , of arguments is referred to as “applying f  pointwise to 
S ”, and the set f (S ) is referred to as the image of S under f .2  The set of values that 
arise from applying f  to all possible arguments is called the range of f . That is, 

range (f ) ::= f (domain (f )). 

Some authors refer to the codomain as the range of a function, but they shouldn’t. 
The distinction between the range and codomain will be important in Sections 4.7 
and 4.8 when we relate sizes of sets to properties of functions between them. 

4.3.1  Function Composition 
Doing things step by step is a universal idea. Taking a walk is a literal example, but 
so is cooking from a recipe, executing a computer program, evaluating a formula, 
and recovering from substance abuse. 
Abstractly,  taking  a  step  amounts  to  applying  a  function,  and  going  step  by 
step corresponds to applying functions one after the other. This is captured by the 
operation  of  composing  functions.  Composing  the  functions  f  and  g  means  that 
ﬁrst  f  applied  is  to  some  argument,  x,  to  produce  f (x),  and  then  g  is  applied  to 
that result to produce g(f (x)). 

→ 
→
B  and g  : B
Deﬁnition 4.3.1.  For functions f  : A
C , the composition, g
→ 
g with f  is deﬁned to be the function h  : A
C  deﬁned by the rule: 
◦ 
f )(x) = h(x) ::= g(f (x)),

(g

◦ 
f , of 

for all x ∈ A. 
Function  composition  is  familiar  as  a basic  concept  from  elementary  calculus, 
and it plays an equally basic role in discrete mathematics. 

4.4  Binary Relations 

Relations  are  another  fundamental  mathematical  data  type.  Equality  and  “less­
than” are very familiar examples of mathematical relations. These are called binary 
relations because they apply to a pair (a, b) of objects; the equality relation holds for 
the pair when a = b, and less-than holds when a and b are real numbers and a < b. 
In  this  chapter  we’ll  deﬁne  some  basic  vocabulary  and  properties  of  binary 
relations. 
2 There is a picky distinction between the function f  which applies to elements of A and the function 
which applies f  pointwise to subsets of A, because the domain of f  is A, while the domain of pointwise­
f  is P (A).  It  is  usually  clear  from  context whether  f  or  pointwise-f  is meant,  so  there  is  no  harm  in 
overloading the symbol f  in this way. 

58 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

4.5  Binary Relations and Functions 

Binary relations are far more general than equality or less-than.  Here’s the ofﬁcial 
deﬁnition: 

Deﬁnition 4.5.1.  A binary relation, R, consists of a set, A, called the domain of R, a 
set, B , called the codomain of R, and a subset of A × B  called the graph of R. 
Notice  that Deﬁnition  4.5.1  is  exactly  the  same  as  the  deﬁnition  in  Section  4.3 
of  a  function,  except  that  it  doesn’t  require  the  functional  condition  that,  for  each 
domain element, a,  there is at most one pair in the graph whose ﬁrst coordinate is 
a.  So a function is a special case of a binary relation. 
A relation whose domain is A and codomain is B  is said to be “between A and 
B ”,  or  “from A  to B .”  When  the  domain  and  codomain  are  the  same  set,  A,  we 
simply  say  the  relation  is  “on  A.”  It’s  common  to  use  inﬁx  notation  “a R b”  to 
mean that the pair (a, b) is in the graph of R. 
For example, we can deﬁne an “in-charge of ” relation, T , for MIT in Spring ’10 
to have domain equal to the set, F , of names of the faculty and codomain equal to 
all the set, N , of subject numbers in the current catalogue. The graph of T  contains 
precisely the pairs of the form 
(�instructor-name� , �subject-num�) 
such  that  the  faculty member named �instructor-name�  is  in charge of  the subject 
with number �subject-num� in Spring ’10.  So graph (T ) contains pairs like 

(A.  R.  Meyer,  6.042), 
(A.  R.  Meyer,  18.062), 
(A.  R.  Meyer,  6.844), 
(T.  Leighton,  6.042), 
(T.  Leighton,  18.062), 
(G,  Freeman, 
6.011), 
6.UAT), 
(G,  Freeman, 
6.881) 
(G.  Freeman, 
6.882) 
(G.  Freeman, 
(T.  Eng, 
6.UAT) 
(J.  Guttag, 
6.00) 
. . . 
This is a surprisingly complicated relation: Meyer is in charge of subjects with 
three numbers. Leighton is also in charge of subjects with two of these three num­
bers —because the same subject, Mathematics for Computer Science, has two num­
bers:  6.042  and  18.062,  and  Meyer  and  Leighton  are  co-in-charge  of  the  subject. 
Freeman is in-charge of even more subjects numbers (around 20), since as Depart­
ment Education Ofﬁcer, he is in charge of whole blocks of special subject numbers. 
Some  subjects,  like  6.844  and  6.00  have  only  one person  in-charge.  Some  faculty, 

4.6.  IMAGES AND INVERSE IMAGES 

59 

like  Guttag,  are  in  charge  of  only  one  subject  number,  and  no  one  else  is  co-in­
charge of his subject, 6.00. 
Some subjects  in  the codomain, N , do not appear  in  the  list —that  is,  they are 
not  an  element  of  any  of  the pairs  in  the  graph  of  T ;  these  are  the  Fall  term  only 
subjects.  Similarly,  there  are  faculty  in  the  domain,  F ,  who  do  not  appear  in  the 
list because all their in-charge subjects are Fall term only. 

4.6  Images and Inverse Images 

The faculty in charge of 6.UAT in Spring ’10 can be found by taking the pairs of the 
form 
(�instructor-name� , 6.U AT ) 
in the graph of the teaching relation, T , and then  just listing the left hand sides of 
these pairs; these turn out to be just Eng and Freeman. 
The  introductory  course  6  subjects  have  numbers  that  start  with  6.0 .  So  we 
can likewise ﬁnd out all the instructors in-charge of introductory course 6 subjects 
this  term,  by  taking  all  the  pairs  of  the  form  (�instructor-name� , 6.0 . . . )  and  list 
the  left  hand  sides  of  these  pairs.  For  example,  from  the  part  of  the  graph  of  T 
shown above, we can see that Meyer, Leighton, Freeman, and Guttag are in-charge 
of introductory subjects this term. 
These  are  all  examples  of  taking  an  inverse  image  of  a  set  under  a  relation.  If 
R  is  a  binary  relation  from A  to B ,  and X  is  any  set,  deﬁne  the  inverse  image  of 
X  under R,  written  simply  as  RX  to  be  the  set  elements  of A  that  are  related  to 
something in X . 
For  example,  let  D  be  the  set  of  introductory  course  6  subject  numbers.  So 
T D ,  the  inverse  image  of  the  set D  under  the  relation,  T ,  is  the  set  of  all  faculty 
members  in-charge of  introductory course 6  subjects  in Spring  ’10.  Notice  that  in 
inverse image notation, D gets written to the right of T  because, to ﬁnd the faculty 
members in T D , we’re looking pairs in the graph of T  whose right hand sides are 
subject numbers in D . 
Here’s a concise deﬁnition of the inverse image of a set X  under a relation, R: 
RX  ::= {a ∈ A  | aRx for some x ∈ X } . 
Similarly, the image of a set Y  under R, written Y R, is the set of elements of the 
codomain, B , that are related to some element in Y , namely, 
Y R ::= {b ∈ B  | yRb for some y ∈ Y } . 
So, {A. Meyer} T  gives the subject numbers that Meyer is in charge of in Spring 
’09.  In  fact, {A. Meyer} T  =  {6.042, 18.062, 6.844}.  Since  the domain, F ,  is  the set 
of all in-charge faculty, F T  is exactly the set of all Spring ’09 subjects being taught. 
Similarly, T N  is the set of people in-charge of a Spring ’09 subject. 
It gets interesting when we write composite expressions mixing images, inverse 
images  and  set  operations.  For  example,  (T D)T  is  the  set  of  Spring  ’09  subjects 

60	

CHAPTER 4.  MATHEMATICAL DATA TYPES 

that  have  people  in-charge  who  also  are  in-charge  of  introductory  subjects.  So 
(T D)T −D are the advanced subjects with someone in-charge who is also in-charge 
of an introductory subject.  Similarly, T D ∩ T (N  − D) is the set of faculty teaching 
both an introductory and an advanced subject in Spring ’09. 
Warning:  When R happens  to be a  function,  the pointwise application, R(Y ), 
of R to a set Y  described in Section 4.3 is exactly the same as the image of Y  under 
R.  That means  that when R  is  a  function, R(Y ) =  Y R —not RY .  Both notations 
are common in math texts, so you’ll have to live with the fact that they clash. Sorry 
about that. 

4.7  Surjective and Injective Relations 

There are a few properties of relations that will be useful when we take up the topic 
of counting because they imply certain relations between the sizes of domains and 
→ 
codomains. We say a binary relation R  : A
B  is:

•	 total when  every  element of A  is  assigned  to  some  element of B ; more  con­
cisely, R is total iff A = RB . 

•	 surjective when every element of B is mapped to at least once3 ; more concisely, 
R is surjective iff AR = B . 

•	 injective if every element of B  is mapped to at most once, and 

•	 bijective if R is total, surjective, and injective function. 

Note that this deﬁnition of R being total agrees with the deﬁnition in Section 4.3 
when R is a function. 
If R  is a binary relation  from A  to B , we deﬁne AR  to  to be  the range of R.  So 
a  relation  is  surjective  iff  its  range  equals  its  codomain.  Again,  in  the  case  that R 
is a function, these deﬁnitions of “range” and “total” agree with the deﬁnitions in 
Section 4.3. 

4.7.1  Relation Diagrams 
→
We can explain all these properties of a relation R  :  A
B  in terms of a diagram 
where all the elements of the domain, A, appear in one column (a very long one if 
A  is  inﬁnite) and all  the elements of  the codomain, B ,  appear  in another column, 
and we  draw  an  arrow  from  a  point  a  in  the  ﬁrst  column  to  a  point  b  in  the  sec­
ond  column when a  is  related  to  b by R.  For example,  here are diagrams  for  two 
functions: 

3  The names  “surjective”  and  “injective”  are unmemorable  and nondescriptive.  Some  authors use 
the term onto for surjective and one-to-one for injective, which are shorter but arguably no more memo­
rable. 

4.8.  THE MAPPING RULE 

61 

A

b

a 

B	
�  1	
�������	�
2	
�	�
�
����
c 
�� 3
�	
���� �
d  �
� 
4	
�
�	
e  �

A

a 

B 
�  1 
������� �
2 
b
� �
� 
c  � �
��
d  �  �
�

3 

4 

���

5 

Here is what the deﬁnitions say about such pictures: 
•	 “R  is  a  function”  means  that  every  point  in  the  domain  column,  A,  has  at 
most one arrow out of it. 
•	 “R is total” means that every point in the A column has at least one arrow out of 
it.  So if R is a function, being total really means every point in the A column 
has exactly one arrow out of it. 
•	 “R  is  surjective” means  that  every  point  in  the  codomain  column,  B ,  has  at 
least one arrow into it. 
•	 “R  is  injective” means  that  every  point  in  the  codomain  column,  B ,  has  at 
most one arrow into it. 
•	 “R is bijective” means that every point in the A column has exactly one arrow 
out of it, and every point in the B  column has exactly one arrow into it. 
So  in  the diagrams above,  the  relation on  the  left  is a  total,  surjective  function 
(every  element  in  the A  column has  exactly  one  arrow  out,  and  every  element  in 
the B column has at least one arrow in), but not injective (element 3 has two arrows 
going into it).  The relation on the right is a total, injective function (every element 
in the A column has exactly one arrow out, and every element in the B column has 
at most one arrow in), but not surjective (element 4 has no arrow going into it). 
Notice  that  the arrows  in a diagram  for R precisely correspond  to  the pairs  in 
the  graph  of R.  But  graph (R)  does  not  determine  by  itself whether R  is  total  or 
surjective; we also need to know what the domain is to determine if R is total, and 
we need to know the codomain to tell if it’s surjective. 
Example  4.7.1.  The  function  deﬁned  by  the  formula  1/x2  is  total  if  its  domain  is 
R+  but partial if its domain is some set of real numbers including 0.  It is bijective 
if  its domain  and  codomain  are both R+ ,  but neither  injective nor  surjective  if  its 
domain and codomain are both R. 

4.8  The Mapping Rule 

The  relational properties  above  are useful  in ﬁguring out  the  relative  sizes of do­
mains and codomains. 

62 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

If A  is a ﬁnite set, we  let  |A| be  the number of elements  in A.  A ﬁnite set may 
have no elements (the empty set), or one element, or two elements,. . . or any non­
negative integer number of elements. 
→
Now  suppose R  :  A
B  is  a  function.  Then  every  arrow  in  the diagram  for 
R  comes  from  exactly  one  element  of  A,  so  the  number  of  arrows  is  at most  the 
number of elements in A. That is, if R is a function, then 
|A| ≥ #arrows. 

Similarly,  if R  is surjective,  then every element of B  has an arrow  into  it,  so  there 
must be at least as many arrows in the diagram as the size of B . That is, 
#arrows ≥ |B | . 
Combining  these  inequalities  implies  that  if R  is a  surjective  function,  then  |A| ≥ 
|B |.  In short,  if we write A  surj  B  to mean that there  is a surjective function from 
A to B , then we’ve just proved a lemma:  if A surj B , then |A| ≥ |B |. The following 
deﬁnition  and  lemma  lists  include  this  statement  and  three  similar  rules  relating 
domain and codomain size to relational properties. 

Deﬁnition 4.8.1.  Let A, B be (not necessarily ﬁnite) sets. Then 

1.  A surj B  iff there is a surjective function from A to B . 

2.  A inj B  iff there is a total injective relation from A to B . 

3.  A bij B  iff there is a bijection from A to B . 

4.  A strict B  iff A surj B , but not B  surj A. 

Lemma 4.8.2.  [Mapping Rules]  Let A and B  be ﬁnite sets. 
1.  If A surj B , then |A| ≥ |B |. 
2.  If A  inj B , then |A| ≤ |B |. 
3.  If R bij B , then |A| = |B |. 
4.  If R strict B , then |A| > |B |. 

Mapping  rule  2  can  be  explained  by  the  same  kind  of  “arrow  reasoning”  we 
used  for  rule  1.  Rules  3  and  4  are  immediate  consequences  of  these  ﬁrst  two 
mapping rules. 

4.9  The sizes of inﬁnite sets 

Mapping Rule 1 has a converse:  if the size of a ﬁnite set, A, is greater than or equal 
to  the  size  of  another  ﬁnite  set,  B ,  then  it’s  always  possible  to deﬁne  a  surjective 

4.9.  THE SIZES OF INFINITE SETS 

63 

function from A to B .  In fact, the surjection can be a total function. To see how this 
works, suppose for example that 
A = {a0 , a1 , a2 , a3 , a4 , a5}
B = {b0 , b1 , b2 , b3} . 
→ 
Then deﬁne a total function f  : A

B by the rules 

f (a0 ) ::= b0 , f (a1 ) ::= b1 , f (a2 ) ::= b2 , f (a3 ) = f (a4 ) = f (a5 ) ::= b3 . 

In  fact,  if A and B  are ﬁnite  sets of  the  same  size,  then we  could also deﬁne a 
bijection from A to B by this method. 
In short, we have ﬁgured out if A and B are ﬁnite sets, then |A| ≥ |B | if and only 
if  A surj B , and similar iff ’s hold for all the other Mapping Rules: 

Lemma 4.9.1.  For ﬁnite sets, A, B , 
|A| ≥ |B | 
|A| ≤ |B | 
|A| = |B | 
|A| > |B | 

iff  A surj B , 
iff  A  inj B , 
iff  A bij B , 
iff  A strict B . 

This  lemma  suggests  a  way  to  generalize  size  comparisons  to  inﬁnite  sets, 
namely, we can  think of  the relation surj as an “at  least as big as” relation between 
sets, even if they are inﬁnite.  Similarly, the relation bij can be regarded as a “same 
size”  relation  between  (possibly  inﬁnite)  sets,  and  strict  can  be  thought  of  as  a 
“strictly bigger than” relation between sets. 
Warning:  We haven’t,  and won’t, deﬁne what  the “size” of an  inﬁnite  is.  The 
deﬁnition of  inﬁnite “sizes”  is cumbersome and  technical,  and we can get by  just 
ﬁne without it.  All we need are the “as big as” and “same size” relations, surj and 
bij, between sets. 
But  there’s  something  else  to  watch  out  for.  We’ve  referred  to  surj  as  an  “as 
big as” relation and bij as a “same size” relation on sets. Of course most of the “as 
big  as”  and  “same  size”  properties  of  surj  and  bij  on  ﬁnite  sets  do  carry  over  to 
inﬁnite sets, but some important ones don’t —as we’re about to show.  So you have to 
be careful: don’t assume that surj has any particular “as big as” property on inﬁnite 
sets until it’s been proved. 
Let’s  begin  with  some  familiar  properties  of  the  “as  big  as”  and  “same  size” 
relations on ﬁnite sets that do carry over exactly to inﬁnite sets: 

Lemma 4.9.2.  For any sets, A, B , C , 

1.  A surj B  and B  surj C, 

implies  A surj C . 

2.  A bij B  and B  bij C, 

implies  A bij C . 

3.  A bij B 

implies  B  bij A. 

64 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

Lemma 4.9.2.1 and 4.9.2.2  follow  immediately  from  the  fact  that compositions 
of  surjections  are  surjections,  and  likewise  for  bijections,  and  Lemma  4.9.2.3  fol­
lows  from  the  fact  that  the  inverse of a bijection  is a bijection.  We’ll  leave a proof 
of these facts to Problem 4.2. 
Another familiar property of ﬁnite sets carries over to inﬁnite sets, but this time 
it’s not so obvious: 
Theorem  4.9.3  (Schr ¨oder-Bernstein).  For  any  sets  A, B ,  if  A  surj  B  and  B  surj  A, 
then A bij B . 
That  is,  the  Schr ¨oder-Bernstein  Theorem  says  that  if  A  is  at  least  as  big  as  B 
and  conversely,  B  is  at  least  as  big  as  A,  then  A  is  the  same  size  as  B .  Phrased 
this way,  you might be  tempted  to  take  this  theorem  for  granted,  but  that would 
be a mistake. For inﬁnite sets A and B , the Schr ¨oder-Bernstein Theorem is actually 
→
pretty  technical.  Just  because  there  is  a  surjective  function  f  :  A
B  —which
→
need not be  a bijection —and  a  surjective  function  g  :  B
A —which  also need 
→
not be a bijection —it’s not at all clear that there must be a bijection e : A
B . The 
idea is to construct e from parts of both f  and g . We’ll leave the actual construction 
to Problem 4.7. 

Inﬁnity is different 

A basic property of ﬁnite sets that does not carry over to inﬁnite sets is that adding 
something  new  makes  a  set  bigger.  That  is,  if  A  is  a  ﬁnite  set  and  b  ∈/ A,  then 
|A ∪ {b}| =  |A| + 1, and so A and A ∪ {b} are not the same size. But if A is inﬁnite, 
then these two sets are the same size! 
Lemma 4.9.4.  Let A be a set and b /∈ A. Then A is inﬁnite iff A bij A ∪ {b}. 
Proof.  Since A is not the same size as A ∪ {b} when A is ﬁnite, we only have to show 
that A ∪ {b} is the same size as A when A is inﬁnite. 
That  is, we have  to ﬁnd a bijection between A ∪ {b} and A when A  is  inﬁnite. 
Here’s how:  since A  is  inﬁnite,  it certainly has at  least one element;  call  it a0 .  But 
since A is inﬁnite, it has at least two elements, and one of them must not be equal 
to a0 ; call this new element a1 . But since A is inﬁnite, it has at least three elements, 
one of which must not equal a0  or a1 ; call this new element a2 .  Continuing in the 
way, we conclude that there is an inﬁnite sequence a0 , a1 , a2 , . . . , an , . . .  of different 
elements of A. Now it’s easy to deﬁne a bijection e : A ∪ {b} → A: 
e(b) ::= a0 , 
e(an ) ::= an+1 
e(a) ::= a 

for n ∈ N, 
for a ∈ A − {b, a0 , a1 , . . . } . 

� 
A  set,  C ,  is  countable  iff  its  elements  can  be  listed  in  order,  that  is,  the distinct 
elements is A are precisely 

c0 , c1 , . . . , cn , . . . . 

4.9.  THE SIZES OF INFINITE SETS 

65 

This means that if we deﬁned a function, f , on the nonnegative integers by the rule 
that f (i) ::= ci , then f  would be a bijection from N to C . More formally, 
Deﬁnition 4.9.5.  A set, C ,  is countably  inﬁnite  iff N  bij  C .  A set  is countable  iff  it  is 
ﬁnite or countably inﬁnite. 

A small modiﬁcation4  of the proof of Lemma 4.9.4 shows that countably inﬁnite 
sets  are  the  “smallest”  inﬁnite  sets,  namely,  if  A  is  a  countably  inﬁnite  set,  then 
A surj N. 
Since  adding  one  new  element  to  an  inﬁnite  set  doesn’t  change  its  size,  it’s 
obvious  that  neither  will  adding  any  ﬁnite  number  of  elements.  It’s  a  common 
mistake  to  think  that  this proves  that you can  throw  in countably  inﬁnitely many 
new elements.  But just because it’s ok to do something any ﬁnite number of times 
doesn’t make it OK to do an inﬁnite number of times.  For example, starting from 
3,  you  can  add  1  any  ﬁnite  number  of  times  and  the  result  will  be  some  integer 
greater  than  or  equal  to  3.  But  if  you  add  add  1  a  countably  inﬁnite  number  of 
times, you don’t get an integer at all. 
It  turns  out  you  really  can  add  a  countably  inﬁnite  number  of  new  elements 
to a countable set and still wind up with  just a countably  inﬁnite set, but another 
argument is needed to prove this: 
Lemma 4.9.6.  If A and B  are countable sets, then so is A ∪ B . 
Proof.  Suppose  the  list  of  distinct  elements  of  A  is  a0 , a1 , . . .  and  the  list  of  B  is 
b0 , b1 , . . . . Then a list of all the elements in A ∪ B  is just 

a0 , b0 , a1 , b1 , . . . an , bn , . . . . 

(4.4) 

Of  course  this  list will  contain  duplicates  if  A  and  B  have  elements  in  common, 
but  then deleting all but  the ﬁrst occurrences of each element  in  list  (4.4)  leaves a 
� 
list of all the distinct elements of A and B . 

4.9.1  Inﬁnities in Computer Science 
We’ve  run  into  a  lot  of  computer  science  students who wonder why  they  should 
care about  inﬁnite sets:  any data set  in a computer memory  is  limited by  the size 
of memory,  and  since  the  universe  appears  to  have  ﬁnite  size,  there  is  a  limit  on 
the possible size of computer memory. 
The problem with this argument is that universe-size bounds on data items are 
so big and uncertain (the universe seems to be getting bigger all the time), that it’s 
simply not helpful to make use of possible bounds. For example, by this argument 
the  physical  sciences  shouldn’t  assume  that measurements might  yield  arbitrary 
real numbers, because there can only be a ﬁnite number of ﬁnite measurements in 
a universe of ﬁnite lifetime.  What do you think scientiﬁc theories would look like 
without using the inﬁnite set of real numbers? 

4 See Problem 4.3 

66 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

Similary,  in computer  science,  it  simply  isn’t plausible  that writing a program 
to add nonnegative integers with up to as many digits as, say,  the stars in the sky 
(billions of galaxies each with billions of stars), would be any different than writing 
a program that would add any two integers no matter how many digits they had. 
That’s why basic programming data types like integers or strings, for example, 
can be deﬁned without imposing any bound on the sizes of data items. Each datum 
of type string has only a ﬁnite number of letters, but there are an inﬁnite number 
of data  items  of  type string.  When we  then  consider  string procedures  of  type 
string-->string, not only are there an inﬁnite number of such procedures, but 
each  procedure  generally  behaves differently  on different  inputs,  so  that  a  single 
string-->string procedure may embody an inﬁnite number of behaviors. 
In short, an educated computer scientist can’t get around having to understand 
inﬁnite sets. 

4.9.2  Problems 

Class Problems 

Problem 4.2. 
Deﬁne a surjection relation, surj, on sets by the rule 

Deﬁnition.  A surj B  iff there is a surjective function from A to B . 

Deﬁne the injection relation, inj, on sets by the rule 

Deﬁnition.  A  inj B  iff there is a total injective relation from A to B . 

(a)  Prove that if A surj B  and B  surj C , then A surj C . 

(b)  Explain why A surj B  iff B  inj A. 

(c)  Conclude from (a) and (b) that if A  inj B  and B  inj C , then A  inj C . 

Problem 4.3. 

4.9.  THE SIZES OF INFINITE SETS 

67 

Lemma 4.9.4. Let A be a set and b /∈ A.  If A is inﬁnite, then there is a bijection from 
A ∪ {b} to A. 

Proof.  Here’s how to deﬁne the bijection:  since A is inﬁnite, it certainly has at least 
one element; call it a0 .  But since A is inﬁnite, it has at least two elements, and one 
of  them must not be  equal  to a0 ;  call  this new  element a1 .  But  since A  is  inﬁnite, 
it has  at  least  three  elements,  one of which must not  equal  a0  or  a1 ;  call  this new 
element a2 .  Continuing in the way, we conclude that there is an inﬁnite sequence 
a0 , a1 , a2 , . . . , an , . . .  of  different  elements  of  A.  Now  we  can  deﬁne  a  bijection 
f  : A ∪ {b} → A: 
f (b) ::= a0 , 
f (an ) ::= an+1 
f (a) ::= a 

for n ∈ N, 
for a ∈ A − {b, a0 , a1 , . . . } . 

� 

(a)  Several students felt the proof of Lemma 4.9.4 was worrisome, if not circular. 
What do you think? 

(b)  Use the proof of Lemma 4.9.4 to show that if A is an inﬁnite set, then there is 
surjective  function  from A  to N,  that  is,  every  inﬁnite  set  is  “as  big  as”  the  set  of 
nonnegative integers. 

Problem 4.4. 
→
Let R  : A
B  be a binary relation.  Use an arrow counting argument to prove the 
following generalization of the Mapping Rule: 
Lemma.  If R is a function, and X  ⊆ A, then 
|X | ≥ |X R| . 

Problem 4.5. 
Let  A  =  {a0 , a1 , . . . , an−1 }  be  a  set  of  size  n,  and  B  =  {b0 , b1 , . . . , bm−1}  a  set  of 
size m.  Prove that |A × B | = mn by deﬁning a simple bijection from A × B  to the 
nonnegative integers from 0 to mn − 1. 

Problem 4.6. 
The rational numbers ﬁll in all the spaces between the integers, so a ﬁrst thought is 
that there must be more of them than the integers, but it’s not true.  In this problem 

68 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

you’ll show that there are the same number of nonnegative rational as nonnegative 
integers.  In short, the nonnegative rationals are countable. 
(a)  Describe a bijection between all the integers, Z, and the nonnegative integers, 
N. 
(b)  Deﬁne a bijection between the nonnegative integers and the set, N × N, of all 
the ordered pairs of nonnegative integers: 

(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), . . . 
(1, 0), (1, 1), (1, 2), (1, 3), (1, 4), . . . 
(2, 0), (2, 1), (2, 2), (2, 3), (2, 4), . . . 
(3.0), (3, 1), (3, 2), (3, 3), (3, 4), . . . 
. . . 

(c)  Conclude  that  N  is  the  same  size  as  the  set,  Q,  of  all  nonnegative  rational 
numbers. 

Problem 4.7. 
Suppose sets A and B have no elements in common, and 

•  B  is as small as A because there is a total injective function g  : B

•  A is as small as B because there is a total injective function f  : A

→ 
B , and 
A.→ 
Picturing  the  diagrams  for  f  and  g ,  there  is  exactly  one  arrow  out  of  each  ele­
ment —a left-to-right f -arrow if the element in A and a right-to-left g -arrow if the 
element in B .  This is because f  and g  are total functions.  Also, there is at most one 
arrow into any element, because f  and g are injections. 
So starting at any element, there is a unique, and unending path of arrows go­
ing forwards. There is also a unique path of arrows going backwards, which might 
be unending, or might end at an element that has no arrow into it. These paths are 
completely separate:  if two ran into each other, there would be two arrows into the 
element where they ran together. 
This divides all the elements into separate paths of four kinds: 

i.  paths that are inﬁnite in both directions, 

ii.  paths that are inﬁnite going forwards starting from some element of A. 

iii.  paths that are inﬁnite going forwards starting from some element of B . 

iv.  paths that are unending but ﬁnite. 

(a)  What do the paths of the last type (iv) look like? 

(b)  Show that for each type of path, either 

4.9.  THE SIZES OF INFINITE SETS 

69 

•  the f -arrows deﬁne a bijection between the A and B  elements on the path, or 
•  the g -arrows deﬁne a bijection between B  and A elements on the path, or 
•  both sets of arrows deﬁne bijections. 

For which kinds of paths do both sets of arrows deﬁne bijections? 

(c)  Explain how  to piece  these bijections  together  to prove  that A  and B  are  the 
same size. 

Homework Problems 

Problem 4.8. 
→ 
→
C  be  functions and h  :  A
Let f  :  A
B  and g  :  B
namely, h(a) ::= g(f (a)) for all a ∈ A. 
(a)  Prove that if f  and g are surjections, then so is h. 

→

C  be  their composition, 

(b)  Prove that if f  and g are bijections, then so is h. 
→ 
(c)  If f  is a bijection, then deﬁne f �  : B
A so that 
f � (b) ::=  the unique a ∈ A such that f (a) = b. 
Prove that f �  is a bijection.  (The function f �  is called the inverse of f .  The notation 
f −1  is often used for the inverse of f .) 

Problem 4.9. 
In  this problem  you will prove  a  fact  that may  surprise  you —or make  you  even 
more convinced that set theory is nonsense:  the half-open unit interval is actually 
the  same  size  as  the  nonnegative  quadrant  of  the  real  plane!5  Namely,  there  is  a 
bijection from (0, 1] to [0, ∞)2 . 
(a)  Describe a bijection from (0, 1] to [0, ∞). 
Hint:  1/x almost works. 
(b)  An  inﬁnite  sequence  of  the  decimal  digits  {0, 1, . . . , 9}  will  be  called  long  if 
it  has  inﬁnitely many  occurrences  of  some  digit  other  than  0.  Let L  be  the  set  of 
all such  long sequences.  Describe a bijection  from L  to  the half-open real  interval 
(0, 1]. 
Hint: Put a decimal point at the beginning of the sequence. 

(c)  Describe  a  surjective  function  from  L  to  L2  that  involves  alternating  digits 
from two long sequences.  a Hint: The surjection need not be total. 

(d)  Prove the following lemma and use it to conclude that there is a bijection from 
L2  to (0, 1]2 . 
5 The half open unit interval, (0, 1], is {r  ∈ R  | 0 < r ≤ 1}.  Similarly, [0, ∞) ::= {r  ∈ R  | r ≥ 0}. 

70 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

Lemma  4.9.7.  Let A  and B  be  nonempty  sets.  If  there  is  a  bijection  from A  to B ,  then 
there is also a bijection from A × A to B × B . 
(e)  Conclude  from  the  previous  parts  that  there  is  a  surjection  from  (0, 1]  and 
(0, 1]2 .  Then appeal to the Schr ¨oder-Bernstein Theorem to show that there is actu­
ally a bijection from (0, 1] and (0, 1]2 . 
(f)  Complete the proof that there is a bijection from (0, 1] to [0, ∞)2 . 

4.10.  GLOSSARY OF SYMBOLS 

71 

4.10  Glossary of Symbols 

symbol  meaning 
∈ 
is a member of 
⊆ 
is a subset of 
⊂ 
is a proper subset of 
∪ 
set union 
∩
set intersection 
complement of a set, A 
A 
P (A) 
powerset of a set, A 
the empty set, {}
∅ 
N 
nonnegative integers 
Z 
integers 
Z+ 
positive integers 
Z− 
negative integers 
Q 
rational numbers 
R 
real numbers 
C 
complex numbers 
the empty string/list 
λ 

72 

CHAPTER 4.  MATHEMATICAL DATA TYPES 

Chapter 5 

First-Order Logic 

5.1  Quantiﬁers 

There are a couple of assertions commonly made about a predicate:  that it is some­
times true and that it is always true.  For example, the predicate 
“x 2  ≥ 0” 

is always true when x is a real number. On the other hand, the predicate 
� 
“5x 2  − 7 = 0” 
is only sometimes true; speciﬁcally, when x = ±  7/5. 
There are several ways to express the notions of “always true” and “sometimes 
true”  in English.  The table below gives some general formats on the  left and spe­
ciﬁc examples using those formats on the right. You can expect to see such phrases 
hundreds of times in mathematical writing! 

For all n, P (n) is true. 
P (n) is true for every n. 

Always True 
For all x ∈ R, x2  ≥ 0. 
x2  ≥ 0 for every x ∈ R. 
Sometimes True 
There exists an n such that P (n) is true.  There exists an x ∈ R such that 5x2  − 7 = 0.

5x2  − 7 = 0 for some x ∈ R.

P (n) is true for some n. 
5x2  − 7 = 0 for at least one x ∈ R.

P (n) is true for at least one n. 
All  these  sentences  quantify  how  often  the  predicate  is  true.  Speciﬁcally,  an 
assertion that a predicate is always true is called a universal quantiﬁcation, and an 
assertion  that a predicate  is  sometimes  true  is an  existential quantiﬁcation.  Some­
times the English sentences are unclear with respect to quantiﬁcation: 

73 

74 

CHAPTER 5.  FIRST-ORDER LOGIC 

“If you can solve any problem we come up with, then you get an A for the 
course.” 

The phrase “you  can  solve any problem we  can  come up with”  could  reasonably 
be interpreted as either a universal or existential quantiﬁcation: 

“you can solve every problem we come up with,” 

or maybe 

“you can solve at least one problem we come up with.” 

In any case, notice that this quantiﬁed phrase appears inside a larger if-then state­
ment. This is quite normal; quantiﬁed statements are themselves propositions and 
can be combined with and, or, implies, etc., just like any other proposition. 

5.1.1  More Cryptic Notation 
There  are  symbols  to  represent  universal  and  existential  quantiﬁcation,  just  as 
there  are  symbols  for  “and”  (∧),  “implies”  (−→),  and  so  forth.  In  particular,  to 
say that a predicate, P , is true for all values of x in some set, D , one writes: 
∀x ∈ D . P (x) 
The symbol ∀ is read “for all”, so this whole expression is read “for all x in D , P (x) 
is  true”.  To  say  that  a  predicate P (x)  is  true  for  at  least  one  value  of  x  in D ,  one 
writes: 
∃x ∈ D . P (x) 
The backward-E, ∃, is read “there exists”. So this expression would be read, “There 
exists an x in D such that P (x) is true.”  The symbols ∀ and ∃ are always followed 
by a variable —usually with an indication of the set the variable ranges over —and 
then a predicate, as in the two examples above. 
As an example, let Probs be the set of problems we come up with, Solves(x) be 
the predicate “You can solve problem x”, and G be the proposition, “You get an A 
for the course.” Then the two different interpretations of 

“If you can solve any problem we come up with, then you get an A for 
the course.” 

can be written as follows: 
(∀x ∈ Probs. Solves(x)) IM P L I E S G, 

or maybe 

(∃x ∈ Probs. Solves(x)) IM P L I E S G. 

5.1.  QUANTIFIERS 

75 

5.1.2  Mixing Quantiﬁers 
Many  mathematical  statements  involve  several  quantiﬁers.  For  example,  Gold­
bach’s Conjecture states: 

“Every even integer greater than 2 is the sum of two primes.” 

Let’s write this more verbosely to make the use of quantiﬁcation clearer: 

For every even integer n greater than 2, there exist primes p and q such 
that n = p + q . 

Let  Evens  be  the  set  of  even  integers  greater  than  2,  and  let  Primes  be  the  set  of 
primes. Then we can write Goldbach’s Conjecture in logic notation as follows: 
�
��
� � 
�� 
� 
∀n ∈ Evens  ∃p ∈ Primes ∃q ∈ Primes. n = p + q . 
for every even 
there exist primes 
integer n >  2 
p and q such that 

5.1.3  Order of Quantiﬁers 
Swapping the order of different kinds of quantiﬁers (existential or universal) usu­
ally changes the meaning of a proposition.  For example,  let’s return to one of our 
initial, confusing statements: 

“Every American has a dream.” 

This sentence is ambiguous because the order of quantiﬁers is unclear. Let A be 
the  set of Americans,  let D  be  the  set of dreams,  and deﬁne  the predicate H (a, d) 
to be “American a has dream d.”.  Now  the  sentence could mean  there  is a  single 
dream that every American shares: 
∃ d ∈ D ∀a ∈ A. H (a, d) 

For  example,  it might  be  that  every  American  shares  the  dream  of  owning  their 
own home. 
Or it could mean that every American has a personal dream: 
∀a ∈ A ∃ d ∈ D . H (a, d) 

For  example,  some Americans may  dream  of  a  peaceful  retirement,  while  others 
dream of continuing practicing their profession as long as they live, and still others 
may dream of being so rich they needn’t think at all about work. 
Swapping  quantiﬁers  in  Goldbach’s  Conjecture  creates  a  patently  false  state­
ment that every even number ≥ 2 is the sum of the same two primes: 
� �
��
� 
� 
�� 
∃ p ∈ Primes ∃ q ∈ Primes  ∀n ∈ Evens. n = p + q . 
for every even 
there exist primes 
integer n >  2 
p and q such that 

76 

CHAPTER 5.  FIRST-ORDER LOGIC 

Variables Over One Domain 

When  all  the variables  in  a  formula  are understood  to  take values  from  the  same 
nonempty set, D ,  it’s conventional to omit mention of D .  For example,  instead of 
∀x  ∈  D  ∃y  ∈  D .  Q(x, y) we’d write  ∀x∃y .  Q(x, y).  The  unnamed  nonempty  set 
that x and y  range over is called the domain of discourse, or just plain domain, of the 
formula. 
It’s  easy  to  arrange  for  all  the variables  to  range  over  one domain.  For  exam­
ple, Goldbach’s Conjecture could be expressed with all variables ranging over the 
domain N as 
∀n. n ∈ Evens IM P L I E S  (∃ p∃ q . p ∈ Primes ∧ q ∈ Primes ∧ n = p + q). 

5.1.4  Negating Quantiﬁers 
There is a simple relationship between the two kinds of quantiﬁers. The following 
two sentences mean the same thing: 

It is not the case that everyone likes to snowboard. 
There exists someone who does not like to snowboard. 

In terms of logic notation, this follows from a general property of predicate formu­
las: 
NO T ∀x. P (x)  is equivalent to  ∃x.  NO T P (x). 
Similarly, these sentences mean the same thing: 

There does not exist anyone who likes skiing over magma. 
Everyone dislikes skiing over magma. 

We can express the equivalence in logic notation this way: 
(NO T ∃x. P (x)) I FF ∀x.  NO T P (x). 

(5.1) 

The  general  principle  is  that  moving  a  “not”  across  a  quantiﬁer  changes  the  kind  of 
quantiﬁer. 

5.1.5  Validity 
A propositional formula is called valid when it evaluates to T no matter what truth 
values  are  assigned  to  the  individual  propositional  variables.  For  example,  the 
propositional version of the Distributive Law is that P  AND (Q OR R) is equivalent 
to (P  AND Q) OR  (P  AND R). This is the same as saying that 

[P  AND  (Q OR R)] I FF  [(P  AND Q) OR  (P  AND R)] 

is valid. 

5.1.  QUANTIFIERS 

77 

The  same  idea  extends  to  predicate  formulas,  but  to  be  valid,  a  formula  now 
must  evaluate  to  true  no matter what  values  its  variables may  take  over  any  un­
speciﬁed domain,  and no matter what  interpretation a predicate variable may be 
given.  For example, we already observed that the rule for negating a quantiﬁer is 
captured by the valid assertion (5.1). 
Another useful example of a valid assertion is 
∃x∀y . P (x, y) IM P L I E S ∀y∃x. P (x, y). 

(5.2) 

Here’s an explanation why this is valid: 

(5.3) 

Let D be the domain for the variables and P0  be some binary predicate1 
on D . We need to show that if 
∃x ∈ D ∀y ∈ D . P0 (x, y) 
holds under this interpretation, then so does 
∀y ∈ D  ∃x ∈ D . P0 (x, y). 
(5.4) 
So suppose (5.3)  is true.  Then by deﬁnition of ∃,  this means that some 
element d0  ∈ D has the property that 
∀y ∈ D . P0 (d0 , y). 
By deﬁnition of ∀, this means that 
P0 (d0 , d) 
is  true  for  all  d  ∈  D .  So  given  any  d  ∈  D ,  there  is  an  element  in  D , 
namely,  d0 ,  such  that  P0 (d0 , d)  is  true.  But  that’s  exactly  what  (5.4) 
means,  so  we’ve  proved  that  (5.4)  holds  under  this  interpretation,  as 
required. 

We  hope  this  is  helpful  as  an  explanation,  but  we  don’t  really  want  to  call  it 
a  “proof.”  The  problem  is  that  with  something  as  basic  as  (5.2),  it’s  hard  to  see 
what more  elementary  axioms  are  ok  to  use  in  proving  it.  What  the  explanation 
above did was  translate  the  logical  formula  (5.2)  into English  and  then  appeal  to 
the  meaning,  in  English,  of  “for  all”  and  “there  exists”  as  justiﬁcation.  So  this 
wasn’t a proof,  just an explanation that once you understand what (5.2) means,  it 
becomes obvious. 
In contrast to (5.2), the formula 
∀y∃x. P (x, y) IM P L I E S ∃x∀y . P (x, y). 

(5.5) 

is not valid.  We  can prove  this  just by describing an  interpretation where  the hy­
pothesis,  ∀y∃x.  P (x, y),  is  true  but  the  conclusion,  ∃x∀y .  P (x, y),  is  not  true.  For 
1 That is, a predicate that depends on two variables. 

78 

CHAPTER 5.  FIRST-ORDER LOGIC 

example,  let  the  domain  be  the  integers  and  P (x, y)  mean  x > y .  Then  the  hy­
pothesis would be true because, given a value, n, for y we could choose the value 
of x  to be n + 1,  for example.  But under  this  interpretation  the conclusion asserts 
that there is an integer that is bigger than all integers, which is certainly false.  An 
interpretation  like  this which  falsiﬁes  an  assertion  is  called  a  counter model  to  the 
assertion. 

5.1.6  Problems 
Class Problems 

Problem 5.1. 
A media  tycoon  has  an  idea  for  an  all-news  television  network  called  LNN:  The 
Logic News Network.  Each segment will begin with a deﬁnition of the domain of 
discourse and a few predicates.  The day’s happenings can then be communicated 
concisely in logic notation.  For example, a broadcast might begin as follows: 
“THIS IS LNN. The domain of discourse is {Albert, Ben, Claire, David, Emily}. 
Let D(x) be a predicate that is true if x is deceitful. Let L(x, y) be a pred­
icate  that  is  true  if x  likes y .  Let G(x, y) be a predicate  that  is  true  if x 
gave gifts to y .” 

Translate the following broadcasted logic notation into (English) statements. 
(a) 

( (D(Ben) ∨ D(David))) −→ (L(Albert, Ben) ∧ L(Ben, Albert))
¬

(b) 

(c) 

(d) 

∀x (x = Claire ∧ ¬L(x, Emily)) ∨ (x =� Claire ∧ L(x, Emily)) ∧ 
∀x (x = David ∧ L(x, Claire)) ∨ (x =� David ∧ ¬L(x, Claire)) 

¬D(Claire) −→ (G(Albert, Ben) ∧ ∃ xG(Ben, x)) 

∀x∃y∃z  (y =�

z ) ∧ L(x, y) ∧ ¬L(x, z ) 

(e)  How  could  you  express  “Everyone  except  for  Claire  likes  Emily”  using  just 
propositional connectives without using any quantiﬁers (∀, ∃)? Can you generalize 
to explain how any logical formula over this domain of discourse can be expressed 
without quantiﬁers?  How big would the formula in the previous part be if it was 
expressed this way? 

5.1.  QUANTIFIERS 

79 

Problem 5.2. 
The  goal  of  this  problem  is  to  translate  some  assertions  about  binary  strings  into 
logic notation. The domain of discourse is the set of all ﬁnite-length binary strings: 
λ,  0,  1,  00,  01,  10,  11,  000,  001,  . . . .  (Here  λ  denotes  the  empty  string.)  In  your 
translations,  you may use  all  the  ordinary  logic  symbols  (including =),  variables, 
and the binary symbols 0, 1 denoting 0, 1. 
A  string  like  01x0y  of  binary  symbols  and  variables  denotes  the  concatenation 
of  the  symbols  and  the binary  strings  represented by  the variables.  For  example, 
if  the value of x  is 011 and  the value of y  is 1111,  then  the value of 01x0y  is  the 
binary string 0101101111. 
Here are some examples of formulas and their English translations. Names for 
these predicates are  listed  in the third column so that you can reuse them  in your 
solutions (as we do in the deﬁnition of the predicate NO -1 S  below). 

Meaning 
x is a preﬁx of y 
x is a substring of y 
x is empty or a string of 0’s 

Formula 
∃z  (xz = y) 
∃u∃v (uxv = y) 
NOT(SU B S TR ING(1, x)) 

Name 
PR E FIX (x, y ) 
SU B S TR ING (x, y ) 
NO -1 S (x) 

(a)  x consists of three copies of some string. 

(b)  x is an even-length string of 0’s. 

(c)  x does not contain both a 0 and a 1. 
(d)  x is the binary representation of 2k  + 1 for some integer k ≥ 0. 
(e)  An elegant, slightly trickier way to deﬁne NO -1 S(x) is: 

Explain why (*) is true only when x is a string of 0’s. 

PR E FIX(x, 0x). 

(*) 

Problem 5.3. 
For  each  of  the  logical  formulas,  indicate  whether  or  not  it  is  true  when  the  do­
main  of  discourse  is  N,  (the  nonnegative  integers  0,  1,  2,  . . . ),  Z  (the  integers),  Q 
(the  rationals),  R  (the  real  numbers),  and  C  (the  complex  numbers).  Add  a  brief 
explanation to the few cases that merit one. 
∃x 
∀x  ∃y 
∀y  ∃x 
∃y 
= 0 
∃x  ∃y 

(x2  =  2) 
(x2  =  y) 
(x2  =  y) 
(xy  =  1)
(x + 2y  =  2) ∧ (2x + 4y = 5) 

∀x  �

80 

CHAPTER 5.  FIRST-ORDER LOGIC 

Problem 5.4. 
Show that 

(∀x∃y . P (x, y)) −→ ∀z . P (z , z ) 
is not valid by describing a counter-model. 

Homework Problems 

Problem 5.5. 
Express each of the following predicates and propositions in formal logic notation. 
The domain of discourse  is  the nonnegative  integers, N.  Moreover,  in addition  to 
the propositional operators,  variables  and quantiﬁers,  you may deﬁne predicates 
using addition, multiplication, and equality symbols, but no constants (like 0, 1,. . . ) 
and no exponentiation (like xy ). For example, the proposition “n is an even number ” 
could be written 
∃m. (m + m = n). 
(a)  n is the sum of two fourth-powers (a fourth-power is k4  for some integer k). 
Since  the  constant  0  is not  allowed  to  appear  explicitly,  the predicate  “x  = 0” 
can’t be written directly, but note that it could be expressed in a simple way as: 
x + x = x. 
Then the predicate x > y could be expressed 
∃w. (y + w = x) ∧ (w = 0)
. 
Note  that  we’ve  used  “w  =�
0”  in  this  formula,  even  though  it’s  technically  not 
” is equivalent to the allowed formula “¬(w + w = w),” 
allowed.  But since “w = 0
we can use “w = 0
” with the understanding that it abbreviates the real thing. And 
now that we’ve shown how to express “x > y ,” it’s ok to use it too. 
(b)  x = 1. 
(c)  m is a divisor of n (notation: m  | n) 
(d)  n is a prime number (hint: use the predicates from the previous parts) 

(e)  n is a power of 3. 

Problem 5.6. 
Translate the following sentence into a predicate formula: 
There  is  a  student  who  has  emailed  exactly  two  other  people  in  the 
class, besides possibly herself. 
The domain of discourse should be the set of students in the class; in addition, 
the only predicates that you may use are 
•  equality, and 
•  E (x, y), meaning that “x has sent e-mail to y .” 

�
�
�
5.2.  THE LOGIC OF SETS 

81 

5.2  The Logic of Sets 

5.2.1  Russell’s Paradox 
Reasoning  naively  about  sets  turns  out  to  be  risky.  In  fact,  one  of  the  earliest  at­
tempts to come up with precise axioms for sets by a late nineteenth century logican 
named  Gotlob  Frege was  shot  down  by  a  three  line  argument  known  as  Russell’s 
Paradox:2  This was an astonishing blow to efforts to provide an axiomatic founda­
tion for mathematics. 

Let S  be a variable ranging over all sets, and deﬁne 
W  ::= {S  | S  �∈ S } . 

So by deﬁnition, 

S  ∈ W  iff S  �∈ S, 
for every set S .  In particular, we can let S  be W , and obtain the contra­
dictory result that 
W  ∈ W  iff W  �∈ W. 

A way  out  of  the paradox was  clear  to Russell  and  others  at  the  time:  it’s  un­
justiﬁed to assume that W  is a set.  So the step in the proof where we let S  be W  has 
no  justiﬁcation,  because  S  ranges  over  sets,  and W  may  not  be  a  set.  In  fact,  the 
paradox implies that W  had better not be a set! 
But denying  that W  is  a  set means we must  reject  the very natural  axiom  that 
every mathematically well-deﬁned  collection of  elements  is  actually  a  set.  So  the 
problem  faced  by  Frege,  Russell  and  their  colleagues  was  how  to  specify  which 
well-deﬁned collections are sets. Russell and his fellow Cambridge University col­
league Whitehead immediately went to work on this problem. They spent a dozen 
years  developing  a  huge  new  axiom  system  in  an  even  huger monograph  called 
Principia Mathematica. 

5.2.2  The ZFC Axioms for Sets 
It’s  generally  agreed  that,  using  some  simple  logical  deduction  rules,  essentially 
all of mathematics can be derived from some axioms about sets called the Axioms 
of Zermelo-Frankel Set Theory with Choice (ZFC). 
We’re not going to be working with these axioms in this course, but we thought 

2 Bertrand Russell was  a mathematician/logician  at Cambridge University  at  the  turn of  the Twen­
tieth Century.  He  reported  that when he  felt  too old  to do mathematics,  he began  to  study  and write 
about philosophy, and when he was no longer smart enough to do philosophy, he began writing about 
politics.  He was jailed as a conscientious objector during World War I. For his extensive philosophical 
and political writing, he won a Nobel Prize for Literature. 

82 

CHAPTER 5.  FIRST-ORDER LOGIC 

you might like to see them –and while you’re at it, get some practice reading quan­
tiﬁed formulas: 

Extensionality.  Two sets are equal if they have the same members.  In formal log­
ical notation, this would be stated as: 
(∀z . (z  ∈ x I FF z  ∈ y)) IM P L I E S x = y . 
Pairing.  For  any  two  sets  x  and  y ,  there  is  a  set,  {x, y},  with  x  and  y  as  its  only 
elements: 
∀x, y . ∃u. ∀z .  [z  ∈ u I FF  (z = x OR z = y)] 

Union.  The union, u, of a collection, z , of sets is also a set: 
∀z . ∃u∀x. (∃y . x ∈ y AND y ∈ z ) I FF x ∈ u. 

Inﬁnity.  There  is an  inﬁnite set.  Speciﬁcally,  there  is a nonempty set, x, such that 
for any set y ∈ x, the set {y} is also a member of x. 
Power Set.  All the subsets of a set form another set: 
∀x. ∃p. ∀u. u ⊆ x I FF u ∈ p. 

Replacement.  Suppose a formula, φ, of set theory deﬁnes the graph of a function, 
that is, 
∀x, y , z . [φ(x, y) AND φ(x, z )] IM P L I E S y = z . 
Then the image of any set, s, under that function is also a set, t. Namely, 
∀s ∃t ∀y . [∃x. φ(x, y) I FF y ∈ t]. 

Foundation.  There cannot be an inﬁnite sequence 
· · · ∈ xn  ∈  · · · ∈ x1  ∈ x0 

of  sets  each  of  which  is  a  member  of  the  previous  one.  This  is  equivalent 
to  saying  every  nonempty  set  has  a  “member-minimal”  element.  Namely, 
deﬁne 
member-minimal(m, x) ::= [m ∈ x AND ∀y ∈ x. y  /∈ m]. 
Then the Foundation axiom is 
∅  IM P L I E S  ∃m. member-minimal(m, x). 
∀x. x =�

Choice.  Given a set, s, whose members are nonempty sets no  two of which have 
any  element  in  common,  then  there  is a  set,  c,  consisting of  exactly one  ele­
ment from each set in s. 

5.2.  THE LOGIC OF SETS 

83 

5.2.3  Avoiding Russell’s Paradox 
These modern ZFC axioms for set theory are much simpler than the system Russell 
and Whitehead ﬁrst  came up with  to  avoid paradox.  In  fact,  the ZFC  axioms  are 
as simple and intuitive as Frege’s original axioms, with one technical addition:  the 
Foundation axiom.  Foundation captures  the  intuitive  idea  that  sets must be built 
up  from  “simpler ”  sets  in  certain  standard ways.  And  in  particular,  Foundation 
implies that no set is ever a member of itself.  So the modern resolution of Russell’s 
paradox  goes  as  follows:  since  S  �∈  S  for  all  sets  S ,  it  follows  that  W ,  deﬁned 
above, contains every set.  This means W  can’t be a set —or it would be a member 
of itself. 

5.2.4  Power sets are strictly bigger 
It turns out that the ideas behind Russell’s Paradox, which caused so much trouble 
for the early efforts to formulate Set Theory,  lead to a correct and astonishing fact 
about inﬁnite sets:  they are not all the same size. 
In particular, 
Theorem 5.2.1.  For any set, A, the power set, P (A), is strictly bigger than A. 
Proof.  First of all, P (A) is as big as A:  for example, the partial function f  : P (A) →
A,  where  f ({a})  ::= a  for  a  ∈  A  and  f  is  only  deﬁned  on  one-element  sets,  is  a 
surjection. 
To show that P (A) is strictly bigger than A, we have to show that if g  is a func­
tion  from A  to P (A),  then  g  is not  a  surjection.  So, mimicking Russell’s Paradox, 
deﬁne 
Ag  ::= {a ∈ A  | a /∈ g(a)} . 
Now Ag  is  a well-deﬁned  subset  of A, which means  it  is  a member  of P (A).  But 
Ag  can’t be in the range of g , because if it were, we would have 
Ag  = g(a0 ) 
for some a0  ∈ A, so by deﬁnition of Ag , 
iff  a /∈ g(a) 
a ∈ g(a0 ) 
iff  a ∈ Ag 
for all a ∈ A. Now letting a = a0  yields the contradiction 
iff  a0  ∈/ g(a0 ). 
a0  ∈ g(a0 ) 
So g  is not a surjection, because there is an element in the power set of A, namely 
� 
the set Ag , that is not in the range of g . 

Larger Inﬁnities 

There are lots of different sizes of inﬁnite sets.  For example, starting with the inﬁ­
nite set, N, of nonnegative integers, we can build the inﬁnite sequence of sets 
N,  P (N),  P (P (N)),  P (P (P (N))),  . . . . 

84	

CHAPTER 5.  FIRST-ORDER LOGIC 

By Theorem 5.2.1,  each of  these  sets  is  strictly bigger  than all  the preceding ones. 
But that’s not all:  the union of all the sets in the sequence is strictly bigger than each 
set in the sequence (see Problem 5.7).  In this way you can keep going, building still 
bigger inﬁnities. 
So there is an endless variety of different size inﬁnities. 

5.2.5  Does All This Really Work? 
So this is where mainstream mathematics stands today:  there is a handful of ZFC 
axioms  from which  virtually  everything  else  in mathematics  can  be  logically  de­
rived. This sounds like a rosy situation, but there are several dark clouds, suggest­
ing that the essence of truth in mathematics is not completely resolved. 

•	 The ZFC axioms weren’t etched in stone by God.  Instead,  they were mostly 
made  up  by  some  guy  named  Zermelo.  Probably  some  days  he  forgot  his 
house keys. 
So  maybe  Zermelo,  just  like  Frege,  didn’t  get  his  axioms  right  and  will  be 
shot  down  by  some  successor  to  Russell  who  will  use  his  axioms  to  prove 
a proposition P  and  its negation NOT P .  Then math would be broken.  This 
sounds crazy, but after all, it has happened before. 
In  fact,  while  there  is  broad  agreement  that  the  ZFC  axioms  are  capable  of 
proving  all  of  standard  mathematics,  the  axioms  have  some  further  conse­
quences  that  sound  paradoxical.  For  example,  the  Banach-Tarski  Theorem 
says  that,  as  a  consequence  of  the  Axiom  of  Choice,  a  solid  ball  can  be  di­
vided  into  six  pieces  and  then  the  pieces  can  be  rigidly  rearranged  to  give 
two solid balls, each the same size as the original! 

•	 Georg Cantor was a contemporary of Frege and Russell who ﬁrst developed 
the  theory  of  inﬁnite  sizes  (because  he  thought  he  needed  it  in  his  study  of 
Fourier series).  Cantor raised the question whether there is a set whose size 
is strictly between the “smallest3” inﬁnite set, N, and P (N); he guessed not: 
Cantor ’s Continuum Hypothesis: There is no set, A, such that P (N) is strictly 
bigger than A and A is strictly bigger than N. 
The  Continuum  Hypothesis  remains  an  open  problem  a  century  later.  Its 
difﬁculty  arises  from  one  of  the  deepest  results  in  modern  Set  Theory  — 
discovered  in  part  by  G ¨odel  in  the  1930’s  and  Paul  Cohen  in  the  1960’s — 
namely,  the ZFC  axioms  are not  sufﬁcient  to  settle  the Continuum Hypoth­
esis:  there  are  two  collections  of  sets,  each obeying  the  laws of ZFC,  and  in 
one collection the Continuum Hypothesis is true, and in the other it is false. 
So settling the Continuum Hypothesis requires a new understanding of what 
Sets  should be  to  arrive  at persuasive new  axioms  that  extend ZFC  and  are 
strong enough to determine the truth of the Continuum Hypothesis one way 
or the other. 
3 See Problem 4.3 

5.2.  THE LOGIC OF SETS	

85 

•	 But  even  if we  use more  or  different  axioms  about  sets,  there  are  some  un­
avoidable problems.  In  the 1930’s, G ¨odel proved  that, assuming  that an ax­
iom  system  like  ZFC  is  consistent  —meaning  you  can’t  prove  both  P  and 
NO T P  for any proposition, P  —then the very proposition that the system is 
consistent  (which  is  not  too  hard  to  express  as  a  logical  formula)  cannot  be 
proved in the system.  In other words, no consistent system is strong enough 
to verify itself. 

5.2.6  Large Inﬁnities in Computer Science 
If the romance of different size inﬁnities and continuum hypotheses doesn’t appeal 
to  you,  not  knowing  about  them  is  not  going  to  lower  your  professional  abilities 
as  a  computer  scientist.  These  abstract  issues  about  inﬁnite  sets  rarely  come  up 
in  mainstream  mathematics,  and  they  don’t  come  up  at  all  in  computer  science, 
where the focus is generally on “countable,” and often just ﬁnite, sets.  In practice, 
only logicians and set theorists have to worry about collections that are too big to 
be sets.  In fact, at the end of the 19th century, the general mathematical community 
doubted  the  relevance of what  they  called  “Cantor ’s paradise” of unfamiliar  sets 
of arbitrary inﬁnite size. 
But  the  proof  that  power  sets  are  bigger  gives  the  simplest  form  of  what  is 
known  as  a  “diagonal  argument.”  Diagonal  arguments  are  used  to  prove  many 
fundamental  results  about  the  limitations  of  computation,  such  as  the  undecid­
ability  of  the  Halting  Problem  for  programs  (see  Problem  5.8)  and  the  inherent, 
unavoidable, inefﬁciency (exponential time or worse) of procedures for other com­
putational problems.  So computer scientists do need to study diagonal arguments 
in order to understand the logical limits of computation. 

5.2.7  Problems 
Class Problems 

Problem 5.7. 
There are lots of different sizes of inﬁnite sets.  For example, starting with the inﬁ­
nite set, N, of nonnegative integers, we can build the inﬁnite sequence of sets 
N,  P (N),  P (P (N)),  P (P (P (N))),  . . . . 
By  Theorem  5.2.1  from  the Notes,  each  of  these  sets  is  strictly  bigger4  than  all  the 
preceding ones.  But that’s not all:  if we  let U  be the union of the sequence of sets 
above, then U  is strictly bigger than every set in the sequence! Prove this: 
Lemma.  Let P n (N) be the nth set in the sequence, and 

∞
P n (N). 
U  ::= 
n=0 

4Reminder:  set A is strictly bigger than set B  just means that A  surj B , but NOT(B  surj A). 

86 

CHAPTER 5.  FIRST-ORDER LOGIC 

Then 
1.	 U  surj P n (N) for every n ∈ N, but 
2.  there is no n ∈ N for which P n (N) surj U . 
Now  of  course,  we  could  take  U, P (U ), P (P (U )), . . .  and  can  keep  on  indeﬁ­
nitely building still bigger inﬁnities. 

Problem 5.8. 
Let’s  refer  to  a  programming  procedure  (written  in  your  favorite  programming 
language —C++, or Java, or Python, . . . )  as a string procedure when it is applicable 
to data of  type string and only returns values of  type boolean.  When a string 
procedure, P ,  applied  to a string,  s,  returns True, we’ll  say  that P  recognizes s. 
If R is the set of strings that P  recognizes, we’ll call P  a recognizer for R. 
(a)  Describe how a  recognizer would work  for  the set of strings containing only 
lower  case  Roman  letter —a,b,...,z —such  that  each  letter  occurs  twice  in  a 
row.  For example, aaccaabbzz, is such a string, but abb, 00bb, AAbb, and a are 
not.  (Even better, actually write a recognizer procedure in your favorite program­
ming language). 
A set of strings is called recognizable if there is a recognizer procedure for it. 
When  you  actually  program  a  procedure,  you  have  to  type  the  program  text 
into  a  computer  system.  This  means  that  every  procedure  is  described  by  some 
string  of  typed  characters.  If  a  string,  s,  is  actually  the  typed  description  of 
some  string procedure,  let’s  refer  to  that procedure  as Ps .  You  can  think  of Ps  as 
the result of compiling s.5 
In  fact,  it will be helpful  to  associate  every  string,  s, with a procedure, Ps ; we 
can  do  this  by  deﬁning  Ps  to  be  some  ﬁxed  string  procedure —it  doesn’t matter 
which one —whenever  s  is not  the  typed description of  an  actual procedure  that 
can be applied to string s.  The result of this is that we have now deﬁned a total 
function, f , mapping every string, s, to the set, f (s), of strings recognized by 
Ps . That is we have a total function, 
f  : string → P (string).	

(5.6) 

(b)	 Explain why the actual range of f  is the set of all recognizable sets of strings. 
This is exactly the set up we need to apply the reasoning behind Russell’s Para­
dox to deﬁne a set that is not in the range of f , that is, a set of strings, N , that is not 
recognizable. 

5 The string, s, and the procedure, Ps , have to be distinguished to avoid a type error: you can’t apply 
a  string  to  string.  For example,  let s be  the  string  that you wrote as your program  to answer part  (a). 
Applying s to a string argument, say oorrmm, should throw a type exception; what you need to do is 
apply the procedure Ps  to oorrmm. This should result in a returned value True, since oorrmm consists 
of three pairs of lowercase roman letters 

5.2.  THE LOGIC OF SETS 

87 

(c)  Let 

N  ::= {s ∈ string | s /∈ f (s)} . 

Prove that N  is not recognizable. 
Hint:  Similar to Russell’s paradox or the proof of Theorem 5.2.1. 

(d)  Discuss what the conclusion of part (c) implies about the possibility of writing 
“program analyzers” that take programs as inputs and analyze their behavior. 

Problem 5.9. 
Though it was a serious challenge for set theorists to overcome Russells’ Paradox, 
the  idea  behind  the  paradox  led  to  some  important  (and  correct  :-)  )  results  in 
Logic and Computer Science. 
To  show  how  the  idea  applies,  let’s  recall  the  formulas  from  Problem  5.2  that 
made  assertions  about  binary  strings.  For  example,  one  of  the  formulas  in  that 
problem was 

NO T[∃y ∃z .s = y1z ] 

(all-0s) 

This  formula deﬁnes a property of a binary  string,  s, namely  that s has no occur­
rence of a 1.  In other words, s  is a string of (zero or more) 0’s.  So we can say that 
this formula describes the set of strings of 0’s. 
More generally, when G is any formula that deﬁnes a string property, let ok-strings(G) 
be  the  set  of  all  the  strings  that  have  this  property.  A  set  of  binary  strings  that 
equals ok-strings(G) for some G is called a describable set of strings.  So,  for exam­
ple, the set of all strings of 0’s is describable because it equals ok-strings(all-0s). 
Now let’s shift gears for a moment and think about the fact that formula all-0s 
appears above. This happens because instructions for formatting the formula were 
generated by a computer text processor (in 6.042, we use the LATEX text processing 
system),  and  then  an  image  suitable  for  printing  or  display  was  constructed  ac­
cording  to  these  instructions.  Since  everybody  knows  that data  is  stored  in  com­
puter  memory  as  binary  strings,  this  means  there  must  have  been  some  binary 
string  in  computer  memory  —call  it  tall-0s  —that  enabled  a  computer  to  display 
formula all-0s once tall-0s  was retrieved from memory. 
In fact, it’s not hard to ﬁnd ways to represent any formula, G, by a correspond­
ing  binary word,  tG ,  that would  allow  a  computer  to  reconstruct G  from  tG .  We 
needn’t be concerned with how this reconstruction process works; all that matters 
for our purposes is that every formula, G, has a representation as binary string, tG . 
Now let 
V  ::= {tG  |  G deﬁnes a property of strings and tG  ∈/ ok-strings(G)} . 

Use reasoning similar to Russell’s paradox to show that V  is not describable. 

88 

CHAPTER 5.  FIRST-ORDER LOGIC 

Homework Problems 

Problem 5.10. 
Let [N → {1, 2, 3}] be the set of all sequences containing only the numbers 1, 2, and 
3, for example, 

(1, 1, 1, 1...), 
(2, 2, 2, 2...), 
(3, 2, 1, 3...). 

For any sequence, s, let s[m] be its mth element. 
Prove that [N → {1, 2, 3}] is uncountable. 
Hint:  Suppose there was a list 
L = sequence0 , sequence1 , sequence2 , . . . 
of sequences in [N → {1, 2, 3}] and show that there is a “diagonal” sequence diag ∈
[N → {1, 2, 3}] that does not appear in the list. Namely, 
diag ::= r(sequence0 [0]), r(sequence1 [1]), r(sequence2 [2]), . . . , 
where r  : {1, 2, 3} → {1, 2, 3} is some function such that r(i) =�
i for i = 1, 2, 3. 

Problem 5.11. 
→
B ] be the set of total functions from A to B . Prove 
For any sets, A, and B , let [A
B ]).→
that if A is not empty and B has more than one element, then NOT(A surj [A
Hint: Suppose there is a function, σ , that maps each element a ∈ A to a function 
� 
→ 
σa  : A
B . Pick any two elements of B ; call them 0 and 1. Then deﬁne 
0 if σa (a) = 1,
diag(a) ::= 
1 otherwise. 

5.3.  GLOSSARY OF SYMBOLS	

89 

5.3  Glossary of Symbols 

symbol	 meaning 
::= 
is deﬁned to be 
∧ 
and 
∨ 
or 
−→ 
implies 
¬ 
not
¬
not P
P 
not P 
P	
←→ 
iff 
←→ 
equivalent
⊕ 
xor 
∃ 
exists 
∀ 
for all 
∈ 
is a member of 
⊆ 
is a subset of 
⊂ 
is a proper subset of 
∪ 
set union 
∩ 
set intersection 
complement of a set, A 
A 
P (A) 
powerset of a set, A 
the empty set, {} 
∅ 

90 

CHAPTER 5.  FIRST-ORDER LOGIC 

Chapter 6 

Induction 

Induction is by far the most powerful and commonly-used proof technique in dis­
crete mathematics and computer science.  In fact, the use of induction is a deﬁning 
characteristic of discrete —as opposed to continuous —mathematics. To understand 
how it works, suppose there is a professor who brings to class a bottomless bag of 
assorted miniature candy bars.  She offers to share the candy in the following way. 
First, she lines the students up in order. Next she states two rules: 

1.  The student at the beginning of the line gets a candy bar. 

2.  If  a  student  gets  a  candy  bar,  then  the  following  student  in  line  also  gets  a 
candy bar. 

Let’s number the students by their order in line, starting the count with 0, as usual 
in Computer Science.  Now we can understand the second rule as a short descrip­
tion of a whole sequence of statements: 
•  If student 0 gets a candy bar, then student 1 also gets one. 

•  If student 1 gets a candy bar, then student 2 also gets one. 

•	 If student 2 gets a candy bar, then student 3 also gets one.

.
. . 
Of course this sequence has a more concise mathematical description: 
If student n gets a candy bar, then student n + 1 gets a candy bar, for all 
nonnegative integers n. 
So suppose you are student 17. By these rules, are you entitled to a miniature candy 
bar? Well, student 0 gets a candy bar by the ﬁrst rule. Therefore, by the second rule, 
student  1  also  gets  one, which means  student  2  gets  one, which means  student  3 
gets one as well, and so on.  By 17 applications of the professor ’s second rule, you 
get  your  candy  bar!  Of  course  the  rules  actually  guarantee  a  candy  bar  to  every 
student, no matter how far back in line they may be. 

91 

92 

CHAPTER 6.  INDUCTION 

6.1  Ordinary Induction 

The reasoning that led us to conclude every student gets a candy bar is essentially 
all there is to induction. 

The Principle of Induction. 
Let P (n) be a predicate.  If 

•  P (0) is true, and 

•  P (n) IM P L I E S P (n + 1) for all nonnegative integers, n, 

then 

•  P (m) is true for all nonnegative integers, m. 

Since we’re going  to  consider  several useful variants of  induction  in  later  sec­
tions,  we’ll  refer  to  the  induction  method  described  above  as  ordinary  induction 
when we need to distinguish it.  Formulated as a proof rule, this would be 

Rule.  Induction Rule 
P (0),  ∀n ∈ N [P (n) IM P L I E S P (n + 1)] 
∀m ∈ N. P (m) 

This general induction rule works for the same intuitive reason that all the stu­
dents get candy bars, and we hope the explanation using candy bars makes it clear 
why the soundness of the ordinary induction can be taken for granted.  In fact, the 
rule  is so obvious  that  it’s hard  to see what more basic principle could be used  to 
justify it.1  What’s not so obvious is how much mileage we get by using it. 

6.1.1  Using Ordinary Induction 
Ordinary  induction  often  works  directly  in  proving  that  some  statement  about 
nonnegative  integers  holds  for  all  of  them.  For  example,  here  is  the  formula  for 
the  sum of  the nonnegative  integer  that we already proved  (equation  (2.2)) using 
the Well Ordering Principle: 
Theorem 6.1.1.  For all n ∈ N, 

· · · 
1 + 2 + 3 +  + n = 

n(n + 1) 
2 

(6.1)

1 But see section 6.3. 

6.1.  ORDINARY INDUCTION	

93 

This time, let’s use the Induction Principle to prove Theorem 6.1.1. 
Suppose that we deﬁne predicate P (n) to be the equation (6.1). Recast in terms 
of  this predicate,  the  theorem claims  that P (n)  is  true  for all n  ∈  N.  This  is great, 
because  the  induction  principle  lets  us  reach  precisely  that  conclusion,  provided 
we establish two simpler facts: 

•	 P (0) is true. 
•	 For all n ∈ N, P (n) IM P L I E S P (n + 1). 
So  now  our  job  is  reduced  to  proving  these  two  statements.  The  ﬁrst  is  true 
because P (0) asserts  that a sum of zero  terms  is equal  to 0(0 + 1)/2 = 0, which  is 
true by deﬁnition.  The second statement  is more complicated.  But  remember  the 
basic plan for proving the validity of any implication:  assume the statement on the 
left and then prove the statement on the right.  In this case, we assume P (n) in order 
to prove P (n + 1), which is the equation 

· · ·	
1 + 2 + 3 +  + n + (n + 1) = 

(n + 1)(n + 2) 
. 
2 
These two equations are quite similar; in fact, adding (n + 1) to both sides of equa­
tion (6.1) and simplifying the right side gives the equation (6.2): 

(6.2)

· · · 
1 + 2 + 3 +  + n + (n + 1) = 

n(n + 1) 
+ (n + 1) 
2 
(n + 2)(n + 1) 
2 
Thus,  if  P (n)  is  true,  then  so  is  P (n + 1).  This  argument  is  valid  for  every  non­
negative  integer  n,  so  this  establishes  the  second  fact  required  by  the  induction 
principle.  Therefore,  the  induction  principle  says  that  the  predicate  P (m)  is  true 
for all nonnegative integers, m, so the theorem is proved. 

= 

6.1.2  A Template for Induction Proofs 
The proof of Theorem 6.1.1 was  relatively  simple, but even  the most complicated 
induction proof follows exactly the same template. There are ﬁve components: 

1.	 State  that  the  proof  uses  induction.  This  immediately  conveys  the  overall 
structure of the proof, which helps the reader understand your argument. 

2.	 Deﬁne  an  appropriate  predicate  P (n).  The  eventual  conclusion  of  the  in­
duction argument will be  that P (n)  is  true  for all nonnegative n.  Thus, you 
should deﬁne the predicate P (n) so that your theorem is equivalent to (or fol­
lows from) this conclusion. Often the predicate can be lifted straight from the 
claim, as in the example above. The predicate P (n) is called the induction hy­
pothesis.  Sometimes  the  induction hypothesis will  involve several variables, 
in which case you should indicate which variable serves as n. 

94	

CHAPTER 6.  INDUCTION 

3.	 Prove  that P (0)  is  true.  This  is usually  easy,  as  in  the  example  above.  This 
part of the proof is called the base case or basis step. 
4.	 Prove  that P (n)  implies P (n + 1)  for  every nonnegative  integer n.  This  is 
called the inductive step. The basic plan is always the same:  assume that P (n) 
is true and then use this assumption to prove that P (n + 1) is true. These two 
statements  should  be  fairly  similar,  but  bridging  the  gap may  require  some 
ingenuity. Whatever argument you give must be valid for every nonnegative 
→
→ 
integer  n,  since  the  goal  is  to  prove  the  implications  P (0) 
P (1),  P (1) 
P (2), P (2) → P (3), etc.  all at once. 
5.	 Invoke  induction.  Given  these  facts,  the  induction  principle  allows  you  to 
conclude that P (n) is true for all nonnegative n.  This is the logical capstone 
to  the whole argument, but  it  is so standard  that  it’s usual not  to mention  it 
explicitly, 

Explicitly labeling the base case and inductive step may make your proofs clearer. 

6.1.3  A Clean Writeup 
The  proof  of  Theorem  6.1.1  given  above  is  perfectly  valid;  however,  it  contains  a 
lot of extraneous explanation that you won’t usually see in  induction proofs.  The 
writeup below is closer to what you might see in print and should be prepared to 
produce yourself. 

Proof.  We use induction. The induction hypothesis, P (n), will be equation (6.1). 
Base  case:  P (0)  is  true,  because  both  sides  of  equation  (6.1)  equal  zero when 
n = 0. 
Inductive step:  Assume that P (n) is true, where n is any nonnegative integer. 
Then 

· · · 
1 + 2 + 3 +  + n + (n + 1) = 

=	

n(n + 1) 
+ (n + 1) 
2

(n + 1)(n + 2)

2 

(by induction hypothesis) 

(by simple algebra) 

which proves P (n + 1). 
So it follows by induction that P (n) is true for all nonnegative n. 

� 
Induction was helpful for proving the correctness of this summation formula, but 
not helpful for discovering it in the ﬁrst place.  Tricks and methods for ﬁnding such 
formulas will appear in a later chapter. 

6.1.4  Courtyard Tiling 
During the development of MIT’s famous Stata Center, costs rose further and fur­
ther  over  budget,  and  there  were  some  radical  fundraising  ideas.  One  rumored 
plan was to install a big courtyard with dimensions 2n  × 2n : 

6.1.  ORDINARY INDUCTION 

95 

2n 

2n 

One of the central squares would be occupied by a statue of a wealthy potential 
donor. Let’s call him “Bill”.  (In the special case n = 0, the whole courtyard consists 
of a  single  central  square;  otherwise,  there are  four  central  squares.)  A  complica­
tion was that the building’s unconventional architect, Frank Gehry, was alleged to 
require that only special L-shaped tiles be used: 

A courtyard meeting these constraints exists, at least for n = 2: 

B 

For larger values of n, is there a way to tile a 2n  × 2n  courtyard with L-shaped 
tiles and a statue in the center? Let’s try to prove that this is so. 
Theorem 6.1.2.  For all n  ≥  0  there exists a  tiling of a 2n  × 2n  courtyard with Bill  in a 
central square. 
Proof.  (doomed attempt) The proof is by induction.  Let P (n) be the proposition that 
there exists a tiling of a 2n  × 2n  courtyard with Bill in the center. 
Base case: P (0) is true because Bill ﬁlls the whole courtyard. 
Inductive step: Assume that there is a tiling of a 2n  × 2n  courtyard with Bill in 
the center for some n ≥  0.  We must prove that there is a way to tile a 2n+1  × 2n+1 
� 
courtyard with Bill in the center . . . . 
Now  we’re  in  trouble!  The  ability  to  tile  a  smaller  courtyard  with  Bill  in  the 
center isn’t much help in tiling a larger courtyard with Bill in the center. We haven’t 
ﬁgured out how to bridge the gap between P (n) and P (n + 1). 

96 

CHAPTER 6.  INDUCTION 

So  if  we’re  going  to  prove  Theorem  6.1.2  by  induction,  we’re  going  to  need 
some other induction hypothesis than simply the statement about n that we’re try­
ing to prove. 
When this happens, your ﬁrst fallback should be to look for a stronger induction 
hypothesis;  that  is,  one  which  implies  your  previous  hypothesis.  For  example, 
we  could  make  P (n)  the  proposition  that  for  every  location  of  Bill  in  a  2n  ×  2n 
courtyard, there exists a tiling of the remainder. 
This  advice  may  sound  bizarre:  “If  you  can’t  prove  something,  try  to  prove 
something grander!” But for induction arguments, this makes sense.  In the induc­
tive step, where you have  to prove P (n) IM P L I E S  P (n + 1), you’re  in better shape 
because you can assume P (n), which is now a more powerful statement.  Let’s see 
how this plays out in the case of courtyard tiling. 

Proof.  (successful  attempt)  The  proof  is  by  induction.  Let  P (n)  be  the  proposition 
that  for  every  location  of  Bill  in  a  2n  ×  2n  courtyard,  there  exists  a  tiling  of  the 
remainder. 
Base case: P (0) is true because Bill ﬁlls the whole courtyard. 
Inductive  step:  Assume  that  P (n)  is  true  for  some  n  ≥  0;  that  is,  for  every 
location of Bill in a 2n × 2n  courtyard, there exists a tiling of the remainder. Divide 
the 2n+1 × 2n+1  courtyard into four quadrants, each 2n × 2n . One quadrant contains 
Bill (B in the diagram below).  Place a temporary Bill (X in the diagram) in each of 
the three central squares lying outside this quadrant: 

2n 

2n 

a 

B 

X 
X  X 

2n 

2n 

Now we can  tile each of  the  four quadrants by  the  induction assumption.  Re­
placing  the  three  temporary  Bills  with  a  single  L-shaped  tile  completes  the  job. 
This  proves  that  P (n)  implies  P (n + 1)  for  all  n  ≥  0.  The  theorem  follows  as  a 
� 
special case. 

This proof has two nice properties. First, not only does the argument guarantee 
that a tiling exists, but also it gives an algorithm for ﬁnding such a tiling.  Second, 
we  have  a  stronger  result:  if  Bill  wanted  a  statue  on  the  edge  of  the  courtyard, 
away from the pigeons, we could accommodate him! 

6.1.  ORDINARY INDUCTION 

97 

Strengthening  the  induction hypothesis  is often a good move when an  induc­
tion  proof  won’t  go  through.  But  keep  in mind  that  the  stronger  assertion must 
actually  be  true;  otherwise,  there  isn’t  much  hope  of  constructing  a  valid  proof! 
Sometimes ﬁnding just the right induction hypothesis requires trial, error, and in­
sight.  For example, mathematicians spent almost  twenty years  trying  to prove or 
disprove  the conjecture  that “Every planar graph  is 5-choosable”2 .  Then,  in 1994, 
Carsten Thomassen  gave  an  induction  proof  simple  enough  to  explain  on  a  nap­
kin.  The  key  turned  out  to  be  ﬁnding  an  extremely  clever  induction  hypothesis; 
with that in hand, completing the argument is easy! 

6.1.5  A Faulty Induction Proof 
False Theorem.  All horses are the same color. 

Notice  that  no  n  is mentioned  in  this  assertion,  so  we’re  going  to  have  to  re­
formulate  it  in  a way  that makes  an n  explicit.  In particular, we’ll  (falsely) prove 
that 
False Theorem 6.1.3.  In every set of n ≥ 1 horses, all are the same color. 
This  a  statement  about  all  integers  n  ≥  1  rather  ≥  0,  so  it’s  natural  to  use  a 
slight variation on induction: prove P (1) in the base case and then prove that P (n) 
implies P (n + 1) for all n ≥ 1 in the inductive step. This is a perfectly valid variant 
of induction and is not the problem with the proof below. 

False proof.  The  proof  is  by  induction  on  n.  The  induction  hypothesis,  P (n),  will 
be 

(6.3) 
In every set of n horses, all are the same color. 
Base case:  (n = 1).  P (1) is true, because in a set of horses of size 1, there’s only 
one horse, and this horse is deﬁnitely the same color as itself. 
Inductive step:  Assume  that P (n)  is  true  for some n  ≥  1.  that  is, assume  that 
in every set of n horses, all are the same color. Now consider a set of n + 1 horses: 

h1 , h2 ,  . . . ,  hn , hn+1 
By our assumption, the ﬁrst n horses are the same color: 
�� 
� 
� 
h1 , h2 ,  . . . ,  hn , hn+1 
same color 
Also by our assumption, the last n horses are the same color: 
� 
� 
�� 
h1 , h2 ,  . . . ,  hn , hn+1 
same color 
2 5-choosability is a slight generalization of 5-colorability. Although every planar graph is 4-colorable 
and therefore 5-colorable, not every planar graph is 4-choosable.  If this all sounds like nonsense, don’t 
panic. We’ll discuss graphs, planarity, and coloring in a later chapter. 

98 

CHAPTER 6.  INDUCTION 

So h1  is the same color as the remaining horses besides hn+1 , and likewise hn+1  is 
the  same  color  as  the  remaining  horses  besides  h1 .  So  h1  and  hn+1  are  the  same 
color. That is, horses h1 , h2 , . . . , hn+1  must all be the same color, and so P (n + 1) is 
true. Thus, P (n) implies P (n + 1). 
By the principle of induction, P (n) is true for all n ≥ 1. 
� 
We’ve proved something  false!  Is math broken?  Should we all become poets? 
No, this proof has a mistake. 
The  error  in  this  argument  is  in  the  sentence  that begins,  “So h1  and hn+1  are 
the  same  color.”  The  “. . . ”  notation  creates  the  impression  that  there  are  some 
remaining horses besides h1  and hn+1 .  However,  this  is not  true when n  = 1.  In 
that  case,  the  ﬁrst  set  is  just  h1  and  the  second  is  h2 ,  and  there  are  no  remaining 
horses besides them.  So h1  and h2  need not be the same color! 
This mistake knocks a critical  link out of our  induction argument.  We proved 
P (1) and we correctly proved P (2)  −→  P (3), P (3)  −→  P (4), etc.  But we  failed  to 
prove P (1) −→ P (2), and so everything falls apart: we can not conclude that P (2), 
P (3), etc., are true. And, of course, these propositions are all false; there are horses 
of a different color. 
Students sometimes claim that the mistake in the proof is because P (n) is false 
for n ≥ 2, and the proof assumes something false, namely, P (n), in order to prove 
P (n + 1). You should think about how to explain to such a student why this claim 
would get no credit on a 6.042 exam. 

6.1.6  Problems 
Class Problems 

Problem 6.1. 
Use induction to prove that 

13  + 23  +

· · · 
+ n 3  = 

�

�2 
n(n + 1) 
2 

. 

(6.4)

for all n ≥ 1. 
Remember to formally 

1.  Declare proof by induction. 

2.  Identify the induction hypothesis P (n). 

3.  Establish the base case. 
⇒ 
4.  Prove that P (n) 
P (n + 1).
5.  Conclude that P (n) holds for all n ≥ 1. 
as in the ﬁve part template. 

6.1.  ORDINARY INDUCTION 

Problem 6.2. 
Prove by induction on n that 

1 + r + r 2  +

· · · 

+ r n  = 

r

n+1  − 1 
r − 1 

for all n ∈ N and numbers r = 1
. 

Problem 6.3. 
Prove by induction: 

for all n > 1. 

1 + 

1
4 

+ 

1 
9 

+ · · · + 

1
n2  < 2 − 

1
n

, 

99 

(6.5)

(6.6) 

Problem 6.4.  (a)  Prove by induction that a 2n × 2n  courtyard with a 1 × 1 statue of 
Bill in a corner can be covered with L-shaped tiles.  (Do not assume or reprove the 
(stronger)  result  of Theorem  6.1.2  that Bill  can  be placed  anywhere.  The point  of 
this problem is to show a different induction hypothesis that works.) 

(b)  Use the result of part (a) to prove the original claim that there is a tiling with 
Bill in the middle. 

Problem 6.5. 
Find the ﬂaw in the following bogus proof that a = 1 for all nonnegative integers 
n
n, whenever a is a nonzero real number. 

Bogus proof.  The proof is by induction on n, with hypothesis 
P (n) ::= ∀k ≤ n. a k  = 1, 

where k  is a nonnegative integer valued variable. 
Base Case:  P (0)  is equivalent  to a0  = 1, which  is  true by deﬁnition of a0 .  (By 
convention, this holds even if a = 0.) 
Inductive Step:  By induction hypothesis, ak  = 1 for all k  ∈ N such that k  ≤ n. 
But then 
·  = 1, 
·  = 
1 1 
n
n
a
a
an−1 
1 
which  implies that P (n + 1) holds.  It follows by  induction that P (n) holds for all 
n ∈ N, and in particular, a = 1 holds for all n ∈ N. 
n
� 

a n+1  = 

�
100 

CHAPTER 6.  INDUCTION 

Problem 6.6. 
We’ve proved in two different ways that 
· · · 
1 + 2 + 3 +  + n = 

n(n + 1) 
2 
But now we’re going to prove a contradictory theorem! 
False Theorem.  For all n ≥ 0, 

· · · 
2 + 3 + 4 +  + n = 

n(n + 1) 
2 
· · · 
Proof.  We  use  induction.  Let  P (n)  be  the  proposition  that  2 + 3 + 4 +  + n  = 
n(n + 1)/2. 
Base  case:  P (0)  is  true,  since  both  sides  of  the  equation  are  equal  to  zero.  (Recall 
that a sum with no terms is zero.) 
Inductive  step:  Now we must  show  that  P (n)  implies  P (n + 1)  for  all  n  ≥  0.  So 
· · · 
suppose  that P (n)  is  true;  that  is,  2 + 3 + 4 +  + n  =  n(n + 1)/2.  Then we can 
reason as follows: 
· · · 
· · · 
2 + 3 + 4 +  + n + (n + 1) = [2 + 3 + 4 +  + n] + (n + 1) 
n(n + 1) 
+ (n + 1) 
2 
(n + 1)(n + 2) 
2 
Above, we  group  some  terms,  use  the  assumption  P (n),  and  then  simplify.  This 
shows  that P (n)  implies P (n + 1).  By  the principle of  induction, P (n)  is  true  for 
all n ∈ N. 
� 
Where exactly is the error in this proof? 

= 

= 

Homework Problems 

Problem 6.7. 

Claim 6.1.4.  If a collection of positive  integers (not necessarily distinct) has sum n  ≥  1, 
then the collection has product at most 3n/3 . 
For example, the collection 2, 2, 3, 4, 4, 7 has the sum: 

2 + 2 + 3 + 4 + 4 + 7  =  22 

On the other hand, the product is: 

·
·
·
·
· 
2 2 3 4 4 7  =  1344
≤  322/3 
≈  3154.2 

6.1.  ORDINARY INDUCTION 

101 

(a)  Use strong induction to prove that n ≤ 3n/3  for every integer n ≥ 0. 
(b)  Prove the claim using induction or strong induction.  (You may ﬁnd it easier to 
use induction on the number of positive integers in the collection rather than induction 
on the sum n.) 

Problem 6.8. 
For  any  binary  string,  α,  let  num (α)  be  the  nonnegative  integer  it  represents  in 
binary notation.  For example, num (10) = 2, and num (0101) = 5. 
An n+1-bit adder adds two n+1-bit binary numbers. More precisely, an n+1-bit 
adder takes two length n + 1 binary strings 

αn  ::= an  . . . a1a0 , 
βn  ::= bn  . . . b1 b0 , 

and a binary digit, c0 , as inputs, and produces a length n + 1 binary string 

σn  ::= sn  . . . s1 s0 , 

and a binary digit, cn+1 , as outputs, and satisﬁes the speciﬁcation: 

num (αn ) + num (βn ) + c0  = 2n+1 cn+1  + num (σn ) . 

(6.7) 

There  is  a  straighforward  way  to  implement  an  n + 1-bit  adder  as  a  digital 
circuit:  an n + 1-bit ripple-carry circuit has 1 + 2(n + 1) binary inputs 

an , . . . , a1 , a0 , bn , . . . , b1 , b0 , c0 , 

and n + 2 binary outputs, 

cn+1 , sn , . . . , s1 , s0 . 
As in Problem 3.5, the ripple-carry circuit is speciﬁed by the following formulas: 

si  ::= ai  XOR  bi  XOR  ci 
ci+1  ::= (ai  AND  bi ) OR  (ai  AND  ci ) OR  (bi  AND  ci ), . 

(6.8) 
(6.9) 

for 0 ≤ i ≤ n. 
(a)  Verify that deﬁnitions (6.8) and (6.9) imply that 

an  + bn  + cn  = 2cn+1  + sn . 

(6.10) 

for all n ∈ N. 
(b)  Prove by induction on n that an n + 1-bit ripple-carry circuit really is an n + 1­
bit adder, that is, its outputs satisfy (6.7). 
Hint: You may assume that, by deﬁnition of binary representation of integers, 

num (αn+1 ) = an+12n+1  + num (αn ) . 

(6.11) 

102 

CHAPTER 6.  INDUCTION 

Problem 6.9. 
The 6.042 mascot, Theory Hippotamus, made a  startling discovery while playing 
with  his  prized  collection  of  unit  squares  over  the  weekend.  Here  is  what  hap­
pened. 
First, Theory Hippotamus put his favorite unit square down on the ﬂoor as in 
Figure 6.1 (a). He noted that the length of the periphery of the resulting shape was 
4,  an  even  number.  Next,  he  put  a  second  unit  square  down  next  to  the  ﬁrst  so 
that the two squares shared an edge as in Figure 6.1 (b). He noticed that the length 
of the periphery of the resulting shape was now 6, which is also an even number. 
(The periphery  of  each  shape  in  the ﬁgure  is  indicated  by  a  thicker  line.)  Theory 
Hippotamus  continued  to  place  squares  so  that  each  new  square  shared  an  edge 
with at least one previously-placed square and no squares overlapped. Eventually, 
he arrived at the shape in Figure 6.1 (c). He realized that the length of the periphery 
of this shape was 36, which is again an even number. 
Our plucky porcine pal is perplexed by this peculiar pattern. Use induction on 
the number of squares to prove that the length of the periphery is always even, no 
matter how many squares Theory Hippotamus places or how he arranges them. 

Figure 6.1:  Some shapes that Theory Hippotamus created. 

6.2  Strong Induction 

A useful variant of induction is called strong induction.  Strong Induction and Ordi­
nary Induction are used for exactly the same thing:  proving that a predicate P (n) 
is true for all n ∈ N. 

(a)(b)(c)6.2.  STRONG INDUCTION 

103 

Principle of Strong Induction.  Let P (n) be a predicate.  If 

•  P (0) is true, and 
•  for all n ∈ N, P (0), P (1), . . . , P (n) together imply P (n + 1), 

then P (n) is true for all n ∈ N. 

The only change from the ordinary induction principle is that strong induction 
allows you to assume more stuff in the inductive step of your proof!  In an ordinary 
induction argument, you assume  that P (n)  is  true and  try  to prove  that P (n + 1) 
is also true.  In a strong induction argument, you may assume that P (0), P (1), . . . , 
and P (n) are all true when you go to prove P (n + 1). These extra assumptions can 
only make your job easier. 

6.2.1  Products of Primes 

As a ﬁrst example, we’ll use strong induction to re-prove Theorem 2.4.1 which we 
previously proved using Well Ordering. 

Lemma 6.2.1.  Every integer greater than 1 is a product of primes. 

Proof.  We  will  prove  Lemma  6.2.1  by  strong  induction,  letting  the  induction  hy­
pothesis, P (n), be 

n is a product of primes. 
So Lemma 6.2.1 will follow if we prove that P (n) holds for all n ≥ 2. 
Base  Case:  (n  = 2)  P (2)  is  true  because  2  is  prime,  and  so  it  is  a  length  one 
product of primes by convention. 
Inductive step:  Suppose that n ≥  2 and that i is a product of primes for every 
integer  i where  2  ≤  i < n + 1.  We must  show  that P (n + 1)  holds,  namely,  that 
n + 1 is also a product of primes. We argue by cases: 
If n + 1 is itself prime, then it is a length one product of primes by convention, 
so P (n + 1) holds in this case. 
Otherwise, n + 1 is not prime, which by deﬁnition means n + 1 = km for some 
integers k , m such that 2 ≤ k , m < n + 1. Now by strong induction hypothesis, we 
know that k  is a product of primes.  Likewise, m is a product of primes.  it follows 
immediately that km = n is also a product of primes. Therefore, P (n + 1) holds in 
this case as well. 
So P (n + 1) holds  in any case, which completes the proof by strong  induction 
that P (n) holds for all nonnegative integers, n. 
� 

104 

CHAPTER 6.  INDUCTION 

6.2.2  Making Change 
The  country  Inductia,  whose  unit  of  currency  is  the  Strong,  has  coins worth  3Sg 
(3  Strongs)  and  5Sg.  Although  the  Inductians  have  some  trouble  making  small 
change  like 4Sg or 7Sg,  it  turns out  that  they can collect coins  to make change  for 
any number that is at least 8 Strongs. 
Strong induction makes this easy to prove for n + 1 ≥ 11, because then (n + 1) −
3 ≥ 8, so by strong induction the Inductians can make change for exactly (n + 1) − 3 
Strongs, and then they can add a 3Sg coin to get (n + 1)Sg.  So the only thing to do 
is check that they can make change for all the amounts from 8 to 10Sg, which is not 
too hard to do. 
Here’s a detailed writeup using the ofﬁcial format: 

Proof.  We prove by strong induction that the Inductians can make change for any 
amount of at least 8Sg. The induction hypothesis, P (n) will be: 
If n ≥ 8, then there is a collection of coins whose value is n Strongs. 
Notice  that  P (n)  is  an  implication.  When  the  hypothesis  of  an  implication  is 
false, we  know  the whole  implication  is  true.  In  this  situation,  the  implication  is 
said to be vacuously true.  So P (n) will be vacuously true whenever n < 8.3 
We now proceed with the induction proof: 
Base case: P (0) is vacuously true. 
Inductive  step:  We  assume  P (i)  holds  for  all  i  ≤  n,  and  prove  that  P (n + 1) 
holds. We argue by cases: 
Case (n + 1 < 8): P (n + 1) is vacuously true in this case. 
Case  (n + 1 = 8):  P (8) holds because  the  Inductians can use one 3Sg coin and 
one 5Sg coins. 
Case (n + 1 = 9): Use three 3Sg coins. 
Case (n + 1 = 10): Use two 5Sg coins. 
Case  (n + 1  ≥  11):  Then  n  ≥  (n +  1) −  3  ≥  8,  so  by  the  strong  induction 
hypothesis, the Inductians can make change for (n + 1) − 3 Strong. Now by adding 
a 3Sg coin, they can make change for (n + 1)Sg. 
So  in any case, P (n + 1)  is  true, and we conclude by strong  induction  that  for 
all n ≥ 8, the Inductians can make change for n Strong. 
� 

6.2.3  The Stacking Game 
Here is another exciting 6.042 game that’s surely about to sweep the nation! 
You  begin  with  a  stack  of  n  boxes.  Then  you make  a  sequence  of moves.  In 
each move,  you  divide  one  stack  of  boxes  into  two  nonempty  stacks.  The  game 

3Another approach that avoids these vacuous cases is to deﬁne 

Q(n) ::= there is a collection of coins whose value is n + 8Sg, 
and prove that Q(n) holds for all n ≥ 0. 

6.2.  STRONG INDUCTION 

105 

ends when  you  have  n  stacks,  each  containing  a  single  box.  You  earn  points  for 
each  move;  in  particular,  if  you  divide  one  stack  of  height  a + b  into  two  stacks 
with heights a and b, then you score ab points for that move.  Your overall score is 
the sum of the points that you earn for each move.  What strategy should you use 
to maximize your total score? 
As an example, suppose that we begin with a stack of n  =  10 boxes.  Then the 
game might proceed as follows: 

Stack Heights 

Score 

10 
5 
5 
25 points 
5  3  2 
6 
4  3  2  1 
4 
2 
3  2  1  2 
4 
2  2  2  1  2  1 
2 
2  2  1  2  1  1 
1 
1 
1  2  1  2  1  1  1 
1 
1 
1  1  1  2  1  1  1  1 
1 
1 
1 
1  1  1  1  1  1  1  1  1 
1 
Total Score  =  45 points 

On each line, the underlined stack is divided in the next step. Can you ﬁnd a better 
strategy? 

Analyzing the Game 

Let’s use strong  induction  to analyze  the unstacking game.  We’ll prove  that your 
score is determined entirely by the number of boxes —your strategy is irrelevant! 
Theorem 6.2.2.  Every way of unstacking n blocks gives a score of n(n − 1)/2 points. 
There are a couple technical points to notice in the proof: 

•	 The template for a strong induction proof is exactly the same as for ordinary 
induction. 

•	 As with ordinary induction, we have some freedom to adjust indices.  In this 
case,  we  prove  P (1)  in  the  base  case  and  prove  that  P (1), . . . , P (n)  imply 
P (n + 1) for all n ≥ 1 in the inductive step. 
Proof.  The proof is by strong induction. Let P (n) be the proposition that every way 
of unstacking n blocks gives a score of n(n − 1)/2. 
Base case:  If n = 1, then there is only one block. No moves are possible, and so 
the total score for the game is 1(1 − 1)/2 = 0. Therefore, P (1) is true. 
Inductive step: Now we must show that P (1), . . . , P (n) imply P (n + 1) for all 
n ≥ 1.  So assume that P (1), . . . , P (n) are all true and that we have a stack of n + 1 
blocks. The ﬁrst move must split this stack into substacks with positive sizes a and 

106 

CHAPTER 6.  INDUCTION 

b where a + b = n + 1 and 0 < a, b ≤ n. Now the total score for the game is the sum 
of points  for  this ﬁrst move plus points obtained by unstacking  the  two  resulting 
substacks: 

by P (a) and P (b)

total score = (score for 1st move) 
+ (score for unstacking a blocks) 
+ (score for unstacking b blocks) 
b(b − 1) 
a(a − 1)  + 
= ab + 
2
2 
(a + b)2  − (a + b)
(a + b)((a + b) − 1)
2 
2
(n + 1)n 
2 
This shows that P (1), P (2), . . . , P (n) imply P (n + 1). 
Therefore, the claim is true by strong induction. 

= 

=

= 

� 
Despite the name, strong induction is technically no more powerful than ordi­
nary induction, though it makes some proofs easier to follow. But any theorem that 
can be proved with strong induction could also be proved with ordinary induction 
(using a slightly more complicated induction hypothesis).  On the other hand, an­
nouncing  that  a  proof  uses  ordinary  rather  than  strong  induction  highlights  the 
fact that P (n + 1) follows directly from P (n), which is generally good to know. 

6.2.4  Problems 
Class Problems 

Problem 6.10. 
A group of n  ≥  1 people can be divided  into  teams,  each containing either 4 or 7 
people.  What  are  all  the  possible  values  of  n?  Use  induction  to  prove  that  your 
answer is correct. 

Problem 6.11. 
The  following  Lemma  is  true,  but  the  proof  given  for  it  below  is  defective.  Pin­
point exactly where the proof ﬁrst makes an unjustiﬁed step and explain why it is 
unjustiﬁed. 

| 
Lemma 6.2.3.  For any prime p and positive integers n, x1 , x2 , . . . , xn , if p x1x2  . . . xn , 
then p | xi  for some 1 ≤ i ≤ n. 
False proof.  Proof by strong induction on n. The induction hypothesis, P (n), is that 
Lemma holds for n. 
Base  case n  = 1:  When n  = 1, we have  p  |  x1 ,  therefore we  can  let  i  = 1 and 
conclude p  | xi . 

6.3.  INDUCTION VERSUS WELL ORDERING 

107 

Induction step: Now assuming the claim holds for all k ≤ n, we must prove it 
for n + 1. 
So suppose p  | x1x2  . . . xn+1 . Let yn  = xnxn+1 , so x1x2  . . . xn+1  = x1x2  . . . xn−1 yn . 
Since the righthand side of this equality is a product of n terms, we have by induc­
tion that p divides one of them.  If p  |  xi  for some i < n,  then we have the desired 
i.  Otherwise p  |  yn .  But  since yn  is a product of  the  two  terms xn , xn+1 , we have 
by  strong  induction  that p divides one of  them.  So  in  this  case p  |  xi  for  i  =  n or 
� 
i = n + 1. 

Problem 6.12. 
Deﬁne  the  potential,  p(S ),  of  a  stack  of  blocks,  S ,  to  be  k(k − 1)/2 where  k  is  the 
number  of  blocks  in  S .  Deﬁne  the  potential,  p(A),  of  a  set  of  stacks,  A,  to  be  the 
sum of the potentials of the stacks in A. 
Generalize  Theorem  6.2.2  about  scores  in  the  stacking  game  to  show  that  for 
any set of stacks, A, if a sequence of moves starting with A leads to another set of 
stacks, B , then p(A) ≥ p(B ), and the score for this sequence of moves is p(A)−p(B ). 
Hint: Try induction on the number of moves to get from A to B . 

6.3  Induction versus Well Ordering 

The Induction Axiom looks nothing like the Well Ordering Principle, but these two 
proof methods are closely related.  In fact, as  the examples above suggest, we can 
take any Well Ordering proof and reformat it into an Induction proof. Conversely, 
it’s equally easy  to  take any  Induction proof and reformat  it  into a Well Ordering 
proof. 
So what’s the difference? Well, sometimes induction proofs are clearer because 
they resemble recursive procedures that reduce handling an input of size n + 1 to 
handling one of size n.  On the other hand, Well Ordering proofs sometimes seem 
more natural, and also come out slightly shorter.  The choice of method is really a 
matter of style—but style does matter. 

108 

CHAPTER 6.  INDUCTION 

Chapter 7 

Partial Orders 

Partial orders are a kind of binary relation that come up a lot. The familiar ≤ order 
on  numbers  is  a  partial  order,  but  so  is  the  containment  relation  on  sets  and  the 
divisibility relation on integers. 
Partial  orders  have  particular  importance  in  computer  science  because  they 
capture key concepts used, for example, in solving task scheduling problems, ana­
lyzing concurrency control, and proving program termination. 

7.1  Axioms for Partial Orders 

The prerequisite structure among MIT subjects provides a nice illustration of par­
tial  orders.  Here  is  a  table  indicating  some  of  the  prerequisites  of  subjects  in  the 
the Course 6 program of Spring ’07: 

Direct Prerequisites  Subject 
6.042 
18.01 
18.01 
18.02 
18.03 
18.01 
8.02 
8.01 
6.034 
6.001 
6.042 
6.046 
6.002 
18.03, 8.02 
6.004 
6.001, 6.002 
6.003 
6.001, 6.002 
6.004 
6.033 
6.857 
6.033 
6.046 
6.840 

Since  18.01  is  a  direct  prerequisite  for  6.042,  a  student must  take  18.01  before 
6.042.  Also, 6.042 is a direct prerequisite for 6.046, so in fact, a student has to take 
both  18.01  and  6.042  before  taking  6.046.  So  18.01  is  also  really  a  prerequisite  for 

109 

110 

CHAPTER 7.  PARTIAL ORDERS 

6.046, though an implicit or indirect one; we’ll indicate this by writing 
→ 

18.01 

6.046.

This prerequisite relation has a basic property known as transitivity:  if subject a 
is an indirect prerequisite of subject b, and b is an indirect prerequisite of subject c, 
then a is also an indirect prerequisite of c. 
In this table, a longest sequence of prerequisites is 
→
→
→
→

6.857

6.004 

6.033 

→ 

18.01 

18.03 

6.002 

so a  student would need at  least  six  terms  to work  through  this  sequence of  sub­
jects.  But  it  would  take  a  lot  longer  to  complete  a  Course  6  major  if  the  direct 
prerequisites led to a situation1  where two subjects turned out to be prerequisites 
→ 
of each other! So another crucial property of the prerequisite relation is that if a
b, 
→
a. This property is called asymmetry. 
then it is not the case that b
Another  basic  example  of  a  partial  order  is  the  subset  relation,  ⊆,  on  sets.  In 
fact, we’ll see that every partial order can be represented by the subset relation. 

•  transitive 

•  asymmetric 

Deﬁnition 7.1.1.  A binary relation, R, on a set A is: 
for every a, b, c ∈ A, 
[a R b and b R c]  IM P L I E S  a R c 
iff 
for all a, b ∈ A, 
iff  a R b  IM P L I E S  NO T(b R a) 
• a strict partial order iff it is transitive and asymmetric. 
→
So the prerequisite relation, 
, on subjects in the MIT catalogue is a strict par­
tial order. More familiar examples of strict partial orders are the relation, <, on real 
numbers, and the proper subset relation, ⊂, on sets. 
The  subset  relation, ⊆,  on  sets  and ≤  relation on numbers  are  examples  of  re­
ﬂexive  relations  in which each element  is  related  to  itself.  Reﬂexive partial orders 
are  called  weak  partial  orders.  Since  asymmetry  is  incompatible  with  reﬂexivity, 
the asymmetry property in weak partial orders is relaxed so it applies only to two 
different elements. This relaxation of the asymmetry is called antisymmetry: 

•  reﬂexive 

Deﬁnition 7.1.2.  A binary relation, R, on a set A, is 
for all a ∈ A, 
iff  a R a 
iff  a R b  IM P L I E S  NO T(b R a) 

b ∈ A, 
for all a =�
• a weak partial order iff it is transitive, reﬂexive and antisymmetric. 

•  antisymmetric 

Some authors deﬁne partial orders to be what we call weak partial orders, but 
we’ll use the phrase “partial order ” to mean either a weak or strict one. 
For weak partial orders in general, we often write an ordering-style symbol like 
�  or  �  instead  of  a  letter  symbol  like  R.  (General  relations  are  usually  denoted 
1MIT’s  Committee  on  Curricula  has  the  responsibility  of  watching  out  for  such  bugs  that  might 
creep into departmental requirements. 

7.2.  REPRESENTING PARTIAL ORDERS BY SET CONTAINMENT 

111 

by  a  letter  like  R  instead  of  a  cryptic  squiggly  symbol,  so  �  is  kind  of  like  the 
musical  performer/composer  Prince,  who  redeﬁned  the  spelling  of  his  name  to 
be  his  own  squiggly  symbol.  A  few  years  ago  he  gave  up  and went  back  to  the 
spelling  “Prince.”)  Likewise,  we  generally  use  �  or  �  to  indicate  a  strict  partial 
order. 
Two more examples of partial orders are worth mentioning: 
Example 7.1.3.  Let A be some family of sets and deﬁne a R b iff a ⊃  b.  Then R is a 
strict partial order. 
For  integers, m, n we write m  |  n  to mean  that m divides n, namely,  there  is an 
integer, k , such that n = km. 
Example 7.1.4.  The divides relation  is a weak partial order on  the nonnegative  in­
tegers. 

7.2  Representing Partial Orders by Set Containment 

Axioms  can  be  a  great way  to  abstract  and  reason  about  important  properties  of 
objects,  but  it  helps  to  have  a  clear  picture  of  the  things  that  satisfy  the  axioms. 
We’ll show that every partial order can be pictured as a collection of sets related by 
containment. That is, every partial order has the “same shape” as such a collection. 
The technical word for “same shape” is “isomorphic.” 
Deﬁnition  7.2.1.  A  binary  relation,  R,  on  a  set,  A,  is  isomorphic  to  a  relation,  S , 
on a set D  iff  there  is a relation-preserving bijection  from A  to D .  That  is,  there  is 
bijection f  : A → D , such that for all a, a�  ∈ A, 
a R a� 
f (a) S f (a� ). 
iff 
Theorem  7.2.2.  Every  weak  partial  order,  �,  is  isomorphic  to  the  subset  relation,  on  a 
collection of sets. 
To  picture  a  partial  order,  �,  on  a  set,  A,  as  a  collection  of  sets,  we  simply 
represent each element A by the set of elements that are � to that element, that is, 
a  ←→  {b ∈ A | b � a} . 
For example,  if � is the divisibility relation on the set of integers, {1, 3, 4, 6, 8, 12}, 
then we represent each of these integers by the set of integers in A that divides it. 
So 

1  ←→  {1}
3  ←→  {1, 3}
4  ←→  {1, 4}
6  ←→  {1, 3, 6}
8  ←→  {1, 4, 8}
12  ←→  {1, 3, 4, 6, 12} 

112 

CHAPTER 7.  PARTIAL ORDERS 

So, the fact that 3 | 12 corresponds to the fact that {1, 3} ⊆ {1, 3, 4, 6, 12}. 
In this way we have completely captured the weak partial order � by the subset 
relation on the corresponding sets.  Formally, we have 
Lemma  7.2.3.  Let  �  be  a  weak  partial  order  on  a  set,  A.  Then  �  is  isomorphic  to  the 
subset relation on the collection of inverse images of elements a ∈ A under the � relation. 
We leave the proof to Problem 7.3. Essentially the same construction shows that 
strict partial orders can be represented by set under the proper subset relation, ⊂. 

7.2.1  Problems 
Class Problems 

Problem 7.1. 

Subject 
Direct Prerequisites 
6.042 
18.01 
18.02 
18.01 
18.03 
18.01 
8.02 
8.01 
6.01 
8.01 
6.042 
6.046 
18.02, 18.03, 8.02, 6.01  6.02 
6.006 
6.01, 6.042 
6.034 
6.01 
6.02 
6.004 

(a)  For the above table of MIT subject prerequisites, draw a diagram showing the 
subject numbers with a  line going down  to  every  subject  from  each of  its  (direct) 
prerequisites. 

(b)  Give an example of a collection of sets partially ordered by the proper subset 
relation, ⊂, that is isomorphic to (“same shape as”) the prerequisite relation among 
MIT subjects from part (a). 

(c)  Explain why  the empty relation  is a strict partial order and describe a collec­
tion of sets partially ordered by the proper subset relation that is isomorphic to the 
empty relation on ﬁve elements —that is, the relation under which none of the ﬁve 
elements is related to anything. 

(d)  Describe a simple collection of sets partially ordered by the proper subset rela­
tion that is isomorphic to the ”properly contains” relation, ⊃, on P {1, 2, 3, 4}. 

Problem 7.2. 
Consider the proper subset partial order, ⊂, on the power set P {1, 2, . . . , 6}. 

7.3.  TOTAL ORDERS 

113 

(a)  What is the size of a maximal chain in this partial order? Describe one. 

(b)  Describe the largest antichain you can ﬁnd in this partial order. 

(c)  What are the maximal and minimal elements?  Are they maximum and mini­
mum? 
(d)  Answer the previous part for the ⊂ partial order on the set P {1, 2, . . . , 6} − ∅. 

Homework Problems 

Problem 7.3. 
This  problem  asks  for  a  proof  of  Lemma  7.2.3  showing  that  every  weak  partial 
order can be represented by (is isomorphic to) a collection of sets partially ordered 
under set inclusion (⊆). Namely, 
Lemma.  Let � be a weak partial order on a set, A.  For any element a ∈ A, let 
L(a) ::= {b ∈ A  | b � a} , 
L ::= {L(a) | a ∈ A} . 
Then  the  function L  :  A  → L  is an  isomorphism  from  the �  relation on A,  to  the  subset 
relation on L. 
(a)  Prove that the function L  : A → L is a bijection. 
(b)  Complete the proof by showing that 
a � b 
iff  L(a) ⊆ L(b) 

(7.1) 

for all a, b ∈ A. 

7.3  Total Orders 

The  familiar  order  relations  on  numbers  have  an  important  additional  property: 
given two different numbers, one will be bigger than the other. Partial orders with 
this property are said to be total2  orders. 
Deﬁnition 7.3.1.  Let R be a binary relation on a set, A, and  let a, b be elements of 
A.  Then  a  and  b  are  comparable with  respect  to R  iff  [a R b  OR  b R a].  A partial 
order for which every two different elements are comparable is called a total order. 
So  <  and  ≤  are  total  orders  on  R.  On  the  other  hand,  the  subset  relation  is 
not  total,  since,  for  example,  any  two  different  ﬁnite  sets  of  the  same  size will  be 
incomparable under ⊆.  The prerequisite relation on Course 6 required subjects  is 
also  not  total  because,  for  example,  neither  8.01  nor  6.001  is  a  prerequisite  of  the 
other. 
2 “Total”  is  an  overloaded  term  when  talking  about  partial  orders:  being  a  total  order  is  a  much 
stronger  condition  than  being  a  partial  order  that  is  a  total  relation.  For  example,  any  weak  partial 
order such as ⊆ is a total relation. 

114 

CHAPTER 7.  PARTIAL ORDERS 

7.3.1  Problems 
Practice Problems 

Problem 7.4. 
For  each  of  the  binary  relations  below,  state  whether  it  is  a  strict  partial  order,  a 
weak  partial  order,  or  neither.  If  it  is  not  a  partial  order,  indicate  which  of  the 
axioms for partial order it violates.  If it is a partial order, state whether it is a total 
order and identify its maximal and minimal elements, if any. 
(a)  The superset relation, ⊇ on the power set P {1, 2, 3, 4, 5}. 
(b)  The relation between any  two nonegative  integers, a,  b  that  the remainder of 
a divided by 8 equals the remainder of b divided by 8. 

(c)  The relation between propositional formulas, G, H , that G IM P L I E S H  is valid. 

(d)  The relation ’beats’ on Rock, Paper and Scissor (for those who don’t know the 
game  Rock,  Paper,  Scissors,  Rock  beats  Scissors,  Scissors  beats  Paper  and  Paper 
beats Rock). 

(e)  The empty relation on the set of real numbers. 

(f)  The identity relation on the set of integers. 
(g)  The divisibility relation on the integers, Z. 

Class Problems 

Problem 7.5.  (a)  Verify that the divisibility relation on the set of nonnegative inte­
gers is a weak partial order. 

(b)  What about the divisibility relation on the set of integers? 

Problem 7.6. 
Consider the nonnegative numbers partially ordered by divisibility. 
(a)  Show that this partial order has a unique minimal element. 

(b)  Show that this partial order has a unique maximal element. 

(c)  Prove that this partial order has an inﬁnite chain. 

(d)  An antichain in a partial order is a set of elements such that any two elements 
in the set are incomparable.  Prove that this partial order has an inﬁnite antichain. 
Hint: The primes. 

(e)  What are  the minimal elements of divisibility on  the  integers greater  than 1? 
What are the maximal elements? 

7.3.  TOTAL ORDERS 

115 

Problem 7.7. 
How many binary relations are there on the set {0, 1}? 
How many are there that are transitive?, . . . asymmetric?, . . . reﬂexive?, . . . irreﬂexive?, 
. . . strict partial orders?, . . . weak partial orders? 
Hint:  There are easier ways to ﬁnd these numbers than  listing all the relations 
and checking which properties each one has. 

Problem 7.8. 
A  binary  relation, R,  on  a  set, A,  is  irreﬂexive  iff  NO T(a R a)  for  all  a  ∈  A.  Prove 
that if a binary relation on a set is transitive and irreﬂexive,  then it is strict partial 
order. 

Problem 7.9. 
Prove that if R is a partial order, then so is R−1 

Homework Problems 

Problem 7.10. 
Let R and S  be binary relations on the same set, A. 
◦ 
Deﬁnition  7.3.2.  The  composition,  S R,  of  R  and  S  is  the  binary  relation  on  A 
deﬁned by the rule:3 

a (S ◦ R) c 

iff  ∃b [a R b  AND  b S c]. 

Suppose  both  R  and  S  are  transitive.  Which  of  the  following  new  relations 
must also be  transitive?  For each part,  justify your answer with a brief argument 
if the new relation is transitive and a counterexample if it is not. 
(a)  R−1 
(b)  R ∩ S 
(c)  R R◦ 
(d)  R S◦ 

Exam Problems 

Problem 7.11. 

3Note the reversal in the order of R and S . This is so that relational composition generalizes function 
composition, Composing  the  functions  f  and  g means  that  f  is  applied ﬁrst,  and  then  g  is  applied  to 
the  result.  That  is,  the  value  of  the  composition  of  f  and  g  applied  to  an  argument,  x,  is  g(f (x)).  To 
◦ 
reﬂect this,  the notation g
f  is commonly used for the composition of f  and g .  Some texts do deﬁne 
◦ 
f  the other way around. 
g

116 

CHAPTER 7.  PARTIAL ORDERS 

(a)  For  each  row  in  the  following  table,  indicate whether  the  binary  relation,  R, 
on  the  set, A,  is  a weak partial  order or  a  total  order by ﬁlling  in  the  appropriate 
entries with either Y = YES or N = NO. In addition, list the minimal and maximal 
elements for each relation. 

total order  minimal(s)  maximal(s) 

A 
R − R+ 
P ({1, 2, 3}) 
N ∪ {i} 

a R b  weak partial order 
a | b 
a ⊆ b 

a > b 

(b)  What is the longest chain on the subset relation, ⊆, on P ({1, 2, 3})?  (If there is 
more than one, provide ONE of them.) 

(c)  What is the longest antichain on the subset relation, ⊆, on P ({1, 2, 3})?  (If there 
is more than one, provide one of them.) 

7.4  Product Orders 

Taking the product of two relations is a useful way to construct new relations from 
old ones. 
Deﬁnition 7.4.1.  The product, R1  × R2 , of relations R1  and R2  is deﬁned to be the 
relation with 

domain (R1  × R2 ) 
codomain (R1  × R2 ) 
(a1 , a2 ) (R1  × R2 ) (b1 , b2 ) 
Example 7.4.2.  Deﬁne a relation, Y , on age-height pairs of being younger and shorter. 
This is the relation on the set of pairs (y , h) where y is a nonnegative integer ≤ 2400 

::=  domain (R1 ) × domain (R2 ) , 
::=  codomain (R1 ) × codomain (R2 ) , 
[a1 R1 b1  and a2 R2 b2 ]. 
iff 

7.5.  SCHEDULING 

117 

which we interpret as an age in months, and h is a nonnegative integer ≤  120 de­
scribing height in inches. We deﬁne Y  by the rule 
iff  y1  ≤ y2  AND  h1  ≤ h2 . 
(y1 , h1 ) Y  (y2 , h2 ) 
That is, Y  is the product of the ≤-relation on ages and the ≤-relation on heights. 
It follows directly from the deﬁnitions that products preserve the properties of 
transitivity,  reﬂexivity,  irreﬂexivity,  and antisymmetry, as shown  in Problem 7.12. 
That is, if R1  and R2  both have one of these properties, then so does R1 × R2 . This 
implies that if R1  and R2  are both partial orders, then so is R1  × R2 . 
On  the  other  hand,  the  property  of  being  a  total  order  is  not  preserved.  For 
example,  the age-height relation Y  is  the product of  two  total orders, but  it  is not 
total:  the age 240 months, height 68 inches pair,  (240,68), and the pair (228,72) are 
incomparable under Y . 

7.4.1  Problems 
Class Problems 

Problem 7.12. 
Let R1 , R2  be binary relations on the same set, A. A relational property is preserved 
under  product,  if  R1  × R2  has  the  property  whenever  both  R1  and  R2  have  the 
property. 
(a)  Verify that each of the following properties are preserved under product. 

1.  reﬂexivity, 

2.  antisymmetry, 

3.  transitivity. 
(b)  Verify that if either of R1  or R2  is irreﬂexive, then so is R1  × R2 . 
Note that it now follows immediately that if if R1  and R2  are partial orders and 
at least one of them is strict, then R1  × R2  is a strict partial order. 

7.5  Scheduling 

Scheduling  problems  are  a  common  source  of  partial  orders:  there  is  a  set,  A,  of 
tasks  and  a  set  of  constraints  specifying  that  starting  a  certain  task  depends  on 
other tasks being completed beforehand.  We can picture the constraints by draw­
ing labelled boxes corresponding to different tasks, with an arrow from one box to 
another if the ﬁrst box corresponds to a task that must be completed before starting 
the second one. 

118 

CHAPTER 7.  PARTIAL ORDERS 

Example 7.5.1.  Here  is a drawing describing  the order  in which you could put on 
clothes. The tasks are the clothes to be put on, and the arrows indicate what should 
be put on directly before what. 

left  shoe 

right  shoe 

belt 

jacket 

left  sock 

right  sock 

pants 

sweater 

underwear 

shirt 

When we have a partial order of tasks to be performed, it can be useful to have 
an  order  in  which  to  perform  all  the  tasks,  one  at  a  time,  while  respecting  the 
dependency  constraints.  This  amounts  to  ﬁnding  a  total  order  that  is  consistent 
with the partial order. This task of ﬁnding a total ordering that is consistent with a 
partial order is known as topological sorting. 
Deﬁnition 7.5.2.  A topological sort of a partial order, �, on a set, A, is a total order­
ing, �, on A such that 
a � b  IM P L I E S  a � b. 

For example, 
shirt � sweater � underwear � leftsock � rightsock � pants 
� leftshoe � rightshoe � belt �  jacket, 
is one topological sort of the partial order of dressing tasks given by Example 7.5.1; 
there are several other possible sorts as well. 
Topological sorts for partial orders on ﬁnite sets are easy to construct by starting 
from minimal elements: 
Deﬁnition 7.5.3.  Let � be a partial order on a set, A. An element a0  ∈ A is minimum 
iff it is � every other element of A, that is, a0  � b for all b =� a0 . 
The element a0  is minimal iff no other element is �  a0 ,  that is, NOT(b �  a0 ) for 
all b = a0 . 
There are corresponding deﬁnitions for maximum and maximal. Alternatively, a 
maximum(al)  element  for  a  relation,  R,  could  be deﬁned  to  be  as  a minimum(al) 
element for R−1 . 
In  a  total  order,  minimum  and  minimal  elements  are  the  same  thing.  But  a 
partial order may have no minimum element but lots of minimal elements.  There 
are four minimal elements in the clothes example:  leftsock, rightsock, underwear, 
and shirt. 

�
7.5.  SCHEDULING 

119 

To construct a total ordering for getting dressed, we pick one of these minimal 
elements,  say  shirt.  Next we pick  a minimal  element  among  the  remaining ones. 
For  example,  once  we  have  removed  shirt,  sweater  becomes  minimal.  We  con­
tinue  in  this  way  removing  successive minimal  elements  until  all  elements  have 
been  picked.  The  sequence  of  elements  in  the  order  they  were  picked  will  be  a 
topological  sort.  This  is  how  the  topological  sort  above  for  getting  dressed  was 
constructed. 
So our construction shows: 

Theorem 7.5.4.  Every partial order on a ﬁnite set has a topological sort. 

There are many other ways of constructing topological sorts.  For example,  in­
stead of starting “from the bottom” with minimal elements, we could build a total 
starting anywhere and simply keep putting additional elements into the total order 
wherever  they will  ﬁt.  In  fact,  the  domain  of  the  partial  order  need  not  even  be 
ﬁnite: we won’t prove it, but all partial orders, even inﬁnite ones, have topological 
sorts. 

7.5.1  Parallel Task Scheduling 

For  a  partial  order  of  task  dependencies,  topological  sorting  provides  a  way  to 
execute tasks one after another while respecting the dependencies.  But what if we 
have the ability to execute more than one task at the same time?  For example, say 
tasks  are  programs,  the  partial  order  indicates  data  dependence,  and  we  have  a 
parallel machine with lots of processors instead of a sequential machine with only 
one. How should we schedule the tasks? Our goal should be to minimize the total 
time  to  complete  all  the  tasks.  For  simplicity,  let’s  say  all  the  tasks  take  the  same 
amount of time and all the processors are identical. 
So,  given  a  ﬁnite  partially  ordered  set  of  tasks,  how  long  does  it  take  to  do 
them  all,  in  an optimal parallel  schedule?  We  can  also use partial order  concepts 
to analyze this problem. 
In  the  clothes  example,  we  could  do  all  the  minimal  elements  ﬁrst  (leftsock, 
rightsock,  underwear,  shirt),  remove  them  and  repeat.  We’d  need  lots  of  hands, 
or maybe dressing servants. We can do pants and sweater next, and then leftshoe, 
rightshoe, and belt, and ﬁnally jacket. 
In general, a schedule for performing tasks speciﬁes which tasks to do at succes­
sive steps. Every task, a, has be scheduled at some step, and all the tasks that have 
to be completed before task a must be scheduled for an earlier step. 

Deﬁnition  7.5.5.  A  parallel  schedule  for  a  strict  partial  order,  �,  on  a  set,  A,  is a 

120 

CHAPTER 7.  PARTIAL ORDERS 

partition4  of A into sets A0 , A1 , . . . , such that for all a, b ∈ A, k ∈ N, 
b ∈ Aj  for some j  < k . 
[a ∈ Ak  AND  b � a] 

IM P L I E S 

The  set  Ak  is  called  the  set  of  elements  scheduled  at  step  k ,  and  the  length  of  the 
schedule  is  the  number  of  sets  Ak  in  the  partition.  The maximum  number  of  el­
ements  scheduled  at  any  step  is  called  the  number  of  processors  required  by  the 
schedule. 

So the schedule we chose above for clothes has four steps 
A0  = {leftsock, rightsock, underwear, shirt} , 
A1  = {pants, sweater} , 
A2  = {leftshoe, rightshoe, belt} , 
A3  = {jacket} . 

and requires four processors (to complete the ﬁrst step). 
Notice  that  the  dependencies  constrain  the  tasks  underwear,  pants,  belt,  and 
jacket  to  be  done  in  sequence.  This  implies  that  at  least  four  steps  are  needed  in 
every  schedule  for getting dressed,  since  if we used  fewer  than  four  steps,  two of 
these tasks would have to be scheduled at the same time.  A set of tasks that must 
be done in sequence like this is called a chain. 

Deﬁnition  7.5.6.  A  chain  in  a partial  order  is  a  set  of  elements  such  that  any  two 
different elements  in  the set are comparable.  A chain  is said  to end at an  its maxi­
mum element. 

In general, the earliest step at which an element a can ever be scheduled must 
be at least as large as any chain that ends at a. A largest chain ending at a is called 
a critical path to a, and the size of the critical path is called the depth of a.  So in any 
possible parallel schedule, it takes at least depth (a) steps to complete task a. 
There  is  a  very  simple  schedule  that  completes  every  task  in  this  minimum 
number of steps.  Just use a “greedy” strategy of performing tasks as soon as pos­
sible. Namely, schedule all the elements of depth k at step k . That’s how we found 
the schedule for getting dressed given above. 
Theorem 7.5.7.  Let � be a  strict partial order on a  set, A.  A minimum  length  schedule 
for � consists of the sets A0 , A1 , . . . , where 
Ak  ::= {a | depth (a) = k} . 
4 Partitioning a set, A, means “cutting it up” into non-overlapping, nonempty pieces. The pieces are 
called the blocks of the partition. More precisely, a partition of A is a set B whose elements are nonempty 
subsets of A such that 
S 
•  if B , B �  ∈ B are different sets, then B ∩ B �  = ∅, and 
B  = A.
• 
B∈B 

7.6.  DILWORTH’S LEMMA 

121 

We’ll  leave  to  Problem  7.19  the  proof  that  the  sets  Ak  are  a  parallel  schedule 
according to Deﬁnition 7.5.5. 
The minimum number of steps needed to schedule a partial order, �, is called 
the parallel  time required by �, and a  largest possible chain  in �  is called a critical 
path  for �.  So we can summarize  the story above by  this way:  with an unlimited 
number  of processors,  the minimum parallel  time  to  complete  all  tasks  is  simply 
the size of a critical path: 

Corollary 7.5.8.  Parallel time = length of critical path. 

7.6  Dilworth’s Lemma 

Deﬁnition 7.6.1.  An antichain  in a partial order  is a  set of elements  such  that any 
two elements in the set are incomparable. 

Our conclusions about scheduling also tell us something about antichains. 

Corollary 7.6.2.  If the largest chain in a partial order on a set, A, is of size t, then A can 
be partitioned into t antichains. 
Proof.  Let the antichains be the sets Ak ::= {a | depth (a) = k}.  It is an easy exercise 
� 
to verify that each Ak  is an antichain (Problem 7.19) 

Corollary 7.6.2 implies a famous result5  about partially ordered sets: 

Lemma 7.6.3 (Dilworth).  For all t > 0, every partially ordered set with n elements must 
have either a chain of size greater than t or an antichain of size at least n/t. 

Proof.  Assume there is no chain of size greater than t, that is, the largest chain is of 
size ≤  t.  Then by Corollary 7.6.2,  the n elements can be partitioned  into at most t 
antichains.  Let  � be  the  size of  the  largest antichain.  Since every element belongs 
to  exactly  one  antichain,  and  there  are  at  most  t  antichains,  there  can’t  be  more 
than  �t  elements,  namely,  �t  ≥  n.  So  there  is  an  antichain  with  at  least  �  ≥  n/t 
� 
elements. 

√
√
Corollary  7.6.4.  Every  partially  ordered  set with  n  elements  has  a  chain  of  size  greater 
n or an antichain of size at least 
n. 
than 
√
n in Lemma 7.6.3. 

Proof.  Set t = 

� 

Example 7.6.5.  In the dressing partially ordered set, n = 10. 
Try t = 3. There is a chain of size 4. 
Try t = 4. There is no chain of size 5, but there is an antichain of size 4 ≥ 10/4. 

5 Lemma 7.6.3 also follows from a more general result known as Dilworth’s Theorem which we will 
not discuss. 

122 

CHAPTER 7.  PARTIAL ORDERS 

Example  7.6.6.  Suppose we  have  a  class  of  101  students.  Then  using  the  product 
partial order, Y , from Example 7.4.2, we can apply Dilworth’s Lemma to conclude 
that there is a chain of 11 students who get taller as they get older, or an antichain 
of  11  students  who  get  taller  as  they  get  younger,  which  makes  for  an  amusing 
in-class demo. 

7.6.1  Problems 
Practice Problems 

Problem 7.13. 
What  is  the  size  of  the  longest  chain  that  is  guaranteed  to  exist  in  any  partially 
ordered set of n elements? What about the largest antichain? 

Problem 7.14. 
Describe  a  sequence  consisting  of  the  integers  from  1  to  10,000  in  some  order  so 
that there is no increasing or decreasing subsequence of size 101. 

Problem 7.15. 
What is the smallest number of partially ordered tasks for which there can be more 
than one minimum time schedule? Explain. 

Class Problems 

Problem 7.16. 
The  table  below  lists  some prerequisite  information  for  some  subjects  in  the MIT 
Computer Science program (in 2006). This deﬁnes an indirect prerequisite relation, 
�, that is a strict partial order on these subjects. 
→ 
→
6.042 
18.01 
→ 
→
18.03 
18.01 
→ 
→
8.02 
8.01 
→ 
→
6.042 
6.046 
→ 
→
6.003 
6.001, 6.002 
→ 
→
6.004 
6.033 
(a)  Explain why  exactly  six  terms  are  required  to ﬁnish  all  these  subjects,  if you 
can  take  as many  subjects  as you want per  term.  Using  a  greedy  subject  selection 
strategy,  you  should  take  as  many  subjects  as  possible  each  term.  Exhibit  your 
complete class schedule each term using a greedy strategy. 

18.01 
6.046 
6.001 
18.03, 8.02 
6.001, 6.002 
6.033 

18.02
6.840
6.034
6.002
6.004
6.857

(b)  In  the  second  term  of  the  greedy  schedule,  you  took  ﬁve  subjects  including 
18.03.  Identify a set of ﬁve subjects not including 18.03 such that it would be possi­

7.6.  DILWORTH’S LEMMA 

123 

ble to take them in any one term (using some nongreedy schedule). Can you ﬁgure 
out how many such sets there are? 

(c)  Exhibit a schedule for taking all the courses —but only one per term. 

(d)  Suppose that you want to take all of the subjects, but can handle only two per 
term. Exactly how many terms are required to graduate? Explain why. 

(e)  What if you could take three subjects per term? 

Problem 7.17. 
A  pair  of  6.042  TAs,  Liz  and  Oscar,  have  decided  to  devote  some  of  their  spare 
time this term to establishing dominion over the entire galaxy. Recognizing this as 
an ambitious project,  they worked out  the  following  table of  tasks on  the back of 
Oscar ’s copy of the lecture notes. 

1.	 Devise a logo and cool imperial theme music - 8 days. 

2.	 Build a ﬂeet of Hyperwarp Stardestroyers out of eating paraphernalia swiped 
from Lobdell - 18 days. 

3.	 Seize control of the United Nations - 9 days, after task #1. 

4.	 Get shots for Liz’s cat, Tailspin - 11 days, after task #1. 

5.	 Open a Starbucks chain for the army to get their caffeine - 10 days, after task 
#3. 

6.	 Train  an  army  of  elite  interstellar  warriors  by  dragging  people  to  see  The 
Phantom Menace dozens of times - 4 days, after tasks #3, #4, and #5. 

7.	 Launch the ﬂeet of Stardestroyers, crush all sentient alien species, and estab­
lish a Galactic Empire - 6 days, after tasks #2 and #6. 

8.	 Defeat Microsoft - 8 days, after tasks #2 and #6. 

We  picture  this  information  in  Figure  7.1  below  by  drawing  a  point  for  each 
task,  and  labelling  it  with  the  name  and  weight  of  the  task.  An  edge  between 
two  points  indicates  that  the  task  for  the  higher  point must  be  completed  before 
beginning the task for the lower one. 
(a)  Give some valid order in which the tasks might be completed. 
Liz  and  Oscar  want  to  complete  all  these  tasks  in  the  shortest  possible  time. 
However, they have agreed on some constraining work rules. 

•	 Only one person can be assigned  to a particular  task;  they can not work  to­
gether on a single task. 

124 

CHAPTER 7.  PARTIAL ORDERS 

�  18 
�  8 
devise logo 
build ﬂeet
� � 
� � 
�  � 
�  � 
�  � 
� 
� 
� 
� 
� 
� 
� 
� 
� 
�
� 
�
� 
� 
� �
��
seize control 
9 
get shots 
� 
� 
� 
�
� 
11
�
� 
� 
� 
� 
� 
� 
open chain  ��
� 
� 
� 
� 
� 
� 
� 
� 
�
�
�
�
�
� 
� 
�
� 
� 
�
10 
� 
�
�
�
��� �� 
� 
� 
� 
� �
�
� �
�
�
� 4 
�
� 
����������������� 
�
� 
train army  �
� 
� 
�
�
����
� 
� 
��  defeat Microsoft 
�
� 
� 
�
� � 
� 
6
8 
launch ﬂeet 

�
�

�

�
�

Figure 7.1: Graph representing the task precedence constraints. 

7.6.  DILWORTH’S LEMMA 

125 

•	 Once  a  person  is  assigned  to  a  task,  that  person must  work  exclusively  on 
the  assignment  until  it  is  completed.  So,  for  example,  Liz  cannot  work  on 
building a ﬂeet for a few days, run to get shots for Tailspin, and then return 
to building the ﬂeet. 
(b)  Liz and Oscar want to know how long conquering the galaxy will take. Oscar 
suggests  dividing  the  total  number  of  days  of  work  by  the  number  of  workers, 
which is two. What lower bound on the time to conquer the galaxy does this give, 
and why might the actual time required be greater? 

(c)  Liz proposes a different method for determining the duration of their project. 
He suggests looking at the duration of the “critical path”, the most time-consuming 
sequence  of  tasks  such  that  each  depends  on  the  one  before.  What  lower  bound 
does this give, and why might it also be too low? 

(d)  What is the minimum number of days that Liz and Oscar need to conquer the 
galaxy? No proof is required. 

Problem 7.18.  (a)  What are the maximal and minimal elements, if any, of the power 
set P ({1, . . . , n}), where n is a positive integer, under the empty relation? 
(b)  What are  the maximal and minimal elements,  if any,  of  the  set, N,  of all non­
negative integers under divisibility?  Is there a minimum or maximum element? 

(c)  What  are  the  minimal  and  maximal  elements,  if  any,  of  the  set  of  integers 
greater than 1 under divisibility? 

(d)  Describe a partially ordered set that has no minimal or maximal elements. 

(e)  Describe a partially ordered set that has a unique minimal element, but no min­
imum element. Hint:  It will have to be inﬁnite. 

Homework Problems 

Problem 7.19. 
Let � be a partial order on a set, A, and let 
Ak  ::= {a | depth (a) = k} 

where k ∈ N. 
(a)  Prove that A0 , A1 , . . .  is a parallel schedule for � according to Deﬁnition 7.5.5. 
(b)  Prove that Ak  is an antichain. 

Problem 7.20. 
Let S  be a sequence of n different numbers.  A subsequence of S  is a sequence  that 
can be obtained by deleting elements of S . 

126 

CHAPTER 7.  PARTIAL ORDERS 

For example, if 

S  = (6, 4, 7, 9, 1, 2, 5, 3, 8) 
Then  647  and  7253  are both  subsequences of S  (for  readability, we have dropped 
the  parentheses  and  commas  in  sequences,  so  647  abbreviates  (6, 4, 7),  for  exam­
ple). 
An  increasing  subsequence  of  S  is  a  subsequence  of whose  successive  elements 
get larger.  For example, 1238 is an increasing subsequence of S . Decreasing subse­
quences are deﬁned similarly; 641 is a decreasing subsequence of S . 
(a)  List all  the maximum  length  increasing  subsequences of S ,  and all  the maxi­
mum length decreasing subsequences. 
Now  let A be  the  set of numbers  in S .  (So A  =  {1, 2, 3, . . . , 9}  for  the example 
above.) There are two straightforward ways to totally order A. The ﬁrst is to order 
its  elements numerically,  that  is,  to  order A with  the <  relation.  The  second  is  to 
order the elements by which comes ﬁrst in S ; call this order <S . So for the example 
above, we would have 

6 <S  4 <S  7 <S  9 <S  1 <S  2 <S  5 <S  3 <S  8 
Next, deﬁne the partial order � on A deﬁned by the rule 
a � a� 
::=  a < a�  and a <S  a� . 
(It’s not hard to prove that � is strict partial order, but you may assume it.) 
(b)  Draw  a  diagram  of  the  partial  order,  �,  on  A.  What  are  the  maximal  ele­
ments,. . . the minimal elements? 

(c)  Explain the connection between increasing and decreasing subsequences of S , 
and chains and anti-chains under �. 
√
√
(d)  Prove  that  every  sequence,  S ,  of  length  n  has  an  increasing  subsequence  of 
n or a decreasing subsequence of length at least 
n. 
length greater than 

(e)  (Optional, tricky) Devise an efﬁcient procedure for ﬁnding the longest increas­
ing  and  the  longest  decreasing  subsequence  in  any  given  sequence  of  integers. 
(There is a nice one.) 

Problem 7.21. 
We want to schedule n partially ordered tasks. 
(a)  Explain why  any  schedule  that  requires  only  p  processors must  take  time  at 
least �n/p�. 
(b)  Let Dn,t  be  the  strict partial order with n elements  that  consists of a  chain of 
t − 1 elements, with the bottom element in the chain being a prerequisite of all the 
remaining elements as in the following ﬁgure: 

7.6.  DILWORTH’S LEMMA 

127 

What  is  the  minimum  time  schedule  for  Dn,t ?  Explain  why  it  is  unique.  How 
many processors does it require? 

(c)  Write  a  simple  formula,  M (n, t, p),  for  the  minimum  time  of  a  p-processor 
schedule to complete Dn,t . 

(d)  Show that every partial order with n vertices and maximum chain size,  t, has 
a p-processor schedule that runs in time M (n, t, p). 
Hint:  Induction on t. 

. . .. . .t - 1n - (t - 1)128 

CHAPTER 7.  PARTIAL ORDERS 

Chapter 8 

Directed graphs 

8.1  Digraphs 

A directed graph (digraph for short)  is formally  the same as a binary relation, R, on 
a set, A —that is, a relation whose domain and codomain are the same set, A.  But 
we describe digraphs as though they were diagrams, with elements of A pictured 
as  points  on  the  plane  and  arrows  drawn  between  related  points.  The  elements 
of A are  referred  to as  the vertices of  the digraph,  and  the pairs  (a, b)  ∈  graph (R) 
→
b is a more suggestive alternative for the pair (a, b).
are directed edges. Writing a
Directed edges are also called arrows. 
For  example,  the  divisibility  relation  on  {1, 2, . . . , 12}  is  could  be  pictured  by 
the digraph: 

Figure 8.1: The Digraph for Divisibility on {1, 2, . . . , 12}. 

129 

126182410571193130 

CHAPTER 8.  DIRECTED GRAPHS 

8.1.1  Paths in Digraphs 
Picturing digraphs with points and arrows makes it natural to talk about following 
a path of successive edges  through  the graph.  For example,  in  the digraph of Fig­
ure 8.1, a path might start at vertex 1, successively follow the edges from vertex 1 
to vertex 2, from 2 to 4, from 4 to 12, and then from 12 to 12 twice (or as many times 
as you  like).  We  can  represent  the path with  the  sequence of  sucessive vertices  it 
went through, in this case: 

1, 2, 4, 12, 12, 12. 
So a path is  just a sequence of vertices, with consecutive vertices on the path con­
nected by directed edges. Here is a formal deﬁnition: 
Deﬁnition 8.1.1.  A path in a digraph is a sequence of vertices a0 , . . . , ak  with k  ≥  0 
such that ai  → ai+1  is an edge of the digraph for i = 0, 1, . . . , k − 1. The path is said 
to start at a0 , to end at ak , and the length of the path is deﬁned to be k .  The path is 
j , then ai  =� aj . 
simple iff all the ai ’s are different, that is, if i =�
Note  that  a  single  vertex  counts  as  length  zero  path  that  begins  and  ends  at 
itself. 
It’s pretty natural to talk about the edges  in a path, but technically, paths only 
→ 
have points, not edges. So to instead, we’ll say a path traverses an edge a
b when 
a and b are consecutive vertices in the path. 
For  any  digraph,  R,  we  can  deﬁne  some  new  relations  on  vertices  based  on 
paths, namely, the path relation, R∗ , and the positive-length path relation, R+ : 
a R∗  b ::= there is a path in R from a to b,

a R+  b ::= there is a positive length path in R from a to b.

By  the deﬁnition of path, both R∗  and R+  are  transitive.  Since edges count as 
length  one paths,  the  edges  of R+  include  all  the  edges  of R.  The  edges  of R∗  in 
turn include all the edges of R+  and,  in addition include an edge (self-loop) from 
each vertex to itself.  The self-loops get included in R∗  because of the a length zero 
paths in R.  So R∗  is reﬂexive.  1 

8.2  Picturing Relational Properties 

Many  of  the  relational  properties  we’ve  discussed  have  natural  descriptions  in 
terms of paths.  For example: 

Reﬂexivity:  All  vertices  have  self-loops  (a  self-loop  at  a  vertex  is  an  arrow  going 
from the vertex back to itself). 

Irreﬂexivity:  No vertices have self-loops. 

Antisymmetry:  At most one (directed) edge between different vertices. 
1 In many texts, R+  is called the transitive closure and R∗  is called the reﬂexive transitive closure of R. 

8.3.  COMPOSITION OF RELATIONS 

131 

Asymmetry:  No self-loops and at most one (directed) edge between different ver­
tices. 

Transitivity:  Short-circuits—for  any  path  through  the  graph,  there  is  an  arrow 
from the ﬁrst vertex to the last vertex on the path. 

Symmetry:  A binary  relation R  is  symmetric  iff aRb  implies  bRa  for  all a, b  in  the 
domain of R.  That  is,  if  there  is an edge  from a  to  b,  there  is also one  in  the 
reverse direction. 

8.3  Composition of Relations 

There  is  a  simple way  to  extend  composition  of  functions  to  composition  of  rela­
tions, and this gives another way to talk about paths in digraphs. 
→
→
C  and S  : A
Let R  : B
B  be relations.  Then the composition of R with S
◦
→ 
is the binary relation (R S ) : A
C  deﬁned by the rule 
a (R ◦ S ) c ::=  ∃b ∈ B . (b R c) AND  (a S b). 

This agrees with the Deﬁnition 4.3.1 of composition in the special case when R and 
S  are functions. 
Now when R is a digraph, it makes sense to compose R with itself.  Then if we 
let Rn  denote the composition of R with itself n times, it’s easy to check that Rn  is 
the length-n path relation: 

a Rn  b 

iff 

there is a length n path in R from a to b. 

This  even  works  for  n  = 0,  if  we  adopt  the  convention  that  R0  is  the  identity 
relation IdA  on the set, A, of vertices. That is, (a IdA  b) iff a = b. 

8.4  Directed Acyclic Graphs 

Deﬁnition 8.4.1.  A cycle in a digraph is deﬁned by a path that begins and ends at 
the same vertex.  This includes the cycle of length zero that begins and ends at the 
vertex.  A  directed  acyclic  graph  (DAG)  is  a  directed  graph  with  no  positive  length 
cycles. 
A  simple  cycle  in a digraph  is  a  cycle whose vertices are distinct  except  for  the 
beginning and end vertices. 

DAG’s can be an economical way to represent partial orders.  For example, the 
direct prerequisite relation between MIT subjects in Chapter 7 was used to determine 
the  partial  order  of  indirect  prerequisites  on  subjects.  This  indirect  prerequisite 
partial order is precisely the positive length path relation of the direct prerequisites. 

Lemma 8.4.2.  If D  is a DAG, then D+  is a strict partial order. 

132 

CHAPTER 8.  DIRECTED GRAPHS 

Proof.  We know that D+  is transitive. Also, a positive length path from a vertex to 
itself would  be  a  cycle,  so  there  are  no  such  paths.  This means D+  is  irreﬂexive, 
� 
which implies it is a strict partial order (see problem 7.8). 

It’s easy to check that conversely, the graph of any strict partial order is a DAG. 
The divisibility partial order can also be more economically represented by the 
path relation in a DAG. A DAG whose path relation is divisibility on {1, 2, . . . , 12}
�� 
is  shown  in  Figure  8.2;  the  arrowheads  are  omitted  in  the  Figure,  and  edges  are 
understood to point upwards. 
�� 
�� 
8 
�� 
�� �� 
12 
�� �� 
.............................
�� �� 
4
9 
�� 
6�� 10 
�� �� �� �� �� 
�� �� �� �� �� 
.............................
.............................
.............................
.............................
2 
7 
5 
11
3 
.
� 
� � � 
� ��
�  �
� � 
�  �
�� 
�  �
�
�
�
�� 
��
1 
Figure 8.2: A DAG whose Path Relation is Divisibility on {1, 2, . . . , 12}. 

If we’re using a DAG  to  represent a partial order —so all we care about  is  the 
the  path  relation  of  the  DAG —we  could  replace  the  DAG  with  any  other  DAG 
with  the  same  path  relation.  This  raises  the  question  of  ﬁnding  a  DAG with  the 
same  path  relation  but  the  smallest  number  of  edges.  This  DAG  turns  out  to  be 
unique and easy to ﬁnd (see problem 8.2). 

8.4.1  Problems 
Practice Problems 

Problem 8.1. 
Why is every strict partial order a DAG? 

Class Problems 

Problem 8.2. 
If a and b are distinct nodes of a digraph, then a is said to cover b if there is an edge 

8.4.  DIRECTED ACYCLIC GRAPHS 

133 

from a  to  b and every path  from a  to  b  traverses  this edge.  If a  covers  b,  the edge 
from a to b is called a covering edge. 
(a)	 What are the covering edges in the following DAG? 

(b)  Let covering (D) be the subgraph of D  consisting of only the covering edges. 
Suppose D  is a ﬁnite DAG. Explain why covering (D) has  the same positive path 
relation as D . 
Hint: Consider longest paths between a pair of vertices. 

(c)  Show that if two DAG’s have the same positive path relation,  then they have 
the same set of covering edges. 

(d)  Conclude  that  covering (D)  is  the  unique  DAG  with  the  smallest  number  of 
edges among all digraphs with the same positive path relation as D . 
The following examples show that the above results don’t work in general for 
digraphs with cycles. 
(e)  Describe two graphs with vertices {1, 2} which have the same set of covering 
edges, but not the same positive path relation (Hint:  Self-loops.) 

(f)	

(i)  The  complete  digraph  without  self-loops  on  vertices  1, 2, 3  has  edges  be­
tween every two distinct vertices. What are its covering edges? 
→ 
(ii)  What are the covering edges of the graph with vertices 1, 2, 3 and edges 1 
2, 2 → 3, 3 → 1? 
(iii)  What about their positive path relations? 

Homework Problems 

Problem 8.3. 
Let R be a binary relation on a set A.  Then Rn  denotes the composition of R with 

126182410571193134 

CHAPTER 8.  DIRECTED GRAPHS 

itself  n  times.  Let  GR  be  the  digraph  associated  with  R.  That  is,  A  is  the  set  of 
vertices ofGR  and R is the set of directed edges.  Let R(n)  denote the length n path 
relation GR , that is, 

a R(n)  b ::= there is a length n path from a to b in GR . 

Prove that 

for all n ∈ N. 

Rn  = R(n) 

(8.1) 

Problem 8.4.  (a)  Prove that if R is a relation on a ﬁnite set, A, then 
a (R ∪ IA )n  b 
there is a path in R of length length ≤ n from a to b. 

iff 

(b)	 Conclude that if A is a ﬁnite set, then 
R∗  = (R ∪ IA )|A|−1 . 

(8.2) 

Chapter 9 

State Machines 

9.1  State machines 

State machines  are  an  abstract model  of  step-by-step  processes,  and  accordingly, 
they  come  up  in  many  areas  of  computer  science.  You  may  already  have  seen 
them in a digital logic course, a compiler course, or a probability course. 

9.1.1  Basic deﬁnitions 
A state machine is really nothing more than a binary relation on a set, except that 
the elements of the set are called “states,” the relation is called the transition relation, 
and  a  pair  (p, q)  in  the  graph  of  the  transition  relation  is  called  a  transition.  The 
transition  from state p  to state q will be written p  −→  q .  The  transition  relation  is 
also  called  the  state  graph  of  the machine.  A  state machine  also  comes  equipped 
with a designated start state. 
State  machines  used  in  digital  logic  and  compilers  usually  have  only  a  ﬁnite 
number of states, but machines that model continuing computations typically have 
an  inﬁnite  number  of  states.  In many  applications,  the  states,  and/or  the  transi­
tions have  labels  indicating  input or output values, costs, capacities, or probabili­
ties, but for our purposes, unlabelled states and transitions are all we need.1 
Example 9.1.1.  A bounded counter, which counts from 0 to 99 and overﬂows at 100. 
The transitions are pictured in Figure 9.1, with start state zero.  This machine isn’t 
much use once it overﬂows, since it has no way to get out of its overﬂow state. 
Example 9.1.2.  An unbounded counter is similar, but has an inﬁnite state set.  This 
is harder to draw :-)

Example 9.1.3.  In the movie Die Hard 3: With a Vengeance, the characters played by

Samuel L. Jackson and Bruce Willis have to disarm a bomb planted by the diaboli­

cal Simon Gruber:

1We  do  name  states,  as  in  Figure  9.1,  so we  can  talk  about  them,  but  the  names  aren’t  part  of  the 
state machine. 

135 

136 

CHAPTER 9.  STATE MACHINES 

Figure 9.1:  State transitions for the 99-bounded counter. 

Simon:  On  the  fountain,  there  should  be  2  jugs,  do  you  see  them?  A  5­
gallon and a 3-gallon.  Fill one of  the  jugs with  exactly 4 gallons of water 
and  place  it  on  the  scale  and  the  timer  will  stop.  You  must  be  precise; 
one  ounce more  or  less will  result  in  detonation.  If  you’re  still  alive  in  5 
minutes, we’ll speak. 
Bruce:  Wait, wait a second.  I don’t get it. Do you get it? 
Samuel:  No. 
Bruce:  Get the jugs.  Obviously, we can’t ﬁll the 3-gallon jug with 4 gallons 
of water. 
Samuel:  Obviously. 
Bruce:  All right.  I know, here we go.  We ﬁll the 3-gallon jug exactly to the 
top, right? 
Samuel:  Uh-huh. 
Bruce:  Okay,  now  we  pour  this  3  gallons  into  the  5-gallon  jug,  giving  us 
exactly 3 gallons in the 5-gallon jug, right? 
Samuel:  Right, then what? 
Bruce:  All right. We take the 3-gallon jug and ﬁll it a third of the way... 
Samuel:  No! He said, “Be precise.” Exactly 4 gallons. 
Bruce:  Sh - -.  Every cop within 50 miles is running his a - - off and I’m out 
here playing kids games in the park. 
Samuel:  Hey, you want to focus on the problem at hand? 

Fortunately,  they ﬁnd a  solution  in  the nick of  time.  We’ll  let  the  reader work 
out how. 
The Die Hard series is getting tired, so we propose a ﬁnal Die Hard Once and For 
All. Here Simon’s brother returns to avenge him, and he poses the same challenge, 
but with the 5 gallon jug replaced by a 9 gallon one. 
We can model jug-ﬁlling scenarios with a state machine.  In the scenario with a 
3 and a 5 gallon water  jug,  the states will be pairs, (b, l) of real numbers such that 

01299overflowstartstate9.1.  STATE MACHINES 

137 

0 ≤  b ≤  5, 0 ≤  l  ≤  3.  We let b and l be arbitrary real numbers.  (We can prove that 
the values of b and l will only be nonnegative integers, but we won’t assume this.) 
The start state is (0, 0), since both jugs start empty. 
Since the amount of water in the jug must be known exactly, we will only con­
sider moves in which a jug gets completely ﬁlled or completely emptied. There are 
several kinds of transitions: 
1.  Fill the little jug:  (b, l) −→ (b, 3) for l < 3. 
2.  Fill the big jug:  (b, l) −→ (5, l) for b < 5. 
3.  Empty the little jug:  (b, l) −→ (b, 0) for l > 0. 
4.  Empty the big jug:  (b, l) −→ (0, l) for b > 0. 
� 
5.  Pour from the little jug into the big jug:  for l > 0, 
if b + l ≤ 5,
(b + l, 0) 
(5, l − (5 − b))  otherwise. 
� 
6.  Pour from big jug into little jug:  for b > 0, 
if b + l ≤ 3,
(0, b + l) 
(b − (3 − l), 3)  otherwise. 

(b, l) −→ 

(b, l) −→ 

Note  that  in  contrast  to  the  99-counter  state  machine,  there  is  more  than  one 
possible  transition  out  of  states  in  the  Die  Hard  machine.  Machines  like  the  99­
counter with  at most  one  transition  out  of  each  state  are  called  deterministic.  The 
Die Hard machine  is nondeterministic because some states have  transitions  to sev­
eral different states. 
Quick exercise: Which states of the Die Hard 3 machine have direct transitions 
to exactly two states? 

9.1.2  Reachability and Preserved Invariants 
The Die Hard 3 machine models every possible way of pouring water among  the 
jugs  according  to  the  rules.  Die Hard  properties  that we want  to  verify  can  now 
be  expressed  and  proved  using  the  state  machine  model.  For  example,  Bruce’s 
character will disarm the bomb if he can get to some state of the form (4, l). 
A  (possibly  inﬁnite)  path  through  the  state  graph  beginning  at  the  start  state 
corresponds to a possible system behavior; such a path is called an execution of the 
state machine. A state is called reachable if it appears in some execution. The bomb 
in Die Hard 3 gets disarmed successfully because the state (4,3) is reachable. 
A useful approach in analyzing state machine is to identify properties of states 
that are preserved by transitions. 

138 

CHAPTER 9.  STATE MACHINES 

Deﬁnition 9.1.4.  A preserved invariant of a state machine is a predicate, P , on states, 
such  that whenever  P (q)  is  true  of  a  state,  q ,  and  q  −→  r  for  some  state,  r ,  then 
P (r) holds. 

The Invariant Principle 

If a preserved invariant of a state machine is true for the start state, 
then it is true for all reachable states. 

The Invariant Principle  is nothing more than the Induction Principle reformu­
lated  in a convenient  form  for state machines.  Showing  that a predicate  is  true  in 
the  start  state  is  the  base  case  of  the  induction,  and  showing  that  a predicate  is  a 
preserved invariant is the inductive step.2 

Die Hard Once and For All 

Now back to Die Hard Once and For All.  This time there is a 9 gallon  jug instead 
of  the  5  gallon  jug.  We  can  model  this  with  a  state  machine  whose  states  and 
transitions  are  speciﬁed  the  same  way  as  for  the  Die  Hard  3  machine,  with  all 
occurrences of “5” replaced by “9.” 
Now reaching any state of the form (4, l) is impossible. We prove this using the 
Invariant Principle.  Namely, we deﬁne  the preserved  invariant predicate, P (b, l), 
to be that b and l are nonnegative integer multiples of 3.  So P  obviously holds for 
the state state (0, 0). 
To prove that P  is a preserved invariant, we assume P (b, l) holds for some state 
(b, l) and show  that  if (b, l)  −→  (b� , l� ),  then P (b� , l� ).  The proof divides  into cases, 
according  to  which  transition  rule  is  used.  For  example,  suppose  the  transition 
followed  from  the “ﬁll  the  little  jug”  rule.  This means  (b, l)  −→  (b, 3).  But P (b, l) 
implies  that b  is an  integer multiple of 3, and of course 3  is an  integer multiple of 
3, so P  still holds for the new state (b, 3).  Another example is when the transition 
rule used is “pour from big jug into little jug” for the subcase that b + l >  3.  Then 
state  is  (b, l)  −→  (b − (3 − l), 3).  But  since  b and  l  are  integer multiples of 3,  so  is 
b − (3 − l).  So in this case too, P  holds after the transition. 
We  won’t  bother  to  crank  out  the  remaining  cases,  which  can  all  be  checked 
just  as  easily.  Now  by  the  Invariant  Principle,  we  conclude  that  every  reachable 

2 Preserved  invariants  are  commonly  just  called  “invariants”  in  the  literature  on  program  correct­
ness,  but  we  decided  to  throw  in  the  extra  adjective  to  avoid  confusion  with  other  deﬁnitions.  For 
example, another subject at MIT uses “invariant” to mean “predicate true of all reachable states.” Let’s 
call this deﬁnition “invariant-2.” Now invariant-2 seems like a reasonable deﬁnition, since unreachable 
states by deﬁnition don’t matter, and all we want to show is that a desired property is invariant-2.  But 
this  confuses  the  objective  of  demonstrating  that  a  property  is  invariant-2  with  the  method  for  show­
ing  that  it  is.  After all,  if we already knew  that a property was  invariant-2, we’d have no need  for an 
Invariant Principle to demonstrate it. 

9.1.  STATE MACHINES 

139 

state satisiﬁes P .  But since no state of  the  form (4, l) satisiﬁes P , we have proved 
rigorously that Bruce dies once and for all! 
By the way, notice that the state (1,0), which satisﬁes NO T(P ), has a transition to 
(0,0), which satisﬁes P . So it’s wrong to assume that the complement of a preserved 
invariant is also a preserved invariant. 

A Robot on a Grid 

There is a robot.  It walks around on a grid, and at every step it moves diagonally 
in a way that changes its position by one unit up or down and one unit left or right. 
The robot starts at position (0, 0). Can the robot reach position (1, 0)? 
To get some  intuition, we can simulate some robot moves.  For example, start­
ing  at  (0,0)  the  robot  could  move  northeast  to  (1,1),  then  southeast  to  (2,0),  then 
southwest to (1,-1), then southwest again to (0,-2). 
Let’s model the problem as a state machine and then ﬁnd a suitable  invariant. 
A  state  will  be  a  pair  of  integers  corresponding  to  the  coordinates  of  the  robot’s 
position.  State (i, j ) has transitions to four different states:  (i ± 1, j ± 1). 
The  problem  is  now  to  choose  an  appropriate  preserved  invariant,  P ,  that  is 
true  for  the  start  state  (0, 0)  and  false  for  (1, 0).  The  Invariant  Theorem  then will 
imply that the robot can never reach (1, 0). A direct attempt for a preserved invari­
ant is the predicate P (q) that q = (1
, 0). 
Unfortunately,  this  is  not  going  to  work.  Consider  the  state  (2, 1).  Clearly 
P (2, 1)  holds  because  (2, 1)  �=  (1, 0).  And  of  course  P (1, 0)  does  not  hold.  But 
(2, 1) −→ (1, 0), so this choice of P  will not yield a preserved invariant. 
We need a stronger predicate.  Looking at our example execution you might be 
able  to guess a proper one, namely,  that  the sum of  the coordinates  is even!  If we 
can  prove  that  this  is  a  preserved  invariant,  then  we  have  proven  that  the  robot 
never  reaches  (1, 0) —because  the  sum  1 + 0  of  its  coordinates  is  odd,  while  the 
sum 0 + 0 of the coordinates of the start state is even. 

Theorem 9.1.5.  The sum of the robot’s coordinates is always even. 

Proof.  The proof uses the Invariant Principle. 
Let P (i, j ) be the predicate that i + j  is even. 
First, we must  show  that  the  predicate  holds  for  the  start  state  (0, 0).  Clearly, 
P (0, 0) is true because 0 + 0 is even. 
Next,  we must  show  that  P  is  a  preserved  invariant.  That  is,  we must  show 
that  for  each  transition  (i, j )  −→  (i� , j � ),  if  i + j  is  even,  then  i�  + j �  is  even.  But 
i�  =  i ± 1 and j �  =  j ± 1 by deﬁnition of the transitions.  Therefore, i�  + j �  is equal 
to i + j  or i + j ± 2, all of which are even. 
� 

Corollary 9.1.6.  The robot cannot reach (1, 0). 

�
140 

CHAPTER 9.  STATE MACHINES 

Robert W. Floyd 

The Invariant Principle was formulated by Robert Floyd at Carnegie Techa  in 1967. 
Floyd was  already  famous  for work  on  formal  grammars which  transformed  the 
ﬁeld  of  programming  language  parsing;  that  was  how  he  got  to  be  a  professor 
even though he never got a Ph.D. (He was admitted to a PhD program as a teenage 
prodigy, but ﬂunked out and never went back.) 
In  that  same  year,  Albert  R.  Meyer  was  appointed  Assistant  Professor  in  the 
Carnegie Tech Computer Science Department where he ﬁrst met Floyd. Floyd and 
Meyer were the only theoreticians in the department, and they were both delighted 
to talk about their shared interests. After just a few conversations, Floyd’s new ju­
nior colleague decided that Floyd was the smartest person he had ever met. 
Naturally,  one  of  the  ﬁrst  things  Floyd wanted  to  tell Meyer  about was  his  new, 
as yet unpublished,  Invariant Principle.  Floyd explained  the result  to Meyer, and 
Meyer wondered  (privately)  how  someone  as  brilliant  as  Floyd  could  be  excited 
by  such a  trivial observation.  Floyd had  to  show Meyer a bunch of examples be­
fore Meyer understood Floyd’s excitement —not at the truth of the utterly obvious 
Invariant Principle,  but  rather  at  the  insight  that  such  a  simple  theorem  could be 
so widely and easily applied in verifying programs. 
Floyd left for Stanford the following year. He won the Turing award —the “Nobel 
prize”  of  computer  science—  in  the  late  1970’s,  in  recognition  both  of  his  work 
on  grammars  and  on  the  foundations  of  program  veriﬁcation.  He  remained  at 
Stanford  from 1968 until his death  in September,  2001.  You can  learn more about 
Floyd’s life and work by reading the eulogy written by his closest colleague, Don 
Knuth. 

a The following year, Carnegie Tech was renamed Carnegie-Mellon Univ. 

9.1.3  Sequential algorithm examples 
Proving Correctness 

Robert Floyd, who pioneered modern approaches to program veriﬁcation, distin­
guished two aspects of state machine or process correctness: 
1.  The  property  that  the  ﬁnal  results,  if  any,  of  the  process  satisfy  system  re­
quirements. This is called partial correctness.

You might  suppose  that  if  a  result was  only  partially  correct,  then  it might

also be partially incorrect, but that’s not what he meant.  The word “partial”

comes from viewing a process that might not terminate as computing a partial

function.  So partial correctness means that when there is a result, it is correct,

but  the  process might  not  always  produce  a  result,  perhaps  because  it  gets

stuck in a loop.


9.1.  STATE MACHINES 

141 

2.  The  property  that  the  process  always  ﬁnishes,  or  is  guaranteed  to  produce 
some legitimate ﬁnal output. This is called termination. 

Partial correctness can commonly be proved using the Invariant Principle. Ter­
mination can commonly be proved using the Well Ordering Principle.  We’ll illus­
trate  Floyd’s  ideas  by  verifying  the  Euclidean  Greatest  Common  Divisor  (GCD) 
Algorithm. 

The Euclidean Algorithm 

The  Euclidean  algorithm  is  a  three-thousand-year-old  procedure  to  compute  the 
greatest  common  divisor,  gcd(a, b)  of  integers  a  and  b.  We  can  represent  this  al­
gorithm as a  state machine.  A  state will be a pair of  integers  (x, y) which we  can 
think of as integer registers in a register program. The state transitions are deﬁned 
by the rule 
(x, y) −→ (y , remainder(x, y)) 
for y = 0
. The algorithm terminates when no further transition is possible, namely 
when y = 0. The ﬁnal answer is in x. 
We want to prove: 

1.  Starting  from  the state with x  =  a and y  =  b >  0,  if we ever ﬁnish,  then we 
have the right answer.  That is, at termination, x  =  gcd(a, b).  This is a partial 
correctness claim. 

2.  We do actually ﬁnish. This is a process termination claim. 

Partial Correctness of GCD  First let’s prove that if GCD gives an answer,  it is a 
correct answer.  Speciﬁcally,  let d ::= gcd(a, b).  We want to prove that if  the proce­
dure ﬁnishes in a state (x, y), then x = d. 

Proof.  Deﬁne the state predicate 

P (x, y) ::=  [gcd(x, y) = d and (x > 0 or y > 0)]. 

P  holds for the start state (a, b), by deﬁnition of d and the requirement that b is 
positive. Also, the preserved invariance of P  follows immediately from 
Lemma 9.1.7.  For all m, n ∈ N such that n = 0
, 

gcd(m, n) = gcd(n, remainder(m, n)). 

(9.1) 

Lemma 9.1.7 is easy to prove:  let q be the quotient and r be the remainder of m 
divided by n.  Then m = qn + r by deﬁnition.  So any factor of both r and n will be 
a factor of m, and similarly any factor of both m and n will be a factor of r .  So r, n 
and m, n have the same common factors and therefore the same gcd.  Now by the 
Invariant Principle, P  holds for all reachable states. 

�
�
142 

CHAPTER 9.  STATE MACHINES 

Since  the  only  rule  for  termination  is  that  y  = 0,  it  follows  that  if  (x, y)  is  a 
terminal  state,  then  y  = 0.  If  this  terminal  state  is  reachable,  then  the  preserved 
invariant  holds  for  (x, y).  This  implies  that  gcd(x, 0)  =  d  and  that  x >  0.  We 
� 
conclude that x = gcd(x, 0) = d. 

Termination  of  GCD  Now  we  turn  to  the  second  property,  that  the  procedure 
must terminate. To prove this, notice that y gets strictly smaller after any one tran­
sition.  That’s  because  the  value  of  y  after  the  transition  is  the  remainder  of  x  di­
vided by y , and this remainder is smaller than y by deﬁnition. But the value of y is 
always a nonnegative integer, so by the Well Ordering Principle, it reaches a mini­
mum value among all its values at reachable states.  But there can’t be a transition 
from a state where y has its minimum value, because the transition would decrease 
y  still  further.  So  the  reachable  state where  y  has  its minimum  value  is  a  state  at 
which no further step is possible, that is, at which the procedure terminates. 
Note  that  this  argument  does  not  prove  that  the minimum  value  of  y  is  zero, 
only that the minimum value occurs at termination. But we already noted that the 
only  rule  for  termination  is  that y  = 0,  so  it  follows  that  the minimum value of y 
must indeed be zero. 

The Extended Euclidean Algorithm 
An important fact about the gcd(a, b) is that it equals an integer linear combination 
of a and b, that is, 

gcd(a, b) = sa + tb 
(9.2) 
for some s, t ∈ Z. We’ll see some nice proofs of (9.2) later when we study Number 
Theory,  but  now we’ll  look  at  an  extension  of  the  Euclidean  Algorithm  that  efﬁ­
ciently,  if  obscurely,  produces  the  desired  s  and  t.  It  is  presented  here  simply  as 
another example of application of the Invariant Method (plus, we’ll need a proce­
dure like this when we take up number theory based cryptography in a couple of 
weeks). 
Don’t  worry  if  you  ﬁnd  this  Extended  Euclidean  Algorithm  hard  to  follow,  and  you 
can’t  imagine where  it  came  from.  In  fact,  that’s  good,  because  this will  illustrate  an  im­
portant  point:  given  the  right  preserved  invariant,  you  can  verify  programs  you  don’t 
understand. 
In  particular,  given  nonnegative  integers  x  and  y ,  with  y >  0,  we  claim  the 
following procedure3  halts with registers S and T containing integers s and t satis­
fying (9.2). 
Inputs:  a, b ∈ N, b > 0. 
Registers: X,Y,S,T,U,V,Q. 
Extended Euclidean Algorithm: 

X  :=  a;  Y  :=  b;  S  :=  0;  T  :=  1;  U  :=  1;  V  :=  0; 
loop: 

3 This procedure is adapted from Aho, Hopcroft, and Ullman’s text on algorithms. 

9.1.  STATE MACHINES 

143 

if  Y  divides  X,  then  halt 
else 
Q  :=  quotient(X,Y); 
;;the  following  assignments  in  braces  are  SIMULTANEOUS 
{X  :=  Y, 
Y  :=  remainder(X,Y); 
U  :=  S, 
V  :=  T, 
S  :=  U  - Q  *  S, 
T  :=  V  - Q  *  T}; 
goto  loop; 

Note that X,Y behave exactly as in the Euclidean GCD algorithm in Section 9.1.3, 
except that this extended procedure stops one step sooner, ensuring that gcd(x, y) 
is  in  Y  at  the  end.  So  for  all  inputs  x, y ,  this  procedure  terminates  for  the  same 
reason  as  the  Euclidean  algorithm:  the  contents,  y ,  of  register  Y  is  a  nonnegative 
integer-valued variable that strictly decreases each time around the loop. 
The  following  properties  are  preserved  invariants  that  imply  partial  correct­
ness: 

gcd(X, Y )  =  gcd(a, b), 
S a + T b  =  Y ,  and 
U a + V b  =  X. 

(9.3) 
(9.4) 
(9.5) 

To  verify  that  these  are  preserved  invariants,  note  that  (9.3)  is  the  same  one 
we  observed  for  the  Euclidean  algorithm.  To  check  the  other  two  properties,  let 
x, y , s, t, u, v be the contents of registers X,Y,S,T,U,V at the start of the loop and 
assume  that  all  the  properties  hold  for  these  values.  We  must  prove  that  (9.4) 
and  (9.5) hold  (we already know  (9.3) does)  for  the new contents x� , y � , s� , t� , u� , v � 
of these registers at the next time the loop is started. 
Now according to the procedure, u�  = s, v �  = t, x�  = y , so (9.5) holds for u� , v � , x� 
because of (9.4) for s, t, y . Also, 
s�  = u − qs, 

t�  = v − qt,  y �  = x − qy 

where q = quotient(x, y), so 
s�a + t� b = (u − qs)a + (v − qt)b = ua + vb − q(sa + tb) = x − qy = y � , 
and therefore (9.4) holds for s� , t� , y � . 
Also,  it’s  easy  to  check  that  all  three  preserved  invariants  are  true  just  before 
the ﬁrst time around the loop. Namely, at the start: 

X  = a, Y  = b, S  = 0, T  = 1 
S a + T b = 0a + 1b = b = Y 

so 
conﬁrming (9.4). 

144	

Also, 

CHAPTER 9.  STATE MACHINES 

U  = 1, V  = 0, 
U a + V b = 1a + 0b = a = X 

so 
conﬁrming (9.5). 

Now  by  the  Invariant  Principle,  they  are  true  at  termination.  But  at  termination, 
the  contents,  Y ,  of  register  Y  divides  the  contents,  X ,  of  register  X,  so  preserved 
invariants (9.3) and (9.4) imply 

gcd(a, b) = gcd(X, Y ) = Y  = S a + T b. 

So we have the gcd in register Y and the desired coefﬁcients in S, T. 
Now we don’t claim that this veriﬁcation offers much insight.  In fact, if you’re 
not wondering how somebody came up with this concise program and invariant, 
you: 

•	 are blessed with an  inspired  intellect allowing you  to see how  this program 
and its invariant were devised, 

•	 have lost interest in the topic, or 

•	 haven’t read this far. 

If none of the above apply to you, we can offer some reassurance by repeating that 
you’re not expected to understand this program. 
We’ve  already  observed  that  a  preserved  invariant  is  really  just  an  induction 
hypothesis.  As  with  induction,  ﬁnding  the  right  hypothesis  is  usually  the  hard 
part. We repeat: 

Given the right preserved invariant, it can be easy to verify a program 
even if you don’t understand it. 

We expect that the Extended Euclidean Algorithm presented above illustrates this 
point. 

9.1.4  Derived Variables 
The preceding  termination proofs  involved ﬁnding a nonnegative  integer-valued 
measure  to  assign  to  states.  We  might  call  this  measure  the  “size”  of  the  state. 
We  then  showed  that  the  size of  a  state decreased with  every  state  transition.  By 
the Well Ordering  Principle,  the  size  can’t  decrease  indeﬁnitely,  so when  a mini­
mum size state  is reached,  there can’t be any  transitions possible:  the process has 
terminated. 
More  generally,  the  technique  of  assigning  values  to  states  —not  necessarily 
nonnegative  integers  and  not  necessarily  decreasing  under  transitions—  is  often 
useful in the analysis of algorithms. Potential functions play a similar role in physics. 
In  the  context  of  computational  processes,  such  value  assignments  for  states  are 
called derived variables. 

9.1.  STATE MACHINES 

145 

For  example,  for  the Die Hard machines we  could have  introduced  a derived 
→
R,  for  the  amount  of  water  in  both  buckets,  by  setting 
variable,  f  :  states 
f ((a, b)) ::= a + b. Similarly, in the robot problem, the position of the robot along the 
x-axis would be given by the derived variable x-coord, where x-coord((i, j )) ::=  i. 
We can formulate our general termination method as follows: 
Deﬁnition  9.1.8.  Let  �  be  a  strict  partial  order  on  a  set,  A.  A  derived  variable 
→ 
f  : states 
A is strictly decreasing iff 
q −→ q �  implies f (q � ) � f (q). 

We conﬁrmed termination of the GCD and Extended GCD procedures by ﬁnd­
ing derived variables, y and Y, respectively, that were nonnegative integer-valued 
and  strictly decreasing.  We  can  summarize  this approach  to proving  termination 
as follows: 
Theorem 9.1.9.  If f  is a strictly decreasing N-valued derived variable of a state machine, 
then the length of any execution starting at state q  is at most f (q). 

Of course we could prove Theorem 9.1.9 by induction on the value of f (q), but 
think about what it says:  “If you start counting down at some nonnegative integer 
f (q), then you can’t count down more than f (q) times.” Put this way, it’s obvious. 

Weakly Decreasing Variables 

In  addition  being  strictly  decreasing,  it  will  be  useful  to  have  derived  variables 
with some other, related properties. 
Deﬁnition  9.1.10.  Let �  be  a weak  partial  order  on  a  set,  A.  A  derived  variable 
→ 
f  : Q A is weakly decreasing iff 
q −→ q �  implies f (q � ) � f (q). 
Strictly increasing and weakly increasing derived variables are deﬁned similarly.4 

9.1.5  Problems 
Homework Problems 

Problem 9.1. 
You are given  two buckets, A and B , a water hose, a receptacle, and a drain.  The 
buckets  and  receptacle  are  initially  empty.  The  buckets  are  labeled with  their  re­
spectively capacities, positive integers a and b.  The receptacle can be used to store 
an  unlimited  amount  of water,  but  has  no measurement markings.  Excess water 
can be dumped into the drain. Among the possible moves are: 

4Weakly  increasing variables are often also  called nondecreasing.  We will avoid  this  terminology  to 
prevent  confusion between nondecreasing variables and variables with  the much weaker property of 
not being a decreasing variable. 

146 

CHAPTER 9.  STATE MACHINES 

1.  ﬁll a bucket from the hose, 

2.  pour from the receptacle to a bucket until the bucket is full or the receptacle 
is empty, whichever happens ﬁrst, 

3.  empty a bucket to the drain, 

4.  empty a bucket to the receptacle, 

5.  pour  from  A  to  B  until  either  A  is  empty  or  B  is  full,  whichever  happens 
ﬁrst, 

6.  pour  from  B  to  A  until  either  B  is  empty  or  A  is  full,  whichever  happens 
ﬁrst. 

(a)  Model  this  scenario with a  state machine.  (What are  the  states?  How does a 
state change in response to a move?) 
(b)  Prove  that  we  can  put  k  ∈  N  gallons  of  water  into  the  receptacle  using  the 
above  operations  if  and  only  if  gcd(a, b)  |  k .  Hint:  Use  the  fact  that  if  a, b  are 
positive  integers  then  there  exist  integers  s, t  such  that  gcd(a, b) =  sa +  tb  (see 
Notes 9.1.3). 

Problem 9.2. 
Here is a very, very fun game.  We start with two distinct, positive integers written 
on a blackboard.  Call them a and b.  You and I now take turns.  (I’ll let you decide 
who goes ﬁrst.) On each player ’s turn, he or she must write a new positive integer 
on the board that is the difference of two numbers that are already there.  If a player 
can not play, then he or she loses. 
For example,  suppose  that 12 and 15 are on  the board  initially.  Your ﬁrst play 
must be 3, which is 15 − 12.  Then I might play 9, which is 12 − 3.  Then you might 
play 6, which is 15 − 9. Then I can not play, so I lose. 
(a)  Show that every number on the board at the end of the game is a multiple of 
gcd(a, b). 

(b)  Show that every positive multiple of gcd(a, b) up to max(a, b)  is on the board 
at the end of the game. 

(c)  Describe a strategy that lets you win this game every time. 

Problem 9.3. 
In the late 1960s, the military junta that ousted the government of the small repub­
lic of Nerdia completely outlawed built-in multiplication operations, and also for­
bade division by any number other than 3.  Fortunately, a young dissident found a 
way to help the population multiply any two nonnegative integers without risking 
persecution by the junta. The procedure he taught people is: 

9.1.  STATE MACHINES 

147 

procedure multiply(x, y :  nonnegative integers)

r  := x;

s := y ;

a := 0;

while s = 0 do

if 3 | s then

r  := r + r + r ;

s := s/3;

else if 3 | (s − 1) then

a := a + r ;

r  := r + r + r ;

s := (s − 1)/3;

else 
a := a + r + r ;

r  := r + r + r ;

s := (s − 2)/3;

return a; 

We can model the algorithm as a state machine whose states are triples of non­
negative  integers (r, s, a).  The  initial state  is (x, y , 0).  The  transitions are given by 
⎧ ⎪⎨ ⎪⎩ 
the rule that for s > 0: 
(3r, s/3, a) 
(3r, (s − 1)/3, a + r) 
(3r, (s − 2)/3, a + 2r) 
(a)  List  the  sequence  of  steps  that  appears  in  the  execution  of  the  algorithm  for 
inputs x = 5 and y = 10. 

if 3 | s 
if 3 |
(s − 1) 
otherwise. 

(r, s, a) → 

(b)  Use the Invariant Method to prove that the algorithm is partially correct —that 
is, if s = 0, then a = xy . 

(c)  Prove  that  the algorithm  terminates after at most 1 + log3 y  executions of  the 
body of the do statement. 

Problem 9.4. 
A  robot named Wall-E wanders  around  a  two-dimensional  grid.  He  starts  out  at 
(0, 0) and is allowed to take four different types of step: 
1.  (+2, −1) 
2.  (+1, −2) 
3.  (+1, +1) 

�
148 

CHAPTER 9.  STATE MACHINES 

4.  (−3, 0) 
Thus,  for  example,  Wall-E  might  walk  as  follows.  The  types  of  his  steps  are 
listed above the arrows. 
(0, 0) → (2, −1) → (3, 0) → (4, −2) → (1, −2) → . . . 
2 
1 
4
3
Wall-E’s  true  love,  the  fashionable  and  high-powered  robot,  Eve,  awaits  at 
(0, 2). 
(a)  Describe a state machine model of this problem. 

(b)  Will Wall-E  ever ﬁnd his  true  love?  Either ﬁnd  a path  from Wall-E  to Eve or 
use the Invariant Principle to prove that no such path exists. 

Problem 9.5. 
A  hungry  ant  is  placed  on  an  unbounded  grid.  Each  square  of  the  grid  either 
contains a crumb or is empty. The squares containing crumbs form a path in which, 
except at the ends, every crumb is adjacent to exactly two other crumbs. The ant is 
placed at one end of the path and on a square containing a crumb. For example, the 
ﬁgure below shows a situation in which the ant faces North, and there is a trail of 
food leading approximately Southeast.  The ant has already eaten the crumb upon 
which it was initially placed. 

The ant can only smell food directly  in  front of  it.  The ant can only remember 
a small number of things, and what it remembers after any move only depends on 
what  it  remembered  and  smelled  immediately  before  the move.  Based  on  smell 
and memory, the ant may choose to move forward one square, or it may turn right 
or left.  It eats a crumb when it lands on it. 
The  above  scenario  can  be  nicely  modelled  as  a  state  machine  in  which  each 
state is a pair consisting of the “ant’s memory” and “everything else” —for exam­
ple, information about where things are on the grid. Work out the details of such a 

9.1.  STATE MACHINES 

149 

model state machine; design  the ant-memory part of  the state machine so  the ant 
will  eat  all  the  crumbs  on  any  ﬁnite  path  at which  it  starts  and  then  signal when 
it  is  done.  Be  sure  to  clearly  describe  the  possible  states,  transitions,  and  inputs 
and  outputs  (if  any)  in  your model.  Brieﬂy  explain why  your  ant will  eat  all  the 
crumbs. 
Note that the last transition is a self-loop; the ant signals done for eternity. One 
could also add another end state so that the ant signals done only once. 

Problem 9.6. 
Suppose  that  you  have  a  regular  deck  of  cards  arranged  as  follows,  from  top  to 
bottom: 

A♥ 2♥ . . . K♥ A♠ 2♠ . . . K♠ A♣ 2♣ . . . K♣ A♦ 2♦ . . . K♦ 
Only  two  operations  on  the  deck  are  allowed:  inshufﬂing  and  outshufﬂing.  In 
both,  you  begin  by  cutting  the  deck  exactly  in  half,  taking  the  top  half  into  your 
right hand and the bottom into your left. Then you shufﬂe the two halves together 
so  that  the cards are perfectly  interlaced;  that  is,  the shufﬂed deck consists of one 
card from the left, one from the right, one from the left, one from the right, etc. The 
top card in the shufﬂed deck comes from the right hand in an outshufﬂe and from 
the left hand in an inshufﬂe. 
(a)  Model this problem as a state machine. 

(b)  Use the Invariant Principle to prove that you can not make the entire ﬁrst half 
of the deck black through a sequence of inshufﬂes and outshufﬂes. 
Note:  Discovering a suitable invariant can be difﬁcult!  The standard approach 
is to identify a bunch of reachable states and then look for a pattern, some feature 
that they all share.5 

Problem 9.7. 
The following procedure can be applied to any digraph, G: 

1.  Delete an edge that is traversed by a directed cycle. 
→
v  if  there  is  a  directed  path  from  vertex  u  to  vertex  v  that
2.  Delete  edge  u
v .→ 
does not traverse u
→ 
v if there is no directed path in either direction between vertex 
3.  Add edge u
u and vertex v . 

Repeat these operations until none of them are applicable. 
This procedure can be modeled as a state machine. The start state is G, and the 
states are all possible digraphs with the same vertices as G. 

5 If this does not work, consider twitching and drooling until someone takes the problem away. 

150 

CHAPTER 9.  STATE MACHINES 

(a)  Let G be the graph with vertices {1, 2, 3, 4} and edges 
4}
{1
→ → → → → 
2, 2
2, 1
4, 3
3, 3
What are the possible ﬁnal states reachable from G? 
A  line  graph  is  a  graph whose  edges  can  all  be  traversed  by  a  directed  simple 
path. All the ﬁnal graphs in part (a) are line graphs. 
(b)  Prove  that  if  the  procedure  terminates  with  a  digraph,  H ,  then  H  is  a  line

graph with the same vertices as G.

Hint:  Show that if H  is not a line graph, then some operation must be applicable.


(c)  Prove that being a DAG is a preserved invariant of the procedure.


(d)  Prove that if G is a DAG and the procedure terminates, then the path relation

of the ﬁnal line graph is a topological sort of G.

Hint: Verify that the predicate


P (u, v) ::= there is a directed path from u to v 

is a preserved invariant of the procedure, for any two vertices u, v of a DAG. 

(e)  Prove that if G is ﬁnite, then the procedure terminates. 
Hint:  Let s be the number of simple cycles, e be the number of edges, and p be the 
number of pairs of vertices with a directed path (in either direction) between them. 
Note  that  p  ≤  n2  where  n  is  the  number  of  vertices  of G.  Find  coefﬁcients  a, b, c 
such that as + bp + e + c is a strictly decreasing, N-valued variable. 

Class Problems 

Problem 9.8. 
In this problem you will establish a basic property of a puzzle toy called the Fifteen 
Puzzle using the method of invariants. The Fifteen Puzzle consists of sliding square 
tiles  numbered  1, . . . , 15  held  in  a  4 × 4  frame  with  one  empty  square.  Any  tile 
adjacent to the empty square can slide into it. 
The standard initial position is 

4 
3 
2 
1 
6 
8 
7 
5 
9 
10  11  12 
13  14  15 

We would like to reach the target position (known in my youth as “the impossible” 
— ARM): 

15  14  13  12 
11  10 
9 
8 
5 
6 
7 
4 
3 
2 
1 

9.1.  STATE MACHINES 

151 

A state machine model of the puzzle has states consisting of a 4 × 4 matrix with 
16  entries  consisting  of  the  integers  1, . . . , 15  as  well  as  one  “empty”  entry—like 
each of the two arrays above. 
The state  transitions correspond  to exchanging  the empty square and an adja­
cent numbered tile. For example, an empty at position (2, 2) can exchange position 
with tile above it, namely, at position (1, 2): 

n2 

n4 
n3 
n1 
n6 
n7 
n5 
n9  n10  n11 
n8 
n12  n13  n14  n15 

−→ 

n4 
n3 
n1 
n2 
n7 
n6 
n5 
n9  n10  n11 
n8 
n12  n13  n14  n15 

We  will  use  the  invariant  method  to  prove  that  there  is  no  way  to  reach  the 
target state starting from the initial state. 
We begin by noting  that a  state can also be  represented as a pair  consisting of 
two things: 

1.	 a  list  of  the  numbers  1, . . . , 15  in  the  order  in  which  they  appear—reading 
rows left-to-right from the top row down, ignoring the empty square, and 

2.  the coordinates of  the empty square—where  the upper  left square has coor­
dinates (1, 1), the lower right (4, 4). 

(a)	 Write out the “list” representation of the start state and the “impossible” state. 
Let L be a  list of  the numbers 1, . . . , 15  in  some order.  A pair of  integers  is an 
out-of-order pair in L when the ﬁrst element of the pair both comes earlier in the list 
and  is  larger,  than  the  second  element of  the pair.  For  example,  the  list  1, 2, 4, 5, 3 
has two out-of-order pairs:  (4,3) and (5,3).  The increasing list 1, 2 . . . n has no out-
of-order pairs. 
Let a state, S , be a pair (L, (i, j )) described above. We deﬁne the parity of S to be 
the mod 2 sum of the number, p(L), of out-of-order pairs in L and the row-number 
of the empty square, that is the parity of S  is p(L) + i  (mod  2). 
(b)  Verify that the parity of the start state and the target state are different. 

(c)  Show  that  the parity of a  state  is preserved under  transitions.  Conclude  that 
“the impossible” is impossible to reach. 
By the way, if two states have the same parity, then in fact there is a way to get 
from  one  to  the  other.  If  you  like  puzzles,  you’ll  enjoy working  this  out  on  your 
own. 

Problem 9.9. 
The  most  straightforward  way  to  compute  the  bth  power  of  a  number,  a,  is  to 
multiply a by itself b times.  This of course requires b − 1 multiplications.  There is 
another way  to  do  it  using  considerably  fewer multiplications.  This  algorithm  is 
called fast exponentiation: 

152 

CHAPTER 9.  STATE MACHINES 

Given  inputs  a  ∈  R, b  ∈  N,  initialize  registers x, y , z  to a, 1, b  respectively,  and 
repeat the following sequence of steps until termination: 
•  if z = 0 return y and terminate 
•  r  := remainder(z , 2) 
•  z  := quotient(z , 2) 
•  if r = 1, then y  := xy 
•  x := x2 
We claim this algorithm always terminates and leaves y = ab . 
(a)  Model  this  algorithm with  a  state machine,  carefully  deﬁning  the  states  and 
transitions. 

(b)  Verify that the predicate P ((x, y , z )) ::=  [yx = ab ] is a preserved invariant. 
z

(c)  Prove that the algorithm is partially correct:  if it halts, it does so with y = ab . 

(d)  Prove that the algorithm terminates. 
(e)  In fact, prove that it requires at most 2 �log2 (b + 1)� multiplications for the Fast 
Exponentiation algorithm to compute ab  for b > 1. 

Problem 9.10. 
A  robot moves  on  the  two-dimensional  integer  grid.  It  starts  out  at  (0, 0),  and  is 
allowed to move in any of these four ways: 

1.  (+2,-1) Right 2, down 1 

2.  (-2,+1) Left 2, up 1 

3.  (+1,+3) 

4.  (-1,-3) 

Prove that this robot can never reach (1,1). 

Problem 9.11. 
The Massachusetts Turnpike Authority is concerned about the integrity of the new 
Zakim bridge.  Their consulting architect has warned that the bridge may collapse 
if  more  than  1000  cars  are  on  it  at  the  same  time.  The  Authority  has  also  been 
warned  by  their  trafﬁc  consultants  that  the  rate  of  accidents  from  cars  speeding 
across bridges has been increasing. 
Both to lighten trafﬁc and to discourage speeding, the Authority has decided to 
make the bridge one-way and to put tolls at both ends of the bridge (don’t laugh, this 
is Massachusetts).  So  cars will  pay  tolls  both  on  entering  and  exiting  the  bridge, 

9.1.  STATE MACHINES 

153 

but  the  tolls  will  be  different.  In  particular,  a  car  will  pay  $3  to  enter  onto  the 
bridge and will pay $2 to exit. To be sure that there are never too many cars on the 
bridge,  the Authority will  let a  car onto  the bridge only  if  the difference between 
the amount of money currently at the entry toll booth minus the amount at the exit 
toll booth is strictly less than a certain threshold amount of $T0 . 
The consultants have decided to model this scenario with a state machine whose 
states are triples of natural numbers, (A, B , C ), where 
•  A is an amount of money at the entry booth, 

•  B  is an amount of money at the exit booth, and 

•  C  is a number of cars on the bridge. 
Any  state  with  C >  1000  is  called  a  collapsed  state,  which  the  Authority  dearly 
hopes to avoid. There will be no transition out of a collapsed state. 
Since the toll booth collectors may need to start off with some amount of money 
in  order  to  make  change,  and  there  may  also  be  some  number  of  “ofﬁcial”  cars 
already  on  the  bridge  when  it  is  opened  to  the  public,  the  consultants  must  be 
ready to analyze the system started at any uncollapsed state. So let A0  be the initial 
number of dollars at the entrance toll booth, B0  the initial number of dollars at the 
exit toll booth, and C0  ≤  1000 the number of ofﬁcial cars on the bridge when  it  is 
opened.  You should assume that even ofﬁcial cars pay tolls on exiting or entering 
the bridge after the bridge is opened. 
(a)  Give a mathematical model of  the Authority’s  system  for  letting cars on and 
off the bridge by specifying a transition relation between states of the form (A, B , C ) 
above. 

(b)  Characterize each of the following derived variables 
A, B , A + B , A − B , 3C − A, 2A − 3B , B + 3C, 2A − 3B − 6C, 2A − 2B − 3C 
as one of the following 
C 
constant 
SI 
strictly increasing 
strictly decreasing 
SD 
weakly increasing but not constant  WI 
weakly decreasing but not constant  WD 
N 
none of the above 
and brieﬂy explain your reasoning. 
The Authority  has  asked  their  engineering  consultants  to determine  T  and  to 
verify that this policy will keep the number of cars from exceeding 1000. 
The  consultants  reason  that  if  C0  is  the  number  of  ofﬁcial  cars  on  the  bridge 
when it is opened, then an additional 1000 − C0  cars can be allowed on the bridge. 
So as long as A − B  has not increased by 3(1000 − C0 ), there shouldn’t more than 
1000 cars on the bridge.  So they recommend deﬁning 
T0  ::= 3(1000 − C0 ) + (A0  − B0 ), 

(9.6) 

154 

CHAPTER 9.  STATE MACHINES 

where A0  is the initial number of dollars at the entrance toll booth, B0  is the initial 
number of dollars at the exit toll booth. 
(c)  Use  the  results  of  part  (b)  to  deﬁne  a  simple  predicate,  P ,  on  states  of  the 
transition  system which  is  satisﬁed  by  the  start  state,  that  is P (A0 , B0 , C0 )  holds, 
is not  satisﬁed by any collapsed state,  and  is a preserved  invariant of  the  system. 
Explain why your P  has these properties. 

(d)  A clever MIT intern working for the Turnpike Authority agrees that the Turn­
pike’s bridge management policy will be safe:  the bridge will not collapse. But she 
warns her boss that the policy will lead to deadlock— a situation where trafﬁc can’t 
move on the bridge even though the bridge has not collapsed. 
Explain more precisely  in terms of system transitions what the  intern means, and 
brieﬂy, but clearly, justify her claim. 

Problem 9.12. 
Start with  102  coins  on  a  table,  98  showing  heads  and  4  showing  tails.  There  are 
two ways to change the coins: 

(i)  ﬂip over any ten coins, or 
(ii)  let n be the number of heads showing. Place n + 1 additional coins, all show­
ing tails, on the table. 

For example, you might begin by ﬂipping nine heads and one tail, yielding 90 
heads and 12 tails, then add 91 tails, yielding 90 heads and 103 tails. 
(a)  Model this situation as a state machine, carefully deﬁning the set of states, the 
start state, and the possible state transitions. 

(b)  Explain how to reach a state with exactly one tail showing. 

(c)  Deﬁne the following derived variables: 

C 
T 
H2 

::= 
the number of coins on the table,  H 
::= 
the number of tails, 
C2 
::=  remainder(H/2), 
T2 

::= 
the number of heads, 
::=  remainder(C/2), 
::=  remainder(T /2). 

Which of these variables is 

1.  strictly increasing 
2.  weakly increasing 
3.  strictly decreasing 
4.  weakly decreasing 
5.  constant 

(d)  Prove that it is not possible to reach a state in which there is exactly one head 
showing. 

9.1.  STATE MACHINES 

155 

Problem 9.13. 
In  some  terms when  6.042  is not  taught  in  a TEAL  room,  students  sit  in  a  square 
arrangement during recitations.  An outbreak of beaver ﬂu sometimes  infects stu­
dents  in  recitation;  beaver  ﬂu  is  a  rare  variant  of  bird  ﬂu  that  lasts  forever,  with 
symptoms including a yearning for more quizzes and the thrill of late night prob­
lem set sessions. 
Here  is  an  example of  a  6 × 6  recitation  arrangement with  the  locations of  in­
fected students marked with an asterisk. 
∗ 

∗ 

∗ 

∗  ∗ 
∗ 

∗ 
∗ 
Outbreaks of infection spread rapidly step by step. A student is infected after a 
step if either 

•	 the student was infected at the previous step (since beaver ﬂu lasts forever), 
or 

•	 the  student was adjacent  to at  least  two already-infected  students at  the pre­
vious step. 

Here  adjacent means  the  students’  individual  squares  share  an  edge  (front,  back, 
left or right, but not diagonal). Thus, each student is adjacent to 2, 3 or 4 others. 
In the example, the infection spreads as shown below. 
∗  ∗  ∗ 
∗  ∗ 
∗ 
∗ 
∗ 
∗  ∗  ∗ 
∗  ∗  ∗  ∗ 
∗  ∗  ∗ 
∗  ∗  ∗  ∗ 
∗ 
∗  ∗  ∗ 
∗  ∗  ∗ 
∗  ∗ 
∗  ∗  ∗  ∗ 
∗  ∗  ∗  ∗ 

∗  ∗ 
∗ 

⇒ 

⇒ 

∗ 

∗ 

∗ 

∗ 

In  this  example,  over  the  next  few  time-steps,  all  the  students  in  class  become 
infected. 
Theorem.  If  fewer  than  n  students  among  those  in  an  n × n  arrangment  are  initially 
infected in a ﬂu outbreak, then there will be at least one student who never gets infected in 
this outbreak, even if students attend all the lectures. 

Prove this theorem. 
Hint: Think of the state of an outbreak as an n × n square above, with asterisks 
indicating infection. The rules for the spread of infection then deﬁne the transitions 
of a state machine.  Try to derive a weakly decreasing state variable that leads to a 
proof of this theorem. 

156 

CHAPTER 9.  STATE MACHINES 

9.2  The Stable Marriage Problem 

Okay,  frequent  public  reference  to  derived  variables  may  not  help  your  mating 
prospects. But they can help with the analysis! 

9.2.1  The Problem 
Suppose  there  are  a  bunch  of  boys  and  an  equal  number  of  girls  that  we  want 
to marry  off.  Each  boy  has  his  personal  preferences  about  the  girls —in  fact,  we 
assume he has a  complete  list of all  the girls  ranked according  to his preferences, 
with no ties. Likewise, each girl has a ranked list of all of the boys. 
The preferences don’t have  to be  symmetric.  That  is,  Jennifer might  like Brad 
best, but Brad doesn’t necessarily  like  Jennifer best.  The goal  is  to marry off boys 
and  girls:  every  boy  must  marry  exactly  one  girl  and  vice-versa—no  polygamy. 
In  mathematical  terms,  we  want  the  mapping  from  boys  to  their  wives  to  be  a 
bijection or perfect matching. We’ll just call this a “matching,” for short. 
Here’s the difﬁculty:  suppose every boy likes Angelina best, and every girl likes 
Brad  best,  but  Brad  and  Angelina  are  married  to  other  people,  say  Jennifer  and 
Billy Bob.  Now Brad and Angelina prefer each other to their spouses, which puts their 
marriages  at  risk:  pretty  soon,  they’re  likely  to  start  spending  late  nights  doing 
6.042 homework together. 
This situation  is  illustrated  in  the  following diagram where  the digits “1” and 
“2” near a boy shows which of the two girls he ranks ﬁrst and which second, and 
similarly for the girls: 

More  generally,  in  any matching,  a  boy  and  girl who  are  not married  to  each 
other and who like each other better than their spouses, is called a rogue couple.  In 
the situation above, Brad and Angelina would be a rogue couple. 
Having a rogue couple is not a good thing, since it threatens the stability of the 
marriages.  On the other hand, if there are no rogue couples, then for any boy and 
girl who  are  not married  to  each  other,  at  least  one  likes  their  spouse  better  than 
the other, and so won’t be tempted to start an affair. 

Deﬁnition 9.2.1.  A stable matching is a matching with no rogue couples. 

The  question  is,  given  everybody’s  preferences,  how  do  you  ﬁnd  a  stable  set 
of marriages?  In the example consisting solely of the four people above, we could 

AngelinaJenniferBillyBobBrad212121219.2.  THE STABLE MARRIAGE PROBLEM 

157 

let Brad and Angelina both have  their ﬁrst  choices by marrying  each other.  Now 
neither Brad nor Angelina prefers anybody else to their spouse, so neither will be 
in a rogue couple.  This leaves Jen not-so-happily married to Billy Bob, but neither 
Jen nor Billy Bob can entice somebody else to marry them. 
It  is  something  of  a  surprise  that  there  always  is  a  stable  matching  among  a 
group of boys and girls, but  there  is,  and we’ll shortly explain why.  The surprise 
springs  in part  from  considering  the  apparently  similar  “buddy” matching prob­
lem.  That  is,  if  people  can  be  paired  off  as  buddies,  regardless  of  gender,  then 
a  stable matching may not be possible.  For  example,  Figure  9.2  shows  a  situation 
with a love triangle and a fourth person who is everyone’s last choice.  In this ﬁgure 
Mergatoid’s preferences aren’t shown because they don’t even matter. 

Figure 9.2:  Some preferences with no stable buddy matching. 

Let’s see why there is no stable matching: 

Lemma.  There is no stable buddy matching among the four people in Figure 9.2. 

Proof.  We’ll prove this by contradiction. 
Assume, for the purposes of contradiction, that there is a stable matching. Then 
there are two members of the  love triangle that are matched.  Since preferences in 
the triangle are symmetric, we may assume in particular, that Robin and Alex are 
matched. Then the other pair must be Bobby-Joe matched with Mergatoid. 
But  then  there  is  a  rogue  couple:  Alex  likes  Bobby-Joe  best,  and  Bobby-Joe 
prefers  Alex  to  his  buddy  Mergatoid.  That  is,  Alex  and  Bobby-Joe  are  a  rogue 
� 
couple, contradicting the assumed stability of the matching. 

So getting a stable buddy matching may not only be hard, it may be impossible. 
But when  boys  are  only  allowed  to marry  girls,  and  vice  versa,  then  it  turns  out 
that a stable matching is not hard to ﬁnd. 

BobbyJoeRobinAlex231321132Mergatoid158 

CHAPTER 9.  STATE MACHINES 

9.2.2  The Mating Ritual 
The  procedure  for  ﬁnding  a  stable  matching  involves  a  Mating  Ritual  that  takes 
place over several days. The following events happen each day: 
Morning:  Each girl stands on her balcony. Each boy stands under the balcony 
of  his  favorite  among  the  girls  on  his  list,  and  he  serenades  her.  If  a  boy  has  no 
girls left on his list, he stays home and does his 6.042 homework. 
Afternoon:  Each girl who has one or more suitors serenading her, says to her 
favorite among them, “We might get engaged. Come back tomorrow.” To the other 
suitors, she says, “No.  I will never marry you! Take a hike!” 
Evening:  Any boy who  is  told by a girl  to  take a hike,  crosses  that girl off his 
list. 
Termination condition: When every girl has at most one suitor, the ritual ends 
with each girl marrying her suitor, if she has one. 
There  are  a  number  of  facts  about  this  Mating  Ritual  that  we  would  like  to 
prove: 

•  The Ritual has a last day. 

•  Everybody ends up married. 

•  The resulting marriages are stable. 

9.2.3  A State Machine Model 
Before we  can  prove  anything, we  should  have  clear mathematical  deﬁnitions  of 
what we’re talking about.  In this section we sketch how to deﬁne a rigorous state 
machine model of the Marriage Problem. 
So let’s begin by formally deﬁning the problem. 

Deﬁnition 9.2.2.  A Marriage Problem consists of two disjoint sets of the same ﬁnite 
size,  called  the-Boys and  the-Girls.  The members of  the-Boys are called boys,  and 
members of  the-Girls are  called girls.  For each boy, B ,  there  is a  strict  total order, 
<B , on the-Girls, and for each girl, G, there is a strict total order, <G , on the-Boys. 
If G1  <B  G2  we  say B  prefers girl G2  to girl G1 .  Similarly,  if B1  <G  B2  we  say G 
prefers boy B2  to boy B1 . 
→
A marriage assignment or perfect matching is a bijection, w  : the-Boys 
the-Girls. 
If B  ∈ the-Boys, then w(B ) is called B ’s wife in the assignment, and if G
∈ the-Girls, 
then w−1 (G)  is  called G’s  husband. A  rogue  couple  is  a  boy,  B ,  and  a  girl, G,  such 
that B  prefers G  to  his wife,  and G  prefers B  to  her  husband.  An  assignment  is 
stable if it has no rogue couples. A solution to a marriage problem is a stable perfect 
matching. 

To model the Mating Ritual with a state machine, we make a key observation: 
to determine what happens on any day of the Ritual, all we need to know is which 
girls are still on which boys’ lists on the morning of that day.  So we deﬁne a state 
to be some mathematical data structure providing this  information.  For example, 

9.2.  THE STABLE MARRIAGE PROBLEM 

159 

we  could  deﬁne  a  state  to  be  the  “still-has-on-his-list”  relation,  R,  between  boys 
and girls, where B R G means girl G is still on boy B ’s list. 
We start the Mating Ritual with no girls crossed off. That is, the start state is the 
complete bipartite relation in which every boy is related to every girl. 
According to the Mating Ritual, on any given morning, a boy will serenade the 
girl  he most  prefers  among  those  he  has  not  as  yet  crossed  out.  Mathematically, 
the girl he is serenading is  just the maximum among the girls on B ’s list, ordered 
by <B .  (If  the  list  is  empty,  he’s  not  serenading  anybody.)  A  girl’s  favorite  is  just 
the maximum, under her preference ordering, among the boys serenading her. 
Continuing in this way, we could mathematically specify a precise Mating Rit­
ual state machine, but we won’t bother.  The intended behavior of the Mating Rit­
ual  is clear enough  that we don’t gain much by giving a  formal state machine,  so 
we  stick  to  a more memorable  description  in  terms  of  boys,  girls,  and  their  pref­
erences.  The  point  is,  though,  that  it’s  not  hard  to  deﬁne  everything  using  basic 
mathematical data structures like sets, functions, and relations, if need be. 

9.2.4  There is a Marriage Day 
It’s easy to see why  the Mating Ritual has a terminal day when people ﬁnally get 
married.  Every day on which the ritual hasn’t terminated, at least one boy crosses 
a girl off his list.  (If the ritual hasn’t terminated, there must be some girl serenaded 
by  at  least  two  boys,  and  at  least  one  of  them  will  have  to  cross  her  off  his  list). 
So  starting  with  n  boys  and  n  girls,  each  of  the  n  boys’  lists  initially  has  n  girls 
on  it,  for  a  total  of n2  list  entries.  Since  no  girl  ever  gets  added  to  a  list,  the  total 
number of entries on the lists decreases every day that the Ritual continues, and so 
the Ritual can continue for at most n2  days. 

9.2.5  They All Live Happily Every After... 
We still have to prove that the Mating Ritual leaves everyone in a stable marriage. 
To  do  this,  we  note  one  very  useful  fact  about  the  Ritual:  if  a  girl  has  a  favorite 
boy  suitor  on  some  morning  of  the  Ritual,  then  that  favorite  suitor  will  still  be 
serenading her the next morning —because his list won’t have changed.  So she is 
sure to have today’s favorite boy among her suitors tomorrow. That means she will 
be able  to choose a  favorite  suitor  tomorrow who  is at  least as desirable  to her as 
today’s favorite.  So day by day, her favorite suitor can stay the same or get better, 
never worse.  In others words, a girl’s favorite is a weakly increasing variable with 
respect to her preference order on the boys. 
Now  we  can  verify  the  Mating  Ritual  using  a  simple  invariant  predicate,  P , 
that captures what’s going on: 

For every girl, G, and every boy, B ,  if G is crossed off B ’s list, then 
G has a suitor whom she prefers over B . 

Why is P  invariant?  Well, we know that G’s favorite tomorrow will be at least 

160 

CHAPTER 9.  STATE MACHINES 

as desirable to her as her favorite today, and since her favorite today is more desir­
able than B , tomorrow’s favorite will be too. 
Notice that P  also holds on the ﬁrst day, since every girl is on every list.  So by 
the Invariant Theorem, we know that P  holds on every day that the Mating Ritual 
runs.  Knowing  the  invariant holds when  the Mating Ritual  terminates will  let us 
complete the proofs. 
Theorem 9.2.3.  Everyone is married by the Mating Ritual. 
Proof.  Suppose,  for  the  sake  of  contradiction,  that  it  is  the  last  day  of  the Mating 
Ritual and some boy does not get married.  Then he can’t be serenading anybody, 
and  so  his  list  must  be  empty.  So  by  invariant  P ,  every  girl  has  a  favorite  boy 
whom  she  prefers  to  that  boy.  In  particular,  every  girl  has  a  favorite  boy  whom 
she marries  on  the  last day.  So  all  the  girls  are married.  What’s more  there  is no 
bigamy:  a boy only serenades one girl, so no two girls have the same favorite. 
But there are the same number of girls as boys, so all the boys must be married 
� 
too. 

Theorem 9.2.4.  The Mating Ritual produces a stable matching. 
Proof.  Let Brad be some boy and Jen be any girl that he is not married to on the last 
day of the Mating Ritual. We claim that Brad and Jen are not a rogue couple.  Since 
Brad is an arbitrary boy, it follows that no boy is part of a rogue couple. Hence the 
marriages on the last day are stable. 
To prove the claim, we consider two cases: 
Case 1.  Jen is not on Brad’s list.  Then by invariant P , we know that Jen prefers 
her husband  to Brad.  So  she’s not  going  to  run  off with Brad:  the  claim holds  in 
this case. 
Case 2.  Otherwise, Jen is on Brad’s list.  But since Brad is not married to Jen, he 
must  be  choosing  to  serenade  his wife  instead  of  Jen,  so  he must  prefer  his wife. 
� 
So he’s not going to run off with Jen:  the claim also holds in this case. 

...Especially the Boys 
9.2.6 
Who is favored by the Mating Ritual, the boys or the girls?  The girls seem to have 
all the power:  they stand on their balconies choosing the ﬁnest among their suitors 
and  spurning  the  rest.  What’s  more,  we  know  their  suitors  can  only  change  for 
the  better  as  the  Ritual  progresses.  Similarly,  a  boy  keeps  serenading  the  girl  he 
most prefers among those on his list until he must cross her off, at which point he 
serenades the next most preferred girl on his list.  So from the boy’s point of view, 
the  girl he  is  serenading  can  only  change  for  the worse.  Sounds  like  a  good deal 
for the girls. 
But  it’s not!  The  fact  is  that  from  the beginning,  the boys are  serenading  their 
ﬁrst  choice  girl,  and  the  desirability  of  the  girl  being  serenaded  decreases  only 
enough to give the boy his most desirable possible spouse.  The mating algorithm 
actually  does  as well  as  possible  for  all  the  boys  and  does  the worst  possible  job 
for the girls. 

9.2.  THE STABLE MARRIAGE PROBLEM 

161 

To  explain  all  this  we  need  some  deﬁnitions.  Let’s  begin  by  observing  that 
while the mating algorithm produces one stable matching, there may be other sta­
ble matchings  among  the  same  set  of  boys  and  girls.  For  example,  reversing  the 
roles of boys and girls will often yield a different stable matching among them. 
But some spouses might be out of the question in all possible stable matchings. 
For  example,  Brad  is  just  not  in  the  realm  of  possibility  for  Jennifer,  since  if  you 
ever pair them, Brad and Angelina will form a rogue couple; here’s a picture: 

Deﬁnition 9.2.5.  Given any marriage problem,  one person  is  in another person’s 
realm  of  possible  spouses  if  there  is  a  stable  matching  in  which  the  two  people  are 
married. A person’s optimal spouse is their most preferred person within their realm 
of  possibility.  A  person’s  pessimal  spouse  is  their  least  preferred  person  in  their 
realm of possibility. 
Everybody  has  an  optimal  and  a  pessimal  spouse,  since  we  know  there  is  at 
least  one  stable matching,  namely  the  one  produced  by  the Mating  Ritual.  Now 
here is the shocking truth about the Mating Ritual: 
Theorem 9.2.6.  The Mating Ritual marries every boy to his optimal spouse. 
Proof.  Assume  for  the  purpose  of  contradiction  that  some  boy  does  not  get  his 
optimal  girl.  There  must  have  been  a  day  when  he  crossed  off  his  optimal  girl 
—otherwise he would still be serenading her or some even more desirable girl. 
By  the Well Ordering Principle,  there must be a ﬁrst day when a boy,  call him 
“Keith,” crosses off his optimal girl, Nicole. 
According to the rules of the Ritual, Keith crosses off Nicole because Nicole has 
a favorite suitor, Tom, and 
Nicole prefers Tom to Keith (*) 
(remember, this is a proof by contradiction :-) ). 
Now  since  this  is  the  ﬁrst day  an  optimal  girl  gets  crossed  off, we  know  Tom 
hasn’t crossed off his optimal girl.  So 
Tom ranks Nicole at least as high as his optimal girl.  (**) 
By  the deﬁnition of an optimal girl,  there must be some stable set of marriages  in 
which  Keith  gets  his  optimal  girl,  Nicole.  But  then  the  preferences  given  in  (*) 
and  (**)  imply  that  Nicole  and  Tom  are  a  rogue  couple  within  this  supposedly 
� 
stable set of marriages (think about it). This is a contradiction. 

AngelinaJenniferBrad2111162 

CHAPTER 9.  STATE MACHINES 

Theorem 9.2.7.  The Mating Ritual marries every girl to her pessimal spouse. 
Proof.  Say Nicole and Keith marry each other as a result of  the Mating Ritual.  By 
the previous Theorem 9.2.6, Nicole is Keith’s optimal spouse, and so in any stable 
set of marriages, 
Keith rates Nicole at least as high as his spouse.  (+) 
Now suppose for the purpose of contradiction that there is another stable set of 
marriages where Nicole does worse than Keith.  That is, Nicole is married to Tom, 
and 

Nicole prefers Keith to Tom (++) 
Then  in  this  stable  set of marriages where Nicole  is married  to Tom,  (+) and  (++) 
imply  that  Nicole  and  Keith  are  a  rogue  couple,  contradicting  stability.  We  con­
� 
clude that Nicole cannot do worse than Keith. 

9.2.7  Applications 
Not surprisingly, a stable matching procedure  is used by at  least one  large dating 
agency.  But  although  “boy-girl-marriage”  terminology  is  traditional  and  makes 
some of  the deﬁnitions  easier  to  remember  (we hope without offending  anyone), 
solutions to the Stable Marriage Problem are widely useful. 
The Mating Ritual was ﬁrst announced in a paper by D. Gale and L.S. Shapley 
in 1962, but ten years before the Gale-Shapley paper was appeared, and unknown 
by them, the Ritual was being used to assign residents to hospitals by the National 
Resident Matching Program (NRMP). The NRMP has, since  the  turn of  the  twen­
tieth  century,  assigned  each  year ’s  pool  of  medical  school  graduates  to  hospital 
residencies  (formerly  called  “internships”) with  hospitals  and  graduates  playing 
the roles of boys and girls.  (In this case there may be multiple boys married to one 
girl, but  there’s an easy way  to use  the Ritual  in  this situation  (see Problem 9.18). 
Before the Ritual was adopted, there were chronic disruptions and awkward coun­
termeasures  taken  to  preserve  assignments  of  graduates  to  residencies.  The  Rit­
ual  resolved  these  problems  so  successfully,  that  it  was  used  essentially  without 
change at least through 1989.6 
MIT Math Prof. Tom Leighton, who  regularly  teaches  6.042  and  also  founded 
the internet infrastructure company, Akamai, reports another application. Akamai 
uses a variation of the Gale-Shapley procedure to assign web trafﬁc to servers.  In 
the early days, Akamai used other combinatorial optimization algorithms that got 
to be too slow as the number of servers and trafﬁc increased.  Akamai switched to 
Gale-Shapley since it is fast and can be run in a distributed manner.  In this case, the 
web  trafﬁc  corresponds  to  the  boys  and  the web  servers  to  the  girls.  The  servers 
have preferences based on latency and packet loss; the trafﬁc has preferences based 
on the cost of bandwidth. 
6Much  more  about  the  Stable  Marriage  Problem  can  be  found  in  the  very  readable  mathematical 
monograph by Dan Gusﬁeld and Robert W. Irving, The Stable Marriage Problem:  Structure and Algo­
rithms, MIT Press, Cambridge, Massachusetts, 1989, 240 pp. 

9.2.  THE STABLE MARRIAGE PROBLEM 

163 

9.2.8  Problems 
Practice Problems 

Problem 9.14. 
Four Students want separate assignments to four VI-A Companies.  Here are their 
preference rankings: 

Student 
Albert: 
Rich: 
Megumi: 
Justin: 

Companies 
HP, Bellcore, AT&T, Draper 
AT&T, Bellcore, Draper, HP 
HP, Draper, AT&T, Bellcore 
Draper, AT&T, Bellcore, HP 

Company 
AT&T: 
Bellcore: 
HP: 
Draper: 

Students 
Justin, Albert, Megumi, Rich 
Megumi, Rich, Albert, Justin 
Justin, Megumi, Albert, Rich 
Rich, Justin, Megumi, Albert 

(a)  Use  the Mating Ritual  to  ﬁnd  two  stable  assignments  of  Students  to Compa­
nies. 

(b)  Describe a simple procedure to determine whether any given stable marriage 
problem has a unique solution, that is, only one possible stable matching. 

Problem 9.15. 
Suppose  that Harry  is  one  of  the  boys  and Alice  is  one  of  the  girls  in  the Mating 
Ritual. Which of the properties below are preserved invariants? Why? 

a.  Alice is the only girl on Harry’s list. 

b.  There is a girl who does not have any boys serenading her. 

c.  If Alice is not on Harry’s list, then Alice has a suitor that she prefers to Harry. 

d.  Alice is crossed off Harry’s list and Harry prefers Alice to anyone he is sere­
nading. 

e.  If Alice is on Harry’s list, then she prefers to Harry to any suitor she has. 

Class Problems 

Problem 9.16. 
A preserved invariant of the Mating ritual is: 

For  every girl, G,  and  every boy, B ,  if G  is  crossed off B ’s  list,  then G 
has a favorite suitor and she prefers him over B . 

164 

CHAPTER 9.  STATE MACHINES 

Use  the  invariant  to  prove  that  the  Mating  Algorithm  produces  stable  mar­
riages.  (Don’t look up the proof in the Notes or slides.) 

Problem 9.17. 
Consider  a  stable  marriage  problem  with  4  boys  and  4  girls  and  the  following 
partial information about their preferences: 

– 
– 
B1:  G1  G2 
– 
– 
B2:  G2  G1 
–  G4  G3 
– 
B3: 
–  G3  G4 
B4: 
– 
– 
– 
G1:  B2  B1 
G2:  B1  B2 
– 
– 
B3  B4 
– 
– 
G3: 
G4: 
– 
– 
B4  B3 

(a)  Verify that 

(B 1, G1), (B 2, G2), (B 3, G3), (B 4, G4) 
will be a stable matching whatever the unspeciﬁed preferences may be. 

(b)  Explain why the stable matching above is neither boy-optimal nor boy-pessimal 
and so will not be an outcome of the Mating Ritual. 

(c)  Describe how to deﬁne a set of marriage preferences among n boys and n girls 
which have at least 2n/2  stable assignments. 
Hint:  Arrange  the boys  into a  list of n/2 pairs, and  likewise arrange  the girls  into 
a  list  of  n/2  pairs  of  girls.  Choose  preferences  so  that  the  kth  pair  of  boys  ranks 
the kth pair of girls just below the previous pairs of girls, and likewise for the kth 
pair of girls. Within the kth pairs, make sure each boy’s ﬁrst choice girl in the pair 
prefers the other boy in the pair. 

Homework Problems 

Problem 9.18. 
The most famous application of stable matching was in assigning graduating med­
ical students to hospital residencies. Each hospital has a preference ranking of stu­
dents  and  each  student  has  a  preference  order  of  hospitals,  but  unlike  the  setup 
in the notes where there are an equal number of boys and girls and monogamous 
marriages, hospitals generally have differing numbers of available residencies, and 
the total number of residencies may not equal the number of graduating students. 
Modify the deﬁnition of stable matching so it applies in this situation, and explain 
how  to  modify  the  Mating  Ritual  so  it  yields  stable  assignments  of  students  to 
residencies. No proof is required. 

9.2.  THE STABLE MARRIAGE PROBLEM 

165 

Problem 9.19. 
Give an example of a stable matching between 3 boys and 3 girls where no person 
gets their ﬁrst choice. Brieﬂy explain why your matching is stable. 

Problem 9.20. 
In a stable matching between n boys and girls produced by the Mating Ritual, call 
a person lucky if they are matched up with one of their �n/2� top choices.  We will 
prove: 

Theorem.  There must be at least one lucky person. 

To prove this, deﬁne the following derived variables for the Mating Ritual: 

q(B ) =  j , where j is the rank of the girl that boy B  is courting.  That is to say, boy 
B  is always courting the j th girl on his list. 
r(G) is the number of boys that girl G has rejected. 
� 
�
q(B ) − 
S  ::= 
r(G). 
G∈the-Girls 
B∈the-Boys 
Show that S  remains the same from one day to the next in the Mating Ritual. 

(a)	 Let 

(9.7) 

(b)  Prove the Theorem above.  (You may assume for simplicity that n is even.) 
Hint: A girl is sure to be lucky if she has rejected half the boys. 

166 

CHAPTER 9.  STATE MACHINES 

Chapter 10 

Simple Graphs 

Graphs  in which edges are not directed are called  simple graphs.  They come up  in 
all sorts of applications, including scheduling, optimization, communications, and 
the  design  and  analysis  of  algorithms.  Two  Stanford  students  even  used  graph 
theory to become multibillionaires! 
But we’ll start with an application designed to get your attention: we are going 
to make  a  professional  inquiry  into  sexual  behavior.  Namely,  we’ll  look  at  some 
data about who, on average, has more opposite-gender partners, men or women. 
Sexual  demographics  have  been  the  subject  of  many  studies.  In  one  of  the 
largest, researchers from the University of Chicago interviewed a random sample 
of  2500  people  over  several  years  to  try  to  get  an  answer  to  this  question.  Their 
study,  published  in  1994,  and  entitled  The  Social  Organization  of  Sexuality  found 
that on average men have 74% more opposite-gender partners than women. 
Other  studies have  found  that  the disparity  is  even  larger.  In particular, ABC 
News claimed that the average man has 20 partners over his lifetime, and the aver­
age woman has 6, for a percentage disparity of 233%.  The ABC News study, aired 
on  Primetime  Live  in  2004,  purported  to  be  one  of  the most  scientiﬁc  ever  done, 
with  only  a  2.5%  margin  of  error.  It  was  called  ”American  Sex  Survey:  A  peek 
between  the  sheets,” —which  raises  some question about  the  seriousness of  their 
reporting. 
Yet again, in August, 2007, the N.Y. Times reported on a study by the National 
Center  for Health  Statistics  of  the U.S.  government  showing  that men  had  seven 
partners while women had four.  Anyway, whose numbers do you think are more 
accurate,  the University of Chicago, ABC News,  or  the National Center?  —don’t 
answer; this is a setup question like “When did you stop beating your wife?” Using 
a  little  graph  theory,  we’ll  explain  why  none  of  these  ﬁndings  can  be  anywhere 
near the truth. 

167 

168 

CHAPTER 10.  SIMPLE GRAPHS 

10.1  Degrees & Isomorphism 

10.1.1  Deﬁnition of Simple Graph 
Informally, a graph is a bunch of dots with lines connecting some of them. Here is 
an example: 

For many mathematical purposes, we don’t really care how the points and lines 
are  laid  out —only which  points  are  connected  by  lines.  The  deﬁnition  of  simple 
graphs aims to capture just this connection data. 

Deﬁnition 10.1.1.  A simple graph, G, consists of a nonempty set, V , called the ver­
tices of G, and a collection, E , of two-element subsets of V .  The members of E  are 
called the edges of G. 

The vertices correspond to the dots in the picture, and the edges correspond to 
the lines. For example, the connection data given in the diagram above can also be 
given by listing the vertices and edges according to the ofﬁcial deﬁnition of simple 
graph: 
V  = {A, B , C, D , E , F , G, H, I }
E  = {{A, B} , {A, C } , {B , D} , {C, D} , {C, E } , {E , F } , {E , G} , {H, I }} . 
It will  be  helpful  to  use  the  notation A—B  for  the  edge  {A, B}.  Note  that A—B 
and B—A are different descriptions of the same edge, since sets are unordered. 
So  the  deﬁnition  of  simple  graphs  is  the  same  as  for  directed  graphs,  except 
→ 
that  instead of a directed edge v
w which  starts at vertex v  and ends at vertex 
w , a simple graph only has an undirected edge, v—w , that connects v and w . 

Deﬁnition 10.1.2.  Two vertices in a simple graph are said to be adjacent if they are 
joined  by  an  edge,  and  an  edge  is  said  to  be  incident  to  the  vertices  it  joins.  The 
number of edges incident to a vertex is called the degree of the vertex; equivalently, 
the degree of a vertex is equals the number of vertices adjacent to it. 

For example, in the simple graph above, A is adjacent to B and B  is adjacent to 
D ,  and  the  edge A—C  is  incident  to vertices A  and C .  Vertex H  has degree  1, D 
has degree 2, and E has degree 3. 

ABCDEFGHI10.1.  DEGREES & ISOMORPHISM 

169 

Graph Synonyms 

A  synonym  for  “vertices”  is  “nodes,”  and we’ll  use  these words  interchangeably. 
Simple graphs are sometimes called networks, edges are sometimes called arcs. We 
mention this as a “heads up” in case you look at other graph theory literature; we 
won’t use these words. 
Some  technical  consequences  of Deﬁnition  10.1.1  are worth  noting  right  from 
the start: 
1.  Simple  graphs  do  not  have  self-loops  ({a, a}  is  not  an  undirected  edge  be­
cause an undirected edge is deﬁned to be a set of two vertices.) 

2.  There is at most one edge between two vertices of a simple graph. 

3.  Simple  graphs  have  at  least  one  vertex,  though  they  might  not  have  any 
edges. 

There’s no harm  in  relaxing  these conditions,  and some authors do, but we don’t 
need self-loops, multiple edges between the same two vertices, or graphs with no 
vertices, and it’s simpler not to have them around. 
For  the  rest  of  this  Chapter we’ll  only  be  considering  simple  graphs,  so we’ll 
just call them “graphs” from now on. 

10.1.2  Sex in America 
Let’s model the question of heterosexual partners  in graph theoretic terms.  To do 
this,  we’ll  let  G  be  the  graph  whose  vertices,  V ,  are  all  the  people  in  America. 
Then we split V  into two separate subsets: M , which contains all the males, and F , 
which contains all the females.1  We’ll put an edge between a male and a female iff 
they have been  sexual partners.  This graph  is pictured  in Figure  10.1 with males 
on the left and females on the right. 

Figure 10.1: The sex partners graph 

1 For simplicity, we’ll ignore the possibility of someone being both, or neither, a man and a woman. 

MW170 

CHAPTER 10.  SIMPLE GRAPHS 

Actually,  this  is  a  pretty  hard  graph  to  ﬁgure  out,  let  alone  draw.  The  graph 
is  enormous:  the  US  population  is  about  300  million,  so  V  ≈  300M .  Of  these, 
|
|
approximately 50.8% are female and 49.2% are male, so |M
≈  147.6M , and |F | ≈
|
152.4M . And we don’t even have trustworthy estimates of how many edges there 
are,  let  alone  exactly  which  couples  are  adjacent.  But  it  turns  out  that  we  don’t 
need  to  know  any  of  this  —we  just  need  to  ﬁgure  out  the  relationship  between 
the  average  number  of  partners  per  male  and  partners  per  female.  To  do  this, 
we note that every edge is incident to exactly one M  vertex (remember, we’re only 
considering male-female relationships); so the sum of the degrees of the M  vertices 
equals the number of edges.  For the same reason, the sum of the degrees of the F 
� 
� 
vertices equals the number of edges.  So these sums are equal: 
deg (y) . 
y∈F 
x∈M
Now suppose we divide both sides of this equation by the product of the sizes of 
� �
� � 
�
� 
the two sets, |M | · |F |: 
y∈F  deg (y)
x∈M  deg (x)
1 
1 
· |M | 
· |F |
|F | 
|M | 
The terms above in parentheses are the average degree of an M  vertex and the average 
degree of a F  vertex.  So we know: 

deg (x) = 

= 

Avg. deg in M  = 

|F | 
|M | · 
Avg. deg in F 
In  other words,  we’ve  proved  that  the  average  number  of  female  partners  of 
males  in  the  population  compared  to  the  average  number  of males  per  female  is 
determined solely by the relative number of males and females in the population. 
Now the Census Bureau reports that there are slightly more females than males 
in  America;  in  particular  |F | / |M |  is  about  1.035.  So  we  know  that  on  average, 
males  have  3.5%  more  opposite-gender  partners  than  females,  and  this  tells  us 
nothing about any sex’s promiscuity or selectivity. Rather, it just has to do with the 
relative  number  of males  and  females.  Collectively,  males  and  females  have  the 
same number of opposite gender partners,  since  it  takes one of each set  for every 
partnership,  but  there  are  fewer  males,  so  they  have  a  higher  ratio.  This  means 
that the University of Chicago, ABC, and the Federal government studies are way 
off. After a huge effort, they gave a totally wrong answer. 
There’s  no  deﬁnite  explanation  for why  such  surveys  are  consistently wrong. 
One hypothesis  is  that males exaggerate  their number of partners —or maybe  fe­
males downplay theirs —but these explanations are speculative.  Interestingly, the 
principal  author  of  the  National  Center  for  Health  Statistics  study  reported  that 
she knew the results had to be wrong, but that was the data collected, and her job 
was to report it. 
The same underlying issue has led to serious misinterpretations of other survey 
data.  For example, a couple of years ago, the Boston Globe ran a story on a survey 

10.1.  DEGREES & ISOMORPHISM 

171 

of  the  study  habits  of  students  on  Boston  area  campuses.  Their  survey  showed 
that  on  average,  minority  students  tended  to  study  with  non-minority  students 
more than the other way around. They went on at great length to explain why this 
“remarkable  phenomenon” might  be  true.  But  it’s  not  remarkable  at  all —using 
our  graph  theory  formulation,  we  can  see  that  all  it  says  is  that  there  are  fewer 
minority students than non-minority students, which is, of course what “minority” 
means. 

10.1.3  Handshaking Lemma 

The previous  argument  hinged  on  the  connection  between  a  sum  of degrees  and 
the number edges. There is a simple connection between these in any graph: 

Lemma 10.1.3.  The sum of the degrees of the vertices in a graph equals twice the number 
of edges. 

Proof.  Every  edge  contributes  two  to  the  sum  of  the  degrees,  one  for  each  of  its 
� 
endpoints. 

Lemma 10.1.3 is sometimes called the Handshake Lemma:  if we total up the num­
ber of people each person at a party shakes hands with, the total will be twice the 
number of handshakes that occurred. 

10.1.4  Some Common Graphs 

Some graphs come up so frequently that they have names. The complete graph on n 
vertices, also called Kn , has an edge between every two vertices. Here is K5 : 

The empty graph has no edges at all. Here is the empty graph on 5 vertices: 

172 

CHAPTER 10.  SIMPLE GRAPHS 

Another 5 vertex graph is L4 , the line graph of length four: 

And here is C5 , a simple cycle with 5 vertices: 

10.1.5  Isomorphism 
Two graphs  that  look  the  same might  actually be different  in  a  formal  sense.  For 
example, the two graphs below are both simple cycles with 4 vertices: 

ABCD123410.1.  DEGREES & ISOMORPHISM 

173 

But one graph has vertex set {A, B , C, D} while the other has vertex set {1, 2, 3, 4}. 
If so, then the graphs are different mathematical objects, strictly speaking. But this 
is a frustrating distinction; the graphs look the same! 
Fortunately,  we  can  neatly  capture  the  idea  of  “looks  the  same”  by  adapting 
Deﬁnition 7.2.1 of isomorphism of digraphs to handle simple graphs. 

Deﬁnition  10.1.4.  If G1  is  a  graph with  vertices,  V1 ,  and  edges,  E1 ,  and  likewise 
for G2 , then G1  is isomorphic to G2  iff there exists a bijection, f  : V1  → V2 , such that 
for every pair of vertices u, v ∈ V1 : 
u—v ∈ E1 

iff  f (u)—f (v) ∈ E2 . 

The function f  is called an isomorphism between G1  and G2 . 

For example, here is an isomorphism between vertices in the two graphs above: 

A corresponds to 1 
D corresponds to 4 

B  corresponds to 2 

C  corresponds to 3. 


You can check that there is an edge between two vertices in the graph on the left if 
and only  if  there  is an edge between  the  two corresponding vertices  in  the graph 
on the right. 
Two  isomorphic graphs may be drawn very differently.  For example, here are 
two different ways of drawing C5 : 

Isomorphism  preserves  the  connection  properties  of  a  graph,  abstracting  out 
what the vertices are called, what they are made out of, or where they appear in a 
drawing of the graph.  More precisely, a property of a graph is said to be preserved 
under  isomorphism  if whenever G  has  that property,  every  graph  isomorphic  to G 
also has  that property.  For  example,  since an  isomorphism  is a bijection between 
sets of vertices, isomorphic graphs must have the same number of vertices. What’s 
more,  if  f  is a graph  isomorphism  that maps a vertex,  v ,  of one graph  to  the ver­
tex, f (v), of an isomorphic graph, then by deﬁnition of isomorphism, every vertex 
adjacent  to  v  in  the  ﬁrst  graph  will  be mapped  by  f  to  a  vertex  adjacent  to  f (v) 
in  the  isomorphic graph.  That  is, v  and f (v) will have  the same degree.  So  if one 
graph has a vertex of degree 4 and another does not, then they can’t be isomorphic. 

174 

CHAPTER 10.  SIMPLE GRAPHS 

In  fact,  they  can’t be  isomorphic  if  the number of degree  4 vertices  in  each of  the 
graphs is not the same. 
Looking for preserved properties can make it easy to determine that two graphs 
are  not  isomorphic,  or  to  actually  ﬁnd  an  isomorphism  between  them,  if  there  is 
one.  In practice, it’s frequently easy to decide whether two graphs are isomorphic. 
However, no one has yet  found a general procedure  for determining whether  two 
graphs  are  isomorphic  that  is  guaranteed  to  run  much  faster  than  an  exhaustive 
(and exhausting) search through all possible bijections between their vertices. 
Having an efﬁcient procedure to detect isomorphic graphs would, for example, 
make it easy to search for a particular molecule in a database given the molecular 
bonds.  On  the  other  hand,  knowing  there  is  no  such  efﬁcient  procedure  would 
also be valuable:  secure protocols for encryption and remote authentication can be 
built on the hypothesis that graph isomorphism is computationally exhausting. 

10.1.6  Problems 

Class Problems 

Problem 10.1.  (a)  Prove that in every graph, there are an even number of vertices 
of odd degree. 
Hint: The Handshaking Lemma 10.1.3. 

(b)  Conclude that at a party where some people shake hands, the number of peo­
ple who shake hands an odd number of times is an even number. 

(c)  Call  a  sequence  of  two  or  more  different  people  at  the  party  a  handshake  se­
quence if, except for the last person, each person in the sequence has shaken hands 
with the next person in the sequence. 

Suppose George was  at  the  party  and  has  shaken  hands with  an  odd  number  of 
people.  Explain why,  starting with George,  there must  be  a  handshake  sequence 
ending with a different person who has shaken an odd number of hands. 
Hint:  Just  look  at  the  people  at  the  ends  of  handshake  sequences  that  start  with 
George. 

Problem 10.2. 
For  each  of  the  following pairs  of  graphs,  either deﬁne  an  isomorphism  between 
them, or prove that there is none.  (We write ab as shorthand for a—b.) 
(a) 

G1  with V1  = {1, 2, 3, 4, 5, 6} , E1  = {12, 23, 34, 14, 15, 35, 45}
G2  with V2  = {1, 2, 3, 4, 5, 6} , E2  = {12, 23, 34, 45, 51, 24, 25} 

10.1.  DEGREES & ISOMORPHISM 

175 

(b) 

G3  with V3  = {1, 2, 3, 4, 5, 6} , E3  = {12, 23, 34, 14, 45, 56, 26}

G4  with V4  = {a, b, c, d, e, f } , E4  = {ab, bc, cd, de, ae, ef , cf }


(c) 
G5  with V5  = {a, b, c, d, e, f , g , h} , E5  = {ab, bc, cd, ad, ef , f g , gh, he, dh, bf }
G6  with V6  = {s, t, u, v , w, x, y , z} , E6  = {st, tu, uv , sv , wx, xy , yz , wz , sw, vz} 

Homework Problems 

Problem 10.3. 
Determine which  among  the  four  graphs  pictured  in  the  Figures  are  isomorphic. 
If two of these graphs are isomorphic, describe an isomorphism between them.  If 
they  are  not,  give  a  property  that  is  preserved  under  isomorphism  such  that  one 
graph  has  the  property,  but  the  other  does  not.  For  at  least  one  of  the  properties 
you  choose,  prove  that  it  is  indeed preserved under  isomorphism  (you  only  need 
prove one of them). 

(a)  G1 

(b)  G2 

(c)  G3 

(d)  G4 

Figure 10.2: Which graphs are isomorphic? 

12345678910123456789101234567891012345678910176 

CHAPTER 10.  SIMPLE GRAPHS 

Problem 10.4.  (a)  For any vertex,  v ,  in a graph,  let N (v) be  the  set of neighbors of 
v , namely, the vertices adjacent to v : 
N (v) ::= {u  | u—v  is an edge of the graph} . 

Suppose  f  is  an  isomorphism  from  graph  G  to  graph  H .  Prove  that  f (N (v))  = 
N (f (v)). 
Your  proof  should  follow  by  simple  reasoning  using  the  deﬁnitions  of  isomor­
phism and neighbors —no pictures or handwaving. 
Hint: Prove by a chain of iff ’s that 
iff  h ∈ f (N (v)) 
h ∈ N (f (v)) 
for every h ∈ VH . Use the fact that h = f (u) for some u ∈ VG . 
(b)  Conclude  that  if G  and H  are  isomorphic  graphs,  then  for  each  k  ∈  N,  they 
have the same number of degree k vertices. 

Problem 10.5. 
Let’s say that a graph has “two ends” if it has exactly two vertices of degree 1 and 
all its other vertices have degree 2.  For example, here is one such graph: 

(a)  A  line graph  is a graph whose vertices can be  listed  in a  sequence with edges 
between  consecutive  vertices  only.  So  the  two-ended  graph  above  is  also  a  line 
graph of length 4. 
Prove that the following theorem is false by drawing a counterexample. 
False Theorem.  Every two-ended graph is a line graph. 

(b)  Point  out  the  ﬁrst  erroneous  statement  in  the  following  alleged  proof  of  the 
false theorem. Describe the error as best you can. 

False proof.  We  use  induction.  The  induction  hypothesis  is  that  every  two-ended 
graph with n edges is a path. 
Base  case  (n  = 1):  The  only  two-ended  graph with  a  single  edge  consists  of  two 
vertices joined by an edge: 

10.1.  DEGREES & ISOMORPHISM 

177 

Sure enough, this is a line graph.

Inductive  case:  We  assume  that  the  induction  hypothesis  holds  for  some  n  ≥  1

and  prove  that  it  holds  for  n + 1.  Let Gn  be  any  two-ended  graph with  n  edges.

By  the  induction  assumption,  Gn  is  a  line  graph.  Now  suppose  that we  create  a

two-ended graph Gn+1  by adding one more edge to Gn .  This can be done in only

one way:  the  new  edge must  join  an  endpoint  of Gn  to  a  new  vertex;  otherwise,

Gn+1  would not be two-ended.


Clearly, Gn+1  is also a line graph. Therefore, the induction hypothesis holds for all 
graphs with n + 1 edges, which completes the proof by induction. 

� 

Exam Problems 

Problem 10.6. 
There are four isomorphisms between these two graphs. List them. 

Problem 10.7. 
A researcher analyzing data on heterosexual sexual behavior in a group of m males 
and  f  females  found  that  within  the  group,  the  male  average  number  of  female 
partners was 10% larger that the female average number of male partners. 
(a)  Circle all of the assertions below that are implied by the above information on 
average numbers of partners: 

Gnnew edge178 

CHAPTER 10.  SIMPLE GRAPHS 

(i)  males exaggerate their number of female partners 
(ii)  m = (9/10)f 
(iii)  m = (10/11)f 
(iv)  m = (11/10)f 
(v)  there  cannot be a perfect matching with each male matched  to one of his  fe­
male partners 
(vi)  there  cannot  be  a  perfect matching with  each  female matched  to  one  of  her 
male partners 

(b)  The  data  shows  that  approximately  20%  of  the  females  were  virgins,  while 
only  5%  of  the males were.  The  researcher wonders  how  excluding  virgins  from 
the population would change the averages.  If he knew graph theory, the researcher 
would realize that the nonvirgin male average number of partners will be x(f /m) 
times the nonvirgin female average number of partners. What is x? 

10.2  Connectedness 

10.2.1  Paths and Simple Cycles 
Paths in simple graphs are esentially the same as paths in digraphs.  We just mod­
ify  the  digraph  deﬁnitions  using  undirected  edges  instead  of  directed  ones.  For 
example, the formal deﬁnition of a path in a simple graph is a virtually that same 
as Deﬁnition 8.1.1 of paths in digraphs: 
Deﬁnition 10.2.1.  A path in a graph, G, is a sequence of k ≥ 0 vertices 

v0 , . . . , vk 
such that vi —vi+1  is an edge of G for all i where 0 ≤ i < k . The path is said to start 
at v0 , to end at vk , and the length of the path is deﬁned to be k . 
An edge, u—v , is traversed n times by the path if there are n different values of 
i such that vi —vi+1  =  u—v .  The path is simple2  iff all the vi ’s are different, that is, 
j  implies vi  =�
if i =�
vj . 
For example, the graph in Figure 10.3 has a length 6 simple path A,B,C,D,E,F,G. 
This is the longest simple path in the graph. 
As  in  digraphs,  the  length  of  a  path  is  the  total  number  of  times  it  traverses 
edges, which is one  less than its length as a sequence of vertices.  For example,  the 
length 6 path A,B,C,D,E,F,G is actually a sequence of seven vertices. 

2Heads  up:  what we  call  “paths”  are  commonly  referred  to  in  graph  theory  texts  as  “walks,”  and 
simple  paths  are  referred  to  as  just  “paths”.  Likewise,  what  we  will  call  cycles  and  simple  cycles  are 
commonly called “closed walks” and just “cycles”. 

10.2.  CONNECTEDNESS 

179 

Figure 10.3: A graph with 3 simple cycles. 

A cycle can be described by a path  that begins and ends with  the same vertex. 
For example, B,C,D,E,C,B is a cycle in the graph in Figure 10.3.  This path suggests 
that  the  cycle  begins  and  ends  at  vertex  B,  but  a  cycle  isn’t  intended  to  have  a 
beginning and end, and can be described by any of the paths that go around it. For 
example, D,E,C,B,C,D describes this same cycle as though  it started and ended at 
D, and D,C,B,C,E,D describes  the  same  cycle as  though  it  started and ended at D 
but  went  in  the  opposite  direction.  (By  convention,  a  single  vertex  is  a  length  0 
cycle beginning and ending at the vertex.) 
All the paths that describe the same cycle have the same length which is deﬁned 
to be the length of the cycle.  (Note that this implies that going around the same cycle 
twice is considered to be different than going around it once.) 
A  simple  cycle  is  a  cycle  that  doesn’t  cross  or  backtrack  on  itself.  For  exam­
ple,  the  graph  in  Figure  10.3  has  three  simple  cycles  B,H,E,C,B  and  C,D,E,C  and 
B,C,D,E,H,B. More  precisely,  a  simple  cycle  is  a  cycle  that  can  be  described  by  a 
path  of  length  at  least  three whose  vertices  are  all  different  except  for  the  begin­
ning and end vertices.  So in contrast to simple paths, the length of a simple cycle is 
the same as the number of distinct vertices that appear in it. 
From now on we’ll  stop being picky about distinguishing  a  cycle  from  a path 
that describes it, and we’ll just refer to the path as a cycle.  3 
Simple  cycles  are  especially  important,  so we will  give  a  proper  deﬁnition  of 
them. Namely, we’ll deﬁne a simple cycle in G to be a subgraph of G that looks like 
a cycle that doesn’t cross itself.  Formally: 
Deﬁnition 10.2.2.  A subgraph, G� , of a graph, G, is a graph whose vertices, V � , are 
a subset of the vertices of G and whose edges are a subset of the edges of G. 
Notice that since a subgraph is itself a graph, the endpoints of every edge of G� 
3 Technically speaking, we haven’t ever deﬁned what a cycle  is, only how  to describe  it with paths. 
But we won’t  need  an  abstract  deﬁnition  of  cycle,  since  all  that matters  about  a  cycle  is which  paths 
describe it. 

ABCDEFGH180 

CHAPTER 10.  SIMPLE GRAPHS 

must be vertices in V � . 
Deﬁnition 10.2.3.  For n ≥ 3, let Cn  be the graph with vertices 1, . . . , n and edges 
1—2,  2—3,  . . . ,  (n − 1)—n,  n—1. 
A graph is a simple cycle of length n iff it is isomorphic to Cn  for some n ≥ 3. A 
simple cycle of a graph, G, is a subgraph of G that is a simple cycle. 

This deﬁnition  formally  captures  the  idea  that  simple  cycles don’t have direc­
tion or beginnings or ends. 

10.2.2  Connected Components 
Deﬁnition  10.2.4.  Two  vertices  in  a  graph  are  said  to  be  connected when  there  is 
a  path  that  begins  at  one  and  ends  at  the  other.  By  convention,  every  vertex  is 
considered to be connected to itself by a path of length zero. 

The diagram in Figure 10.4 looks like a picture of three graphs, but is intended 
to be a picture of one graph.  This graph consists of three pieces (subgraphs).  Each 
piece  by  itself  is  connected,  but  there  are  no  paths  between  vertices  in  different 
pieces. 

Figure 10.4: One graph with 3 connected components. 

Deﬁnition  10.2.5.  A graph  is  said  to be  connected when  every pair of vertices  are 
connected. 

These connected pieces of a graph are called  its connected components.  A rigor­
ous deﬁnition is easy: a connected component is the set of all the vertices connected 
to some single vertex. So a graph is connected iff it has exactly one connected com­
ponent. The empty graph on n vertices has n connected components. 

10.2.  CONNECTEDNESS 

181 

10.2.3  How Well Connected? 
If we think of a graph as modelling cables in a telephone network, or oil pipelines, 
or electrical power lines, then we not only want connectivity, but we want connec­
tivity that survives component failure. A graph is called k-edge connected if it takes 
at least k “edge-failures” to disconnect it. More precisely: 

Deﬁnition 10.2.6.  Two vertices in a graph are k-edge connected if they remain con­
nected in every subgraph obtained by deleting k − 1 edges.  A graph with at least 
two vertices is k-edge connected4  if every two of its vertices are k-edge connected. 

So 1-edge connected is the same as connected for both vertices and graphs. An­
other way to say that a graph is k-edge connected is that every subgraph obtained 
from it by deleting at most k − 1 edges is connected.  For example, in the graph in 
Figure 10.3, vertices B and E are 2-edge connected, G and E are 1-edge connected, 
and  no  vertices  are  3-edge  connected.  The  graph  as  a whole  is  only  1-edge  con­
nected.  More  generally,  any  simple  cycle  is  2-edge  connected,  and  the  complete 
graph, Kn , is (n − 1)-edge connected. 
If  two  vertices  are  connected  by  k  edge-disjoint  paths  (that  is,  no  two  paths 
traverse the same edge), then they are obviously k-edge connected. A fundamental 
fact, whose ingenious proof we omit, is Menger ’s theorem which conﬁrms that the 
converse  is also  true:  if  two vertices are k-edge  connected,  then  there are k  edge-
disjoint paths connecting them.  It even takes some ingenuity to prove this for the 
case k = 2. 

10.2.4  Connection by Simple Path 
Where  there’s  a  path,  there’s  a  simple  path.  This  is  sort  of  obvious,  but  it’s  easy 
enough to prove rigorously using the Well Ordering Principle. 

Lemma 10.2.7.  If vertex u is connected to vertex v  in a graph, then there is a simple path 
from u to v . 

Proof.  Since there is a path from u to v , there must, by the Well-ordering Principle, 
be a minimum length path from u to v .  If the minimum length is zero or one, this 
minimum  length  path  is  itself  a  simple  path  from  u  to  v .  Otherwise,  there  is  a 
minimum length path 

v0 , v1 , . . . , vk 
from  u  =  v0  to  v  =  vk  where  k  ≥  2.  We  claim  this  path  must  be  simple.  To 
prove  the claim,  suppose  to  the contrary  that  the path  is not simple,  that  is,  some 
vertex  on  the  path  occurs  twice.  This means  that  there  are  integers  i, j  such  that 
0 ≤ i < j  ≤ k with vi  = vj . Then deleting the subsequence 

vi+1 , . . . vj 

4 The  corresponding  deﬁnition  of  connectedness  based  on  deleting  vertices  rather  than  edges  is 
common in Graph Theory texts and is usually simply called “k-connected” rather than “k-vertex con­
nected.” 

182 

CHAPTER 10.  SIMPLE GRAPHS 

yields a strictly shorter path 

v0 , v1 , . . . , vi , vj+1 , vj+2 , . . . , vk 

from u to v , contradicting the minimality of the given path. 

� 

Actually, we proved something stronger: 

Corollary 10.2.8.  For any path of length k  in a graph, there is a simple path of length at 
most k with the same endpoints. 

10.2.5  The Minimum Number of Edges in a Connected Graph 
The  following  theorem  says  that  a  graph  with  few  edges  must  have  many  con­
nected components. 
Theorem  10.2.9.  Every  graph  with  v  vertices  and  e  edges  has  at  least  v − e  connected 
components. 

Of course for Theorem 10.2.9 to be of any use,  there must be fewer edges than 
vertices. 

Proof.  We  use  induction  on  the  number  of  edges,  e.  Let  P (e)  be  the  proposition 
that 

for  every  v ,  every graph with  v  vertices and  e  edges has at  least  v − e 
connected components. 

Base case:(e = 0).  In a graph with 0 edges and v vertices, each vertex is itself a 
connected component, and so  there are exactly v  =  v − 0 connected components. 
So P (e) holds. 
Inductive step: Now we assume that the induction hypothesis holds for every 
e-edge  graph  in  order  to  prove  that  it  holds  for  every  (e + 1)-edge  graph,  where 
e ≥ 0. Consider a graph, G, with e + 1 edges and k vertices. We want to prove that 
G has at  least v − (e + 1) connected components.  To do  this,  remove an arbitrary 
edge  a—b  and  call  the  resulting  graph  G� .  By  the  induction  assumption,  G�  has 
at  least  v − e  connected  components.  Now  add  back  the  edge  a—b  to  obtain  the 
original graph G.  If a and b were in the same connected component of G� ,  then G 
has  the  same  connected  components  as G� ,  so G  has  at  least  v − e > v − (e + 1) 
components.  Otherwise,  if a and b were in different connected components of G� , 
then  these  two  components  are  merged  into  one  in  G,  but  all  other  components 
remain unchanged, reducing the number of components by 1.  Therefore, G has at 
least (v −e)−1 = v − (e+1) connected components. So in either case, P (e+1) holds. 
� 
This completes the Inductive step. The theorem now follows by induction. 
Corollary 10.2.10.  Every connected graph with v vertices has at least v − 1 edges. 

10.2.  CONNECTEDNESS 

183 

A couple of points about the proof of Theorem 10.2.9 are worth noticing.  First, 
we  used  induction  on  the  number  of  edges  in  the  graph.  This  is  very  common 
in proofs  involving graphs,  and  so  is  induction on  the number of vertices.  When 
you’re  presented with  a  graph  problem,  these  two  approaches  should  be  among 
the ﬁrst you consider. The second point is more subtle. Notice that in the inductive 
step, we took an arbitrary (n + 1)-edge graph, threw out an edge so that we could 
apply the induction assumption, and then put the edge back. You’ll see this shrink-
down,  grow-back  process  very  often  in  the  inductive  steps  of  proofs  related  to 
graphs.  This might seem  like needless effort; why not start with an n-edge graph 
and  add  one  more  to  get  an  (n +  1)-edge  graph?  That  would  work  ﬁne  in  this 
case,  but opens  the door  to a nasty  logical error  called  buildup  error,  illustrated  in 
Problems  10.5  and  10.11.  Always  use  shrink-down,  grow-back  arguments,  and 
you’ll never fall into this trap. 

10.2.6  Problems 

Class Problems 

Problem 10.8. 
The n-dimensional hypercube, Hn , is a graph whose vertices are the binary strings 
of length n.  Two vertices are adjacent if and only if they differ in exactly 1 bit.  For 
example,  in H3 , vertices 111 and 011 are adjacent because they differ only in the 
ﬁrst  bit,  while  vertices  101  and  011  are  not  adjacent  because  they  differ  at  both 
the ﬁrst and second bits. 
(a)  Prove  that  it  is  impossible  to ﬁnd  two spanning  trees of H3  that do not share 
some edge. 

(b)  Verify  that  for  any  two vertices x  =�
y  of H3 ,  there  are  3 paths  from x  to  y  in 
H3 , such that, besides x and y , no two of those paths have a vertex in common. 

(c)  Conclude that the connectivity of H3  is 3. 

(d)  Try extending your reasoning to H4 .  (In fact, the connectivity of Hn  is n for all 
n ≥ 1. A proof appears in the problem solution.) 

Problem 10.9. 
A set, M , of vertices of a graph is a maximal connected set if every pair of vertices in 
the  set  are  connected,  and  any  set  of vertices properly  containing M  will  contain 
two vertices that are not connected. 
(a)  What are the maximal connected subsets of the following (unconnected) graph? 

184 

CHAPTER 10.  SIMPLE GRAPHS 

(b)  Explain the connection between maximal connected sets and connected com­
ponents. Prove it. 

Problem 10.10.  (a)  Prove that Kn  is (n − 1)-edge connected for n > 1. 
Let  Mn  be  a  graph  deﬁned  as  follows:  begin  by  taking  n  graphs  with  non-
overlapping sets of vertices, where each of the n graphs is (n − 1)-edge connected 
(they could be disjoint copies of Kn , for example). These will be subgraphs of Mn . 
Then  pick  n  vertices,  one  from  each  subgraph,  and  add  enough  edges  between 
pairs of picked vertices  that  the  subgraph of  the n picked vertices  is also  (n − 1)­
edge connected. 
(b)  Draw a picture of M4 . 
(c)  Explain why Mn  is (n − 1)-edge connected. 

Problem 10.11. 
Deﬁnition 10.2.5.  A graph  is connected  iff  there  is a path between every pair of  its 
vertices. 

False Claim.  If every vertex in a graph has positive degree, then the graph is connected. 

(a)  Prove that this Claim is indeed false by providing a counterexample. 

(b)  Since  the  Claim  is  false,  there  must  be  an  logical  mistake  in  the  following 
bogus proof. Pinpoint the ﬁrst logical mistake (unjustiﬁed step) in the proof. 

Bogus proof.  We prove the Claim above by  induction.  Let P (n) be the proposition 
that  if  every  vertex  in  an  n-vertex  graph  has  positive  degree,  then  the  graph  is 
connected. 
Base  cases: (n  ≤  2).  In  a  graph  with  1  vertex,  that  vertex  cannot  have  positive 
degree, so P (1) holds vacuously.

P (2)  holds  because  there  is  only  one  graph with  two  vertices  of  positive  degree,

namely, the graph with an edge between the vertices, and this graph is connected.


10.2.  CONNECTEDNESS 

185 

Inductive step: We must show that P (n) implies P (n + 1) for all n ≥  2.  Consider 
an n-vertex  graph  in which  every  vertex  has positive degree.  By  the  assumption 
P (n), this graph is connected; that is, there is a path between every pair of vertices. 
Now we add one more vertex x to obtain an (n + 1)-vertex graph: 

All that remains is to check that there is a path from x to every other vertex z . Since 
x has positive degree, there is an edge from x to some other vertex, y . Thus, we can 
obtain a path from x to z  by going from x to y and then following the path from y 
to z . This proves P (n + 1). 
By the principle of induction, P (n) is true for all n ≥ 0, which proves the Claim. 
� 

Homework Problems 

Problem 10.12. 
In  this  problem we’ll  consider  some  special  cycles  in  graphs  called  Euler  circuits, 
named  after  the  famous  mathematician  Leonhard  Euler.  (Same  Euler  as  for  the 
constant e ≈ 2.718 —he did a lot of stuff.) 
Deﬁnition  10.2.11.  An  Euler  circuit  of  a  graph  is  a  cycle  which  traverses  every 
edge exactly once. 
Does the graph in the following ﬁgure contain an Euler circuit? 

zyXn − vertex graphABCDFEG186 

CHAPTER 10.  SIMPLE GRAPHS 

Well, if it did, the edge (E , F ) would need to be included.  If the path does not 
start at F  then at some point it traverses edge (E , F ), and now it is stuck at F  since 
F  has no other edges incident to it and an Euler circuit can’t traverse (E , F ) twice. 
But then the path could not be a circuit.  On the other hand, if the path starts at F , 
it must then go to E along (E , F ), but now it cannot return to F .  It again cannot be 
a circuit.  This argument generalizes to show that if a graph has a vertex of degree 
1, it cannot contain an Euler circuit. 
So  how  do  you  tell  in  general  whether  a  graph  has  an  Euler  circuit?  At  ﬁrst 
glance  this may  seem  like  a  daunting  problem  (the  similar  sounding  problem  of 
ﬁnding a cycle that touches every vertex exactly once is one of those million dollar 
NP-complete problems known as the Traveling Salesman Problem) —but it turns out 
to be easy. 
(a)  Show that if a graph has an Euler circuit, then the degree of each of its vertices 
is even. 
In  the  remaining  parts,  we’ll  work  out  the  converse:  if  the  degree  of  every 
vertex of a connected ﬁnite graph  is even,  then  it has an Euler circuit.  To do  this, 
let’s deﬁne an Euler path to be a path that traverses each edge at most once. 
(b)  Suppose that an Euler path in a connected graph does not traverse every edge. 
Explain why there must be an untraversed edge that is incident to a vertex on the 
path. 
In the remaining parts, let W  be the longest Euler path in some ﬁnite, connected 
graph. 
(c)  Show that if W  is a cycle, then it must be an Euler circuit. 
Hint: part (b) 

(d)  Explain why  all  the  edges  incident  to  the  end  of W  must  already  have  been 
traversed by W . 

(e)  Show that if the end of W  was not equal to the start of W , then the degree of 
the end would be odd. 
Hint: part (d) 

(f)  Conclude  that  if  every  vertex  of  a  ﬁnite,  connected  graph  has  even  degree, 
then it has an Euler circuit. 

Homework Problems 

Problem 10.13. 
An edge is said to leave a set of vertices if one end of the edge is in the set and the 
other end is not. 
(a)  An n-node graph is said to be mangled if there is an edge leaving every set of 
�n/2� or fewer vertices. Prove the following claim. 
Claim.  Every mangled graph is connected. 
An  n-node  graph  is  said  to  be  tangled  if  there  is  an  edge  leaving  every  set  of 
�n/3� or fewer vertices. 

10.3.  TREES 

187 

(b)  Draw a tangled graph that is not connected. 

(c)  Find the error in the proof of the following 
False Claim.  Every tangled graph is connected. 

False proof.  The proof is by strong induction on the number of vertices in the graph. 
Let P (n) be the proposition that if an n-node graph is tangled, then it is connected. 
In the base case, P (1) is true because the graph consisting of a single node is triv­
ially connected. 
For  the  inductive  case,  assume  n  ≥  1  and  P (1), . . . , P (n)  hold.  We  must  prove 
P (n + 1), namely, that if an (n + 1)-node graph is tangled, then it is connected. 
So let G be a tangled, (n + 1)-node graph.  Choose �n/3� of the vertices and let G1 
be the tangled subgraph of G with these vertices and G2  be the tangled subgraph 
with  the  rest  of  the  vertices.  Note  that  since  n  ≥  1,  the  graph  G  has  a  least  two 
vertices,  and  so  both G1  and G2  contain  at  least  one vertex.  Since G1  and G2  are 
tangled, we may assume by strong induction that both are connected.  Also, since 
G is tangled, there is an edge leaving the vertices of G1  which necessarily connects 
to  a  vertex  of  G2 .  This  means  there  is  a  path  between  any  two  vertices  of  G: a 
path  within  one  subgraph  if  both  vertices  are  in  the  same  subgraph,  and  a  path 
traversing the connecting edge if the vertices are in separate subgraphs. Therefore, 
the  entire graph, G,  is  connected.  This  completes  the proof of  the  inductive  case, 
and the Claim follows by strong induction. 

� 

Problem 10.14. 
Let G be the graph formed from C2n , the simple cycle of length 2n, by connecting 
every pair of vertices at maximum distance  from each other  in C2n  by an edge  in 
G. 
(a)  Given two vertices of G ﬁnd their distance in G. 

(b)  What is the diameter of G, that is, the largest distance between two vertices? 

(c)  Prove that the graph is not 4-connected. 

(d)  Prove that the graph is 3-connected. 

10.3  Trees 

Trees  are  a  fundamental  data  structure  in  computer  science,  and  there  are many 
kinds,  such  as  rooted,  ordered,  and  binary  trees.  In  this  section we  focus  on  the 
purest kind of tree. Namely, we use the term tree to mean a connected graph with­
out simple cycles. 
A  graph with  no  simple  cycles  is  called  acyclic;  so  trees  are  acyclic  connected 
graphs. 

188 

CHAPTER 10.  SIMPLE GRAPHS 

10.3.1  Tree Properties 
Here is an example of a tree: 

A vertex of degree at most one is called a leaf.  In this example, there are 5 leaves. 
Note that the only case where a tree can have a vertex of degree zero is a graph with 
a single vertex. 
The graph shown above would no  longer be a tree  if any edge were removed, 
because it would no longer be connected.  The graph would also not remain a tree 
if any edge were added between two of its vertices, because then it would contain 
a  simple  cycle.  Furthermore,  note  that  there  is  a unique path between  every pair 
of vertices. These features of the example tree are actually common to all trees. 

Theorem 10.3.1.  Every tree has the following properties: 

1.  Any connected subgraph is a tree. 

2.  There is a unique simple path between every pair of vertices. 

3.  Adding an edge between two vertices creates a cycle. 

4.  Removing any edge disconnects the graph. 

5.  If it has at least two vertices, then it has at least two leaves. 

6.  The number of vertices is one larger than the number of edges. 

Proof. 
1.  A simple cycle in a subgraph is also a simple cycle in the whole graph, 
so any subgraph of an acyclic graph must also be acyclic.  If the subgraph is 
also connected, then by deﬁnition, it is a tree. 

2.  There is at least one path, and hence one simple path, between every pair of 
vertices, because the graph is connected. Suppose that there are two different 
simple paths between vertices u and v . Beginning at u, let x be the ﬁrst vertex 
where the paths diverge, and let y  be the next vertex they share.  Then there 
are  two  simple  paths  from  x  to  y  with  no  common  edges,  which  deﬁnes  a 
simple cycle.  This is a contradiction, since trees are acyclic.  Therefore,  there 
is exactly one simple path between every pair of vertices. 

10.3.  TREES 

189 

3.  An  additional  edge  u—v  together  with  the  unique  path  between  u  and  v 
forms a simple cycle. 

4.  Suppose  that we  remove edge u—v .  Since  the  tree contained a unique path 
between u and v , that path must have been u—v .  Therefore, when that edge 
is removed, no path remains, and so the graph is not connected. 

5.  Let  v1 , . . . , vm  be  the  sequence  of  vertices  on  a  longest  simple  path  in  the 
tree.  Then  m  ≥  2,  since  a  tree  with  two  vertices  must  contain  at  least  one 
edge.  There  cannot  be  an  edge  v1 —vi  for  2  < i  ≤  m;  otherwise,  vertices 
v1 , . . . , vi  would  from a simple cycle.  Furthermore,  there cannot be an edge 
u—v1  where u is not on the path; otherwise, we could make the path longer. 
Therefore,  the  only  edge  incident  to  v1  is  v1 —v2 ,  which  means  that  v1  is  a 
leaf. By a symmetric argument, vm  is a second leaf. 

6.  We use  induction on  the number of vertices.  For a  tree with a single vertex, 
the claim holds since it has no edges and 0 + 1 = 1 vertex. Now suppose that 
the claim holds for all n-vertex trees and consider an (n+1)-vertex tree, T . Let 
v be a leaf of the tree. You can verify that deleting a vertex of degree 1 (and its 
incident  edge)  from  any  connected  graph  leaves  a  connected  subgraph.  So 
by  1.,  deleting  v  and  its  incident  edge  gives  a  smaller  tree,  and  this  smaller 
tree has one more vertex  than edge by  induction.  If we re-attach  the vertex, 
v , and its incident edge, then the equation still holds because the number of 
vertices and number of edges both increase by 1. Thus, the claim holds for T 
and, by induction, for all trees. 
� 

Various subsets of these properties provide alternative characterizations of trees, 
though we won’t prove this. For example, a connected graph with a number of ver­
tices one larger than the number of edges is necessarily a tree.  Also, a graph with 
unique paths between every pair of vertices is necessarily a tree. 

10.3.2  Spanning Trees 
Trees  are  everywhere.  In  fact,  every  connected graph  contains  a  subgraph  that  is 
a  tree with  the  same  vertices  as  the  graph.  This  is  a  called  a  spanning  tree  for  the 

uxyv190 

CHAPTER 10.  SIMPLE GRAPHS 

graph.  For  example,  here  is  a  connected graph with  a  spanning  tree highlighted. 

Theorem 10.3.2.  Every connected graph contains a spanning tree. 

Proof.  Let T  be a connected subgraph of G, with the same vertices as G, and with 
the  smallest  number  of  edges  possible  for  such  a  subgraph.  We  show  that  T  is 
acyclic by contradiction.  So suppose that T  has a cycle with the following edges: 

v0 —v1 , v1 —v2 , . . . , vn —v0 

Suppose  that  we  remove  the  last  edge,  vn —v0 .  If  a  pair  of  vertices  x  and  y  was 
joined by a path not containing vn —v0 ,  then  they remain  joined by  that path.  On 
the  other hand,  if x  and  y  were  joined  by  a path  containing  vn —v0 ,  then  they  re­
main  joined by a path containing the remainder of the cycle.  So all the vertices of 
G are still connected after we remove an edge from T . This is a contradiction, since 
T  was deﬁned  to  be  a minimum  size  connected  subgraph with  all  the vertices  of 
� 
G.  So T  must be acyclic. 

10.3.3  Problems 
Class Problems 

Problem 10.15. 
Procedure M ark  starts with  a  connected,  simple  graph with  all  edges  unmarked 
and  then marks  some  edges.  At  any point  in  the procedure  a path  that  traverses 
only  marked  edges  is  called  a  fully  marked  path,  and  an  edge  that  has  no  fully 
marked path between its endpoints is called eligible. 
Procedure  M ark  simply  keeps  marking  eligible  edges,  and  terminates  when 
there are none. 
Prove  that M ark  terminates,  and  that  when  it  does,  the  set  of  marked  edges 
forms a spanning tree of the original graph. 

Problem 10.16. 

10.3.  TREES 

191 

Procedure create-spanning-tree 
Given a simple graph G, keep applying the following operations to the 
graph until no operation applies: 

1.  If an edge u—v of G is on a simple cycle, then delete u—v . 
2.  If vertices u and v of G are not connected, then add the edge u—v . 
Assume the vertices of G are the integers 1, 2, . . . , n for some n ≥ 2.  Procedure 
create-spanning-tree can be modeled as a state machine whose states are all possi­
ble simple graphs with vertices 1, 2, . . . , n.  The start state is G, and the ﬁnal states 
are the graphs on which no operation is possible. 
(a)  Let G be the graph with vertices {1, 2, 3, 4} and edges 
{1—2, 3—4} 

What are the possible ﬁnal states reachable from start state G? Draw them. 

(b)  Prove that any ﬁnal state of must be a tree on the vertices. 
(c)  For any state, G� ,  let e be  the number of edges  in G� , c be  the number of con­
nected  components  it  has,  and  s  be  the  number  of  simple  cycles.  For  each  of  the 
derived  variables  below,  indicate  the  strongest  of  the  properties  that  it  is  guaran­
teed  to  satisfy,  no matter what  the  starting  graph G  is  and  be prepared  to  brieﬂy 
explain your answer. 
The choices for properties are:  constant, strictly increasing, strictly decreasing, weakly 
increasing, weakly decreasing, none of these. The derived variables are 

(i)  e 
(ii)  c 
(iii)  s 
(iv)  e − s 
(v)  c + e 
(vi)  3c + 2e 
(vii)  c + s 
(viii)  (c, e), partially ordered coordinatewise (the product partial order, Ch. 7.4). 

(d)  Prove that procedure create-spanning-tree terminates.  (If your proof depends 
on one of the answers to part (c), you must prove that answer is correct.) 

Problem 10.17. 
Prove that a graph is a tree iff it has a unique simple path between any two vertices. 

192 

CHAPTER 10.  SIMPLE GRAPHS 

Homework Problems 

Problem 10.18.  (a)  Prove that the average degree of a tree is less than 2. 

(b)  Suppose every vertex in a graph has degree at least k .  Explain why the graph 
has a simple path of length k . 
Hint: Consider a longest simple path. 

10.4  Coloring Graphs 

In  section  10.1.2,  we  used  edges  to  indicate  an  afﬁnity  between  two  nodes,  but 
having  an  edge  represent  a  conﬂict between  two nodes  also  turns out  to be  really 
useful. 

10.5  Modelling Scheduling Conﬂicts 

Each  term  the MIT  Schedules Ofﬁce must  assign  a  time  slot  for  each  ﬁnal  exam. 
This  is not easy, because some students are  taking several classes with ﬁnals, and 
a student can take only one test during a particular time slot. The Schedules Ofﬁce 
wants  to  avoid  all  conﬂicts.  Of  course,  you  can make  such  a  schedule  by  having 
every exam  in a different slot, but  then you would need hundreds of slots  for  the 
hundreds of courses, and exam period would run all year! So, the Schedules Ofﬁce 
would also like to keep exam period short. The Schedules Ofﬁce’s problem is easy 
to describe as a graph. There will be a vertex for each course with a ﬁnal exam, and 
two  vertices  will  be  adjacent  exactly  when  some  student  is  taking  both  courses. 
For example, suppose we need to schedule exams for 6.041, 6.042, 6.002, 6.003 and 
6.170. The scheduling graph might look like this: 

6.002 and 6.042 cannot have an exam at the same time since there are students in 
both courses, so there is an edge between their nodes. On the other hand, 6.042 and 
6.170 can have an exam at the same time if they’re taught at the same time (which 
they  sometimes are),  since no  student  can be  enrolled  in both  (that  is,  no  student 
should  be  enrolled  in  both when  they  have  a  timing  conﬂict).  Next,  identify  each 

00204104200317010.5.  MODELLING SCHEDULING CONFLICTS 

193 

time slot with a color.  For example, Monday morning is red, Monday afternoon is 
blue, Tuesday morning is green, etc. 
Assigning an exam to a time slot is now equivalent to coloring the correspond­
ing  vertex.  The main  constraint  is  that  adjacent  vertices must  get  different  colors — 
otherwise,  some  student  has  two  exams  at  the  same  time.  Furthermore,  in  order 
to keep  the exam period short, we should  try  to color all  the vertices using as  few 
different colors as possible.  For our example graph, three colors sufﬁce: 

This  coloring  corresponds  to  giving  one  ﬁnal  on Monday morning  (red),  two 
Monday  afternoon  (blue),  and  two  Tuesday morning  (green).  Can we  use  fewer 
than three colors?  No!  We can’t use only two colors since there is a triangle in the 
graph, and three vertices in a triangle must all have different colors. 
This is an example of what is a called a graph coloring problem:  given a graph G, 
assign colors to each node such that adjacent nodes have different colors.  A color 
assignment with this property is called a valid coloring of the graph —a “coloring,” 
for short. A graph G is k-colorable if it has a coloring that uses at most k colors. 

Deﬁnition 10.5.1.  The minimum value of k  for which a graph, G, has a valid col­
oring is called its chromatic number, χ(G). 

In general, trying to ﬁgure out if you can color a graph with a ﬁxed number of 
colors  can  take  a  long  time.  It’s  a  classic  example  of  a problem  for which  no  fast 
algorithms are known.  In fact,  it  is easy to check  if a coloring works, but  it seems 
really  hard  to  ﬁnd  it  (if  you  ﬁgure  out  how,  then  you  can  get  a  $1  million  Clay 
prize). 

10.5.1  Degree-bounded Coloring 
There  are  some  simple  graph  properties  that  give  useful  upper  bounds  on  color­
ings.  For example, if we have a bound on the degrees of all the vertices in a graph, 
then we can easily ﬁnd a coloring with only one more color than the degree bound. 

Theorem 10.5.2.  A graph with maximum degree at most k  is (k + 1)-colorable. 

Unfortunately,  if  you  try  induction  on  k ,  it will  lead  to  disaster.  It  is  not  that 
it  is  impossible,  just  that  it  is  extremely  painful  and would  ruin  you  if  you  tried 

redgreenbluegreenblue194 

CHAPTER 10.  SIMPLE GRAPHS 

it on an exam.  Another option, especially with graphs,  is  to change what you are 
inducting on.  In graphs,  some good choices are n,  the number of nodes, or e,  the 
number of edges. 

Proof.  We use induction on the number of vertices in the graph, which we denote 
by n. Let P (n) be the proposition that an n-vertex graph with maximum degree at 
most k  is (k + 1)-colorable. 
Base case: (n = 1) A 1-vertex graph has maximum degree 0 and is 1-colorable, 
so P (1) is true. 
Inductive  step:  Now assume  that P (n)  is  true,  and  let G be an  (n + 1)-vertex 
graph with maximum degree at most k . Remove a vertex v (and all edges incident 
to  it),  leaving  an n-vertex  subgraph, H .  The maximum degree  of H  is  at most  k , 
and so H  is (k + 1)-colorable by our assumption P (n). Now add back vertex v . We 
can assign v  a color different  from all  its adjacent vertices,  since  there are at most 
k adjacent vertices and k + 1 colors are available. Therefore, G is (k + 1)-colorable. 
� 
This completes the inductive step, and the theorem follows by induction. 

Sometimes  k + 1  colors  is  the  best  you  can  do.  For  example,  in  the  complete 
graph,  Kn ,  every  one  of  its  n  vertices  is  adjacent  to  all  the  others,  so  all  n  must 
be  assigned  different  colors.  Of  course  n  colors  is  also  enough,  so  χ(Kn ) =  n. 
So Kk+1  is an example where Theorem 10.5.2 gives  the best possible bound.  This 
means  that Theorem 10.5.2 also gives  the best possible bound  for  any graph with 
degree bounded by k that has Kk+1  as a subgraph. But sometimes k + 1 colors is far 
from the best that you can do. Here’s an example of an n-node star graph for n = 7: 

In  the n-node star graph,  the maximum degree  is n − 1, but  the star only needs 2 
colors! 

10.5.2  Why coloring? 
One  reason  coloring  problems  come  all  the  time  is  because  scheduling  conﬂicts 
are  so  common.  For  example,  at Akamai,  a  new  version  of  software  is  deployed 
over  each  of  20,000  servers  every  few  days.  The  updates  cannot  be  done  at  the 
same time since the servers need to be taken down in order to deploy the software. 
Also,  the  servers  cannot  be  handled  one  at  a  time,  since  it would  take  forever  to 

10.5.  MODELLING SCHEDULING CONFLICTS 

195 

update them all (each one takes about an hour). Moreover, certain pairs of servers 
cannot be taken down at the same time since they have common critical functions. 
This problem was  eventually  solved by making  a  20,000 node  conﬂict graph  and 
coloring it with 8 colors – so only 8 waves of install are needed!  Another example 
comes from the need to assign frequencies to radio stations.  If two stations have an 
overlap  in  their broadcast area,  they can’t be given  the same  frequency.  Frequen­
cies are precious and expensive, so you want to minimize the number handed out. 
This amounts to ﬁnding the minimum coloring for a graph whose vertices are the 
stations and whose edges are between stations with overlapping areas. 
Coloring  also  comes up  in  allocating  registers  for program variables.  While  a 
variable is in use, its value needs to be saved in a register, but registers can often be 
reused for different variables. But two variables need different registers if they are 
referenced during overlapping  intervals of program execution.  So register alloca­
tion  is  the coloring problem  for a graph whose vertices are  the variables;  vertices 
are adjacent if their intervals overlap, and the colors are registers. 
Finally,  there’s  the  famous  map  coloring  problem  stated  in  Propostion  1.2.5. 
The  question  is  how many  colors  are  needed  to  color  a map  so  that  adjacent  ter­
ritories  get  different  colors?  This  is  the  same  as  the  number  of  colors  needed  to 
color a graph that can be drawn in the plane without edges crossing.  A proof that 
four colors are enough for the planar graphs was acclaimed when it was discovered 
about thirty years ago.  Implicit in that proof was a 4-coloring procedure that takes 
time  proportional  to  the  number  of  vertices  in  the  graph  (countries  in  the map). 
On  the  other  hand,  it’s  another  of  those million  dollar  prize  questions  to  ﬁnd  an 
efﬁcient procedure  to  tell  if a planar graph  really needs  four  colors or  if  three will 
actually do the job. But it’s always easy to tell if an arbitrary graph is 2-colorable, as 
we show in Section 10.6.  Later in Chapter 12, we’ll develop enough planar graph 
theory to present an easy proof at least that planar graphs are 5-colorable. 

10.5.3  Problems 

Class Problems 

Problem 10.19. 
Let G be the graph below5 . Carefully explain why χ(G) = 4. 

5 From Discrete Mathematics, Lov ´asz, Pelikan, and Vesztergombi.  Springer, 2003. Exercise 13.3.1 

196 

CHAPTER 10.  SIMPLE GRAPHS 

Homework Problems 

Problem 10.20. 
6.042 is often taught using recitations.  Suppose it happened that 8 recitations were 
needed, with two or three staff members running each recitation.  The assignment 
of staff to recitation sections is as follows: 

•  R1: Eli, Megumi, Rich 

•  R2: Eli, Stephanie, David 

•  R3: Megumi, Stav 

•  R4: Liz, Stephanie, Oscar 

•  R5: Liz, Tom, David 

•  R6: Tom, Stav 

•  R7: Tom, Stephanie 

•  R8: Megumi, Stav, David 

Two  recitations  can  not  be  held  in  the  same  90-minute  time  slot  if  some  staff 
member is assigned to both recitations. The problem is to determine the minimum 
number of time slots required to complete all the recitations. 

10.5.  MODELLING SCHEDULING CONFLICTS 

197 

(a)  Recast  this  problem  as  a  question  about  coloring  the  vertices  of  a  particular 
graph. Draw the graph and explain what the vertices, edges, and colors represent. 

(b)  Show a coloring of this graph using the fewest possible colors. What schedule 
of recitations does this imply? 

Problem 10.21. 
This  problem  generalizes  the  result  proved  Theorem  10.5.2  that  any  graph  with 
maximum degree at most w is (w + 1)-colorable. 
A simple graph, G, is said to have width, w , iff its vertices can be arranged in a 
sequence  such  that each vertex  is adjacent  to at most w  vertices  that precede  it  in 
the sequence.  If the degree of every vertex is at most w , then the graph obviously 
has width at most w —just list the vertices in any order. 
(a)  Describe an example of a graph with 100 vertices, width 3, but average degree 
more than 5. Hint: Don’t get stuck on this; if you don’t see it after ﬁve minutes, ask 
for a hint. 

(b)  Prove that every graph with width at most w is (w + 1)-colorable. 

(c)  Prove that the average degree of a graph of width w is at most 2w . 

Exam Problems 

Problem 10.22. 
Recall that a coloring of a graph is an assignment of a color to each vertex such that 
no two adjacent vertices have the same color. A k-coloring is a coloring that uses at 
most k colors. 
False  Claim.  Let  G  be  a  graph  whose  vertex  degrees  are  all  ≤  k .  If  G  has  a  vertex  of 
degree strictly less than k , then G is k-colorable. 

(a)  Give a counterexample to the False Claim when k = 2. 

(b)  Underline  the exact sentence or part of a sentence where  the  following proof 
of the False Claim ﬁrst goes wrong: 

False proof.  Proof by induction on the number n of vertices:

Induction hypothesis:

P (n)::=  “Let G  be  an  n-vertex  graph whose  vertex degrees  are  all ≤  k .  If G  also

has a vertex of degree strictly less than k , then G is k-colorable.”

Base case: (n = 1) G has one vertex, the degree of which is 0. Since G is 1-colorable,

P (1) holds.

Inductive step:


198 

CHAPTER 10.  SIMPLE GRAPHS 

We may assume P (n).  To prove P (n + 1), let Gn+1  be a graph with n + 1 vertices 
whose vertex degrees are all k or less. Also, suppose Gn+1  has a vertex, v , of degree 
strictly less than k . Now we only need to prove that Gn+1  is k-colorable. 
To do this, ﬁrst remove the vertex v  to produce a graph, Gn , with n vertices.  Let u 
be a vertex that is adjacent to v  in Gn+1 .  Removing v  reduces the degree of u by 1. 
So  in Gn , vertex u has degree strictly  less  than k .  Since no edges were added,  the 
vertex degrees  of Gn  remain ≤  k .  So Gn  satisﬁes  the  conditions  of  the  induction 
hypothesis, P (n), and so we conclude that Gn  is k-colorable. 
Now  a  k-coloring  of  Gn  gives  a  coloring  of  all  the  vertices  of  Gn+1 ,  except  for 
v .  Since  v  has  degree  less  than  k ,  there  will  be  fewer  than  k  colors  assigned  to 
the nodes  adjacent  to  v .  So  among  the  k  possible  colors,  there will be  a  color not 
used  to  color  these  adjacent  nodes,  and  this  color  can  be  assigned  to  v  to  form  a 
� 
k-coloring of Gn+1 . 

(c)  With a slightly strengthened condition, the preceding proof of the False Claim 
could be revised into a sound proof of the following Claim: 
Claim.  Let G be a graph whose vertex degrees are all ≤ k .  If �statement inserted from below�
has a vertex of degree strictly less than k , then G is k-colorable. 

Circle each of the statements below that could be inserted to make the Claim true. 

•  G is connected and 

•  G has no vertex of degree zero and 

•  G does not contain a complete graph on k vertices and 

•  every connected component of G 

•  some connected component of G 

10.6  Bipartite Matchings 

10.6.1  Bipartite Graphs 

There were  two  kinds  of  vertices  in  the  “Sex  in America”  graph —males  and  fe­
males,  and edges only went between  the  two kinds.  Graphs  like  this  come up  so 
frequently they have earned a special name —they are called bipartite graphs. 

Deﬁnition 10.6.1.  A bipartite graph is a graph together with a partition of its vertices 
into  two  sets,  L  and R,  such  that  every  edge  is  incident  to  a  vertex  in L  and  to  a 
vertex in R. 

So every bipartite graph looks something like this: 

10.6.  BIPARTITE MATCHINGS 

199 

Now  we  can  immediately  see  how  to  color  a  bipartite  graph  using  only  two 
colors:  let all the L vertices be black and all the R vertices be white.  Conversely, if 
a graph is 2-colorable, then it is bipartite with L being the vertices of one color and 
R the vertices of the other color.  In other words, 

“bipartite” is a synonym for “2-colorable.” 

The following Lemma gives another useful characterization of bipartite graphs. 

Theorem 10.6.2.  A graph is bipartite iff it has no odd-length cycle. 

The proof of Theorem 10.6.2 is left to Problem 10.26. 

10.6.2  Bipartite Matchings 

The  bipartite  matching  problem  resembles  the  stable  Marriage  Problem  in  that  it 
concerns a set of girls and a set of at  least as many boys.  There are no preference 
lists, but each girl does have some boys she  likes and others she does not  like.  In 
the bipartite matching problem, we ask whether every girl can be paired up with a 
boy that she likes. Any particular matching problem can be speciﬁed by a bipartite 
graph with a vertex for each girl, a vertex for each boy, and an edge between a boy 
and  a  girl  iff  the  girl  likes  the  boy.  For  example,  we  might  obtain  the  following 
graph: 

200 

CHAPTER 10.  SIMPLE GRAPHS 

Now a matching will mean a way of assigning every girl to a boy so that differ­
ent girls are assigned  to different boys,  and a girl  is always assigned  to a boy she 
likes.  For example, here is one possible matching for the girls: 

Hall’s Matching Theorem states necessary and sufﬁcient conditions for the ex­
istence  of  a matching  in  a  bipartite  graph.  It  turns  out  to  be  a  remarkably  useful 
mathematical tool. 

10.6.3  The Matching Condition 
We’ll state and prove Hall’s Theorem using girl-likes-boy terminology.  Deﬁne the 
set  of  boys  liked  by  a  given  set  of  girls  to  consist  of  all  boys  liked  by  at  least  one  of 
those girls.  For example, the set of boys liked by Martha and Jane consists of Tom, 
Michael, and Mergatroid. For us to have any chance at all of matching up the girls, 
the following matching condition must hold: 

Every subset of girls likes at least as large a set of boys. 

MarthaAliceSarahJaneMergatroidChuckTomJohnMichaelMarthaAliceSarahJaneMergatroidChuckTomJohnMichael10.6.  BIPARTITE MATCHINGS 

201 

For example, we can not ﬁnd a matching if some 4 girls like only 3 boys. Hall’s 
Theorem  says  that  this  necessary  condition  is  actually  sufﬁcient;  if  the matching 
condition holds, then a matching exists. 

Theorem 10.6.3.  A matching for a set of girls G with a set of boys B  can be found if and 
only if the matching condition holds. 

Proof.  First,  let’s suppose that a matching exists and show that the matching con­
dition holds.  Consider an arbitrary subset of girls.  Each girl  likes at  least  the boy 
she is matched with.  Therefore, every subset of girls likes at least as large a set of 
boys. Thus, the matching condition holds. 
Next, let’s suppose that the matching condition holds and show that a matching 
exists. We use strong induction on |G|, the number of girls. 
Base Case: (|G|  = 1)  If  |G|  = 1,  then  the matching  condition  implies  that  the 
lone girl likes at least one boy, and so a matching exists. 
Inductive Step: Now suppose that |G| ≥ 2. There are two cases: 

Case 1:  Every proper subset of girls likes a strictly larger set of boys.  In this case, we 
have  some  latitude:  we pair  an  arbitrary girl with  a boy  she  likes  and  send 
them both away.  The matching  condition  still holds  for  the  remaining boys 
and girls, so we can match the rest of the girls by induction. 
Case 2:  Some  proper  subset  of  girls  X  ⊂  G  likes  an  equal-size  set  of  boys  Y  ⊂  B . 
We match  the girls  in X  with  the boys  in Y  by  induction and  send  them all 
away.  We  can  also match  the  rest  of  the  girls  by  induction  if we  show  that 
the matching condition holds for the remaining boys and girls.  To check the 
matching condition for the remaining people, consider an arbitrary subset of 
the  remaining  girls X �  ⊆  (G − X ),  and  let  Y �  be  the  set  of  remaining  boys 
that  they  like.  We must  show  that  |X � | ≤ |Y � |.  Originally,  the combined  set 
of girls X  ∪ X �  liked  the  set of boys Y  ∪ Y � .  So, by  the matching condition, 
we know: 
|X ∪ X � | ≤ |Y  ∪ Y � | 
We  sent  away  |X |  girls  from  the  set  on  the  left  (leaving X � )  and  sent  away 
an equal number of boys from the set on the right (leaving Y � ).  Therefore, it 
must be that |X � | ≤ |Y � | as claimed. 

So  there  is  in  any  case  a matching  for  the  girls,  which  completes  the  proof  of 
� 
the Inductive step. The theorem follows by induction. 

The proof of this theorem gives an algorithm for ﬁnding a matching in a bipar­
tite graph, albeit not a very efﬁcient one. However, efﬁcient algorithms for ﬁnding 
a  matching  in  a  bipartite  graph  do  exist.  Thus,  if  a  problem  can  be  reduced  to 
ﬁnding  a matching,  the  problem  is  essentially  solved  from  a  computational  per­
spective. 

202 

CHAPTER 10.  SIMPLE GRAPHS 

10.6.4  A Formal Statement 
Let’s  restate  Hall’s  Theorem  in  abstract  terms  so  that  you’ll  not  always  be  con­
demned to saying, “Now this group of little girls likes at least as many little boys...” 
A  matching  in  a  graph,  G,  is  a  set  of  edges  such  that  no  two  edges  in  the  set 
share a vertex.  A matching  is said  to cover a set, L, of vertices  iff each vertex  in L 
has an edge of the matching incident to it.  In any graph, the set N (S ), of neighbors6 
of some set, S , of vertices is the set of all vertices adjacent to some vertex in S . That 
is, 
N (S ) ::= {r  | s—r is an edge for some s ∈ S } . 
S  is called a bottleneck if 

|S | > |N (S )| . 
Theorem 10.6.4 (Hall’s Theorem).  Let G be a bipartite graph with vertex partition L, R. 
There is matching in G that covers L iff no subset of L is a bottleneck. 

An Easy Matching Condition 

The  bipartite  matching  condition  requires  that  every  subset  of  girls  has  a  certain 
property.  In general, verifying that every subset has some property, even if it’s easy 
to  check  any  particular  subset  for  the  property,  quickly  becomes  overwhelming 
because  the number of  subsets of even  relatively  small  sets  is enormous —over a 
billion  subsets  for  a  set  of  size  30.  However,  there  is  a  simple  property  of  vertex 
degrees  in  a  bipartite  graph  that  guarantees  a  match  and  is  very  easy  to  check. 
Namely, call a bipartite graph degree-constrained if vertex degrees on the left are at 
least as large as those on the right. More precisely, 

Deﬁnition 10.6.5.  A bipartite graph G with vertex partition L, R is degree-constrained 
if deg (l) ≥ deg (r) for every l ∈ L and r ∈ R. 
Now we can always ﬁnd a matching in a degree-constrained bipartite graph. 

Lemma  10.6.6.  Every  degree-constrained  bipartite  graph  satisiﬁes  the  matching  condi­
tion. 

Proof.  Let S  be  any  set of vertices  in L.  The number of  edges  incident  to vertices 
in S  is  exactly  the  sum  of  the degrees  of  the  vertices  in S .  Each  of  these  edges  is 
incident  to  a  vertex  in N (S )  by  deﬁnition  of N (S ).  So  the  sum  of  the  degrees  of 
the  vertices  in N (S )  is  at  least  as  large  as  the  sum  for  S .  But  since  the  degree  of 
every  vertex  in N (S )  is  at most  as  large  as  the  degree  of  every  vertex  in  S ,  there 
would have to be at  least as many terms  in the sum for N (S ) as  in the sum for S . 
So there have to be at least as many vertices in N (S ) as in S , proving that S  is not a 
bottleneck.  So there are no bottlenecks, proving that the degree-constrained graph 
� 
satisiﬁes the matching condition. 

6An  equivalent  deﬁnition  of  N (S )  uses  relational  notation:  N (S )  is  simply  the  image,  SR,  of  S 
under the adjacency relation, R, on vertices of the graph. 

10.6.  BIPARTITE MATCHINGS 

203 

Of course being degree-constrained is a very strong property, and lots of graphs 
that aren’t degree-constrained have matchings.  But we’ll see examples of degree-
constrained graphs come up naturally in some later applications. 

10.6.5  Problems 

Class Problems 

Problem 10.23. 
MIT  has  a  lot  of  student  clubs  loosely  overseen  by  the MIT  Student Association. 
Each eligible club would like to delegate one of its members to appeal to the Dean 
for funding, but the Dean will not allow a student to be the delegate of more than 
one  club.  Fortunately,  the  Association  VP  took  6.042  and  recognizes  a matching 
problem when she sees one. 
(a)  Explain how to model the delegate selection problem as a bipartite matching 
problem. 

(b)  The VP’s records show that no student is a member of more than 9 clubs. The 
VP  also  knows  that  to  be  eligible  for  support  from  the Dean’s  ofﬁce,  a  club must 
have  at  least  13  members.  That’s  enough  for  her  to  guarantee  there  is  a  proper 
delegate selection.  Explain.  (If only the VP had taken 6.046, Algorithms, she could 
even have found a delegate selection without much effort.) 

Problem 10.24. 
A  Latin  square  is  n ×  n  array  whose  entries  are  the  number  1, . . . , n.  These  en­
tries  satisfy  two constraints:  every  row contains all n  integers  in  some order,  and 
also  every  column  contains  all  n  integers  in  some  order.  Latin  squares  come  up 
frequently  in the design of scientiﬁc experiments for reasons  illustrated by a  little 
story in a footnote7 

7At Guinness  brewery  in  the  eary  1900’s, W.  S. Gosset  (a  chemist)  and  E.  S.  Beavan  (a  “maltster ”) 
were trying to improve the barley used to make the brew. The brewery used different varieties of barley 
according to price and availability, and their agricultural consultants suggested a different fertilizer mix 
and best planting month for each variety. 
Somewhat sceptical about paying high prices for customized fertilizer, Gosset and Beavan planned a 
season long test of the inﬂuence of fertilizer and planting month on barley yields.  For as many months 
as  there were varieties of barley,  they would plant one sample of each variety using a different one of 
the  fertilizers.  So every month,  they would have all  the barley varieties planted and all  the  fertilizers 
used, which would give them a way to judge the overall quality of that planting month.  But they also 
wanted  to  judge  the  fertilizers,  so  they  wanted  each  fertilizer  to  be  used  on  each  variety  during  the 
course of the season. Now they had a little mathematical problem, which we can abstract as follows. 
Suppose there are n barley varieties and an equal number of recommended fertilizers. Form an n × n 
array with a column for each fertilizer and a row for each planting month. We want to ﬁll in the entries 
of  this array with  the  integers 1,. . . ,n numbering  the barley varieties,  so  that  every  row  contains all n 
integers  in  some  order  (so  every month  each  variety  is  planted  and  each  fertilizer  is  used),  and  also 
every column contains all n integers (so each fertilizer is used on all the varieties over the course of the 
growing season). 

204 

CHAPTER 10.  SIMPLE GRAPHS 

For example, here is a 4 × 4 Latin square: 

1  2  3  4 
3  4  2  1 
2  1  4  3 
4  3  1  2 

(a)  Here are three rows of what could be part of a 5 × 5 Latin square: 

2  4  5  3  1 
4  1  3  2  5 
3  2  1  5  4 

Fill in the last two rows to extend this “Latin rectangle” to a complete Latin square. 
(b)  Show  that ﬁlling  in  the next  row  of  an n × n Latin  rectangle  is  equivalent  to 
ﬁnding a matching in some 2n-vertex bipartite graph. 

(c)  Prove  that a matching must exist  in  this bipartite graph and,  consequently,  a 
Latin rectangle can always be extended to a Latin square. 

Exam Problems 

Problem 10.25. 
Overworked  and  over-caffeinated,  the  TAs  decide  to  oust  Albert  and  teach  their 
own recitations.  They will run a recitation session at 4 different times in the same 
room. There are exactly 20 chairs to which a student can be assigned in each recita­
tion.  Each  student  has  provided  the  TAs with  a  list  of  the  recitation  sessions  her 
schedule  allows  and  no  student’s  schedule  conﬂicts with  all  4  sessions.  The  TAs 
must  assign  each  student  to  a  chair  during  recitation  at  a  time  she  can  attend,  if 
such an assignment is possible. 
(a)  Describe how to model this situation as a matching problem. Be sure to specify 
what  the  vertices/edges  should  be  and  brieﬂy  describe  how  a  matching  would 
determine  seat  assignments  for  each  student  in  a  recitation  that  does  not  conﬂict 
with his  schedule.  (This  is a modeling problem; we aren’t  looking  for a description 
of an algorithm to solve the problem.) 

(b)  Suppose  there  are  65  students.  Given  the  information  provided  above,  is  a 
matching guaranteed? Brieﬂy explain. 

10.6.  BIPARTITE MATCHINGS 

205 

Homework Problems 

Problem 10.26. 
In this problem you will prove: 

Theorem.  A graph G is 2-colorable iff it contains no odd length cycle. 

As  usual  with  “iff ”  assertions,  the  proof  splits  into  two  proofs:  part  (a)  asks 
you to prove that the left side of the “iff ” implies the right side. The other problem 
parts prove that the right side implies the left. 
(a)  Assume the left side and prove the right side.  Three to ﬁve sentences should 
sufﬁce. 

(b)  Now assume the right side. As a ﬁrst step toward proving the left side, explain 
why we can focus on a single connected component H within G. 

(c)  As a second step, explain how to 2-color any tree. 

(d)  Choose any 2-coloring of a spanning tree, T , of H . Prove that H  is 2-colorable 
by showing that any edge not in T  must also connect different-colored vertices. 

Problem 10.27. 
Take a regular deck of 52 cards. Each card has a suit and a value. The suit is one of 
four possibilities:  heart, diamond, club, spade.  The value is one of 13 possibilities, 
A, 2, 3, . . . , 10, J, Q, K .  There  is  exactly  one  card  for  each  of  the  4 ×  13  possible 
combinations of suit and value. 
Ask  your  friend  to  lay  the  cards  out  into  a  grid with  4  rows  and  13  columns. 
They can ﬁll the cards in any way they’d like.  In this problem you will show that 
you  can  always pick  out  13  cards,  one  from  each  column  of  the  grid,  so  that  you 
wind up with cards of all 13 possible values. 
(a)  Explain how to model this trick as a bipartite matching problem between the 
13 column vertices and the 13 value vertices.  Is the graph necessarily degree con­
strained? 

(b)  Show  that  any n  columns must  contain  at  least n different  values  and prove 
that a matching must exist. 

Problem 10.28. 
Scholars through the ages have identiﬁed twenty fundamental human virtues: hon­
esty, generosity, loyalty, prudence, completing the weekly course reading-response, 
etc.  At the beginning of the term, every student in 6.042 possessed exactly eight of 
these  virtues.  Furthermore,  every  student  was  unique;  that  is,  no  two  students 
possessed exactly the same set of virtues. The 6.042 course staff must select one ad­
ditional virtue to impart to each student by the end of the term. Prove that there is 

206 

CHAPTER 10.  SIMPLE GRAPHS 

a way to select an additional virtue for each student so that every student is unique 
at the end of the term as well. 
Suggestion:  Use Hall’s theorem.  Try various interpretations for the vertices on 
the left and right sides of your bipartite graph. 

Chapter 11 

Recursive Data Types 

Recursive data types play a central role in programming. From a mathematical point 
of view, recursive data types are what induction is about. Recursive data types are 
speciﬁed  by  recursive  deﬁnitions  that  say  how  to  build  something  from  its  parts. 
These deﬁnitions have two parts: 

•  Base case(s) that don’t depend on anything else. 

•  Constructor case(s) that depend on previous cases. 

11.1  Strings of Brackets 

Let brkts be  the set of all strings of square brackets.  For example,  the  following 
two strings are in brkts: 
[ ] ] [ [ [ [ [ ] ]  and  [ [ [ ] ] [ ] ] [ ] 

(11.1) 

Since we’re  just  starting  to  study  recursive  data,  just  for  practice we’ll  formulate 
brkts as a recursive data type, 

Deﬁnition  11.1.1.  The  data  type,  brkts,  of  strings  of  brackets  is  deﬁned  recur­
sively: 

•  Base case: The empty string, λ, is in brkts. 
•  Constructor case:  If s ∈ brkts, then s]  and s[  are in brkts. 
Here we’re writing s]  to  indicate the string that  is the sequence of brackets (if 
any) in the string s, followed by a right bracket; similarly for s[ . 
A  string,  s  ∈  brkts,  is  called  a  matched  string  if  its  brackets  “match  up”  in 
the usual way.  For example, the left hand string above is not matched because its 
second right bracket does not have a matching left bracket. The string on the right 
is matched. 

207 

208 

CHAPTER 11.  RECURSIVE DATA TYPES 

We’re going  to  examine  several different ways  to deﬁne  and prove properties 
of matched strings using recursively deﬁned sets and functions.  These properties 
are  pretty  straighforward,  and  you might wonder whether  they  have  any  partic­
ular  relevance  in  computer  scientist  —other  than  as  a  nonnumerical  example  of 
recursion.  The  honest  answer  is  “not much  relevance,  any more.”  The  reason  for 
this is one of the great successes of computer science. 

Expression Parsing 

During the early development of computer science in the 1950’s and 60’s, creation 
of effective programming language compilers was a central concern. A key aspect 
in processing a program for compilation was expression parsing. The problem was 
to take in an expression like 

x + y ∗ z 2  ÷ y + 7 

and put in the brackets that determined how it should be evaluated —should it be 
[[x + y ] ∗ z 2  ÷ y ] + 7,  or, 
x + [y ∗ z 2  ÷ [y + 7]],  or, 
[x + [y ∗ z 2 ]] ÷ [y + 7], 

or . . . ? 
The  Turing  award  (the  “Nobel  Prize”  of  computer  science)  was  ultimately  be­
stowed  on  Robert  Floyd,  for,  among  other  things,  being  discoverer  of  a  simple 
program that would insert the brackets properly. 
In  the  70’s  and  80’s,  this  parsing  technology  was  packaged  into  high-level 
compiler-compilers  that  automatically  generated  parsers  from  expression  gram­
mars. This automation of parsing was so effective that the subject needed no longer 
demanded attention.  It largely disappeared from the computer science curriculum 
by the 1990’s. 

One precise way to determine if a string is matched is to start with 0 and read 
the  string  from  left  to  right,  adding  1  to  the  count  for  each  left  bracket  and  sub­
tracting 1  from  the count  for each right bracket.  For example, here are  the counts 

11.1.  STRINGS OF BRACKETS 

209 

for the two strings above 
] 
[
]
0  −1
1

0

[
1

[ 
2 

0

[
3

[
0

]
2

[
1

]
1

[
2

[
2

[
3

]
1

[
4

]
0

]
3

[
1

]
2

]
1

] 
0 

] 
0 

A string has a good count if its running count never goes negative and ends with 0. 
So the second string above has a good count, but the ﬁrst one does not because its 
count went negative at the third step. 

Deﬁnition 11.1.2.  Let 
GoodCount ::= {s ∈ brkts  | s has a good count} . 
The  matched  strings  can  now  be  characterized  precisely  as  this  set  of  strings 
with good counts.  But  it  turns out  to be really useful  to characterize  the matched 
strings in another way as well, namely, as a recursive data type: 

Deﬁnition 11.1.3.  Recursively deﬁne the set, RecMatch, of strings as follows: 
•  Base case:  λ ∈ RecMatch. 
•  Constructor case:  If s, t ∈ RecMatch, then 
[ s ] t ∈ RecMatch. 

Here  we’re  writing  [ s ] t  to  indicate  the  string  that  starts  with  a  left  bracket, 
followed  by  the  sequence  of  brackets  (if  any)  in  the  string  s,  followed  by  a  right 
bracket, and ending with the sequence of brackets in the string t. 
Using this deﬁnition, we can see that λ ∈ RecMatch by the Base case, so 
[ λ] λ = [ ]  ∈ RecMatch 
by the Constructor case.  So now, 
[ λ] [ ]  = [ ] [ ]  ∈ RecMatch 
[ [ ] ] λ = [ [ ] ]  ∈ RecMatch 
[ [ ] ] [ ]  ∈ RecMatch 
are  also  strings  in  RecMatch  by  repeated  applications  of  the  Constructor  case.  If 
you  haven’t  seen  this  kind  of  deﬁnition  before,  you  should  try  continuing  this 
example to verify that [ [ [ ] ] [ ] ] [ ]  ∈ RecMatch 
Given the way this section is set up, you might guess that RecMatch = GoodCount, 
and  you’d  be  right,  but  it’s  not  completely  obvious.  The  proof  is  worked  out  in 
Problem 11.6. 

(letting s = λ, t = [ ] ) 
(letting s = [ ] , t = λ) 
(letting s = [ ] , t = [ ] ) 

210 

CHAPTER 11.  RECURSIVE DATA TYPES 

11.2  Arithmetic Expressions 

Expression evaluation is a key feature of programming languages, and recognition 
of expressions as a recursive data type is a key to understanding how they can be 
processed. 
To  illustrate  this  approach we’ll work with  a  toy  example:  arithmetic  expres­
sions like 3x2 + 2x + 1 involving only one variable, “x.” We’ll refer to the data type 
of such expressions as Aexp. Here is its deﬁnition: 

Deﬁnition 11.2.1. 

•  Base cases: 

1.  The variable, x, is in Aexp. 
2.  The arabic numeral, k, for any nonnegative integer, k , is in Aexp. 
•	 Constructor cases:  If e, f  ∈ Aexp, then 
3.	 (e + f ) ∈ Aexp. The expression (e + f ) is called a sum. The Aexp’s e and 
f  are called the components of the sum; they’re also called the summands. 
4.	 (e ∗ f )  ∈  Aexp.  The  expression  (e ∗ f )  is  called  a  product.  The Aexp’s 
e and f  are called the components of the product;  they’re also called the 
multiplier and multiplicand. 
5.	 −(e) ∈ Aexp. The expression −(e) is called a negative. 
Notice  that Aexp’s  are  fully  parenthesized,  and  exponents  aren’t  allowed.  So 
the  Aexp  version  of  the  polynomial  expression  3x2  + 2x + 1  would  ofﬁcially  be 
written as 
((3 ∗ (x ∗ x)) + ((2 ∗ x) + 1)).	
(11.2) 
These parentheses and ∗’s clutter up examples,  so we’ll often use simpler expres­
sions  like  “3x2  + 2x + 1”  instead  of  (11.2).  But  it’s  important  to  recognize  that 
3x2  + 2x + 1 is not an Aexp; it’s an abbreviation for an Aexp. 

11.3  Structural Induction on Recursive Data Types 

Structural induction is a method for proving some property, P , of all the elements 
of a recursively-deﬁned data type. The proof consists of two steps: 

•	 Prove P  for the base cases of the deﬁnition. 

•	 Prove P  for the constructor cases of the deﬁnition, assuming that it is true for 
the component data items. 

A  very  simple  application  of  structural  induction  proves  that  the  recursively 
deﬁned matched  strings  always have  an  equal number of  left  and  right brackets. 
To do this, deﬁne a predicate, P , on strings s ∈ brkts: 
P (s) ::=  s has an equal number of left and right brackets. 

11.3.  STRUCTURAL INDUCTION ON RECURSIVE DATA TYPES 

211 

Proof.  We’ll prove that P (s) holds for all s ∈ RecMatch by structural induction on 
the deﬁnition that s ∈ RecMatch, using P (s) as the induction hypothesis. 
Base  case:  P (λ)  holds  because  the  empty  string  has  zero  left  and  zero  right 
brackets. 
Constructor case: For r = [ s ] t, we must show that P (r) holds, given that P (s) 
and P (t) holds.  So let ns , nt  be, respectively, the number of left brackets in s and t. 
So the number of left brackets in r is 1 + ns  + nt . 
Now from the respective hypotheses P (s) and P (t), we know that the number 
of right brackets in s is ns , and likewise, the number of right brackets in t is nt .  So 
the number of right brackets  in r  is 1 + ns  + nt , which  is  the same as  the number 
of  left brackets.  This proves P (r).  We  conclude by  structural  induction  that P (s) 
holds for all s ∈ RecMatch. 
� 

11.3.1  Functions on Recursively-deﬁned Data Types 
Functions  on  recursively-deﬁned data  types  can  be deﬁned  recursively using  the 
same cases as the data type deﬁnition.  Namely, to deﬁne a function, f , on a recur­
sive data  type, deﬁne  the value of f  for  the base cases of  the data  type deﬁnition, 
and then deﬁne the value of f  in each constructor case in terms of the values of f 
on the component data items. 
For  example,  from  the  recursive  deﬁnition  of  the  set,  RecMatch,  of  strings  of 
matched brackets, we deﬁne: 
Deﬁnition 11.3.1.  The depth, d(s), of a string, s ∈ RecMatch, is deﬁned recursively 
by the rules: 
•  d(λ) ::= 0. 
•  d([ s ] t) ::= max {d(s) + 1, d(t)} 

Warning:  When  a  recursive  deﬁnition  of  a  data  type  allows  the  same  element  to 
be  constructed  in  more  than  one  way,  the  deﬁnition  is  said  to  be  ambiguous. A 
function deﬁned recursively from an ambiguous deﬁnition of a data type will not 
be well-deﬁned unless  the values  speciﬁed  for  the different ways  of  constructing 
the element agree. 

We were  careful  to  choose  an  unambiguous  deﬁnition  of  RecMatch  to  ensure 
that functions deﬁned recursively on the deﬁnition would always be well-deﬁned. 
As an example of the trouble an ambiguous deﬁnition can cause, let’s consider yet 
another deﬁnition of the matched strings. 
Example 11.3.2.  Deﬁne the set, M  ⊆ brkts recursively as follows: 
•  Base case:  λ ∈ M , 
•  Constructor cases:  if s, t ∈ M , then the strings [ s ]  and st are also in M . 

212 

CHAPTER 11.  RECURSIVE DATA TYPES 

Quick Exercise: Give an easy proof by structural induction that M  = RecMatch. 

Since  M  =  RecMatch,  and  the  deﬁnition  of  M  seems  more  straightforward, 
why didn’t we use it? Because the deﬁnition of M  is ambiguous, while the trickier 
deﬁnition of RecMatch is unambiguous.  Does this ambiguity matter?  Yes it does. 
For suppose we deﬁned 

f (λ) ::= 1, 
f ( [ s ]  ) ::= 1 + f (s), 
f (st) ::= (f (s) + 1) · (f (t) + 1) 
for st =� λ. 
Let  a be  the  string  [ [ ] ]  ∈  M  built by  two  successive  applications of  the ﬁrst 
M  constructor starting with λ. Next let b ::= aa and c ::= bb, each built by successive 
applications of the second M  constructor starting with a. 
Alternatively, we can build ba from the second constructor with s = b and t = a, 
and then get to c using the second constructor with s = ba and t = a. 
Now by  these rules, f (a) = 2, and f (b)  =  (2 + 1)(2 + 1)  =  9.  This means  that 
f (c) = f (bb) = (9 + 1)(9 + 1) = 100. 
But also f (ba) = (9+ 1)(2+ 1) = 27, so that f (c) = f (ba a) = (27+ 1)(2+ 1) = 84. 
The outcome is that f (c) is deﬁned to be both 100 and 84, which shows that the 
rules deﬁning f  are inconsistent. 
On  the  other  hand,  structural  induction  remains  a  sound  proof method  even 
for ambiguous recursive deﬁnitions, which  is why  it was easy  to prove  that M  = 
RecMatch. 

11.3.2  Recursive Functions on Nonnegative Integers 
The nonnegative integers can be understood as a recursive data type. 
Deﬁnition 11.3.3.  The set, N, is a data type deﬁned recursivly as: 
•  0 ∈ N. 
•  If n ∈ N, then the successor, n + 1, of n is in N. 
This of course makes it clear that ordinary induction is simply the special case 
of  structural  induction  on  the  recursive  Deﬁnition  11.3.3,  This  also  justiﬁes  the 
familiar  recursive  deﬁnitions  of  functions  on  the  nonnegative  integers.  Here  are 
some examples. 

The Factorial function.  This function is often written “n!.”  You will see a lot of it 
later in the term. Here we’ll use the notation fac(n): 

•  fac(0) ::= 1. 
•  fac(n + 1) ::= (n + 1)  fac(n) for n ≥ 0.
· 

11.3.  STRUCTURAL INDUCTION ON RECURSIVE DATA TYPES 

213 

The Fibonacci numbers.  Fibonacci  numbers  arose  out  of  an  effort  800  years  ago 
to  model  population  growth.  They  have  a  continuing  fan  club  of  people 
captivated by their extraordinary properties.  The nth Fibonacci number, ﬁb, 
can be deﬁned recursively by: 

ﬁb(0) ::= 0, 
ﬁb(1) ::= 1, 
ﬁb(n) ::= ﬁb(n − 1) + ﬁb(n − 2) 

for n ≥ 2. 

Here  the  recursive  step  starts  at  n  = 2 with  base  cases  for  0  and  1.  This  is 
needed since the recursion relies on two previous values. 
What is ﬁb(4)? Well, ﬁb(2) = ﬁb(1) + ﬁb(0) = 1, ﬁb(3) = ﬁb(2) + ﬁb(1) = 2, 
�
so ﬁb(4) = 3. The sequence starts out 0, 1, 1, 2, 3, 5, 8, 13, 21, . . . . 
n 
Sum-notation.  Let  “S (n)”  abbreviate  the  expression  “ 
=1 f (i).”  We  can  recur­
i
sively deﬁne S (n) with the rules 

•  S (0) ::= 0. 
•  S (n + 1) ::= f (n + 1) + S (n) for n ≥ 0. 

Ill-formed Function Deﬁnitions 

There  are  some  blunders  to  watch  out  for  when  deﬁning  functions  recursively. 
Below are some function speciﬁcations that resemble good deﬁnitions of functions 
on the nonnegative integers, but they aren’t. 

f1 (n) ::= 2 + f1 (n − 1). 

(11.3) 

This “deﬁnition” has no base case.  If some function, f1 , satisﬁed (11.3), so would a 
function obtained by adding a constant to the value of f1 .  So equation (11.3) does 
not uniquely deﬁne an f1 . 
� 
0, 
if n = 0,
f2 (n) ::= 
f2 (n + 1)  otherwise. 

(11.4)

This  “deﬁnition”  has  a  base  case,  but  still  doesn’t  uniquely  determine  f2 .  Any 
function that is 0 at 0 and constant everywhere else would satisfy the speciﬁcation, 
so (11.4) also does not uniquely deﬁne anything. 
In  a  typical  programming  language,  evaluation  of  f2 (1)  would  begin  with  a 
recursive call of f2 (2), which would lead to a recursive call of f2 (3), . . . with recur­
sive calls continuing without end. This “operational” approach interprets (11.4) as 
deﬁning a partial function, f2 , that is undeﬁned everywhere but 0. 

214 

CHAPTER 11.  RECURSIVE DATA TYPES 

⎧ ⎪⎨ ⎪⎩ 
0, 
if n is divisible by 2, 
f3 (n) ::= 
1, 
if n is divisible by 3, 
2,  otherwise. 
This  “deﬁnition”  is  inconsistent:  it  requires  f3 (6)  =  0  and  f3 (6)  =  1,  so  (11.5) 
doesn’t deﬁne anything. 

(11.5) 

A Mysterious Function 

⎧ ⎪⎨ ⎪⎩ 
Mathematicians have been wondering about this function speciﬁcation for a while: 
if n ≤ 1, 
1, 
f4 (n) ::= 
if n > 1 is even, 
f4 (n/2) 
f4 (3n + 1) 
if n > 1 is odd. 
For example, f4 (3) = 1 because 
f4 (3) ::= f4 (10) ::= f4 (5) ::= f4 (16) ::= f4 (8) ::= f4 (4) ::= f4 (2) ::= f4 (1) ::= 1. 

(11.6) 

The  constant  function  equal  to  1 will  satisfy  (11.6),  but  it’s  not  known  if  another 
function  does  too.  The  problem  is  that  the  third  case  speciﬁes  f4 (n)  in  terms  of 
f4  at  arguments  larger  than  n,  and  so  cannot  be  justiﬁed  by  induction  on  N.  It’s 
known that any f4  satisfying (11.6) equals 1 for all n up to over a billion. 
Quick exercise: Why does the constant function 1 satisfy (11.6)? 

11.3.3  Evaluation and Substitution with Aexp’s 
Evaluating Aexp’s 

Since  the  only  variable  in  an  Aexp  is  x,  the  value  of  an  Aexp  is  determined  by 
the value of x.  For  example,  if  the value  of x  is  3,  then  the value of  3x2  + 2x + 1 
is  obviously  34.  In  general,  given  any  Aexp,  e,  and  an  integer  value,  n,  for  the 
variable, x, we can evaluate e to ﬁnds  its value, eval(e, n).  It’s easy, and useful,  to 
specify this evaluation process with a recursive deﬁnition. 
Deﬁnition  11.3.4.  The  evaluation  function,  eval  :  Aexp × Z  →  Z,  is deﬁned  recur­
sively on expressions, e ∈ Aexp, as follows. Let n be any integer. 

•  Base cases: 

1.  Case[e is x]


eval(x, n) ::= n.


(The value of the variable, x, is given to be n.) 

11.3.  STRUCTURAL INDUCTION ON RECURSIVE DATA TYPES 

215 

2.  Case[e is k]


eval(k, n) ::= k .


(The value of the numeral k is the integer k , no matter what value x has.) 

•  Constructor cases: 

3.  Case[e is (e1  + e2 )] 

eval((e1  + e2 ), n) ::= eval(e1 , n) + eval(e2 , n). 
4.  Case[e is (e1  ∗ e2 )] 
eval((e1  ∗ e2 ), n) ::= eval(e1 , n)  eval(e2 , n).
· 
5.  Case[e is −(e1 )]


eval(−(e1 ), n) ::= − eval(e1 , n). 


For  example,  here’s  how  the  recursive  deﬁnition  of  eval  would  arrive  at  the 
value of 3 + x2  when x is 2: 
eval((3 + (x ∗ x)), 2) = eval(3, 2) + eval((x ∗ x), 2) 
= 3 + eval((x ∗ x), 2) 
· 
= 3 + (eval(x, 2)  eval(x, 2)) 
· 
= 3 + (2  2) 
= 3 + 4 = 7. 

(by Def 11.3.4.3) 
(by Def 11.3.4.2) 
(by Def 11.3.4.4)
(by Def 11.3.4.1)

Substituting into Aexp’s 

Substituting expressions  for variables  is a  standard,  important operation.  For ex­
ample the result of substituting the expression 3x for x in the (x(x − 1)) would be 
(3x(3x − 1). We’ll use the general notation subst(f , e) for the result of substituting 
an Aexp, f , for each of the x’s in an Aexp, e.  For instance, 
subst(3x, x(x − 1)) = 3x(3x − 1). 

This substitution function has a simple recursive deﬁnition: 
Deﬁnition 11.3.5.  The  substitution  function  from Aexp × Aexp  to Aexp  is deﬁned 
recursively on expressions, e ∈ Aexp, as follows. Let f  be any Aexp. 

•  Base cases: 

1.  Case[e is x]


subst(f , x) ::= f .


(The result of substituting f  for the variable, x, is just f .) 

216 

CHAPTER 11.  RECURSIVE DATA TYPES 

2.  Case[e is k]


subst(f , k) ::= k.


(The numeral, k, has no x’s in it to substitute for.) 

•  Constructor cases: 

3.  Case[e is (e1  + e2 )] 

subst(f , (e1  + e2 ))) ::= (subst(f , e1 ) + subst(f , e2 )). 
4.  Case[e is (e1  ∗ e2 )] 
subst(f , (e1  ∗ e2 ))) ::= (subst(f , e1 ) ∗ subst(f , e2 )). 
5.  Case[e is −(e1 )] 

subst(f , −(e1 )) ::= −(subst(f , e1 )). 

Here’s how the recursive deﬁnition of the substitution function would ﬁnd the 
result of substituting 3x for x in the x(x − 1): 
subst(3x, (x(x − 1))) = subst(3x, (x ∗ (x + −(1)))) 
(unabbreviating) 
= (subst(3x, x) ∗ subst(3x, (x + −(1)))) 
(by Def 11.3.5 4) 
= (3x ∗ subst(3x, (x + −(1)))) 
(by Def 11.3.5 1) 
= (3x ∗ (subst(3x, x) + subst(3x, −(1)))) 
(by Def 11.3.5 3) 
= (3x ∗ (3x + −(subst(3x, 1)))) 
(by Def 11.3.5 1 & 5) 
= (3x ∗ (3x + −(1))) 
(by Def 11.3.5 2) 
= 3x(3x − 1) 
(abbreviation) 
Now  suppose we  have  to  ﬁnd  the  value  of  subst(3x, (x(x − 1))) when  x  = 2. 
There are two approaches. 
First, we  could  actually do  the  substitution  above  to  get  3x(3x − 1),  and  then 
we  could evaluate 3x(3x − 1) when x  = 2,  that  is, we  could  recursively  calculate 
eval(3x(3x − 1), 2)  to  get  the  ﬁnal  value  30.  In  programming  jargon,  this  would 
be  called  evaluation  using  the  Substitution  Model.  Tracing  through  the  steps  in 
the evaluation, we ﬁnd that the Substitution Model requires two substitutions for 
occurrences of x and 5  integer operations:  3  integer multiplications,  1  integer ad­
dition, and 1  integer negative operation.  Note  that  in  this Substitution Model  the 
· 
multiplication  3 2 was performed  twice  to get  the value of  6  for  each of  the  two 
occurrences of 3x. 
The other approach is called evaluation using the Environment Model.  Namely, 
we evaluate 3x when x = 2 using just 1 multiplication to get the value 6.  Then we 
evaluate x(x − 1) when x has  this value 6  to arrive at  the value 6  5 = 30.  So  the 
· 
Environment Model  requires  2  variable  lookups  and  only  4  integer  operations:  1 

11.3.  STRUCTURAL INDUCTION ON RECURSIVE DATA TYPES 

217 

· 
multiplication to ﬁnd the value of 3x, another multiplication to ﬁnd the value 6 5,
along with 1 integer addition and 1 integer negative operation. 
So the Environment Model approach of calculating 
eval(x(x − 1), eval(3x, 2)) 

instead of the Substitution Model approach of calculating 
eval(subst(3x, x(x − 1)), 2) 

is  faster.  But  how  do  we  know  that  these  ﬁnal  values  reached  by  these  two  ap­
proaches  always  agree?  We  can  prove  this  easily  by  structural  induction  on  the 
deﬁnitions of the two approaches. More precisely, what we want to prove is 
Theorem 11.3.6.  For all expressions e, f  ∈ Aexp and n ∈ Z, 

eval(subst(f , e), n) = eval(e, eval(f , n)). 

(11.7) 

Proof.  The proof is by structural induction on e.1 
Base cases: 

•  Case[e is x] 
The  left  hand  side  of  equation  (11.7)  equals  eval(f , n)  by  this  base  case  in 
Deﬁnition  11.3.5  of  the  substitution  function,  and  the  right  hand  side  also 
equals eval(f , n) by this base case in Deﬁnition 11.3.4 of eval. 

•  Case[e is k]. 
The  left  hand  side  of  equation  (11.7)  equals  k  by  this  base  case  in  Deﬁni­
tions 11.3.5 and 11.3.4 of the substitution and evaluation functions. Likewise, 
the right hand side equals k by two applications of this base case in the Deﬁ­
nition 11.3.4 of eval. 

Constructor cases: 

•  Case[e is (e1  + e2 )] 
By  the  structural  induction  hypothesis  (11.7),  we  may  assume  that  for  all 
f  ∈ Aexp and n ∈ Z, 

eval(subst(f , ei ), n) = eval(ei , eval(f , n)) 
for i = 1, 2. We wish to prove that 

(11.8) 

eval(subst(f , (e1  + e2 )), n) = eval((e1  + e2 ), eval(f , n)) 

(11.9) 

1 This  is  an  example  of why  it’s  useful  to  notify  the  reader what  the  induction  variable  is—in  this 
case it isn’t n. 

218 

CHAPTER 11.  RECURSIVE DATA TYPES 

But the left hand side of (11.9) equals 
eval( (subst(f , e1 ) + subst(f , e2 )), n) 
by Deﬁnition 11.3.5.3 of substitution into a sum expression. But this equals 
eval(subst(f , e1 ), n) + eval(subst(f , e2 ), n) 
by  Deﬁnition  11.3.4.3  of  eval  for  a  sum  expression.  By  induction  hypothe­
sis (11.8), this in turn equals 
eval(e1 , eval(f , n)) + eval(e2 , eval(f , n)). 
Finally,  this  last  expression  equals  the  right  hand  side  of  (11.9)  by  Deﬁni­
tion 11.3.4.3 of eval for a sum expression. This proves (11.9) in this case. 
•  e is (e1  ∗ e2 ).  Similar. 
•  e is −(e1 ). Even easier. 
This covers all  the constructor cases,  and  so completes  the proof by  structural 
induction. 
� 

11.3.4  Problems 
Practice Problems 

Problem 11.1. 

Deﬁnition.  Consider a new recursive deﬁnition, MB0 , of the same set of “match­
ing” brackets strings as MB  (deﬁnition of MB  is provided in the Appendix): 
•  Base case:  λ ∈ MB0 . 
•  Constructor cases: 
(i)  If s is in MB0 , then [s] is in MB0 . 
(ii)  If s, t ∈ MB0 , s =� λ, and t =� λ, then st is in MB0 . 
(a)  Suppose  structural  induction was being used  to prove  that MB0  ⊆  MB .  Cir­
cle  the  one  predicate  below  that  would  ﬁt  the  format  for  a  structural  induction 
hypothesis in such a proof. 
•  P0 (n) ::= |s| ≤ n IM P L I E S  s ∈ MB . 
•  P1 (n) ::= |s| ≤ n IM P L I E S  s ∈ MB0 . 
•  P2 (s) ::= s ∈ MB . 
•  P3 (s) ::= s ∈ MB0 . 
•  P4 (s) ::=  (s ∈ MB  IM P L I E S  s ∈ MB0 ). 
(b)  The recursive deﬁnition MB0  is ambiguous.  Verify this by giving two different 
derivations for the string ”[ ][ ][ ]” according to MB0 . 

11.3.  STRUCTURAL INDUCTION ON RECURSIVE DATA TYPES 

219 

Class Problems 

Problem 11.2. 
The Elementary 18.01 Functions (F18’s) are the set of functions of one real variable 
deﬁned recursively as follows: 
Base cases: 
•	 The identity function, id(x) ::= x is an F18, 
•	 any constant function is an F18, 
•	 the sine function is an F18, 
Constructor cases: 
If f , g are F18’s, then so are 
1.	 f  + g , f g , eg  (the constant e), 
2.  the inverse function f (−1) , 
g .◦ 
3.  the composition f
(a)  Prove that the function 1/x is an F18. 
Warning: Don’t confuse 1/x = x−1  with the inverse, id(−1)  of the identity function 
id(x). The inverse id(−1)  is equal to id. 
(b)  Prove  by  Structural  Induction  on  this  deﬁnition  that  the  Elementary  18.01 
Functions  are  closed  under  taking  derivatives.  That  is,  show  that  if  f (x)  is  an  F18, 
then  so  is  f �  ::= df /dx.  (Just  work  out  2  or  3  of  the most  interesting  constructor 
cases; you may skip the less interesting ones.) 

Problem 11.3. 
Here is a simple recursive deﬁnition of the set, E , of even integers: 
Deﬁnition.  Base case:  0 ∈ E . 
Constructor cases:  If n ∈ E , then so are n + 2 and −n. 
�	
� 
Provide similar simple recursive deﬁnitions of the following sets: 
�	
� 
(a)  The set S  ::=  2k 3m 5n  | k , m, n ∈ N  . 
�	
� 
(b)  The set T  ::=  2k 32k+m5m+n  | k , m, n ∈ N  . 
(c)	 The set L ::=  (a, b) ∈ Z2  | 3  | (a − b)  . 
Let L�  be  the set deﬁned by  the recursive deﬁnition you gave  for L  in  the pre­
vious part.  Now  if you did  it right,  then L�  =  L, but maybe you made a mistake. 
So let’s check that you got the deﬁnition right. 
(d)  Prove by structural induction on your deﬁnition of L�  that 
L�  ⊆ L. 

220 

CHAPTER 11.  RECURSIVE DATA TYPES 

(e)  Conﬁrm that you got the deﬁnition right by proving that 
L ⊆ L� . 

(f)  See if you can give an unambiguous recursive deﬁnition of L. 

Problem 11.4.

Let p be the string [ ] . A string of brackets is said to be erasable iff it can be reduced

to  the  empty  string  by  repeatedly  erasing  occurrences  of  p.  For  example,  here’s

how to erase the string [ [ [ ] ] [ ] ] [ ] :

→ → 
→ 
[ ] 
[ [ ] ] 
[ [ [ ] ] [ ] ] [ ] 
On the other hand the string [ ] ] [ [ [ [ [ ] ]  is not erasable because when we try to 
erase, we get stuck: 

λ.

[ ] ] [ [ [ [ [ ] ]  → ] [ [ [ [ ]  → ] [ [ [  �→ 
Let  Erasable  be  the  set  of  erasable  strings  of  brackets.  Let  RecMatch  be  the 
recursive data type of strings of matched brackets given in Deﬁnition 11.3.7. 
(a)  Use structural induction to prove that 
RecMatch ⊆ Erasable. 

(b)  Supply the missing parts of the following proof that 
Erasable ⊆ RecMatch. 
Proof.  We  prove  by  induction  on  the  length,  n,  of  strings,  x,  that  if  x  ∈  Erasable, 
then x ∈ RecMatch. The induction predicate is 
P (n) ::= ∀x ∈ Erasable. (|x| ≤ n  IM P L I E S  x ∈ RecMatch) 

Base case: 
What is the base case? Prove that P  is true in this case. 
Inductive step: To prove P (n + 1), suppose |x ≤ n + 1 and x ∈ Erasable. We need 
|
only show that x  ∈  RecMatch.  Now if |x| < n 
+ 1, then the induction hypothesis, 
P (n), implies that x ∈ RecMatch, so we only have to deal with x of length exactly 
n + 1. 
Let’s say that a string y  is an erase of a string z  iff y  is the result of erasing a single 
occurrence of p in z . 
Since x ∈ Erasable and has positive length, there must be an erase, y ∈ Erasable, of 
x.  So  y = n − 1, and since y ∈ Erasable, we may assume by induction hypothesis 
|
| 
∈
RecMatch. 
that y

11.3.  STRUCTURAL INDUCTION ON RECURSIVE DATA TYPES 

221 

Now we argue by cases:

Case (y  is the empty string).

Prove that x ∈ RecMatch in this case.

Case (y = [ s ] t for some strings s, t ∈ RecMatch.) Now we argue by subcases.

•	 Subcase (x is of the form [ s�  ] t where s is an erase of s� ). 
Since s ∈ RecMatch, it is erasable by part (b), which implies that s�  ∈ Erasable. 
But |s� | < |x|, so by induction hypothesis, we may assume that s�  ∈ RecMatch. 
This shows that x is the result of the constructor step of RecMatch, and there­
fore x ∈ RecMatch. 
•	 Subcase (x is of the form [ s ] t�  where t is an erase of t� ).

Prove that x ∈ RecMatch in this subcase.

•	 Subcase(x = p[ s ] t).

Prove that x ∈ RecMatch in this subcase.

The proofs of the remaining subcases are just like this last one.  List these remain­
ing subcases. 
This completes the proof by induction on n, so we conclude that P (n) holds for all 
n ∈ N. Therefore x ∈ RecMatch for every string x ∈ Erasable. That is, 
Erasable ⊆ RecMatch and hence Erasable = RecMatch. 

� 

Problem 11.5. 

Deﬁnition.  The  recursive data  type,  binary-2PTG,  of  binary  trees with  leaf  labels, 
L, is deﬁned recursively as follows: 
•	 Base case:  �leaf, l� ∈ binary-2PTG, for all labels l ∈ L. 
•	 Constructor case:  If G1 , G2  ∈ binary-2PTG, then 
�bintree, G1 , G2 � ∈ binary-2PTG. 
The size, |G|, of G ∈ binary-2PTG is deﬁned recursively on this deﬁnition by: 
•	 Base case:


|�leaf, l�| ::= 1, 

for all l ∈ L.


•	 Constructor case: 

|�bintree, G1 , G2 �| ::= |G1 | + |G2 | + 1. 

222 

CHAPTER 11.  RECURSIVE DATA TYPES 

Figure 11.1: A picture of a binary tree w . 

For example, for the size of the binary-2PTG, G, pictured in Figure 11.1, is 7. 
(a)  Write out (using angle brackets and labels bintree, leaf, etc.)  the binary-2PTG, 
G, pictured in Figure 11.1. 
The  value  of  ﬂatten(G)  for G  ∈  binary-2PTG  is  the  sequence  of  labels  in L  of 
the leaves of G.  For example, for the binary-2PTG, G, pictured in Figure 11.1, 

ﬂatten(G) = (win, lose, win, win). 

(b)  Give a recursive deﬁnition of ﬂatten.  (You may use the operation of concatena­
tion (append) of two sequences.) 

(c)  Prove by structural induction on the deﬁnitions of ﬂatten and size that 
2 · length(ﬂatten(G)) = |G| + 1. 

(11.10) 

Homework Problems 

Problem 11.6. 

Deﬁnition  11.3.7.  The  set,  RecMatch,  of  strings  of matching  brackets,  is  deﬁned 
recursively as follows: 
•  Base case:  λ ∈ RecMatch. 

GG11winG1,2winlosewin11.4.  GAMES AS A RECURSIVE DATA TYPE 

223 

•	 Constructor case:  If s, t ∈ RecMatch, then 
[ s ] t ∈ RecMatch. 

There is a simple test to determine whether a string of brackets is in RecMatch: 
starting with zero, read the string from left to right adding one for each left bracket 
and -1 for each right bracket.  A string has a good count when the count never goes 
negative and is back to zero by the end of the string. Let GoodCount be the bracket 
strings with good counts. 
(a)  Prove that GoodCount contains RecMatch by structural induction on the def­
inition of RecMatch. 

(b)  Conversely, prove that RecMatch contains GoodCount. 

Problem 11.7. 
Fractals  are  example  of  a mathematical  object  that  can  be  deﬁned  recursively.  In 
this problem, we  consider  the Koch  snowﬂake.  Any Koch  snowﬂake  can be  con­
structed by the following recursive deﬁnition. 
•	 Base  Case:  An  equilateral  triangle  with  a  positive  integer  side  length  is  a 
Koch snowﬂake. 

•	 Recursive  case:  Let K  be  a  Koch  snowﬂake,  and  let  l  be  a  line  segment  on 
the  snowﬂake.  Remove  the  middle  third  of  l,  and  replace  it  with  two  line 
segments of the same length as is done below: 

The resulting ﬁgure is also a Koch snowﬂake. 
√
Prove by structural induction that the area inside any Koch snowﬂake is of the 
3, where q  is a rational number. 
form q

11.4  Games as a Recursive Data Type 

Chess,  Checkers,  and  Tic-Tac-Toe  are  examples  of  two-person  terminating  games  of 
perfect  information, —2PTG’s  for  short.  These  are  games  in which  two  players  al­
ternate moves that depend only on the visible board position or state of the game. 
“Perfect information” means that the players know the complete state of the game 
at each move.  (Most card games are not games of perfect information because nei­
ther player can see the other ’s hand.)  “Terminating” means that play cannot go on 
forever —it must end after a ﬁnite number of moves.2 
2 Since board positions can repeat in chess and checkers, termination is enforced by rules that prevent 
any position from being repeated more  than a ﬁxed number of  times.  So  the “state” of  these games  is 
the board position plus a record of how many times positions have been reached. 

224 

CHAPTER 11.  RECURSIVE DATA TYPES 

We will deﬁne 2PTG’s as a recursive data type.  To see how this will work, let’s 
use the game of Tic-Tac-Toe as an example. 

11.4.1  Tic-Tac-Toe 
Tic-Tac-Toe  is  a  game  for  young  children.  There  are  two  players who  alternately 
write  the  letters  “X” and “O”  in  the  empty boxes of a 3 × 3 grid.  Three  copies of 
the  same  letter ﬁlling a  row,  column,  or diagonal of  the grid  is  called a  tic-tac-toe, 
and the ﬁrst player who gets a tic-tac-toe of their letter wins the game. 
We’re now going give a precise mathematical deﬁnition of the Tic-Tac-Toe game 
tree as a recursive data type. 
Here’s  the  idea  behind  the  deﬁnition:  at  any  point  in  the  game,  the  “board 
position” is the pattern of X’s and O’s on the 3 × 3 grid. From any such Tic-Tac-Toe 
pattern,  there  are  a  number  of  next  patterns  that might  result  from  a move.  For 
example,  from  the  initial  empty  grid,  there  are  nine  possible  next  patterns,  each 
with a single X in some grid cell and the other eight cells empty. From any of these 
patterns, there are eight possible next patterns gotten by placing an O in an empty 
cell.  These move possibilities are given by the game tree for Tic-Tac-Toe indicated 
in Figure 11.2. 
Deﬁnition 11.4.1.  A Tic-Tac-Toe pattern is a 3× 3 grid each of whose 9 cells contains 
either the single letter, X, the single letter, O, or is empty. 
A  pattern,  Q,  is  a  possible  next  pattern  after  P ,  providing  P  has  no  tic-tac-toes 
and 

•	 if P  has an equal number of X’s and O’s, and Q is the same as P  except that 
a cell that was empty in P  has an X in Q, or 

•	 if P  has one more X  than O’s,  and Q  is  the same as P  except  that a cell  that 
was empty in P  has an O in Q. 

If  P  is  a  Tic-Tac-Toe  pattern,  and  P  has  no  next  patterns,  then  the  terminated 
Tic-Tac-Toe game trees at P  are 
•	 �P , �win��, if P  has a tic-tac-toe of X’s. 
•	 �P , �lose��, if P  has a tic-tac-toe of O’s. 
•	 �P , �tie��, otherwise. 

The Tic-Tac-Toe game trees starting at P  are deﬁned recursively: 
Base Case:  A terminated Tic-Tac-Toe game tree at P  is a Tic-Tac-Toe game tree 
starting at P . 
Constructor  case:  If  P  is  a  non-terminated  Tic-Tac-Toe  pattern,  then  the  Tic-
Tac-Toe game tree starting at P  consists of P  and the set of all game trees starting 
at possible next patterns after P . 

11.4.  GAMES AS A RECURSIVE DATA TYPE 

225 

Figure 11.2: The Top of the Game Tree for Tic-Tac-Toe. 

XXXXXXXXXXXXO…XOX(cid:36)(cid:37)(cid:36)(cid:37)O…OO(cid:36)O(cid:37)X(cid:36)X(cid:37)X226 

CHAPTER 11.  RECURSIVE DATA TYPES 

For example, if 

P0  = 

Q1  = 

Q2  = 

R = 

X 
O 

O 
X 

X 
O 

O 
X 
X 
O 
O 
X 
X 
X 
O 
O  X  O 
X  O  X 
X  O 
O  X  O 
X  O  X 
X  O  X 

the game tree starting at P0  is pictured in Figure 11.3. 

Figure 11.3: Game Tree for the Tic-Tac-Toe game starting at P0 . 

Game trees are usually pictured in this way with the starting pattern (referred 

OXXXXOOOXOOXOOXOXXOOO<lose>XOOXXXXOXOXOXXOOOX<tie>XX11.4.  GAMES AS A RECURSIVE DATA TYPE 

227 

to as the “root” of the tree) at the top and lines connecting the root to the game trees 
that start at each possible next pattern. The “leaves” at the bottom of the tree (trees 
grow upside down in computer science) correspond to terminated games.  A path 
from the root to a leaf describes a complete play of the game.  (In English, “game” 
can  be  used  in  two  senses:  ﬁrst we  can  say  that Chess  is  a  game,  and  second we 
can  play  a  game  of  Chess.  The  ﬁrst  usage  refers  to  the  data  type  of  Chess  game 
trees, and the second usage refers to a “play.”) 

11.4.2  Inﬁnite Tic-Tac-Toe Games 
At any point  in a Tic-Tac-Toe game,  there are at most nine possible next patterns, 
and no play can continue  for more  than nine moves.  But we can expand Tic-Tac-
Toe  into  a  larger  game  by  running  a  5-game  tournament:  play  Tic-Tac-Toe  ﬁve 
times  and  the  tournament  winner  is  the  player  who  wins  the  most  individual 
games. A 5-game tournament can run for as many as 45 moves. 
It’s  not much  of  generalization  to  have  an  n-game  Tic-Tac-Toe  tournament.  But 
then comes a generalization that sounds simple but can be mind-boggling:  consol­
idate all these different size tournaments into a single game we can call Tournament-
Tic-Tac-Toe (T 4 ).  The ﬁrst player in a game of T 4  chooses any integer n >  0.  Then 
the  players  play  an  n-game  tournament.  Now we  can  no  longer  say  how  long  a 
T 4  play can  take.  In  fact,  there are T 4  plays  that  last as  long as you might  like:  if 
you want  a game  that has  a play with,  say,  nine billion moves,  just have  the ﬁrst 
player  choose n  equal  to  one  billion.  This  should make  it  clear  the  game  tree  for 
T 4  is inﬁnite. 
But still, it’s obvious that every possible T 4  play will stop.  That’s because after 
the  ﬁrst  player  chooses  a  value  for  n,  the  game  can’t  continue  for  more  than  9n 
moves.  So  it’s  not possible  to  keep playing  forever  even  though  the  game  tree  is 
inﬁnite. 
This isn’t very hard to understand, but there is an important difference between 
any given n-game tournament and T 4 : even though every play of T 4  must come to 
an end, there is no longer any initial bound on how many moves it might be before 
the game ends —a play might end after 9 moves, or 9(2001) moves, or 9(1010  + 1) 
moves.  It just can’t continue forever. 
Now that we recognize T 4  as a 2PTG, we can go on to a meta-T 4  game, where 
the ﬁrst player chooses a number, m > 0, of T 4  games to play, and then the second 
player gets the ﬁrst move in each of the individual T 4  games to be played. 
Then, of course, there’s meta-meta-T 4 . . . . 

11.4.3  Two Person Terminating Games 
Familiar  games  like  Tic-Tac-Toe,  Checkers,  and  Chess  can  all  end  in  ties,  but  for 
simplicity we’ll only consider win/lose games —no “everybody wins”-type games 
at MIT. :-).  But everything we show about win/lose games will extend easily to 
games with  ties,  and more  generally  to  games with  outcomes  that  have different 
payoffs. 

228 

CHAPTER 11.  RECURSIVE DATA TYPES 

Like Tic-Tac-Toe, or Tournament-Tic-Tac-Toe,  the  idea behind  the deﬁnition of 
2PTG’s as a recursive data type is that making a move in a 2PTG leads to the start 
of a subgame.  In other words, given any set of games, we can make a new game 
whose ﬁrst move is to pick a game to play from the set. 
So what  deﬁnes  a  game?  For  Tic-Tac-Toe,  we  used  the  patterns  and  the  rules 
of Tic-Tac-Toe to determine the next patterns.  But once we have a complete game 
tree, we don’t really need the pattern labels:  the root of a game tree itself can play 
the role of a “board position” with its possible “next positions” determined by the 
roots  of  its  subtrees.  So  any  game  is  deﬁned  by  its  game  tree.  This  leads  to  the 
following very simple —perhaps deceptively simple —general deﬁnition. 

Deﬁnition  11.4.2.  The  2PTG,  game  trees  for  two-person  terminating  games  of  perfect 
information are deﬁned recursively as follows: 

•  Base cases: 

�leaf, win�
∈ 2PTG,  and 
�leaf, lose� ∈ 2PTG. 
•  Constructor case:  If G  is a nonempty set of 2PTG’s, then G is a 2PTG, where 
G ::= �tree, G � . 
The game trees in G  are called the possible next moves from G. 
These  games  are  called  “terminating”  because,  even  though  a  2PTG  may  be 
a  (very)  inﬁnite datum  like Tournament2 -Tic-Tac-Toe,  every play of  a  2PTG must 
terminate.  This is something we can now prove, after we give a precise deﬁnition 
of “play”: 

Deﬁnition 11.4.3.  A play of a 2PTG, G, is a (potentially inﬁnite) sequence of 2PTG’s 
starting with G and such that if G1  and G2  are consecutive 2PTG’s in the play, then 
G2  is a possible next move of G1 . 
If a 2PTG has no inﬁnite play, it is called a terminating game. 

Theorem 11.4.4.  Every 2PTG is terminating. 

Proof.  By  structural  induction  on  the deﬁnition  of  a  2PTG, G, with  induction  hy­
pothesis 

G is terminating. 
Base case:  If G = �leaf, win� or G = �leaf, lose� then the only possible play 
of G is the length one sequence consisting of G. Hence G terminates. 
Constructor  case:  For  G  =  �tree, G �,  we  must  show  that  G  is  terminating, 
given the Induction Hypothesis that every G�  ∈ G  is terminating. 
But any play of G is, by deﬁnition, a sequence starting with G and followed by 
a play starting with some G0  ∈ G .  But G0  is terminating, so the play starting at G0 
is ﬁnite, and hence so is the play starting at G. 
This completes the structural  induction, proving that every 2PTG, G,  is termi­
� 
nating. 

11.4.  GAMES AS A RECURSIVE DATA TYPE 

229 

11.4.4  Game Strategies 
A key question about a game is whether a player has a winning strategy. A strategy 
for a player  in a game speciﬁes which move  the player should make at any point 
in  the game.  A winning  strategy  ensures  that  the player will win no matter what 
moves the other player makes. 
In Tic-Tac-Toe  for example, most elementary  school  children ﬁgure out  strate­
gies for both players that each ensure that the game ends with no tic-tac-toes, that 
is,  it  ends  in  a  tie.  Of  course  the ﬁrst player  can win  if his  opponent plays  child­
ishly, but not if the second player follows the proper strategy.  In more complicated 
games like Checkers or Chess, it’s not immediately clear that anyone has a winning 
strategy, even if we agreed to count ties as wins for the second player. 
But structural induction makes it easy to prove that in any 2PTG, somebody has 
the winning strategy! 
Theorem  11.4.5.  Fundamental  Theorem  for  Two-Person  Games:  For  every  two-
person  terminating  game  of  perfect  information,  there  is  a  winning  strategy  for  one  of 
the players. 
Proof.  The  proof  is  by  structural  induction  on  the  deﬁnition  of  a  2PTG,  G.  The 
induction hypothesis is that there is a winning strategy for G. 
Base cases: 
1.	 G =  �leaf, win�.  Then the ﬁrst player has the winning strategy:  “make the 
winning move.” 
2.	 G =  �leaf, lose�.  Then the second player has a winning strategy:  “Let the 
ﬁrst player make the losing move.” 
Constructor  case:  Suppose  G  =  �tree, G �.  By  structural  induction,  we may 
assume  that  some  player  has  a winning  strategy  for  each G�  ∈ G .  There  are  two 
cases to consider: 
•	 some  G0  ∈ G  has  a  winning  strategy  for  its  second  player.  Then  the  ﬁrst 
player  in G  has  a winning  strategy:  make  the move  to G0  and  then  follow 
the second player ’s winning strategy in G0 . 
•	 every  G�  ∈ G  has  a  winning  strategy  for  its  ﬁrst  player.  Then  the  second 
player in G has a winning strategy:  if the ﬁrst player ’s move in G is to G0  ∈ G , 
then follow the winning strategy for the ﬁrst player in G0 . 
So  in any  case,  one of  the players has a winning  strategy  for G, which  completes 
the proof of the constructor case. 
It  follows  by  structural  induction  that  there  is  a  winning  strategy  for  every 
� 
2PTG, G. 
Notice  that  although  Theorem  11.4.5  guarantees  a winning  strategy,  its  proof 
gives no clue which player has it.  For most familiar 2PTG’s like Chess, Go, . . . , no 
one knows which player has a winning strategy.3 
3Checkers used  to  be  in  this  list,  but  there has  been  a  recent  announcement  that  each player has  a 

230 

CHAPTER 11.  RECURSIVE DATA TYPES 

11.4.5  Problems 
Homework Problems 

Problem 11.8. 
Deﬁne 2-person 50-point games of perfect information50-PG’s, recursively as follows: 
Base  case:  An  integer,  k ,  is  a  50-PG  for  −50  ≤  k  ≤  50.  This  50-PG  called 
the  terminated  game  with  payoff  k . A  play  of  this  50-PG  is  the  length  one  integer 
sequence, k . 
Constructor case:  If G0 , . . . , Gn  is a ﬁnite sequence of 50-PG’s for some n  ∈ N, 
then the following game, G, is a 50-PG:  the possible ﬁrst moves in G are the choice 
of  an  integer  i  between  0  and n,  the possible  second moves  in G  are  the possible 
ﬁrst moves in Gi , and the rest of the game G proceeds as in Gi . 
A  play  of  the  50-PG,  G,  is  a  sequence  of  nonnegative  integers  starting  with  a 
possible  move,  i,  of  G,  followed  by  a  play  of  Gi .  If  the  play  ends  at  the  game 
terminated game, k , then k  is called the payoff  of the play. 
There are two players in a 50-PG who make moves alternately. The objective of 
one player (call him the max-player) is to have the play end with as high a payoff 
as possible, and the other player (called the min-player) aims to have play end with 
as low a payoff as possible. 
Given which of the players moves ﬁrst in a game, a strategy for the max-player 
is  said  to  ensure  the  payoff,  k ,  if  play  ends  with  a  payoff  of  at  least  k ,  no  matter 
what moves the min-player makes.  Likewise, a strategy for the min-player is said 
to hold down the payoff to k , if play ends with a payoff of at most k , no matter what 
moves the max-player makes. 
A  50-PG  is  said  to have max  value,  k ,  if  the max-player has  a  strategy  that  en­
sures payoff k , and the min-player has a strategy that holds down the payoff to k , 
when  the max-player moves  ﬁrst.  Likewise,  the  50-PG has min  value,  k ,  if  the max­
player has a strategy  that ensures k ,  and  the min-player has a strategy  that holds 
down the payoff to k , when the min-player moves ﬁrst. 
The  Fundamental  Theorem  for  2-person  50-point  games  of  perfect  information 
is  that  is  that  every  game has  both  a max value  and  a min value.  (Note:  the  two 
values are usually different.) 
What  this means  is  that  there’s no point  in playing  a  game:  if  the max player 
gets  the ﬁrst move,  the min-player should  just pay  the max-player  the max value 
of the game without bothering to play (a negative payment means the max-player 
is paying the min-player). Likewise, if the min-player gets the ﬁrst move, the min­
player should just pay the max-player the min value of the game. 
(a)  Prove  this Fundamental Theorem  for  50-valued  50-PG’s by  structural  induc­
tion. 

(b)  A  meta-50-PG  game  has  as  possible  ﬁrst  moves  the  choice  of  any  50-PG  to 
play.  Meta-50-PG games aren’t any harder  to understand  than 50-PG’s,  but  there 
is one notable difference, they have an inﬁnite number of possible ﬁrst moves. We 
could also deﬁne meta-meta-50-PG’s  in which  the ﬁrst move was  a  choice of any 

strategy that forces a tie.  (reference TBA) 

11.5.  INDUCTION IN COMPUTER SCIENCE 

231 

50-PG or the meta-50-PG game to play.  In meta-meta-50-PG’s there are an inﬁnite 
number of possible ﬁrst and second moves. And then there’s meta3  − 50-PG . . . . 
To model such inﬁnite games, we could have modiﬁed the recursive deﬁnition of 
50-PG’s to allow ﬁrst moves that choose any one of an inﬁnite sequence 

G0 , G1 , . . . , Gn , Gn+1 , . . . 

of 50-PG’s. Now a 50-PG can be a mind-bendingly inﬁnite datum instead of a ﬁnite 
one. 
Do these inﬁnite 50-PG’s still have max and min values?  In particular, do you think 
it would be correct to use structural induction as in part (a) to prove a Fundamental 
Theorem  for  such  inﬁnite  50-PG’s?  Offer  an  answer  to  this  question,  and  brieﬂy 
indicate why you believe in it. 

11.5  Induction in Computer Science 

Induction  is  a  powerful  and  widely  applicable  proof  technique,  which  is  why 
we’ve  devoted  two  entire  chapters  to  it.  Strong  induction  and  its  special  case  of 
ordinary  induction  are  applicable  to  any  kind  of  thing  with  nonnegative  integer 
sizes –which is a awful lot of things, including all step-by-step computational pro­
cesses. 
Structural  induction  then  goes  beyond  natural  number  counting  by  offering 
a  simple,  natural  approach  to  proving  things  about  recursive  computation  and 
recursive  data  types.  This makes  it  a  technique  every  computer  scientist  should 
embrace. 

232 

CHAPTER 11.  RECURSIVE DATA TYPES 

Chapter 12 

Planar Graphs 

12.1  Drawing Graphs in the Plane 

Here are three dogs and three houses. 

���� 

���� 

���� 

Dog 

Dog 

Dog 

Can you ﬁnd a path from each dog to each house such that no two paths inter­
sect? 
A quadapus  is a  little-known animal similar  to an octopus, but with  four arms. 
Here are ﬁve quadapi resting on the seaﬂoor: 
�� 
�� 
�� 
��� 
��������
����� 
...........................................................................................
� 
� �
� �
� 
�� �
......�� 
��
���� 
�� 
��� 
�
�
��� 
���
��� 
...............................................................................................
���
� 
� 
� � 
� 
�� �
�� 
�� 
�� 
� �
�� �
� 
� 
�  � 
� 
.....................................................................................................
� 
...........................................................................
���� ��
�
�
��� 
���
�
� 
��
� � 
�� �
� 
.....................................................................................................
�
���� 
� 
��
� 
� 
. ......................................................................................................
� 
���� 

.........................................................
� 
�� �

.........................................................

233 

234 

CHAPTER 12.  PLANAR GRAPHS 

Can  each  quadapus  simultaneously  shake  hands  with  every  other  in  such  a 
way that no arms cross? 
Informally,  a planar graph  is a graph  that  can be drawn  in  the plane  so  that no 
edges cross, as in a map of showing the borders of countries or states.  Thus, these 
two puzzles are asking whether the graphs below are planar; that is, whether they 
can be redrawn so that no edges cross. The ﬁrst graph is called the complete bipartite 
graph, K3,3 , and the second is K5 . 

� 
� 
�
�
�
� � 
� �
�� 
�  �
��  �  � � 
��
�  � �
� 
�� ���
���
��� 
���
��
�
� �� �
� �
� 
� 
�� �
�
� 
�
� 
� 

�

� 
��  ��� 
� �
�� 
�
�
�
�
�
�
�
�
�
�
�
� 
� 
�
� �
� 
� 
� �� 
� 
� �
�
� � 
� �
������
�� ��
�
�  � �� 
� ��� � 
� 
�
� �  �
� 
�

In each case, the answer is, “No— but almost!”  In fact, each drawing would be 
possible if any single edge were removed. 
Planar  graphs  have  applications  in  circuit  layout  and  are  helpful  in  display­
ing  graphical  data,  for  example,  program  ﬂow  charts,  organizational  charts,  and 
scheduling conﬂicts. We will treat them as a recursive data type and use structural 
induction to establish their basic properties. Then we’ll be able to describe a simple 
recursive procedure to color any planar graph with ﬁve colors, and also prove that 
there is no uniform way to place n satellites around the globe unless n = 4, 6, 8, 12, 
or 20. 

12.2.  CONTINUOUS & DISCRETE FACES 

235 

When wires are arranged on a surface, like a circuit board or microchip, crossings 
require troublesome three-dimensional structures. When Steve Wozniak designed 
the disk drive  for  the  early Apple  II  computer,  he  struggled mightly  to  achieve  a 
nearly planar design: 

For two weeks, he worked late each night to make a satisfactory design. 
When he was ﬁnished, he found that if he moved a connector he could 
cut down  on  feedthroughs, making  the  board more  reliable.  To make 
that move, however, he had to start over in his design. This time it only 
took  twenty  hours.  He  then  saw  another  feedthrough  that  could  be 
eliminated, and again started over on his design. ”The ﬁnal design was 
generally recognized by computer engineers as brilliant and was by en­
gineering aesthetics beautiful.  Woz  later  said,  ’It’s  something you  can 
only do if you’re the engineer and the PC board layout person yourself. 
That was an artistic layout. The board has virtually no feedthroughs.’”a 

a From apple2history.org which in turn quotes Fire in the Valley by Freiberger and Swaine. 

12.2  Continuous & Discrete Faces 

Planar  graphs  are  graphs  that  can  be  drawn  in  the  plane —like  familiar maps  of 
countries  or  states.  “Drawing”  the  graph  means  that  each  vertex  of  the  graph 
corresponds to a distinct point  in the plane, and  if two vertices are adjacent,  their 
vertices are connected by a smooth, non-self-intersecting curve. None of the curves 
may  “cross” —the  only  points  that  may  appear  on  more  than  one  curve  are  the 
vertex points.  These  curves  are  the boundaries of  connected  regions of  the plane 
called the continuous faces of the drawing. 
For  example,  the  drawing  in  Figure  12.1  has  four  continuous  faces.  Face  IV, 
which extends off to inﬁnity in all directions, is called the outside face. 
This  deﬁnition  of  planar  graphs  is  perfectly  precise,  but  completely  unsatis­
fying:  it  invokes  smooth  curves  and  continuous  regions  of  the  plane  to  deﬁne  a 
property  of  a  discrete  data  type.  So  the  ﬁrst  thing  we’d  like  to  ﬁnd  is  a  discrete 
data type that represents planar drawings. 
The  clue  to  how  to  do  this  is  to  notice  that  the  vertices  along  the  boundary 
of  each  of  the  faces  in  Figure  12.1  form  a  simple  cycle.  For  example,  labeling  the 
vertices as in Figure 12.2, the simple cycles for the face boundaries are 

abca 

abda 

bcdb 

acda. 

Since every edge in the drawing appears on the boundaries of exactly two contin­
uous  faces,  every  edge  of  the  simple  graph  appears  on  exactly  two  of  the  simple 
cycles. 
Vertices around the boundaries of states and countries in an ordinary map are 

236 

CHAPTER 12.  PLANAR GRAPHS 

Figure 12.1: A Planar Drawing with Four Faces. 

Figure 12.2: The Drawing with Labelled Vertices. 

always simple cycles, but oceans are slightly messier. The ocean boundary is the set 
of all boundaries of islands and continents in the ocean;  it is a set of simple cycles 
(this  can  happen  for  countries  too —like  Bangladesh).  But  this  happens  because 
islands  (and  the  two parts of Bangladesh) are not connected  to each other.  So we 
can dispose of this complication by treating each connected component separately. 
But  general  planar  graphs,  even when  they  are  connected, may  be  a  bit more 
complicated  than maps.  For  example  a  planar  graph may  have  a  “bridge,”  as  in 
Figure 12.3. Now the cycle around the outer face is 

abcefgecda. 

This is not a simple cycle, since it has to traverse the bridge c—e twice. 
Planar  graphs  may  also  have  “dongles,”  as  in  Figure  12.4.  Now  the  cycle 
around the inner face is 

rstvxyxvwvtur, 

IVIIIIIabcd12.3.  PLANAR EMBEDDINGS 

237 

Figure 12.3: A Planar Drawing with a Bridge. 

Figure 12.4: A Planar Drawing with a Dongle. 

because it has to traverse every edge of the dongle twice —once “coming” and once 
“going.” 
But  bridges  and  dongles  are  really  the  only  complications,  which  leads  us  to 
the discrete data  type of planar  embeddings  that we can use  in place of continuous 
planar drawings.  Namely, we’ll deﬁne  a planar  embedding  recursively  to  be  the 
set of boundary-tracing cycles we could get drawing one edge after another. 

12.3  Planar Embeddings 

By thinking of the process of drawing a planar graph edge by edge, we can give a 
useful recursive deﬁnition of planar embeddings. 

Deﬁnition 12.3.1.  A planar embedding of a connected graph consists of a nonempty 
set of cycles of the graph called the discrete faces of the embedding.  Planar embed­

adbcgfertsuyxwv238 

CHAPTER 12.  PLANAR GRAPHS 

dings are deﬁned recursively as follows: 
•	 Base case:  If G  is a graph consisting of a single vertex,  v ,  then a planar em­
bedding of G has one discrete face, namely the length zero cycle, v . 
•	 Constructor Case:  (split a face) Suppose G is a connected graph with a planar 
embedding, and suppose a and b are distinct, nonadjacent vertices of G that 
appear on some discrete face, γ , of the planar embedding. That is, γ is a cycle 
of the form 
· · · 
a . . . b 
a.
Then  the  graph  obtained  by  adding  the  edge  a—b  to  the  edges  of  G  has  a 
planar  embedding  with  the  same  discrete  faces  as  G,  except  that  face  γ  is 
replaced by the two discrete faces1 
a . . . ba  and  ab · · · a, 
as illustrated in Figure 12.5. 

Figure 12.5: The Split a Face Case. 

•	 Constructor  Case:  (add  a  bridge)  Suppose  G  and  H  are  connected  graphs 
with planar embeddings and disjoint sets of vertices.  Let a be a vertex on a 
discrete face, γ , in the embedding of G. That is, γ  is of the form 

a . . . a. 
1  There  is one exception  to  this rule.  If G  is a  line graph beginning with a and ending with b,  then 
the cycles  into which γ  splits are actually the same.  That’s because adding edge a—b creates a simple 
cycle graph, Cn , that divides the plane into an “inner ” and an “outer ” region with the same border.  In 
order  to maintain  the  correspondence  between  continuous  faces  and  discrete  faces, we  have  to  allow 
two “copies” of  this same cycle  to count as discrete  faces.  But since  this  is  the only situation  in which 
two  faces  are  actually  the  same  cycle,  this  exception  is  better  explained  in  a  footnote  than mentioned 
explicitly in the deﬁnition. 

azybxwawxbyza→awxba, abyza12.3.  PLANAR EMBEDDINGS 

239 

Similarly, let b be a vertex on a discrete face, δ , in the embedding of H , so δ is 
of the form 

· · · 
b 
b.

Then the graph obtained by connecting G and H  with a new edge, a—b, has 
a planar embedding whose discrete  faces are  the union of  the discrete  faces 
of G and H , except that faces γ  and δ are replaced by one new face 
· · · 
a . . . ab 
ba.

This is illustrated in Figure 12.6, where the faces of G and H  are: 
G : {axyza,  axya,  ayza} 
H  : {btuvwb,  btvwb,  tuvt} , 

and after adding the bridge a—b, there is a single connected graph with faces 
{axyzabtuvwba,  axya,  ayza,  btvwb,  tuvt} . 

Figure 12.6: The Add Bridge Case. 

An arbitrary graph  is planar  iff each of  its connected components has a planar 
embedding. 

axyza, btuvwb→axyzabtuvwbayxzautbvw240 

CHAPTER 12.  PLANAR GRAPHS 

12.4  What outer face? 

Notice  that  the  deﬁnition  of  planar  embedding  does  not  distinguish  an  “outer ” 
face. There really isn’t any need to distinguish one. 
In fact, a planar embedding could be drawn with any given face on the outside. 
An  intuitive explanation of  this  is  to  think of drawing  the embedding on a  sphere 
instead of the plane.  Then any face can be made the outside face by “puncturing” 
that  face  of  the  sphere,  stretching  the  puncture  hole  to  a  circle  around  the  rest  of 
the faces, and ﬂattening the circular drawing onto the plane. 
So pictures  that show different “outside” boundaries may actually be  illustra­
tions of the same planar embedding. 
This  is what  justiﬁes  the  “add  bridge”  case  in  a planar  embedding:  whatever 
face is chosen in the embeddings of each of the disjoint planar graphs, we can draw 
a bridge between  them without needing  to cross any other edges  in  the drawing, 
because we can assume the bridge connects two “outer ” faces. 

12.5  Euler ’s Formula 

The  value  of  the  recursive  deﬁnition  is  that  it  provides  a  powerful  technique  for 
proving properties of planar graphs, namely, structural induction. 
One  of  the most  basic properties  of  a  connected planar  graph  is  that  its  num­
ber of vertices and edges determines the number of faces in every possible planar 
embedding: 

Theorem 12.5.1 (Euler ’s Formula).  If a connected graph has a planar embedding, then 
v − e + f  = 2 

where v  is the number of vertices, e is the number of edges, and f  is the number of faces. 
For example, in Figure 12.1, |V | = 4, |E | = 6, and f  = 4. Sure enough, 4−6+4 = 
2, as Euler ’s Formula claims. 

Proof.  The proof is by structural induction on the deﬁnition of planar embeddings. 
Let P (E ) be the proposition that v − e + f  = 2 for an embedding, E . 
Base case:  (E  is the one vertex planar embedding).  By deﬁnition, v  = 1, e = 0, 
and f  = 1, so P (E ) indeed holds. 
Constructor  case:  (split a  face) Suppose G  is a  connected graph with a planar 
embedding, and suppose a and b are distinct, nonadjacent vertices of G that appear 
· · · 
on some discrete face, γ  = a . . . b 
a, of the planar embedding. 
Then the graph obtained by adding the edge a—b to the edges of G has a planar 
embedding with  one more  face  and  one more  edge  than  G.  So  the  quantity  v − 
e + f  will remain the same for both graphs, and since by structural induction this 
quantity is 2 for G’s embedding, it’s also 2 for the embedding of G with the added 
edge.  So P  holds for the constructed embedding. 

12.6.  NUMBER OF EDGES VERSUS VERTICES 

241 

Constructor  case:  (add  bridge)  Suppose G  and H  are  connected  graphs with 
planar embeddings and disjoint sets of vertices. Then connecting these two graphs 
with a bridge merges the two bridged faces into a single face, and leaves all other 
faces  unchanged.  So  the  bridge  operation  yields  a  planar  embedding  of  a  con­
nected  graph  with  vG  + vH  vertices,  eG  + eH  + 1  edges,  and  fG  + fH  − 1  faces. 
But 
(vG  + vH ) − (eG  + eH  + 1) + (fG  + fH  − 1) 
= (vG  − eG  + fG ) + (vH  − eH  + fH ) − 2 
= (2) + (2) − 2 
= 2. 
So v − e + f  remains equal to 2 for the constructed embedding. That is, P  also holds 
in this case. 
This completes  the proof of  the constructor cases,  and  the  theorem  follows by 
� 
structural induction. 

(by structural induction hypothesis) 

12.6  Number of Edges versus Vertices 

Like Euler ’s formula, the following lemmas follow by structural induction directly 
from the deﬁnition of planar embedding. 
Lemma 12.6.1.  In a planar embedding of a connected graph,  each edge  is  traversed once 
by each of two different faces, or is traversed exactly twice by one face. 
Lemma  12.6.2.  In  a  planar  embedding  of  a  connected  graph with  at  least  three  vertices, 
each face is of length at least three. 
Corollary 12.6.3.  Suppose a connected planar graph has v ≥ 3 vertices and e edges. Then 
e ≤ 3v − 6. 
Proof.  By deﬁnition, a connected graph is planar iff it has a planar embedding.  So 
suppose  a  connected  graph with  v  vertices  and  e  edges  has  a  planar  embedding 
with  f  faces.  By  Lemma  12.6.1,  every  edge  is  traversed  exactly  twice  by  the  face 
boundaries.  So the sum of the lengths of the face boundaries is exactly 2e. Also by 
Lemma  12.6.2, when  v  ≥  3,  each  face boundary  is of  length  at  least  three,  so  this 
sum is at least 3f . This implies that 

3f  ≤ 2e. 
But f  = e − v + 2 by Euler ’s formula, and substituting into (12.1) gives 
3(e − v + 2) ≤ 2e 
e − 3v + 6 ≤ 0 
e ≤ 3v − 6 

(12.1) 

� 

242 

CHAPTER 12.  PLANAR GRAPHS 

Corollary  12.6.3  lets  us  prove  that  the  quadapi  can’t  all  shake  hands  with­
out crossing.  Representing quadapi by vertices and  the necessary handshakes by 
edges, we get  the  complete graph, K5 .  Shaking hands without  crossing amounts 
to showing that K5  is planar. But K5  is connected, has 5 vertices and 10 edges, and 
10 >  3 5 − 6.  This violates the condition of Corollary 12.6.3 required for K5  to be 
· 
planar, which proves 

Lemma 12.6.4.  K5  is not planar. 

Another consequence is 

Lemma 12.6.5.  Every planar graph has a vertex of degree at most ﬁve. 

Proof.  If  every  vertex  had degree  at  least  6,  then  the  sum  of  the  vertex degrees  is 
at least 6v , but since the sum equals 2e, we have e ≥  3v  contradicting the fact that 
e ≤ 3v − 6 < 3v by Corollary 12.6.3. 
� 

12.7  Planar Subgraphs 

If you draw a graph in the plane by repeatedly adding edges that don’t cross, you 
clearly  could  add  the  edges  in  any  other  order  and  still  wind  up  with  the  same 
drawing.  This is so basic that we might presume that our recursively deﬁned pla­
nar  embeddings  have  this  property.  But  that wouldn’t  be  fair:  we  really  need  to 
prove it. After all, the recursive deﬁnition of planar embedding was pretty techni­
cal —maybe we got it a little bit wrong, with the result that our embeddings don’t 
have this basic draw-in-any-order property. 
Now  any  ordering  of  edges  can  be  obtained  just  by  repeatedly  switching  the 
order  of  successive  edges,  and  if  you  think  about  the  recursive  deﬁnition  of  em­
bedding  for  a minute,  you  should  realize  that  you  can  switch  any  pair  of  succes­
sive edges if you can just switch the last two.  So it all comes down to the following 
lemma. 

Lemma 12.7.1.  Suppose that, starting  from some embeddings of planar graphs with dis­
joint sets of vertices, it is possible by two successive applications of constructor operations 
to add edges e and  then f  to obtain a planar embedding, F .  Then starting  from  the same 
embeddings,  it  is  also  possible  to  obtain  F  by  adding  f  and  then  e  with  two  successive 
applications of constructor operations. 

We’ll leave the proof of Lemma 12.7.1 to Problem 12.6. 

Corollary  12.7.2.  Suppose  that,  starting  from  some  embeddings  of  planar  graphs  with 
disjoint sets of vertices, it is possible to add a sequence of edges e0 , e1 , . . . , en  by successive 
applications  of  constructor  operations  to  obtain  a  planar  embedding,  F .  Then  starting 
from  the  same  embeddings,  it  is  also  possible  to  obtain  F  by  applications  of  constructor 
operations that successively add any permutation2  of the edges e0 , e1 , . . . , en . 
2 If π  : {0, 1, . . . , n} → {0, 1, . . . , n} is a bijection, then the sequence eπ(0) , eπ(1) , . . . , eπ(n)  is called 
a permutation of the sequence e0 , e1 , . . . , en . 

12.8.  PLANAR 5-COLORABILITY 

243 

Corollary 12.7.3.  Deleting an edge from a planar graph leaves a planar graph. 

Proof.  By Corollary 12.7.2, we may assume the deleted edge was the last one added 
in  constructing  an  embedding  of  the  graph.  So  the  embedding  to which  this  last 
� 
edge was added must be an embedding of the graph without that edge. 
Since we can delete a vertex by deleting all its incident edges, Corollary 12.7.3 
immediately implies 

Corollary 12.7.4.  Deleting a vertex from a planar graph, along with all its incident edges 
of course, leaves another planar graph. 

A  subgraph of  a graph, G,  is  any graph whose  set of vertices  is  a  subset of  the 
vertices of G and whose set of edges is a subset of the set of edges of G.  So we can 
summarize Corollaries 12.7.3 and 12.7.4 and their consequences in a Theorem. 

Theorem 12.7.5.  Any subgraph of a planar graph is planar. 

12.8  Planar 5-Colorability 

We need to know one more property of planar graphs in order to prove that planar 
graphs are 5-colorable. 

Lemma  12.8.1.  Merging  two  adjacent  vertices  of  a  planar  graph  leaves  another  planar 
graph. 

Here merging  two  adjacent  vertices,  n1  and n2  of  a  graph means deleting  the 
two vertices and then replacing them by a new “merged” vertex, m, adjacent to all 
the vertices that were adjacent to either of n1  or n2 , as illustrated in Figure 12.7. 
Lemma  12.8.1  can  be  proved  by  structural  induction,  but  the  proof  is  kind  of 
boring,  and we hope  you’ll  be  relieved  that we’re  going  to  omit  it.  (If  you  insist, 
we can add it to the next problem set.) 
Now we’ve got all the simple facts we need to prove 5-colorability. 

Theorem 12.8.2.  Every planar graph is ﬁve-colorable. 

Proof.  The  proof  will  be  by  strong  induction  on  the  number,  v ,  of  vertices,  with 
induction hypothesis: 

Every planar graph with v vertices is ﬁve-colorable. 
Base cases (v ≤ 5):  immediate. 
Inductive  case:  Suppose G  is  a planar  graph with  v + 1  vertices.  We will de­
scribe a ﬁve-coloring of G. 
First, choose a vertex, g , of G with degree at most 5; Lemma 12.6.5 guarantees 
there will be such a vertex. 
Case  1  (deg (g)  <  5):  Deleting  g  from  G  leaves  a  graph,  H ,  that  is  planar  by 
Lemma 12.7.4, and, since H  has v vertices, it is ﬁve-colorable by induction hypoth­
esis.  Now deﬁne a ﬁve coloring of G as follows:  use the ﬁve-coloring of H  for all 

244 

CHAPTER 12.  PLANAR GRAPHS 

Figure 12.7: Merging adjacent vertices n1  and n2  into new vertex, m. 

n11nn2n1mn212.9.  CLASSIFYING POLYHEDRA 

245 

the vertices besides g , and assign one of the ﬁve colors to g  that is not the same as 
the color assigned to any of its neighbors.  Since there are fewer than 5 neighbors, 
there will always be such a color available for g . 
Case  2  (deg (g) = 5):  If  the  ﬁve  neighbors  of  g  in G were  all  adjacent  to  each 
other, then these ﬁve vertices would form a nonplanar subgraph isomorphic to K5 , 
contradicting Theorem 12.7.5.  So there must be two neighbors, n1  and n2 , of g that 
are not adjacent.  Now merge n1  and g  into a new vertex, m,  as  in Figure 12.7.  In 
this new graph, n2  is adjacent  to m, and  the graph  is planar by Lemma 12.8.1.  So 
we  can  then  merge  m  and  n2  into  a  another  new  vertex,  m� ,  resulting  in  a  new 
graph, G� , which by Lemma 12.8.1 is also planar. Now G�  has v − 1 vertices and so 
is ﬁve-colorable by the induction hypothesis. 
Now  deﬁne  a  ﬁve  coloring  of G  as  follows:  use  the  ﬁve-coloring  of G�  for  all 
the vertices besides g , n1  and n2 .  Next assign  the color of m�  in G�  to be  the color 
of  the  neighbors  n1  and  n2 .  Since  n1  and  n2  are  not  adjacent  in G,  this  deﬁnes  a 
proper  ﬁve-coloring  of G  except  for  vertex  g .  But  since  these  two  neighbors  of  g 
have  the  same  color,  the  neighbors  of  g  have  been  colored  using  fewer  than  ﬁve 
colors  altogether.  So  complete  the ﬁve-coloring  of G  by  assigning  one  of  the ﬁve 
colors to g  that is not the same as any of the colors assigned to its neighbors. 
� 

A  graph  obtained  from  a  graph,  G,  be  repeatedly  deleting  vertices,  deleting 
edges, and merging adjacent vertices is called a minor of G.  Since K5  and K3,3  are 
not planar, Lemmas 12.7.3, 12.7.4, and 12.8.1 immediately imply: 

Corollary 12.8.3.  A graph which has K5  or K3,3  as a minor is not planar. 

We don’t have time to prove it, but the converse of Corollary 12.8.3 is also true. 
This gives the following famous, very elegant, and purely discrete characterization 
of planar graphs: 

Theorem 12.8.4 (Kuratowksi).  A graph is not planar iff it has K5  or K3,3  as a minor. 

12.9  Classifying Polyhedra 

The Pythagoreans had two great mathematical secrets, the irrationality of 
a geometric construct that we’re about to rediscover! 
A polyhedron is a convex, three-dimensional region bounded by a ﬁnite number 
of polygonal faces.  If the faces are identical regular polygons and an equal number 
of polygons meet at each corner, then the polyhedron is regular. Three examples of 
regular polyhedra are shown below: the tetrahedron, the cube, and the octahedron. 

2 and 

√

246 

CHAPTER 12.  PLANAR GRAPHS 

We  can  determine  how  many  more  regular  polyhedra  there  are  by  thinking 
about  planarity.  Suppose  we  took  any  polyhedron  and  placed  a  sphere  inside 
it.  Then we could project  the polyhedron  face boundaries onto  the sphere, which 
would give  an  image  that was  a planar graph  embedded on  the  sphere, with  the 
images  of  the  corners  of  the  polyhedron  corresponding  to  vertices  of  the  graph. 
But we’ve already observed that embeddings on a sphere are the same as embed-
dings on the plane, so Euler ’s formula for planar graphs can help guide our search 
for regular polyhedra. 
For example, planar embeddings of the three polyhedra above look like this: 

� � �� 
� 
� 
� 
�
�������
����
���

� 
� 

� 
� 

� 
� 

� 
� 

�� �
�� �
� �  � � 
� � � 
� � 
��� 
�����
���  �� 
�� 
����������� �����

Let m be the number of faces that meet at each corner of a polyhedron, and let 
n  be  the  number  of  sides  on  each  face.  In  the  corresponding  planar  graph,  there 
are m  edges  incident  to  each  of  the  v  vertices.  Since  each  edge  is  incident  to  two 
vertices, we know: 

mv = 2e 
Also, each face is bounded by n edges.  Since each edge is on the boundary of two 
faces, we have: 

nf  = 2e 
Solving  for v  and f  in  these equations and  then substituting  into Euler ’s  formula 
gives: 

2e 
m 

2e 
− e +  = 2 
n 

which simpliﬁes to 

1 
1 
1
1
+  = + 
2 
m n 
e 
This last equation (12.2) places strong restrictions on the structure of a polyhedron. 
Every nondegenerate polygon has at least 3 sides, so n ≥ 3. And at least 3 polygons 
must meet  to  form a corner, so m  ≥  3.  On  the other hand,  if either n or m were 6 
or more, then the left side of the equation could be at most 1/3 + 1/6 = 1/2, which 

(12.2) 

12.9.  CLASSIFYING POLYHEDRA 

247 

is  less  than  the  right  side.  Checking  the ﬁnitely-many  cases  that  remain  turns up 
only ﬁve  solutions.  For  each  valid  combination  of n  and m, we  can  compute  the 
associated number  of  vertices  v ,  edges  e,  and  faces  f .  And polyhedra with  these 
properties do actually exist: 

f  polyhedron 
n m 
v
e
6 
4 
4 
3  3 
tetrahedron 
6 
8  12 
4  3 
cube 
8  octahedron 
3  4 
6  12 
3  5  12  30  20 
icosahedron 
5  3  20  30  12  dodecahedron 

The last polyhedron in this list, the dodecahedron, was the other great mathemat­
ical  secret of  the Pythagorean  sect.  These ﬁve,  then,  are  the only possible  regular 
polyhedra. 
So  if  you  want  to  put  more  than  20  geocentric  satellites  in  orbit  so  that  they 
uniformly blanket the globe —tough luck! 

12.9.1  Problems 
Exam Problems 

Problem 12.1. 

(a)  Describe  an  isomorphism  between  graphs  G1  and  G2 ,  and  another  isomor­
phism between G2  and G3 . 

(b)  Why does part (a) imply that there is an isomorphism between graphs G1  and 
G3 ?

Let G and H be planar graphs. An embedding EG  of G is isomorphic to an embed­

ding EH  of H  iff there is an isomorphism from G to H  that also maps each face of

EG  to a face of EH .


knlomgjhifcbaedG1G2G3248 

CHAPTER 12.  PLANAR GRAPHS 

(c)  One of the embeddings pictured above is not isomorphic to either of the oth­
ers. Which one? Brieﬂy explain why. 

(d)  Explain why all embeddings of two isomorphic planar graphs must have the 
same number of faces. 

Class Problems 

Problem 12.2. 
Figures 1–4 show different pictures of planar graphs. 

12.9.  CLASSIFYING POLYHEDRA 

249 

(a)  For  each  picture,  describe  its  discrete  faces  (simple  cycles  that  deﬁne  the  re­
gion borders). 

(b)  Which  of  the  pictured  graphs  are  isomorphic?  Which  pictures  represent  the 
same planar embedding?  – that is, they have the same discrete faces. 

1abcdFigure 1abcdFigure 2abcdeFigure 3abcdeFigure 4250 

CHAPTER 12.  PLANAR GRAPHS 

(c)  Describe a way to construct the embedding in Figure 4 according to the recur­
sive Deﬁnition  12.3.1 of planar  embedding.  For  each  application of  a  constructor 
rule,  be  sure  to  indicate  the  faces  (cycles)  to which  the  rule was  applied  and  the 
cycles which result from the application. 

Problem 12.3.  (a)  Show that if a connected planar graph with more than two ver­
tices is bipartite, then 
e ≤ 2v − 4. 
(12.3) 
Hint:  Similar to the proof of Corollary 12.6.3 that for planar graphs e ≤ 3v − 6. 
(b)  Conclude that that K3,3  is not planar.  (K3,3  is the graph with six vertices and 
an edge from each of the ﬁrst three vertices to each of the last three.) 

Problem 12.4. 
Prove  the  following assertions by  structural  induction on  the deﬁnition of planar 
embedding. 
(a)  In a planar embedding of a graph, each edge is traversed a total of two times 
by the faces of the embedding. 

(b)  In a planar embedding of a connected graph with at least three vertices, each 
face is of length at least three. 

Homework Problems 

Problem 12.5. 
A simple graph is triangle-free when it has no simple cycle of length three. 
(a)  Prove  for any connected  triangle-free planar graph with v >  2 vertices and e 
edges, e ≤ 2v − 4. 
Hint:  Similar to the proof that e ≤ 3v − 6. Use Problem 12.4. 
(b)  Show that any connected triangle-free planar graph has at least one vertex of 
degree three or less. 

(c)  Prove by induction on the number of vertices that any connected triangle-free 
planar graph is 4-colorable. 
Hint: use part (b). 

Problem 12.6.  (a)  Prove Lemma 12.7.1.  Hint:  There are  four cases  to analyze, de­
pending  on  which  two  constructor  operations  are  applied  to  add  e  and  then  f . 
Structural induction is not needed. 

12.9.  CLASSIFYING POLYHEDRA 

251 

(b)  Prove Corollary 12.7.2. 
Hint: By induction on the number of switches of adjacent elements needed to con­
vert the sequence 0,1,. . . ,n into a permutation π(0), π(1), . . . , π(n). 

252 

CHAPTER 12.  PLANAR GRAPHS 

Chapter 13 

Communication Networks 

13.1  Communication Networks 

Modeling  communication  networks  is  an  important  application  of  digraphs  in 
computer  science.  In  this  such models,  vertices  represent  computers,  processors, 
and switches; edges will represent wires, ﬁber, or other transmission lines through 
which data ﬂows.  For some communication networks, like the internet, the corre­
sponding graph is enormous and largely chaotic.  Highly structured networks, by 
contrast, ﬁnd application in telephone switching systems and the communication 
hardware inside parallel computers.  In this chapter, we’ll look at some of the nicest 
and most commonly used structured networks. 

13.2  Complete Binary Tree 

Let’s  start  with  a  complete  binary  tree.  Here  is  an  example  with  4  inputs  and  4 
outputs. 

253 

254 

CHAPTER 13.  COMMUNICATION NETWORKS 

The kinds of communication networks we consider aim to transmit packets of 
data between computers, processors, telephones, or other devices. The term packet 
refers  to  some  roughly  ﬁxed-size  quantity  of  data—  256  bytes  or  4096  bytes  or 
whatever.  In  this diagram  and many  that  follow,  the  squares  represent  terminals, 
sources and destinations for packets of data.  The circles represent switches, which 
direct packets through the network.  A switch receives packets on incoming edges 
and relays them forward along the outgoing edges.  Thus, you can imagine a data 
packet hopping through the network from an input terminal,  through a sequence 
of switches joined by directed edges, to an output terminal. 
Recall that there is a unique simple path between every pair of vertices in a tree. 
So  the natural way  to  route  a packet of data  from  an  input  terminal  to  an output 
in the complete binary tree is along the corresponding directed path.  For example, 
the route of a packet traveling from input 1 to output 3 is shown in bold. 

13.3  Routing Problems 

Communication  networks  are  supposed  to  get  packets  from  inputs  to  outputs, 
with each packet entering  the network at  its own  input  switch and arriving at  its 
own output switch.  We’re going to consider several different communication net­
work designs, where each network has N  inputs and N  outputs; for convenience, 
we’ll assume N  is a power of two. 
Which input is supposed to go where is speciﬁed by a permutation of {0, 1, . . . , N  − 1}. 
So a permutation, π , deﬁnes a routing problem:  get a packet that starts at input i to 
output π(i). A routing, P , that solves a routing problem, π , is a set of paths from each 
input to its speciﬁed output.  That is, P  is a set of n paths, Pi ,  for i  = 0 . . . , N  − 1, 
where Pi  goes from input i to output π(i). 

INOUTINININOUTOUTOUT0011223313.4.  NETWORK DIAMETER 

255 

13.4  Network Diameter 

The  delay  between  the  time  that  a  packets  arrives  at  an  input  and  arrives  at  its 
designated  output  is  a  critical  issue  in  communication  networks.  Generally  this 
delay is proportional to the length of the path a packet follows.  Assuming it takes 
one  time unit  to  travel  across  a wire,  the delay  of  a packet will  be  the number  of 
wires it crosses going from input to output. 
Generally  packets  are  routed  to  go  from  input  to  output  by  the  shortest  path 
possible.  With  a  shortest  path  routing,  the  worst  case  delay  is  the  distance  be­
tween  the  input  and  output  that  are  farthest  apart.  This  is  called  the  diameter  of 
the network.  In other words, the diameter of a network1  is the maximum length of 
any shortest path between an  input and an output.  For example,  in  the complete 
binary tree above, the distance from input 1 to output 3 is six. No input and output 
are farther apart than this, so the diameter of this tree is also six. 
More generally, the diameter of a complete binary tree with N  inputs and out­
puts is 2 log N + 2.  (All logarithms in this lecture— and in most of computer science 
—are base 2.) This is quite good, because the logarithm function grows very slowly. 
We could connect up 210  =  1024  inputs and outputs using a complete binary tree 
and  the worst  input-output delay  for any packet would be  this diameter, namely, 
2 log(210 ) + 2 = 22. 

13.4.1  Switch Size 
One way to reduce the diameter of a network is to use larger switches.  For exam­
ple,  in  the  complete  binary  tree, most  of  the  switches  have  three  incoming  edges 
and  three  outgoing  edges,  which  makes  them  3 ×  3  switches.  If  we  had  4 ×  4 
switches, then we could construct a complete ternary tree with an even smaller di­
ameter.  In  principle,  we  could  even  connect  up  all  the  inputs  and  outputs  via  a 
single monster N  × N  switch. 
This isn’t very productive, however, since we’ve just concealed the original net­
work design problem inside this abstract switch.  Eventually, we’ll have to design 
the internals of the monster switch using simpler components, and then we’re right 
back where we  started.  So  the  challenge  in  designing  a  communication  network 
is  ﬁguring  out  how  to  get  the  functionality  of  an N  × N  switch  using  ﬁxed  size, 
elementary devices, like 3 × 3 switches. 

13.5  Switch Count 

Another goal  in designing a communication network  is  to use as  few switches as 
· · ·
possible. The number of switches in a complete binary tree is 1 + 2 + 4 + 8 + + N ,
since there is 1 switch at the top (the “root switch”), 2 below it, 4 below those, and 

1 The usual deﬁnition  of  diameter  for  a  general  graph  (simple  or directed)  is  the  largest distance  be­
tween  any  two  vertices,  but  in  the  context  of  a  communication  network  we’re  only  interested  in  the 
distance between inputs and outputs, not between arbitrary pairs of vertices. 

256 

CHAPTER 13.  COMMUNICATION NETWORKS 

so  forth.  By  the  formula  (6.5)  for geometric sums,  the  total number of switches  is 
2N  − 1, which is nearly the best possible with 3 × 3 switches. 

13.6  Network Latency 

We’ll sometimes be choosing routings through a network that optimize some quan­
tity  besides  delay.  For  example,  in  the  next  section  we’ll  be  trying  to  minimize 
packet congestion. When we’re not minimizing delay, shortest routings are not al­
ways the best, and in general, the delay of a packet will depend on how it is routed. 
For any  routing,  the most delayed packet will be  the one  that  follows  the  longest 
path in the routing. The length of the longest path in a routing is called its latency. 
The  latency  of  a  network  depends  on  what’s  being  optimized.  It  is measured 
by  assuming  that  optimal  routings  are  always  chosen  in  getting  inputs  to  their 
speciﬁed outputs. That is, for each routing problem, π , we choose an optimal rout­
ing  that solves π .  Then network  latency  is deﬁned  to be  the  largest routing  latency 
among  these  optimal  routings.  Network  latency  will  equal  network  diameter  if 
routings are always chosen  to optimize delay, but  it may be signiﬁcantly  larger  if 
routings are chosen to optimize something else. 
For  the networks we consider below, paths  from  input  to output are uniquely 
determined  (in  the  case  of  the  tree)  or  all  paths  are  the  same  length,  so  network 
latency will always equal network diameter. 

13.7  Congestion 

The complete binary tree has a fatal drawback:  the root switch is a bottleneck.  At 
best, this switch must handle an enormous amount of trafﬁc:  every packet travel­
ing  from  the  left  side  of  the  network  to  the  right  or  vice-versa.  Passing  all  these 
packets  through  a  single  switch  could  take  a  long  time.  At  worst,  if  this  switch 
fails, the network is broken into two equal-sized pieces. 
For example, if the routing problem is given by the identity permutation, Id (i)::= 
i, then there is an easy routing, P , that solves the problem:  let Pi  be the path from 
input  i up  through  one  switch  and  back down  to  output  i.  On  the  other hand,  if 
the problem was given by π(i) ::= (N  − 1) − i, then in any solution, Q, for π , each 
path Qi  beginning at input i must eventually loop all the way up through the root 
switch and then travel back down to output (N  − 1) − i.  These two situations are 
illustrated below. 

13.8.  2-D ARRAY 

257 

We  can  distinguish  between  a  “good”  set  of  paths  and  a  “bad”  set  based  on 
congestion.  The congestion of a routing, P ,  is equal to the largest number of paths 
in P  that pass through a single switch.  For example, the congestion of the routing 
on  the  left  is  1,  since  at  most  1  path  passes  through  each  switch.  However,  the 
congestion  of  the  routing  on  the  right  is  4,  since  4  paths  pass  through  the  root 
switch (and the two switches directly below the root). Generally, lower congestion 
is better since packets can be delayed at an overloaded switch. 
By extending the notion of congestion to networks, we can also distinguish be­
tween “good” and “bad” networks with respect to bottleneck problems.  For each 
routing problem, π , for the network, we assume a routing is chosen that optimizes 
congestion, that is, that has the minimum congestion among all routings that solve 
π .  Then  the  largest  congestion  that  will  ever  be  suffered  by  a  switch  will  be  the 
maximum congestion among  these optimal routings.  This “maximin” congestion 
is called the congestion of the network. 
So for the complete binary tree, the worst permutation would be π(i) ::= (N  −
1) − i.  Then in every possible solution for π , every packet, would have to follow a 
path  passing  through  the  root  switch.  Thus,  the max  congestion  of  the  complete 
binary tree is N  —which is horrible! 
Let’s tally the results of our analysis so far: 

network  diameter 
complete binary tree  2 log N  + 2 

switch size  # switches  congestion 
3 × 3 
2N  − 1
N

13.8  2-D Array 

Let’s look at an another communication network. This one is called a 2-dimensional 
array or grid. 

INOUTINININOUTOUTOUT00112233INOUTINININOUTOUTOUT00112233258 

CHAPTER 13.  COMMUNICATION NETWORKS 

Here there are four inputs and four outputs, so N  = 4. 
The diameter in this example is 8, which is the number of edges between input 
0 and output 3. More generally, the diameter of an array with N  inputs and outputs 
is 2N , which is much worse than the diameter of 2 log N + 2 in the complete binary 
tree.  On  the  other  hand,  replacing  a  complete  binary  tree  with  an  array  almost 
eliminates congestion. 

Theorem 13.8.1.  The congestion of an N -input array is 2. 

Proof.  First, we  show  that  the  congestion  is  at most  2.  Let π  be  any permutation. 
Deﬁne a solution, P , for π to be the set of paths, Pi , where Pi  goes to the right from 
input i to column π(i) and then goes down to output π(i). Thus, the switch in row 
i and column j transmits at most two packets:  the packet originating at input i and 
the packet destined for output j . 
Next,  we  show  that  the  congestion  is  at  least  2.  This  follows  because  in  any 
routing problem, π , where π(0) = 0 and π(N − 1) = N − 1, two packets must pass 
� 
through the lower left switch. 

As with the tree, the network latency when minimizing congestion is the same 
as the diameter. That’s because all the paths between a given input and output are 
the same length. 
Now we can record the characteristics of the 2-D array. 

diameter 
network 
complete binary tree  2 log N  + 2 
2N 
2-D array 

switch size  # switches  congestion
3 × 3 
2N  − 1
N
2 × 2 
2
N 2

The crucial entry here is the number of switches, which is N 2 . This is a major defect 
of the 2-D array; a network of size N  = 1000 would require a million 2 × 2 switches! 
Still,  for  applications where N  is  small,  the  simplicity  and  low  congestion  of  the 
array make it an attractive choice. 

ININININ0123OUTOUTOUTOUT012313.9.  BUTTERFLY 

13.9  Butterﬂy 

259 

The  Holy  Grail  of  switching  networks  would  combine  the  best  properties  of  the 
complete  binary  tree  (low  diameter,  few  switches)  and  of  the  array  (low  conges­
tion). The butterﬂy is a widely-used compromise between the two. 
A good way to understand butterﬂy networks is as a recursive data type.  The 
recursive  deﬁnition works  better  if we  deﬁne  just  the  switches  and  their  connec­
tions,  omitting  the  terminals.  So we  recursively deﬁne Fn  to be  the  switches  and 
connections of the butterﬂy net with N  ::= 2n  input and output switches. 
The base  case  is F1  with 2  input  switches and 2 output  switches  connected as 
in Figure 13.1. 

Figure 13.1: F1 , the Butterﬂy Net switches with N  = 21 . 

In  the  constructor  step,  we  construct  Fn+1  with  2n+1  inputs  and  outputs  out 
of  two  Fn  nets  connected  to  a  new  set  of  2n+1  input  switches,  as  shown  in  as  in 
Figure  13.2.  That  is,  the  ith  and  2n  + ith  new  input  switches  are  each  connected 
to  the  same  two  switches,  namely,  to  the  ith  input  switches  of  each  of  two  Fn 
components  for  i  = 1, . . . , 2n .  The output switches of Fn+1  are simply  the output 
switches of each of the Fn  copies. 
So Fn+1  is  laid  out  in  columns  of  height  2n+1  by  adding  one more  column  of 
switches  to  the  columns  in  Fn .  Since  the  construction  starts  with  two  columns 
when  n  = 1,  the  Fn+1  switches  are  arrayed  in  n + 1  columns.  The  total  number 
of  switches  is  the  height  of  the  columns  times  the  number  of  columns,  namely, 
2n+1 (n + 1). Remembering that n =  log N , we conclude that the Butterﬂy Net with 

2inputs2 outputsN= 21N= 21260 

CHAPTER 13.  COMMUNICATION NETWORKS 

Figure 13.2: Fn+1 , the Butterﬂy Net switches with 2n+1  inputs and outputs. 

N  inputs has N (log N  + 1) switches. 
Since every path in Fn+1  from an input switch to an output is the same length, 
namely, n + 1, the diameter of the Butterﬂy net with 2n+1  inputs is this length plus 
two  because  of  the  two  edges  connecting  to  the  terminals  (square  boxes)  —one 
edge  from  input  terminal  to  input  switch  (circle)  and  one  from  output  switch  to 
output terminal. 
There  is  an  easy  recursive  procedure  to  route  a  packet  through  the  Butterﬂy 
Net.  In the base case, there is obviously only one way to route a packet from one of 
the two inputs to one of the two outputs. Now suppose we want to route a packet 
from  an  input  switch  to  an  output  switch  in  Fn+1 .  If  the  output  switch  is  in  the 
“top” copy of Fn ,  then the ﬁrst step in the route must be from the input switch to 
the unique  switch  it  is connected  to  in  the  top copy;  the  rest of  the  route  is deter­
mined by recursively routing  the rest of  the way  in  the  top copy of Fn .  Likewise, 
if  the output  switch  is  in  the “bottom”  copy of Fn ,  then  the ﬁrst  step  in  the  route 
must be to the switch in the bottom copy, and the rest of the route is determined by 
recursively routing in the bottom copy of Fn .  In fact, this argument shows that the 
routing is unique:  there is exactly one path in the Butterﬂy Net from each input to 
each output, which implies that the network latency when minimizing congestion 
is the same as the diameter. 

⎧⎨F⎨⎩2nFn2n1  tt⎩⎧⎨F2n+1  outputs⎨⎩2nFnFnewinputs⎩Fn+113.10.  BENE ˘S NETWORK 
N  if N  is an even power of 2 and � 
√
√
The congestion of  the butterﬂy network  is about 
N , more precisely,  the con­
N/2 if N  is an odd power of 2.  A 
gestion is 
simple proof of this appears in Problem13.8. 
Let’s add the butterﬂy data to our comparison table: 

261 

switch size 
3 × 3 
2 × 2 
2 × 2 

# switches 
2N  − 1
N 2
N (log(N ) + 1) 

network  diameter 
complete binary tree  2 log N  + 2 
2N 
2-D array 
log N  + 2 
butterﬂy 

congestion 
N  or � 
N
2
N/2
The  butterﬂy  has  lower  congestion  than  the  complete  binary  tree.  And  it  uses 
fewer  switches  and  has  lower  diameter  than  the  array.  However,  the  butterﬂy 
does  not  capture  the  best  qualities  of  each  network,  but  rather  is  a  compromise 
somewhere between the two.  So our quest for the Holy Grail of routing networks 
goes on. 

√

13.10  Bene ˘s Network 

In  the  1960’s,  a  researcher  at  Bell  Labs  named  Bene ˘s  had  a  remarkable  idea.  He 
obtained  a marvelous  communication  network with  congestion  1  by  placing  two 
butterﬂies back-to-back. This amounts to recursively growing Bene˘s nets by adding 
both  inputs  and  outputs  at  each  stage.  Now  we  recursively  deﬁne  Bn  to  be  the 
switches  and  connections  (without  the  terminals)  of  the  Bene ˘s  net with N  ::= 2n 
input and output switches. 
The  base  case,  B1 ,  with  2  input  switches  and  2  output  switches  is  exactly  the 
same as F1  in Figure 13.1. 
In  the  constructor  step,  we  construct Bn+1  out  of  two Bn  nets  connected  to  a 
new set of 2n+1  input switches and also a new set of 2n+1  output switches.  This is 
illustrated in Figure 13.3. 
Namely, the ith and 2n + ith new input switches are each connected to the same 
two switches, namely, to the ith input switches of each of two Bn  components for 
i  = 1, . . . , 2n , exactly as  in the Butterﬂy net.  In addition,  the ith and 2n  + ith new 
output switches are connected to the same two switches, namely, to the ith output 
switches of each of two Bn  components. 
Now Bn+1  is laid out in columns of height 2n+1  by adding two more columns 
of  switches  to  the  columns  in  Bn .  So  the  Bn+1  switches  are  arrayed  in  2(n + 1) 
columns.  The total number of switches is the number of columns times the height 
of the columns, namely, 2(n + 1)2n+1 . 
All  paths  in  Bn+1  from  an  input  switch  to  an  output  are  the  same  length, 
namely,  2(n + 1) − 1,  and  the  diameter  of  the  Bene ˘s  net with  2n+1  inputs  is  this 
length plus two because of the two edges connecting to the terminals. 
So Bene ˘s has doubled the number of switches and the diameter, of course, but 
completely eliminates congestion problems! The proof of this fact relies on a clever 
induction argument that we’ll come to in a moment.  Let’s ﬁrst see how the Bene ˘s 

262 

CHAPTER 13.  COMMUNICATION NETWORKS 

Figure 13.3: Bn+1 , the Bene ˘s Net switches with 2n+1  inputs and outputs. 

network stacks up: 

network  diameter 
2 log N  + 2

complete binary tree 
2N

2-D array 
log N  + 2

butterﬂy 
2 log N  + 1

Bene ˘s 

switch size 
3 × 3 
2 × 2 
2 × 2 
2 × 2 

# switches 
2N  − 1

N 2

N (log(N ) + 1)

2N log N


congestion 
N  or � 
N 
2

N/2

1


√

The  Bene ˘s  network  has  small  size  and  diameter,  and  completely  eliminates  con­
gestion. The Holy Grail of routing networks is in hand! 

Theorem 13.10.1.  The congestion of the N -input Bene˘s network is 1.


Proof.  By induction on n where N  = 2n .  So the induction hypothesis is


⎧⎫⎧⎨⎩2n⎫⎪Bn⎩⎧⎪⎬⎪2n+1⎧⎨⎩2n⎪⎭Bn⎩⎭Bnew inputsnew outputsBn+1pp13.10.  BENE ˘S NETWORK 

263 

P (n) ::= the congestion of Bn  is 1. 
Base case (n = 1): B1  = F1  and the unique routings in F1  have congestion 1. 
Inductive step:  We assume that the congestion of an N  = 2n -input Bene ˘s net­
work is 1 and prove that the congestion of a 2N -input Bene ˘s network is also 1. 
Digression.  Time  out!  Let’s work  through  an  example,  develop  some  intu­
ition, and then complete the proof.  In the Bene ˘s network shown below with N  = 8 
inputs and outputs, the two 4-input/output subnetworks are in dashed boxes. 

By the inductive assumption, the subnetworks can each route an arbitrary per­
mutation with congestion 1. So if we can guide packets safely through just the ﬁrst 
and last levels, then we can rely on induction for the rest! Let’s see how this works 
in an example. Consider the following permutation routing problem: 

π(0) = 1 
π(1) = 5 
π(2) = 4 
π(3) = 7 

π(4) = 3 
π(5) = 6 
π(6) = 0 
π(7) = 2 

We  can  route  each  packet  to  its  destination  through  either  the  upper  subnet­
work or the lower subnetwork. However, the choice for one packet may constrain 
the  choice  for another.  For  example, we  can not  route both packet 0  and packet 4 
through the same network since that would cause two packets to collide at a single 
switch, resulting in congestion.  So one packet must go through the upper network 
and the other through the lower network. Similarly, packets 1 and 5, 2 and 6, and 3 

OUTOUTOUTOUTOUTOUT01OUT32OUT4567ININININININININ01234567264 

CHAPTER 13.  COMMUNICATION NETWORKS 

and 7 must be routed through different networks. Let’s record these constraints in 
a graph. The vertices are the 8 packets.  If two packets must pass through different 
networks,  then  there  is  an  edge  between  them.  Thus,  our  constraint  graph  looks 
like this: 

Notice that at most one edge is incident to each vertex. 
The output side of the network imposes some further constraints. For example, 
the  packet  destined  for  output  0  (which  is  packet  6)  and  the  packet  destined  for 
output  4  (which  is  packet  2)  can  not  both  pass  through  the  same  network;  that 
would require both packets to arrive from the same switch.  Similarly, the packets 
destined for outputs 1 and 5, 2 and 6, and 3 and 7 must also pass through different 
switches. We can record these additional constraints in our graph with gray edges: 

Notice  that  at  most  one  new  edge  is  incident  to  each  vertex.  The  two  lines 
drawn between vertices 2 and 6 reﬂect the two different reasons why these packets 
must be routed through different networks. However, we intend this to be a simple 
graph; the two lines still signify a single edge. 
Now  here’s  the  key  insight:  a  2-coloring  of  the  graph  corresponds  to  a  solution  to 
the  routing  problem.  In  particular,  suppose  that we  could  color  each  vertex  either 
red  or  blue  so  that  adjacent  vertices  are  colored  differently.  Then  all  constraints 
are  satisﬁed  if we  send  the  red  packets  through  the  upper  network  and  the  blue 
packets through the lower network. 
The  only  remaining  question  is  whether  the  constraint  graph  is  2-colorable, 
which is easy to verify: 

123456701234567013.10.  BENE ˘S NETWORK 

265 

Lemma 13.10.2.  Prove that if the edges of a graph can be grouped into two sets such that 
every vertex has at most 1 edge from each set incident to it, then the graph is 2-colorable. 

Proof.  Since the two sets of edges may overlap, let’s call an edge that is in both sets 
a doubled edge. 
We know  from Theorem 10.6.2  that all we have  to do  is show  that every cycle 
has even length. There are two cases: 
Case  1:  [The  cycle  contains  a  doubled  edge.]  No  other  edge  can  be  incident 
to  either  of  the  endpoints  of  a  doubled  edge,  since  that  endpoint  would  then  be 
incident to two edges from the same set.  So a cycle traversing a doubled edge has 
nowhere to go but back and forth along the edge an even number of times. 
Case  2:  [No  edge  on  the  cycle  is  doubled.]  Since  each  vertex  is  incident  to 
at  most  one  edge  from  each  set,  any  path  with  no  doubled  edges  must  traverse 
successive edges that alternate from one set to the other.  In particular, a cycle must 
traverse a path of alternating edges that begins and ends with edges from different 
� 
sets. This means the cycle has to be of even length. 

For example, here is a 2-coloring of the constraint graph: 

The solution to this graph-coloring problem provides a start on the packet rout­
ing problem: 
We can complete  the routing  in  the  two smaller Bene ˘s networks by  induction! 
Back to the proof. End of Digression. 
Let  π  be  an  arbitrary  permutation  of  {0, 1, . . . , N  − 1}.  Let  G  be  the  graph 
whose  vertices  are  packet  numbers  0, 1, . . . , N  −  1  and  whose  edges  come  from 
the union of these two sets: 
E1 ::= {u—v  | |u − v | = N/2} ,  and 
E2 ::= {u—w  | |π(u) − π(w)| = N/2} . 
Now any vertex, u, is incident to at most two edges:  a unique edge u—v ∈ E1  and 
a  unique  edge  u—w  ∈  E2 .  So  according  to  Lemma  13.10.2,  there  is  a  2-coloring 
for  the  vertices  of G.  Now  route  packets  of  one  color  through  the  upper  subnet­
work and packets of the other color through the lower subnetwork.  Since for each 

12345670redblueredredredblueblueblue266 

CHAPTER 13.  COMMUNICATION NETWORKS 

edge  in  E1 ,  one  vertex  goes  to  the  upper  subnetwork  and  the  other  to  the  lower 
subnetwork,  there will  not  be  any  conﬂicts  in  the  ﬁrst  level.  Since  for  each  edge 
in E2 , one vertex comes from the upper subnetwork and the other from the lower 
subnetwork,  there will not be any  conﬂicts  in  the  last  level.  We  can  complete  the 
� 
routing within each subnetwork by the induction hypothesis P (n). 

13.10.1  Problems 
Exam Problems 

Problem 13.1. 
Consider the following communication network: 

(a)  What is the max congestion? 

(b)	 Give an input/output permutation, π0 , that forces maximum congestion: 
π0 (0) = 
π0 (1) = 
π0 (2) = 

(c)  Give an input/output permutation, π1 , that allows minimum congestion: 
π1 (2) = 
π1 (1) = 
π1 (0) = 

(d)  What  is  the  latency  for  the  permutation  π1 ?  (If  you  could  not  ﬁnd  π1 ,  just 
choose a permutation and ﬁnd its latency.) 

Class Problems 

Problem 13.2. 
The  Bene ˘s  network  has  a max  congestion  of  1;  that  is,  every  permutation  can  be 
routed  in such a way  that a single packet passes  through each switch.  Let’s work 
through an example. A Bene ˘s network of size N  = 8 is attached. 
(a)  Within  the  Bene ˘s  network  of  size N  = 8,  there  are  two  subnetworks  of  size 
N  = 4.  Put  boxes  around  these.  Hereafter,  we’ll  refer  to  these  as  the  upper  and 
lower subnetworks. 

IN0IN1IN2OUT0OUT1OUT213.10.  BENE ˘S NETWORK 

267 

(b)  Now consider the following permutation routing problem: 

π(0) = 3 
π(1) = 1 
π(2) = 6 
π(3) = 5 

π(4) = 2 
π(5) = 0 
π(6) = 7 
π(7) = 4 

Each  packet  must  be  routed  through  either  the  upper  subnetwork  or  the  lower 
subnetwork.  Construct  a  graph with  vertices  0,  1,  . . . ,  7  and  draw  a  dashed  edge 
between each pair of packets that can not go through the same subnetwork because 
a collision would occur in the second column of switches. 

(c)  Add a  solid edge  in your graph between each pair of packets  that  can not go 
through  the  same  subnetwork because  a  collision would occur  in  the next-to-last 
column of switches. 

(d)  Color  the  vertices  of  your  graph  red  and  blue  so  that  adjacent  vertices  get 
different colors. Why must this be possible, regardless of the permutation π? 

(e)  Suppose  that  red  vertices  correspond  to  packets  routed  through  the  upper 
subnetwork and blue vertices correspond to packets routed through the lower sub­
network.  On  the  attached  copy  of  the  Bene ˘s  network,  highlight  the  ﬁrst  and  last 
edge traversed by each packet. 

(f)  All that remains is to route packets through the upper and lower subnetworks. 
One way  to  do  this  is  by  applying  the  procedure  described  above  recursively  on 
each subnetwork. However, since the remaining problems are small, see if you can 
complete all the paths on your own. 

268 

CHAPTER 13.  COMMUNICATION NETWORKS 

OUTOUTOUTOUTOUTOUT01OUT32OUT4567ININININININININ0123456713.10.  BENE ˘S NETWORK 

269 

Problem 13.3. 
A multiple binary-tree network has n inputs and n outputs, where n is a power of 2. 
Each input is connected to the root of a binary tree with n/2 leaves and with edges 
pointing  away  from  the  root.  Likewise,  each  output  is  connected  to  the  root  of  a 
binary tree with n/2 leaves and with edges pointing toward the root. 
Two edges point from each leaf of an input tree, and each of these edges points 
to a leaf of an output tree. The matching of leaf edges is arranged so that for every 
input and output tree, there is an edge from a leaf of the input tree to a leaf of the 
output tree, and every output tree leaf has exactly two edges pointing to it. 
(a)  Draw such a multiple binary-tree net for n = 4. 

(b)  Fill in the table, and explain your entries. 

# switches  switch size  diameter  max congestion 

Problem 13.4. 
The  n-input  2-D  Array  network  was  shown  to  have  congestion  2.  An  n-input  2­
Layer Array consisting of two n-input 2-D Arrays connected as pictured below for 
n = 4. 

In general, an n-input 2-Layer Array has two layers of switches, with each layer 
connected like an n-input 2-D Array. There is also an edge from each switch in the 
ﬁrst  layer  to  the  corresponding  switch  in  the  second  layer.  The  inputs  of  the  2­
Layer Array enter  the  left  side of  the ﬁrst  layer,  and  the n outputs  leave  from  the 
bottom row of either layer. 
(a)  For any given input-output permutation,  there  is a way to route packets that 
achieves congestion 1. Describe how to route the packets in this way. 

(b)  What is the latency of a routing designed to minimize latency? 

IN0IN1IN2IN3OUT0OUT1OUT2OUT3270 

CHAPTER 13.  COMMUNICATION NETWORKS 

(c)  Explain why the congestion of any minimum latency (CML) routing of pack­
ets through this network is greater than the network’s congestion. 

Problem 13.5. 
A 5-path communication network is shown below.  From this, it’s easy to see what 
an n-path network would be. Fill in the table of properties below, and be prepared 
to justify your answers. 

5-Path 

network  # switches  switch size  diameter  max congestion 
5-path 
n-path 

Problem 13.6. 
Tired of being a TA, Megumi has decided to become famous by coming up with a 
new, better communication network design.  Her network has the following spec­
iﬁcations:  every  input  node will  be  sent  to  a  Butterﬂy  network,  a  Benes  network 
and a 2D Grid network. At the end, the outputs of all three networks will converge 
on the new output. 
In  the Megumi-net  a minimum  latency  routing  does  not  have minimum  con­
gestion.  The  latency  for min-congestion (LMC) of a net  is the best bound on  latency 
achievable  using  routings  that  minimize  congestion.  Likewise,  the  congestion  for 
min-latency  (CML)  is  the best bound on congestion achievable using  routings  that 
minimize latency. 

IN0IN1IN2IN3IN4OUT0OUT1OUT2OUT3OUT413.10.  BENE ˘S NETWORK 

271 

Fill in the following chart for Megumi’s new net and explain your answers. 

network 
Megumi’s net 

diameter 

# switches 

congestion 

LMC 

CML 

Homework Problems 

Problem 13.7. 
Louis Reasoner ﬁgures that, wonderful as the Bene ˘s network may be, the butterﬂy 
network has a few advantages, namely:  fewer switches, smaller diameter, and an 
easy  way  to  route  packets  through  it.  So  Louis  designs  an  N -input/output  net­
work he modestly calls a Reasoner-net with the aim of combining the best features 
of both the butterﬂy and Bene ˘s nets: 

The ith input switch in a Reasoner-net connects to two switches, ai  and 
bi ,  and  likewise,  the  j th  output  switch  has  two  switches,  yj  and  zj , 
connected  to  it.  Then  the Reasoner-net has an N -input Bene ˘s network 
connected using  the ai  switches as  input switches and  the yj  switches 
as its output switches.  The Reasoner-net also has an N -input butterﬂy 
net  connected  using  the  bi  switches  as  inputs  and¡  the  zj  switches  as 
outputs. 

In  the Reasoner-net a minimum  latency  routing does not have minimum con­
gestion.  The  latency  for min-congestion (LMC) of a net  is the best bound on  latency 
achievable  using  routings  that  minimize  congestion.  Likewise,  the  congestion  for 
min-latency  (CML)  is  the best bound on congestion achievable using  routings  that 
minimize latency. 

..............................I1I2I3INO1O2O3ONButterflyBenes2-D272 

CHAPTER 13.  COMMUNICATION NETWORKS 

Fill  in  the  following  chart  for  the  Reasoner-net  and  brieﬂy  explain  your  an­
swers. 

diameter  switch size(s)  # switches  congestion  LMC  CML 

Problem 13.8. 
Show that the congestion of the butterﬂy net, Fn , is exactly 
Hint: 

√
N  when n is even. 

•	 There  is  a unique path  from  each  input  to  each output,  so  the  congestion  is 
the maximum number of messages passing through a vertex for any routing 
problem. 

•	 If v  is a vertex  in column  i of  the butterﬂy network,  there  is a path  from ex­
actly 2i  input vertices to v and a path from v  to exactly 2n−i  output vertices. 

•	 At  which  column  of  the  butterﬂy  network  must  the  congestion  be  worst? 
What is the congestion of the topmost switch in that column of the network? 

Chapter 14 

Number Theory 

Number  theory  is  the  study  of  the  integers.  Why  anyone would want  to  study  the 
integers is not immediately obvious. First of all, what’s to know? There’s 0, there’s 
1, 2, 3, and so on, and, oh yeah, -1, -2,  . . . .  Which one don’t you understand?  Sec­
ond, what practical value is there in it? The mathematician G. H. Hardy expressed 
pleasure in its impracticality when he wrote: 

[Number  theorists]  may  be  justiﬁed  in  rejoicing  that  there  is  one  sci­
ence,  at any  rate,  and  that  their own, whose very  remoteness  from or­
dinary human activities should keep it gentle and clean. 

Hardy was specially concerned that number theory not be used in warfare; he 
was  a  paciﬁst.  You  may  applaud  his  sentiments,  but  he  got  it  wrong:  Number 
Theory underlies modern cryptography, which is what makes secure online com­
munication  possible.  Secure  communication  is  of  course  crucial  in  war —which 
may leave poor Hardy spinning in his grave.  It’s also central to online commerce. 
Every time you buy a book from Amazon, check your grades on WebSIS, or use a 
PayPal account, you are relying on number theoretic algorithms. 

14.1  Divisibility 

Since we’ll be focussing on properties of the integers, we’ll adopt the default con­
vention in this chapter that variables range over integers, Z. 
The nature of number theory emerges as soon as we consider the divides relation 

iff  ak = b for some k . 
a divides b 
The notation, a | b, is an abbreviation for “a divides b.”  If a  | b, then we also say that 
b  is a multiple of a.  A consequence of  this deﬁnition  is  that every number divides 
zero. 
This  seems  simple  enough,  but  let’s play with  this deﬁnition.  The Pythagore­
ans, an ancient sect of mathematical mystics, said that a number is perfect if it equals 

273 

274 

CHAPTER 14.  NUMBER THEORY 

the sum of its positive integral divisors, excluding itself. For example, 6 = 1 + 2 + 3 
and  28  =  1 + 2 + 4 + 7 + 14  are  perfect  numbers.  On  the  other  hand,  10  is  not 
perfect because 1 + 2 + 5 = 8, and 12 is not perfect because 1 + 2 + 3 + 4 + 6 = 16. 
Euclid  characterized  all  the  even  perfect  numbers  around  300  BC.  But  is  there  an 
odd perfect number? More than two thousand years later, we still don’t know!  All 
numbers up to about 10300  have been ruled out, but no one has proved that there 
isn’t an odd perfect number waiting just over the horizon. 
So a half-page into number theory, we’ve strayed past the outer limits of human 
knowledge!  This is pretty typical; number theory is full of questions that are easy 
to  pose,  but  incredibly  difﬁcult  to  answer.  Interestingly,  we’ll  see  that  computer 
scientists have found ways to turn some of these difﬁculties to their advantage. 
Don’t  Panic —we’re  going  to  stick  to  some  relatively  benign  parts  of  number 
theory. We rarely put any of these super-hard unsolved problems on exams :-) 

14.1.1  Facts About Divisibility 

The lemma below states some basic facts about divisibility that are not difﬁcult to 
prove: 

Lemma 14.1.1.  The following statements about divisibility hold. 
1.  If a  | b, then a | bc for all c. 

2.  If a  | b and b | c, then a | c. 

3.  If a  | b and a  | c, then a  | sb + tc for all s and t. 

, a  | b if and only if ca | cb. 
4.  For all c = 0

Proof.  We’ll prove only part 2.; the other proofs are similar. 
Proof of 2.:  Since a  |  b,  there exists an  integer k1  such  that ak1  =  b.  Since b  |  c, 
there  exists  an  integer  k2  such  that  bk2  =  c.  Substituting  ak1  for  b  in  the  second 
equation gives (ak1 )k2  = c.  So a(k1k2 ) = c, which implies that a  | c. 
� 

A  number  p >  1  with  no  positive  divisors  other  than  1  and  itself  is  called  a 
prime.  Every other number greater than 1  is called composite.  For example, 2, 3, 5, 
7,  11,  and 13 are all prime,  but 4,  6,  8,  and 9 are  composite.  Because of  its  special 
properties, the number 1 is considered to be neither prime nor composite. 

�
14.1.  DIVISIBILITY 

275 

Famous Problems in Number Theory 

Fermat’s Last Theorem  Do there exist positive integers x, y , and z  such that 

x n  + y n  = z n 

for  some  integer  n >  2?  In  a  book  he  was  reading  around  1630,  Fermat 
claimed to have a proof, but not enough space in the margin to write it down. 
Wiles ﬁnally gave a proof of the theorem in 1994, after seven years of working 
in secrecy and isolation in his attic. His proof did not ﬁt in any margin. 

Goldbach Conjecture  Is  every  even  integer  greater  than  two  equal  to  the  sum  of 
two primes?  For example, 4 = 2 + 2, 6 = 3 + 3, 8 = 3 + 5, etc. The conjecture 
holds for all numbers up to 1016 .  In 1939 Schnirelman proved that every even 
number  can  be written  as  the  sum  of  not more  than  300,000  primes,  which 
was a start.  Today, we know that every even number is the sum of at most 6 
primes. 

Twin Prime Conjecture  Are  there  inﬁnitely many primes p such  that p + 2  is also 
a prime?  In 1966 Chen showed  that  there are  inﬁnitely many primes p such 
that p + 2 is the product of at most two primes.  So the conjecture is known to 
be almost true! 

√
Primality Testing  Is  there  an  efﬁcient  way  to  determine  whether  n  is  prime?  A 
n, 
naive  search  for  factors  of  n  takes  a  number  of  steps  proportional  to 
which is exponential in the size of n in decimal or binary notation. All known 
procedures for prime checking blew up like this on various inputs. Finally in 
2002, an amazingly simple, new method was discovered by Agrawal, Kayal, 
and  Saxena,  which  showed  that  prime  testing  only  required  a  polynomial 
number  of  steps.  Their paper  began with  a  quote  from Gauss  emphasizing 
the importance and antiquity of the problem even in his time— two centuries 
ago.  So prime testing is deﬁnitely not in the category of infeasible problems 
requiring an exponentially growing number of steps in bad cases. 

Factoring  Given the product of two large primes n =  pq , is there an efﬁcient way 
to  recover  the  primes  p  and  q?  The  best  known  algorithm  is  the  “number 
ﬁeld sieve”, which runs in time proportional to: 

1.9(ln n)1/3 (ln ln n)2/3 
e 

This is infeasible when n has 300 digits or more. 

276 

CHAPTER 14.  NUMBER THEORY 

14.1.2  When Divisibility Goes Bad 
As  you  learned  in  elementary  school,  if  one  number  does  not  evenly  divide  an­
other, you get a “quotient” and a “remainder ” left over. More precisely: 
Theorem 14.1.2 (Division Theorem).  1  Let n and d be  integers such that d >  0.  Then 
there exists a unique pair of integers q and r , such that 
n = q d + r AND  0 ≤ r < d. 
· 
The number q is called the quotient and the number r is called the remainder of n 
divided by d.  We use the notation qcnt(n, d) for the quotient and rem(n, d) for the 
remainder. 
For  example,  qcnt(2716, 10)  =  271  and  rem(2716, 10)  =  6,  since  2716  =  271  · 
10 + 6.  Similarly, rem(−11, 7)  =  3, since −11  =  (−2)  7 + 3.  There is a remainder 
· 
operator  built  into  many  programming  languages.  For  example,  the  expression 
“32 %  5”  evaluates  to  2  in  Java,  C,  and  C++.  However,  all  these  languages  treat 
negative numbers strangely. 
We’ll take this familiar Division Theorem for granted without proof. 

(14.1)

14.1.3  Die Hard 
We’ve  previously  looked  at  the  Die Hard water  jug  problem with  jugs  of  sizes  3 
and  5,  and  3  and  9.  A  little  number  theory  lets  us  solve  all  these  silly water  jug 
questions at once.  In particular, it will be easy to ﬁgure out exactly which amounts 
of water can be measured out using jugs with capacities a and b. 

Finding an Invariant Property 
Suppose  that we have water  jugs with capacities a and b with b  ≥  a.  The state of 
the system is described below with a pair of numbers (x, y), where x is the amount 
of water  in the  jug with capacity a and y  is the amount  in the  jug with capacity b. 
Let’s carry out sample operations and see what happens, assuming the b-jug is big 
enough: 

(0, 0) 

→ 
(a, 0) 
ﬁll ﬁrst jug 
→ 
(0, a) 
pour ﬁrst into second 
→ 
(a, a) 
ﬁll ﬁrst jug 
pour ﬁrst into second (assuming 2a ≥ b) 
→ (2a − b, b) 
→ (2a − b, 0) 
empty second jug 
→ (0, 2a − b) 
pour ﬁrst into second 
→ (a, 2a − b) 
ﬁll ﬁrst 
pour ﬁrst into second (assuming 3a ≥ 2b) 
→ (3a − 2b, b) 
1 This theorem is often called the “Division Algorithm,” even though it is not what we would call an 
algorithm. 

14.1.  DIVISIBILITY 

277 

What leaps out is that at every step, the amount of water in each jug is of the form 
·
· 
s	 a + t b 
(14.2)
for some integers s and t. An expression of the form (14.2) is called an integer linear 
combination of a and b, but in this chapter we’ll just call it a linear combination, since 
we’re only talking integers.  So we’re suggesting: 
Lemma 14.1.3.  Suppose that we have water jugs with capacities a and b. Then the amount 
of water in each jug is always a linear combination of a and b. 
Lemma 14.1.3 is easy to prove by induction on the number of pourings. 
Proof.  The  induction  hypothesis,  P (n),  is  the  proposition  that  after  n  steps,  the 
amount of water in each jug is a linear combination of a and b. 
·
· 
Base case: (n = 0). P (0) is true, because both jugs are initially empty, and 0  a + 0 
b = 0.

Inductive step.  We assume by induction hypothesis that after n steps the amount

of water in each jug is a linear combination of a and b. There are two cases:

•	 If we ﬁll a jug from the fountain or empty a jug into the fountain, then that jug 
is empty or full. The amount in the other jug remains a linear combination of 
a and b.  So P (n + 1) holds. 
•	 Otherwise, we pour water from one jug to another until one is empty or the 
other is full.  By our assumption, the amount in each jug is a linear combina­
tion of a and b before we begin pouring: 
j1  = s1  · a + t1  · b 
j2  = s2  · a + t2  · b 
After pouring, one jug is either empty (contains 0 gallons) or full (contains a 
or b gallons). Thus, the other jug contains either j1 + j2  gallons, j1 + j2 − a, or 
j1 + j2 − b gallons, all of which are linear combinations of a and b. So P (n + 1) 
holds in this case as well. 
So in any case, P (n + 1) follows, completing the proof by induction. 

� 

This theorem has an important corollary: 
Corollary 14.1.4.  Bruce dies. 
Proof.  In Die Hard 6, Bruce has water  jugs with capacities 3 and 6 and must form 
4 gallons of water.  However, the amount in each jug is always of the form 3s + 6t 
by Lemma 14.1.3.  This  is always a multiple of 3 by Lemma 14.1.1.3,  so he cannot 
� 
measure out 4 gallons. 
But Lemma  14.1.3  isn’t very  satisfying.  We’ve  just managed  to  recast  a pretty 
understandable question about water jugs into a complicated question about linear 
combinations. This might not seem like progress. Fortunately, linear combinations 
are closely related to something more familiar, namely greatest common divisors, 
and these will help us solve the water jug problem. 

278 

CHAPTER 14.  NUMBER THEORY 

14.2  The Greatest Common Divisor 
We’ve  already  examined  the  Euclidean  Algorithm  for  computing  gcd(a, b),  the 
greatest  common  divisor  of  a  and  b.  This  quantity  turns  out  to  be  a  very  valu­
able piece of information about the relationship between a and b. We’ll be making 
arguments about greatest common divisors all the time. 

14.2.1  Linear Combinations and the GCD 
The  theorem  below  relates  the  greatest  common  divisor  to  linear  combinations. 
This theorem is very useful; take the time to understand it and then remember it! 
Theorem 14.2.1.  The greatest common divisor of a and b is equal to the smallest positive 
linear combination of a and b. 
For example, the greatest common divisor of 52 and 44 is 4. And, sure enough, 
4 is a linear combination of 52 and 44: 
6  52 + (−7)  44 = 4 
·
· 
Furthermore,  no  linear  combination  of  52  and  44  is  equal  to  a  smaller  positive 
integer. 

(14.3) 

Proof.  By  the  Well  Ordering  Principle,  there  is  a  smallest  positive  linear  combi­
nation  of  a  and  b;  call  it  m.  We’ll  prove  that  m  =  gcd(a, b)  by  showing  both 
gcd(a, b) ≤ m and m ≤ gcd(a, b). 
First, we show that gcd(a, b) ≤ m.  Now any common divisor of a and b —that 
is,  any  c  such  that  c  |  a  and  c  |  b —will divide  both  sa  and  tb,  and  therefore  also 
divides sa + tb. The gcd(a, b) is by deﬁnition a common divisor of a and b, so 
gcd(a, b) | sa + tb 
every s and t.  In particular, gcd(a, b) | m, which implies that gcd(a, b) ≤ m. 
Now,  we  show  that  m  ≤  gcd(a, b).  We  do  this  by  showing  that  m  |  a. A 
symmetric argument  shows  that m  |  b, which means  that m  is a  common divisor 
of a and b.  Thus, m must be less than or equal to the greatest common divisor of a 
and b. 
All that remains is to show that m | a. By the Division Algorithm, there exists a 
quotient q and remainder r such that: 
· 
(where 0 ≤ r < m)
a = q m + r 
Recall that m = sa + tb for some integers s and t.  Substituting in for m gives: 
· 
a = q  (sa + tb) + r, 
r = (1 − qs)a + (−qt)b. 
We’ve  just  expressed  r  as  a  linear  combination  of  a  and  b.  However,  m  is  the 
smallest  positive  linear  combination  and  0  ≤  r < m.  The  only  possibility  is  that 
the remainder r is not positive; that is, r = 0. This implies m | a. 
� 

so

14.2.  THE GREATEST COMMON DIVISOR 

279 

Corollary  14.2.2.  An  integer  is  linear  combination  of  a  and  b  iff  it  is  a  multiple  of 
gcd(a, b). 

Proof.  By (14.3), every linear combination of a and b is a multiple of gcd(a, b). Con­
versely, since gcd(a, b) is a linear combination of a and b, every multiple of gcd(a, b) 
� 
is as well. 

Now  we  can  restate  the  water  jugs  lemma  in  terms  of  the  greatest  common 
divisor: 

Corollary  14.2.3.  Suppose  that  we  have  water  jugs  with  capacities  a  and  b.  Then  the 
amount of water in each jug is always a multiple of gcd(a, b). 

For example, there is no way to form 2 gallons using 1247 and 899 gallon jugs, 
because 2 is not a multiple of gcd(1247, 899) = 29. 

14.2.2  Properties of the Greatest Common Divisor 
We’ll often make use of some basic gcd facts: 

Lemma 14.2.4.  The following statements about the greatest common divisor hold: 

1.  Every common divisor of a and b divides gcd(a, b). 
· 
2.	 gcd(ka, kb) = k  gcd(a, b) for all k > 0.
3.  If gcd(a, b) = 1 and gcd(a, c) = 1, then gcd(a, bc) = 1. 
4.  If a  | bc and gcd(a, b) = 1, then a  | c. 
5.	 gcd(a, b) = gcd(b, rem(a, b)). 

Here’s the trick to proving these statements:  translate the gcd world to the lin­
ear  combination  world  using  Theorem  14.2.1,  argue  about  linear  combinations, 
and then translate back using Theorem 14.2.1 again. 

Proof.	 We prove only parts 3. and 4. 
Proof  of  3.  The  assumptions  together  with  Theorem  14.2.1  imply  that  there 
exist integers s, t, u, and v such that: 

sa + tb = 1 
ua + vc = 1 

Multiplying these two equations gives: 

(sa + tb)(ua + vc) = 1 
· 
The  left  side  can  be  rewritten  as  a  (asu +  btu +  csv) +  bc(tv).  This  is  a  linear 
combination of a and bc that is equal to 1, so gcd(a, bc) = 1 by Theorem 14.2.1. 

280 

CHAPTER 14.  NUMBER THEORY 

Proof of 4. Theorem 14.2.1 says that gcd(ac, bc) is equal to a linear combination 
of  ac  and  bc.  Now  a  |  ac  trivially  and  a  |  bc by  assumption.  Therefore,  a divides 
every  linear  combination  of  ac  and  bc.  In  particular,  a  divides  gcd(ac, bc) =  c  · 
· 
gcd(a, b) =  c  1 =  c.  The ﬁrst equality uses part 2. of  this  lemma, and  the second 
� 
uses the assumption that gcd(a, b) = 1. 
Lemma  14.2.4.5  is  the  preserved  invariant  from  Lemma  9.1.7  that we  used  to 
prove partial correctness of the Euclidean Algorithm. 
Now  let’s  see  if  it’s  possible  to  make  3  gallons  using  21  and  26-gallon  jugs. 
Using Euclid’s algorithm: 

gcd(26, 21) = gcd(21, 5) = gcd(5, 1) = 1. 

Now  3  is  a multiple of  1,  so we  can’t  rule  out  the possibility  that  3 gallons  can be 
formed. On the other hand, we don’t know it can be done. 

14.2.3  One Solution for All Water Jug Problems 
Can Bruce form 3 gallons using 21 and 26-gallon jugs? This question is not so easy 
to answer without some number theory. 
Corollary 14.2.2 says that 3 can be written as a linear combination of 21 and 26, 
since 3 is a multiple of gcd(21, 26) =  1.  In other words, there exist integers s and t 
such that: 
·
· 
3 = s  21 + t  26
We don’t know what the coefﬁcients s and t are, but we do know that they exist. 
Now  the  coefﬁcient  s  could  be  either  positive  or  negative.  However,  we  can 
readily transform this linear combination into an equivalent linear combination 
·
· 
3 = s�  21 + t�  26 
(14.4)
where  the  coefﬁcient  s�  is  positive.  The  trick  is  to  notice  that  if we  increase  s  by 
26  in  the original  equation  and decrease  t by  21,  then  the value of  the  expression 
·
· 
s  21 + t  26  is unchanged overall.  Thus,  by  repeatedly  increasing  the value of  s
(by  26  at  a  time)  and  decreasing  the  value  of  t  (by  21  at  a  time),  we  get  a  linear 
combination s�  · 21 + t�  · 26 = 3 where the coefﬁcient s�  is positive. Notice that then 
t�  must be negative; otherwise, this expression would be much greater than 3. 
Now here’s how to form 3 gallons using jugs with capacities 21 and 26: 
Repeat s�  times: 
1.  Fill the 21-gallon jug. 

2.  Pour all  the water  in  the 21-gallon  jug  into  the 26-gallon  jug.  Whenever  the 
26-gallon jug becomes full, empty it out. 

At  the  end  of  this  process,  we must  have  have  emptied  the  26-gallon  jug  exactly 
|t� | times.  Here’s why:  we’ve taken s�  · 21 gallons of water from the fountain, and 
we’ve poured out some multiple of 26 gallons.  If we emptied fewer than |t� | times, 

14.2.  THE GREATEST COMMON DIVISOR 

281 

then by (14.4), the big jug would be left with at least 3 + 26 gallons, which is more 
than it can hold;  if we emptied it more times, the big jug would be left containing 
at most 3 − 26 gallons, which is nonsense. But once we have emptied the 26-gallon 
jug exactly |t� | times, equation (14.4) implies that there are exactly 3 gallons left. 
Remarkably, we don’t  even need  to know  the  coefﬁcients  s�  and  t�  in order  to 
use this strategy!  Instead of repeating the outer loop s�  times, we could just repeat 
until we obtain 3 gallons, since that must happen eventually.  Of course, we have to 
keep  track  of  the  amounts  in  the  two  jugs  so we  know when we’re done.  Here’s 
the solution that approach gives: 

(0, 0) 

−−−−−−−−→ 
−−−→ 
pour 21 into 26 
ﬁll 21 
(0, 21)
(21, 0) 
−−−→  (21, 21)  −−−−−−−−→  (16, 26)  −−−−−→  (16, 0)  −−−−−−−−→  (0, 16) 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
−−−→  (21, 16)  −−−−−−−−→  (11, 26)  −−−−−→  (11, 0)  −−−−−−−−→  (0, 11) 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(6, 0)  −−−−−−−−→ 
(6, 26)  −−−−−→ 
−−−→  (21, 11)  −−−−−−−−→ 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(0, 6) 
(1, 26)  −−−−−→ 
(21, 6)  −−−−−−−−→ 
−−−→ 
(1, 0)  −−−−−−−−→ 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(0, 1) 
−−−→ 
(21, 1)  −−−−−−−−→ 
pour 21 into 26 
ﬁll 21 
(0, 22) 
−−−→  (21, 22)  −−−−−−−−→  (17, 26)  −−−−−→  (17, 0)  −−−−−−−−→  (0, 17) 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
−−−→  (21, 17)  −−−−−−−−→  (12, 26)  −−−−−→  (12, 0)  −−−−−−−−→  (0, 12) 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
−−−→  (21, 12)  −−−−−−−−→ 
(7, 26)  −−−−−→ 
(7, 0)  −−−−−−−−→ 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(0, 7) 
(2, 26)  −−−−−→ 
(21, 7)  −−−−−−−−→ 
−−−→ 
(2, 0)  −−−−−−−−→ 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(0, 2) 
(21, 2)  −−−−−−−−→ 
−−−→ 
pour 21 into 26 
ﬁll 21 
(0, 23) 
−−−→  (21, 23)  −−−−−−−−→  (18, 26)  −−−−−→  (18, 0)  −−−−−−−−→  (0, 18) 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
−−−→  (21, 18)  −−−−−−−−→  (13, 26)  −−−−−→  (13, 0)  −−−−−−−−→  (0, 13) 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(8, 0)  −−−−−−−−→ 
(8, 26)  −−−−−→ 
−−−→  (21, 13)  −−−−−−−−→ 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(0, 8) 
−−−→ 
(21, 8)  −−−−−−−−→ 
(3, 26)  −−−−−→ 
(3, 0)  −−−−−−−−→ 
pour 21 into 26 
empty 26 
pour 21 into 26 
ﬁll 21 
(0, 3) 

The same approach works regardless of the jug capacities and even regardless 
the  amount we’re  trying  to  produce!  Simply  repeat  these  two  steps  until  the  de­
sired amount of water is obtained: 

1.  Fill the smaller jug. 

2.  Pour all the water in the smaller jug into the larger jug. Whenever the larger

jug becomes full, empty it out.


By the same reasoning as before, this method eventually generates every mul­
tiple  of  the  greatest  common  divisor  of  the  jug  capacities —all  the  quantities we 
can possibly produce. No ingenuity is needed at all! 

282 

CHAPTER 14.  NUMBER THEORY 

14.2.4  The Pulverizer 
We saw that no matter which pair of integers a and b we are given, there is always 
a pair of integer coefﬁcients s and t such that 

gcd(a, b) = sa + tb. 

The previous subsection gives a roundabout and not very efﬁcient method of ﬁnd­
ing  such  coefﬁcients  s  and  t.  In  Chapter  9.1.3  we  deﬁned  and  veriﬁed  the  “Ex­
tended  Euclidean  GCD  algorithm,”  which  is  a  much  more  efﬁcient  way  to  ﬁnd 
these  coefﬁcients.  In  this  section we ﬁnally  explain where  the  obscure procedure 
in  Chapter  9.1.3  came  from  by  describing  it  in  a  way  that  dates  to  sixth-century 
India, where it was called kuttak, which means “The Pulverizer.” 
Suppose  we  use  Euclid’s  Algorithm  to  compute  the  GCD  of  259  and  70,  for 
example: 

gcd(259, 70)  =  gcd(70, 49) 
=  gcd(49, 21) 
=  gcd(21, 7) 
=  gcd(7, 0) 
= 7. 

since rem(259, 70) = 49 
since rem(70, 49) = 21 
since rem(49, 21) = 7 
since rem(21, 7) = 0 

The Pulverizer goes through the same steps, but requires some extra bookkeeping 
along  the  way:  as  we  compute  gcd(a, b),  we  keep  track  of  how  to  write  each  of 
the  remainders  (49,  21,  and  7,  in  the  example)  as  a  linear  combination  of  a  and  b 
(this  is worthwhile,  because  our  objective  is  to write  the  last  nonzero  remainder, 
which  is  the  GCD,  as  such  a  linear  combination).  For  our  example,  here  is  this 
extra bookkeeping: 

x 
259 
70 

49 

21 

y 
70 
49 

21 

7 

(rem(x, y))  =  x − q · y 
49  =  259 − 3 · 70 
21  =  70 − 1 · 49 
=  70 − 1 · (259 − 3 · 70) 
=  −1 · 259 + 4 · 70 
7  =  49 − 2 · 21 
=  (259 − 3 · 70) − 2 · (−1 · 259 + 4 · 70) 
3 · 259 − 11 · 70 
= 

0 

We began by  initializing two variables, x  =  a and y  =  b.  In the ﬁrst two columns 
above,  we  carried  out  Euclid’s  algorithm.  At  each  step,  we  computed  rem(x, y), 
which can be written in the form x − q y .  (Remember that the Division Algorithm 
· 
says x = q y+r , where r is the remainder. We get r = x−q y by rearranging terms.) 
·
·
Then we replaced x and y  in this equation with equivalent linear combinations of 
a and  b, which we already had  computed.  After  simplifying, we were  left with a 
linear combination of a and b that was equal to the remainder as desired. The ﬁnal 
solution is boxed. 

14.3.  THE FUNDAMENTAL THEOREM OF ARITHMETIC 

283 

14.2.5  Problems 
Class Problems 

Problem 14.1. 
A number is perfect if it is equal to the sum of its positive divisors, other than itself. 
For  example,  6  is perfect,  because  6  =  1 + 2 + 3.  Similarly,  28  is perfect,  because 
28 = 1 + 2 + 4 + 7 + 14. Explain why 2k−1 (2k  − 1) is perfect when 2k  − 1 is prime.2 

Problem 14.2.  (a)  Use the Pulverizer to ﬁnd integers x, y such that 
·
· 
x  50 + y  21 = gcd(50, 21).
(b)  Now ﬁnd integers x� , y �  with y �  > 0 such that 
·
· 
x�  50 + y �  21 = gcd(50, 21)

Problem 14.3. 
For nonzero integers, a, b, prove the following properties of divisibility and GCD’S. 
(You may use the fact that gcd(a, b) is an integer linear combination of a and b. You 
may not appeal to uniqueness of prime factorization because the properties below 
are needed to prove unique factorization.) 
(a)  Every common divisor of a and b divides gcd(a, b). 
(b)  If a | bc and gcd(a, b) = 1, then a  | c. 
(c)  If p  | ab for some prime, p, then p | a or p  | b. 
(d)  Let  m  be  the  smallest  integer  linear  combination  of  a  and  b  that  is  positive. 
Show that m = gcd(a, b). 

14.3  The Fundamental Theorem of Arithmetic 

We now have almost enough tools to prove something that you probably already 
know. 
Theorem 14.3.1 (Fundamental Theorem of Arithmetic).  Every positive integer n can 
be written in a unique way as a product of primes: 
(p1  ≤ p2  ≤  · · · ≤ pj ) 
n  =  p1  · p2  · · · pj 
2 Euclid  proved 
the 
About  250  years  ago,  Euler  proved 
this  2300  years  ago. 
every  even  perfect  number 
converse: 
see 
is  of 
this 
form 
(for  a 
simple  proof 
http://primes.utm.edu/notes/proofs/EvenPerfect.html).  As  is  typical  in  number 
theory, apparently simple results lie at the brink of the unknown.  For example, it is not known if there 
are an inﬁnite number of even perfect numbers or any odd perfect numbers at all. 

284 

CHAPTER 14.  NUMBER THEORY 

Notice that the theorem would be false if 1 were considered a prime; for exam­
·
·
·
·
·
ple, 15 could be written as 3 5 or 1 3 5 or 12  3 5. Also, we’re relying on a standard 
convention:  the product of an empty set of numbers is deﬁned to be 1, much as the 
sum  of  an  empty  set  of  numbers  is deﬁned  to  be  0.  Without  this  convention,  the 
theorem would be false for n = 1. 
There is a certain wonder in the Fundamental Theorem, even if you’ve known 
it since you were in a crib.  Primes show up erratically in the sequence of integers. 
In fact, their distribution seems almost random: 

2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, . . . 

Basic  questions  about  this  sequence  have  stumped  humanity  for  centuries.  And 
yet we know that every natural number can be built up from primes in exactly one 
way.  These  quirky  numbers  are  the  building  blocks  for  the  integers.  The  Funda­
mental Theorem is not hard to prove, but we’ll need a couple of preliminary facts. 
Lemma 14.3.2.  If p is a prime and p | ab, then p | a or p  | b. 

Proof.  The greatest common divisor of a and p must be either 1 or p, since these are 
the only positive divisors of p.  If gcd(a, p) = p, then the claim holds, because a is a 
multiple of p. Otherwise, gcd(a, p) = 1 and so p  | b by Lemma 14.2.4.4. 
� 

A routine induction argument extends this statement to: 
Lemma 14.3.3.  Let p be a prime.  If p  | a1a2  · · · an , then p divides some ai . 

Now we’re ready to prove the Fundamental Theorem of Arithmetic. 

Proof.  Theorem  2.4.1  showed,  using  the Well Ordering Principle,  that  every posi­
tive integer can be expressed as a product of primes.  So we just have to prove this 
expression is unique. We will use Well Ordering to prove this too. 
The  proof  is  by  contradiction:  assume,  contrary  to  the  claim,  that  there  exist 
positive  integers  that can be written as products of primes  in more  than one way. 
By the Well Ordering Principle, there is a smallest integer with this property.  Call 
this integer n, and let 

n = p1  · 
p2  · · · 
pj
= q1  · 
q2  · · · 
qk
be two of the (possibly many) ways to write n as a product of primes.  Then p1  | n 
and  so p1  |  q1 q2  · · · qk .  Lemma 14.3.3  implies  that p1  divides one of  the primes  qi . 
But  since  qi  is a prime,  it must be  that p1  =  qi .  Deleting p1  from  the ﬁrst product 
and  qi  from  the  second, we ﬁnd  that n/p1  is a positive  integer  smaller  than n  that 
can also be written as a product of primes in two distinct ways. But this contradicts 
� 
the deﬁnition of n as the smallest such positive integer. 

14.3.  THE FUNDAMENTAL THEOREM OF ARITHMETIC 

285 

The Prime Number Theorem


Let π(x) denote the number of primes less than or equal to x. For example, π(10) = 
4  because  2,  3,  5,  and  7  are  the  primes  less  than  or  equal  to  10.  Primes  are  very 
irregularly distributed, so the growth of π  is similarly erratic. However, the Prime 
Number Theorem gives an approximate answer: 

π(x)
lim 
x→∞  x/ ln x 

= 1 

Thus, primes gradually taper off.  As a rule of thumb, about 1 integer out of every 
ln x in the vicinity of x is a prime. 
The Prime Number Theorem was  conjectured  by Legendre  in  1798  and proved  a 
century  later  by  de  la Vallee  Poussin  and Hadamard  in  1896.  However,  after  his 
death,  a  notebook  of  Gauss was  found  to  contain  the  same  conjecture,  which  he 
apparently made in 1791 at age 15.  (You sort of have to feel sorry for all the other­
wise “great” mathematicians who had  the misfortune of being contemporaries of 
Gauss.) 
� 
� 
In late 2004 a billboard appeared in various locations around the country: 
.  com 

ﬁrst 10-digit prime found 
in consecutive digits of e 

Substituting  the  correct  number  for  the  expression  in  curly-braces  produced  the 
URL  for a Google employment page.  The  idea was  that Google was  interested  in 
hiring the sort of people that could and would solve such a problem. 
How hard is this problem? Would you have to look through thousands or millions 
or billions of digits of e  to ﬁnd a 10-digit prime?  The rule of  thumb derived  from 
the Prime Number Theorem says that among 10-digit numbers, about 1 in 
ln 1010  ≈ 23 

is prime. This suggests that the problem isn’t really so hard!  Sure enough, the ﬁrst 
10-digit prime in consecutive digits of e appears quite early: 

e =2.718281828459045235360287471352662497757247093699959574966 
9676277240766303535475945713821785251664274274663919320030 
599218174135966290435729003342952605956307381323286279434 . . . 

286 

CHAPTER 14.  NUMBER THEORY 

14.3.1  Problems 
Class Problems 
Problem 14.4.  (a)  Let m = 295241171712  and n = 2372211211131 179 192 . What is the 
gcd(m, n)? What is the least common multiple, lcm(m, n), of m and n? Verify that 
· 
gcd(m, n)  lcm(m, n) = mn. 

(14.5)

(b)  Describe  in  general  how  to  ﬁnd  the  gcd(m, n)  and  lcm(m, n)  from  the  prime 
factorizations of m and n. Conclude that equation (14.5) holds for all positive inte­
gers m, n. 

14.4  Alan Turing 

Photograph removed due to copyright restrictions.
 A similar photograph can be seen 
  here: http://en.wikipedia.org/wiki/File:Alan_Turing_photo.jpg. 

The man pictured  above  is Alan Turing,  the most  important ﬁgure  in  the  history 
of computer science.  For decades, his fascinating life story was shrouded by gov­
ernment secrecy, societal taboo, and even his own deceptions. 
At  age  24,  Turing wrote  a  paper  entitled On  Computable Numbers,  with  an Ap­
plication  to  the Entscheidungsproblem.  The crux of  the paper was an elegant way  to 
model a computer in mathematical terms.  This was a breakthrough, because it al­
lowed the tools of mathematics to be brought to bear on questions of computation. 
For example, with his model in hand, Turing immediately proved that there exist 
problems that no computer can solve— no matter how ingenious the programmer. 
Turing’s paper is all the more remarkable because he wrote it in 1936, a full decade 
before any electronic computer actually existed. 
The  word  “Entscheidungsproblem”  in  the  title  refers  to  one  of  the  28 mathe­
matical problems posed by David Hilbert in 1900 as challenges to mathematicians 

14.4.  ALAN TURING 

287 

of  the 20th century.  Turing knocked  that one off  in  the same paper.  And perhaps 
you’ve heard of the “Church-Turing thesis”? Same paper. So Turing was obviously 
a brilliant guy who generated  lots of amazing  ideas.  But  this  lecture  is about one 
of Turing’s less-amazing ideas.  It involved codes.  It involved number theory. And 
it was sort of stupid. 
Let’s  look  back  to  the  fall  of  1937.  Nazi Germany was  rearming  under Adolf 
Hitler,  world-shattering war  looked  imminent,  and—  like  us—  Alan  Turing was 
pondering  the usefulness  of number  theory.  He  foresaw  that preserving military 
secrets would  be  vital  in  the  coming  conﬂict  and  proposed  a way  to  encrypt  com­
munications using number theory.  This is an idea that has ricocheted up to our own 
time.  Today,  number  theory  is  the  basis  for numerous public-key  cryptosystems, 
digital  signature  schemes,  cryptographic  hash  functions,  and  electronic  payment 
systems.  Furthermore, military funding agencies are among the biggest investors 
in cryptographic research.  Sorry Hardy! 
Soon after devising his code, Turing disappeared from public view, and half a 
century would pass before the world learned the full story of where he’d gone and 
what he did  there.  We’ll  come back  to Turing’s  life  in a  little while;  for now,  let’s 
investigate  the  code  Turing  left  behind.  The  details  are  uncertain,  since  he  never 
formally published the idea, so we’ll consider a couple of possibilities. 

14.4.1  Turing’s Code (Version 1.0) 
The ﬁrst challenge is to translate a text message into an integer so we can perform 
mathematical operations on it. This step is not intended to make a message harder 
to  read,  so  the  details  are  not  too  important.  Here  is  one  approach:  replace  each 
letter of the message with two digits (A =  01, B  =  02, C  =  03, etc.)  and string all 
the digits together to form one huge number.  For example, the message “victory” 
could be translated this way: 

→ 

“v
c
i 
22  09  03

t
y” 
r
o
20  15  18  25

Turing’s code requires the message to be a prime number, so we may need to pad 
the  result  with  a  few  more  digits  to  make  a  prime.  In  this  case,  appending  the 
digits 13 gives the number 2209032015182513, which is prime. 
Now  here  is  how  the  encryption  process  works.  In  the  description  below,  m 
is  the  unencoded  message  (which  we  want  to  keep  secret),  m∗  is  the  encrypted 
message (which the Nazis may intercept), and k  is the key. 

Beforehand  The sender and receiver agree on a secret key, which is a large prime 
k . 

Encryption  The sender encrypts the message m by computing: 
m∗  = m k· 

288 

CHAPTER 14.  NUMBER THEORY 

Decryption  The receiver decrypts m∗  by computing: 
·  = m 
m∗  m k 
= 
k 
k

For example, suppose that the secret key is the prime number k = 22801763489 
and the message m is “victory”. Then the encrypted message is: 
m∗  = m k· 
· 
= 2209032015182513  22801763489
= 50369825549820718594667857 

There  are  a  couple  of  questions  that  one  might  naturally  ask  about  Turing’s 
code. 

1.  How can the sender and receiver ensure that m and k are prime numbers, as 
required? 
The  general  problem  of  determining  whether  a  large  number  is  prime  or 
composite  has  been  studied  for  centuries,  and  reasonably  good  primality 
tests were known even in Turing’s time.  In 2002, Manindra Agrawal, Neeraj 
Kayal,  and  Nitin  Saxena  announced  a  primality  test  that  is  guaranteed  to 
work  on  a  number  n  in  about  (log n)12  steps,  that  is,  a  number  of  steps 
bounded  by  a  twelfth  degree  polynomial  in  the  length  (in  bits)  of  the  in­
put,  n.  This  deﬁnitively  places  primality  testing  way  below  the  problems 
of  exponential  difﬁculty.  Amazingly,  the  description  of  their  breakthrough 
algorithm was only thirteen lines long! 
Of course, a twelfth degree polynomial grows pretty fast, so the Agrawal, et 
al. procedure is of no practical use.  Still, good ideas have a way of breeding 
more  good  ideas,  so  there’s  certainly  hope  further  improvements  will  lead 
to  a  procedure  that  is  useful  in  practice.  But  the  truth  is,  there’s  no  practi­
cal need to improve it, since very efﬁcient probabilistic procedures for prime-
testing have been known since the early 1970’s. These procedures have some 
probability of giving a wrong answer, but their probability of being wrong is 
so tiny that relying on their answers is the best bet you’ll ever make. 

2.  Is Turing’s code secure? 
· 
The  Nazis  see  only  the  encrypted  message  m∗  =  m k ,  so  recovering  the 
original message m requires factoring m∗ . Despite immense efforts, no really 
efﬁcient  factoring  algorithm has  ever been  found.  It  appears  to be  a  funda­
mentally difﬁcult problem,  though a breakthrough someday  is not  impossi­
ble.  In effect, Turing’s code puts to practical use his discovery that there are 
limits to the power of computation.  Thus, provided m and k are sufﬁciently 
large, the Nazis seem to be out of luck! 

This all sounds promising, but there is a major ﬂaw in Turing’s code. 

14.5.  MODULAR ARITHMETIC 

289 

14.4.2  Breaking Turing’s Code 
Let’s  consider  what  happens  when  the  sender  transmits  a  second  message  using 
Turing’s code and  the same key.  This gives  the Nazis  two encrypted messages  to 
look at: 
1  = m1  · k 
2  = m2  · k 
m∗ 
m∗ 
and 
The  greatest  common  divisor  of  the  two  encrypted messages,  m∗ 
1  and m∗ 
2 ,  is  the 
secret key k .  And, as we’ve seen, the GCD of two numbers can be computed very 
efﬁciently.  So after the second message is sent, the Nazis can recover the secret key 
and read every message! 
It  is  difﬁcult  to  believe  a mathematician  as  brilliant  as  Turing  could  overlook 
such a glaring problem. One possible explanation is that he had a slightly different 
system in mind, one based on modular arithmetic. 

14.5  Modular Arithmetic 

On page 1 of his masterpiece on number theory, Disquisitiones Arithmeticae, Gauss 
introduced the notion of “congruence”. Now, Gauss is another guy who managed 
to cough up a half-decent idea every now and then, so let’s take a look at this one. 
Gauss said that a is congruent to b modulo n iff n | (a − b). This is written 
a ≡ b  (mod  n). 

For example: 

29 ≡ 15  (mod  7)  because 7 | (29 − 15). 
There is a close connection between congruences and remainders: 

Lemma 14.5.1 (Congruences and Remainders). 
a ≡ b  (mod  n) 

iff 

rem(a, n) = rem(b, n). 

Proof.  By the Division Theorem, there exist unique pairs of integers q1 , r1  and q2 , r2 
such that: 

a = q1n + r1 
b = q2n + r2 

where 0 ≤ r1  < n, 
where 0 ≤ r2  < n. 

Subtracting the second equation from the ﬁrst gives: 
where −n < r1  − r2  < n. 
a − b = (q1  − q2 )n + (r1  − r2 ) 
Now a  ≡  b  (mod  n)  if  and only  if n divides  the  left  side.  This  is  true  if  and only 
if  n  divides  the  right  side,  which  holds  if  and  only  if  r1  −  r2  is  a  multiple  of  n. 
Given  the bounds  on  r1  − r2 ,  this happens precisely when  r1  =  r2 ,  that  is, when 
� 
rem(a, n) = rem(b, n). 

290 

CHAPTER 14.  NUMBER THEORY 

So we can also see that 
29 ≡ 15  (mod  7)  because  rem(29, 7) = 1 = rem(15, 7). 

This formulation explains why the congruence relation has properties like an equal­
ity relation.  Notice that even though (mod 7) appears over on the right side the ≡
symbol, it isn’t any more strongly associated with the 15 than with the 29.  It would 
really be clearer to write 29 ≡  mod  7  15 for example, but the notation with the mod­
ulus at the end is ﬁrmly entrenched and we’ll stick to it. 
We’ll make frequent use of the following immediate Corollary of Lemma 14.5.1: 

Corollary 14.5.2. 

a ≡ rem(a, n)  (mod  n) 

Still another way to think about congruence modulo n is that it deﬁnes a partition 
of the integers into n sets so that congruent numbers are all in the same set. For example, 
suppose  that we’re working modulo  3.  Then we  can partition  the  integers  into  3 
sets as follows: 

{ 
{ 
{

. . . ,  −6,  −3,  0,  3,  6, 
9, 
. . . ,  −5,  −2,  1,  4,  7,  10, 
. . . ,  −4,  −1,  2,  5,  8,  11, 

. . .  }

}

. . .

} 
. . . 

according  to whether  their  remainders on division by 3 are 0, 1, or 2.  The upshot 
is  that  when  arithmetic  is  done  modulo  n  there  are  really  only  n  different  kinds 
of numbers  to worry about, because  there are only n possible remainders.  In  this 
sense, modular  arithmetic  is  a  simpliﬁcation  of  ordinary  arithmetic  and  thus  is  a 
good reasoning tool. 
There are many useful facts about congruences, some of which are listed in the 
lemma below. The overall theme is that congruences work a lot like equations, though 
there are a couple of exceptions. 
Lemma 14.5.3 (Facts About Congruences).  The following hold for n ≥ 1: 
1.  a ≡ a  (mod  n) 
2.  a ≡ b  (mod  n) implies b ≡ a  (mod  n) 
3.  a ≡ b  (mod  n) and b ≡ c  (mod  n) implies a ≡ c  (mod  n) 
4.  a ≡ b  (mod  n) implies a + c ≡ b + c  (mod  n) 
5.  a ≡ b  (mod  n) implies ac ≡ bc  (mod  n) 
6.  a ≡ b  (mod  n) and c ≡ d  (mod  n) imply a + c ≡ b + d  (mod  n) 
7.  a ≡ b  (mod  n) and c ≡ d  (mod  n) imply ac ≡ bd  (mod  n) 

14.5.  MODULAR ARITHMETIC 

291 

Proof.  Parts 1.–3. follow immediately from Lemma 14.5.1.  Part 4. follows immedi­
ately from the deﬁnition that a ≡ b  (mod  n) iff n  (a − b). Likewise, part 5. follows 
|
because if n  | (a − b) then it divides (a − b)c = ac
− bc. To prove part 6., assume 
a ≡ b  (mod  n) 
(14.6) 

and 

Then 

c ≡ d  (mod  n). 

(14.7) 

a + c ≡ b + c  (mod  n) 
c + b ≡ d + b  (mod  n) 
b + c ≡ b + d  (mod  n) 
a + c ≡ b + d  (mod  n) 
as a similar proof. 

Part 7. h

(by part 4. and (14.6)), 
(by part 4. and (14.7)), so 
and therefore 
(by part 3.) 

� 

14.5.1  Turing’s Code (Version 2.0) 
In 1940 France had fallen before Hitler ’s army, and Britain alone stood against the 
Nazis  in  western  Europe.  British  resistance  depended  on  a  steady  ﬂow  of  sup­
plies brought across the north Atlantic from the United States by convoys of ships. 
These convoys were engaged in a cat-and-mouse game with German “U-boats” — 
submarines —which prowled  the Atlantic,  trying  to sink supply ships and starve 
Britain  into  submission.  The outcome of  this  struggle pivoted on a balance of  in­
formation:  could  the  Germans  locate  convoys  better  than  the  Allies  could  locate 
U-boats or vice versa? 
Germany lost. 
But a critical reason behind Germany’s loss was made public only in 1974: Ger­
many’s  naval  code,  Enigma,  had  been  broken  by  the  Polish  Cipher  Bureau  (see 
http://en.wikipedia.org/wiki/Polish  Cipher  Bureau)  and  the  secret 
had been turned over to the British a few weeks before the Nazi invasion of Poland 
in 1939. Throughout much of the war, the Allies were able to route convoys around 
German submarines by  listening  in to German communications.  The British gov­
ernment  didn’t  explain  how  Enigma  was  broken  until  1996.  When  it  was  ﬁnally 
released  (by  the  US),  the  story  revealed  that  Alan  Turing  had  joined  the  secret 
British  codebreaking  effort  at  Bletchley  Park  in  1939,  where  he  became  the  lead 
developer  of  methods  for  rapid,  bulk  decryption  of  German  Enigma  messages. 
Turing’s Enigma deciphering was an invaluable contribution to the Allied victory 
over Hitler. 
Governments are always tight-lipped about cryptography, but the half-century 
of  ofﬁcial  silence  about Turing’s  role  in breaking Enigma  and  saving Britain may 
be related to some disturbing events after the war. 
Let’s  consider  an  alternative  interpretation  of  Turing’s  code.  Perhaps we  had 
the basic  idea  right  (multiply  the message by  the key),  but  erred  in using  conven­
tional arithmetic instead of modular arithmetic. Maybe this is what Turing meant: 

292 

CHAPTER 14.  NUMBER THEORY 

Beforehand  The sender and receiver agree on a large prime p, which may be made 
public.  (This will be the modulus for all our arithmetic.)  They also agree on 
a secret key k ∈ {1, 2, . . . , p − 1}. 
Encryption  The message m can be any integer in the set {0, 1, 2, . . . , p − 1}; in par­
ticular, the message is no longer required to be a prime. The sender encrypts 
the message m to produce m∗  by computing: 
m∗  = rem(mk , p) 

(14.8) 

Decryption  (Uh-oh.) 

The decryption step  is a problem.  We might hope  to decrypt  in  the same way 
as  before:  by  dividing  the  encrypted message m∗  by  the  key  k .  The  difﬁculty  is 
that m∗  is  the remainder when mk  is divided by p.  So dividing m∗  by k might not 
even give us an integer! 
This decoding difﬁculty can be overcome with a better understanding of arith­
metic modulo a prime. 

14.5.2  Problems 
Class Problems 

Problem 14.5. 
The  following properties of equivalence mod n  follow directly  from  its deﬁnition 
and  simple  properties  of  divisibility.  See  if  you  can  prove  them without  looking 
up the proofs in the text. 
(a)  If a ≡ b  (mod  n), then ac ≡ bc  (mod  n). 
(b)  If a ≡ b  (mod  n) and b ≡ c  (mod  n), then a ≡ c  (mod  n). 
(c)  If a ≡ b  (mod  n) and c ≡ d  (mod  n), then ac ≡ bd  (mod  n). 
(d)  rem(a, n) ≡ a  (mod  n). 

Problem 14.6.  (a)  Why is a number written in decimal evenly divisible by 9 if and 
only if the sum of its digits is a multiple of 9? Hint:  10 ≡ 1  (mod  9). 
(b)  Take  a  big  number,  such  as  37273761261.  Sum  the  digits,  where  every  other 
one is negated: 
3 + (−7) + 2 + (−7) + 3 + (−7) + 6 + (−1) + 2 + (−6) + 1 = −11 

Explain  why  the  original  number  is  a  multiple  of  11  if  and  only  if  this  sum  is  a 
multiple of 11. 

14.6.  ARITHMETIC WITH A PRIME MODULUS 

293 

Problem 14.7. 
At one  time,  the Guinness Book of World Records  reported  that  the “greatest hu­
man  calculator ”  was  a  guy  who  could  compute  13th  roots  of  100-digit  numbers 
that were powers of 13. What a curious choice of tasks . . . . 
(a)  Prove that 
d13  ≡ d  (mod  10) 

(14.9) 

for 0 ≤ d < 10. 
(b)  Now prove that 

for all n. 

n 13  ≡ n  (mod  10) 

(14.10) 

14.6  Arithmetic with a Prime Modulus 

14.6.1  Multiplicative Inverses 
The multiplicative inverse of a number x is another number x−1  such that: 
· 
x x−1  = 1 

Generally, multiplicative inverses exist over the real numbers. For example, the 
multiplicative inverse of 3 is 1/3 since: 

1
· 
3  = 1 
3 

The sole exception is that 0 does not have an inverse. 
On the other hand, inverses generally do not exist over the integers.  For exam­
ple, 7 can not be multiplied by another integer to give 1. 
Surprisingly,  multiplicative  inverses  do  exist  when  we’re  working  modulo  a 
prime number.  For example,  if we’re working modulo 5,  then 3  is a multiplicative 
inverse of 7, since: 
7 3 ≡ 1  (mod  5) 
· 
(All  numbers  congruent  to  3  modulo  5  are  also  multiplicative  inverses  of  7;  for 
example, 7 8 ≡ 1  (mod  5) as well.) The only exception is that numbers congruent 
· 
to 0 modulo 5 (that is, the multiples of 5) do not have inverses, much as 0 does not 
have an inverse over the real numbers. Let’s prove this. 

Lemma  14.6.1.  If  p  is  prime  and  k  is  not  a  multiple  of  p,  then  k  has  a  multiplicative 
inverse. 

Proof.  Since  p  is  prime,  it  has  only  two  divisors:  1  and  p.  And  since  k  is  not  a 
multiple of p, we must have gcd(p, k) = 1.  Therefore, there is a linear combination 
of p and k equal to 1: 

sp + tk = 1 

294 

CHAPTER 14.  NUMBER THEORY 

Rearranging terms gives: 

sp = 1 − tk 
This  implies  that p  |  (1 − tk) by  the deﬁnition of divisibility, and  therefore  tk  ≡  1 
(mod  p) by the deﬁnition of congruence. Thus, t is a multiplicative inverse of k .  � 
Multiplicative inverses are the key to decryption in Turing’s code.  Speciﬁcally, 
we  can  recover  the  original message  by multiplying  the  encoded message  by  the 
inverse of the key: 
·
· 
m∗  k−1  = rem(mk , p)  k−1 
≡ (mk)k−1 
(mod  p) 
≡ m  (mod  p). 
This shows that m∗k−1  is congruent to the original message m.  Since m was in 
the range 0, 1, . . . , p − 1, we can recover it exactly by taking a remainder: 
m = rem(m∗k−1 , p) 

(the def. (14.8) of m∗ )
(by Cor. 14.5.2) 

So now we can decrypt! 

14.6.2  Cancellation 
Another sense in which real numbers are nice is that one can cancel multiplicative 
terms.  In other words, if we know that m1k = m2k , then we can cancel the k ’s and 
conclude  that m1  =  m2 ,  provided  k  =�
0.  In  general,  cancellation  is  not  valid  in 
modular arithmetic.  For example, 
2 3 ≡ 4  3  (mod  6),
·
· 
cancelling  the  3’s  leads  to  the  false  conclusion  that  2  ≡  4  (mod  6).  The  fact  that 
multiplicative  terms  can  not  be  cancelled  is  the  most  signiﬁcant  sense  in  which 
congruences differ  from ordinary  equations.  However,  this difference goes  away 
if we’re working modulo a prime; then cancellation is valid. 

Lemma 14.6.2.  Suppose p is a prime and k  is not a multiple of p. Then 
IM P L I E S  a ≡ b  (mod  p). 
ak ≡ bk 
(mod  p) 
� 
Proof.  Multiply both sides of the congruence by k−1 . 
We can use this lemma to get a bit more insight into how Turing’s code works. 
In particular,  the  encryption  operation  in Turing’s  code  permutes  the  set  of  possible 
messages. This is stated more precisely in the following corollary. 

Corollary 14.6.3.  Suppose p is a prime and k  is not a multiple of p. Then the sequence: 
rem(((p − 1)  k) , p)
· 
·
· 
rem((2  k), p), 
rem((1  k), p), 

. . . , 

14.6.  ARITHMETIC WITH A PRIME MODULUS 

295 

is a permutation3  of the sequence: 

(p − 1). 
1,  2, 
. . . , 
Proof.  The sequence of remainders contains p−1 numbers. Since i k is not divisible 
·
by  p  for  i  = 1, . . . p −  1,  all  these  remainders  are  in  the  range  1  to  p −  1  by  the 
deﬁnition  of  remainder.  Furthermore,  the  remainders  are  all  different:  no  two 
numbers  in  the  range  1  to  p − 1  are  congruent modulo  p,  and  by  Lemma  14.6.2, 
i k ≡ j k  (mod  p) if and only if i ≡ j  (mod  p). Thus, the sequence of remainders 
·
· 
must contain all of the numbers from 1 to p − 1 in some order. 
� 

For example, suppose p = 5 and k = 3. Then the sequence: 
��· 
��· 
��· 
��· 
� 
� 
�
� 
�
� 
�
� 
rem((4  3), 5)
rem((3  3), 5), 
rem((2  3), 5), 
rem((1  3), 5), 
=3 
=4 
=2 
=1
is  a  permutation  of  1,  2,  3,  4.  As  long  as  the  Nazis  don’t  know  the  secret  key  k , 
they don’t know how the set of possible messages are permuted by the process of 
encryption and thus can’t read encoded messages. 

14.6.3  Fermat’s Little Theorem 
A  remaining  challenge  in  using  Turing’s  code  is  that  decryption  requires  the  in­
verse of the secret key k .  An effective way to calculate k−1  follows from the proof 
of Lemma 14.6.1, namely 

k−1  = rem(t, p) 
where s, t are coefﬁcients such that sp + tk  = 1.  Notice that t is easy to ﬁnd using 
the Pulverizer. 
An  alternative  approach,  about  equally  efﬁcient  and  probably  more  memo­
rable, is to rely on Fermat’s Little Theorem, which is much easier than his famous 
Last Theorem. 

Theorem 14.6.4 (Fermat’s Little Theorem).  Suppose p is a prime and k is not a multiple 
of p. Then: 
kp−1  ≡ 1  (mod  p) 

3A permutation of a sequence of elements  is a sequence with  the same elements  (including repeats) 
possibly in a different order. More formally, if 

�e ::= e1 , e2 , . . . , en 
is a length n sequence, and π  : {1, . . . , n} → {1, . . . , n} is a bijection, then 

eπ(1) , eπ(2) , . . . , eπ(n) , 

is a permutation of �e. 

296 

CHAPTER 14.  NUMBER THEORY 

Proof.  We reason as follows: 
(p − 1)
(p − 1)! ::= 1  2 
· 
· · · 
rem((p − 1)k , p) 
· · · 
· 
= rem(k , p)  rem(2k , p) 
(p − 1)k 
≡ k  2k 
· 
· · · 
(mod  p) 
≡ (p − 1)!  kp−1 
· 
(mod  p) 

(by Cor 14.6.3)
(by Cor 14.5.2)
(rearranging terms) 

Now (p−1)! is not a multiple of p because the prime factorizations of 1, 2, . . . , (p−
1) contain only primes smaller than p.  So by Lemma 14.6.2, we can cancel (p − 1)! 
� 
from the ﬁrst and last expressions, which proves the claim. 
Here is how we can ﬁnd inverses using Fermat’s Theorem. Suppose p is a prime 
and k  is not a multiple of p. Then, by Fermat’s Theorem, we know that: 
kp−2  k ≡ 1  (mod  p)
· 
Therefore,  kp−2  must be  a multiplicative  inverse of  k .  For  example,  suppose  that 
we  want  the  multiplicative  inverse  of  6  modulo  17.  Then  we  need  to  compute 
rem(615 , 17), which we can do by successive squaring.  All the congruences below 
hold modulo 17. 

62  ≡ 36 ≡ 2 
64  ≡ (62 )2  ≡ 22  ≡ 4 
68  ≡ (64 )2  ≡ 42  ≡ 16 
615  ≡ 68  64  62  6 ≡ 16  4  2  6 ≡ 3
·
·
· 
·
·
· 
Therefore, rem(615 , 17) = 3.  Sure enough, 3 is the multiplicative inverse of 6 mod­
ulo 17, since: 
3 6 ≡ 1  (mod  17) 
· 
In general,  if we were working modulo a prime p, ﬁnding a multiplicative  in­
verse by trying every value between 1 and p − 1 would require about p operations. 
However,  the  approach  above  requires  only  about  log p  operations,  which  is  far 
better when p is large. 

14.6.4  Breaking Turing’s Code —Again 
The Germans didn’t bother to encrypt their weather reports with the highly-secure 
Enigma system.  After all,  so what  if  the Allies  learned  that  there was  rain off  the 
south  coast  of  Iceland?  But,  amazingly,  this  practice  provided  the  British with  a 
critical edge in the Atlantic naval battle during 1941. 
The problem was that some of those weather reports had originally been trans­
mitted using Enigma  from U-boats out  in  the Atlantic.  Thus,  the British obtained 
both unencrypted reports and  the same reports encrypted with Enigma.  By com­
paring  the  two,  the  British were  able  to  determine which  key  the  Germans were 

14.6.  ARITHMETIC WITH A PRIME MODULUS 

297 

using that day and could read all other Enigma-encoded trafﬁc. Today, this would 
be called a known-plaintext attack. 
Let’s see how a known-plaintext attack would work against Turing’s code. Sup­
pose that the Nazis know both m and m∗  where: 
m∗  ≡ mk 

(mod  p) 

Now they can compute: 
·
· 
mp−2  m∗  = mp−2  rem(mk , p) 
≡ mp−2  mk 
· 
(mod  p) 
≡ mp−1  k 
· 
(mod  p)
≡ k 
(mod  p) 

(def. (14.8) of m∗ )
(by Cor 14.5.2)

(Fermat’s Theorem) 

Now the Nazis have the secret key k and can decrypt any message! 
This  is  a  huge  vulnerability,  so  Turing’s  code  has  no  practical  value.  Fortu­
nately, Turing got better at  cryptography after devising  this  code;  his  subsequent 
deciphering of Enigma messages surely saved thousands of lives, if not the whole 
of Britain. 

14.6.5  Turing Postscript 
A few years after the war, Turing’s home was robbed. Detectives soon determined 
that a former homosexual  lover of Turing’s had conspired  in the robbery.  So they 
arrested  him  —that  is,  they  arrested  Alan  Turing  —because  homosexuality  was 
a  British  crime  punishable  by  up  to  two  years  in  prison  at  that  time.  Turing was 
sentenced to a hormonal “treatment” for his homosexuality: he was given estrogen 
injections. He began to develop breasts. 
Three years later, Alan Turing, the founder of computer science, was dead. His 
mother  explained  what  happened  in  a  biography  of  her  own  son.  Despite  her 
repeated  warnings,  Turing  carried  out  chemistry  experiments  in  his  own  home. 
Apparently, her worst fear was realized: by working with potassium cyanide while 
eating an apple, he poisoned himself. 
However,  Turing  remained  a  puzzle  to  the  very  end.  His  mother  was  a  de­
voutly  religious  woman  who  considered  suicide  a  sin.  And,  other  biographers 
have pointed out,  Turing had previously discussed  committing  suicide by  eating 
a  poisoned  apple.  Evidently,  Alan  Turing,  who  founded  computer  science  and 
saved  his  country,  took  his  own  life  in  the  end,  and  in  just  such  a  way  that  his 
mother could believe it was an accident. 
Turing’s  last project before he disappeared  from public view  in 1939  involved 
the  construction  of  an  elaborate mechanical device  to  test  a mathematical  conjec­
ture  called  the  Riemann  Hypothesis.  This  conjecture  ﬁrst  appeared  in  a  sketchy 
paper by Berhard Riemann  in  1859  and  is now one of  the most  famous unsolved 
problem in mathematics. 

298 

CHAPTER 14.  NUMBER THEORY 

The Riemann Hypothesis 

The formula for the sum of an inﬁnite geometric series says: 

1
1 − x 
Substituting  x  =  2
s  ,  x  =  5
s  ,  x  =  3
1 
1 
1 
s  ,  and  so  on  for  each  prime  number  gives  a 
sequence of equations: 

1 + x + x 2  + x 3  +

· · · 

= 

+ 

+ 

· · · 

= 

+

· · · 

= 

1 
23s 
1 
33s 
1 
53s 

1
22s 
1
32s 
1
52s 

1
1 +  + 
2s 
1
1 +  + 
3s 
1
1 +  + 
5s 

1
1 − 1/2s 
1
1 − 1/3s 
1
1 − 1/5s 
etc.

� 
1  � 
� 
� 
Multiplying together all the left sides and all the right sides gives:

∞
1 − 1/ps 
p∈primes 
n=1 

1 
ns

· · · 

= 

+ 

+

+

= 

The sum on the left is obtained by multiplying out all the inﬁnite series and apply­
ing the Fundamental Theorem of Arithmetic.  For example, the term 1/300s  in the 
sum is obtained by multiplying 1/22s  from the ﬁrst equation by 1/3s  in the second 
and 1/52s  in the third.  Riemann noted that every prime appears in the expression 
on  the  right.  So  he  proposed  to  learn  about  the  primes  by  studying  the  equiva­
lent,  but  simpler expression on  the  left.  In particular, he  regarded s as a  complex 
number and  the  left side as a  function,  ζ (s).  Riemann  found  that  the distribution 
of  primes  is  related  to  values  of  s  for  which  ζ (s) = 0,  which  led  to  his  famous 
conjecture: 

The Riemann Hypothesis:  Every nontrivial zero of the zeta function ζ (s) 
lies on the line s = 1/2 + ci in the complex plane. 

Researchers  continue  to work  intensely  to  settle  this  conjecture,  as  they  have  for 
over  a  century.  A  proof would  immediately  imply,  among  other  things,  a  strong 
form  of  the  Prime  Number  Theorem  —and  earn  the  prover  a  $1  million  prize! 
(We’re not sure what the cash would be for a counter-example, but the discoverer 
would be wildly applauded by mathematicians everywhere.) 

14.7.  ARITHMETIC WITH AN ARBITRARY MODULUS 

299 

14.6.6  Problems 
Class Problems 

Problem 14.8. 
Two  nonparallel  lines  in  the  real  plane  intersect  at  a  point.  Algebraically,  this 
means that the equations 

y = m1x + b1 
y = m2x + b2 
have a unique solution (x, y), provided m1  =� m2 .  This statement would be false if 
we restricted x and y to the integers, since the two lines could cross at a noninteger 
point: 

However, an analogous statement holds if we work over the integers modulo a 
prime, p.  Find a solution to the congruences 
y ≡ m1x + b1 
(mod  p) 
y ≡ m2x + b2 
(mod  p) 
�≡  m2  (mod  p).  Express  your  solution  in  the  form  x  ≡?  (mod  p)  and 
when  m1 
y  ≡?  (mod  p) where the ?’s denote expressions  involving m1 , m2 , b1 , and b2 .  You 
may ﬁnd it helpful to solve the original equations over the reals ﬁrst. 

Problem 14.9. 
Let Sk  = 1k + 2k + . . .+ (p− 1)k , where p is an odd prime and k is a positive multiple 
of p − 1. Use Fermat’s theorem to prove that Sk  ≡ −1  (mod  p). 

Homework Problems 

Problem 14.10.  (a)  Use  the  Pulverizer  to  ﬁnd  the  inverse  of  13 modulo  23  in  the 
range {1, . . . , 22}. 
(b)  Use Fermat’s theorem to ﬁnd the inverse of 13 modulo 23 in the range {1, . . . , 22}. 

14.7  Arithmetic with an Arbitrary Modulus 

Turing’s code did not work as he hoped. However, his essential idea— using num­
ber theory as the basis for cryptography— succeeded spectacularly in the decades 
after his death. 

300 

CHAPTER 14.  NUMBER THEORY 

In 1977, Ronald Rivest, Adi Shamir, and Leonard Adleman at MIT proposed a 
highly secure cryptosystem (called RSA) based on number theory. Despite decades 
of  attack,  no  signiﬁcant  weakness  has  been  found.  Moreover,  RSA  has  a  major 
advantage  over  traditional  codes:  the  sender  and  receiver  of  an  encrypted  mes­
sage  need  not meet  beforehand  to  agree  on  a  secret  key.  Rather,  the  receiver  has 
both a  secret key, which she guards closely,  and a public key, which she distributes 
as  widely  as  possible.  The  sender  then  encrypts  his  message  using  her  widely-
distributed public key.  Then she decrypts the received message using her closely-
held private key.  The use of such a public key cryptography system allows you and 
Amazon,  for  example,  to  engage  in  a  secure  transaction without meeting  up  be­
forehand in a dark alley to exchange a key. 
Interestingly,  RSA does not  operate modulo  a prime,  as Turing’s  scheme may 
have, but rather modulo the product of two large primes. Thus, we’ll need to know 
a bit about how arithmetic works modulo a composite number in order to under­
stand  RSA. Arithmetic modulo  an  arbitrary  positive  integer  is  really  only  a  little 
more  painful  than working modulo  a  prime —though  you may  think  this  is  like 
the doctor saying, “This is only going to hurt a little,” before he jams a big needle 
in your arm. 

14.7.1  Relative Primality and Phi 
First, we need a new deﬁnition.  Integers a and b are relatively prime iff gcd(a, b) = 1. 
For example, 8 and 15 are relatively prime, since gcd(8, 15) =  1.  Note that, except 
for multiples of p, every integer is relatively prime to a prime number p. 
We’ll also need a certain function that is deﬁned using relative primality.  Let n 
be a positive integer. Then φ(n) denotes the number of integers in {1, 2, . . . , n − 1}
that are relatively prime to n.  For example, φ(7) = 6, since 1, 2, 3, 4, 5, and 6 are all 
relatively prime  to 7.  Similarly, φ(12)  =  4,  since only 1,  5,  7,  and 11 are  relatively 
prime  to  12.  If  you  know  the  prime  factorization  of  n,  then  computing  φ(n)  is  a 
piece of cake, thanks to the following theorem.  The function φ is known as Euler ’s 
φ function; it’s also called Euler ’s totient function. 
Theorem 14.7.1.  The function φ obeys the following relationships: 
(a)  If a and b are relatively prime, then φ(ab) = φ(a)φ(b). 
(b)  If p is a prime, then φ(pk ) = pk  − pk−1  for k ≥ 1. 
Here’s an example of using Theorem 14.7.1 to compute φ(300): 
·
· 
φ(300) = φ(22  3 52 )
·
· 
= φ(22 )  φ(3)  φ(52 ) 
= (22  − 21 )(31  − 30 )(52  − 51 ) 
= 80. 
The  proof  of  Theorem  14.7.1.(a)  requires  a  few  more  properties  of  modular 
arithmetic worked out  in  the next section  (see Problem 14.15).  We’ll also give an­
other a proof in a few weeks based on rules for counting things. 

(by Theorem 14.7.1.(a))
(by Theorem 14.7.1.(b)) 

14.7.  ARITHMETIC WITH AN ARBITRARY MODULUS 

301 

To prove Theorem 14.7.1.(b), notice that every pth number among the pk  num­
bers  in  the  interval  from  0  to pk  − 1  is divisible by p,  and only  these are divisible 
by p.  So 1/pth of these numbers are divisible by p and the remaining ones are not. 
That is, 
φ(p k ) = p k  − (1/p)p k  = p k  − p k−1 . 

14.7.2  Generalizing to an Arbitrary Modulus 
Let’s  generalize what we  know  about  arithmetic modulo  a  prime.  Now,  instead 
of  working  modulo  a  prime  p,  we’ll  work  modulo  an  arbitrary  positive  integer 
n.  The  basic  theme  is  that  arithmetic modulo  n may  be  complicated,  but  the  in­
tegers  relatively  prime  to  n  remain  fairly well-behaved.  For  example,  the  proof  of 
Lemma  14.6.1  of  an  inverse  for  k  modulo  p  extends  to  an  inverse  for  k  relatively 
prime to n: 

Lemma 14.7.2.  Let n be a positive integer.  If k is relatively prime to n, then there exists 
an integer k−1  such that: 
k k−1  ≡ 1  (mod  n)
· 
As a consequence of this lemma, we can cancel a multiplicative term from both 
sides of a congruence if that term is relatively prime to the modulus: 

Corollary 14.7.3.  Suppose n is a positive integer and k  is relatively prime to n.  If 
ak ≡ bk 

(mod  n) 

then 

a ≡ b  (mod  n) 
This  holds  because we  can multiply  both  sides  of  the ﬁrst  congruence  by  k−1 
and simplify to obtain the second. 

14.7.3  Euler ’s Theorem 
RSA  essentially  relies  on  Euler ’s  Theorem,  a  generalization  of  Fermat’s  Theorem 
to  an  arbitrary modulus.  The  proof  is much  like  the  proof  of  Fermat’s  Theorem, 
except  that we  focus on  integers relatively prime  to  the modulus.  Let’s start with 
a lemma. 

Lemma 14.7.4.  Suppose n is a positive integer and k is relatively prime to n. Let k1 , . . . , kr 
denote all the integers relatively prime to n in the range 1 to n − 1. Then the sequence: 
, rem(kr  · k , n) 
rem(k3  · k , n), 
rem(k2  · k , n), 
rem(k1  · k , n), 

. . . 

is a permutation of the sequence: 

k1 ,

k2 , 

. . . 

, kr . 

302 

CHAPTER 14.  NUMBER THEORY 

Proof.  We will  show  that  the  remainders  in  the  ﬁrst  sequence  are  all  distinct  and 
are  equal  to  some member of  the  sequence of kj ’s.  Since  the  two  sequences have 
the same length, the ﬁrst must be a permutation of the second. 
First, we show that the remainders in the ﬁrst sequence are all distinct. Suppose 
that  rem(kik , n)  =  rem(kj k , n).  This  is  equivalent  to  kik  ≡  kj k  (mod  n),  which 
implies  ki  ≡  kj  (mod  n)  by  Corollary  14.7.3.  This,  in  turn,  means  that  ki  =  kj 
since both are between 1 and n − 1.  Thus, none of the remainder terms in the ﬁrst 
sequence is equal to any other remainder term. 
Next, we  show  that  each  remainder  in  the ﬁrst  sequence  equals  one  of  the  ki . 
By assumption, gcd(ki , n) = 1 and gcd(k , n) = 1, which means that 

gcd(n, rem(kik , n)) = gcd(kik , n) 
(by Lemma 14.2.4.5) 
= 1 
(by Lemma 14.2.4.3). 
Now rem(kik , n) is in the range from 0 to n − 1 by the deﬁnition of remainder, but 
since  it  is  relatively prime  to n,  it  is  actually  in  the  range  0  to n − 1.  The  kj ’s  are 
� 
deﬁned to be the set of all such integers, so rem(kik , n) must equal some kj . 

We can now prove Euler ’s Theorem: 

Theorem 14.7.5  (Euler ’s Theorem).  Suppose n  is a positive  integer and k  is  relatively 
prime to n. Then 

kφ(n)  ≡ 1  (mod  n) 
Proof.  Let k1 , . . . , kr  denote all integers relatively prime to n such that 0 ≤  ki  < n. 
Then r = φ(n), by the deﬁnition of the function φ. Now we can reason as follows: 
k1  · k2  · · · kr 
= rem(k1  · k , n) · rem(k2  · k , n) · · · rem(kr  · k , n) 
≡ (k1  · k) · (k2  · k) · · · · (kr  · k)  (mod  n) 
≡ (k1  · k2  · · · kr ) · kr 
(mod  n) 
· k2  · · · 
kr  is  prime  relative  to  n.  So  by  Corol­
Lemma  14.2.4.3.  implies  that  k1 
lary  14.7.3,  we  can  cancel  this  product  from  the  ﬁrst  and  last  expressions.  This 
� 
proves the claim. 

(by Lemma 14.7.4) 
(by Cor 14.5.2) 
(rearranging terms) 

We can ﬁnd multiplicative inverses using Euler ’s theorem as we did with Fer-
mat’s theorem:  if k  is relatively prime to n, then kφ(n)−1  is a multiplicative inverse 
of k modulo n.  However,  this approach  requires computing φ(n).  Unfortunately, 
ﬁnding φ(n) is about as hard as factoring n, and factoring is hard in general. How­
ever, when we know how to factor n, we can use Theorem 14.7.1 to compute φ(n) 
efﬁciently.  Then computing kφ(n)−1  to ﬁnd inverses is a competitive alternative to 
the Pulverizer. 

14.7.  ARITHMETIC WITH AN ARBITRARY MODULUS 

303 

14.7.4  RSA 
Finally, we are ready to see how the RSA public key encryption scheme works: 

RSA Public Key Encryption 

Beforehand  The receiver creates a public key and a secret key as follows. 

1.  Generate two distinct primes, p and q . 
2.  Let n = pq . 
3.  Select an integer e such that gcd(e, (p − 1)(q − 1)) = 1. 
The public key is the pair (e, n). This should be distributed widely. 
4.  Compute d such that de ≡ 1  (mod  (p − 1)(q − 1)). 
The secret key is the pair (d, n). This should be kept hidden! 
Encoding  The sender encrypts message m to produce m�  using the public key: 

m�  = rem(m e , n). 
Decoding  The  receiver decrypts message m�  back  to message m using  the  secret 
key: 
m = rem((m� )d , n). 

We’ll explain why this way of Decoding works in Problem 14.14. 

14.7.5  Problems 
Practice Problems 

Problem 14.11.  (a)  Prove that 2212001  has a multiplicative inverse modulo 175. 

(b)  What is the value of φ(175), where φ is Euler ’s function? 

(c)  What is the remainder of 2212001  divided by 175? 

Problem 14.12.  (a)  Use the Pulverizer to ﬁnd integers s, t such that 

40s + 7t = gcd(40, 7). 

Show your work. 

(b)  Adjust your answer to part (a) to ﬁnd an inverse modulo 40 of 7 in the range 
{1, . . . , 39}. 

304 

Class Problems 

CHAPTER 14.  NUMBER THEORY 

Problem 14.13. 
Let’s  try out RSA! There  is  a  complete description of  the  algorithm  at  the bottom 
of the page. You’ll probably need extra paper. Check your work carefully! 
(a)  As a team, go through the beforehand steps. 

•	 Choose primes p and q  to be relatively small, say in the range 10-40.  In prac­
tice,  p  and  q  might  contain  several  hundred  digits,  but  small  numbers  are 
easier to handle with pencil and paper. 

•	 Try e = 3, 5, 7, . . . until you ﬁnd something that works. Use Euclid’s algorithm 
to compute the gcd. 

•	 Find d  (using  the Pulverizer —see appendix  for a  reminder on how  the Pul­
verizer works —or Euler ’s Theorem). 

When you’re done, put your public key on the board.  This lets another team send 
you a message. 

(b)  Now send an encrypted message to another team using their public key. Select 
your message m from the codebook below: 

•	 2 = Greetings and salutations! 

•	 3 = Yo, wassup? 

•	 4 = You guys are slow! 

•	 5 = All your base are belong to us. 

•	 6 = Someone on our team thinks someone on your team is kinda cute. 

•	 7 = You are the weakest link. Goodbye. 

(c)  Decrypt the message sent to you and verify that you received what the other 
team sent! 

RSA Public Key Encryption 

14.7.  ARITHMETIC WITH AN ARBITRARY MODULUS 

305 

Beforehand  The receiver creates a public key and a secret key as follows. 

1.  Generate two distinct primes, p and q . 
2.  Let n = pq . 
3.  Select an integer e such that gcd(e, (p − 1)(q − 1)) = 1. 
The public key is the pair (e, n). This should be distributed widely. 
4.  Compute d such that de ≡ 1  (mod  (p − 1)(q − 1)). 
The secret key is the pair (d, n). This should be kept hidden! 
Encoding  The sender encrypts message m, where 0 ≤ m < n, to produce m�  using 
the public key: 
m�  = rem(m e , n). 
Decoding  The  receiver decrypts message m�  back  to message m using  the  secret 
key: 
m = rem((m� )d , n). 

Problem 14.14. 
A  critical  fact  about  RSA  is,  of  course,  that  decrypting  an  encrypted message  al­
ways gives back the original message!  That is, that rem((md )e , pq) = m.  This will 
follow from something slightly more general: 
Lemma  14.7.6.  Let  n  be  a  product  of  distinct  primes  and  a  ≡  1  (mod  φ(n))  for  some 
nonnegative integer, a. Then 
m a  ≡ m  (mod  n). 
(a)  Explain why Lemma 14.7.6 implies that k and k5  have the same last digit.  For 
example: 

(14.11) 

25  = 32 
Hint: What is φ(10)? 

795  = 3077056399 

(b)  Explain why Lemma 14.7.6 implies that the original message, m, equals rem((me )d , pq). 
(c)  Prove that if p is prime, then 
m a  ≡ m  (mod  p) 
for all nonnegative integers a ≡ 1  (mod  p − 1). 
(d)  Prove that if n is a product of distinct primes, and a ≡ b  (mod  p) for all prime 
factors, p, of n, then a ≡ b  (mod  n). 
(e)  Combine the previous parts to complete the proof of Lemma 14.7.6. 

(14.12) 

306 

CHAPTER 14.  NUMBER THEORY 

Homework Problems 

Problem 14.15. 
Suppose m, n are relatively prime.  In the problem you will prove the key property 
of Euler ’s function that φ(mn) = φ(m)φ(n). 
(a)  Prove that for any a, b, there is an x such that 
x ≡ a  (mod m), 
x ≡ b  (mod  n). 

(14.13) 
(14.14) 

Hint: Congruence (14.13) holds iff 

x = jm + a. 

for some j .  So there is such an x only if 
jm + a ≡ b  (mod  n). 

Solve (14.16) for j . 

(14.15) 

(14.16) 

(b)  Prove that there is an x satisfying the congruences (14.13) and (14.14) such that 
0 ≤ x < mn. 
(c)  Prove that the x satisfying part (b) is unique. 
(d)  For an integer k , let k∗  be the integers between 1 and k − 1 that are relatively 
prime to k . Conclude from part (c) that the function 
f  : (mn)∗  → m∗  × n∗ 

deﬁned by 

is a bijection. 

f (x) ::= (rem(x, m), rem(x, n)) 

(e)  Conclude from the preceding parts of this problem that 

φ(mn) = φ(m)φ(n). 

Exam Problems 

Problem 14.16. 
· 
Find the remainder of 261818181  divided by 297.  Hint:  1818181 =  (180  10101) + 1;
Euler ’s theorem 

Problem 14.17. 
Find an  integer k >  1 such that n and nk  agree  in their  last three digits whenever 
n is divisible by neither 2 nor 5. Hint: Euler ’s theorem. 

Chapter 15 

Sums & Asymptotics 

15.1  The Value of an Annuity 

Would you prefer a million dollars today or $50,000 a year for the rest of your life? 
On the one hand,  instant gratiﬁcation is nice.  On the other hand,  the total dollars 
received at $50K per year is much larger if you live long enough. 
Formally, this is a question about the value of an annuity. An annuity is a ﬁnan­
cial  instrument  that pays  out  a ﬁxed  amount  of money  at  the  beginning  of  every 
year  for some speciﬁed number of years.  In particular, an n-year, m-payment an­
nuity pays m dollars at the start of each year for n years.  In some cases, n is ﬁnite, 
but not always.  Examples include lottery payouts, student loans, and home mort­
gages. There are even Wall Street people who specialize in trading annuities. 
A  key  question  is what  an  annuity  is worth.  For  example,  lotteries  often  pay 
out  jackpots over many years.  Intuitively, $50, 000 a year  for 20 years ought  to be 
worth less than a million dollars right now.  If you had all the cash right away, you 
could  invest  it and begin collecting  interest.  But what  if  the choice were between 
$50, 000  a  year  for  20  years  and  a  half  million  dollars  today?  Now  it  is  not  clear 
which option is better. 
In  order  to  answer  such  questions,  we  need  to  know  what  a  dollar  paid  out 
in  the  future  is  worth  today.  To  model  this,  let’s  assume  that  money  can  be  in­
vested at a ﬁxed annual interest rate p. We’ll assume an 8% rate1  for the rest of the 
discussion. 
Here  is why  the  interest  rate  p matters.  Ten  dollars  invested  today  at  interest 
rate p will become (1 + p)  10 = 10.80 dollars in a year, (1 + p)2  10 ≈ 11.66 dollars
·
· 
in two years, and so forth. Looked at another way, ten dollars paid out a year from 
now are only really worth 1/(1+ p) 10 ≈ 9.26 dollars today. The reason is that if we 
·

1U.S.  interest  rates  have dropped  steadily  for  several  years,  and  ordinary  bank deposits  now  earn 
around  1.5%.  But  just  a  few  years  ago  the  rate was  8%;  this  rate makes  some  of  our  examples  a  little 
more dramatic. The rate has been as high as 17% in the past thirty years. 
In  Japan,  the  standard  interest  rate  is near zero%,  and on a  few occasions  in  the past  few years has 
even been slightly negative.  It’s a mystery why the Japanese populace keeps any money in their banks. 

307 

308 

CHAPTER 15.  SUMS & ASYMPTOTICS 

had  the  $9.26  today, we  could  invest  it  and would have  $10.00  in  a year  anyway. 
Therefore, p determines the value of money paid out in the future. 

15.1.1  The Future Value of Money 
So for an n-year, m-payment annuity, the ﬁrst payment of m dollars is truly worth 
m  dollars.  But  the  second  payment  a  year  later  is worth  only m/(1 + p)  dollars. 
Similarly,  the  third payment  is worth m/(1 + p)2 ,  and  the n-th payment  is worth 
only m/(1 + p)n−1 .  The  total  value,  V ,  of  the  annuity  is  equal  to  the  sum  of  the 
n� 
payment values. This gives: 
m 
n−1 � 
1  �j 
(1 + p)i−1 
� 
i=1 
= m · 
� 
1 + p 
j=0 
n−1
· 
xj 
j=0 

(substitute j  ::= i − 1) 

(substitute x =

1 
). 
1 + p 

(15.1)

V  = 

= m

(15.2)

1 − xn 
. 
1 − x 

The  summation  in  (15.1)  is  a  geometric  sum  that  has  a  closed  form,  making  the 
� 
evaluation a lot easier, namely2 , 
n−1
i 
x  = 
i=0 
(The phrase “closed  form”  refers  to a mathematical expression without any  sum­
mation or product notation.) 
Equation  (15.2)  was  proved  by  induction  in  problem  6.2,  but,  as  is  often  the 
case, the proof by induction gave no hint about how the formula was found in the 
ﬁrst place.  So we’ll take this opportunity to explain where it comes from. The trick 
is to let S  be the value of the sum and then observe what −xS  is: 
· · · 
+xn−1 
S  = 1 +x  +x2  +x3  +
−x  −x2  −x3  − 
· · ·  −xn−1  − xn . 
−xS  = 
Adding these two equations gives: 
S − xS  = 1 − x n , 

so 

1 − x
n
1 − x 
We’ll  look  further  into  this  method  of  proof  in  a  few  weeks  when  we  introduce 
generating functions in Chapter 16. 
2 To make this equality hold for x = 0, we adopt the convention that 00  ::= 1. 

S  = 

.

15.1.  THE VALUE OF AN ANNUITY 

309 

15.1.2  Closed Form for the Annuity Value 

So now we have a simple formula for V , the value of an annuity that pays m dollars 
at the start of each year for n years. 
1 − x
n 
V  = m 
1 − x 
1 + p − (1/(1 + p))n−1 
= m 
p 

(by (15.1) and (15.2)) 

(x = 1/(1 + p)). 

(15.4) 

(15.3)

The  formula  (15.4)  is much easier  to use  than a summation with dozens of  terms. 
For  example,  what  is  the  real  value  of  a winning  lottery  ticket  that  pays  $50, 000 
per  year  for  20  years?  Plugging  in  m  =  $50, 000,  n  =  20,  and  p  = 0.08  gives 
V  ≈  $530, 180.  So  because  payments  are  deferred,  the  million  dollar  lottery  is 
really  only worth  about  a half million dollars!  This  is  a  good  trick  for  the  lottery 
advertisers! 

15.1.3  Inﬁnite Geometric Series 

The question we began with was whether you would prefer a million dollars today 
or $50, 000 a year for the rest of your life. Of course, this depends on how long you 
live,  so  optimistically  assume  that  the  second  option  is  to  receive  $50, 000  a  year 
forever.  This  sounds  like  inﬁnite  money!  But  we  can  compute  the  value  of  an 
annuity with an inﬁnite number of payments by taking the limit of our geometric 
sum in (15.2) as n tends to inﬁnity. 
Theorem 15.1.1.  If |x| < 1, then 
� 
∞
i x  = 
i=0 

1
1 − x 
.

Proof. 

� 
�
∞
n−1

x i  ::=  lim 
x i

n→∞ 
i=0

i=0 
1 − x
n

=  lim 
n→∞  1 − x 
1 
.

1 − x

The ﬁnal line follows from that fact that limn→∞ xn  = 0 when |x| < 1. 

(by (15.2)) 

= 

� 

310 

CHAPTER 15.  SUMS & ASYMPTOTICS 

In our annuity problem, x = 1/(1 + p) <  1, so Theorem 15.1.1 applies, and we 
� 
get 
∞
· 
xj 
j=0 
1 
1 − x 
1 + p
p 

· 
= m 
· 
= m 

(by (15.1))

V  = m

(by Theorem 15.1.1)

(x = 1/(1 + p)).

Plugging in m = $50, 000 and p = 0.08, the value, V , is only $675, 000. Amazingly, 
a million dollars today is worth much more than $50, 000 paid every year forever! 
Then again,  if we had a million dollars  today  in  the bank earning 8%  interest, we 
could take out and spend $80, 000 a year forever. So on second thought, this answer 
really isn’t so amazing. 

15.1.4  Problems 
Class Problems 

Problem 15.1. 
You’ve seen this neat trick for evaluating a geometric sum: 

S  = 1 + z + z 2  + . . . + z 
n
zS  = z + z 2  + . . . + z n  + z n+1 
S − zS  = 1 − z n+1 
1 − zn+1 
1 − z 
Use the same approach to ﬁnd a closed-form expression for this sum: 

S  = 

T  = 1z + 2z 2  + 3z 3  + . . . + nz 
n

Homework Problems 

Problem 15.2. 
Is  a  Harvard  degree  really  worth  more  than  an  MIT  degree?!  Let  us  say  that  a 
person  with  a  Harvard  degree  starts  with  $40,000  and  gets  a  $20,000  raise  every 
year  after  graduation,  whereas  a  person with  an MIT  degree  starts with  $30,000, 
but gets a 20% raise every year. Assume inﬂation is a ﬁxed 8% every year.  That is, 
$1.08 a year from now is worth $1.00 today. 
(a)  How much is a Harvard degree worth today if the holder will work for n years 
following graduation? 

(b)  How much is an MIT degree worth in this case? 

15.2.  BOOK STACKING 

311 

(c)  If you plan to retire after twenty years, which degree would be worth more? 

Problem 15.3. 
Suppose you deposit  $100  into your MIT Credit Union  account  today,  $99  in one 
month from now, $98 in two months from now, and so on.  Given that the interest 
rate is constantly 0.3% per month, how long will it take to save $5,000? 

15.2  Book Stacking 

Suppose you have a pile of books and you want  to stack  them on a  table  in some 
off-center  way  so  the  top  book  sticks  out  past  books  below  it.  How  far  past  the 
edge of the table do you think you could get the top book to go without having the 
stack fall over? Could the top book stick out completely beyond the edge of table? 
Most people’s ﬁrst response to this question—sometimes also their second and 
third  responses—is  “No,  the  top  book will never  get  completely past  the  edge  of 
the table.” But in fact, you can get the top book to stick out as far as you want: one 
booklength, two booklengths, any number of booklengths! 

15.2.1  Formalizing the Problem 
We’ll approach this problem recursively.  How far past the end of the table can we 
get one book to stick out?  It won’t tip as long as its center of mass is over the table, 
so we can get it to stick out half its length, as shown in Figure 15.1. 

Figure 15.1: One book can overhang half a book length. 

Now  suppose we have  a  stack  of books  that will  stick  out past  the  table  edge 
without  tipping over—call  that a  stable stack.  Let’s deﬁne  the overhang of a stable 
stack  to  be  the  largest  horizontal  distance  from  the  center  of mass  of  the  stack  to 
the furthest edge of a book.  If we place the center of mass of the stable stack at the 
edge of the table as in Figure 15.2, that’s how far we can get a book in the stack to 
stick out past the edge. 

table12center of massof book312 

CHAPTER 15.  SUMS & ASYMPTOTICS 

Figure 15.2: Overhanging the edge of the table. 

So we want a formula for the maximum possible overhang, Bn , achievable with 
a stack of n books. 
We’ve  already  observed  that  the  overhang  of  one  book  is  1/2  a  book  length. 
That is, 

B1  = 

1 
.2 
Now suppose we have a stable stack of n + 1 books with maximum overhang. 
If  the overhang of  the n books on  top of  the bottom book was not maximum, we 
could  get  a  book  to  stick  out  further  by  replacing  the  top  stack with  a  stack  of  n 
books with larger overhang.  So the maximum overhang, Bn+1 , of a stack of n + 1 
books is obtained by placing a maximum overhang stable stack of n books on top 
of the bottom book.  And we get the biggest overhang for the stack of n + 1 books 
by placing the center of mass of the n books right over the edge of the bottom book 
as in Figure 15.3. 
So we  know where  to  place  the  n + 1st  book  to  get maximum  overhang,  and 
all we  have  to do  is  calculate what  it  is.  The  simplest way  to do  that  is  to  let  the 
center of mass of the top n books be the origin. That way the horizontal coordinate 
of  the  center  of  mass  of  the  whole  stack  of  n + 1  books  will  equal  the  increase 
in  the  overhang.  But  now  the  center  of  mass  of  the  bottom  book  has  horizontal 
coordinate 1/2, so the horizontal coordinate of center of mass of the whole stack of 
n + 1 books is 
·
·  = 
0  n + (1/2) 1 
n + 1 

1
. 
2(n + 1) 

In other words, 

as shown in Figure 15.3. 

Bn+1  = Bn  + 

1 
, 
2(n + 1) 

(15.5)

tablecenter of massof the whole stackoverhang15.2.  BOOK STACKING 

313 

Figure 15.3: Additional overhang with n + 1 books. 

Expanding equation (15.5), we have 

+ 

1 
2(n + 1) 
1
· · · 
+
2n 

+

1
Bn+1  = Bn−1  +
2n 
1 
= B1  + 
� 
· 
2 2 
1 n+1 1 
. 
2 
i 
i=1 

= 

+

1 
2(n + 1) 

(15.6)

Deﬁnition 15.2.1. 

The nth Harmonic number, Hn , is deﬁned to be 
n� 1 
Hn  ::= 
. 
i 
i=1 

So (15.6) means that 

Bn  = 

Hn
.2 
The  ﬁrst  few  Harmonic  numbers  are  easy  to  compute.  For  example,  H4  = 
1 +  1  +  1  +  1  =  25 .  The  fact  that H4  is greater  than  2 has  special  signiﬁcance;  it 
4 
12 
2
3
implies that the total extension of a 4-book stack is greater than one full book! This 
is the situation shown in Figure 15.4. 

15.2.2  Evaluating the Sum—The Integral Method 
It would be nice to answer questions like, “How many books are needed to build a 
stack extending 100 book lengths beyond the table?” One approach to this question 

table}2(n+1)1ntopbooks}center of massof topbooksncenter of massof all+1 booksn314 

CHAPTER 15.  SUMS & ASYMPTOTICS 

Figure 15.4:  Stack of four books with maximum overhang. 

would  be  to  keep  computing  Harmonic  numbers  until  we  found  one  exceeding 
200. However, as we will see, this is not such a keen idea. 
Such questions would be settled if we could express Hn  in a closed form.  Un­
fortunately, no closed form is known, and probably none exists.  As a second best, 
however, we can ﬁnd closed forms for very good approximations to Hn  using the 
Integral Method.  The  idea  of  the  Integral Method  is  to  bound  terms  of  the  sum 
above and below by simple functions as suggested in Figure 15.5.  The integrals of 
these functions then bound the value of the sum above and below. 

�
Figure  15.5:  This  ﬁgure  illustrates  the  Integral  Method  for  bounding  a  sum.  The  area 
n 
under  the  “stairstep”  curve  over  the  interval  [0, n]  is  equal  to  Hn  = 
=1 1/i.  The 
i
function 1/x is everywhere greater than or equal to the stairstep and so the integral of 1/x 
over  this  interval  is an upper bound on  the  sum.  Similarly,  1/(x + 1)  is  everywhere  less 
than or equal to the stairstep and so the integral of 1/(x + 1) is a lower bound on the sum. 

The  Integral Method gives  the  following upper and  lower bounds on  the har­

Table1/21/41/61/810123456781 / x1 / (x + 1)15.2.  BOOK STACKING 

monic number Hn : 

� 
n  1 
�  n 
Hn  ≤  1 + 
1  x 
1
0  x + 1 

Hn  ≥ 

�  n+1
dx = 1 + ln n 
1 

dx = 

1 
x 

315 

(15.7) 

(15.8) 

dx =  ln(n + 1). 

These bounds imply that the harmonic number Hn  is around ln n. 
But ln n grows —slowly —but without bound. That means we can get books to 
overhang any distance past  the edge of  the  table by piling  them high enough!  For 
example, to build a stack extending three book lengths beyond the table, we need 
a number of books n so that Hn  ≥ 6. By inequality (15.8), this means we want 
Hn  ≥  ln(n + 1) ≥ 6, 
so n ≥ e6 − 1 books will work, that is, 403 books will be enough to get a three book 
overhang.  Actual  calculation  of H6  shows  that  227  books  is  the  smallest  number 
that will work. 

15.2.3  More about Harmonic Numbers 
In the preceding section, we showed that Hn  is about ln n. An even better approx­
imation is known: 

Hn  =  ln n + γ +

1
2n 

+ 

1 
12n2 

+

�(n)
120n4 

Here γ  is a value 0.577215664 . . .  called Euler ’s constant, and �(n) is between 0 and 
1 for all n. We will not prove this formula. 

Asymptotic Equality 
The  shorthand  Hn  ∼  ln n  is  used  to  indicate  that  the  leading  term  of  Hn  is  ln n. 
More precisely: 
→ 
Deﬁnition 15.2.2.  For functions f , g  : R
R, we say f  is asymptotically equal to g , 
in symbols, 
f (x) ∼ g(x) 

iff 

lim  f (x)/g(x) = 1. 
x→∞ 
It’s  tempting  to might write Hn  ∼  ln n + γ  to  indicate  the  two  leading  terms, 
but  it  is  not  really  right.  According  to  Deﬁnition  15.2.2,  Hn  ∼  ln n +  c  where  c 
is  any  constant.  The  correct  way  to  indicate  that  γ  is  the  second-largest  term  is 
Hn  − ln n ∼ γ . 

316 

CHAPTER 15.  SUMS & ASYMPTOTICS 

The reason that the ∼ notation is useful is that often we do not care about lower 
order terms. For example, if n = 100, then we can compute H (n) to great precision 
���� 
����
using only the two leading terms: 
1 
1
120  1004  < 
· 
200 

|Hn  − ln n − γ | ≤ 

1 
. 
200 

− 

1 
120000 

+ 

15.2.4  Problems 
Class Problems 

Problem 15.4. 
An  explorer  is  trying  to  reach  the  Holy  Grail,  which  she  believes  is  located  in  a 
desert  shrine  d days walk  from  the  nearest  oasis.  In  the desert  heat,  the  explorer 
must drink continuously.  She can carry at most 1 gallon of water, which is enough 
for 1 day.  However, she is free to make multiple trips carrying up to a gallon each 
time to create water caches out in the desert. 
For  example,  if  the  shrine  were  2/3  of  a  day’s  walk  into  the  desert,  then  she 
could  recover  the  Holy  Grail  after  two  days  using  the  following  strategy.  She 
leaves  the oasis with 1 gallon of water,  travels 1/3 day  into  the desert,  caches 1/3 
gallon,  and  then walks back  to  the oasis— arriving  just as her water  supply  runs 
out. Then she picks up another gallon of water at the oasis, walks 1/3 day into the 
desert,  tops off her water  supply by  taking  the 1/3 gallon  in her cache, walks  the 
remaining 1/3 day to the shrine, grabs the Holy Grail, and then walks for 2/3 of a 
day back to the oasis— again arriving with no water to spare. 
But what if the shrine were located farther away? 
(a)  What  is  the most distant point  that  the explorer can reach and  then return  to 
the oasis if she takes a total of only 1 gallon from the oasis? 

(b)  What  is  the most  distant  point  the  explorer  can  reach  and  still  return  to  the 
oasis if she takes a total of only 2 gallons from the oasis? No proof is required; just 
do the best you can. 

(c)  The explorer will travel using a recursive strategy to go far into the desert and 
back drawing a total of n gallons of water from the oasis.  Her strategy is to build 
up a cache of n − 1 gallons, plus enough to get home, a certain fraction of a day’s 
distance  into  the  desert.  On  the  last  delivery  to  the  cache,  instead  of  returning 
home, she proceeds recursively with her n − 1 gallon strategy to go farther into the 
desert and return  to  the cache.  At  this point,  the cache has  just enough water  left 
to get her home. 
Prove  that  with  n  gallons  of  water,  this  strategy  will  get  her  Hn/2  days  into  the 
desert and back, where Hn  is the nth Harmonic number: 
1 
1 
1
1
· · · 
Hn  ::= + + +  + 
.
1
2
3 
n 
Conclude that she can reach the shrine, however far it is from the oasis. 

15.3.  FINDING SUMMATION FORMULAS 

317 

(d)  Suppose  that  the  shrine  is d  =  10 days walk  into  the desert.  Use  the asymp­
totic approximation Hn  ∼  ln n  to show  that  it will  take more  than a million years 
for the explorer to recover the Holy Grail. 
�
∞
i=1 

ip  converges iff p < a.  What is the value of a?

Problem 15.5. 
There is a number a such that 
Prove it. 

Homework Problems 

Problem 15.6. 
There  is  a  bug  on  the  edge  of  a  1-meter  rug.  The  bug wants  to  cross  to  the  other 
side of the rug.  It crawls at 1 cm per second.  However, at the end of each second, 
a malicious ﬁrst-grader named Mildred Anderson stretches the rug by 1 meter. As­
sume that her action is instantaneous and the rug stretches uniformly. Thus, here’s 
what happens in the ﬁrst few seconds: 

•	 The bug walks 1 cm in the ﬁrst second, so 99 cm remain ahead. 

•	 Mildred stretches the rug by 1 meter, which doubles its length.  So now there 
are 2 cm behind the bug and 198 cm ahead. 

•	 The bug walks another 1 cm in the next second, leaving 3 cm behind and 197 
cm ahead. 

•	 Then Mildred strikes, stretching the rug from 2 meters to 3 meters.  So there 
·	
· 
are now 3  (3/2) = 4.5 cm behind the bug and 197  (3/2) = 295.5 cm ahead. 
•	 The bug walks another 1 cm in the third second, and so on. 

Your job is to determine this poor bug’s fate. 
(a)  During second i, what fraction of the rug does the bug cross? 

(b)  Over  the  ﬁrst  n  seconds,  what  fraction  of  the  rug  does  the  bug  cross  alto­
gether? Express your answer in terms of the Harmonic number Hn . 
· 
(c)  The  known  universe  is  thought  to  be  about  3  1010  light  years  in  diameter. 
How many universe diameters must the bug travel to get to the end of the rug? 

15.3  Finding Summation Formulas 
The  Integral  Method  offers  a  way  to  derive  formulas  like  those  for  the  sum  of 
� 
consecutive integers, 
n
i = n(n + 1)/2, 
i=1 

318 

CHAPTER 15.  SUMS & ASYMPTOTICS 

or for the sum of squares, 

n� 
i2 
i=1 

= 

(2n + 1)(n + 1)n 
6 

=

3
n
3 

+

2
n
2

+ 

n 
. 
6 

(15.9)

These equations appeared in Chapter 2 as equations (2.2) and (2.3) where they 
were  proved  using  the Well-ordering  Principle.  But  those  proofs  did  not  explain 
how someone ﬁgured out in the ﬁrst place that these were the formulas to prove. 
Here’s  how  the  Integral Method  leads  to  the  sum-of-squares  formula,  for  ex­
�  n
�  n 
� 
ample.  First, get a quick estimate of the sum: 
n
i2  ≤ 
x 2  dx ≤ 
(x + 1)2  dx, 
0
0
i=1 
� 
n
i2  ≤ (n + 1)3/3 − 1/3. 
i=1 
� 
and the upper and lower bounds (15.10) imply that 
n
i2  ∼ n 3 /3. 
i=1 

n 3/3 ≤ 

so 

(15.10) 

To get an exact formula, we then guess the general form of the solution. Where we 
are uncertain, we can add parameters a, b, c, . . . .  For example, we might make the 
� 
guess: 
n
i2  = an 3  + bn2  + cn + d. 
i=1 
If  the  guess  is  correct,  then  we  can  determine  the  parameters  a,  b,  c,  and  d  by 
plugging  in  a  few  values  for  n.  Each  such  value  gives  a  linear  equation  in  a,  b, 
c,  and d.  If we plug  in  enough values, we may get a  linear  system with a unique 
solution. Applying this method to our example gives: 

n = 0 
n = 1 
n = 2 
n = 3 

implies  0 = d 
implies  1 = a + b + c + d 
implies  5 = 8a + 4b + 2c + d 
implies  14 = 27a + 9b + 3c + d. 

Solving this system gives the solution a = 1/3, b = 1/2, c = 1/6, d = 0.  Therefore, 
if  our  initial guess at  the  form of  the  solution was  correct,  then  the  summation  is 
equal to n3 /3 + n2/2 + n/6, which matches equation (15.9). 

15.3.  FINDING SUMMATION FORMULAS 

319 

The point is that if the desired formula turns out to be a polynomial, then once 
you  get  an  estimate  of  the  degree  of  the  polynomial —by  the  Integral Method  or 
any other way —all the coefﬁcients of the polynomial can be found automatically. 
Be  careful!  This method  let’s you discover  formulas,  but  it doesn’t guarantee 
they are right! After obtaining a formula by this method, it’s important to go back 
and  prove  it using  induction or  some other method,  because  if  the  initial guess  at 
the  solution  was  not  of  the  right  form,  then  the  resulting  formula  will  be  com­
pletely wrong! 

= 

= 

= 

= 

(geometric sum formula (15.2))

(inﬁnite geometric sum, Theorem 15.1.1) 

15.3.1  Double Sums 
Sometimes  we  have  to  evaluate  sums  of  sums,  otherwise  known  as  double  sum­
mations.  This  can  be  easy:  evaluate  the  inner  sum,  replace  it with  a  closed  form, 
and  then evaluate  the outer  sum which no  longer has a  summation  inside  it.  For 
� 
� 
∞ �� 
example, 
n
∞ � 
� 
i 
n
x 
y
i=0 � 
n=0 
y n 1 − x
n+1 
�
�
1 − x 
n=0 ∞ 
∞ 
�
n 
nxn+1

n=0 y

− 
n=0 y
1 − x 
1 − x 
∞ 
n=0  (xy)n 
1 
x 
− 
1 − x 
(1 − y)(1 − x) 
1 
x 
− 
(1 − y)(1 − x) 
(1 − xy)(1 − x) 
(1 − xy) − x(1 − y)
(1 − xy)(1 − y)(1 − x) 
1 − x 
(1 − xy)(1 − y)(1 − x)

1

(1 − xy)(1 − y) 
.
When  there’s no  obvious  closed  form  for  the  inner  sum,  a  special  trick  that  is 
often  useful  is  to  try  exchanging  the  order  of  summation.  For  example,  suppose we 
�  � � 
want to compute the sum of the harmonic numbers 
n
n
k
1/j 
Hk  =
k=1 j=1 
k=1 
� 
� 
For intuition about this sum, we can try the integral method: 
n
n 
Hk  ≈ 
ln x dx ≈ n ln n − n. 
1
k=1 

(inﬁnite geometric sum, Theorem 15.1.1) 

= 

= 

= 

320 

CHAPTER 15.  SUMS & ASYMPTOTICS 

Now let’s look for an exact answer.  If we think about the pairs (k , j ) over which 
we are summing, they form a triangle: 

j 
1 
1 
1 
1 
1 
. . . 
1 

k  1 
2 
3 
4 

n 

2 

3 

4 

5 

. . . 

n 

1/2 
1/2 
1/2 

1/2 

1/3 
1/3  1/4 

. . . 

1/n 

The  summation  above  is  summing  each  row  and  then  adding  the  row  sums.  In­
stead,  we  can  sum  the  columns  and  then  add  the  column  sums.  Inspecting  the 
�  � � 
table we see that this double sum can be written as 
n
n
k
Hk  =
1/j 
� � 
k=1 j=1 
k=1 
n
n
1/j 
�  � 
j=1 k=j 
n
n
1/j 
1 
n� 1 
j=1 
k=j 
(n − j + 1) 
n� n − j + 1 
j 
j=1 
� n + 1  � j
j
j=1 
n
n
− 
n� 1  � 
j 
j
j=1 
j=1 
n
− 
1 
= (n + 1) 
j 
j=1 
j=1 
= (n + 1)Hn  − n. 

(15.11) 

= 

= 

=

=

= 

15.4  Stirling’s Approximation 
The familiar factorial notation, n!, is an abbreviation for the product 
� 
n
i. 
i=1 

15.4.  STIRLING’S APPROXIMATION 

321 

This is by far the most common product in discrete mathematics.  In this section we 
describe  a good  closed-form  estimate of n!  called Stirling’s Approximation.  Unfor­
tunately, all we can do is estimate:  there is no closed form for n! —though proving 
so would take us beyond the scope of 6.042. 

15.4.1  Products to Sums 
A  good  way  to  handle  a  product  is  often  to  convert  it  into  a  sum  by  taking  the 
logarithm.  In the case of factorial, this gives 
(n − 1)  n)
·
·
· · · 
· 
ln(n!) = ln(1  2  3 
� 
= ln 1 + ln 2 + ln 3 +  + ln(n − 1) + ln n
· · · 
n
ln i. 
i=1 

= 

We’ve not seen a summation containing a  logarithm before!  Fortunately, one tool 
that we  used  in  evaluating  sums  is  still  applicable:  the  Integral Method.  We  can 
bound the terms of this sum with ln x and ln(x + 1) as shown in Figure 15.6.  This 
� 
� 
gives bounds on ln(n!) as follows: 
�
� 
� 
ln x dx ≤ 
n 
n ) + 1 ≤  �n 
ln(x + 1) dx
i=1

0

1
n + 1  + 1 
ln i  ≤ (n + 1) ln 
�n+1 
�
� �
n ln( 
i=1
e 
e
n + 1 
e ≤ 
nn
n! 
e 
e

ln i  ≤ 

≤ 

e. 

n 

n 

The  second  line  follows  from  the  ﬁrst  by  completing  the  integrations.  The  third 
line is obtained by exponentiating. 
So n! behaves  something  like  the  closed  form  formula  (n/e)n .  A more  careful 
analysis yields an unexpected closed form formula that is asymptotically exact: 
� 
�n √
n 
e 

Lemma (Stirling’s Formula). 

(15.12) 

n! ∼ 

2πn, 

Stirling’s  Formula  describes  how  n!  behaves  in  the  limit,  but  to  use  it  effec­
tively, we need  to know how close  it  is  to  the  limit  for different values of n.  That 
information is given by the bounding formulas: 
� n �n 
� n �n 
Fact (Stirling’s Approximation). 
√
2πn 
2πn 
e 
e

1/(12n+1) 
e 

≤ n! ≤

1/12n

√

. 

e

322 

CHAPTER 15.  SUMS & ASYMPTOTICS 

�
n 
Figure 15.6: This ﬁgure illustrates the Integral Method for bounding the sum 
=1  ln i. 
i

Stirling’s Approximation implies the asymptotic formula (15.12), since e1/(12n+1) 
and e1/12n  both approach 1 as n grows large.  These inequalities can be veriﬁed by 
induction, but the details are nasty. 
The bounds  in Stirling’s  formula are very  tight.  For example,  if n  =  100,  then 
�
�100 
Stirling’s bounds are: 
100 
e �
�100 
200π 
100 
200π 
e 

100! ≥

100! ≤

√

√

e 1/1201 

e 1/1200 

The  only  difference  between  the  upper  bound  and  the  lower  bound  is  in  the 
ﬁnal  term.  In  particular  e1/1201  ≈  1.00083299  and  e1/1200  ≈  1.00083368.  As a 
result,  the upper bound  is no more  than 1 + 10−6  times  the  lower bound.  This  is 
amazingly tight! Remember Stirling’s formula; we will use it often. 

15.5  Asymptotic Notation 

Asymptotic notation  is a shorthand used  to give a quick measure of  the behavior 
of a function f (n) as n grows large. 

15.5.1  Little Oh 
The asymptotic notation, ∼, of Deﬁnition 15.2.2 is a binary relation indicating that 
two functions grow at the same rate.  There is also a binary relation indicating that 
one function grows at a signiﬁcantly slower rate than another. Namely, 
→ 
R,  with  g  nonnegative,  we  say  f  is
Deﬁnition  15.5.1.  For  functions  f , g  :  R

ln(x + 1)ln(x)15.5.  ASYMPTOTIC NOTATION 

323 

asymptotically smaller than g , in symbols, 

iff 

f (x) = o(g(x)), 

lim  f (x)/g(x) = 0. 
x→∞ 

For example, 1000x1.9  = o(x2 ), because 1000x1.9 /x2  = 1000/x0.1  and since x0.1 
goes to inﬁnity with x and 1000 is constant, we have limx→∞ 1000x1.9 /x2  = 0. This 
argument generalizes directly to yield 

Lemma 15.5.2.  x = o(xb ) for all nonnegative constants a < b. 
a

Using the familiar fact that log x < x for all x > 1, we can prove 

Lemma 15.5.3.  log x = o(x� ) for all � > 0 and x > 1. 

Proof.  Choose � > δ > 0 and let x = z δ  in the inequality log x < x. This implies 

log z < z δ /δ = o(z � ) 

by Lemma 15.5.2. 

(15.13) 
� 

Corollary 15.5.4.  xb  = o(ax ) for any a, b ∈ R with a > 1. 

Proof.  From (15.13), 

for all z > 1, δ > 0. Hence 

log z < z δ /δ 

�
�z  /δ 
(e b )log z  < (e b )z δ /δ 
δ
z b  < elog a(b/ log a) 
(b/δ log a)z δ 
= a
< az 

for all z  such that 

(b/δ log a)z δ  < z . 

But  choosing  δ <  1, we know  z δ  =  o(z ),  so  this  last  inequality holds  for  all  large 
� 
enough z . 

Lemma  15.5.3  and  Corollary  15.5.4  can  also  be  proved  easily  in  several  other 
ways, for example, using L’Hopital’s Rule or the McLaurin Series for log x and e . 
x
Proofs can be found in most calculus texts. 

324 

CHAPTER 15.  SUMS & ASYMPTOTICS 

15.5.2  Big Oh 
Big Oh is the most frequently used asymptotic notation.  It is used to give an upper 
bound on the growth of a function, such as the running time of an algorithm. 
→ 
Deﬁnition 15.5.5.  Given nonnegative functions f , g  : R
R, we say that 

iff 

f  = O(g) 

lim sup f (x)/g(x) < ∞. 
x→∞ 

This deﬁnition3  makes it clear that 
Lemma 15.5.6.  If f  = o(g) or f  ∼ g , then f  = O(g). 
Proof.  lim f /g = 0 or lim f /g = 1 implies lim f /g < ∞. 
� 
It  is  easy  to  see  that  the  converse  of  Lemma  15.5.6  is  not  true.  For  example, 
2x = O(x), but 2x  �∼ x and 2x =�
o(x). 
The  usual  formulation  of  Big  Oh  spells  out  the  deﬁnition  of  lim sup  without 
mentioning it. Namely, here is an equivalent deﬁnition: 
→ 
Deﬁnition 15.5.7.  Given functions f , g  : R
R, we say that 

f  = O(g) 
iff there exists a constant c ≥ 0 and an x0  such that for all x ≥ x0 , |f (x)| ≤ cg(x). 
This  deﬁnition  is  rather  complicated,  but  the  idea  is  simple:  f (x) =  O(g(x)) 
means f (x) is less than or equal to g(x), except that we’re willing to ignore a con­
stant factor, namely, c, and to allow exceptions for small x, namely, x < x0 . 
We observe, 

Lemma 15.5.8.  If f  = o(g), then it is not true that g = O(f ). 

Proof. 

so g =� O(f ). 

g(x)
lim 
x→∞  f (x) 

= 

1 
limx→∞ f (x)/g(x)

=

1
0 

= ∞, 

� 
3We  can’t  simply  use  the  limit  as  x  → ∞  in  the  deﬁnition  of  O(),  because  if  f (x)/g(x)  oscil­
lates  between,  say,  3  and  5  as  x  grows,  then  f  =  O(g)  because  f  ≤  5g ,  but  limx→∞  f (x)/g(x) 
does  not  exist.  So  instead  of  limit,  we  use  the  technical  notion  of  lim sup.  In  this  oscillating  case, 
f (x)/g(x) = 5.
x→∞
lim sup
The precise deﬁnition of lim sup is 

lim sup h(x) ::=  lim  luby≥x h(y), 
x→∞ 
x→∞ 
where “lub” abbreviates “least upper bound.” 

15.5.  ASYMPTOTIC NOTATION 

325 

Proposition 15.5.9.  100x2  = O(x2 ). 
��
��
Proof.  Choose c =  100 and x0  = 1.  Then the proposition holds, since for all x ≥  1, 
≤ 100x
� 
100x2 
2 . 
Proposition 15.5.10. 

x2  + 100x + 10 = O(x2 ).

Proof.  (x2  + 100x + 10)/x2  =  1 + 100/x + 10/x2  and  so  its  limit  as x  approaches 
inﬁnity is 1+ 0+ 0 = 1. So in fact, x2 + 100x+ 10 ∼ x2 , and therefore x2 + 100x+ 10 = 
� 
O(x2 ).  Indeed, it’s conversely true that x2  = O(x2  + 100x + 10). 

Proposition 15.5.10 generalizes to an arbitrary polynomial: 
Proposition 15.5.11.  For ak  �= 0, ak xk  + ak−1xk−1  + · · · + a1x + a0  = O(xk ). 
We’ll omit the routine proof. 
Big Oh notation is especially useful when describing the running time of an al­
gorithm. For example, the usual algorithm for multiplying n × n matrices requires 
proportional  to  n3  operations  in  the  worst  case.  This  fact  can  be  expressed  con­
cisely by saying that the running time is O(n3 ).  So this asymptotic notation allows 
the  speed  of  the  algorithm  to  be  discussed  without  reference  to  constant  factors 
or  lower-order terms that might be machine speciﬁc.  In this case there  is another, 
ingenious matrix multiplication procedure that requires O(n2.55 ) operations.  This 
procedure  will  therefore  be  much  more  efﬁcient  on  large  enough  matrices.  Un­
fortunately,  the O(n2.55 )-operation multiplication procedure  is almost never used 
because it happens to be less efﬁcient than the usual O(n3 ) procedure on matrices 
of practical size. 

15.5.3  Theta 
Deﬁnition 15.5.12. 

f  = Θ(g) 

iff  f  = O(g) and g = O(f ). 

The statement f  = Θ(g) can be paraphrased intuitively as “f  and g are equal to 
within a constant factor.” 
The value of these notations is that they highlight growth rates and allow sup­
pression  of  distracting  factors  and  low-order  terms.  For  example,  if  the  running 
time of an algorithm is 
T (n) = 10n 3  − 20n 2  + 1, 

then 

T (n) = Θ(n 3 ). 
In this case, we would say that T  is of order n3  or that T (n) grows cubically. 
Another such example is 
(2.7x113  + x9  − 86)4 
√
x 

− 1.083x  = Θ(3x ). 

π23x−7  + 

326 

CHAPTER 15.  SUMS & ASYMPTOTICS 

Just  knowing  that  the  running  time  of  an  algorithm  is  Θ(n3 ),  for  example,  is 
useful, because if n doubles we can predict that the running time will by and large4 
increase by a factor of at most 8 for large n.  In this way, Theta notation preserves in­
formation about the scalability of an algorithm or system.  Scalability is, of course, 
a big issue in the design of algorithms and systems. 

15.5.4  Pitfalls with Big Oh 
There  is  a  long  list  of ways  to make mistakes with  Big Oh  notation.  This  section 
presents some of the ways that Big Oh notation can lead to ruin and despair. 

The Exponential Fiasco 

Sometimes  relationships  involving  Big Oh  are  not  so  obvious.  For  example,  one 
might  guess  that  4x  =  O(2x )  since  4  is  only  a  constant  factor  larger  than  2.  This 
reasoning is incorrect, however; actually 4x  grows much faster than 2x . 
Proposition 15.5.13.  4x  =� O(2x ) 
Proof.  2x /4x  = 2x /(2x 2x ) = 1/2x .  Hence, limx→∞ 2x /4x  = 0, so in fact 2x  =  o(4x ). 
We observed earlier that this implies that 4x  =� O(2x ). 
� 

False Theorem 15.5.14. 

Constant Confusion 
Every  constant  is  O(1).  For  example,  17  =  O(1).  This  is  true  because  if  we  let 
f (x) = 17 and g(x) = 1, then there exists a c > 0 and an x0  such that |f (x)| ≤ cg(x). 
In particular, we could choose  c = 17 and x0  = 1,  since  |17| ≤  17 · 1  for all x  ≥  1. 
We can construct a false theorem that exploits this fact. 
� 
n
i = O(n) 
�
i=1 
· · · 
n 
=1  i = 1 + 2 + 3 +  + n.  Since we have shown that 
False proof.  Deﬁne f (n) = 
�
· · · 
�
i
every constant i is O(1), f (n) = O(1) + O(1) +  + O(1) = O(n). 
i=1  i = n(n + 1)/2 =� O(n). 
n
Of course in reality 
The error stems from confusion over what is meant in the statement i  =  O(1). 
For any constant i  ∈  N  it  is  true  that  i  =  O(1).  More precisely,  if f  is any constant 
function,  then  f  =  O(1).  But  in  this  False  Theorem,  i  is  not  constant  but  ranges 
over a set of values 0,1,. . . ,n that depends on n. 
And  anyway,  we  should  not  be  adding O(1)’s  as  though  they were  numbers. 
We  never  even  deﬁned what  O(g) means  by  itself;  it  should  only  be  used  in  the 
context “f  = O(g)” to describe a relation between functions f  and g . 

4 Since Θ(n3 )  only  implies  that  the  running  time,  T (n),  is between  cn3  and  dn3  for  constants  0  < 
c < d, the time T (2n) could regularly exceed T (n) by a factor as large as 8d/c.  The factor is sure to be 
close to 8 for all large n only if T (n) ∼ n3 . 

15.5.  ASYMPTOTIC NOTATION 

327 

Lower Bound Blunder 

Sometimes  people  incorrectly  use  Big  Oh  in  the  context  of  a  lower  bound.  For 
example,  they might  say,  “The  running  time,  T (n),  is  at  least O(n2 ),”  when  they 
probably mean something like “O(T (n)) = n2 ,” or more properly, “n2  = O(T (n)).” 

Equality Blunder 

The notation f  = O(g) is too ﬁrmly entrenched to avoid, but the use of “=” is really 
regrettable.  For example, if f  = O(g), it seems quite reasonable to write O(g) = f . 
But doing so might tempt us to the following blunder:  because 2n = O(n), we can 
say O(n) = 2n.  But n  =  O(n), so we conclude that n  =  O(n) = 2n, and therefore 
n = 2n. To avoid such nonsense, we will never write “O(f ) = g .” 

15.5.5  Problems 
Practice Problems 

Problem 15.7. 
Let  f (n) =  n3 .  For  each  function  g(n)  in  the  table  below,  indicate  which  of  the 
indicated asymptotic relations hold. 

f  = O(g)  f  = o(g)  g = O(f )  g = o(f ) 

g(n) 
6 − 5n − 4n2  + 3n3 
n3  log n 
(sin (πn/2) + 2) n3 
nsin(πn/2)+2 
log n! 
e0.2n  − 100n3 

Homework Problems 

Problem 15.8.  (a)  Prove that log x < x for all x > 1 (requires elementary calculus). 

(b)  Prove  that the relation, R, on functions such  that f  R g  iff f  =  o(g)  is a strict 
partial order. 
(c)  Prove that f  ∼ g  iff f  = g + h for some function h = o(g). 

Problem 15.9. 
Indicate  which  of  the  following  holds  for  each  pair  of  functions  (f (n), g(n))  in 
the  table  below.  Assume  k  ≥  1,  � >  0,  and  c >  1  are  constants.  Pick  the  four 
table  entries  you  consider  to  be  the  most  challenging  or  interesting  and  justify 
your answers to these. 

328 

CHAPTER 15.  SUMS & ASYMPTOTICS 

f  = O(g)  f  = o(g)  g = O(f )  g = o(f )  f  = Θ(g)  f  ∼ g 

f (n) 
2n 
√
n 
log(n!) 
nk 
logk n 

g(n) 
2n/2 
nsin nπ/2 
log(nn ) 
cn 
n� 

Problem 15.10. 
Let  f ,  g  be  nonnegative  real-valued  functions  such  that  limx→∞ f (x) =  ∞  and 
f  ∼ g . 
(a)  Give an example of f , g such that NO T(2f  ∼ 2g ). 
(b)  Prove that log f  ∼ log g . 
(c)  Use Stirling’s formula to prove that in fact 
log(n!) ∼ n log n 

Class Problems 

Problem 15.11. 
Give an elementary proof (without appealing to Stirling’s formula)  that  log(n!)  = 
Θ(n log n). 

Problem 15.12. 
Recall that for functions f , g on N, f  = O(g) iff 
c · g(n) ≥ |f (n)| . 
∃c ∈ N ∃n0  ∈ N ∀n ≥ n0 
For  each  pair  of  functions  below,  determine  whether  f  =  O(g)  and  whether 
g  =  O(f ).  In  cases  where  one  function  is  O()  of  the  other,  indicate  the  smallest 
nonegative  integer,  c,  and  for  that  smallest  c,  the  smallest  corresponding  nonegative 
integer n0  ensuring that condition (15.14) applies. 
(a)  f (n) = n2 , g(n) = 3n. 
f  = O(g) 
NO 
YES 
g = O(f ) 
NO 
YES 
(b)  f (n) = (3n − 7)/(n + 4), g(n) = 4 
f  = O(g) 
YES 
NO 
g = O(f ) 
NO 
YES 

If YES, c = 
If YES, c = 

If YES, c = 
If YES, c = 

(15.14) 

, n0  = 
, n0  = 

, n0  = 
, n0  = 

15.5.  ASYMPTOTIC NOTATION 

329 

(c)  f (n) = 1 + (n sin(nπ/2))2 , g(n) = 3n 
f  = O(g) 
YES 
NO 
g = O(f ) 
NO 
YES 

If yes, c = 
If yes, c = 

n0  = 
n0  = 

Problem 15.13. 

False Claim. 

(15.15) 
Explain  why  the  claim  is  false.  Then  identify  and  explain  the  mistake  in  the 
following bogus proof. 

2n  = O(1). 

Bogus proof.  The proof by induction on n where the induction hypothesis, P (n), is 
the assertion (15.15). 
base case: P (0) holds trivially. 
inductive  step:  We  may  assume  P (n),  so  there  is  a  constant  c >  0  such  that 
2n  ≤ c  1. Therefore, 
· 
2n+1  = 2  2n  ≤ (2c) 1,
·
· 
which implies that 2n+1  = O(1). That is, P (n + 1) holds, which completes the proof 
of the inductive step. 
We  conclude  by  induction  that  2n  =  O(1)  for  all  n.  That  is,  the  exponential 
function is bounded by a constant. 
� 

Problem 15.14. 
(a)  Deﬁne a function f (n) such that f  = Θ(n2 ) and NO T(f  ∼ n2 ). 
n2 ) and g =�
(b)  Deﬁne a function g(n) such that g = O(n2 ), g = Θ(

o(n2 ). 

�
330 

CHAPTER 15.  SUMS & ASYMPTOTICS 

Chapter 16 

Counting 

16.1  Why Count? 

Are  there  two different  subsets  of  the  ninety  25-digit  numbers  shown  below  that 
have the same sum —for example, maybe the sum of the numbers in the ﬁrst col­
umn is equal to the sum of the numbers in the second column? 

0020480135385502964448038 
5763257331083479647409398 
0489445991866915676240992 
5800949123548989122628663 
1082662032430379651370981 
6042900801199280218026001 
1178480894769706178994993 
6116171789137737896701405 
1253127351683239693851327 
6144868973001582369723512 
1301505129234077811069011 
6247314593851169234746152 
1311567111143866433882194 
6814428944266874963488274 
1470029452721203587686214 
6870852945543886849147881 
1578271047286257499433886 
6914955508120950093732397 
1638243921852176243192354 
6949632451365987152423541 
1763580219131985963102365 
7128211143613619828415650 
1826227795601842231029694 
7173920083651862307925394 
1843971862675102037201420 
7215654874211755676220587 
2396951193722134526177237 
7256932847164391040233050 
2781394568268599801096354 
7332822657075235431620317 
2796605196713610405408019 
7426441829541573444964139 
2931016394761975263190347 
7632198126531809327186321 
2933458058294405155197296 
7712154432211912882310511 
3075514410490975920315348 

3171004832173501394113017 
8247331000042995311646021 
3208234421597368647019265 
8496243997123475922766310 
3437254656355157864869113 
8518399140676002660747477 
3574883393058653923711365 
8543691283470191452333763 
3644909946040480189969149 
8675309258374137092461352 
3790044132737084094417246 
8694321112363996867296665 
3870332127437971355322815 
8772321203608477245851154 
4080505804577801451363100 
8791422161722582546341091 
4167283461025702348124920 
9062628024592126283973285 
4235996831123777788211249 
9137845566925526349897794 
4670939445749439042111220 
9153762966803189291934419 
4815379351865384279613427 
9270880194077636406984249 
4837052948212922604442190 
9324301480722103490379204 
5106389423855018550671530 
9436090832146695147140581 
5142368192004769218069910 
9475308159734538249013238 
5181234096130144084041856 
9492376623917486974923202 
5198267398125617994391348 
9511972558779880288252979 
5317592940316231219758372 
9602413424619187112552264 
5384358126771794128356947 

331 

332 

CHAPTER 16.  COUNTING 

7858918664240262356610010 
8149436716871371161932035 
3111474985252793452860017 
7898156786763212963178679 
3145621587936120118438701 
8147591017037573337848616 
3148901255628881103198549 
5692168374637019617423712 

9631217114906129219461111 
3157693105325111284321993 
5439211712248901995423441 
9908189853102753335981319 
5610379826092838192760458 
9913237476341764299813987 
5632317555465228677676044 
8176063831682536571306791 

Finding  two  subsets  with  the  same  sum  may  seem  like  an  silly  puzzle,  but 
solving problems like this turns out to be useful, for example in ﬁnding good ways 
to ﬁt packages into shipping containers and in decoding secret messages. 
The answer to the question turns out to be “yes.” Of course this would be easy 
to conﬁrm just by showing two subsets with the same sum, but that turns out to be 
kind of hard to do. So before we put a lot of effort into ﬁnding such a pair, it would 
be nice to be sure there were some.  Fortunately,  it is very easy to see why there is 
such a pair —or at least it will be easy once we have developed a few simple rules 
for counting things. 

The Contest to Find Two Sets with the Same Sum 

One  term,  Eric Lehman,  a  6.042  instructor who  contributed  to many parts  of  this 
book,  offered  a  $100  prize  for  being  the  ﬁrst  6.042  student  to  actually  ﬁnd  two 
different  subsets  of  the  above  ninety  25-digit  numbers  that  have  the  same  sum. 
Eric didn’t expect to have to pay off this bet, but he underestimated the ingenuity 
and initiative of 6.042 students. 
One computer science major wrote a program  that cleverly  searched only among 
a reasonably small set of “plausible” sets, sorted them by their sums, and actually 
found  a  couple with  the  same  sum.  He won  the  prize.  A  few  days  later,  a math 
major  ﬁgured  out  how  to  reformulate  the  sum  problem  as  a  “lattice  basis  reduc­
tion” problem;  then he  found a software package  implementing an efﬁcient basis 
reduction  procedure,  and  using  it,  he  very  quickly  found  lots  of  pairs  of  subsets 
with  the  same  sum.  He didn’t win  the prize,  but he  got  a  standing  ovation  from 
the class —staff included. 

Counting seems easy enough: 1, 2, 3, 4, etc. This direct approach works well for 
counting  simple  things —like  your  toes —and may  be  the  only  approach  for  ex­
tremely complicated things with no identiﬁable structure. However, subtler meth­
ods can help you count many things in the vast middle ground, such as: 

•	 The  number  of  different  ways  to  select  a  dozen  doughnuts  when  there  are 
ﬁve varieties available. 

•	 The number of 16-bit numbers with exactly 4 ones. 

16.2.  COUNTING ONE THING BY COUNTING ANOTHER 

333 

Counting is useful in computer science for several reasons: 

•	 Determining the time and storage required to solve a computational problem 
—a  central  objective  in  computer  science —often  comes  down  to  solving  a 
counting problem. 

•	 Counting  is  the  basis  of  probability  theory, which  plays  a  central  role  in  all 
sciences, including computer science. 

•	 Two  remarkable  proof  techniques,  the  “pigeonhole  principle”  and  “combi­
natorial proof,”  rely on  counting.  These  lead  to  a variety of  interesting  and 
useful insights. 

We’re going to present a lot of rules for counting.  These rules are actually the­
orems,  but most  of  them  are  pretty  obvious  anyway,  so we’re  not  going  to  focus 
on proving them. Our objective is to teach you simple counting as a practical skill, 
like integration. 

16.2  Counting One Thing by Counting Another 

How  do  you  count  the  number  of  people  in  a  crowded  room?  You  could  count 
heads,  since  for  each  person  there  is  exactly  one  head.  Alternatively,  you  could 
count ears and divide by two.  Of course, you might have to adjust the calculation 
if  someone  lost  an  ear  in  a pirate  raid  or  someone was born with  three  ears.  The 
point  here  is  that  you  can  often  count  one  thing  by  counting  another,  though  some 
fudge factors may be required. 
In more formal terms, every counting problem comes down to determining the 
size of some set.  The size or cardinality of a ﬁnite set, S , is the number of elements 
in  it and  is denoted  |S |.  In  these  terms, we’re claiming  that we can often ﬁnd  the 
size  of  one  set  by  ﬁnding  the  size  of  a  related  set.  We’ve  already  seen  a  general 
statement of this idea in the Mapping Rule of Lemma 4.8.2. 

16.2.1  The Bijection Rule 
We’ve  already  implicitly  used  the  Bijection  Rule  of  Lemma  3  a  lot.  For  example, 
when we studied Stable Marriage and Bipartite Matching, we assumed the obvious 
fact that if we can pair up all the girls at a dance with all the boys, then there must 
be an equal number of each.  If we needed  to be explicit about using  the Bijection 
Rule,  we  could  say  that  A  was  the  set  of  boys,  B  was  the  set  of  girls,  and  the 
bijection between them was how they were paired. 
The Bijection Rule acts as a magniﬁer of counting ability;  if you ﬁgure out  the 
size of  one  set,  then you  can  immediately determine  the  sizes of many  other  sets 
via bijections.  For example, let’s return to two sets mentioned earlier: 
A = all ways to select a dozen doughnuts when ﬁve varieties are available 
B = all 16-bit sequences with exactly 4 ones 

334 

CHAPTER 16.  COUNTING 

Let’s consider a particular element of set A: 
���� 
�� 
���� 
���� 
���� 
� 
� 
0 0
0 0
0 0 0 0 0 0
0 0
sugar 
glazed 
lemon-ﬁlled 
plain 
chocolate 
We’ve depicted each doughnut with a 0 and left a gap between the different vari­
eties. Thus, the selection above contains two chocolate doughnuts, no lemon-ﬁlled, 
six sugar, two glazed, and two plain. Now let’s put a 1 into each of the four gaps: 
���� 
���� 
� 
���� 
���� 
�� 
� 
0 0
0 0
0 0 0 0 0 0
0 0
sugar 
plain 
glazed 
lemon-ﬁlled 
chocolate 
We’ve just formed a 16-bit number with exactly 4 ones— an element of B ! 
This example suggests a bijection from set A to set B : map a dozen doughnuts 
consisting of: 

1 

1 

1 

1

1

1

1

1

c chocolate, l lemon-ﬁlled, s sugar, g glazed, and p plain 
to the sequence: 
� �� � 
� �� � 
� �� � 
� �� � 
� �� � 
0 . . . 0
0 . . . 0
0 . . . 0
0 . . . 0
0 . . . 0
p 
c 
l 
g
s
The  resulting  sequence  always  has  16  bits  and  exactly  4  ones,  and  thus  is  an 
element  of  B .  Moreover,  the  mapping  is  a  bijection;  every  such  bit  sequence  is 
mapped to by exactly one order of a dozen doughnuts. Therefore, |A| = |B | by the 
Bijection Rule! 
This  demonstrates  the  magnifying  power  of  the  bijection  rule.  We  managed 
to prove  that  two very different sets are actually  the same size— even  though we 
don’t know exactly how big either one is.  But as soon as we ﬁgure out the size of 
one set, we’ll immediately know the size of the other. 
This particular bijection might seem frighteningly ingenious if you’ve not seen 
it  before.  But  you’ll  use  essentially  this  same  argument  over  and  over,  and  soon 
you’ll consider it routine. 

16.2.2  Counting Sequences 
The  Bijection  Rule  lets  us  count  one  thing  by  counting  another.  This  suggests  a 
general  strategy:  get  really  good  at  counting  just  a  few  things  and  then use  bijec­
tions  to  count  everything  else.  This  is  the  strategy we’ll  follow.  In particular, we’ll 
get really good at counting sequences. When we want to determine the size of some 
other set T , we’ll ﬁnd a bijection from T  to a set of sequences S . Then we’ll use our 
super-ninja sequence-counting skills to determine |S |, which immediately gives us 
|T |. We’ll need to hone this idea somewhat as we go along, but that’s pretty much 
the plan! 

16.2.  COUNTING ONE THING BY COUNTING ANOTHER 

335 

16.2.3  The Sum Rule 
Linus allocates his big sister Lucy a quota of 20 crabby days, 40 irritable days, and 
60  generally  surly  days.  On  how  many  days  can  Lucy  be  out-of-sorts  one  way 
or  another?  Let  set  C  be  her  crabby  days,  I  be  her  irritable  days,  and  S  be  the 
generally  surly.  In  these  terms,  the  answer  to  the  question  is  |C ∪ I ∪ S |.  Now 
assuming  that  she  is  permitted  at most  one  bad  quality  each  day,  the  size  of  this 
union of sets is given by the Sum Rule: 
Rule 1 (Sum Rule).  If A1 , A2 , . . . , An  are disjoint sets, then: 
|A1  ∪ A2  ∪ . . . ∪ An | = |A1 | + |A2 | + . . . + |An | 
Thus, according to Linus’ budget, Lucy can be out-of-sorts for: 
|C ∪ I ∪ S | = |C | + |I | + |S |
= 20 + 40 + 60 
= 120 days 

Notice  that  the  Sum  Rule  holds  only  for  a  union  of  disjoint  sets.  Finding  the 
size  of  a union  of  intersecting  sets  is  a more  complicated problem  that we’ll  take 
up later. 

16.2.4  The Product Rule 
The Product Rule gives the size of a product of sets.  Recall that if P1 , P2 , . . . , Pn  are 
sets, then 
P1  × P2  × . . . × Pn 
is the set of all sequences whose ﬁrst term is drawn from P1 , second term is drawn 
from P2  and so forth. 
Rule 2 (Product Rule).  If P1 , P2 , . . . Pn  are sets, then: 
|P1  × P2  × . . . × Pn | = |P1 | · |P2 | · · · |Pn | 
Unlike the sum rule, the product rule does not require the sets P1 , . . . , Pn  to be 
disjoint.  For example, suppose a daily diet consists of a breakfast selected from set 
B , a lunch from set L, and a dinner from set D : 
B = {pancakes, bacon and eggs, bagel, Doritos}

L = {burger and fries, garden salad, Doritos}

D = {macaroni, pizza, frozen burrito, pasta, Doritos}

Then B ×L×D is the set of all possible daily diets. Here are some sample elements:

(pancakes, burger and fries, pizza)

(bacon and eggs, garden salad, pasta)

(Doritos, Doritos, frozen burrito)


336 

CHAPTER 16.  COUNTING 

The Product Rule tells us how many different daily diets are possible: 
|B × L × D | = |B | · |L| · |D |
·
· 
= 4  3  5
= 60 

16.2.5  Putting Rules Together 
Few  counting  problems  can  be  solved with  a  single  rule.  More  often,  a  solution 
is  a  ﬂurry  of  sums,  products,  bijections,  and  other  methods.  Let’s  look  at  some 
examples that bring more than one rule into play. 

Counting Passwords 

The  sum  and  product  rules  together  are  useful  for  solving  problems  involving 
passwords, telephone numbers, and license plates.  For example, on a certain com­
puter  system,  a  valid  password  is  a  sequence  of  between  six  and  eight  symbols. 
The ﬁrst  symbol must be  a  letter  (which  can be  lowercase  or uppercase),  and  the 
remaining symbols must be either letters or digits. How many different passwords 
are possible? 
Let’s  deﬁne  two  sets,  corresponding  to  valid  symbols  in  the  ﬁrst  and  subse­
quent positions in the password. 
F  = {a, b, . . . , z , A, B , . . . , Z }

S  = {a, b, . . . , z , A, B , . . . , Z, 0, 1, . . . , 9}

In these terms, the set of all possible passwords is: 
(F  × S 5 ) ∪ (F  × S 6 ) ∪ (F  × S 7 ) 
Thus, the length-six passwords are in set F × S 5 , the length-seven passwords are in 
F × S 6 , and the length-eight passwords are in F × S 7 .  Since these sets are disjoint, 
we can apply  the Sum Rule and count  the  total number of possible passwords as 
��
��
��
��
��
��
��
��
follows: 
(F  × S 5 ) ∪ (F  × S 6 ) ∪ (F  × S 7 )  =  F  × S 5  +  F  × S 6  +  F  × S 7 
Sum Rule 
= |F | · |S | 5  + |F | · |S | 6  + |F | · |S | 7  Product Rule 
· 
·
·
= 52  625  + 52  626  + 52  627 
≈ 1.8  1014  different passwords 
· 

Subsets of an n-element Set 

How many different subsets of an n-element set X  are there?  For example, the set 
X  = {x1 , x2 , x3 } has eight different subsets: 
{x2}
∅
{x1 }
{x3 } {x1 , x3}
{x2 , x3}

{x1 , x2}
{x1 , x2 , x3 } 

16.2.  COUNTING ONE THING BY COUNTING ANOTHER 

337 

There is a natural bijection from subsets of X to n-bit sequences. Let x1 , x2 , . . . , xn 
be the elements of X . Then a particular subset of X maps to the sequence (b1 , . . . , bn ) 
where  bi  = 1  if  and  only  if  xi  is  in  that  subset.  For  example,  if  n  =  10,  then  the 
subset {x2 , x3 , x5 , x7 , x10} maps to a 10-bit sequence as follows: 
subset:  { 
(
sequence: 

x2 , x3 ,
1,  0, 
1, 

x10  }
) 
1

0, 

x5 ,
1,  0, 

x7 ,
1,  0,  0, 

We  just  used  a  bijection  to  transform  the  original  problem  into  a  question  about 
sequences  —exactly  according  to  plan!  Now  if  we  answer  the  sequence  question, 
then we’ve solved our original problem as well. 
But  how  many  different  n-bit  sequences  are  there?  For  example,  there  are  8 
different 3-bit sequences: 

(0, 1, 1) 
(1, 1, 1) 

(0, 0, 0) 
(0, 0, 1) 
(0, 1, 0) 
(1, 1, 0) 
(1, 0, 1) 
(1, 0, 0) 
Well, we can write the set of all n-bit sequences as a product of sets: 
�� 
� 
� 
{0, 1} × {0, 1} × . . . × {0, 1} = {0, 1} n 
n terms 
Then Product Rule gives the answer: 
|{0, 1} n | = |{0, 1}| n 
= 2n 

This means  that  the number of  subsets of an n-element  set X  is also 2n .  We’ll 
put this answer to use shortly. 

16.2.6  Problems 
Practice Problems 

Problem 16.1. 
How many ways  are  there  to  select  k  out  of  n  books  on  a  shelf  so  that  there  are 
always  at  least  3  unselected  books  between  selected  books?  (Assume  n  is  large 
enough for this to be possible.) 

Class Problems 

Problem 16.2. 
A license plate consists of either: 

•  3 letters followed by 3 digits (standard plate) 

•  5 letters (vanity plate) 

338 

CHAPTER 16.  COUNTING 

•  2 characters – letters or numbers (big shot plate) 

Let L be the set of all possible license plates. 
(a)  Express L in terms of 

A = {A, B , C, . . . , Z } 
D = {0, 1, 2, . . . , 9} 

using unions (∪) and set products (×). 
(b)  Compute |L|, the number of different license plates, using the sum and prod­
uct rules. 

Problem 16.3.  (a)  How  many  of  the  billion  numbers  in  the  range  from  1  to  109 
contain the digit 1? (Hint: How many don’t?) 

(b)  There are 20 books arranged in a row on a shelf. Describe a bijection between 
ways of choosing 6 of  these books so  that no  two adjacent books are selected and 
15-bit strings with exactly 6 ones. 

That is 

Problem 16.4. 
(a)  Let Sn,k  be the possible nonnegative integer solutions to the inequality 
+ xk  ≤ n. 
· · · 
x1  + x2  +
�
� 
Sn,k  ::=  (x1 , x2 , . . . , xk ) ∈ Nk  | (16.1) is true  . 
Describe a bijection between Sn,k  and the set of binary strings with n zeroes and k 
ones. 
(b)  Let Ln,k  be the length k weakly increasing sequences of nonnegative integers 
� 
� 
≤ n. That is 
Ln,k  ::=  (y1 , y2 , . . . , yk ) ∈ Nk  | y1  ≤ y2  ≤  · · · ≤ yk  ≤ n . 
Describe a bijection between Ln,k  and Sn,k . 

(16.1)

Problem 16.5. 
An n-vertex numbered tree is a tree whose vertex set is {1, 2, . . . , n} for some n > 2. 
We deﬁne the code of the numbered tree to be a sequence of n − 2  integers from 1 
to n obtained by the following recursive process: 

16.2.  COUNTING ONE THING BY COUNTING ANOTHER 

339 

If  there  are more  than  two  vertices  left, write  down  the  father  of  the  largest  leafa , 
delete this leaf, and continue this process on the resulting smaller tree. 
If there are only two vertices left, then stop —the code is complete. 

a The necessarily unique node adjacent to a leaf is called its father. 

For  example,  the  codes  of  a  couple  of  numbered  trees  are  shown  in  the  Fig­
ure 16.2. 

Coding Numbered Trees

Tree
Tree

2

3

2

6

5

4

4

5

7

Code

4 3 2

6 5 6 2 2

1

1

3

Image by MIT OpenCourseWare.
Figure 16.1: 

(a)  Describe a procedure for reconstructing a numbered tree from its code. 

(b)  Conclude there is a bijection between the n-vertex numbered trees and {1, . . . , n} n−2 , 
and state how many n-vertex numbered trees there are. 

340 

CHAPTER 16.  COUNTING 

Homework Problems 

Problem 16.6. 
Answer the following questions with a number or a simple formula involving fac­
torials and binomial coefﬁcients. Brieﬂy explain your answers. 
(a)  How many ways are there to order the 26 letters of the alphabet so that no two 
of  the vowels a, e, i, o, u appear consecutively and  the  last  letter  in  the ordering 
is not a vowel? 
Hint: Every vowel appears to the left of a consonant. 

(b)  How many ways are there to order the 26 letters of the alphabet so that there 
are at least two consonants immediately following each vowel? 

(c)  In how many different ways can 2n students be paired up? 

(d)  Two  n-digit  sequences  of  digits  0,1,. . . ,9  are  said  to  be  of  the  same  type  if  the 
digits of one are a permutation of  the digits of  the other.  For n  = 8,  for example, 
the  sequences 03088929 and 00238899 are  the  same  type.  How many  types of 
n-digit integers are there? 

Problem 16.7. 
In  a  standard  52-card  deck,  each  card  has  one  of  thirteen  ranks  in  the  set,  R,  and 
one of four suits in the set, S , where 
R ::= {A, 2, . . . , 10, J, Q, K } , 
S  ::= {♣, ♦, ♥, ♠} . 

A 5-card hand is a set of ﬁve distinct cards from the deck. 
For each part describe a bijection between a set that can easily be counted using 
the Product and Sum Rules of Ch. 16.2, and the set of hands matching the speciﬁ­
cation. Give bijections, not numerical answers. 
For instance, consider the set of 5-card hands containing all 4 suits.  Each such 
hand  must  have  2  cards  of  one  suit.  We  can  describe  a  bijection  between  such 
hands  and  the  set  S  × R2  × R3  where R2  is  the  set  of  two-element  subsets  of R. 
Namely, an element 

(s, {r1 , r2 } , (r3 , r4 , r5 )) ∈ S × R2  × R3 

indicates 
1.  the repeated suit, s ∈ S , 
2.  the set, {r1 , r2 } ∈ R2 , of ranks of the cards of suit, s, and 
3.  the  ranks  (r3 , r4 , r5 ) of  remaining  three  cards,  listed  in  increasing  suit order 
where ♣ � ♦ � ♥ � ♠. 

16.3.  THE PIGEONHOLE PRINCIPLE 

341 

For example, 

(♣, {10, A} , (J, J, 2))  ←→  {A♣, 10♣, J ♦, J ♥, 2♠} . 

(a)  A single pair of the same rank (no 3-of-a-kind, 4-of-a-kind, or second pair). 

(b)  Three or more aces. 

16.3  The Pigeonhole Principle 

Here is an old puzzle: 

A  drawer  in  a  dark  room  contains  red  socks,  green  socks,  and  blue 
socks. How many socks must you withdraw to be sure that you have a 
matching pair? 

For example, picking out three socks is not enough; you might end up with one 
red, one green, and one blue.  The solution relies on the Pigeonhole Principle, which 
is a friendly name for the contrapositive of the injective case 2 of the Mapping Rule 
of Lemma 4.8.2. Let’s write it down: 
If |X | > |Y |, then no total function1  f  : X  → Y  is injective. 

And now rewrite it again to eliminate the word “injective.” 
Rule 3 (Pigeonhole Principle).  If |X | >  |Y |, then for every total function f  : X  →  Y , 
there exist two different elements of X  that are mapped to the same element of Y . 

What  this  abstract  mathematical  statement  has  to  do  with  selecting  footwear 
under  poor  lighting  conditions  is maybe  not  obvious.  However,  let  A  be  the  set 
of socks you pick out, let B  be the set of colors available, and let f  map each sock 
to  its  color.  The Pigeonhole Principle  says  that  if  |A|  >  |B |  = 3,  then at  least  two 
elements of A (that is, at least two socks) must be mapped to the same element of 
B  (that  is,  the  same  color).  For  example,  one  possible  mapping  of  four  socks  to 
three colors is shown below. 

A 

f 

1st sock 

2nd sock 

3rd sock 
4th sock �

�

�
�

B 
red� 
� 
green 
���
�

blue 

1 This Mapping Rule actually applies even if f  is a total injective relation. 

342 

CHAPTER 16.  COUNTING 

Therefore, four socks are enough to ensure a matched pair. 
Not  surprisingly,  the  pigeonhole  principle  is  often  described  in  terms  of  pi­
geons: 

If  there  are  more  pigeons  than  holes  they  occupy,  then  at  least  two  pigeons 
must be in the same hole. 

In  this  case,  the  pigeons  form  set  A,  the  pigeonholes  are  set  B ,  and  f  describes 
which hole each pigeon ﬂies into. 
Mathematicians  have  come  up  with  many  ingenious  applications  for  the  pi­
geonhole principle.  If there were a cookbook procedure for generating such argu­
ments, we’d give it to you. Unfortunately, there isn’t one. One helpful tip, though: 
when you try to solve a problem with the pigeonhole principle, the key is to clearly 
identify three things: 

1.  The set A (the pigeons). 

2.  The set B  (the pigeonholes). 

3.  The function f  (the rule for assigning pigeons to pigeonholes). 

16.3.1  Hairs on Heads 
There are a number of generalizations of the pigeonhole principle.  For example: 
Rule 4 (Generalized Pigeonhole Principle).  If |X | > k · |Y |, then every total function 
→ 
f  : X Y  maps at least k + 1 different elements of X  to the same element of Y .
For example,  if you pick  two people at random, surely  they are extremely un­
likely  to  have  exactly  the  same  number  of  hairs  on  their  heads.  However,  in  the 
remarkable city of Boston, Massachusetts there are actually three people who have 
exactly the same number of hairs! Of course, there are many bald people in Boston, 
and they all have zero hairs. But we’re talking about non-bald people; say a person 
is non-bald if they have at least ten thousand hairs on their head. 
Boston has  about  500,000 non-bald people,  and  the number  of hairs  on  a per­
son’s  head  is  at most  200,000.  Let  A  be  the  set  of  non-bald  people  in  Boston,  let 
B  =  {10, 000, 10, 001, . . . , 200, 000}, and let f  map a person to the number of hairs 
on his or her head.  Since |A| > 2 |B |, the Generalized Pigeonhole Principle implies 
that at  least  three people have  exactly  the  same number of hairs.  We don’t know 
who they are, but we know they exist! 

16.3.2  Subsets with the Same Sum 
We asserted that two different subsets of the ninety 25-digit numbers listed on the 
ﬁrst page have the same sum. This actually follows from the Pigeonhole Principle. 
Let A be the collection of all subsets of the 90 numbers in the list. Now the sum of 
·
any subset of numbers is at most 90 1025 , since there are only 90 numbers and every 

16.3.  THE PIGEONHOLE PRINCIPLE 

343 
� 
� 
· 
25-digit number is less than 1025 . So let B be the set of integers  0, 1, . . . , 90  1025  ,
and let f  map each subset of numbers (in A) to its sum (in B ). 
We proved that an n-element set has 2n  different subsets. Therefore: 
|A| = 290 
≥ 1.237 × 1027 

On the other hand: 

|B | = 90 · 1025  + 1 
≤ 0.901 × 1027 
Both quantities are enormous,  but  |A|  is a bit greater  than  |B |.  This means  that f 
maps at least two elements of A to the same element of B .  In other words, by the 
Pigeonhole Principle, two different subsets must have the same sum! 
Notice  that  this proof  gives no  indication which  two  sets  of numbers have  the 
same sum. This frustrating variety of argument is called a nonconstructive proof. 

Sets with Distinct Subset Sums 

How  can  we  construct  a  set  of  n  positive  integers  such  that  all  its  subsets  have 
distinct sums? One way is to use powers of two: 
{1, 2, 4, 8, 16} 

This approach is so natural that one suspects all other such sets must involve larger 
numbers.  (For example, we could safely replace 16 by 17, but not by 15.)  Remark­
ably, there are examples involving smaller numbers. Here is one: 
{6, 9, 11, 12, 13} 

One  of  the  top mathematicans  of  the Twentieth Century,  Paul Erd ˝os,  conjectured 
in  1931  that  there  are  no  such  sets  involving  signiﬁcantly  smaller  numbers.  More 
precisely, he conjectured that the largest number must be > c2n  for some constant 
c >  0.  He offered $500 to anyone who could prove or disprove his conjecture, but 
the problem remains unsolved. 

16.3.3  Problems 
Class Problems 

Problem 16.8. 
Solve  the  following  problems  using  the  pigeonhole  principle.  For  each  problem, 

344 

CHAPTER 16.  COUNTING 

try  to  identify  the  pigeons,  the  pigeonholes,  and  a  rule  assigning  each  pigeon  to  a 
pigeonhole. 
(a)  Every MIT ID number starts with a 9 (we think).  Suppose that each of the 75 
students  in 6.042  sums  the nine digits of his or her  ID number.  Explain why  two 
people must arrive at the same sum. 

(b)  In  every  set of  100  integers,  there  exist  two whose difference  is  a multiple of 
37. 

√
(c)  For any ﬁve points  inside a unit square  (not on  the boundary),  there are  two 
2. 
points at distance less than 1/
(d)  Show  that  if  n + 1  numbers  are  selected  from  {1, 2, 3, . . . , 2n},  two  must  be 
consecutive, that is, equal to k and k + 1 for some k . 

Homework Problems 

Problem 16.9. 
Pigeon Huntin’ 
· 
(a)  Show that any odd integer x in the range 109  < x <  2  109  containing all ten 
digits 0, 1, . . . , 9 must have consecutive even digits.  Hint:  What can you conclude 
about the parities of the ﬁrst and last digit? 

(b)  Show  that  there are 2 vertices of  equal degree  in any ﬁnite undirected graph 
with n  ≥  2 vertices.  Hint:  Cases  conditioned upon  the existence of a degree zero 
vertex. 

Problem 16.10. 
Show  that  for  any  set  of  201  positive  integers  less  than  300,  there  must  be  two 
whose quotient is a power of three (with no remainder). 

16.4  The Generalized Product Rule 

We realize everyone has been working pretty hard this term, and we’re considering 
awarding  some  prizes  for  truly  exceptional  coursework.  Here  are  some  possible 
categories: 

Best Administrative Critique  We asserted that the quiz was closed-book.  On the 
cover page, one strong candidate for this award wrote, “There is no book.” 

Awkward Question Award  “Okay,  the  left  sock,  right  sock,  and  pants  are  in  an 
antichain, but how— even with assistance— could I put on all three at once?” 

Best Collaboration Statement  Inspired by a student who wrote “I worked alone” 
on Quiz 1. 

16.4.  THE GENERALIZED PRODUCT RULE 

345 

In how many ways can, say, three different prizes be awarded to n people? This 
is easy to answer using our strategy of translating the problem about awards into 
a problem about sequences.  Let P  be  the set of n people  in 6.042.  Then  there  is a 
bijection  from ways of  awarding  the  three prizes  to  the  set P 3  ::= P  × P  × P .  In 
particular, the assignment: 
��
��
“person x wins prize #1, y wins prize #2, and z wins prize #3” 
P 3  =  P|
| 3  =  n3 , so 
maps to the sequence (x, y , z ).  By the Product Rule, we have 
there are n3  ways to award the prizes to a class of n people. 
But what  if  the  three prizes must be awarded  to different  students?  As before, 
we could map the assignment 

“person x wins prize #1, y wins prize #2, and z wins prize #3” 
to the triple (x, y , z ) ∈ P 3 .  But this function is no longer a bijection.  For example, no 
valid  assignment maps  to  the  triple  (Dave,  Dave,  Becky)  because Dave  is  not  al­
� 
� 
lowed to receive two awards. However, there is a bijection from prize assignments 
to the set: 
S  =  (x, y , z ) ∈ P 3  | x, y , and z are different people 
This  reduces  the  original  problem  to  a  problem  of  counting  sequences.  Unfortu­
nately, the Product Rule is of no help in counting sequences of this type because the 
entries depend on one another;  in particular, they must all be different.  However, 
a slightly sharper tool does the trick. 

Rule 5 (Generalized Product Rule).  Let S  be a set of length-k sequences.  If there are: 

•  n1  possible ﬁrst entries, 

•  n2  possible second entries for each ﬁrst entry, 

•  n3  possible third entries for each combination of ﬁrst and second entries, etc. 

then: 

|S | = n1  · n2  · n3  · · · nk 
In  the  awards  example,  S  consists  of  sequences  (x, y , z ).  There  are  n ways  to 
choose x, the recipient of prize #1. For each of these, there are n − 1 ways to choose 
y , the recipient of prize #2, since everyone except for person x is eligible.  For each 
combination of x and y , there are n − 2 ways to choose z , the recipient of prize #3, 
because everyone except for x and y is eligible. Thus, according to the Generalized 
Product Rule, there are 

|S | = n · (n − 1) · (n − 2) 

ways to award the 3 prizes to different people. 

346 

CHAPTER 16.  COUNTING 

16.4.1  Defective Dollars 
A dollar is defective if some digit appears more than once in the 8-digit serial num­
ber.  If  you  check  your wallet,  you’ll  be  sad  to  discover  that  defective  dollars  are 
all-too-common.  In  fact,  how  common  are  nondefective  dollars?  Assuming  that 
the digit portions of  serial numbers all occur equally often, we could answer  this 
question by computing: 

fraction dollars that are nondefective = 

# of serial #’s with all digits different 
total # of serial #’s 
Let’s ﬁrst consider the denominator. Here there are no restrictions; there are are 10 
possible ﬁrst digits, 10 possible second digits, 10 third digits, and so on.  Thus, the 
total number of 8-digit serial numbers is 108  by the Product Rule. 
Next,  let’s  turn  to  the  numerator.  Now  we’re  not  permitted  to  use  any  digit 
twice.  So  there  are  still  10  possible  ﬁrst  digits,  but  only  9  possible  second  digits, 
8 possible third digits, and so forth.  Thus, by the Generalized Product Rule, there 
are 

·
·
·
·
·
·
· 
10  9  8  7  6  5  4  3 = 

10!
2 
= 1, 814, 400 

serial  numbers  with  all  digits  different.  Plugging  these  results  into  the  equation 
above, we ﬁnd: 

fraction dollars that are nondefective = 

1, 814, 400
100, 000, 000 
= 1.8144% 

16.4.2  A Chess Problem 
In  how many different ways  can we place  a pawn  (p),  a  knight  (k),  and  a  bishop 
(b) on a chessboard so that no two pieces share a row or a column? A valid conﬁg­
uration  is  shown below on  the  left,  and  an  invalid  conﬁguration  is  shown on  the 
right. 

k 

b 

p 

valid 

p 

b 

k 

invalid 

16.5.  THE DIVISION RULE 

347 

First, we map this problem about chess pieces to a question about sequences. There 
is a bijection from conﬁgurations to sequences 
(rp , cp , rk , ck , rb , cb ) 
where  rp ,  rk ,  and  rb  are  distinct  rows  and  cp ,  ck ,  and  cb  are  distinct  columns.  In 
particular, rp  is the pawn’s row, cp  is the pawn’s column, rk  is the knight’s row, etc. 
Now we  can  count  the number of  such  sequences using  the Generalized Product 
Rule: 
• rp  is one of 8 rows 
• cp  is one of 8 columns 
• rk  is one of 7 rows (any one but rp ) 
• ck  is one of 7 columns (any one but cp ) 
• rb  is one of 6 rows (any one but rp  or rk ) 
• cb  is one of 6 columns (any one but cp  or ck ) 
·
· 
Thus, the total number of conﬁgurations is (8  7  6)2 .

16.4.3  Permutations 
A permutation of a set S is a sequence that contains every element of S exactly once. 
For example, here are all the permutations of the set {a, b, c}: 
(b, a, c) 
(a, c, b)
(a, b, c)
(b, c, a)
(c, a, b)
(c, b, a) 

How many permutations of an n-element set are there? Well, there are n choices 
for  the  ﬁrst  element.  For  each  of  these,  there  are  n − 1  remaining  choices  for  the 
second  element.  For  every  combination  of  the ﬁrst  two  elements,  there  are n − 2 
ways to choose the third element, and so forth. Thus, there are a total of 
n  (n − 1)  (n − 2) 
· 
· 
· · · 
·
· 
3 2 1 = n!
permutations  of  an  n-element  set.  In  particular,  this  formula  says  that  there  are 
3!  =  6  permuations  of  the  3-element  set  {a, b, c},  which  is  the  number we  found 
above. 
Permutations  will  come  up  again  in  this  course  approximately  1.6  bazillion 
times.  In  fact,  permutations  are  the  reason  why  factorial  comes  up  so  often  and 
� n �n 
why we taught you Stirling’s approximation: 
√
n! ∼
2πn 
e 

16.5  The Division Rule 

Counting ears and dividing by two is a silly way to count the number of people in 
a room, but this approach is representative of a powerful counting principle. 
A k-to-1 function maps exactly k elements of the domain to every element of the 
codomain.  For example, the function mapping each ear to its owner is 2-to-1: 

348 

CHAPTER 16.  COUNTING 

ear 1 

ear 4 

�  person A 
�� �
�
ear 2 
����
��� �
� 
ear 3  �
� �
�
�����
�� ��
� 
ear 5 
� 
ear 6  � 

person C 

person B 

Similarly, the function mapping each ﬁnger to its owner is 10-to-1, and the func­
tion mapping each ﬁnger and toe to its owner is 20-to-1. The general rule is: 
Rule 6 (Division Rule).  If f  : A → B  is k-to-1, then |A| = k · |B |. 
For example, suppose A is the set of ears in the room and B  is the set of people. 
There is a 2-to-1 mapping from ears to people, so by the Division Rule |A| = 2 · |B |
or,  equivalently,  |B |  =  |A| /2,  expressing  what  we  knew  all  along:  the  number 
of  people  is  half  the  number  of  ears.  Unlikely  as  it  may  seem,  many  counting 
problems are made much easier by initially counting every item multiple times and 
then correcting the answer using the Division Rule. Let’s look at some examples. 

16.5.1  Another Chess Problem 
In how many different ways can you place two identical rooks on a chessboard so 
that they do not share a row or column?  A valid conﬁguration is shown below on 
the left, and an invalid conﬁguration is shown on the right. 

r 

r 

r 

invalid 

r 

valid 

Let A be the set of all sequences 

(r1 , c1 , r2 , c2 ) 

where  r1  and  r2  are  distinct  rows  and  c1  and  c2  are  distinct  columns.  Let  B  be 
the set of all valid rook conﬁgurations.  There is a natural function f  from set A to 
set B ; in particular, f  maps the sequence (r1 , c1 , r2 , c2 ) to a conﬁguration with one 
rook in row r1 , column c1  and the other rook in row r2 , column c2 . 

16.5.  THE DIVISION RULE 

349 

But now there’s a snag. Consider the sequences: 

(1, 1, 8, 8) 

and 

(8, 8, 1, 1) 

The ﬁrst sequence maps to a conﬁguration with a rook in the lower-left corner and 
a rook in the upper-right corner. The second sequence maps to a conﬁguration with 
a rook in the upper-right corner and a rook in the lower-left corner. The problem is 
that those are two different ways of describing the same conﬁguration!  In fact, this 
arrangement is shown on the left side in the diagram above. 
More generally, the function f  maps exactly two sequences to every board con­
ﬁguration;  that  is  f  is  a  2-to-1  function.  Thus,  by  the  quotient  rule,  |A|  = 2 · |B |. 
Rearranging terms gives: 

|B | = 

|A
| 
2 
(8 · 7)2 
2 
On the second line, we’ve computed the size of A using the General Product Rule 
just as in the earlier chess problem. 

= 

16.5.2  Knights of the Round Table 
In  how  many  ways  can  King  Arthur  seat  n  different  knights  at  his  round  table? 
Two  seatings  are  considered  equivalent  if  one  can  be  obtained  from  the  other  by 
rotation.  For example, the following two arrangements are equivalent: 
��
��
k3 
k1 
�� 
�� 
k4 
k2 
k1 
k3 

k4 

k2 

Let A be all the permutations of the knights, and let B  be the set of all possible 
seating arrangements at the round table. We can map each permutation in set A to 
a circular seating arrangement in set B  by seating the ﬁrst knight in the permuta­
tion anywhere, putting the second knight to his  left,  the third knight to the  left of 
the second, and so forth all the way around the table.  For example: 
��
k2 
�� 
k4 
k1 

(k2 , k4 , k1 , k3 ) 

−→ 

k3 

350 

CHAPTER 16.  COUNTING 

This mapping is actually an n-to-1 function from A to B , since all n cyclic shifts of 
the original sequence map to the same seating arrangement.  In the example, n = 4 
different sequences map to the same seating arrangement: 
(k2 , k4 , k1 , k3 )  ��k2 
−→  ��k4
(k4 , k1 , k3 , k2 ) 
k3 
(k1 , k3 , k2 , k4 ) 
(k3 , k2 , k4 , k1 ) 
k1 

Therefore, by the division rule, the number of circular seating arrangements is: 
|A
| 
|B | = 
n 
n! = 
n 
= (n − 1)! 
Note that |A| = n! since there are n! permutations of n knights. 

16.5.3  Problems 
Class Problems 

Problem 16.11. 
Your  6.006  tutorial  has  12  students,  who  are  supposed  to  break  up  into  4  groups 
of 3  students  each.  Your TA has observed  that  the  students waste  too much  time 
trying  to  form  balanced  groups,  so  he  decided  to  pre-assign  students  to  groups 
and email the group assignments to his students. 
(a)  Your TA has a list of the 12 students in front of him, so he divides the list into 
consecutive groups of 3.  For example, if the list is ABCDEFGHIJKL, the TA would 
deﬁne a sequence of four groups to be ({A, B , C } , {D , E , F } , {G, H, I } , {J, K, L}). 
This way of forming groups deﬁnes a mapping from a list of twelve students to a 
sequence of four groups. This is a k-to-1 mapping for what k? 

(b)  A group assignment  speciﬁes which  students are  in  the  same group,  but not 
any order in which the groups should be listed.  If we map a sequence of 4 groups, 
({A, B , C } , {D , E , F } , {G, H, I } , {J, K, L}), 

into a group assignment 
{{A, B , C } , {D , E , F } , {G, H, I } , {J, K, L}} , 

this mapping is j -to-1 for what j ? 

16.5.  THE DIVISION RULE 

351 

(c)  How many group assignments are possible? 

(d)  In how many ways can 3n students be broken up into n groups of 3? 

Problem 16.12. 
A pizza house is having a promotional sale. Their commercial reads: 

We offer 9 different  toppings  for your pizza!  Buy 3  large pizzas at  the 
regular price, and you can get each one with as many different toppings 
as you wish, absolutely free. That’s 22, 369, 621 different ways to choose 
your pizzas! 

The  ad  writer  was  a  former  Harvard  student  who  had  evaluated  the  formula 
(29 )3 /3! on his calculator and gotten close to 22, 369, 621. Unfortunately, (29 )3/3! is 
obviously not an integer, so clearly something is wrong. What mistaken reasoning 
might have  led  the ad writer  to  this  formula?  Explain how  to ﬁx  the mistake and 
get a correct formula. 

Problem 16.13. 
Answer the following quesions using the Generalized Product Rule. 
(a)  Next week, I’m going to get really ﬁt! On day 1, I’ll exercise for 5 minutes. On 
each subsequent day, I’ll exercise 0, 1, 2, or 3 minutes more than the previous day. 
For example, the number of minutes that I exercise on the seven days of next week 
might be 5, 6, 9, 9, 9, 11, 12. How many such sequences are possible? 

(b)  An  r-permutation  of  a  set  is  a  sequence  of  r  distinct  elements  of  that  set.  For 
example, here are all the 2-permutations of {a, b, c, d}: 

(a, b)
(b, a)
(c, a)
(d, a)

(a, c)
(b, c)
(c, b)
(d, b)

(a, d) 
(b, d) 
(c, d) 
(d, c) 

How  many  r-permutations  of  an  n-element  set  are  there?  Express  your  answer 
using factorial notation. 
(c)  How many n× n matrices are there with distinct entries drawn from {1, . . . , p}, 
where p ≥ n2 ? 

Exam Problems 

Problem 16.14. 
Suppose  that  two  identical  52-card decks  are mixed  together.  Write  a  simple  for­
mula for the number of 104-card double-deck mixes that are possible. 

352 

CHAPTER 16.  COUNTING 

16.6  Counting Subsets 

How many  k-element  subsets  of  an n-element  set  are  there?  This question  arises 
all the time in various guises: 

•	 In how many ways can I select 5 books from my collection of 100 to bring on 
vacation? 

•	 How many different 13-card Bridge hands can be dealt from a 52-card deck? 

•	 In how many ways can I select 5 toppings for my pizza if there are 14 avail­
able toppings? 
�  � 
This number comes up so often that there is a special notation for it: 
n 
�  � 
::=  the number of k-element subsets of an n-element set. 
k 
n
is  read  “n  choose  k .”  Now we  can  immediately  express 
The  expression 
k 
�
� 
the answers to all three questions above: 
100 
� � 
•	 I can select 5 books from 100 in 
5 
52 
� � 
•  There are 
13 
14 
•  There are 
5 

different 5-topping pizzas, if 14 toppings are available. 

ways.

different Bridge hands. 

16.6.1  The Subset Rule 
We  can  derive  a  simple  formula  for  the  n-choose-k  number  using  the  Division 
Rule.  We  do  this  by  mapping  any  permutation  of  an  n-element  set  {a1 , . . . , an}
into  a  k-element  subset  simply  by  taking  the ﬁrst  k  elements  of  the permutation. 
That is, the permutation a1a2  . . . an  will map to the set {a1 , a2 , . . . , ak }. 
Notice  that  any  other  permutation  with  the  same  ﬁrst  k  elements  a1 , . . . , ak 
in  any  order  and  the  same  remaining  elements  n  −  k  elements  in  any  order  will 
also map to this set.  What’s more, a permutation can only map to {a1 , a2 , . . . , ak }
if  its  ﬁrst  k  elements  are  the  elements  a1 , . . . , ak  in  some  order.  Since  there  are 
k !  possible  permutations  of  the  ﬁrst  k  elements  and  (n − k)!  permutations  of  the 
remaining  elements,  we  conclude  from  the  Product  Rule  that  exactly  k !(n −  k)! 
permutations  of  the  n-element  set  map  to  the  the  particular  subset,  S .  In  other 
words, the mapping from permutations to k-element subsets is k !(n − k)!-to-1. 
� � 
But we know there are n! permutations of an n-element set, so by the Division 
Rule, we conclude that 
n 
n! = k !(n − k)! 
k 

16.7.  SEQUENCES WITH REPETITIONS 

353 

which proves: 
Rule 7 (Subset Rule).  The number, 

�  � 
n 
, 
k 

of k-element subsets of an n-element set is 

n! 
. 
k ! (n − k)! 
Notice that this works even for 0-element subsets: n!/0!n! = 1. Here we use the 
fact  that  0!  is  a  product  of  0  terms, which  by  convention  equals  1.  (A  sum  of  zero 
terms equals 0.) 

16.6.2  Bit Sequences 
How many n-bit sequences contain exactly k ones? We’ve already seen the straight­
forward  bijection  between  subsets  of  an  n-element  set  and  n-bit  sequences.  For 
example, here  is a 3-element subset of {x1 , x2 , . . . , x8 } and the associated 8-bit se­
quence: 
}
{
,  x
, 
x
x
5 
4
1
1
1
0,  0,
1
( 
) 
,  0,  0,  0 
,
,
Notice  that  this  sequence  has  exactly  3  ones,  each  corresponding  to  an  element 
of  the  3-element  subset.  More  generally,  the  n-bit  sequences  corresponding  to  a 
�  � 
k-element subset will have exactly k ones.  So by the Bijection Rule, 
n
. 
k 

The number of n-bit sequences with exactly k ones is 

16.7  Sequences with Repetitions 

16.7.1  Sequences of Subsets 
Choosing  a  k-element  subset  of  an  n-element  set  is  the  same  as  splitting  the  set 
into a pair of subsets:  the ﬁrst subset of size k and the second subset consisting of 
the remaining n − k  elements.  So the Subset Rule can be understood as a rule for 
counting the number of such splits into pairs of subsets. 
We  can  generalize  this  to  splits  into more  than  two  subsets.  Namely,  let A  be 
an  n-element  set  and  k1 , k2 , . . . , km  be  nonnegative  integers  whose  sum  is  n. A 
(k1 , k2 , . . . , km )-split of A is a sequence 

(A1 , A2 , . . . , Am ) 
where the Ai  are pairwise disjoint2  subsets of A and |Ai | = ki  for i = 1, . . . , m. 
2 That is Ai  ∩ Aj  =  ∅ whenever i  �=  j .  Another way to say this is that no element appears in more 
than one of the Ai ’s. 

354 

CHAPTER 16.  COUNTING 

The  same  reasoning used  to explain  the Subset Rule extends directly  to a  rule 
for counting the number of splits into subsets of given sizes. 
� 
� 
Rule 8 (Subset Split Rule).  The number of (k1 , k2 , . . . , km )-splits of an n-element set is 
n! 
n
::= 
· · · 
km !
k1 ! k2 ! 
k1 , . . . , km 
The proof  of  this Rule  is  essentially  the  same  as  for  the  Subset Rule.  Namely, 
we map any permutation a1a2  . . . an  of an n-element set, A, into a (k1 , k2 , . . . , km )­
split by letting the 1st subset in the split be the ﬁrst k1  elements of the permutation, 
the  2nd  subset of  the  split be  the next  k2  elements,  . . . ,  and  the mth  subset of  the 
· · · 
split be the ﬁnal km  elements of the permutation. This map is a k1 ! k2 ! 
km !-to-1
from  the  n!  permutations  to  the  (k1 , k2 , . . . , km )-splits  of  A,  and  the  Subset  Split 
Rule now follows from the Division Rule. 

16.7.2  The Bookkeeper Rule 
We can also generalize our count of n-bit sequences with k-ones to counting length 
n  sequences of  letters over  an  alphabet with more  than  two  letters.  For  example, 
how many sequences can be formed by permuting the letters in the 10-letter word 
BOOKKEEPER? 
Notice that there are 1 B, 2 O’s, 2 K’s, 3 E’s, 1 P, and 1 R in BOOKKEEPER. This 
leads  to  a  straightforward bijection between permutations of BOOKKEEPER  and 
(1,2,2,3,1,1)-splits of {1, . . . , n}. Namely, map a permutation to the sequence of sets 
of positions where each of the different letters occur. 
For example,  in  the permutation BOOKKEEPER  itself,  the B  is  in  the 1st posi­
tion,  the O’s occur  in  the 2nd and 3rd positions, K’s  in 4th and 5th,  the E’s  in  the 
6th, 7th and 9th, P in the 8th, and R is in the 10th position, so BOOKKEEPER maps 
to 
({1} , {2, 3} , {4, 5} , {6, 7, 9} , {8} , {10}). 
From this bijection and the Subset Split Rule, we conclude that the number of ways 
to rearrange the letters in the word BOOKKEEPER is: 
���� 
total letters 
���� ���� ���� ���� ���� ���� 
10! 
1!
1!
1!
3!
2!
2!
B’s  O’s  K’s  E’s 
P’s  R’s 
This example generalizes directly to an exceptionally useful counting principle 
which we will call the 
Rule 9 (Bookkeeper Rule).  Let l1 , . . . , lm  be distinct elements. The number of sequences 
with k1  occurrences of l1 , and k2  occurrences of l2 , . . . , and km  occurrences of lm  is 
(k1  + k2  + . . . + km )! 
k1 ! k2 !  . . .  km ! 

16.7.  SEQUENCES WITH REPETITIONS 

355 

Example.  20-Mile Walks. 
I’m planning a 20-mile walk, which should  include 5 northward miles, 5 east­
ward miles, 5 southward miles, and 5 westward miles. How many different walks 
are possible? 
There  is a bijection between such walks and sequences with 5 N’s, 5 E’s, 5 S’s, 
and 5 W’s. By the Bookkeeper Rule, the number of such sequences is: 

20! 
5!4 

16.7.3  A Word about Words 

Someday you might refer to the Subset Split Rule or the Bookkeeper Rule in front 
of a roomful of colleagues and discover that they’re all staring back at you blankly. 
This is not because they’re dumb, but rather because we made up the name “Book­
keeper  Rule”.  However,  the  rule  is  excellent  and  the  name  is  apt,  so we  suggest 
that you play through:  “You know?  The Bookkeeper Rule?  Don’t you guys know 
anything???” 
The Bookkeeper Rule  is sometimes called  the “formula  for permutations with 
indistinguishable  objects.”  The  size  k  subsets  of  an  n-element  set  are  sometimes 
called k-combinations. Other similar-sounding descriptions are “combinations with 
repetition, permutations with repetition, r-permutations, permutations with indis­
tinguishable  objects,”  and  so  on.  However,  the  counting  rules we’ve  taught  you 
are  sufﬁcient  to  solve all  these  sorts of problems without knowing  this  jargon,  so 
we won’t burden you with it. 

16.7.4  Problems 

Class Problems 

Problem 16.15. 
The Tao  of BOOKKEEPER: we  seek  enlightenment  through  contemplation  of  the 
word BOOKKEEP ER. 
(a)  In how many ways can you arrange the letters in the word P OKE ? 

(b)  In how many ways can you arrange the letters in the word BO1O2K ? Observe 
that we have subscripted the O’s to make them distinct symbols. 

(c)  Suppose  we  map  arrangements  of  the  letters  in  BO1O2K  to  arrangements 
of  the  letters  in  BOOK  by  erasing  the  subscripts.  Indicate with  arrows  how  the 
arrangements on the left are mapped to the arrangements on the right. 

356 

CHAPTER 16.  COUNTING 

O2BO1K

KO2BO1

O1BO2K 
KO1BO2 
BO1O2K 
BO2O1K

. . .


BOOK 
OBOK 
KOBO 
. . . 

(d)  What kind of mapping is this, young grasshopper? 

(e)  In light of the Division Rule, how many arrangements are there of BOOK ? 

(f)  Very good, young master! How many arrangements are there of the letters in 
KE1E2P E3R? 

(g)  Suppose  we  map  each  arrangement  of  KE1E2P E3R  to  an  arrangement  of 
KEEP ER by erasing subscripts. List all the different arrangements of KE1E2P E3R 
that are mapped to REP EEK  in this way. 

(h)  What kind of mapping is this? 

(i)  So how many arrangements are there of the letters in KEEP ER? 

(j)  Now you are ready to face the BOOKKEEPER! 
How many arrangements of BO1O2K1K2E1E2P E3R are there? 

(k)  How many arrangements of BOOK1K2E1E2P E3R are there? 

(l)  How many arrangements of BOOKKE1E2P E3R are there? 

(m)  How many arrangements of BOOKKEEP ER are there? 

Remember well what you have learned:  subscripts on, subscripts off.

This is the Tao of Bookkeeper.


(n)  How many arrangements of V OODOODOLL are there? 

(o)  How  many  length  52  sequences  of  digits  contain  exactly  17  two’s,  23  ﬁves, 
and 12 nines? 

16.8  Magic Trick 

There is a Magician and an Assistant.  The Assistant goes into the audience with a 
deck of 52 cards while the Magician looks away.3 

3  There are 52 cards in a standard deck. Each card has a suit and a rank. There are four suits: 
♦( diamonds) 
♣( clubs) 
♥( hearts) 
♠( spades) 

16.8.  MAGIC TRICK 

357 

Five audience members each select one card from the deck.  The Assistant then 
gathers up the ﬁve cards and holds up four of them so the Magician can see them. 
The  Magician  concentrates  for  a  short  time  and  then  correctly  names  the  secret, 
ﬁfth card! 
Since we  don’t  really  believe  the Magician  can  read minds,  we  know  the As­
sistant  has  somehow  communicated  the  secret  card  to  the  Magician.  Since  real 
Magicians  and  Assistants  are  not  to  be  trusted,  we  can  expect  that  the  Assistant 
would  illegitimately  signal  the  Magician  with  coded  phrases  or  body  language, 
but they don’t have to cheat in this way.  In fact, the Magician and Assistant could 
be  kept  out  of  sight  of  each  other  while  some  audience  member  holds  up  the  4 
cards designated by the Assistant for the Magician to see. 
Of  course,  without  cheating,  there  is  still  an  obvious  way  the  Assistant  can 
communicate  to  the Magician:  he  can  choose  any  of  the  4!  =  24  permutations  of 
the 4 cards as the order in which to hold up the cards.  However,  this alone won’t 
quite work:  there are 48 cards remaining in the deck, so the Assistant doesn’t have 
enough  choices  of  orders  to  indicate  exactly  what  the  secret  card  is  (though  he 
could narrow it down to two cards). 

16.8.1  The Secret 

The method  the Assistant  can  use  to  communicate  the  ﬁfth  card  exactly  is  a  nice 
application of what we know about counting and matching. 
The Assistant really has another legitimate way to communicate: he can choose 
which of the ﬁve cards to keep hidden. Of course, it’s not clear how the Magician could 
determine which of these ﬁve possibilities the Assistant selected by looking at the 
four visible cards, but there is a way, as we’ll now explain. 
The problem facing the Magician and Assistant is actually a bipartite matching 
problem.  Put all  the  sets of 5  cards  in a  collection, X ,  on  the  left.  And put all  the 
sequences of 4 distinct cards in a collection, Y , on the right.  These are the two sets 
of  vertices  in  the  bipartite  graph.  There  is  an  edge  between  a  set  of  5  cards  and 
a  sequence  of  4  if  every  card  in  the  sequence  is  also  in  the  set.  In  other words,  if 
the  audience  selects  a  set  of  cards,  then  the  Assistant  must  reveal  a  sequence  of 
cards that is adjacent in the bipartite graph.  Some edges are shown in the diagram 
below. 

And there are 13 ranks, listed here from lowest to highest: 

Jack  Queen  King 
Ace 
A ,  2 ,  3 ,  4 ,  5 ,  6 ,  7 ,  8 ,  9 , J ,  Q , K 

Thus, for example, 8♥ is the 8 of hearts and A♠ is the ace of spades. 

358 

CHAPTER 16.  COUNTING 

X  = 
all sets of 
5 cards 

• 
• 
• 
• 
{8♥, K♠, Q♠, 2♦, 6♦} 
• 
• 
{8♥, K♠, Q♠, 9♣, 6♦} 
• 

• 
Y  = all 
• 
sequences of 4 
distinct cards 
• 
(8♥, K♠, Q♠, 2♦) 
�������� 
����������� 
(K♠, 8♥, Q♠, 2♦)
������������� 
���� 
(K♠, 8♥, 6♦, Q♠)
�������� 
��������� 
• 
• 
• 

For example, 

{8♥, K♠, Q♠, 2♦, 6♦} 
(16.2) 
is  an  element  of  X  on  the  left.  If  the  audience  selects  this  set  of  5  cards,  then 
there  are  many  different  4-card  sequences  on  the  right  in  set  Y  that  the  Assis­
tant  could  choose  to  reveal,  including  (8♥, K♠, Q♠, 2♦),  (K♠, 8♥, Q♠, 2♦),  and 
(K♠, 8♥, 6♦, Q♠). 
What the Magician and his Assistant need to perform the trick is a matching for 
the X vertices.  If they agree in advance on some matching, then when the audience 
selects a set of 5 cards, the Assistant reveals the matching sequence of 4 cards. The 
Magician  uses  the  reverse  of  the matching  to  ﬁnd  the  audience’s  chosen  set  of  5 
cards, and so he can name the one not already revealed. 
For example, suppose the Assistant and Magician agree on a matching contain­
ing the two bold edges in the diagram above.  If the audience selects the set 
{8♥, K♠, Q♠, 9♣, 6♦} , 

(16.3) 

then the Assistant reveals the corresponding sequence 
(K♠, 8♥, 6♦, Q♠). 

(16.4) 

Using  the matching,  the Magician  sees  that  the  hand  (16.3)  is matched  to  the  se­
quence  (16.4),  so  he  can  name  the  one  card  in  the  corresponding  set  not  already 
revealed, namely, the 9♣.  Notice that the fact that the sets are matched, that is, that 
different  sets  are  paired  with  distinct  sequences,  is  essential.  For  example,  if  the 
audience  picked  the  previous  hand  (16.2),  it  would  be  possible  for  the  Assistant 
to  reveal  the  same  sequence  (16.4),  but  he  better  not  do  that:  if  he  did,  then  the 
Magician would have no way to tell if the remaining card was the 9♣ or the 2♦. 
So how can we be sure the needed matching can be found?  The reason  is that 
· 
each  vertex  on  the  left  has  degree  5  4!  =  120,  since  there  are  ﬁve ways  to  select
the  card  kept  secret  and  there  are  4!  permutations  of  the  remaining  4  cards.  In 
addition, each vertex on the right has degree 48, since there are 48 possibilities for 
the ﬁfth card.  So this graph is degree-constrained according to Deﬁnition 10.6.5, and 
therefore satisﬁes Hall’s matching condition. 

16.8.  MAGIC TRICK 

359 

In fact, this reasoning show that the Magician could still pull off the trick if 120 
cards were  left  instead of 48,  that  is,  the  trick would work with a deck as  large as 
124 different cards —without any magic! 

16.8.2  The Real Secret 
� � 
But  wait  a  minute!  It’s  all  very  well  in  principle  to  have  the  Magician  and  his 
Assistant agree on a matching, but how are they supposed to remember a matching 
with  5  = 2, 598, 960  edges?  For  the  trick  to work  in  practice,  there  has  to  be  a 
52
way to match hands and card sequences mentally and on the ﬂy. 
We’ll describe one approach. As a running example, suppose that the audience 
selects: 
10♥  9♦  3♥  Q♠  J ♦ 
•	 The Assistant picks out two cards of the same suit.  In the example, the assis­
tant might choose the 3♥ and 10♥. 
•	 The Assistant locates the ranks of these two cards on the cycle shown below: 

K

A 

2 

Q	

J	

10	

9

3 

4 

5 

6 

8

7 

For any two distinct ranks on this cycle, one is always between 1 and 6 hops 
clockwise  from  the other.  For example,  the 3♥  is 6 hops clockwise  from  the 
10♥. 
•	 The more counterclockwise of these two cards is revealed ﬁrst, and the other 
becomes  the  secret  card.  Thus,  in our example,  the 10♥ would be  revealed, 
and the 3♥ would be the secret card. Therefore: 
–	 The suit of the secret card is the same as the suit of the ﬁrst card revealed. 
–	 The rank of the secret card is between 1 and 6 hops clockwise from the 
rank of the ﬁrst card revealed. 

•	 All that remains is to communicate a number between 1 and 6. The Magician 
and  Assistant  agree  beforehand  on  an  ordering  of  all  the  cards  in  the  deck 
from smallest to largest such as: 
A♣ A♦ A♥ A♠ 2♣ 2♦ 2♥ 2♠ 

K♥ K♠ 

. . . 

360 

CHAPTER 16.  COUNTING 

The order in which the last three cards are revealed communicates the num­
ber according to the following scheme: 

)  = 1 
( 
small,  medium, 
large 
large,  medium  )  = 2 
( 
small, 
(  medium, 
)  = 3 
small, 
large 
(  medium, 
)  = 4 
large, 
small 
small,  medium  )  = 5 
( 
large, 
( 
)  = 6 
large,  medium, 
small 

In  the  example,  the Assistant wants  to  send  6  and  so  reveals  the  remaining 
three cards in large, medium, small order. Here is the complete sequence that 
the Magician sees: 
10♥  Q♠  J ♦  9♦ 
•	 The Magician  starts with  the  ﬁrst  card,  10♥,  and  hops  6  ranks  clockwise  to 
reach 3♥, which is the secret card! 
So  that’s  how  the  trick  can  work  with  a  standard  deck  of  52  cards.  On  the 
other hand, Hall’s Theorem implies that the Magician and Assistant can in principle 
perform the trick with a deck of up to 124 cards.  It turns out that there is a method 
which  they could actually  learn  to use with a reasonable amount of practice  for a 
124 card deck (see The Best Card Trick by Michael Kleber). 

16.8.3  Same Trick with Four Cards? 
Suppose  that  the  audience  selects  only  four  cards  and  the  Assistant  reveals  a  se­
quence of three to the Magician. Can the Magician determine the fourth card? 
Let X  be all  the sets of  four cards  that  the audience might select,  and  let Y  be 
� �52 
all the sequences of three cards that the Assistant might reveal. Now, on one hand, 
we have 
4 
by the Subset Rule. On the other hand, we have 
|Y | = 52 · 51 · 50 = 132, 600 
by the Generalized Product Rule.  Thus, by the Pigeonhole Principle, the Assistant 
� 
� 
must reveal the same sequence of three cards for at least 
270, 725  = 3 
132, 600 

= 270, 725 

|X | = 

different  four-card  hands.  This  is  bad  news  for  the  Magician:  if  he  sees  that  se­
quence of three, then there are at least three possibilities for the fourth card which 
he cannot distinguish.  So there is no legitimate way for the Assistant to communi­
cate exactly what the fourth card is! 

16.8.  MAGIC TRICK 

16.8.4  Problems 
Class Problems 

361 

Problem 16.16.  (a)  Show that the Magician could not pull off the trick with a deck 
larger than 124 cards. 
Hint:  Compare the number of 5-card hands in an n-card deck with the number of 
4-card sequences. 

(b)  Show that, in principle, the Magician could pull off the Card Trick with a deck 
of 124 cards. 
Hint: Hall’s Theorem and degree-constrained (10.6.5) graphs. 

Problem 16.17. 
The Magician can determine the 5th card in a poker hand when his Assisant reveals 
the other 4  cards.  Describe a  similar method  for determining 2 hidden  cards  in a 
hand of 9 cards when your Assisant reveals the other 7 cards. 

Homework Problems 

Problem 16.18. 
Section 16.8.3 explained why it is not possible to perform a four-card variant of the 
hidden-card magic trick with one card hidden. But the Magician and her Assistant 
are determined to ﬁnd a way to make a trick like this work. They decide to change 
the  rules  slightly:  instead of  the Assistant  lining up  the  three unhidden  cards  for 
the Magician to see, he will line up all four cards with one card face down and the 
other three visible. We’ll call this the face-down four-card trick. 
For  example,  suppose  the  audience members  had  selected  the  cards  9♥,  10♦, 
A♣,  5♣.  Then  the  Assistant  could  choose  to  arrange  the  4  cards  in  any  order  so 
long as one is face down and the others are visible. Two possibilities are: 

A♣ 

? 

10♦ 

5♣ 

? 

5♣ 

9♥ 

10♦ 

(a)  Explain why there must be a bipartite matching which will in theory allow the 
Magician and Assistant to perform the face-down four-card trick. 

(b)  There is actually a simple way to perform the face-down four-card trick. 

362 

CHAPTER 16.  COUNTING 

Case 1.  there are two cards with the same suit: Say there are two ♠ cards. The Assistant 
proceeds as in the original card trick:  he puts one of the ♠ cards face up as the ﬁrst 
card. He will place the second ♠ card face down. He then uses a permutation of the 
face down card and the remaining two face up cards to code the offset of the face 
down card from the ﬁrst card. 
Case 2.  all four cards have different suits: Assign numbers 0, 1, 2, 3 to the four suits in 
some agreed upon way. The Assistant computes, s, the sum modulo 4 of the ranks 
of the four cards, and chooses the card with suit s to be placed face down as the ﬁrst 
card.  He then uses a permutation of the remaining three face-up cards to code the 
rank of the face down card.a 
a This elegant method was devised in Fall ’09 by student Katie E Everett. 

Explain  how  in Case  2.  the Magician  can determine  the  face down  card  from  the 
cards the Assistant shows her. 

(c)  Explain how any method for performing the face-down four-card trick can be 
adapted  to  perform  the  regular  (5-card  hand,  show  4  cards) with  a  52-card  deck 
consisting of the usual 52 cards along with a 53rd card call the joker. 

16.9  Counting Practice: Poker Hands 

Five-Card  Draw  is  a  card  game  in  which  each  player  is  initially  dealt  a  hand, a 
subset  of  5  cards.  (Then  the  game  gets  complicated,  but  let’s  not  worry  about 
that.) The number of different hands in Five-Card Draw is the number of 5-element 
� � 
subsets of a 52-element set, which is 52 choose 5: 
52
5 

total # of hands = 

= 2, 598, 960

Let’s get some counting practice by working out the number of hands with various 
special properties. 

16.9.1  Hands with a Four-of-a-Kind 
A  Four-of-a-Kind  is  a  set  of  four  cards  with  the  same  rank.  How  many  different 
hands contain a Four-of-a-Kind? Here are a couple examples: 
{  8♠,  8♦, Q♥,  8♥,  8♣ }
{  A♣,  2♣,  2♥,  2♦,  2♠ } 

As usual, the ﬁrst step is to map this question to a sequence-counting problem.  A 
hand with a Four-of-a-Kind is completely described by a sequence specifying: 

16.9.  COUNTING PRACTICE: POKER HANDS 

363 

1.  The rank of the four cards. 

2.  The rank of the extra card. 

3.  The suit of the extra card. 

Thus, there is a bijection between hands with a Four-of-a-Kind and sequences con­
sisting of two distinct ranks followed by a suit. For example, the three hands above 
are associated with the following sequences: 
} 
(8, Q, ♥)
↔ { 
8♠,  8♦,  8♥,  8♣, Q♥
↔ {  2♣,  2♥,  2♦,  2♠, A♣ } 
(2, A, ♣) 

Now we need only count the sequences. There are 13 ways to choose the ﬁrst rank, 
12 ways  to  choose  the  second  rank,  and  4 ways  to  choose  the  suit.  Thus,  by  the 
·
· 
Generalized Product Rule, there are 13  12  4 = 624 hands with a Four-of-a-Kind. 
This means that only 1 hand in about 4165 has a Four-of-a-Kind; not surprisingly, 
this is considered a very good poker hand! 

16.9.2  Hands with a Full House 
A Full House is a hand with three cards of one rank and two cards of another rank. 
Here are some examples: 
{  2♠,  2♣,  2♦, J ♣, J ♦ }
{  5♦,  5♣,  5♥,  7♥,  7♣ } 

Again,  we  shift  to  a  problem  about  sequences.  There  is  a  bijection  between  Full 
Houses and sequences specifying: 
� � 
1.  The rank of the triple, which can be chosen in 13 ways. 
4  ways. 
2.  The suits of the triple, which can be selected in  3
� � 
3.  The rank of the pair, which can be chosen in 12 ways. 
4  ways. 
4.  The suits of the pair, which can be selected in  2
The example hands correspond to sequences as shown below: 
(2, {♠, ♣, ♦} , J, {♣, ♦})  ↔ {  2♠,  2♣,  2♦, J ♣, J ♦ }
(5, {♦, ♣, ♥} , 7, {♥, ♣})  ↔ {  5♦,  5♣,  5♥,  7♥,  7♣ } 
� � 
� � 
By the Generalized Product Rule, the number of Full Houses is: 
4
4
· 
· 
13 
3 
2 

12

·

We’re on a roll— but we’re about to hit a speedbump. 

364 

CHAPTER 16.  COUNTING 

16.9.3  Hands with Two Pairs 
How  many  hands  have  Two  Pairs;  that  is,  two  cards  of  one  rank,  two  cards  of 
another rank, and one card of a third rank? Here are examples: 
{  3♦,  3♠, Q♦, Q♥, A♣ }
{  9♥,  9♦,  5♥, 
5♣, K♠ } 
Each hand with Two Pairs is described by a sequence consisting of: 
� � 
1.  The rank of the ﬁrst pair, which can be chosen in 13 ways. 
2.  The suits of the ﬁrst pair, which can be selected  4
2 ways. 
� � 
3.  The rank of the second pair, which can be chosen in 12 ways. 
4.  The suits of the second pair, which can be selected in  4
2 ways. 
� � 
5.  The rank of the extra card, which can be chosen in 11 ways. 
1 = 4 ways. 
6.  The suit of the extra card, which can be selected in  4
� � 
� � 
Thus, it might appear that the number of hands with Two Pairs is: 
4
4
· 
· 
· 
·
·
11 4
12 
13 
2 
2 

{  3♦,  3♠, Q♦, Q♥, A♣ } 

Wrong answer!  The problem is that there is not a bijection from such sequences to 
hands with Two Pairs. This is actually a 2-to-1 mapping. For example, here are the 
pairs of sequences that map to the hands given above: 
(3, {♦, ♠} , Q, {♦, ♥} , A, ♣)  � 
� 
(Q, {♦, ♥} , 3, {♦, ♠} , A, ♣) 
(9, {♥, ♦} , 5, {♥, ♣} , K, ♠)  �  {  9♥,  9♦,  5♥, 
(5, {♥, ♣} , 9, {♥, ♦} , K, ♠)  � 
The problem is that nothing distinguishes the ﬁrst pair from the second.  A pair of 
5’s and a pair of 9’s  is  the same as a pair of 9’s and a pair of 5’s.  We avoided  this 
difﬁculty  in  counting Full Houses because,  for  example,  a pair  of  6’s  and  a  triple 
of kings is different from a pair of kings and a triple of 6’s. 
We  ran  into  precisely  this  difﬁculty  last  time,  when  we  went  from  counting 
arrangements of different pieces on a chessboard to counting arrangements of two 
identical rooks. The solution then was to apply the Division Rule, and we can do the 
same here.  In  this  case,  the Division  rule  says  there are  twice as many  sequences 
� � 
� � 
as hands, so the number of hands with Two Pairs is actually: 
2 · 11  4·
· 
· 
· 
12
4
4
2
2 

5♣, K♠ }

13

16.9.  COUNTING PRACTICE: POKER HANDS 

365 

Another Approach 

The preceding example was disturbing! One could easily overlook the fact that the 
mapping was  2-to-1  on  an  exam,  fail  the  course,  and  turn  to  a  life  of  crime.  You 
can make the world a safer place in two ways: 
→
1.  Whenever you use a mapping f  : A
B  to translate one counting problem 
to  another,  check  that  the  same  number  elements  in  A  are mapped  to  each 
element in B .  If k elements of A map to each of element of B , then apply the 
Division Rule using the constant k . 

2.  As an extra check, try solving the same problem in a different way. Multiple 
approaches  are  often  available—  and  all  had  better  give  the  same  answer! 
(Sometimes  different  approaches  give  answers  that  look  different,  but  turn 
out to be the same after some algebra.) 
We already used  the ﬁrst method;  let’s  try  the  second.  There  is a bijection be­
� �  � � � � 
tween hands with two pairs and sequences that specify: 
13
1.  The ranks of the two pairs, which can be chosen in  2  ways. 
4  ways. 
2.  The suits of the lower-rank pair, which can be selected in  2
3.  The suits of the higher-rank pair, which can be selected in  4
2  ways. 
� � 
4.  The rank of the extra card, which can be chosen in 11 ways. 
1  = 4 ways. 
5.  The suit of the extra card, which can be selected in  4
For example, the following sequences and hands correspond: 
({3, Q} , {♦, ♠} , {♦, ♥} , A, ♣)  ↔ {  3♦,  3♠, Q♦, Q♥, A♣ }
({9, 5} , {♥, ♣} , {♥, ♦} , K, ♠)  ↔ {  9♥,  9♦,  5♥, 
5♣, K♠ } 
� �  � �  � � 
Thus, the number of hands with two pairs is: 
13 
4 
4 
· 
· 
·
2 
2 
2 

· 
11  4

This is the same answer we got before, though in a slightly different form. 

16.9.4  Hands with Every Suit 
How many hands contain at least one card from every suit? Here is an example of 
such a hand: 
{  7♦, K♣,  3♦, A♥,  2♠ } 
Each such hand is described by a sequence that speciﬁes: 

1.  The  ranks of  the diamond,  the  club,  the heart,  and  the  spade, which  can be 
·
·
· 
selected in 13  13  13  13 = 134  ways.

366 

CHAPTER 16.  COUNTING 

2.  The suit of the extra card, which can be selected in 4 ways. 

3.  The rank of the extra card, which can be selected in 12 ways. 

For example, the hand above is described by the sequence: 
(7, K, A, 2, ♦, 3)  ↔ {  7♦, K♣, A♥,  2♠,  3♦ } 

Are  there other  sequences  that  correspond  to  the  same hand?  There  is one more! 
We  could  equally  well  regard  either  the  3♦  or  the  7♦  as  the  extra  card,  so  this 
is  actually  a  2-to-1  mapping.  Here  are  the  two  sequences  corresponding  to  the 
example hand: 
(7, K, A, 2, ♦, 3)  �  {  7♦, K♣, A♥,  2♠,  3♦ }
(3, K, A, 2, ♦, 7)  � 

Therefore, the number of hands with every suit is: 
·
· 
134  4  12
2 

16.9.5  Problems 
Class Problems 

Problem 16.19. 
Solve the following counting problems by deﬁning an appropriate mapping (bijec­
tive or k-to-1) between a set whose size you know and the set in question. 
(a)  How many different ways are  there  to select a dozen donuts  if  four varieties 
are available? 

(b)  In  how  many  ways  can  Mr.  and  Mrs.  Grumperson  distribute  13  identical 
pieces of coal to their two —no, three! —children for Christmas? 

(c)  How many solutions over the nonnegative integers are there to the inequality: 

x1  + x2  + . . . + x10 

≤ 

100

(d)  We want to count step-by-step paths between points in the plane with integer 
coordinates. Ony two kinds of step are allowed:  a right-step which increments the 
x coordinate, and an up-step which increments the y coordinate. 

(i)  How many paths are there from (0, 0) to (20, 30)? 
(ii)  How  many  paths  are  there  from  (0, 0)  to  (20, 30)  that  go  through  the  point 
(10, 10)? 

16.9.  COUNTING PRACTICE: POKER HANDS 

367 

(iii)  How many paths are there from (0, 0) to (20, 30) that do not go through either 
of the points (10, 10) and (15, 20)?

Hint: Let P  be the set of paths from (0, 0) to (20, 30), N1  be the paths in P  that

go through (10, 10) and N2  be the paths in P  that go through (15, 20).


Problem 16.20. 
Solve the following counting problems.  Deﬁne an appropriate mapping (bijective 
or k-to-1) between a set whose size you know and the set in question. 
(a)  An  independent  living  group  is  hosting  nine  new  candidates  for  member­
ship.  Each candidate must be assigned a task:  1 must wash pots, 2 must clean the 
kitchen,  3 must  clean  the  bathrooms,  1 must  clean  the  common  area,  and  2 must 
serve dinner.  Write  a multinomial  coefﬁcient  for  the  number  of ways  this  can  be 
done. 

(b)  Write  a multinomial  coefﬁcient  for  the  number  of  nonnegative  integer  solu­
tions for the equation: 

x1  + x2  + x3  + x4  + x5  = 8.	

(16.5) 

(c)  How  many  nonnegative  integers  less  than  1,000,000  have  exactly  one  digit 
equal to 9 and have a sum of digits equal to 17? 

Exam Problems 

Problem 16.21. 
Here are the solutions to the next 10 problem parts, in no particular order. 
� 
� 
� 
� 
� 
� 
n − 1 + m 
n − 1 + m
n + m
n 
m	
m

n! 
(n − m)! 

n 
m 

m

n

2mn 

(a)	 How many solutions over the natural numbers are there to the inequality 
· · · 
+ xn  ≤ m?
x1  + x2  +

(b)	 How many length m words can be formed from an n-letter alphabet, if no 
letter is used more than once? 

(c)	 How  many  length  m  words  can  be  formed  from  an  n-letter  alphabet,  if 
letters can be reused? 

368 

CHAPTER 16.  COUNTING 

(d)	 How many  binary  relations  are  there  from  set A  to  set B  when  |A|  =  m 
and |B | = n? 

|
|

(e)	 How  many  injections  are  there  from  set  A  to  set  B ,  where  A =  m  and

|B | = n ≥ m? 

(f)	 How many ways are  there  to place a  total of m distinguishable balls  into

n  distinguishable  urns,  with  some  urns  possibly  empty  or  with  several

balls?


(g)	 How many ways are there to place a total of m indistinguishable balls into

n  distinguishable  urns,  with  some  urns  possibly  empty  or  with  several

balls?


(h)	 How many ways are  there  to put a  total of m distinguishable balls  into n

distinguishable urns with at most one ball in each urn?


16.10  Inclusion-Exclusion 

How  big  is  a  union  of  sets?  For  example,  suppose  there  are  60 math majors,  200 
EECS majors, and 40 physics majors.  How many students are there in these three 
departments? Let M  be the set of math majors, E be the set of EECS majors, and P 
be the set of physics majors.  In these terms, we’re asking for |M  ∪ E ∪ P |. 
The Sum Rule says that the size of union of disjoint sets is the sum of their sizes: 
|M  ∪ E ∪ P | = |M | + |E | + |P | 

(if M , E , and P  are disjoint) 

However, the sets M , E , and P  might not be disjoint.  For example, there might be 
a  student majoring  in  both math  and  physics.  Such  a  student would  be  counted 
twice  on  the  right  side  of  this  equation,  once  as  an  element  of M  and  once  as  an 
element of P . Worse, there might be a triple-major4  counted three times on the right 
side! 
Our last counting rule determines the size of a union of sets that are not neces­
sarily disjoint.  Before we  state  the  rule,  let’s  build  some  intuition  by  considering 
some easier special cases: unions of just two or three sets. 

16.10.1  Union of Two Sets 
For  two  sets, S1  and S2 ,  the  Inclusion-Exclusion Rule  is  that  the  size of  their union 
is: 
|S1  ∪ S2 | = |S1 | + |S2 | − |S1  ∩ S2 |	
4 . . . though not at MIT anymore. 

(16.6) 

16.10.  INCLUSION-EXCLUSION 

369 

Intuitively, each element of S1  is accounted for in the ﬁrst term, and each element 
of S2  is accounted for in the second term.  Elements in both S1  and S2  are counted 
twice—  once  in  the  ﬁrst  term  and  once  in  the  second.  This  double-counting  is 
corrected by the ﬁnal term. 
We can capture this double-counting idea in a precise way by decomposing the 
union  of  S1  and  S2  into  three  disjoint  sets,  the  elements  in  each  set  but  not  the 
other, and the elements in both: 
S1  ∪ S2  = (S1  − S2 ) ∪ (S2  − S1 ) ∪ (S1  ∩ S2 ). 
Similarly,  we  can  decompose  each  of  S1  and  S2  into  the  elements  exclusively  in 
each set and the elements in both: 
S1  = (S1  − S2 ) ∪ (S1  ∩ S2 ), 
S2  = (S2  − S1 ) ∪ (S1  ∩ S2 ). 
Now we have from (16.8) and (16.9) 
|S1 | + |S2 | = (|S1  − S2 | + |S1  ∩ S2 |) + (|S2  − S1 | + |S1  ∩ S2 |) 
= |S1  − S2 | + |S2  − S1 | + 2 |S1  ∩ S2 | , 
(16.10) 
which  shows  the  double-counting  of  S1  ∩ S2  in  the  sum.  On  the  other  hand, we 
have from (16.7) 

(16.8) 
(16.9) 

(16.7) 

|S1  ∪ S2 | = |S1  − S2 | + |S2  − S1 | + |S1  ∩ S2 | . 
Subtracting (16.11) from (16.10), we get 
(|S1 | + |S2 |) − |S1  ∪ S2 | = |S1  ∩ S2 | 

(16.11) 

which proves (16.6). 

16.10.2  Union of Three Sets 
So how many students are there in the math, EECS, and physics departments?  In 
other words, what is |M  ∪ E ∪ P | if: 
|M | = 60 
|E | = 200 
|P | = 40 

The size of a union of three sets is given by a more complicated Inclusion-Exclusion 
formula: 

|S1  ∪ S2  ∪ S3 | = |S1 | + |S2 | + |S3 | 
− |S1  ∩ S2 | − |S1  ∩ S3 | − |S2  ∩ S3 |
+ |S1  ∩ S2  ∩ S3 | 

370 

CHAPTER 16.  COUNTING 

Remarkably, the expression on the right accounts for each element in the union of 
S1 , S2 , and S3  exactly once.  For example, suppose that x is an element of all three 
sets. Then x is counted three times (by the |S1 |, |S2 |, and |S3 | terms), subtracted off 
three times (by the |S1  ∩ S2 |, |S1  ∩ S3 |, and |S2  ∩ S3 | terms), and then counted once 
more (by the |S1  ∩ S2  ∩ S3 | term). The net effect is that x is counted just once. 
So we can’t answer the original question without knowing the sizes of the var­
ious intersections. Let’s suppose that there are: 

4  math - EECS double majors 
3  math - physics double majors 
11  EECS - physics double majors 
triple majors 
2 
Then  |M  ∩ E |  = 4 + 2,  |M  ∩ P |  = 3 + 2,  |E ∩ P |  =  11 + 2,  and  |M  ∩ E ∩ P |  = 2. 
Plugging all this into the formula gives: 
|M  ∪ E ∪ P | = |M | + |E | + |P | − |M  ∩ E | − |M  ∩ P | − |E ∩ P | + |M  ∩ E ∩ P |
= 60 + 200 + 40 − 6 − 5 − 13 + 2 
= 278 

Sequences with 42, 04, or 60 
In how many permutations of the set {0, 1, 2, . . . , 9} do either 4 and 2, 0 and 4, or 6 
and 0 appear consecutively?  For example, none of these pairs appears in: 

(7, 2, 9, 5, 4, 1, 3, 8, 0, 6) 

The  06  at  the  end  doesn’t  count;  we  need  60.  On  the  other  hand,  both  04  and  60 
appear consecutively in this permutation: 

(7, 2, 5, 6, 0, 4, 3, 8, 1, 9) 

Let  P42  be  the  set  of  all  permutations  in  which  42  appears;  deﬁne  P60  and  P04 
similarly.  Thus,  for example,  the permutation above  is contained  in both P60  and 
P04 .  In these terms, we’re looking for the size of the set P42  ∪ P04  ∪ P60 . 
First, we must determine  the  sizes of  the  individual  sets,  such as P60 .  We  can 
use a trick:  group the 6 and 0 together as a single symbol.  Then there is a natural 
bijection between permutations of  {0, 1, 2, . . . 9}  containing  6  and  0  consecutively 
and permutations of: 
{60, 1, 2, 3, 4, 5, 7, 8, 9} 
For example, the following two sequences correspond: 
↔ 
(7, 2, 5, 60, 4, 3, 8, 1, 9)
(7, 2, 5, 6, 0, 4, 3, 8, 1, 9) 
There  are  9!  permutations  of  the  set  containing  60,  so  |P60 |  =  9!  by  the  Bijection 
Rule.  Similarly, |P04 | = |P42 | = 9! as well. 

16.10.  INCLUSION-EXCLUSION 

371 

Next, we must determine the sizes of the two-way intersections, such as P42  ∩
P60 .  Using  the grouping  trick  again,  there  is  a bijection with permutations of  the 
set: 
{42, 60, 1, 3, 5, 7, 8, 9} 
Thus, |P42  ∩ P60 | = 8!.  Similarly, |P60  ∩ P04 | = 8! by a bijection with the set: 
{604, 1, 2, 3, 5, 7, 8, 9} 
And |P42  ∩ P04 | = 8! as well by a similar argument. Finally, note that |P60  ∩ P04  ∩ P42 | = 
7! by a bijection with the set: 

{6042, 1, 3, 5, 7, 8, 9} 

Plugging all this into the formula gives: 
|P42  ∪ P04  ∪ P60 | = 9! + 9! + 9! − 8! − 8! − 8! + 7! 

16.10.3  Union of n Sets 
The size of a union of n sets is given by the following rule. 

Rule 10 (Inclusion-Exclusion). 
|S1  ∪ S2  ∪ · · · ∪ Sn | 
the sum of the sizes of the individual sets 
the sizes of all two-way intersections 
the sizes of all three-way intersections 
the sizes of all four-way intersections 
the sizes of all ﬁve-way intersections, etc. 

minus 
plus 
minus 
plus 

=

The  formulas  for unions of  two and  three sets are special cases of  this general 
rule. 
This way  of  expressing  Inclusion-Exclusion  is  easy  to  understand  and  nearly 
as  precise  as  expressing  it  in mathematical  symbols,  but we’ll  need  the  symbolic 
version below, so let’s work on deciphering it now. 
We already have a standard notation for the sum of sizes of the individual sets, 
� 
namely, 
n |Si | . 
i=1 
A “two-way  intersection”  is a set of the form Si  ∩ Sj  for i  =�
j .  We regard Sj  ∩ Si 
as the same two-way intersection as Si  ∩ Sj , so we can assume that i < j . Now we 
� 
can express the sum of the sizes of the two-way intersections as 
|Si  ∩ Sj |
1≤i<j≤n 

.

372 

CHAPTER 16.  COUNTING 

� 
Similarly, the sum of the sizes of the three-way intersections is 
|Si  ∩ Sj  ∩ Sk |
1≤i<j<k≤n 

.

These  sums  have  alternating  signs  in  the  Inclusion-Exclusion  formula,  with  the 
sum  of  the  k-way  intersections  getting  the  sign  (−1)k−1 .  This  ﬁnally  leads  to  a 
symbolic version of the rule: 
����� 
����� 
�  � 
n
 
Rule (Inclusion-Exclusion). 
n
|Si |
= 
Si 
i=1 
i=1 
−
|Si  ∩ Sj |
�  ����� 
1≤i<j≤n 
|Si  ∩ Sj  ∩ Sk | + · · · 
����� 
+ 
� 
1≤i<j<k≤n

n

+ (−1)n−1 
Si  . 
i=1 
16.10.4  Computing Euler ’s Function 
We will now use Inclusion-Exclusion to calculate Euler ’s function, φ(n). By deﬁni­
tion, φ(n) is the number of nonnegative integers less than a positive integer n that 
are relatively prime to n. But the set, S , of nonnegative integers less than n that are 
not relatively prime to n will be easier to count. 
· · · 
e1 
Suppose  the  prime  factorization  of  n  is  p1 
em  for  distinct  primes  pi .  This
pm
means that the integers in S  are precisely the nonnegative integers less than n that 
are  divisible  by  at  least  one  of  the  pi ’s.  So,  letting  Ci  be  the  set  of  nonnegative 
m
 
integers less than n that are divisible by pi , we have 
Ci . 
i=1 

S  = 

We’ll  be  able  to  ﬁnd  the  size  of  this  union  using  Inclusion-Exclusion  because 
the  intersections  of  the  Ci ’s  are  easy  to  count.  For  example,  C1  ∩ C2  ∩ C3  is  the 
set of nonnegative  integers  less  than n  that  are divisible by  each of  p1 ,  p2  and  p3 . 
But since the pi ’s are distinct primes, being divisible by each of these primes is that 
same as being divisible by their product. Now observe that if r is a positive divisor 
of n,  then exactly n/r  nonnegative  integers  less  than n are divisible by r , namely, 
0, r, 2r, . . . , ((n/r) − 1)r .  So exactly n/p1p2p3  nonnegative  integers  less  than n are 
divisible by all three primes p1 , p2 , p3 .  In other words, 
n

|C1  ∩ C2  ∩ C3 | = 
.

p1p2p3 

373 

|S | 

= 

= 

16.10.  INCLUSION-EXCLUSION 
So reasoning this way about all the intersections among the Ci ’s and applying 
����� 
����� � 
m
 
Inclusion-Exclusion, we get 
����� 
����� 
Ci 
� 
� 
� 
i=1 
m
m
|Ci  ∩ Cj |
|
Ci | − 
|Ci  ∩ Cj  ∩ Ck | − · · · + (−1)m−1 
+
Ci 
� 
� 
� 
1≤i<j≤m 
1≤i<j<k≤m 
i=1 
i=1 
m
n 
n 
− 
⎞ 
⎛
=
+ 
� 
� 
� 
pipj 
pi 
1≤i<j≤m 
1≤i<j<k≤m 
⎠
= n ⎝
i=1 
m
1 
1 
1
− 
+ 
pipj 
pi 
pipj pk 
1≤i<j≤m 
1≤i<j<k≤m 
i=1 
⎛
But φ(n) = n − |S
| by deﬁnition, so 
� 
� 
� 
φ(n) = n ⎝1 − 
m
1 
− 
+ 
� 
� 
m� 
pi 
1≤i<j≤m 
1≤i<j<k≤m 
i=1 
1 − 
= n 
. 
i=1 

n 
− · · · + (−1)m−1 
p1p2  · · · pn

1
+ (−1)m 
+ · · · 
p1p2  · · · pn

1
pipj pk 

− · · · + (−1)m−1

1 
p1p2  · · · pn

⎞ 
⎠

(16.12)

n
pipj pk 

1 
pipj 

1
pi

� 
� 
Notice that in case n = pk  for some prime, p, then (16.12) simpliﬁes to 
1 
φ(p k ) = p k  1 − 
p 

= p  − p 
k−1
k

as claimed in chapter 14. 
Quick Question: Why does equation (16.12) imply that 

φ(ab) = φ(a)φ(b) 

for relatively prime integers a, b > 1, as claimed in Theorem 14.7.1.(a)? 

16.10.5  Problems 
Practice Problems 

Problem 16.22. 
The  working  days  in  the  next  year  can  be  numbered  1,  2,  3,  . . . ,  300.  I’d  like  to 
avoid as many as possible. 

•  On even-numbered days, I’ll say I’m sick. 

•  On days that are a multiple of 3, I’ll say I was stuck in trafﬁc. 

374	

CHAPTER 16.  COUNTING 

•	 On days that are a multiple of 5, I’ll refuse to come out from under the blan­
kets. 

In total, how many work days will I avoid in the coming year? 

Class Problems 

Problem 16.23. 
A  certain  company  wants  to  have  security  for  their  computer  systems.  So  they 
have given everyone a name and password.  A length 10 word containing each of 
the characters: 

a, d, e, f, i, l, o, p, r, s, 

is  called  a  cword.  A password will be  a  cword which does not  contain  any of  the 
subwords ”fails”, ”failed”, or ”drop”. 
For example, the following two words are passwords: 

adeﬁloprs, srpolifeda, 

but the following three cwords are not: 

adropeﬂis, failedrops, dropefails. 

(a)  How many cwords contain the subword “drop”? 

(b)  How many cwords contain both “drop” and “fails”? 

(c)  Use the Inclusion-Exclusion Principle to ﬁnd a simple formula for the number 
of passwords. 

Homework Problems 

Problem 16.24. 
How  many  paths  are  there  from  point  (0, 0)  to  (50, 50)  if  every  step  increments 
one coordinate and leaves the other unchanged?  How many are there when there 
are  impassable  boulders  sitting  at  points  (10, 11)  and  (21, 20)?  (You  do  not  have 
to  calculate  the  number  explicitly;  your  answer  may  be  an  expression  involving 
binomial coefﬁcients.) 
Hint:  Count  the number of paths going  through  (10, 11),  the number  through 
(21, 20), and use Inclusion-Exclusion. 

Problem 16.25. 
A  derangement  is  a  permutation  (x1 , x2 , . . . , xn )  of  the  set  {1, 2, . . . , n}  such  that 
xi  =�
i  for all  i.  For example,  (2, 3, 4, 5, 1)  is a derangement, but (2, 1, 3, 5, 4)  is not 
because  3  appears  in  the  third position.  The  objective  of  this problem  is  to  count 
derangements. 

16.10.  INCLUSION-EXCLUSION 

375 

It  turns  out  to  be  easier  to  start  by  counting  the permutations  that  are  not de­
rangements.  Let Si  be  the  set  of  all permutations  (x1 , x2 , . . . , xn )  that  are  not de­
n
 
rangements because xi  = i.  So the set of non-derangements is 
Si . 
i=1 

(a)  What is |Si |? 
(b)  What is |Si  ∩ Sj | where i =�
j ? 
(c)  What is |Si1  ∩ Si2  ∩ · · · ∩ Sik | where i1 , i2 , . . . , ik  are all distinct? 
(d)  Use the inclusion-exclusion formula to express the number of non-derangements 
in terms of sizes of possible intersections of the sets S1 , . . . , Sn . 
(e)  How many terms in the expression in part (d) have the form |Si1  ∩ Si2  ∩ · · · ∩ Sik |? 
�
�
(f)  Combine  your  answers  to  the  preceding  parts  to  prove  the  number  of  non-
derangements is: 
1 
1 
1
1
n!
3! 
2! 
1! 
n! 
� 
Conclude that the number of derangements is 
n! 1 − 

− · · · ± 

+ · · · ± 

− 

+ 

+ 

.
� 
1 
. 
n! 

1
1! 

1
2! 

− 

1 
3! 

(g)  As n goes to inﬁnity, the number of derangements approaches a constant frac­
tion of all permutations. What is that constant? Hint: 

e x  = 1 + x + 

x2 
2! 

+ 

x3 
3! 

+ · · · 

Problem 16.26. 
How many of  the numbers 2, . . . , n are prime?  The  Inclusion-Exclusion Principle 
offers a useful way  to calculate  the answer when n  is  large.  Actually, we will use 
Inclusion-Exclusion  to  count  the  number  of  composite  (nonprime)  integers  from  2 
to n.  Subtracting this from n − 1 gives the number of primes. 
Let Cn  be  the  set of  composites  from 2  to n,  and  let Am  be  the  set of numbers 
in the range m + 1, . . . , n that are divisible by m. Notice that by deﬁnition, Am  = ∅
n−1
 
for m ≥ n.  So 
i=2 

Cn  = 
(a)  Verify that if m | k , then Am  ⊇ Ak . 

(16.13) 

Ai . 

376 

CHAPTER 16.  COUNTING 

(16.14) 


 
(b)  Explain why the right hand side of (16.13) equals 
Ap . 
primes p≤√
n 
(c)  Explain why |Am | = �n/m� − 1 for m ≥ 2. 
(d)  Consider any two relatively prime numbers p, q ≤ n. What is the one number 
in (Ap  ∩ Aq ) − Ap q ? 
·
������ 
������ 
(e)  Let P  be a ﬁnite set of at least two primes. Give a simple formula for 
� 
Ap  . 
p∈P 
(f)  Use  the  Inclusion-Exclusion  principle  to  obtain  a  formula  for  |C150 |  in  terms 
the sizes of intersections among the sets A2 , A3 , A5 , A7 , A11 .  (Omit the intersections 
that are empty; for example, any intersection of more than three of these sets must 
be empty.) 

(g)  Use this formula to ﬁnd the number of primes up to 150. 

16.11  Binomial Theorem 

Counting  gives  insight  into  one  of  the  basic  theorems  of  algebra.  A  binomial  is  a 
sum of two terms, such as a + b. Now consider its 4th power, (a + b)4 . 
If we multiply out this 4th power expression completely, we get 

(a + b)4  = 

aaaa  +  aaab  +  aaba  +  aabb 
+  abaa  +  abab  +  abba  +  abbb 
+  baaa  +  baab  +  baba  +  babb 
+  bbaa  +  bbab  +  bbba  +  bbbb 
Notice  that  there  is  one  term  for  every  sequence  of  a’s  and  b’s.  So  there  are  24 
�  � 
terms, and the number of terms with k copies of b and n − k copies of a is: 
n! 
n 
k ! (n − k)! 
k 
�  � 
by the Bookkeeper Rule. Now let’s group equivalent terms, such as aaab = aaba = 
� � 
� � 
� � 
� � 
� � 
abaa = baaa. Then the coefﬁcient of an−k bk  is  n
k  .  So for n = 4, this means: 
4
4
4
4
4
· 
· 
· 
· 
· 
a 0 b4 
a 1 b3  + 
a 2 b2  + 
a 3 b1  + 
4 b0  + 
a
0 
1
2
3
4 

= 

(a + b)4  = 

In general, this reasoning gives the Binomial Theorem: 

16.11.  BINOMIAL THEOREM 

377 

Theorem 16.11.1 (Binomial Theorem).  For all n ∈ N and a, b ∈ R: 
n � � 
� 
a n−k bk 
n
k 
k=0 

(a + b)n  = 

�  � 
n
k 

is often called a “binomial coefﬁcient”  in honor of  its ap­

The expression 
pearance here. 
This reasoning about binomials extends nicely to multinomials, which are sums 
of two or more terms.  For example, suppose we wanted the coefﬁcient of 

bo2k2 e 3 pr 

in the expansion of (b + o + k + e + p + r)10 . Each term in this expansion is a product 
of 10 variables where each variable is one of b, o, k , e, p, or r .  Now, the coefﬁcient 
of bo2k2 e3pr is the number of those terms with exactly 1 b, 2 o’s, 2 k ’s, 3 e’s, 1 p, and 
1 r . And the number of such terms is precisely the number of rearrangments of the 
� 
� 
word BOOKKEEPER: 
10 
1, 2, 2, 3, 1, 1 

10! 
.
1! 2! 2! 3! 1! 1! 

= 

The  expression  on  the  left  is  called  a  “multinomial  coefﬁcient.”  This  reasoning 
extends to a general theorem. 
Deﬁnition 16.11.2.  For n, k1 , . . . , km  ∈ naturals, such that k1  + k2  +
� 
� 
deﬁne the multinomial coefﬁcient 
n! 
n
::= 
. 
k1 ! k2 !  . . . km ! 
k1 , k2 , . . . , km 
� � 
� 
Theorem 16.11.3 (Multinomial Theorem).  For all n ∈ N and z1 , . . . zm  ∈ R: 
n 
2  · · ·  m 
z k1 z k2 
z km
1
k1 , k2 , . . . , km 
k1 ,...,km∈N 
···
k1 + +km =n

(z1  + z2  + · · · + zm

· · · 
+ km  = n,

)n  = 

You’ll be better off  remembering  the  reasoning behind  the Multinomial Theo­
rem rather than this ugly formal statement. 

16.11.1  Problems 
Practice Problems 

Problem 16.27. 
Find the coefﬁcients of x10 y5  in (19x + 4y)15 

378 

CHAPTER 16.  COUNTING 

Class Problems 

Problem 16.28. 
Find the coefﬁcients of 
(a)  x5  in (1 + x)11 

(b)  x8 y9  in (3x + 2y)17 

(c)  a6 b6  in (a2  + b3 )5 

Problem 16.29.  (a)  Use the Multinomial Theorem 16.11.3 to prove that 
· · · 
+ xn )p  ≡ x1 
· · · 
p  + x2 
p  +
p 
+ xn
(x1  + x2  +
� 
� 
for all primes p.  (Do not prove it using Fermat’s “little” Theorem. The point of this 
problem is to offer an independent proof of Fermat’s theorem.) 
p
Hint:  Explain why  k1 ,k2
is  divisible  by  p  if  all  the  ki ’s  are  positive  integers 
,...,kn 
less than p. 
(b)  Explain how (16.15) immediately proves Fermat’s Little Theorem 14.6.4: np−1  ≡
1  (mod  p) when n is not a multiple of p. 

(mod  p) 

(16.15)

Homework Problems 

Problem 16.30. 
The  degree  sequence  of  a  simple  graph  is  the  weakly  decreasing  sequence  of  de­
grees  of  its  vertices.  For  example,  the  degree  sequence  for  the  5-vertex  num­
bered  tree  pictured  in  the  Figure  16.2  is  (2, 2, 2, 1, 1)  and  for  the  7-vertex  tree  it 
is (3, 3, 2, 1, 1, 1, 1). 
We’re interested in counting how many numbered trees there are with a given 
degree sequence. We’ll do this using the bijection deﬁned in Problem 16.5 between 
n-vertex numbered trees and length n−2 code words whose characters are integers 
between 1 and n. 
The  occurrence  number  for  a  character  in  a  word  is  the  number  of  times  that 
the  character  occurs  in  the  word.  For  example,  in  the  word  65622,  the  occur­
rence number for 6 is two, and the occurrence number for 5 is one.  The occurrence 
sequence  of  a  word  is  the  weakly  decreasing  sequence  of  occurrence  numbers  of 
characters  in  the word.  The occurrence sequence  for  this word  is  (2, 2, 1) because 
it has two occurrences of each of the characters 6 and 2, and one occurrence of 5. 
(a)  There is simple relationship between the degree sequence of an n-vertex num­
bered tree and the occurrence sequence of its code.  Describe this relationship and 
explain  why  it  holds.  Conclude  that  counting  n-vertex  numbered  trees  with  a 
given  degree  sequence  is  the  same  as  counting  the  number  of  length  n − 2  code 
words with a given occurrence sequence. 
Hint: How many times does a vertex of degree, d, occur in the code? 

16.11.  BINOMIAL THEOREM 

379 

Coding Numbered Trees

Tree
Tree

2

3

2

6

5

4

4

5

7

Code

4 3 2

6 5 6 2 2

1

1

3

Figure 16.2: 

Image by MIT OpenCourseWare.

For  simplicity,  let’s  focus  on  counting  9-vertex  numbered  trees  with  a  given 
degree sequence.  By part  (a),  this  is  the same as counting  the number of  length 7 
code words with a given occurrence sequence. 
Any length 7 code word has a pattern, which is another length 7 word over the 
alphabet a,b,c,d,e,f,g that has the same occurrence sequence. 
(b)  How many length 7 patterns are there with three occurrences of a, two occur­
rences of b, and one occurrence of c and d? 
(c)  How many ways are there to assign occurrence numbers to integers 1, 2, . . . , 9 
so  that  a  code  word  with  those  occurrence  numbers  would  have  the  occurrence 
sequence 3, 2, 1, 1, 0, 0, 0, 0, 0? 
In general,  to ﬁnd  the pattern  of  a  code word,  list  its  characters  in decreasing  or­
der  by  number  of  occurrences,  and  list  characters  with  the  same  number  of  occur­
rences  in  decreasing  order.  Then  replace  successive  characters  in  the  list  by  suc­
cessive  letters  a,b,c,d,e,f,g.  The  code word  2468751,  for  example,  has  the 
pattern fecabdg, which  is obtained by replacing  its characters 8,7,6,5,4,2,1 
by a,b,c,d,e,f,g, respectively. The code word 2449249 has pattern caabcab, 
which is obtained by replacing its characters 4,9,2 by a,b,c, respectively. 

380 

CHAPTER 16.  COUNTING 

(d)  What length 7 code word has three occurrences of 7, two occurrences of 8, one 
occurrence each of 2 and 9, and pattern abacbad? 

(e)  Explain  why  the  number  of  9-vertex  numbered  trees  with  degree  sequence 
(4, 3, 2, 2, 1, 1, 1, 1, 1) is the product of the answers to parts (b) and (c). 

16.12  Combinatorial Proof 

Suppose you have n different T-shirts, but only want to keep k . You could equally 
well select the k  shirts you want to keep or select the complementary set of n − k 
shirts  you  want  to  throw  out.  Thus,  the  number  of  ways  to  select  k  shirts  from 
� � � 
� 
among n must be equal to the number of ways to select n − k shirts from among n. 
Therefore: 
n 
n
= 
n − k 
k
This is easy to prove algebraically, since both sides are equal to: 

n!

k ! (n − k)!


But we didn’t really have to resort to algebra; we just used counting principles. 
Hmm. 

16.12.1  Boxing 
Jay, famed 6.042 TA, has decided to try out for the US Olympic boxing team. After 
all, he’s watched all of the Rocky movies and spent hours in front of a mirror sneer­
ing,  “Yo,  you wanna  piece  a’ me?!”  Jay  ﬁgures  that  n  people  (including  himself) 
are competing for spots on the team and only k will be selected. As part of maneu­
vering for a spot on the team, he needs to work out how many different teams are 
possible. There are two cases to consider: 
•	 Jay is selected for the team, and his k − 1 teammates are selected from among 
the other n−1 competitors. The number of different teams that can be formed 
� 
� 
in this way is: 
n − 1 
k − 1 

•	 Jay  is  not  selected  for  the  team,  and  all  k  team  members  are  selected  from 
among the other n − 1 competitors. The number of teams that can be formed 
� 
� 
this way is: 
n − 1 
k 

16.12.  COMBINATORIAL PROOF 

381 

All  teams  of  the  ﬁrst  type  contain  Jay,  and  no  team  of  the  second  type  does; 
therefore, the two sets of teams are disjoint. Thus, by the Sum Rule, the total num­
� 
�  � 
� 
ber of possible Olympic boxing teams is: 
n − 1 
n − 1
+ 
k − 1 
k

Jeremy,  equally-famed  6.042  TA,  thinks  Jay  isn’t  so  tough  and  so  he might  as 
well also try out. He reasons that n people (including himself) are trying out for k 
�  � 
spots. Thus, the number of ways to select the team is simply: 
n 
k 
Jeremy  and  Jay  each  correctly  counted  the  number  of  possible  boxing  teams; 
� 
�  �  � 
�  � 
thus, their answers must be equal.  So we know: 
n − 1
n − 1
n
+ 
= 
k − 1 
k
k
This  is  called Pascal’s  Identity.  And we  proved  it without  any  algebra!  Instead, we 
relied purely on counting techniques. 

16.12.2  Finding a Combinatorial Proof 
A combinatorial proof  is an argument that establishes an algebraic fact by relying on 
counting principles. Many such proofs follow the same basic outline: 

1.  Deﬁne a set S . 
2.  Show that |S | = n by counting one way. 
3.  Show that |S | = m by counting another way. 
4.  Conclude that n = m. 

� 
� � 
� 
In the preceding example, S was the set of all possible Olympic boxing teams.  Jay 
computed 
n − 1 
n − 1 
+ 
k − 1
k 
�  � 
by counting one way, and Jeremy computed 
n 
k 

|S | = 

|S | = 

by counting another. Equating these two expressions gave Pascal’s Identity. 
More typically,  the set S  is deﬁned  in terms of simple sequences or sets rather 
than an elaborate story. Here is less colorful example of a combinatorial argument. 

382 

Theorem 16.12.1. 

CHAPTER 16.  COUNTING 
� � �
3n 
= 
n 

� �� 
n�  n 
2n 
n − r
r
r=0 
Proof.  We give  a  combinatorial proof.  Let S  be  all n-card hands  that  can be dealt 
from a deck containing n red cards (numbered 1, . . . , n) and 2n black cards (num­
� � 
bered 1, . . . , 2n).  First, note that every 3n-element set has 
3n 
|S | = 
n 
n-element subsets. 
�  �� 
� 
From another perspective, the number of hands with exactly r red cards is 
2n 
n 
� 
�  � 
� 
n − r 
r
since  there  are  n
2−n
r  ways  to  choose  the  r  red  cards  and  n
r  ways  to  choose  the 
n − r black cards.  Since the number of red cards can be anywhere from 0 to n, the 
n � �� 
�
�  n 
total number of n-card hands is: 
2n 
|S | = 
n − r 
r
r=0 
Equating these two expressions for |S | proves the theorem. 
� 
Combinatorial proofs  are  almost magical.  Theorem  16.12.1  looks pretty  scary, 
but we proved it without any algebraic manipulations at all. The key to construct­
� � 
ing a combinatorial proof is choosing the set S properly, which can be tricky. Gen­
erally, the simpler side of the equation should provide some guidance.  For exam­
n  , which suggests choosing S  to be all 
ple,  the  right  side of Theorem 16.12.1  is  3
n
n-element subsets of some 3n-element set. 

16.12.3  Problems 
Class Problems 

Problem 16.31. 
� 
�
According to the Multinomial theorem, (w + x + y + z )n  can be expressed as a sum 
of terms of the form 
n 
r1  r2  r3  r4
w x y z . 
r1 , r2 , r3 , r4 
(a)  How many terms are there in the sum? 
�
�
� 
(b)  The sum of these multinomial coefﬁcients has an easily expressed value. What 
is it? 
n 
r1 , r2 , r3 , r4 
r1+r2 +r3+r4=n, 
ri∈N 

(16.16) 

=? 

16.12.  COMBINATORIAL PROOF 

383 

Hint:  How many  terms are  there when (w + x + y + z )n  is expressed as a sum of 
monomials in w, x, y , z before terms with like powers of these variables are collected 
together under a single coefﬁcient? 

Homework Problems 

Problem 16.32. 
� �� �  � �� 
� 
Prove the following identity by algebraic manipulation and by giving a combina­
torial argument: 
n − k 
r 
n
n
= 
r − k 
k 
k
r
n � ��  n  = 2n . 
Problem 16.33.  (a)  Find a combinatorial (not algebraic) proof that 
i 
i=0 
(b)  Below is a combinatorial proof of an equation. What is the equation? 

Proof.  Stinky Peterson owns n newts,  t  toads,  and s  slugs.  Conveniently,  he  lives 
in  a  dorm  with  n +  t + s  other  students.  (The  students  are  distinguishable,  but 
creatures  of  the  same  variety  are  not  distinguishable.)  Stinky  wants  to  put  one 
creature in each neighbor ’s bed.  Let W  be the set of all ways in which this can be 
done. 
On one hand, he could ﬁrst determine who gets  the slugs.  Then, he could decide 
who among his remaining neighbors has earned a toad.  Therefore, |W | is equal to 
the expression on the left. 
On the other hand, Stinky could ﬁrst decide which people deserve newts and slugs 
and then, from among those, determine who truly merits a newt.  This shows that 
|W | is equal to the expression on the right. 
Since both expressions are equal to |W |, they must be equal to each other. 

� 

(Combinatorial  proofs  are  real  proofs.  They  are  not  only  rigorous,  but  also  con­
vey an intuitive understanding that a purely algebraic argument might not reveal. 
However, combinatorial proofs are usually less colorful than this one.) 

Problem 16.34. 
According to the Multinomial Theorem 16.11.3, (x1+x2+...+xk )n  can be expressed 
as a sum of terms of the form � 
� 
n 
2  ...x rk 
1  x r2 
x r1 
k  . 
r1 , r2 , ..., rk 

384 

CHAPTER 16.  COUNTING 

(a)  How many terms are there in the sum? 
� 
� 
� 
(b)  The sum of these multinomial coefﬁcients has an easily expressed value: 
n 
r1 , r2 ,  ...,  rk 
r1+r2+...+rk =n, 
ri∈N 

= kn 

(16.17) 

Give a combinatorial proof of this identity.

Hint: How many terms are there when (x1  + x2  + ... + xk )n  is expressed as a sum

of monomials  in  xi  before  terms with  like  powers  of  these  variables  are  collected

together under a single coefﬁcient?


Problem 16.35. 
Give combinatorial proofs of  the  identities below.  Use  the  following structure  for 
each  proof.  First,  deﬁne  an  appropriate  set  S .  Next,  show  that  the  left  side  of 
the  equation  counts  the  number  of  elements  in  S .  Then  show  that,  from  another 
perspective,  the  right  side  of  the  equation  also  counts  the  number  of  elements  in 
set S . Conclude that the left side must be equal to the right, since both are equal to 
|S
|. 
� � 
n � � � 
�
2n  �  n
(a)
n 
· 
= 
n − k 
k 
n
r �
� � 
�
k=0 
�  n + i
n + r + 1 
= 
r 
i
i=0 

(b) 

Hint:  consider a set of binary strings that could be counted using the right side of 
the equation, then try partitioning them into subsets countable by the elements of 
the sum on the left. 

Chapter 17 

Generating Functions 

Generating Functions are one of the most surprising and useful inventions in Dis­
crete  Math.  Roughly  speaking,  generating  functions  transform  problems  about 
sequences  into  problems  about  functions.  This  is  great  because  we’ve  got  piles  of 
mathematical machinery  for manipulating  functions.  Thanks  to generating  func­
tions, we can apply all  that machinery  to problems about sequences.  In  this way, 
we can use generating functions to solve all sorts of counting problems.  There is a 
huge chunk of mathematics concerning generating functions, so we will only get a 
taste of the subject. 
In this chapter, we’ll put sequences in angle brackets to more clearly distinguish 
them from the many other mathematical expressions ﬂoating around. 
The ordinary generating function for �g0 , g1 , g2 , g3  . . . � is the power series: 
G(x) = g0  + g1x + g2x 2  + g3x 3  + · · ·  . 
There are a  few other kinds of generating  functions  in common use, but ordinary 
generating  functions  are  enough  to  illustrate  the power of  the  idea,  so we’ll  stick 
to them.  So from now on generating function will mean the ordinary kind. 
A generating  function  is  a  “formal” power  series  in  the  sense  that we usually 
regard  x  as  a  placeholder  rather  than  a  number.  Only  in  rare  cases will we  actu­
ally  evaluate  a  generating  function  by  letting  x  take  a  real  number  value,  so  we 
generally ignore the issue of convergence. 
Throughout this chapter, we’ll indicate the correspondence between a sequence 
and its generating function with a double-sided arrow as follows: 
�g0 , g1 , g2 , g3 , . . . �  ←→  g0  + g1x + g2x 2  + g3x 3  + · · · 
For example, here are some sequences and their generating functions: 
�0, 0, 0, 0, . . . �  ←→  0 + 0x + 0x 2  + 0x 3  +  = 0 
· · · 
�1, 0, 0, 0, . . . �  ←→  1 + 0x + 0x 2  + 0x 3  +  = 1 
· · · 
�3, 2, 1, 0, . . . �  ←→  3 + 2x + 1x 2  + 0x 3  +  = 3 + 2x + x 2 
· · · 

385 

386 

CHAPTER 17.  GENERATING FUNCTIONS 

The  pattern  here  is  simple:  the  ith  term  in  the  sequence  (indexing  from  0)  is  the 
coefﬁcient of xi  in the generating function. 
Recall that the sum of an inﬁnite geometric series is: 

1 + z + z 2  + z 3  +

1
1 − z 
This equation does not hold when |z | ≥ 1, but as remarked, we don’t worry about 
convergence  issues.  This  formula  gives  closed  form  generating  functions  for  a 
whole range of sequences.  For example: 

· · · 

= 

�1, 1, 1, 1, . . . �  ←→  1 + x + x2  + x3  + · · · 

=

�1, −1, 1, −1, . . . �  ←→  1 − x + x2  − x3  + x4  − · · ·  = 
�
� 
1, a, a2 , a3 , . . . 

1 + ax + a2x2  + a3x3  +

←→ 

· · · 

= 

�1, 0, 1, 0, 1, 0, . . . �  ←→  1 + x2  + x4  + x6  + · · · 

=

1 
1 − x 
1 
1 + x 

1
1 − ax 
1 
1 − x2 

17.1  Operations on Generating Functions 

The  magic  of  generating  functions  is  that  we  can  carry  out  all  sorts  of  manipu­
lations  on  sequences  by  performing mathematical  operations  on  their  associated 
generating  functions.  Let’s  experiment with  various  operations  and  characterize 
their effects in terms of sequences. 

17.1.1  Scaling 
Multiplying a generating function by a constant scales every term in the associated 
sequence by the same constant.  For example, we noted above that: 

�1, 0, 1, 0, 1, 0, . . . �  ←→  1 + x 2  + x 4  + x 6  + · · · =

1 
1 − x2 

Multiplying the generating function by 2 gives 
2  = 2 + 2x 2  + 2x 4  + 2x 6  +
1 − x2 

· · · 

which generates the sequence: 

�2, 0, 2, 0, 2, 0, . . . � 

17.1.  OPERATIONS ON GENERATING FUNCTIONS 

387 

Rule 11 (Scaling Rule).  If 

�f0 , f1 , f2 , . . . �  ←→  F (x), 

then 

�cf0 ,  cf1 ,  cf2 ,  . . . �  ←→  c F (x).
· 
The idea behind this rule is that: 
�cf0 , cf1 , cf2 , . . . �  ←→ 
= 
= 

cf0  + cf1x + cf2x 2  + · · · 
· 
· · · 
c  (f0  + f1x + f2x 2  + )
cF (x) 

17.1.2  Addition 
Adding  generating  functions  corresponds  to  adding  the  two  sequences  term  by 
term.  For example, adding two of our earlier examples gives: 
�  1, 
�  ←→ 

. . . 

1, 

1, 

1, 

1, 

1, 

+  �  1,  −1,  1,  −1,  1,  −1, 

. . . 

�  ←→ 

1 
1 − x 
1 
1 + x 

1 
1
�  ←→ 
�  2, 
+ 
0, 
2, 
0, 
2, 
0, 
. . . 
1 − x 
1 + x 
We’ve now derived two different expressions that both generate the sequence �2, 0, 2, 0, . . . �. 
They are, of course, equal: 
1  =
1  + 
1 − x 
1 + x 
Rule 12 (Addition Rule).  If 
�f0 , f1 , f2 , . . . �  ←→  F (x), 
�g0 , g1 , g2 , . . . �  ←→  G(x), 

(1 + x) + (1 − x)
(1 − x)(1 + x)

2

1 − x2


and 

= 

then 

�f0  + g0 , f1  + g1 , f2  + g2 ,  . . . �  ←→  F (x) + G(x). 
� � 
The idea behind this rule is that: 
∞
�f0  + g0 , f1  + g1 , f2  + g2 ,  . . . �  ←→ 
� 
�  � 
(fn  + gn )x n 
� 
� 
n=0 
∞
∞
gnx n 
fnx n  + 
n=0 
n=0 
F (x) + G(x) 

= 

= 

388 

CHAPTER 17.  GENERATING FUNCTIONS 

17.1.3  Right Shifting 
Let’s start over again with a simple sequence and its generating function: 
�1, 1, 1, 1, . . . �  ←→ 

1 
1 − x 
Now let’s right-shift the sequence by adding k  leading zeros: 
�� 
� 
� 
�0, 0, . . . , 0, 1, 1, 1, . . . � 
←→ 
k zeroes 

· · · 
x k  + x k+1  + x k+2  + x k+3  + 

= 

= 

· 
· · · 
x k  (1 + x + x 2  + x 3  + )
kx
1 − x 
Evidently, adding k  leading zeros to the sequence corresponds to multiplying the 
generating function by xk . This holds true in general. 
Rule 13 (Right-Shift Rule).  If �f0 , f1 , f2 , . . . �  ←→  F (x), then: 
�� 
� 
� 
· 
�0, 0, . . . , 0, f0 , f1 , f2 , . . . �  ←→  x k  F (x)
k zeroes 
The idea behind this rule is that: 
� 
�� 
� 
k zeroes 
�0, 0, . . . , 0, f0 , f1 , f2 , . . . �  ←→ 
= 
= 

f0x k  + f1x k+1  + f2x k+2  + · · · 
· 
· · · 
x k  (f0  + f1x + f2x 2  + f3x 3  + )
· 
x k  F (x)

d
dx 

(1 + x + x 2  + x 3  + x 4  + · · · )

17.1.4  Differentiation 
What  happens  if we  take  the  derivative  of  a  generating  function?  As  an  example, 
let’s differentiate  the now-familiar generating  function  for an  inﬁnite sequence of 
� 
� 
1’s. 
1 
d 
dx  1 − x 
1
(1 − x)2 
1 
(1 − x)2 
We found a generating function for the sequence �1, 2, 3, 4, . . . � of positive integers! 
In  general,  differentiating  a  generating  function  has  two  effects  on  the  corre­
sponding sequence:  each term is multiplied by its index and the entire sequence is 
shifted left one place. 

�1, 2, 3, 4, . . . �  ←→ 

1 + 2x + 3x 2  + 4x 3  +

(17.1)

· · · 

= 

= 

17.1.  OPERATIONS ON GENERATING FUNCTIONS 

389 

Rule 14 (Derivative Rule).  If 
�f0 , f1 , f2 , f3 , . . . �  ←→  F (x), 

then 

�f1 , 2f2 , 3f3 , . . . �  ←→  F � (x). 
The idea behind this rule is that: 
�f1 , 2f2 , 3f3 , . . . �  ←→  f1  + 2f2x + 3f3x 2  + · · · 
d  (f0  + f1x + f2x 2  + f3x 3  + )
· · · 
= 
dx 
d = 
dx 

F (x)

The Derivative Rule is very useful.  In fact, there is frequent, independent need 
for each of differentiation’s two effects, multiplying terms by their index and left-
shifting one place. Typically, we want just one effect and must somehow cancel out 
the other.  For example, let’s try to ﬁnd the generating function for the sequence of 
squares,  �0, 1, 4, 9, 16, . . . �.  If we  could  start with  the  sequence  �1, 1, 1, 1, . . . �  and 
multiply each term by its index two times, then we’d have the desired result: 
�0 0,  1 1,  2 2,  3 3,  . . . � = �0, 1, 4, 9, . . . �
·
·
·
· 

A  challenge  is  that differentiation not  only multiplies  each  term  by  its  index,  but 
also shifts the whole sequence left one place. However, the Right-Shift Rule 13 tells 
how to cancel out this unwanted left-shift: multiply the generating function by x. 
Our procedure, therefore, is to begin with the generating function for �1, 1, 1, 1, . . . �, 
differentiate, multiply by x, and then differentiate and multiply by x once more. 

= 

�1, 1, 1, 1, . . . �  ←→ 
�1, 2, 3, 4, . . . �  ←→ 

1 
1 − x 
1 
1
d 
dx  1 − x 
(1 − x)2 
1 
x 
�0, 1, 2, 3, . . . �  ←→  x · 
(1 − x)2  = 
(1 − x)2 
1 + x 
x 
d
dx  (1 − x)2  = 
(1 − x)3 
1 + x
x(1 + x) 
�0, 1, 4, 9, . . . �  ←→  x · 
(1 − x)3  = 
(1 − x)3 

�1, 4, 9, 16, . . . �  ←→ 

Thus, the generating function for squares is: 

x(1 + x) 
(1 − x)3 

(17.2) 

390 

CHAPTER 17.  GENERATING FUNCTIONS 

17.1.5  Products 
Rule 15 ( Product Rule).  If 
�a0 , a1 , a2 , . . . �  ←→  A(x), 

and 

�b0 , b1 , b2 , . . . �  ←→  B (x), 

then 

�c0 , c1 , c2 ,  . . . �  ←→  A(x)  B (x),
· 

where 

· · · 
+ an b0 .

cn  ::= a0 bn  + a1 bn−1  + a2 bn−2  +
� 
To understand this rule, let 
∞
cnx n .
n=0 
· 
We  can  evaluate  the  product  A(x)  B (x)  by  using  a  table  to  identify  all  the 
cross-terms from the product of the sums: 

· 
C (x) ::= A(x)  B (x) = 

b0x0 

b1x1 

b2x2 

b3x3 

a0x0 

a0 b0x0 

a0 b1x1 

a0 b2x2 

a0 b3x3 

a1x1 

a1 b0x1 

a1 b1x2 

a1 b2x3 

. . . 

. . . 

. . . 

a2x2 

a2 b0x2 

a2 b1x3 

. . . 

a3x3 

a3 b0x3 

. . . 

. . . 

. . . 
Notice  that  all  terms  involving  the  same  power  of  x  lie  on  a  /-sloped  diagonal. 
Collecting these terms together, we ﬁnd that the coefﬁcient of xn  in the product is 
the sum of all the terms on the (n + 1)st diagonal, namely, 
· · · 

a0 bn  + a1 bn−1  + a2 bn−2  +

+ an b0 . 

(17.3)

This  expression  (17.3)  may  be  familiar  from  a  signal  processing  course;  the  se­
quence �c0 , c1 , c2 , . . . � is called the convolution of sequences �a0 , a1 , a2 , . . . � and �b0 , b1 , b2 , . . . �. 

17.2  The Fibonacci Sequence 

Sometimes we can ﬁnd nice generating functions for more complicated sequences. 
For example, here is a generating function for the Fibonacci numbers: 
x 
�0, 1, 1, 2, 3, 5, 8, 13, 21, . . . �  ←→ 
1 − x − x2 

17.2.  THE FIBONACCI SEQUENCE 

391 

The  Fibonacci  numbers  may  seem  like  a  fairly  nasty  bunch,  but  the  generating 
function is simple! 
We’re going  to derive  this generating  function and  then use  it  to ﬁnd a closed 
form  for  the  nth  Fibonacci  number.  The  techniques we’ll  use  are  applicable  to  a 
large class of recurrence equations. 

17.2.1  Finding a Generating Function 
Let’s begin by recalling the deﬁnition of the Fibonacci numbers: 

f0  = 0 
f1  = 1 
fn  = fn−1  + fn−2 

(for n ≥ 2) 
We  can  expand  the  ﬁnal  clause  into  an  inﬁnite  sequence  of  equations.  Thus,  the 
Fibonacci numbers are deﬁned by: 

f0  =0 
f1  =1 
f2  =f1  + f0 
f3  =f2  + f1 
f4  =f3  + f2 
. . . 
Now the overall plan is to deﬁne a function F (x) that generates the sequence on 
the  left  side  of  the  equality  symbols, which  are  the  Fibonacci  numbers.  Then we 
derive a  function  that generates  the sequence on  the right side.  Finally, we equate 
the two and solve for F (x). Let’s try this.  First, we deﬁne: 
F (x) = f0  + f1x + f2x 2  + f3x 3  + f4x 4  + · · · 
Now we need to derive a generating function for the sequence: 
�0,  1, f1  + f0 , f2  + f1 , f3  + f2 ,  . . . � 
One  approach  is  to  break  this  into  a  sum  of  three  sequences  for which we  know 
generating functions and then apply the Addition Rule: 
�  ←→  x 
�  0, 
1, 
�  ←→  xF (x) 
�  0,
f0 ,
�  ←→  x2F (x) 
�  0, 
0,
�  ←→  x + xF (x) + x2F (x) 
�  0,  1 + f0 ,
This sequence is almost identical to the right sides of the Fibonacci equations.  The 
one  blemish  is  that  the  second  term  is  1 + f0  instead  of  simply  1.  However,  this 
amounts to nothing, since f0  = 0 anyway. 

0, 
f3 , 
f2 , 
f3  + f2 , 

. . . 
. . . 
. . . 
. . . 

+	

0, 
f1 ,
f0 ,
f1  + f0 ,

0, 
f2 ,
f1 ,
f2  + f1 ,

392 

CHAPTER 17.  GENERATING FUNCTIONS 

Now if we equate F (x) with the new function x + xF (x) + x2F (x), then we’re 
implicitly writing down  all of  the  equations  that deﬁne  the Fibonacci numbers  in 
one fell swoop: 

x3  + · · · 
=  f0  + 
F (x)
x + 
x2  + 
f3 
f2 
f1 
� 
� 
� 
� 
� 
x + xF (x) + x2F (x)  =  0  + (1 + f0 ) x + (f1  + f0 ) x2  + (f2  + f1 ) x3  + · · · 

Solving for F (x) gives the generating function for the Fibonacci sequence: 

F (x) = x + xF (x) + x 2F (x) 

so 

x 
1 − x − x2 
.
Sure enough, this is the simple generating function we claimed at the outset. 

F (x) = 

17.2.2  Finding a Closed Form 
Why should one care about the generating function for a sequence? There are sev­
eral answers, but here  is one:  if we can ﬁnd a generating function for a sequence, 
then we can often ﬁnd a closed form for the nth coefﬁcient— which can be pretty 
useful!  For example, a closed form for the coefﬁcient of x in the power series for 
n
x/(1 − x − x2 ) would be an explicit formula for the nth Fibonacci number. 
So our next task is to extract coefﬁcients from a generating function.  There are 
several  approaches.  For  a  generating  function  that  is  a  ratio  of  polynomials,  we 
can use  the method  of  partial  fractions, which  you  learned  in  calculus.  Just  as  the 
terms in a partial fraction expansion are easier to integrate, the coefﬁcients of those 
terms are easy to compute. 
Let’s  try  this  approach  with  the  generating  function  for  Fibonacci  numbers. 
First, we factor the denominator: 
1 − x − x 2  = (1 − α1x)(1 − α2x) 
5) and α2  =  1 (1 − √
5). Next, we ﬁnd A1  and A2  which satisfy: 
2 
A2 
A1 
x
1 − α2x 
1 − α1x 
1 − x − x2 
We  do  this  by  plugging  in  various  values  of  x  to  generate  linear  equations  in A1 
and A2 . We can then ﬁnd A1  and A2  by solving a linear system. This gives: 

√
where α1  =  1 (1 + 
2

+

=

A1  =

A2  = 

1 
1
√
= 
α1  − α2 
5 
−
= − √1
1 
− 
5 
α1 
α2 

17.2.  THE FIBONACCI SEQUENCE 

393 

� 
�
Substituting  into  the  equation  above  gives  the  partial  fractions  expansion  of 
F (x): 
1 
1
1 
x 
1 − x − x2  =  √
1 − α2x 
1 − α1x 
5
Each term in the partial fractions expansion has a simple power series given by the 
geometric sum formula: 

− 

1 
1x 2  + · · · 
= 1 + α1x + α2
1 − α1x 
1 
2x 2  + · · · 
= 1 + α2x + α2
1 − α2x 
� 
� 
Substituting in these series gives a power series for the generating function: 
1
1 
1 
F (x) =  √
1  �
� 
1 − α2x 
1 − α1x 
5
=  √
1x 2  + · · · ) − (1 + α2x + α2
2x 2  + · · · )  , 
(1 + α1x + α2
5 

− 

so 

1  − α2 
�� 
αn 
n 
fn  =  √
5 
√
1 + 
2 

1 
=  √
5

�
n
5 

� 
� � 
1 − √
n
5 
− 
2 

This  formula  may  be  scary  and  astonishing  —it’s  not  even  obvious  that  its 
value  is  an  integer  —but  it’s  very  useful.  For  example,  it  provides  (via  the  re­
peated  squaring method)  a much more  efﬁcient way  to  compute  Fibonacci  num­
bers  than  crunching  through  the  recurrence,  and  it  also  clearly  reveals  the  expo­
nential growth of these numbers. 

17.2.3  Problems 
Class Problems 

Problem 17.1. 
The famous mathematician, Fibonacci, has decided to start a rabbit farm to ﬁll up 
his time while he’s not making new sequences to torment future college students. 
Fibonacci  starts his  farm on month zero  (being a mathematician),  and at  the  start 
of month one he receives his ﬁrst pair of rabbits. Each pair of rabbits takes a month 
to mature,  and  after  that  breeds  to  produce  one  new  pair  of  rabbits  each month. 
Fibonacci decides that in order never to run out of rabbits or money, every time a 
batch of new rabbits is born, he’ll sell a number of newborn pairs equal to the total 
number of pairs he had three months earlier.  Fibonacci is convinced that this way 
he’ll never run out of stock. 

394 

CHAPTER 17.  GENERATING FUNCTIONS 

(a)  Deﬁne  the  number,  rn ,  of  pairs  of  rabbits  Fibonacci  has  in month  n,  using  a 
recurrence relation. That is, deﬁne rn  in terms of various ri  where i < n. 

(b)  Let R(x) be the generating function for rabbit pairs, 
R(x) ::= r0  + r1x + r2x 2  + ·. 
Express R(x) as a quotient of polynomials. 

(c)  Find a partial fraction decomposition of the generating function R(x). 

(d)  Finally, use the partial fraction decomposition to come up with a closed form 
expression for  the number of pairs of rabbits Fibonacci has on his farm on month 
n. 

Problem 17.2. 
Less well-known than the Towers of Hanoi —but no less fascinating —are the Tow­
ers  of  Sheboygan.  As  in Hanoi,  the  puzzle  in  Sheboygan  involves  3  posts  and  n 
disks of different sizes.  Initially, all the disks are on post #1: 

Post #1 

Post #2 

Post #3 

The  objective  is  to  transfer  all  n  disks  to  post  #2  via  a  sequence  of moves.  A 
move  consists  of  removing  the  top  disk  from  one  post  and  dropping  it  onto  an­
other post with the restriction that a larger disk can never lie above a smaller disk. 
Furthermore,  a  local ordinance  requires  that  a disk  can  be moved  only  from  a post  to 
the  next  post  on  its  right —or  from  post  #3  to  post  #1.  Thus,  for  example,  moving  a 
disk directly from post #1 to post #3 is not permitted. 
(a)  One  procedure  that  solves  the  Sheboygan  puzzle  is  deﬁned  recursively:  to 
move an initial stack of n disks to the next post, move the top stack of n − 1 disks 
to the furthest post by moving it to the next post two times, then move the big, nth 
disk to the next post, and ﬁnally move the top stack another two times to land on 
top of the big disk.  Let sn  be the number of moves that this procedure uses. Write 
a simple linear recurrence for sn . 
(b)  Let S (x) be the generating function for the sequence �s0 , s1 , s2 , . . . �. Show that 
S (x) is a quotient of polynomials. 

17.2.  THE FIBONACCI SEQUENCE 

395 

(c)  Give a simple formula for sn . 

(d)  A  better  (indeed  optimal,  but  we  won’t  prove  this)  procedure  to  solve  the 
Towers  of  Sheboygan  puzzle  can  be  deﬁned  in  terms  of  two  mutually  recursive 
procedures,  procedure  P1 (n)  for  moving  a  stack  of  n  disks  1  pole  forward,  and 
P2 (n)  for moving a stack of n disks 2 poles  forward.  This  is  trivial  for n  = 0.  For 
n > 0, deﬁne: 
P1 (n): Apply P2 (n − 1) to move the top n − 1 disks two poles forward to the third 
pole.  Then move  the  remaining  big  disk  once  to  land  on  the  second  pole.  Then 
apply P2 (n − 1) again to move the stack of n − 1 disks two poles forward from the 
third pole to land on top of the big disk. 
P2 (n):  Apply  P2 (n − 1)  to  move  the  top  n − 1  disks  two  poles  forward  to  land 
on  the  third  pole.  Then  move  the  remaining  big  disk  to  the  second  pole.  Then 
apply P1 (n − 1)  to move  the stack of n − 1 disks one pole  forward  to  land on  the 
ﬁrst pole.  Now move  the big disk 1 pole  forward again  to  land on  the  third pole. 
Finally, apply P2 (n − 1) again to move the stack of n − 1 disks two poles forward 
to land on the big disk. 
Let tn  be the number of moves needed to solve the Sheboygan puzzle using proce­
dure P1 (n).  Show that 

tn  = 2tn−1  + 2tn−2  + 3, 

(17.4) 

for n > 1. 
Hint:  Let sn  be the number of moves used by procedure P2 (n).  Express each of tn 
and sn  as linear combinations of tn−1  and sn−1  and solve for tn . 

(e)  Derive values a, b, c, α, β  such that 

tn  = aαn  + bβ n  + c. 

Conclude that tn  = o(sn ). 

Homework Problems 

Problem 17.3. 
Taking derivatives of generating functions is another useful operation. This is done 
termwise, that is, if 

F (x) = f0  + f1x + f2x 2  + f3x 3  + · · ·  , 

then 

For example, 

F � (x) ::= f1  + 2f2x + 3f3x 2  + · · ·  . 
�
� 
� 
1 
(1 − x) 

= 1 + 2x + 3x 2  +

1
(1 − x)2 

= 

· · · 

396 

CHAPTER 17.  GENERATING FUNCTIONS 

so 

H (x) ::= 

= 0 + 1x + 2x 2  + 3x 3  +

x 
(1 − x)2 
is the generating function for the sequence of nonegative integers. Therefore 
1 + x 
(1 − x)3  = H � (x) = 1 + 22 x + 32 x 2  + 42 x 3  + · · ·  , 

· · · 

so 

x2  + x 
(1 − x)3  = xH � (x) = 0 + 1x + 22 x 2  + 32 x 3  + · · · + n 2 x n  + · · · 
is the generating function for the nonegative integer squares. 
(a)  Prove  that  for  all  k  ∈  N,  the  generating  function  for  the nonnegative  integer 
kth  powers  is  a  quotient  of  polynomials  in  x.  That  is,  for  all  k  ∈  N  there  are 
� 
� 
polynomials Rk (x) and Sk (x) such that 
Rk (x) 
Sk (x) 

= n . 
k

(17.5)

[x n ]

Hint: Observe that the derivative of a quotient of polynomials is also a quotient of 
polynomials.  It is not necessary work out explicit formulas for Rk  and Sk  to prove 
this part. 

(b)  Conclude that if f (n) is a function on the nonnegative integers deﬁned recur­
sively in the form 
f (n) = af (n − 1) + bf (n − 2) + cf (n − 3) + p(n)αn 
where  the  a, b, c, α  ∈  C  and  p  is  a polynomial with  complex  coefﬁcients,  then  the 
generating function for the sequence f (0), f (1), f (2), . . .  will be a quotient of poly­
nomials in x, and hence there is a closed form expression for f (n). 
Hint: Consider 

Rk (αx) 
Sk (αx) 

Problem 17.4. 
Generating functions provide an interesting way to count the number of strings of 
matched  parentheses.  To  do  this,  we’ll  use  the  description  of  these  strings  given 
in Deﬁnition  11.1.2  as  the  set,  GoodCount,  of  strings  of  parentheses with  a  good 
count.  Let cn  be the number of strings in GoodCount with exactly n left parenthe­
ses, and let C (x) be the generating function for these numbers: 
C (x) ::= c0  + c1x + c2x 2  + · · ·  . 

17.2.  THE FIBONACCI SEQUENCE 

397 

(a)  The  wrap  of  a  string,  s,  is  the  string,  (s),  that  starts  with  a  left  parenthesis 
followed  by  the  characters  of  s,  and  then  ends with  a  right  parenthesis.  Explain 
why the generating function for the wraps of strings with a good count is xC (x). 
Hint:  The wrap of a  string with good  count also has a good  count  that  starts and 
ends with 0 and remains positive everywhere else. 

(b)  Explain why, for every string, s, with a good count, there is a unique sequence 
s1  · · · 
of  strings  s1 , . . . , sk  that  are wraps  of  strings with  good  counts  and  s  = 
sk .
For  example,  the  string  r  ::= (())()(()())  ∈  GoodCount  equals  s1 s2 s3  where  s1  = 
(()), s2  =  (), s3  =  (()()),  and  this  is  the  only  way  to  express  r  as  a  sequence  of 
wraps of strings with good counts. 

(17.6) 

(17.7)

(17.8)

(17.9)

(c)  Conclude that 

so 

and hence 

C  = 1 + xC + (xC )2  + · · · + (xC )n  + · · ·  , 

, 

1 
C  = 
1 − xC 
1 ± √
1 − 4x 
2x 

C  = 

. 

Let D(x) ::= 2xC (x). Expressing D as a power series 
D(x) = d0  + d1x + d2x 2  + · · ·  , 

we have 

dn+1 . 
2 
(d)  Use (17.12), (17.13), and the value of c0  to conclude that 
D(x) = 1 − √
1 − 4x. 

cn  = 

(e)  Prove that 

dn  = 

(2n − 3) · (2n − 5) · · · 5 · 3 · 1 · 2n 
. 
n! 

Hint:  dn  = D(n) (0)/n! 

(f)  Conclude that 

� �
2n 
1
n + 1  n 

. 

cn  = 

398 

CHAPTER 17.  GENERATING FUNCTIONS 

Exam Problems 

Problem 17.5. 
Deﬁne the sequence r0 , r1 , r2 , . . .  recursively by the rule that r0  = r1  = 0 and 

rn  = 7rn−1  + 4rn−2  + (n + 1), 
for n  ≥  2.  Express  the generating  function of  this sequence as a quotient of poly­
nomials  or  products  of  polynomials.  You  do  not  have  to  ﬁnd  a  closed  form  for 
rn . 

17.3  Counting with Generating Functions 

Generating functions are particularly useful for solving counting problems.  In par­
ticular, problems involving choosing items from a set often lead to nice generating 
functions by letting the coefﬁcient of xn  be the number of ways to choose n items. 

17.3.1  Choosing Distinct Items from a Set 
� � 
� �  � � 
�� � � � � � 
� � 
� � 
� 
The  generating  function  for  binomial  coefﬁcients  follows  directly  from  the  Bino­
mial Theorem: 
k 
k 
k 
←→ 
· · · 
k
k
k
k
k
x 2  +
x k 
+ 
, 0, 0, 0, . . . 
+ 
x + 
, 
, 
, . . . , 
0
1
2 
0
1 
2 
k 
k 
� � 
(1 + x)k 
= 
� � 
Thus, the coefﬁcient of xn  in (1 + x)k  is  k  , the number of ways to choose n dis­
n 
tinct items from a set of size k . For example, the coefﬁcient of x2  is  k 
2  , the number 
of ways  to choose 2  items  from a  set with k  elements.  Similarly,  the coefﬁcient of 
xk+1  is the number of ways to choose k + 1 items from a size k  set, which is zero. 
(Watch  out  for  this  reversal  of  the  roles  that  k  and  n  played  in  earlier  examples; 
we’re led to this reversal because we’ve been using n to refer to the power of x in 
a power series.) 

17.3.2  Building Generating Functions that Count 
Often we  can  translate  the description  of  a  counting problem directly  into  a  gen­
erating  function  for  the  solution.  For  example, we  could  ﬁgure  out  that  (1 + x)k 
generates the number of ways to select n distinct items from a k-element set with­
out resorting to the Binomial Theorem or even fussing with binomial coefﬁcients! 
Here is how.  First, consider a single-element set {a1 }.  The generating function 
for the number of ways to select n elements from this set is simply 1 + x: we have 1 
way to select zero elements, 1 way to select one element, and 0 ways to select more 
than one element.  Similarly, the number of ways to select n elements from the set 
{a2 } is also given by the generating function 1 + x. The fact that the elements differ 
in the two cases is irrelevant. 

17.3.  COUNTING WITH GENERATING FUNCTIONS 

399 

· 

= 

= 1 + 2x + x 2 

= 

Now  here  is  the main  trick:  the  generating  function  for  choosing  elements  from  a 
union of disjoint sets is the product of the generating functions for choosing from each set. 
We’ll justify this in a moment, but let’s ﬁrst look at an example.  According to this 
principle, the generating function for the number of ways to select n elements from 
the {a1 , a2 } is: 
� �� � 
�  ��  � 
� �� � 
(1 + x)2 
(1 + x) 
(1 + x) 
gen func for

gen func for 
gen func for 
selecting an a2 
selecting from

selecting an a1 
{a1 , a2 }

Sure enough, for the set {a1 , a2 }, we have 1 way to select zero elements, 2 ways to 
select  one  element,  1 way  to  select  two  elements,  and  0 ways  to  select more  than 
two elements. 
Repeated  application  of  this  rule gives  the  generating  function  for  selecting n 
items from a k-element set {a1 , a2 , . . . , ak }: 
� �� � 
� �� � 
�  ��  � 
� ��  � 
· 
· · · 
(1 + x)k 
(1 + x) 
(1 + x) 
(1 + x) 
gen func for 
gen func for 
gen func for 
gen func for 
selecting from 
selecting an ak 
selecting an a2 
selecting an a1 
{a1 , a2 , . . . , ak } 
This is the same generating function that we obtained by using the Binomial Theo­
rem. But this time around we translated directly from the counting problem to the 
generating function. 
We can extend these ideas to a general principle: 
Rule  16  (Convolution  Rule).  Let  A(x)  be  the  generating  function  for  selecting  items 
from  set A,  and  let B (x)  be  the  generating  function  for  selecting  items  from  set B .  If A
and B  are disjoint, then the generating function for selecting items from the union A ∪ B 
· 
is the product A(x)  B (x).
This  rule  is  rather ambiguous:  what  exactly are  the  rules governing  the  selec­
tion of  items  from  a  set?  Remarkably,  the Convolution Rule  remains valid under 
many  interpretations of selection.  For example, we could  insist  that distinct  items 
be  selected  or  we  might  allow  the  same  item  to  be  picked  a  limited  number  of 
times or any number of  times.  Informally,  the only restrictions are  that  (1)  the or­
der in which items are selected is disregarded and (2) restrictions on the selection 
of  items  from  sets A  and  B  also  apply  in  selecting  items  from A ∪ B .  (Formally, 
there  must  be  a  bijection  between  n-element  selections  from  A ∪ B  and  ordered 
pairs of selections from A and B containing a total of n elements.) 
To count the number of ways to select n items from A ∪ B , we observe that we 
can select n  items by choosing j  items from A and n − j  items from B , where j  is 
any number  from 0  to n.  This can be done  in aj bn−j  ways.  Summing over all  the 
possible values of j  gives a total of 
a0 bn  + a1 bn−1  + a2 bn−2  +

· · · 
+ an b0

400 

CHAPTER 17.  GENERATING FUNCTIONS 

ways to select n items from A ∪ B . By the Product Rule, this is precisely the coefﬁ­
cient of xn  in the series for A(x)B (x). 

17.3.3  Choosing Items with Repetition 
The  ﬁrst  counting  problem  we  considered  was  the  number  of  ways  to  select  a 
dozen doughnuts when ﬁve ﬂavors were  available.  We  can  generalize  this ques­
tion  as  follows:  in  how many ways  can we  select  n  items  from  a  k-element  set  if 
we’re allowed to pick the same item multiple times?  In these terms, the doughnut 
problem asks  in how many ways we can select n  =  12 doughnuts  from  the set of 
k = 5 ﬂavors 
{chocolate, lemon-ﬁlled, sugar, glazed, plain} 
where, of course, we’re allowed to pick several doughnuts of the same ﬂavor. Let’s 
approach this question from a generating functions perspective. 
Suppose we make n choices  (with repetition allowed) of  items  from a set con­
taining  a  single  item.  Then  there  is  one  way  to  choose  zero  items,  one  way  to 
choose one item, one way to choose two items, etc.  Thus, the generating function 
for choosing n elements with repetition from a 1-element set is: 
1 + x + x 2  + x 3  + · · · 
�1, 1, 1, 1, . . . �  ←→ 
1 
= 
1 − x 
The Convolution Rule says that the generating function for selecting items from 
a union of disjoint sets is the product of the generating functions for selecting items 
from each set: 
� �� � 
� �� � 
� �� � 
�  ��  � 
1 
1 
1
1
(1 − x)k 
1 − x 
1 − x 
1 − x 
gen func for 
gen func for 
gen func for 
gen func for 
choosing ak ’s 
choosing a2 ’s 
choosing a1 ’s 
repeated choice from 
{a1 , a2 , . . . , ak } 

· · · 

· 

= 

Therefore,  the  generating  function  for  choosing  items  from  a  k-element  set  with 
repetition allowed is 1/(1 − x)k . 
Now  the Bookkeeper Rule  tells us  that  the number of ways  to  choose n  items 
� 
� 
with repetition from an k element set is 
n + k − 1 
, 
n 
so this is the coefﬁcient of xn  in the series expansion of 1/(1 − x)k . 
On the other hand, it’s instructive to derive this coefﬁcient algebraically, which 
we can do using Taylor ’s Theorem: 

17.3.  COUNTING WITH GENERATING FUNCTIONS 

401 

f (x) = f (0) + f � (0)x + 

Theorem 17.3.1 (Taylor ’s Theorem). 
f ���
f ��
(0) 
(0) 
(0) 
)
f (n
x 3  + · · · + 
x n  + · · ·  . 
x 2  + 
!
3!
2!
n
This theorem says that the nth coefﬁcient of 1/(1 − x)k  is equal to its nth deriva­
tive evaluated at 0 and divided by n!.  Computing the nth derivative turns out not 
to be very difﬁcult (Problem 17.7). 

17.3.4  Problems 
Practice Problems 

Problem 17.6. 
You would  like  to  buy  a  bouquet  of  ﬂowers.  You  ﬁnd  an  online  service  that will 
make bouquets of lilies, roses and tulips, subject to the following constraints: 

•  there must be at most 3 lilies, 

•  there must be an odd number of tulips, 

•  there can be any number of roses. 

Example: A bouquet of 3 tulips, 5 roses and no lilies satisﬁes the constraints. 
Let fn  be the number of possible bouquets with n ﬂowers that ﬁt the service’s 
constraints. Express F (x), the generating function corresponding to �f0 , f1 , f2 , . . . �, 
as a quotient of polynomials (or products of polynomials). You do not need to sim­
plify this expression. 

Class Problems 
�
Problem 17.7. 
∞ 
Let A(x) = 
n=0 anxn . Then it’s easy to check that 

A(n) (0) 
, 
n! 
where A(n)  is the nth derivative of A. Use this fact (which you may assume) instead 
∞ � 
n + k − 1� 
� 
of the Convolution Counting Principle, to prove that 
n
x . 
k − 1 
n=0 

1 
(1 − x)k 

an  = 

= 

So  if  we  didn’t  already  know  the  Bookkeeper  Rule,  we  could  have  proved  it 
from this calculation and the Convolution Rule for generating functions. 

402 

CHAPTER 17.  GENERATING FUNCTIONS 

Problem 17.8. 
We are interested in generating functions for the number of different ways to com­
pose a bag of n donuts  subject  to various  restrictions.  For each of  the  restrictions 
in (a)-(e) below, ﬁnd a closed form for the corresponding generating function. 
(a)  All the donuts are chocolate and there are at least 3. 

(b)  All the donuts are glazed and there are at most 2. 

(c)  All the donuts are coconut and there are exactly 2 or there are none. 

(d)  All the donuts are plain and their number is a multiple of 4. 

(e)  The donuts must be chocolate, glazed, coconut, or plain and: 

•  there must be at least 3 chocolate donuts, and 
•  there must be at most 2 glazed, and 
•  there must be exactly 0 or 2 coconut, and 
•  there must be a multiple of 4 plain. 

(f)  Find  a  closed  form  for  the  number  of ways  to  select  n  donuts  subject  to  the 
constraints of the previous part. 

Problem 17.9.  (a)  Let 

S (x) ::= 

x2  + x 
(1 − x)3 
.
What is the coefﬁcient of xn  in the generating function series for S (x)? 
�
(b)  Explain why S (x)/(1 − x) is the generating function for the sums of squares. 
That is, the coefﬁcient of xn  in the series for S (x)/(1 − x) is 
n  k2 .
k=1 
n� 
(c)  Use the previous parts to prove that 
k2  = 
k=1 

n(n + 1)(2n + 1) 
. 
6 

Homework Problems 

Problem 17.10. 
We  will  use  generating  functions  to  determine  how  many  ways  there  are  to  use 
pennies, nickels, dimes, quarters, and half-dollars to give n cents change. 
(a)  Write the sequence Pn  for the number of ways to use only pennies to change 
n cents. Write the generating function for that sequence. 

(b)  Write the sequence Nn  for the number of ways to use only nickels to change n 
cents. Write the generating function for that sequence. 

17.4.  AN “IMPOSSIBLE” COUNTING PROBLEM 

403 

(c)  Write the generating function for the number of ways to use only nickels and 
pennies to change n cents. 

(d)  Write the generating function for the number of ways to use pennies, nickels, 
dimes, quarters, and half-dollars to give n cents change. 

(e)  Explain  how  to  use  this  function  to  ﬁnd  out  how  many  ways  are  there  to 
change  50  cents;  you do  not have  to provide  the  answer  or  actually  carry  out  the 
process. 

Exam Problems 

Problem 17.11. 
The  working  days  in  the  next  year  can  be  numbered  1,  2,  3,  . . . ,  300.  I’d  like  to 
avoid as many as possible. 

•	 On even-numbered days, I’ll say I’m sick. 

•	 On days that are a multiple of 3, I’ll say I was stuck in trafﬁc. 

•	 On days that are a multiple of 5, I’ll refuse to come out from under the blan­
kets. 

In total, how many work days will I avoid in the coming year? 

Problem 17.12. 
Deﬁne the sequence r0 , r1 , r2 , . . .  recursively by the rule that r0  = r1  = 0 and 

rn  = 7rn−1  + 4rn−2  + (n + 1), 
for n  ≥  2.  Express  the generating  function of  this sequence as a quotient of poly­
nomials  or  products  of  polynomials.  You  do  not  have  to  ﬁnd  a  closed  form  for 
rn . 

Problem 17.13. 
Find the coefﬁcients of x10 y5  in (19x + 4y)15 

17.4  An “Impossible” Counting Problem 

So  far  everything we’ve done with  generating  functions we  could have done  an­
other way.  But here  is an absurd counting problem— really over  the  top!  In how 
many ways can we ﬁll a bag with n fruits subject to the following constraints? 

•	 The number of apples must be even. 

404 

CHAPTER 17.  GENERATING FUNCTIONS 

•  The number of bananas must be a multiple of 5. 

•  There can be at most four oranges. 

•  There can be at most one pear.


For example, there are 7 ways to form a bag with 6 fruits:

6  4  4  2  2  0  0 
Apples 
Bananas  0  0  0  0  0  5  5 
Oranges  0  2  1  4  3  1  0 
0  0  1  0  1  0  1 
Pears 

These  constraints  are  so  complicated  that  the  problem  seems  hopeless!  But  let’s 
see what generating functions reveal. 
Let’s ﬁrst construct a generating function for choosing apples. We can choose a 
set of 0 apples in one way, a set of 1 apple in zero ways (since the number of apples 
must be even), a set of 2 apples  in one way, a set of 3 apples  in zero ways, and so 
forth.  So we have: 

· · · 

A(x) = 1 + x 2  + x 4  + x 6  +

1 
1 − x2 
Similarly, the generating function for choosing bananas is: 
1 
· · · 
1 − x5 
Now,  we  can  choose  a  set  of  0  oranges  in  one way,  a  set  of  1  orange  in  one way, 
and  so  on.  However, we  can not  choose more  than  four  oranges,  so we have  the 
generating function: 

B (x) = 1 + x 5  + x 10  + x 15  +

= 

= 

1 − x5 
1 − x 
Here we’re using the geometric sum formula.  Finally, we can choose only zero or 
one pear, so we have: 

O(x) = 1 + x + x 2  + x 3  + x 4  =

P (x) = 1 + x 
The Convolution Rule says that the generating function for choosing from among 
all four kinds of fruit is: 

A(x)B (x)O(x)P (x) = 

1 − x5 
1
1 
(1 + x)
1 − x2  1 − x5  1 − x 
1 
= 
(1 − x)2 
= 1 + 2x + 3x 2  + 4x 3  + · · · 
Almost  everything  cancels!  We’re  left with  1/(1 − x)2 ,  which we  found  a  power 
series for earlier:  the coefﬁcient of xn  is simply n + 1. Thus, the number of ways to 
form a bag of n fruits is just n + 1.  This is consistent with the example we worked 
out, since there were 7 different fruit bags containing 6 fruits. Amazing! 

17.4.  AN “IMPOSSIBLE” COUNTING PROBLEM 

405 

17.4.1  Problems 
Homework Problems 

Problem 17.14. 
Miss McGillicuddy never goes outside without a collection of pets.  In particular: 

•  She brings a positive number of songbirds, which always come in pairs. 

•  She may or may not bring her alligator, Freddy. 

•  She brings at least 2 cats. 

•  She brings two or more chihuahuas and labradors leashed together in a line. 

Let Pn  denote the number of different collections of n pets that can accompany 
her, where we  regard chihuahuas and  labradors  leashed up  in different orders as 
different collections, even if there are the same number chihuahuas and labradors 
leashed in the line. 
For example, P6  = 4 since there are 4 possible collections of 6 pets: 

•  2 songbirds, 2 cats, 2 chihuahuas leashed in line 

•  2 songbirds, 2 cats, 2 labradors leashed in line 

•  2 songbirds, 2 cats, a labrador leashed behind a chihuahua 

•  2 songbirds, 2 cats, a chihuahua leashed behind a labrador 

And P7  = 16 since there are 16 possible collections of 7 pets: 

•  2 songbirds, 3 cats, 2 chihuahuas leashed in line 

•  2 songbirds, 3 cats, 2 labradors leashed in line 

•  2 songbirds, 3 cats, a labrador leashed behind a chihuahua 

•  2 songbirds, 3 cats, a chihuahua leashed behind a labrador 

•  4 collections consisting of 2 songbirds, 2 cats, 1 alligator, and a line of 2 dogs 

•  8 collections consisting of 2 songbirds, 2 cats, and a line of 3 dogs. 

(a)  Let 

P (x) ::= P0  + P1x + P2x 2  + P3x 3  + · · · 
be the generating function for the number of Miss McGillicuddy’s pet collections. 
Verify that 

P (x) = 

(b)  Find a simple formula for Pn . 

4x6 
(1 − x)2 (1 − 2x) 
.

406 

CHAPTER 17.  GENERATING FUNCTIONS 

Problem 17.15. 
Generating functions provide an interesting way to count the number of strings of 
matched  parentheses.  To  do  this,  we’ll  use  the  description  of  these  strings  given 
in Deﬁnition  11.1.2  as  the  set,  GoodCount,  of  strings  of  parentheses with  a  good 
count.  Let cn  be the number of strings in GoodCount with exactly n left parenthe­
ses, and let C (x) be the generating function for these numbers: 
C (x) ::= c0  + c1x + c2x 2  + · · ·  . 
(a)  The  wrap  of  a  string,  s,  is  the  string,  (s),  that  starts  with  a  left  parenthesis 
followed  by  the  characters  of  s,  and  then  ends with  a  right  parenthesis.  Explain 
why the generating function for the wraps of strings with a good count is xC (x). 
Hint:  The wrap of a  string with good  count also has a good  count  that  starts and 
ends with 0 and remains positive everywhere else. 

(b)  Explain why, for every string, s, with a good count, there is a unique sequence 
s1  · · · 
of  strings  s1 , . . . , sk  that  are wraps  of  strings with  good  counts  and  s  = 
sk .
For  example,  the  string  r  ::= (())()(()())  ∈  GoodCount  equals  s1 s2 s3  where  s1  = 
(()), s2  =  (), s3  =  (()()),  and  this  is  the  only  way  to  express  r  as  a  sequence  of 
wraps of strings with good counts. 

(17.10) 

(17.11)

(17.12)

(17.13)

(c)  Conclude that 

C  = 1 + xC + (xC )2  + · · · + (xC )n  + · · ·  , 

so 

and hence 

, 

1 
C  = 
1 − xC 
1 ± √
1 − 4x 
2x 

Let D(x) ::= 2xC (x). Expressing D as a power series

D(x) = d0  + d1x + d2x 2  + · · ·  , 

C  = 

. 

we have 

(e)  Prove that 

dn+1 . 
cn  = 
2 
(d)  Use (17.12), (17.13), and the value of c0  to conclude that 
D(x) = 1 − √
1 − 4x. 
(2n − 3) · (2n − 5) · · · 5 · 3 · 1 · 2n 
.
n! 
� �
2n 
1
n + 1  n 

(f)  Conclude that 

Hint:  dn  = D(n) (0)/n! 

cn  = 

. 

dn 

= 

17.4.  AN “IMPOSSIBLE” COUNTING PROBLEM 

407 

Exam Problems 

Problem 17.16. 
T-Pain is planning an epic boat trip and he needs to decide what to bring with him. 

•	 He deﬁnitely wants to bring burgers, but they only come in packs of 6. 

•	 He and his  two friends can’t decide whether  they want  to dress formally or 
casually. He’ll either bring 0 pairs of ﬂip ﬂops or 3 pairs. 

•	 He doesn’t have very much  room  in his suitcase  for  towels,  so he can bring 
at most 2. 

•	 In order  for  the boat  trip  to be  truly epic, he has  to bring at  least 1 nautical­
themed pashmina afghan. 
�
(a)  Let gn  be the the number of different ways for T-Pain to bring n items (burgers, 
pairs of ﬂip ﬂops, towels, and/or afghans) on his boat trip. Express the generating 
∞ 
function G(x) ::= 
n=0 gnxn  as a quotient of polynomials. 
(b)  Find a closed formula in n for the number of ways T-Pain can bring exactly n 
items with him. 

408 

CHAPTER 17.  GENERATING FUNCTIONS 

Chapter 18 

Introduction to Probability 

Probability plays a key  role  in  the  sciences —”hard” and  social —including  com­
puter  science.  Many  algorithms  rely  on  randomization.  Investigating  their  cor­
rectness  and  performance  requires  probability  theory.  Moreover,  computer  sys­
tems  designs,  such  as  memory  management,  branch  prediction,  packet  routing, 
and load balancing are based on probabilistic assumptions and analyses. Probabil­
ity  is central as well  in  related subjects such as  information  theory,  cryptography, 
artiﬁcial intelligence, and game theory.  But we’ll start with a more down-to-earth 
application:  getting a prize in a game show. 

18.1  Monty Hall 

In  the September 9, 1990  issue of Parade magazine,  the columnist Marilyn vos Sa­
vant responded to this letter: 

Suppose  you’re  on  a  game  show,  and  you’re  given  the  choice  of  three  doors. 
Behind one door is a car, behind the others, goats. You pick a door, say number 
1,  and  the  host, who  knows what’s  behind  the  doors,  opens  another  door,  say 
number  3,  which  has  a  goat.  He  says  to  you,  ”Do  you  want  to  pick  door 
number 2?” Is it to your advantage to switch your choice of doors? 
Craig. F. Whitaker 
Columbia, MD 

The letter describes a situation like one faced by contestants on the 1970’s game 
show Let’s Make a Deal, hosted by Monty Hall and Carol Merrill.  Marilyn  replied 
that the contestant should indeed switch.  She explained that if the car was behind 
either  of  the  two  unpicked  doors —which  is  twice  as  likely  as  the  the  car  being 
behind the picked door —the contestant wins by switching. But she soon received 
a torrent of letters, many from mathematicians, telling her that she was wrong. The 
problem generated thousands of hours of heated debate. 

409 

410 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

This  incident  highlights  a  fact  about  probability:  the  subject  uncovers  lots  of 
examples where ordinary intuition leads to completely wrong conclusions.  So un­
til  you’ve  studied  probabilities  enough  to  have  reﬁned  your  intuition,  a  way  to 
avoid  errors  is  to  fall  back  on  a  rigorous,  systematic  approach  such  as  the  Four 
Step Method. 

18.1.1  The Four Step Method 
Every probability problem involves some sort of randomized experiment, process, 
or game. And each such problem involves two distinct challenges: 

1.  How do we model the situation mathematically? 

2.  How do we solve the resulting mathematical problem? 

In this section, we introduce a four step approach to questions of the form, “What 
is  the  probability  that  —–  ?”  In  this  approach,  we  build  a  probabilistic  model 
step-by-step,  formalizing  the  original  question  in  terms  of  that  model.  Remark­
ably, the structured thinking that this approach imposes provides simple solutions 
to many  famously-confusing  problems.  For  example,  as  you’ll  see,  the  four  step 
method  cuts  through  the  confusion  surrounding  the  Monty  Hall  problem  like  a 
Ginsu  knife.  However,  more  complex  probability  questions  may  spin  off  chal­
lenging  counting,  summing,  and  approximation  problems—  which,  fortunately, 
you’ve already spent weeks learning how to solve. 

18.1.2  Clarifying the Problem 
Craig’s original letter to Marilyn vos Savant is a bit vague, so we must make some 
assumptions in order to have any hope of modeling the game formally: 

1.  The car is equally likely to be hidden behind each of the three doors. 

2.  The player is equally likely to pick each of the three doors, regardless of the 
car ’s location. 

3.  After the player picks a door, the host must open a different door with a goat 
behind it and offer the player the choice of staying with the original door or 
switching. 

4.  If  the  host  has  a  choice  of  which  door  to  open,  then  he  is  equally  likely  to 
select each of them. 

In  making  these  assumptions,  we’re  reading  a  lot  into  Craig  Whitaker ’s  letter. 
Other  interpretations  are  at  least  as  defensible,  and  some  actually  lead  to  differ­
ent answers. But let’s accept these assumptions for now and address the question, 
“What is the probability that a player who switches wins the car?” 

18.1.  MONTY HALL 

411 

18.1.3  Step 1:  Find the Sample Space 
Our  ﬁrst  objective  is  to  identify  all  the  possible  outcomes  of  the  experiment.  A 
typical  experiment  involves  several  randomly-determined  quantities.  For  exam­
ple, the Monty Hall game involves three such quantities: 

1.  The door concealing the car. 

2.  The door initially chosen by the player. 

3.  The door that the host opens to reveal a goat. 

Every possible combination of  these randomly-determined quantities  is called an 
outcome.  The  set of  all possible outcomes  is  called  the  sample  space  for  the  experi­
ment. 
A  tree  diagram  is  a  graphical  tool  that  can  help  us work  through  the  four  step 
approach when  the number  of  outcomes  is not  too  large  or  the problem  is nicely 
structured.  In particular, we  can use  a  tree diagram  to help understand  the  sam­
ple  space  of  an  experiment.  The  ﬁrst  randomly-determined  quantity  in  our  ex­
periment  is  the  door  concealing  the  prize.  We  represent  this  as  a  tree with  three 
branches: 

In  this  diagram,  the  doors  are  called  A,  B ,  and  C  instead  of  1,  2,  and  3  because 
we’ll be adding a lot of other numbers to the picture later. 
Now,  for  each  possible  location  of  the  prize,  the  player  could  initially  choose 
any of the three doors. We represent this in a second layer added to the tree. Then a 
third layer represents the possibilities of the ﬁnal step when the host opens a door 
to reveal a goat: 

carlocationCAB412 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

Notice  that  the  third  layer  reﬂects  the  fact  that  the  host  has  either  one  choice 
or two, depending on the position of the car and the door initially selected by the 
player. For example, if the prize is behind door A and the player picks door B, then 
the host must open door C. However, if the prize is behind door A and the player 
picks door A, then the host could open either door B or door C. 
Now let’s relate this picture to the terms we introduced earlier:  the leaves of the 
tree  represent  outcomes  of  the  experiment,  and  the  set  of  all  leaves  represents  the 
sample space.  Thus,  for this experiment,  the sample space consists of 12 outcomes. 
For reference, we’ve labeled each outcome with a triple of doors indicating: 
(door concealing prize,  door initially chosen,  door opened to reveal a goat) 
� 
� 
In these terms, the sample space is the set: 
(A, A, B ), 
(A, A, C ),  (A, B , C ),  (A, C, B ),  (B , A, C ),  (B , B , A), 
(B , B , C ),  (B , C, A),  (C, A, B ),  (C, B , A), 
(C, C, B ) 
(C, C, A), 
The  tree  diagram  has  a  broader  interpretation  as  well:  we  can  regard  the  whole 
experiment as  following a path  from  the  root  to a  leaf, where  the branch  taken at 
each stage is “randomly” determined.  Keep this interpretation in mind; we’ll use 
it again later. 

carlocationplayer’sinitial guessdoorrevealedCCCABABABCABCABACACCBABoutcomeB(A,A,B)(A,A,C)(A,B,C)(B,A,C)(B,B,A)(B,B,C)(B,C,A)(C,A,B)(C,B,A)(C,C,A)(C,C,B)(A,C,B)18.1.  MONTY HALL 

413 

18.1.4  Step 2: Deﬁne Events of Interest 
Our objective is to answer questions of the form “What is the probability that . . . ?”, 
where  the  missing  phrase  might  be  “the  player  wins  by  switching”,  “the  player 
initially  picked  the  door  concealing  the  prize”,  or  “the  prize  is  behind  door  C”, 
for example.  Each of  these phrases characterizes a set of outcomes:  the outcomes 
speciﬁed by “the prize is behind door C ” is: 
{(C, A, B ), (C, B , A), (C, C, A), (C, C, B )} 

A  set  of  outcomes  is  called  an  event.  So  the  event  that  the  player  initially  picked 
the door concealing the prize is the set: 
{(A, A, B ), (A, A, C ), (B , B , A), (B , B , C ), (C, C, A), (C, C, B )} 

And what we’re really after, the event that the player wins by switching, is the set 
of outcomes: 
{(A, B , C ), (A, C, B ), (B , A, C ), (B , C, A), (C, A, B ), (C, B , A)} 

Let’s annotate our tree diagram to indicate the outcomes in this event. 

carlocationplayer’sinitial guessdoorrevealedswitchwins?CCCABABABCABCABACACCBABoutcomeXXXXXXB(A,A,B)(A,A,C)(A,B,C)(B,A,C)(B,B,A)(B,B,C)(B,C,A)(C,A,B)(C,B,A)(C,C,A)(C,C,B)(A,C,B)414 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

Notice that exactly half of the outcomes are marked, meaning that the player wins 
by  switching  in  half  of  all  outcomes.  You  might  be  tempted  to  conclude  that  a 
player who  switches wins with  probability  1/2.  This  is wrong.  The  reason  is  that 
these outcomes are not all equally likely, as we’ll see shortly. 

18.1.5  Step 3: Determine Outcome Probabilities 

So  far  we’ve  enumerated  all  the  possible  outcomes  of  the  experiment.  Now  we 
must start assessing the likelihood of those outcomes.  In particular, the goal of this 
step is to assign each outcome a probability, indicating the fraction of the time this 
outcome  is  expected  to  occur.  The  sum  of  all  outcome probabilities must  be  one, 
reﬂecting the fact that there always is an outcome. 
Ultimately,  outcome  probabilities  are  determined  by  the  phenomenon  we’re 
modeling  and  thus  are  not  quantities  that  we  can  derive  mathematically.  How­
ever, mathematics can help us compute the probability of every outcome based on 
fewer  and  more  elementary  modeling  decisions.  In  particular,  we’ll  break  the  task  of 
determining outcome probabilities into two stages. 

Step 3a: Assign Edge Probabilities 

First, we record a probability on each edge of the tree diagram. These edge-probabilities 
are determined by the assumptions we made at the outset:  that the prize is equally 
likely  to  be  behind  each  door,  that  the  player  is  equally  likely  to  pick  each  door, 
and  that  the  host  is  equally  likely  to  reveal  each  goat,  if  he  has  a  choice.  Notice 
that when the host has no choice regarding which door to open, the single branch 
is assigned probability 1. 

18.1.  MONTY HALL 

415 

Step 3b: Compute Outcome Probabilities 

Our next  job  is  to  convert  edge probabilities  into outcome probabilities.  This  is  a 
purely mechanical process:  the probability of an outcome  is  equal  to  the product of  the 
edge-probabilities on the path from the root to that outcome. For example, the probability 
of the topmost outcome, (A, A, B ) is 
1 = 
1 1 1 
· 
· 
.
18 
2 
3 
3 
There’s  an  easy,  intuitive  justiﬁcation  for  this  rule.  As  the  steps  in  an  experi­
ment progress randomly along a path from the root of the tree to a leaf, the proba­
bilities on the edges indicate how likely the walk is to proceed along each branch. 
For example, a path starting at the root in our example is equally likely to go down 
each of the three top-level branches. 
Now,  how  likely  is  such  a  walk  to  arrive  at  the  topmost  outcome,  (A, A, B )? 
Well,  there  is  a  1-in-3  chance  that  a  walk  would  follow  the  A-branch  at  the  top 
level,  a  1-in-3  chance  it  would  continue  along  the  A-branch  at  the  second  level, 
and  1-in-2  chance  it would  follow  the B -branch  at  the  third  level.  Thus,  it  seems 
that  about  1 walk  in  18  should  arrive  at  the  (A, A, B )  leaf,  which  is  precisely  the 
probability we assign it. 
Anyway, let’s record all the outcome probabilities in our tree diagram. 

carlocationplayer’sinitial guessdoorrevealedswitchwins?CCCABABABCABCABACACC1/31/31/31/31/31/31/31/31/31/31/31/31111111/2B1/21/21/2AB1/21/2outcomeXXXXXXB(A,A,B)(A,A,C)(A,B,C)(B,A,C)(B,B,A)(B,B,C)(B,C,A)(C,A,B)(C,B,A)(C,C,A)(C,C,B)(A,C,B)416 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

Specifying the probability of each outcome amounts to deﬁning a function that 
maps  each  outcome  to  a  probability.  This  function  is  usually  called  Pr.  In  these 
terms, we’ve just determined that: 

1

Pr {(A, A, B )} = 
18 

1

Pr {(A, A, C )} = 
18 

1

Pr {(A, B , C )} = 
9

etc. 

18.1.6  Step 4: Compute Event Probabilities 

We now have a probability  for each  outcome,  but we want  to determine  the prob­
ability of an event which will be the sum of the probabilities of the outcomes in it. 
The probability of an  event, E ,  is written Pr {E }.  For  example,  the probability of 

carlocationplayer’sinitial guessdoorrevealedswitchwins?CCCABABABCABCABACACC1/31/31/31/31/31/31/31/31/31/31/31/31111111/2B1/21/21/2AB1/21/2outcomeXXXXXXprobability1/181/181/91/91/91/181/181/91/91/91/181/18B(A,A,B)(A,A,C)(A,B,C)(B,A,C)(B,B,A)(B,B,C)(B,C,A)(C,A,B)(C,B,A)(C,C,A)(C,C,B)(A,C,B)18.1.  MONTY HALL 

417 

the event that the player wins by switching is: 
Pr {switching wins} = Pr {(A, B , C )} + Pr {(A, C, B )} + Pr {(B , A, C )} + 
Pr {(B , C, A)} + Pr {(C, A, B )} + Pr {(C, B , A)}
1 
1
1
1
1
1
= + + + + +
9
9
9
9
9
9 
2 = 
3 

It  seems  Marilyn’s  answer  is  correct;  a  player  who  switches  doors  wins  the  car 
with probability 2/3!  In contrast, a player who stays with his or her original door 
wins with probability 1/3, since staying wins if and only if switching loses. 
We’re done with the problem! We didn’t need any appeals to intuition or inge­
nious analogies.  In fact, no mathematics more difﬁcult than adding and multiply­
ing fractions was required. The only hard part was resisting the temptation to leap 
to an “intuitively obvious” answer. 

18.1.7  An Alternative Interpretation of the Monty Hall Problem 
Was  Marilyn  really  right?  Our  analysis  suggests  she  was.  But  a  more  accurate 
conclusion  is  that  her  answer  is  correct  provided  we  accept  her  interpretation  of  the 
question.  There  is  an  equally  plausible  interpretation  in  which Marilyn’s  answer 
is wrong.  Notice  that  Craig Whitaker ’s  original  letter  does  not  say  that  the  host 
is  required  to  reveal  a  goat  and  offer  the  player  the  option  to  switch,  merely  that 
he did  these  things.  In  fact,  on  the Let’s Make  a Deal  show, Monty Hall  sometimes 
simply opened the door that the contestant picked initially. Therefore, if he wanted 
to, Monty  could  give  the  option  of  switching  only  to  contestants who picked  the 
correct door initially.  In this case, switching never works! 

18.1.8  Problems 
Class Problems 

Problem 18.1.

[A Baseball Series]

The  New  York  Yankees  and  the  Boston  Red  Sox  are  playing  a  two-out-of-three 
series.  (In  other words,  they  play  until  one  team  has won  two  games.  Then  that 
team is declared the overall winner and the series ends.) Assume that the Red Sox 
win each game with probability 3/5, regardless of the outcomes of previous games. 
Answer the questions below using the four step method. You can use the same 
tree diagram for all three problems. 
(a)  What is the probability that a total of 3 games are played? 

(b)  What is the probability that the winner of the series loses the ﬁrst game? 

(c)  What is the probability that the correct team wins the series? 

418 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

Problem 18.2. 
To determine which of two people gets a prize, a coin is ﬂipped twice.  If the ﬂips 
are  a Head  and  then  a Tail,  the ﬁrst player wins.  If  the ﬂips  are  a Tail  and  then  a 
Head, the second player wins. However, if both coins land the same way, the ﬂips 
don’t count and whole the process starts over. 
Assume  that  on  each  ﬂip,  a  Head  comes  up  with  probability  p,  regardless  of 
what happened on other ﬂips.  Use the four step method to ﬁnd a simple formula 
for  the  probability  that  the  ﬁrst  player wins.  What  is  the  probability  that  neither 
player wins? 
Suggestions:  The tree diagram and sample space are inﬁnite, so you’re not go­
ing to ﬁnish drawing the tree. Try drawing only enough to see a pattern. Summing 
all  the  winning  outcome  probabilities  directly  is  difﬁcult.  However,  a  neat  trick 
solves  this  problem  and  many  others.  Let  s  be  the  sum  of  all  winning  outcome 
probabilities  in  the whole  tree.  Notice  that  you  can write  the  sum  of  all  the winning 
probabilities  in  certain  subtrees  as  a  function  of  s.  Use  this  observation  to  write  an 
equation in s and then solve. 

Problem 18.3.

[The Four-Door Deal]

Let’s  see  what  happens  when  Let’s Make  a  Deal  is  played  with  four  doors.  A 
prize  is  hidden  behind  one  of  the  four  doors.  Then  the  contestant  picks  a  door. 
Next, the host opens an unpicked door that has no prize behind it.  The contestant 
is allowed to stick with their original door or to switch to one of the two unopened, 
unpicked  doors.  The  contestant  wins  if  their  ﬁnal  choice  is  the  door  hiding  the 
prize. 
Use  The  Four  Step Method  of  Section  18.1  to  ﬁnd  the  following  probabilities. 
The  tree diagram may become awkwardly  large,  in which case  just draw enough 
of it to make its structure clear. 
(a)  Contestant Stu, a sanitation engineer from Trenton, New Jersey, stays with his 
original door. What is the probability that Stu wins the prize? 

(b)  Contestant Zelda, an alien abduction researcher from Helena, Montana, switches 
to one of the remaining two doors with equal probability.  What is the probability 
that Zelda wins the prize? 

Problem 18.4.

[Simulating  a  fair  coin]  Suppose  you  need  a  fair  coin  to  decide  which  door  to

choose in the 6.042 Monty Hall game. After making everyone in your group empty

their pockets, all you managed to turn up is some crumpled bubble gum wrappers,

a  few used  tissues,  and one penny.  However,  the penny was  from Prof.  Meyer ’s

pocket, so it is not safe to assume that it is a fair coin.

How  can  we  use  a  coin  of  unknown  bias  to  get  the  same  effect  as  a  fair  coin 

18.2.  SET THEORY AND PROBABILITY 

419 

of bias 1/2?  Draw the tree diagram for your solution, but since it is inﬁnite, draw 
only enough to see a pattern. 
Suggestion:  A  neat  trick  allows  you  to  sum  all  the  outcome  probabilities  that 
cause you  to say ”Heads”:  Let s be  the sum of all ”Heads” outcome probabilities 
in the whole tree.  Notice that you can write the sum of all the ”Heads” outcome proba­
bilities in certain subtrees as a function of s. Use this observation to write an equation 
in s and then solve. 

Homework Problems 

Problem 18.5. 
I have a deck of 52 regular playing cards, 26 red, 26 black, randomly shufﬂed. They 
all  lie face down  in the deck so that you can’t see them.  I will draw a card off the 
top  of  the  deck  and  turn  it  face  up  so  that  you  can  see  it  and  then  put  it  aside.  I 
will continue to turn up cards like this but at some point while there are still cards 
left  in the deck, you have to declare that you want the next card  in the deck to be 
turned up.  If that next card turns up black you win and otherwise you lose. Either 
way, the game is then over. 
(a)  Show that if you take the ﬁrst card before you have seen any cards, you then 
have probability 1/2 of winning the game. 

(b)  Suppose you don’t take the ﬁrst card and it turns up red.  Show that you have 
then have a probability of winning the game that is greater than 1/2. 

(c)  If there are r red cards left in the deck and b black cards, show that the proba­
bility of winning in you take the next card is b/(r + b). 

(d)  Either, 

1.  come up with a strategy for this game that gives you a probability of winning 
strictly greater than 1/2 and prove that the strategy works, or, 
2.  come up with a proof that no such strategy can exist. 

18.2  Set Theory and Probability 

Let’s  abstract  what  we’ve  just  done  in  this  Monty  Hall  example  into  a  general 
mathematical  deﬁnition  of  probability.  In  the  Monty  Hall  example,  there  were 
only  ﬁnitely many  possible  outcomes.  Other  examples  in  this  course will  have  a 
countably inﬁnite number of outcomes. 
General probability theory deals with uncountable sets like the set of real num­
bers,  but  we  won’t  need  these,  and  sticking  to  countable  sets  lets  us  deﬁne  the 
probability  of  events  using  sums  instead  of  integrals.  It  also  lets  us  avoid  some 
distracting technical problems in set theory like the Banach-Tarski “paradox” men­
tioned in Chapter 5.2.5. 

420 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

18.2.1  Probability Spaces 
Deﬁnition  18.2.1.  A  countable  sample  space,  S ,  is  a  nonempty  countable  set.  An 
element w ∈ S  is called an outcome. A subset of S  is called an event. 
Deﬁnition  18.2.2.  A  probability  function  on  a  sample  space,  S ,  is  a  total  function 
Pr {} : S → R such that 
� 
•  Pr {w} ≥ 0 for all w ∈ S , and 
Pr {w} = 1. 
w∈S 
The sample space together with a probability function is called a probability space. 
For any event, E  ⊆ S , the probability of E  is deﬁned to be the sum of the proba­
� 
bilities of the outcomes in E : 
Pr {E } ::= 
w∈E 

Pr {w} . 

• 

An immediate consequence of the deﬁnition of event probability is that for dis­
joint events, E , F , 
Pr {E ∪ F } = Pr {E } + Pr {F } . 
This  generalizes  to  a  countable  number  of  events.  Namely,  a  collection  of  sets  is 
pairwise disjoint when no element is in more than one of them —formally, A ∩ B = ∅
for all sets A = B  in the collection. 
� 
� 
Rule (Sum Rule).  If {E0 , E1 , . . . } is collection of pairwise disjoint events, then 
� 

 
Pr {En} . 
En  = 
Pr 
n∈N 
n∈N 

The  Sum  Rule1  lets  us  analyze  a  complicated  event  by  breaking  it  down  into 
simpler cases.  For example, if the probability that a randomly chosen MIT student 
�  � 
is  native  to  the United  States  is  60%,  to Canada  is  5%,  and  to Mexico  is  5%,  then 
the probability that a random MIT student is native to North America is 70%. 
Another consequence of  the Sum Rule  is  that Pr {A} + Pr  A  = 1, which  fol­
lows  because  Pr {S }  = 1  and  S  is  the  union  of  the  disjoint  sets  A  and  A.  This 
equation often comes up in the form 

1 If you think like a mathematician, you should be wondering if the inﬁnite sum is really necessary. 
Namely,  suppose  we  had  only  used  ﬁnite  sums  in  Deﬁnition  18.2.2  instead  of  sums  over  all  natural 
numbers. Would this imply the result for inﬁnite sums?  It’s hard to ﬁnd counterexamples, but there are 
some:  it is possible to ﬁnd a pathological “probability” measure on a sample space satisfying the Sum 
Rule for ﬁnite unions, in which the outcomes w0 , w1 , . . .  each have probability zero, and the probability 
assigned to any event is either zero or one!  So the inﬁnite Sum Rule fails dramatically, since the whole 
space is of measure one, but it is a union of the outcomes of measure zero. 
The construction of such weird examples is beyond the scope of this text.  You can learn more about 
this by taking a course in Set Theory and Logic that covers the topic of “ultraﬁlters.” 

�
18.2.  SET THEORY AND PROBABILITY 

421 

Rule (Complement Rule). 

�  � 
Pr  A  = 1 − Pr {A} . 

Sometimes the easiest way to compute the probability of an event is to compute 
the probability of its complement and then apply this formula. 
Some  further  basic  facts  about  probability  parallel  facts  about  cardinalities  of 
ﬁnite sets.  In particular: 

Pr {B − A} = Pr {B } − Pr {A ∩ B } , 
Pr {A ∪ B } = Pr {A} + Pr {B } − Pr {A ∩ B } , 
Pr {A ∪ B } ≤ Pr {A} + Pr {B } . 

(Difference Rule) 
(Inclusion-Exclusion) 
(Boole’s Inequality) 

The Difference Rule follows from the Sum Rule because B  is the union of the dis­
joint  sets B − A  and A ∩ B .  Inclusion-Exclusion  then  follows  from  the  Sum  and 
Difference Rules, because A∪B is the union of the disjoint sets A and B −A. Boole’s 
inequality is an immediate consequence of Inclusion-Exclusion since probabilities 
are nonnegative. 
The  two  event  Inclusion-Exclusion  equation  above  generalizes  to  n  events  in 
the  same  way  as  the  corresponding  Inclusion-Exclusion  rule  for  n  sets.  Boole’s 
inequality also generalizes to 

Pr {E1  ∪ · · · ∪ En} ≤ Pr {E1 } + · · · + Pr {En} . 

(Union Bound) 

This  simple  Union  Bound  is  actually  useful  in  many  calculations.  For  example, 
suppose  that  Ei  is  the  event  that  the  i-th  critical  component  in  a  spacecraft  fails. 
Then E1 ∪ · · · ∪ En  is the event that some critical component fails. The Union Bound 
can give an adequate upper bound on this vital probability. 
Similarly, the Difference Rule implies that 

If A ⊆ B ,  then  Pr {A} ≤ Pr {B } . 

(Monotonicity) 

18.2.2  An Inﬁnite Sample Space 

Suppose  two  players  take  turns  ﬂipping  a  fair  coin.  Whoever  ﬂips  heads  ﬁrst  is 
declared  the  winner.  What  is  the  probability  that  the  ﬁrst  player  wins?  A  tree 
diagram for this problem is shown below: 

422 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

= 

+

= 

=

+

+ 

· · · 

+

2 
.
3 

1
128 

The  event  that  the  ﬁrst  player wins  contains  an  inﬁnite  number  of  outcomes, 
but we can still sum their probabilities: 
∞ � 
1 �n 
1 
1
1
Pr {ﬁrst player wins} = + +
� � 
+ 
2 
8 
32 
1 
� 
4 
2
n=0 
1
1 
1 − 1/4
2
Similarly, we can compute the probability that the second player wins: 
1
1 
1
1
Pr {second player wins} = +
· · · 
4 
16 
64 
256 
1 = 
.3 
To be formal about this, sample space is the inﬁnite set 
S  ::= {TnH  | n ∈ N} 
where Tn  stands for a length n string of T’s. The probability function is 
1
Pr {TnH} ::= 
.
2n+1 
Since  this  function  is  obviously  nonnegative,  To  verify  that  this  is  a  probability 
space,  we  just  have  to  check  that  all  the  probabilities  sum  to  1.  But  this  follows 
1 �  1
�  1
�
directly from the formula for the sum of a geometric series: 
Pr {TnH} = 
2n+1 
2
2n 
Tn H∈S 
n∈N 
n∈N 
Notice  that  this model does not have  an  outcome  corresponding  to  the possi­
bility  that  both  players  keep  ﬂipping  tails  forever —in  the  diagram,  ﬂipping  for­
ever  corresponds  to  following  the  inﬁnite  path  in  the  tree without  ever  reaching 

=

= 1.

1/21/21/21/21/21/21/21/2etc.HHHHTTTTfirstplayersecondplayerfirstplayersecondplayer1/21/41/81/1618.2.  SET THEORY AND PROBABILITY 

423 

a  leaf/outcome.  If  leaving  this  possibility  out  of  the  model  bothers  you,  you’re 
welcome  to ﬁx  it by adding another outcome, wforever ,  to  indicate  that  that’s what 
happened. Of course since the probabililities of the other outcomes already sum to 
1, you have to deﬁne the probability of wforever  to be 0.  Now outcomes with prob­
ability zero will have no impact on our calculations, so there’s no harm in adding 
it  in  if  it makes  you  happier.  On  the  other  hand,  there’s  also  no  harm  in  simply 
leaving it out as we did, since it has no impact. 
The mathematical machinery we’ve developed  is adequate  to model and ana­
lyze many interesting probability problems with inﬁnite sample spaces. However, 
some  intricate  inﬁnite  processes  require  uncountable  sample  spaces  along  with 
more powerful  (and more complex) measure-theoretic notions of probability.  For 
example, if we generate an inﬁnite sequence of random bits b1 , b2 , b3 , . . ., then what 
is the probability that 

+

+

b3
b2 
b1 
23 
22 
21 
is  a  rational  number?  Fortunately, we won’t  have  any  need  to worry  about  such 
things. 

+

· · · 

18.2.3  Problems 
Class Problems 

Problem 18.6. 
Suppose there is a system with n components, and we know from past experience 
that any particular component will fail in a given year with probability p.  That is, 
letting Fi  be the event that the ith component fails within one year, we have 
Pr {Fi } = p 
for 1  ≤  i  ≤  n.  The system will fail  if any one of  its components fails.  What can we 
say about the probability that the system will fail within one year? 
Let F  be the event that the system fails within one year. Without any additional 
assumptions, we can’t get an exact answer for Pr {F }. However, we can give useful 
upper and lower bounds, namely, 
p ≤ Pr {F } ≤ np. 
We may  as well  assume  p <  1/n,  since  the upper bound  is  trivial otherwise.  For 
example, if n = 100 and p = 10−5 , we conclude that there is at most one chance in 
1000 of system failure within a year and at least one chance in 100,000. 
Let’s model this situation with the sample space S ::= P ({1, . . . , n}) whose out­
comes are subsets of positive integers ≤ n, where s ∈ S  corresponds to the indices 
of  exactly  those  components  that  fail within  one  year.  For  example,  {2, 5}  is  the 
outcome that the second and ﬁfth components failed within a year and none of the 
other components failed.  So the outcome that the system did not fail corresponds 
to the emptyset, ∅. 

(18.1) 

424 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

(a)  Show  that  the  probability  that  the  system  fails  could  be  as  small  as  p  by  de­
scribing  appropriate  probabilities  for  the  outcomes.  Make  sure  to  verify  that  the 
sum of your outcome probabilities is 1. 

(b)  Show that the probability that the system fails could actually be as large as np 
by describing appropriate probabilities for the outcomes. Make sure to verify that 
the sum of your outcome probabilities is 1. 

(c)  Prove inequality (18.1). 

Problem 18.7. 
Here are some handy rules for reasoning about probabilities that all follow directly 
from the Disjoint Sum Rule in the Appendix. Prove them. 
Pr {A − B } = Pr {A} − Pr {A ∩ B } 
�  � 
Pr  A  = 1 − Pr {A} 

(Complement Rule) 

(Difference Rule) 

Pr {A ∪ B } = Pr {A} + Pr {B } − Pr {A ∩ B } 

(Inclusion-Exclusion) 

Pr {A ∪ B } ≤ Pr {A} + Pr {B } . 

(2-event Union Bound) 

If A ⊆ B ,  then  Pr {A} ≤ Pr {B } . 

(Monotonicity) 

Problem 18.8. 
Suppose Pr {}  :  S →  [0, 1]  is  a probability  function  on  a  sample  space,  S ,  and  let 
B  be an event such that Pr {B } > 0.  Deﬁne a function PrB  {·} on events outcomes 
� 
w ∈ S  by the rule: 
if w ∈ B , 
Pr {w} / Pr {B } 
PrB  {w} ::= 
if w /∈ B . 
0 
(a)  Prove  that  PrB  {·}  is  also  a  probability  function  on  S  according  to  Deﬁni­
tion 18.2.2. 

(18.2)

(b)  Prove that 

for all A ⊆ S . 

PrB  {A} = 

Pr {A ∩ B }
Pr {B } 

18.3.  CONDITIONAL PROBABILITY 

425 

18.3  Conditional Probability 

Suppose that we pick a random person in the world. Everyone has an equal chance 
of being selected.  Let A be  the event  that  the person  is an MIT student, and  let B 
be the event that the person lives in Cambridge. What are the probabilities of these 
events?  Intuitively, we’re picking a  random point  in  the big ellipse  shown below 
and asking how likely that point is to fall into region A or B : 

The  vast majority  of  people  in  the  world  neither  live  in  Cambridge  nor  are MIT 
students, so events A and B both have low probability. But what is the probability 
that  a  person  is  an MIT  student,  given  that  the  person  lives  in  Cambridge?  This 
should be much greater— but what is it exactly? 
What we’re  asking  for  is  called  a  conditional  probability;  that  is,  the probability 
that one event happens, given that some other event deﬁnitely happens. Questions 
about conditional probabilities come up all the time: 

•	 What is the probability that it will rain this afternoon, given that it is cloudy 
this morning? 

•	 What  is  the  probability  that  two  rolled  dice  sum  to  10,  given  that  both  are 
odd? 

•	 What  is  the  probability  that  I’ll  get  four-of-a-kind  in  Texas  No  Limit  Hold 
’Em Poker, given that I’m initially dealt two queens? 
There is a special notation for conditional probabilities.  In general, Pr {A  |  B }
denotes the probability of event A, given that event B happens. So, in our example, 
Pr {A  |  B }  is  the  probability  that  a  random  person  is  an MIT  student,  given  that 
he or she is a Cambridge resident. 
How  do we  compute  Pr {A  |  B }?  Since we  are  given  that  the  person  lives  in 
Cambridge,  we  can  forget  about  everyone  in  the  world  who  does  not.  Thus,  all 
outcomes outside event B  are irrelevant.  So,  intuitively, Pr {A  |  B } should be the 
fraction  of  Cambridge  residents  that  are  also  MIT  students;  that  is,  the  answer 

ABset of all peoplein the worldset of people wholive in Cambridgeset of MITstudents426 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

should be  the probability  that  the person  is  in  set A ∩ B  (darkly  shaded) divided 
by  the probability  that  the person  is  in  set B  (lightly  shaded).  This motivates  the 
deﬁnition of conditional probability: 

Deﬁnition 18.3.1. 

Pr {A  |  B } ::= 

Pr {A ∩ B }
Pr {B } 

If Pr {B } = 0, then the conditional probability Pr {A  |  B } is undeﬁned. 
Pure probability is often counterintuitive, but conditional probability is worse! 
Conditioning can subtly alter probabilities and produce unexpected results in ran­
domized  algorithms  and  computer  systems  as well  as  in  betting  games.  Yet,  the 
mathematical deﬁnition of conditional probability given above is very simple and 
should give you no trouble— provided you rely on formal reasoning and not intu­
ition. 

18.3.1  The “Halting Problem” 

The  Halting  Problem  was  the  ﬁrst  example  of  a  property  that  could  not  be  tested 
by  any  program.  It  was  introduced  by  Alan  Turing  in  his  seminal  1936  paper. 
The problem is to determine whether a Turing machine halts on a given . . . yadda 
yadda  yadda  . . . what’s  much  more  important,  it  was  the  name  of  the  MIT  EECS 
department’s famed C-league hockey team. 
In  a  best-of-three  tournament,  the  Halting  Problem  wins  the  ﬁrst  game  with 
probability 1/2.  In subsequent games,  their probability of winning  is determined 
by  the  outcome  of  the  previous  game.  If  the  Halting  Problem  won  the  previous 
game, then they are invigorated by victory and win the current game with proba­
bility 2/3.  If they lost the previous game, then they are demoralized by defeat and 
win  the  current  game with  probablity  only  1/3.  What  is  the  probability  that  the 
Halting Problem wins the tournament, given that they win the ﬁrst game? 
This  is  a  question  about  a  conditional probability.  Let A  be  the  event  that  the 
Halting  Problem  wins  the  tournament,  and  let  B  be  the  event  that  they  win  the 
ﬁrst game. Our goal is then to determine the conditional probability Pr {A  |  B }. 
We  can  tackle  conditional  probability  questions  just  like  ordinary  probability 
problems: using a tree diagram and the four step method. A complete tree diagram 
is shown below, followed by an explanation of its construction and use. 

18.3.  CONDITIONAL PROBABILITY 

427 

Step 1:  Find the Sample Space 

Each internal vertex in the tree diagram has two children, one corresponding to a 
win for the Halting Problem (labeled W ) and one corresponding to a loss (labeled 
L). The complete sample space is: 
S  = {W W,  W LW,  W LL,  LW W,  LW L,  LL} 

Step 2: Deﬁne Events of Interest 

The event that the Halting Problem wins the whole tournament is: 
T  = {W W,  W LW,  LW W } 

And the event that the Halting Problem wins the ﬁrst game is: 
F  = {W W, W LW, W LL} 

The outcomes in these events are indicated with checkmarks in the tree diagram. 

Step 3: Determine Outcome Probabilities 

Next, we must assign a probability  to each outcome.  We begin by  labeling edges 
as speciﬁed in the problem statement.  Speciﬁcally, The Halting Problem has a 1/2 
chance  of winning  the  ﬁrst  game,  so  the  two  edges  leaving  the  root  are  each  as­
signed probability 1/2.  Other  edges are  labeled 1/3 or 2/3 based on  the outcome 

2/3L1/2W1/2W1/3L2/3L1/3W2/3LL1/3W2/3W1/31st gameoutcome2nd gameoutcome3rd gameoutcomeprobabilityoutcome1/31/181/91/91/181/3event B:win the1st game?event A:win theseries?WWWLWWLLLWWLWLLLoutcome428 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

of the preceding game. We then ﬁnd the probability of each outcome by multiply­
ing  all  probabilities  along  the  corresponding  root-to-leaf  path.  For  example,  the 
probability of outcome W LL is: 

1 1 2 
· 
· 
2 
3 
3

1 = 
9 

Step 4: Compute Event Probabilities 

Pr {A  |  B } = 

We  can  now  compute  the  probability  that  The Halting  Problem wins  the  tourna­
ment, given that they win the ﬁrst game: 
Pr {A ∩ B }
Pr {B }
Pr {{W W, W LW }}
Pr {{W W, W LW, W LL}}
1/3 + 1/18 
= 
1/3 + 1/18 + 1/9 
7 = 
9 

= 

We’re done!  If  the Halting Problem wins  the ﬁrst game,  then  they win  the whole 
tournament with probability 7/9. 

18.3.2  Why Tree Diagrams Work 
We’ve  now  settled  into  a  routine  of  solving  probability  problems  using  tree  dia­
grams.  But we’ve left a big question unaddressed:  what is the mathematical justi­
ﬁcation behind those funny little pictures? Why do they work? 
The  answer  involves  conditional  probabilities.  In  fact,  the  probabilities  that 
we’ve  been  recording  on  the  edges  of  tree diagrams  are  conditional probabilities. 
For example, consider the uppermost path in the tree diagram for the Halting Prob­
lem, which corresponds to the outcome W W .  The ﬁrst edge is labeled 1/2, which 
is  the probability  that  the Halting Problem wins  the ﬁrst game.  The  second  edge 
is  labeled 2/3, which  is  the probability  that  the Halting Problem wins  the  second 
game, given that they won the ﬁrst— that’s a conditional probability! More gener­
ally, on each edge of a tree diagram, we record the probability that the experiment 
proceeds along that path, given that it reaches the parent vertex. 
So we’ve been using conditional probabilities all along.  But why can we mul­
tiply edge probabilities  to get outcome probabilities?  For example, we concluded 
that: 

1 2
· 
Pr {W W } = 
2 
3 
1 = 
3 

18.3.  CONDITIONAL PROBABILITY 

429 

Why is this correct? 
The  answer  goes  back  to  Deﬁnition  18.3.1  of  conditional  probability  which 
could be written in a form called the Product Rule for probabilities: 
Rule (Product Rule for 2 Events).  If Pr {E1} = 0
, then: 
Pr {E1  ∩ E2} = Pr {E1} · Pr {E2  |  E1 } 

Multiplying  edge  probabilities  in  a  tree  diagram  amounts  to  evaluating  the 
right side of this equation.  For example: 
Pr {win ﬁrst game ∩ win second game} 
= Pr {win ﬁrst game} · Pr {win second game  |  win ﬁrst game}
1 2 
· 
= 
2 
3 

So the Product Rule is the formal justiﬁcation for multiplying edge probabilities to 
get outcome probabilities! Of course to justify multiplying edge probabilities along 
longer paths, we need a Product Rule for n events.  The pattern of the n event rule 
should be apparent from 

Rule (Product Rule for 3 Events). 
Pr {E1  ∩ E2  ∩ E3 } = Pr {E1 } · Pr {E2  |  E1} · Pr {E3  |  E2  ∩ E1} 
providing Pr {E1  ∩ E2 } = 0
. 
This  rule  follows  from  the deﬁnition of  conditional probability  and  the  trivial 
identity 

Pr {E1  ∩ E2  ∩ E3 } = Pr {E1 } · 

Pr {E2  ∩ E1 }  Pr {E3  ∩ E2  ∩ E1 }
· 
Pr {E1}
Pr {E2  ∩ E1} 

18.3.3  The Law of Total Probability 
Breaking  a probability  calculation  into  cases  simpliﬁes many problems.  The  idea 
is  to  calculate  the  probability  of  an  event  A  by  splitting  into  two  cases  based  on 
whether or not another event E  occurs.  That is, calculate the probability of A ∩ E 
and A ∩ E . By the Sum Rule, the sum of these probabilities equals Pr {A}. Express­
ing the intersection probabilities as conditional probabilities yields 
� �
� 
� � 
Pr {A} = Pr {A  |  E } · Pr {E } + Pr  A  �  E 
Rule (Total Probability). 
· Pr  E . 
For  example,  suppose  we  conduct  the  following  experiment.  First,  we  ﬂip  a 
coin.  If heads comes up, then we roll one die and take the result.  If tails comes up, 
then we roll two dice and take the sum of the two results.  What is the probability 

�
�
430 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

�  � 
that  this  process  yields  a  2?  Let  E  be  the  event  that  the  coin  comes  up  heads, 
and  let  A  be  the  event  that  we  get  a  2  overall.  Assuming  that  the  coin  is  fair, 
�
� 
� 
Pr {E }  =  Pr  E  = 1/2.  There  are now  two  cases.  If we ﬂip heads,  then we  roll 
ﬂip tails, then we get a sum of 2 on two dice with probability Pr  A  �  E  = 1/36. 
a  2  on  a  single  die  with  probabilty  Pr {A  |  E }  = 1/6. 
On  the  other  hand,  if  we 
Therefore, the probability that the whole process yields a 2 is 

Pr {A} =

1 1
· 
2 
6

+ 

1
2 

· 

1 
36 

= 

7
.
72 

There is also a form of the rule to handle more than two cases. 

Rule  (Multicase  Total  Probability).  If  E1 , . . . , En  are  pairwise  disjoint  events  whose 
union is the whole sample space, then: 
� 
n
Pr {A  |  Ei} · Pr {Ei} . 
i=1 

Pr {A} = 

18.3.4  Medical Testing 

There  is  an  unpleasant  condition  called  BO  suffered  by  10%  of  the  population. 
There  are  no  prior  symptoms;  victims  just  suddenly  start  to  stink.  Fortunately, 
there  is  a  test  for  latent  BO  before  things  start  to  smell.  The  test  is  not  perfect, 
however: 

•	 If you have the condition, there is a 10% chance that the test will say you do 
not.  (These are called “false negatives”.) 

•	 If you do not have the condition,  there is a 30% chance that the test will say 
you do.  (These are “false positives”.) 

Suppose  a  random  person  is  tested  for  latent  BO.  If  the  test  is  positive,  then 
what is the probability that the person has the condition? 

Step 1:  Find the Sample Space 

The sample space is found with the tree diagram below. 

18.3.  CONDITIONAL PROBABILITY 

431 

Step 2: Deﬁne Events of Interest 

Let  A  be  the  event  that  the  person  has  BO.  Let  B  be  the  event  that  the  test  was 
positive.  The  outcomes  in  each  event  are marked  in  the  tree  diagram.  We  want 
to  ﬁnd  Pr {A  |  B },  the  probability  that  a  person  has  BO,  given  that  the  test  was 
positive. 

Step 3:  Find Outcome Probabilities 

First, we assign probabilities to edges. These probabilities are drawn directly from 
the problem statement.  By  the Product Rule,  the probability of an outcome  is  the 
product of  the probabilities on  the corresponding root-to-leaf path.  All probabili­
ties are shown in the ﬁgure. 

Step 4: Compute Event Probabilities 

p 

Pr {A B } = 
| 

Pr {A ∩ B }
Pr {B }
0.09 
= 
0.09 + 0.27 
1 = 
4 

If you test positive, then there is only a 25% chance that you have the condition! 

personhas BO?test resultoutcomeprobabilityevent A    B?yesnoposnegposneg.1.9.9.1.3.7.09.01.27.63event A:event B:hasBO?testpositive?432 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

This  answer  is  initially  surprising,  but  makes  sense  on  reﬂection.  There  are 
two ways you  could  test positive.  First,  it  could be  that you  are  sick  and  the  test 
is  correct.  Second,  it  could  be  that  you  are  healthy  and  the  test  is  incorrect.  The 
problem  is  that almost everyone  is healthy;  therefore, most of  the positive results 
arise from incorrect tests of healthy people! 
We can also compute the probability that the test is correct for a random person. 
This event consists of two outcomes. The person could be sick and the test positive 
(probability 0.09), or the person could be healthy and the test negative (probability 
0.63).  Therefore,  the  test  is  correct with  probability  0.09 + 0.63  =  0.72.  This  is  a 
relief; the test is correct almost three-quarters of the time. 
But wait! There is a simple way to make the test correct 90% of the time: always 
return  a negative  result!  This  “test” gives  the  right  answer  for  all healthy people 
and the wrong answer only for the 10% that actually have the condition.  The best 
strategy is to completely ignore the test result! 
There  is  a  similar  paradox  in  weather  forecasting.  During  winter,  almost  all 
days in Boston are wet and overcast. Predicting miserable weather every day may 
be more accurate than really trying to get it right! 

18.3.5  Conditional Identities 

The probability rules above extend to probabilities conditioned on the same event. 
For  example,  the  Inclusion-Exclusion  formula  for  two  sets holds when  all proba­
bilities are conditioned on an event C : 

Pr {A ∪ B  |  C } = Pr {A  |  C } + Pr {B  |  C } − Pr {A ∩ B  |  C } . 

This follows from the fact that if Pr {C } = 0 
and we deﬁne 

PrC  {A} ::= Pr {A  |  C } 

then PrC  {} satisﬁes the deﬁnition of being probability function. 
It  is  important not  to mix up events before and after  the conditioning bar.  For 
example, the following is not a valid identity: 

False Claim. 

Pr {A  |  B ∪ C } = Pr {A  |  B } + Pr {A  |  C } − Pr {A  |  B ∩ C } . 

(18.3) 

A counterexample is shown below.  In this case, Pr {A  |  B } = 1, Pr {A  |  C } = 1, 
and Pr {A  |  B ∪ C }  = 1.  However,  since  1 =�
1 + 1,  the  equation  above does not 
hold. 

�
18.3.  CONDITIONAL PROBABILITY 

433 

So  you’re  convinced  that  this  equation  is  false  in  general,  right?  Let’s  see  if  you 
really believe that. 

18.3.6  Discrimination Lawsuit 
Several years ago there was a sex discrimination lawsuit against Berkeley. A female 
professor was denied tenure, allegedly because she was a woman. She argued that 
in  every  one  of  Berkeley’s  22  departments,  the  percentage  of male  applicants  ac­
cepted was greater than the percentage of female applicants accepted. This sounds 
very suspicious! 
However, Berkeley’s  lawyers argued  that across  the whole university  the per­
centage of male tenure applicants accepted was actually lower than the percentage 
of  female  applicants  accepted.  This  suggests  that  if  there  was  any  sex  discrimi­
nation,  then  it was against men!  Surely,  at  least one party  in  the dispute must be 
lying. 
Let’s simplify the problem and express both arguments in terms of conditional 
probabilities.  Suppose  that  there are only  two departments, EE and CS, and  con­
sider  the  experiment  where  we  pick  a  random  applicant.  Deﬁne  the  following 
events: 

•  Let A be the event that the applicant is accepted. 

•  Let FEE  the event that the applicant is a female applying to EE. 

•  Let FCS  the event that the applicant is a female applying to CS. 

•  Let MEE  the event that the applicant is a male applying to EE. 

•  Let MCS  the event that the applicant is a male applying to CS. 

Assume that all applicants are either male or female, and that no applicant applied 
to both departments. That is, the events FEE , FCS , MEE , and MCS  are all disjoint. 
In these terms, the plaintiff is make the following argument: 
Pr {A  |  FEE } < Pr {A  |  MEE }

Pr {A  |  FCS } < Pr {A  |  MCS }


sample spaceABC434 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

That is, in both departments, the probability that a woman is accepted for tenure is 
less than the probability that a man is accepted.  The university retorts that overall 
a woman applicant is more likely to be accepted than a man: 
Pr {A  |  FEE  ∪ FCS } > Pr {A  |  MEE  ∪ MCS } 

It is easy to believe that these two positions are contradictory.  In fact, we might 
even  try  to prove  this by adding  the plaintiff ’s  two  inequalities and  then arguing 
as follows: 

Pr {A  |  FEE } + Pr {A  |  FCS } < Pr {A  |  MEE } + Pr {A  |  MCS } 
Pr {A  |  FEE  ∪ FCS } < Pr {A  |  MEE  ∪ MCS } 

⇒ 

The  second  line  exactly  contradicts  the  university’s  position!  But  there  is  a  big 
problem  with  this  argument;  the  second  inequality  follows  from  the  ﬁrst  only  if 
we accept the false identity (18.3).  This argument is bogus! Maybe the two parties 
do not hold contradictory positions after all! 
In fact, the table below shows a set of application statistics for which the asser­
tions of both the plaintiff and the university hold: 

CS 

0% 
0 females accepted, 1 applied 
50% 
50 males accepted, 100 applied 
70% 
70 females accepted, 100 applied 
EE 
100% 
1 male accepted, 1 applied 
Overall  70 females accepted, 101 applied  ≈ 70% 
51 males accepted, 101 applied  ≈ 51% 

In this case, a higher percentage of males were accepted in both departments, but 
overall a higher percentage of females were accepted! Bizarre! 

18.3.7  A Posteriori Probabilities 
Suppose that we turn the hockey question around: what is the probability that the 
Halting Problem won their ﬁrst game, given that they won the series? 
This  seems  like an absurd question!  After all,  if  the Halting Problem won  the 
series,  then  the winner of  the ﬁrst game has already been determined.  Therefore, 
who won  the ﬁrst game  is  a question of  fact,  not  a question of probability.  How­
ever, our mathematical  theory of probability contains no notion of one event pre­
ceding  another—  there  is  no  notion  of  time  at  all.  Therefore,  from  a mathemati­
cal  perspective,  this  is  a  perfectly  valid  question.  And  this  is  also  a  meaningful 
question  from  a  practical  perspective.  Suppose  that  you’re  told  that  the  Halting 
Problem won  the  series,  but not  told  the  results of  individual games.  Then,  from 
your perspective, it makes perfect sense to wonder how likely it is that The Halting 
Problem won the ﬁrst game. 
A  conditional  probability  Pr {B  |  A}  is  called  a  posteriori  if  event  B  precedes 
event A in time. Here are some other examples of a posteriori probabilities: 

18.3.  CONDITIONAL PROBABILITY 

435 

•	 The probability  it was cloudy this morning, given that  it rained  in the after­
noon. 

•	 The probability that I was initially dealt two queens in Texas No Limit Hold 
’Em poker, given that I eventually got four-of-a-kind. 
Mathematically,  a  posteriori  probabilities  are  no  different  from  ordinary  probabil­
ities;  the  distinction  is  only  at  a  higher,  philosophical  level.  Our  only  reason  for 
drawing attention to them is to say, “Don’t let them rattle you.” 
Let’s return  to  the original problem.  The probability  that  the Halting Problem 
won their ﬁrst game, given that they won the series is Pr {B  |  A}. We can compute 
this using the deﬁnition of conditional probability and our earlier tree diagram: 
Pr {B ∩ A}
Pr {B A} = 
| 
Pr {A}
1/3 + 1/18 
= 
1/3 + 1/18 + 1/9 
7 = 
9 
This answer is suspicious!  In the preceding section, we showed that Pr {A  |  B }
was  also  7/9.  Could  it  be  true  that  Pr {A  |  B }  =  Pr {B  |  A}  in  general?  Some 
reﬂection suggests this is unlikely.  For example, the probability that I feel uneasy, 
given that I was abducted by aliens,  is pretty large.  But the probability that I was 
abducted by aliens, given that I feel uneasy, is rather small. 
Let’s work  out  the  general  conditions  under which  Pr {A  |  B }  =  Pr {B  |  A}. 
By the deﬁnition of conditional probability, this equation holds if an only if: 
Pr {A ∩ B } 
Pr {A ∩ B }
Pr {A} 
Pr {B } 
This equation,  in turn, holds only if the denominators are equal or the numerator 
is 0: 
Pr {B } = Pr {A} 
Pr {A ∩ B } = 0 
or 
The former condition holds in the hockey example; the probability that the Halting 
Problem wins  the  series  (event A)  is  equal  to  the probability  that  it wins  the ﬁrst 
game (event B ).  In fact, both probabilities are 1/2. 
Such pairs of probabilities are related by Bayes’ Rule: 
Theorem 18.3.2 (Bayes’ Rule).  If Pr {A} and Pr {B } are nonzero, then: 
Pr {A  |  B } · Pr {B }  = Pr {B	
|  A} 
Pr {A}
Proof.  When Pr {A} and Pr {B } are nonzero, we have 
Pr {A  |  B } · Pr {B } = Pr {A ∩ B } = Pr {B  |  A} · Pr {A} 
by deﬁnition of conditional probability. Dividing by Pr {A} gives (18.4). 

(18.4)

= 

� 

436 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

In  the hockey problem,  the probability  that  the Halting Problem wins  the ﬁrst 
game  is  1/2  and  so  is  the  probability  that  the  Halting  Problem  wins  the  series. 
Therefore, Pr {A}  =  Pr {B }  = 1/2.  This,  together with Bayes’ Rule, explains why 
Pr {A  |  B } and Pr {B  |  A} turned out to be equal in the hockey example. 

18.3.8  Problems 
Practice Problems 

Problem 18.9. 
Dirty Harry  places  two  bullets  in  the  six-shell  cylinder  of  his  revolver.  He  gives 
the cylinder a random spin and says “Feeling lucky?”  as he holds the gun against 
your heart. 
(a)  What is the probability that you will get shot if he pulls the trigger? 

(b)  Suppose he pulls  the  trigger and you don’t get  shot.  What  is  the probability 
that you will get shot if he pulls the trigger a second time? 

(c)  Suppose  you  noticed  that  he  placed  the  two  shells  next  to  each  other  in  the 
cylinder. How does this change the answers to the previous two questions? 

Class Problems 

Problem 18.10. 
There are two decks of cards.  One  is complete, but the other  is missing the ace of 
spades.  Suppose  you  pick  one  of  the  two  decks with  equal  probability  and  then 
select  a  card  from  that  deck  uniformly  at  random.  What  is  the  probability  that 
you picked the complete deck, given that you selected the eight of hearts? Use the 
four-step method and a tree diagram. 

Problem 18.11. 
There  are  three prisoners  in  a maximum-security prison  for ﬁctional  villains:  the 
Evil  Wizard  Voldemort,  the  Dark  Lord  Sauron,  and  Little  Bunny  Foo-Foo.  The 
parole  board  has  declared  that  it  will  release  two  of  the  three,  chosen  uniformly 
at random, but has not yet released their names.  Naturally, Sauron ﬁgures that he 
will  be  released  to  his  home  in Mordor,  where  the  shadows  lie,  with  probability 
2/3. 
A guard offers to tell Sauron the name of one of the other prisoners who will be 
released  (either Voldemort or Foo-Foo).  Sauron knows  the guard  to be  a  truthful 
fellow.  However,  Sauron  declines  this  offer.  He  reasons  that  if  the  guard  says, 
for  example,  “Little  Bunny  Foo-Foo  will  be  released”,  then  his  own  probability 
of  release  will  drop  to  1/2.  This  is  because  he  will  then  know  that  either  he  or 
Voldemort will also be released, and these two events are equally likely. 
Using a tree diagram and the four-step method, either prove that the Dark Lord 
Sauron has reasoned correctly or prove that he is wrong. Assume that if the guard 

18.3.  CONDITIONAL PROBABILITY 

437 

has  a  choice  of  naming  either  Voldemort  or  Foo-Foo  (because  both  are  to  be  re­
leased), then he names one of the two uniformly at random. 

Homework Problems 

Problem 18.12. 
There  is a course —not 6.042, naturally —in which 10% of  the assigned problems 
contain errors.  If you ask a TA whether a problem has an error, then he or she will 
answer correctly 80% of  the  time.  This 80% accuracy holds regardless of whether 
or not a problem has an error. Likewise when you ask a lecturer, but with only 75% 
accuracy. 
We  formulate  this  as  an  experiment  of  choosing  one  problem  randomly  and 
asking a particular TA and Lecturer about it. Deﬁne the following events: 

E 
T 
L 

::=  “the problem has an error,”

::=  “the TA says the problem has an error,”

::=  “the lecturer says the problem has an error.”


(a)  Translate  the description above  into a precise set of equations  involving con­
ditional probabilities among the events E , T , and L 

(b)  Suppose  you  have  doubts  about  a  problem  and  ask  a  TA  about  it,  and  she 
tells you that the problem is correct. To double-check, you ask a lecturer, who says 
that the problem has an error.  Assuming that the correctness of the  lecturers’ answer 
and the TA’s answer are independent of each other, regardless of whether there is an error2 , 
what is the probability that there is an error in the problem? 

(c)  Is the event that “the TA says that there is an error ”, independent of the event 
that “the lecturer says that there is an error ”? 

Problem 18.13.  (a)  Suppose  you  repeatedly  ﬂip  a  fair  coin  until  you  see  the  se­
quence  HHT  or  the  sequence  TTH. What  is  the  probability  you will  see  HHT  ﬁrst? 
Hint:  Symmetry between Heads and Tails. 

(b)  What is the probability you see the sequence HTT before you see the sequence 
HHT? Hint:  Try to ﬁnd the probability that HHT comes before HTT conditioning on 
whether you ﬁrst toss an H or a T. The answer is not 1/2. 

Problem 18.14. 
A 52-card deck is thoroughly shufﬂed and you are dealt a hand of 13 cards. 
(a)  If you have one ace, what is the probability that you have a second ace? 

2 This assumption  is questionable:  by and  large, we would expect  the  lecturer and  the TA’s  to  spot 
the same glaring errors and to be fooled by the same subtle ones. 

438 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

(b)  If you have  the ace of spades, what  is  the probability that you have a second 
ace? 
Remarkably, the two answers are different.  This problem will test your count­
ing ability! 

Problem 18.15. 
You are organizing a neighborhood census and instruct your census takers to knock 
on doors and note the sex of any child that answers the knock.  Assume that there 
are  two  children  in  a  household  and  that  girls  and  boys  are  equally  likely  to  be 
children and to open the door. 
A sample space for this experiment has outcomes that are triples whose ﬁrst el­
ement is either B or G for the sex of the elder child, likewise for the second element 
and  the  sex of  the younger child,  and whose  third coordinate  is E or Y  indicating 
whether the elder child or younger child opened the door.  For example, (B, G, Y) is 
the  outcome  that  the  elder  child  is  a  boy,  the  younger  child  is  a  girl,  and  the  girl 
opened the door. 
(a)  Let T be the event that the household has two girls, and O be the event that a 
girl opened the door. List the outcomes in T and O. 
(b)  What  is  the  probability  Pr {T  |  O},  that  both  children  are  girls,  given  that  a 
girl opened the door? 

(c)  Where is the mistake in the following argument? 

If a girl opens the door, then we know that there is at least one girl in the 
household. The probability that there is at least one girl is 
1 − Pr {both children are boys} = 1 − (1/2 × 1/2) = 3/4. 

(18.5) 

So, 

Pr {T  |  there is at least one girl in the household} 
Pr {T  ∩ there is at least one girl in the household}
= 
Pr {there is at least one girl in the household} 
Pr {T }
Pr {there is at least one girl in the household}
=  (1/4)/(3/4) = 1/3. 

= 

(18.6) 

(18.7) 

(18.8) 

(18.9) 

Therefore,  given  that  a  girl  opened  the  door,  the  probability  that  there 
are two girls in the household is 1/3. 

18.4  Independence 

Suppose  that  we  ﬂip  two  fair  coins  simultaneously  on  opposite  sides  of  a  room.

Intuitively,  the  way  one  coin  lands  does  not  affect  the  way  the  other  coin  lands.


18.4.  INDEPENDENCE 

439 

The mathematical concept that captures this intuition is called independence: 
Deﬁnition.  Events A and B  are independent if and only if: 
Pr {A ∩ B } = Pr {A} · Pr {B } 
Generally, independence is something you assume in modeling a phenomenon— 
or  wish  you  could  realistically  assume.  Many  useful  probability  formulas  only 
hold if certain events are independent, so a dash of independence can greatly sim­
plify the analysis of a system. 

18.4.1  Examples 
Let’s  return  to  the  experiment  of  ﬂipping  two  fair  coins.  Let A  be  the  event  that 
the ﬁrst coin comes up heads, and let B be the event that the second coin is heads. 
If we  assume  that A  and B  are  independent,  then  the probability  that  both  coins 
come up heads is: 

Pr {A ∩ B } = Pr {A} · Pr {B }
1 1 
· 
= 
2 
2 
1 = 
4 
On  the  other  hand,  let  C  be  the  event  that  tomorrow  is  cloudy  and  R  be  the 
event  that  tomorrow  is  rainy.  Perhaps  Pr {C }  = 1/5  and  Pr {R}  = 1/10  around 
here.  If these events were independent, then we could conclude that the probabil­
ity of a rainy, cloudy day was quite small: 
Pr {R ∩ C } = Pr {R} · Pr {C }
1 
1
· 
= 
5 
10 
1 = 
50 
Unfortunately,  these  events  are  deﬁnitely  not  independent;  in  particular,  every 
rainy day is cloudy. Thus, the probability of a rainy, cloudy day is actually 1/10. 

18.4.2  Working with Independence 
There  is  another way  to  think  about  independence  that  you may  ﬁnd more  intu­
itive.  According  to  the deﬁnition,  events A  and B  are  independent  if  and  only  if 
Pr {A ∩ B } = Pr {A} ·Pr {B }. This equation holds even if Pr {B } = 0, but assuming 
it  is not, we can divide both sides by Pr {B } and use  the deﬁnition of conditional 
probability to obtain an alternative formulation of independence: 
Proposition.  If Pr {B } = 0, then events A and B  are independent if and only if 
Pr {A  |  B } = Pr {A} . 

(18.10) 

�
440 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

Equation  (18.10)  says  that  events  A  and  B  are  independent  if  the  probability 
of A  is unaffected by  the  fact  that B  happens.  In  these  terms,  the  two  coin  tosses 
of  the  previous  section  were  independent,  because  the  probability  that  one  coin 
comes up heads is unaffected by the fact that the other came up heads.  Turning to 
our other example,  the probability of clouds  in  the sky  is strongly affected by  the 
fact that it is raining.  So, as we noted before, these events are not independent. 
Warning: Students sometimes get the idea that disjoint events are independent. 
The opposite is true:  if A ∩ B  =  ∅, then knowing that A happens means you know 
that B  does not happen.  So disjoint events are never  independent —unless one of 
them has probability zero. 

18.4.3  Mutual Independence 
We have deﬁned what it means for two events to be independent. But how can we 
talk about independence when there are more than two events? For example, how 
can we say that the orientations of n coins are all independent of one another? 
Events E1 , . . . , En  are mutually  independent  if  and only  if  for  every  subset of  the 
events,  the  probability  of  the  intersection  is  the  product  of  the  probabilities.  In 
other words, all of the following equations must hold: 
Pr {Ei  ∩ Ej } = Pr {Ei } · Pr {Ej } 
Pr {Ei  ∩ Ej  ∩ Ek } = Pr {Ei } · Pr {Ej } · Pr {Ek } 
Pr {Ei  ∩ Ej  ∩ Ek  ∩ El } = Pr {Ei } · Pr {Ej } · Pr {Ek } · Pr {El } 
. . . 
Pr {E1  ∩ · · · ∩ En} = Pr {E1} · · · Pr {En} 

for all distinct i, j 
for all distinct i, j , k 
for all distinct i, j , k , l 

As  an  example,  if we  toss  100  fair  coins  and  let  Ei  be  the  event  that  the  ith  coin 
lands heads,  then we might reasonably assume that E1 , . . . , E100  are mutually  in­
dependent. 

18.4.4  Pairwise Independence 
The deﬁnition of mutual independence seems awfully complicated— there are so 
many conditions!  Here’s an example that illustrates the subtlety of independence 
when  more  than  two  events  are  involved  and  the  need  for  all  those  conditions. 
Suppose that we ﬂip three fair, mutually-independent coins.  Deﬁne the following 
events: 

•  A1  is the event that coin 1 matches coin 2. 

•  A2  is the event that coin 2 matches coin 3. 

•  A3  is the event that coin 3 matches coin 1. 

Are A1 , A2 , A3  mutually independent? 

18.4.  INDEPENDENCE 

441 

The sample space for this experiment is: 
{HHH,  HH T ,  H T H,  H T T ,  T HH,  T H T ,  T T H,  T T T } 

Every outcome has probability (1/2)3  = 1/8 by our assumption that the coins are 
mutually independent. 
To  see  if  events  A1 ,  A2 ,  and  A3  are  mutually  independent,  we  must  check  a 
sequence  of  equalities.  It will  be  helpful  ﬁrst  to  compute  the  probability  of  each 
event Ai : 

Pr {A1} = Pr {HHH } + Pr {HH T } + Pr {T T H } + Pr {T T T }
1 
1
1
1
= + + +
8
8
8
8 
1 = 
2 
By  symmetry,  Pr {A2 }  =  Pr {A3}  = 1/2  as well.  Now we  can  begin  checking  all 
the equalities required for mutual independence. 
Pr {A1  ∩ A2} = Pr {HHH } + Pr {T T T }
1 
1
= +
8
8 
1 = 
4 
1 1 
· 
= 
2 
2 
= Pr {A1 } Pr {A2} 
By  symmetry,  Pr {A1  ∩ A3}  =  Pr {A1 } ·  Pr {A3}  and  Pr {A2  ∩ A3}  =  Pr {A2} · 
Pr {A3 } must hold also.  Finally, we must check one last condition: 
Pr {A1  ∩ A2  ∩ A3 } = Pr {HHH } + Pr {T T T }
1 
1
= +
8
8 
1 = 
4 
= Pr {A1} Pr {A2} Pr {A3 } =

1 
8 

The  three  events A1 ,  A2 ,  and A3  are  not mutually  independent  even  though  any 
two of them are independent! This not-quite mutual independence seems weird at 
ﬁrst, but it happens.  It even generalizes: 

Deﬁnition  18.4.1.  A  set  A0 , A1 , . . .  of  events  is  k-way  independent  iff  every  set  of 
k  of  these  events  is mutually  independent.  The  set  is  pairwise  independent  iff  it  is 
2-way independent. 

�
442 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

So  the  sets  A1 , A2 , A3  above  are  pairwise  independent,  but  not  mutually  in­
dependent.  Pairwise  independence  is  a  much  weaker  property  than  mutual  in­
dependence,  but  it’s  all  that’s  needed  to  justify  a  standard  approach  to  making 
probabilistic estimates that will come up later. 

18.4.5  Problems 
Class Problems 

Problem 18.16. 
Suppose that you ﬂip three fair, mutually independent coins. Deﬁne the following 
events: 

•  Let A be the event that the ﬁrst coin is heads. 

•  Let B be the event that the second coin is heads. 

•  Let C  be the event that the third coin is heads. 

•  Let D be the event that an even number of  coins are heads. 

(a)  Use  the  four  step method  to  determine  the  probability  space  for  this  experi­
ment and the probability of each of A, B , C, D . 

(b)  Show that these events are not mutually independent. 

(c)  Show that they are 3-way independent. 

18.5  The Birthday Principle 

There  are  85  students  in  a  class.  What  is  the  probability  that  some  birthday  is 
shared by two people?  Comparing 85 students to the 365 possible birthdays, you 
might guess the probability lies somewhere around 1/4 —but you’d be wrong:  the 
probability  that  there  will  be  two  people  in  the  class  with matching  birthdays  is 
actually more than 0.9999. 
To work this out, we’ll assume that the probability that a randomly chosen stu­
dent  has  a  given  birthday  is  1/d,  where  d  =  365  in  this  case.  We’ll  also  assume 
that a class is composed of n randomly and independently selected students, with 
n = 85 in this case.  These randomness assumptions are not really true, since more 
babies  are  born  at  certain  times  of  year,  and  students’  class  selections  are  typi­
cally  not  independent  of  each  other,  but  simplifying  in  this  way  gives  us  a  start 
on analyzing  the problem.  More  importantly,  these assumptions are  justiﬁable  in 
important  computer  science  applications of birthday matching.  For  example,  the 
birthday matching is a good model for collisions between items randomly inserted 
into a hash  table.  So we won’t worry about  things  like Spring procreation prefer­
ences  that make  January birthdays more  common,  or about  twins’ preferences  to 
take classes together (or not). 

18.5.  THE BIRTHDAY PRINCIPLE 

443 

Selecting a sequence of n students for a class yields a sequence of n birthdays. 
Under  the  assumptions  above,  the  dn  possible  birthday  sequences  are  equally 
likely outcomes.  Let’s examine  the consequences of  this probability model by  fo­
cussing on the ith and j th elements in a birthday sequence, where 1 ≤  i =�
j  ≤  n. 
It makes for a better story if we refer to the ith birthday as “Alice’s” and the j th as 
“Bob’s.” 
Now  since  Bob’s  birthday  is  assumed  to  be  independent  of Alice’s,  it  follows 
that whichever  of  the  d  birthdays Alice’s  happens  to  be,  the  probability  that  Bob 
has  the  same  birthday  1/d.  Next,  If  we  look  at  two  other  birthdays —call  them 
“Carol’s”  and  “Don’s”  —then  whether  Alice  and  Bob  have  matching  birthdays 
has  nothing  to  do  with  whether  Carol  and  Don  have  matching  birthdays.  That 
is,  the  event  that  Alice  and  Bob  have  matching  birthdays  is  independent  of  the 
event  that  Carol  and  Don  have  matching  birthdays.  In  fact,  for  any  set  of  non-
overlapping couples, the events that a couple has matching birthdays are mutually 
independent. 
In  fact,  it’s pretty  clear  that  the  probability  that Alice  and Bob  have matching 
birthdays  remains  1/d  whether  or  not  Carol  and  Alice  have  matching  birthdays. 
That is, the event that Alice and Bob match is also independent of Alice and Carol 
matching.  In short, the set of all events in which a couple has macthing birthdays 
is  pairwise  independent,  despite  the  overlapping  couples.  This will  be  important 
in Chapter 21 because pairwise independence will be enough to justify some con­
clusions about the expected number of matches.  However,  it’s obvious  that these 
matching birthday events are not mutually independent, not even 3-way indepen­
dent:  if Alice and Bob match and also Alice and Carol match, then Bob and Carol 
will match. 
We  could  justify  all  these  assertions  of  independence  routinely using  the  four 
step method, but it’s pretty boring, and we’ll skip it. 
It  turns  out  that  as  long  as  the  number  of  students  is  noticeably  smaller  than 
the number of possible birthdays, we  can get a pretty good  estimate of  the birth­
day  matching  probabilities  by  pretending  that  the  matching  events  are  mutually 
independent.  (An  intuitive  justiﬁcation  for  this  is  that with  only  a  small  number 
�  � 
of matching pairs,  it’s  likely  that none of  the pairs overlap.)  Then  the probability 
of no matching birthdays would be the same as rth power of the probability that a 
couple does not have matching birthdays, where r ::=  n 
2  is the number of couples. 
That is, the probability of no matching birthdays would be 
(1 − 1/d)(n 
2 )
�  � 
Using the fact that e > 1 + x for all x,3  we would conclude that the probability of 
x
no matching birthdays is at most 
n 
− 
2 
(18.12) 
d . 
e
3 This approximation is obtained by truncating the Taylor series e−x  = 1 − x + x2 /2! − x3 /3! + · · · . 
The approximation e−x  ≈ 1 − x is pretty accurate when x is small. 

(18.11) 

. 

444 

CHAPTER 18.  INTRODUCTION TO PROBABILITY 

The matching  birthday  problem  ﬁts  in  here  so  far  as  a  nice  example  illustrat­
ing  pairwise  and  mutual  independence.  But  it’s  actually  not  hard  to  justify  the 
bound (18.12) without any pretence or any explicit consideration of independence. 
Namely,  there  are  d(d − 1)(d − 2) 
(d − (n − 1))  length  n  sequences  of  distinct 
· · · 
birthdays.  So the probability that everyone has a different birthday is: 
(d − (n − 1))
d(d − 1)(d − 2) 
· · · 
dn 
d − (n − 1)
d d − 1  d − 2 
� 
� � 
� � 
�
�
· · · 
· 
· 
= 
d 
d 
d 
d
2 
1 
0 
=  1 − 
· · ·  1 − 
1 − 
1 − 
d 
d 
d 
· 
· · · 
· 
0  e−1/d  e−2/d 
e−(n−1)/d
= e−(P 
< e
n−1 
i=1  i/d) 
= e−(n(n−1)/2d) 
= the bound (18.12). 

� 
n − 1 
d 

(since 1 + x < ex )

For n = 85 and d = 365, (18.12) is less than 1/17, 000, which means the probabil­
ity of having some pair of matching birthdays actually is more than 1 − 1/17, 000 > 
0.9999.  So  it would  be  pretty  astonishing  if  there were  no  pair  of  students  in  the 
class with matching birthdays. 
For d ≤  n2/2, the probability of no match turns out to be asymptotically equal 
to the upper bound (18.12).  For d = n2 /2 in particular, the probability of no match 
is  asymptotically  equal  to  1/e.  This  leads  to  a  rule  of  thumb  which  is  useful  in 
many contexts in computer science: 

The Birthday Principle 
√
2d  people  in  a  room,  then  the  probability  that 
If  there  are  d  days  in  a  year  and 
two share a birthday is about 1 − 1/e ≈ 0.632. 

√
2  365 ≈ 27 people
· 
For example, the Birthday Principle says that if you have 
in a room, then the probability that two share a birthday is about 0.632. The actual 
probability is about 0.626, so the approximation is quite good. 
Among other applications, the Birthday Principle famously comes into play as 
the basis of “birthday attacks” that crack certain cryptographic systems. 

Chapter 19 

Random Processes 

Random Walks are used to model situations in which an object moves in a sequence 
of steps in randomly chosen directions. For example in Physics, three-dimensional 
random walks are used to model Brownian motion and gas diffusion.  In this chap­
ter we’ll examine  two examples of random walks.  First, we’ll model gambling as 
a  simple  1-dimensional  random  walk —a  walk  along  a  straight  line.  Then  we’ll 
explain  how  the Google  search  engine  used  random walks  through  the  graph  of 
world-wide web links to determine the relative importance of websites. 

19.1  Gamblers’ Ruin 

a Suppose a gambler starts with an initial stake of n dollars and makes a sequence 
of $1 bets.  If he wins an individual bet, he gets his money back plus another $1.  If 
he loses, he loses the $1. 
We  can model  this  scenario  as  a  random  walk  between  integer  points  on  the 
reall line.  The position on the line at any time corresponds to the gambler ’s cash-
on-hand  or  capital.  Walking  one  step  to  the  right  (left)  corresponds  to  winning 
(losing) a $1 bet and thereby increasing (decreasing) his capital by $1. The gambler 
plays  until  either  he  is  bankrupt  or  increases  his  capital  to  a  target  amount  of  T 
dollars.  If he  reaches his  target,  then he  is  called an overall winner,  and his proﬁt, 
m,  will  be  T  −  n  dollars.  If  his  capital  reaches  zero  dollars  before  reaching  his 
target, then we say that he is “ruined” or goes broke. We’ll assume that the gambler 
has the same probability, p, of winning each individual $1 bet and that the bets are 
mutually independent. We’d like to ﬁnd the probability that the gambler wins. 
The  gambler ’s  situation  as  he  proceeds  with  his  $1  bets  is  illustrated  in  Fig­
ure  19.1.  The  random walk  has  boundaries  at  0  and  T .  If  the  random walk  ever 
reaches either of these boundary values, then it terminates. 
In a  fair game,  the gambler  is equally  likely  to win or  lose each bet,  that  is p  = 
1/2. The corresponding random walk is called unbiased. The gambler is more likely 
to win  if p >  1/2 and  less  likely  to win  if p <  1/2;  these random walks are called 

445 

446 

CHAPTER 19.  RANDOM PROCESSES 

Figure 19.1:  This is a graph of the gambler ’s capital versus time for one possible sequence 
of  bet  outcomes.  At  each  time  step,  the  graph  goes  up with  probability  p  and  down with 
probability 1 − p. The gambler continues betting until the graph reaches either 0 or T . 

biased. We want to determine the probability that the walk terminates at boundary 
T , namely,  the probability  that  the gambler  is a winner.  We’ll do  this by showing 
that the probability satisﬁes a simple linear recurrence and solving the recurrence, 
but before we derive the probability, let’s just look at what it turns out to be. 
Let’s  begin  by  supposing  the  coin  is  fair,  the  gambler  starts  with  100  dollars, 
and he wants to double his money. That is, he plays until he goes broke or reaches 
a target of 200 dollars.  Since he starts equidistant from his target and bankruptcy, 
it’s clear by symmetry that his probability of winning in this case is 1/2. 
We’ll show below that starting with n dollars and aiming for a target of T  ≥ n 
dollars,  the  probability  the  gambler  reaches  his  target  before  going  broke  is  n/T . 
For  example,  suppose  he want  to win  the  same  $100,  but  instead  starts  out with 
$500.  Now  his  chances  are  pretty  good:  the  probability  of  his  making  the  100 
dollars  is  5/6.  And  if he  started with one million dollars  still  aiming  to win  $100 
dollars he almost certain to win:  the probability is 1M /(1M  + 100) > .9999. 
So  in the fair game,  the  larger the  initial stake relative to the target,  the higher 
the probability the gambler will win, which makes some intuitive sense.  But note 
that although the gambler now wins nearly all the time, the game is still fair. When 
he  wins,  he  only  wins  $100;  when  he  loses,  he  loses  big:  $1M.  So  the  gambler ’s 
average win is actually zero dollars. 
Now suppose instead that the gambler chooses to play roulette in an American 
casino,  always  betting  $1  on  red.  A  roulette wheel  has  18  black  numbers,  18  red 
numbers,  and  2  green  numbers,  designed  so  that  each  number  is  equally  likely 
to  appear.  So  this  game  is  slightly  biased  against  the  gambler:  the  probability 
of  winning  a  single  bet  is  p  =  18/38  ≈  0.47.  It’s  the  two  green  numbers  that 

capitalgambler’snT = n + mtimebet outcomes:WLLWLWWLLL19.1.  GAMBLERS’ RUIN 

447 

slightly bias the bets and give the casino an edge.  Still, the bets are almost fair, and 
you might expect  that  starting with $500,  the gambler has a  reasonable  chance of 
winning  $100 —the  5/6 probability  of winning  in  the unbiased  game  surely  gets 
reduced, but perhaps not too drastically. 
Not so! The gambler ’s odds of winning $100 making one dollar bets against the 
“slightly” unfair roulette wheel are  less than 1  in 37,000.  If that seems surprising, 
listen  to  this:  no matter how much money  the gambler has  to start —$5000, $50,000, 
· 
$5  1012  —his odds are still less than 1 in 37,000 of winning a mere 100 dollars! 
Moral: Don’t play! 
The theory of random walks is ﬁlled with such fascinating and counter-intuitive 
conclusions. 

19.1.1  A Recurrence for the Probability of Winning 
The  probability  the  gambler wins  is  a  function  of  his  initial  capital,  n,  his  target, 
T  ≥ n, and the probability, p, that he wins an individual one dollar bet.  Let’s let p 
and T  be ﬁxed, and let wn  be the gambler ’s probabiliity of winning when his initial 
capital  is  n  dollars.  For  example,  w0  is  the  probability  that  the  gambler will win 
given  that he  starts off broke and wT  is  the probability he will win  if he  starts off 
with his target amount, so clearly 

w0  = 0, 
wT  = 1. 

(19.1) 
(19.2) 

Otherwise,  the gambler  starts with n dollars, where 0  < n < T .  Consider  the 
outcome of his ﬁrst bet.  The gambler wins  the ﬁrst bet with probability p.  In  this 
case, he is left with n + 1 dollars and becomes a winner with probability wn+1 . On 
the other hand, he loses the ﬁrst bet with probability q ::= 1 − p. Now he is left with 
n − 1 dollars and becomes a winner with probability wn−1 . By the Total Probability 
Rule, he wins with probability wn  = pwn+1  + qwn−1 .  Solving for wn+1  we have 
wn  − rwn−1 
p 

wn+1  = 

(19.3) 

where 

q 
r ::= 
. 
p 
This recurrence holds only for n + 1 ≤ T , but there’s no harm in using (19.3) to 
deﬁne wn+1  for all n + 1 > 1. Now, letting 
W (x) ::= w0  + w1x + w2x 2  + · · · 

be  the  generating  function  for  the wn , we derive  from  (19.3)  and  (19.1) using  our 
generating function methods that 

xW (x) = 

w1x
, 
(1 − x)(1 − rx) 

(19.4)

448 

so if p =�

CHAPTER 19.  RANDOM PROCESSES 
� 
� 
q , then using partial fractions we can calculate that 
1
, 
1 − rx 

1 
1 − x

w1 
r − 1

W (x) = 

− 

which implies 

(19.5) 

w1  = 

− 1 
nr
wn  = w1 
. 
r − 1 
Now we can use (19.5) to solve for w1  by letting n = T  to get 
r − 1 
. 
rT  − 1 
Plugging this value of w1  into (19.5), we ﬁnally arrive at the solution: 
− 1 
. 
− 1 
The  expression  (19.6)  for  the  probability  that  the  Gambler  wins  in  the  biased 
game  is a  little hard  to  interpret.  There  is a simpler upper bound which  is nearly 
tight when the gambler ’s starting capital is large and the game is biased against the 
gambler.  Then  both  the  numerator  and denominator  in  the  quotient  in  (19.6)  are 
positive, and the quotient is less than one. This implies that 

wn  = 

(19.6)

n 

r
T 
r

wn  <

n 
r = r T −n , 
rT 

which proves: 

Pr {the gambler is a winner} <

Corollary 19.1.1.  In the Gambler ’s Ruin game with probability p < 1/2 of winning each 
� �T −n 
individual bet, with initial capital, n, and target, T , 
p 
q 
The amount T  − n is called the Gambler ’s intended proﬁt.  So the gambler gains 
his  intended  proﬁt  before  going  broke with  probability  at most  p/q  raised  to  the 
intended-proﬁt power. Notice that this upper bound does not depend on the gam­
bler ’s starting capital, but only on his intended proﬁt. This has the amazing conse­
quence we announced above:  no matter how much money he starts with, if he makes 
� 
� 
9  �100 
18/38 �100 
$1  bets  on  red  in  roulette  aiming  to win  $100,  the  probability  that  he wins  is  less 
than 
10
20/38 

1 
.
37, 648 

(19.7) 

= 

<

The  bound  (19.7)  is  exponential  in  the  intended  proﬁt.  So,  for  example,  dou­
bling his  intended proﬁt will square his probability of winning.  In particular,  the 

19.1.  GAMBLERS’ RUIN 

449 

probability that the gambler ’s stake goes up 200 dollars before he goes broke play­
�2
�
ing roulette is at most 
1
37, 648 

(9/10)200  = ((9/10)100 )2  = 

,

which is about 1 in 70 billion. 
The solution  (19.6) only applies  to biased walks, but  the method above works 
just as well in getting a formula for the unbiased case (except that the partial frac­
tions involve a repeated root).  But it’s simpler settle the fair case simply by taking 
the  limit  as  r  approaches  1  of  (19.6).  By  L’Hopital’s  Rule  this  limit  is  n/T ,  as we 
claimed above. 

19.1.2  Intuition 
Why  is  the gambler  so unlikely  to make money when  the game  is  slightly biased 
against  him?  Intuitively,  there  are  two  forces  at work.  First,  the  gambler ’s  capi­
tal has random upward and downward swings due to runs of good and bad luck. 
Second, the gambler ’s capital will have a steady, downward drift, because the neg­
ative  bias  means  an  average  loss  of  a  few  cents  on  each  $1  bet.  The  situation  is 
shown in Figure 19.2. 
Our intuition is that if the gambler starts with, say, a billion dollars,  then he is 
sure to play for a very long time, so at some point there should be a lucky, upward 
swing that puts him $100 ahead. The problem is that his capital is steadily drifting 
downward.  If the gambler does not have a lucky, upward swing early on, then he is 
doomed. After his capital drifts downward a few hundred dollars, he needs a huge 
upward  swing  to  save himself.  And  such a huge  swing  is extremely  improbable. 
As a rule of thumb, drift dominates swings in the long term. 

19.1.3  Problems 
Homework Problems 

Problem 19.1. 
A  drunken  sailor  wanders  along main  street,  which  conveniently  consists  of  the 
points  along  the  x  axis  with  integral  coordinates.  In  each  step,  the  sailor moves 
one unit  left or right along  the x axis.  A particular path  taken by  the sailor can be 
described  by  a  sequence  of  “left”  and  “right”  steps.  For  example,  �left,left,right�
describes the walk that goes left twice then goes right. 
We model  this  scenario with  a  random walk  graph whose  vertices  are  the  in­
tegers  and with  edges  going  in  each  direction  between  consecutive  integers.  All 
edges are labelled 1/2. 
The sailor begins his random walk at the origin.  This is described by an initial 
distribution which  labels  the origin with probability  1  and  all other vertices with 
probability  0.  After one  step,  the  sailor  is  equally  likely  to be  at  location  1 or −1, 

450 

CHAPTER 19.  RANDOM PROCESSES 

Figure 19.2:  In an unfair game, the gambler ’s capital swings randomly up and down, but 
steadily drifts downward.  If the gambler does not have a winning swing early on, then his 
capital drifts downward, and later upward swings are insufﬁcient to make him a winner. 

so the distribution after one step gives label 1/2 to the vertices 1 and −1 and labels 
all other vertices with probability 0. 
(a)  Give  the  distributions  after  the  2nd,  3rd,  and  4th  step  by  ﬁlling  in  the  table 
of  probabilities  below,  where  omitted  entries  are  0.  For  each  row,  write  all  the 
nonzero entries so they have the same denominator. 
location 
0 
-1 
1 
1/2  0  1/2 
? 
? 
? 
? 
? 
? 
? 
? 
? 

initially 
after 1 step 
after 2 steps 
after 3 steps 
after 4 steps 

2  3  4 

? 
? 
? 

-4 

-3 

-2 

? 
? 

? 

? 
? 

? 

1 

? 
? 
? 

(b) 

1.  What is the ﬁnal location of a t-step path that moves right exactly i times? 
2.  How many different paths are there that end at that location? 
3.  What is the probability that the sailor ends at this location? 

(c)  Let L be the random variable giving the sailor ’s location after t steps, and let 
B ::= (L + t)/2. Use the answer to part (b) to show that B has an unbiased binomial 
density function. 

T = n + mtimegambler’scapitalndownwarddriftswingupward(too late!)19.2.  RANDOM WALKS ON GRAPHS 

451 

< 

. 

(d)  Again  let  L  be  the  random  variable  giving  the  sailor ’s  location  after  t  steps, 
� 
� 
where t is even.  Show that 
√
t 
|L| < 
Pr 
2 

1
2 

√
t/2 steps from 
So there is a better than even chance that the sailor ends up at least 
where he started. 
Hint: Work in terms of B .  Then you can use an estimate that bounds the binomial 
distribution.  Alternatively, observe that the origin is the most likely ﬁnal location 
� 
and then use the asymptotic estimate 
2 
.
πt 

Pr {L = 0} = Pr {B = t/2} ∼ 

19.2  Random Walks on Graphs 

The hyperlink structure of the World Wide Web can be described as a digraph. The 
vertices are  the web pages with a directed edge  from vertex x  to vertex y  if x has 
a link to y .  For example, in the following graph the vertices x1 , . . . , xn  correspond 
to web pages and xi  → xj  is a directed edge when page xi  contains a hyperlink to 
page xj . 

The web  graph  is  an  enormous  graph with many  billions  and  probably  even 
trillions  of  vertices.  At  ﬁrst  glance,  this  graph  wouldn’t  seem  to  be  very  inter­
esting.  But  in  1995,  two  students  at  Stanford,  Larry  Page  and  indexBrin,  Sergey 
Sergey Brin realized that the structure of this graph could be very useful in build­
ing  a  search  engine.  Traditional  document  searching  programs  had  been  around 
for  a  long  time  and  they  worked  in  a  fairly  straightforward  way.  Basically,  you 
would enter  some search  terms and  the searching program would  return all doc­
uments containing those terms.  A relevance score might also be returned for each 
document  based  on  the  frequency  or  position  that  the  search  terms  appeared  in 

x1x3x4x7x6x2x5452 

CHAPTER 19.  RANDOM PROCESSES 

the  document.  For  example,  if  the  search  term  appeared  in  the  title  or  appeared 
100 times in a document, that document would get a higher score.  So if an author 
wanted a document  to get a higher  score  for  certain keywords, he would put  the 
keywords  in  the  title  and make  it  appear  in  lots  of  places.  You  can  even  see  this 
today with some bogus web sites. 
This approach works ﬁne if you only have a few documents that match a search 
term. But on the web, there are billions of documents and millions of matches to a 
typical search. 
For  example,  a  few  years  ago  a  search  on Google  for  “math  for  computer  sci­
ence  notes”  gave  378,000  hits!  How  does Google  decide which  10  or  20  to  show 
ﬁrst?  It wouldn’t be smart to pick a page that gets a high keyword score because it 
has “math math . . .  math” across the front of the document. 
One  way  to  get  placed  high  on  the  list  is  to  pay  Google  an  advertising  fees 
—and  Google  gets  an  enormous  revenue  stream  from  these  fees.  Of  course  an 
early listing is worth a fee only if an advertiser ’s target audience is attracted to the 
listing.  But  an  audience  does  get  attracted  to Google  listings  because  its  ranking 
method  is really good at determining  the most relevant web pages.  For example, 
Google demonstrated  its accuracy  in our case by giving ﬁrst rank  to  the Fall 2002 
open courseware page for 6.042 :-) .  So how did Google know to pick 6.042 to be 
ﬁrst out of 378, 000? 
Well back in 1995, Larry and Sergey got the idea to allow the digraph structure 
of the web to determine which pages are likely to be the most important. 

19.2.1  A First Crack at Page Rank 

Looking at  the web graph, any  idea which vertex/page might be  the best  to rank 
1st?  Assume  that  all  the pages match  the  search  terms  for now.  Well,  intuitively, 
we should choose x2 , since lots of other pages point to it. This leads us to their ﬁrst 
idea:  try  deﬁning  the  page  rank  of  x  to  be  the  number  of  links  pointing  to  x,  that 
is, indegree(x).  The idea is to think of web pages as voting for the most important 
page —the more votes, the better rank. 
Of course, there are some problems with this idea. Suppose you wanted to have 
your page get a high ranking.  One thing you could do is to create lots of dummy 
pages with links to your page. 

+n19.2.  RANDOM WALKS ON GRAPHS 

453 

There is another problem —a page could become unfairly inﬂuential by having 
lots of links to other pages it wanted to hype. 

So  this  strategy  for  high  ranking  would  amount  to,  “vote  early,  vote  often,” 
which is no good if you want to build a search engine that’s worth paying fees for. 
So, admittedly, their original idea was not so great.  It was better than nothing, but 
certainly not worth billions of dollars. 

19.2.2  Random Walk on the Web Graph 
But  then Sergey and Larry  thought some more and came up with a couple of  im­
provements.  Instead of just counting the indegree of a vertex, they considered the 
probability of being at each page after a  long  random walk on  the web graph.  In 
particular,  they  decided  to model  a  user ’s web  experience  as  following  each  link 
→ 
on a page with uniform probability.  That is, they assigned each edge x
y of the 
web graph with a probability conditioned on being on page x: 
Pr {follow link x → y  |  at page x} ::= 

1
. 
outdegree(x) 

The user experience is then just a random walk on the web graph. 
For example, if the user is at page x, and there are three links from page x, then 
each link is followed with probability 1/3. 
We can also compute the probability of arriving at a particular page, y , by sum­
� 
ming over all edges pointing to y . We thus have 
Pr {follow link x → y  |  at page x} · Pr {at page x}
Pr {go to y}  = 
� 
edges  x y→
Pr {at x}
outdegree(x)
edges  x y→

(19.8)

= 

For example, in our web graph, we have 
Pr {at x7 }  + 
2

Pr {go to x4} = 

Pr {at x2 } 
1 

.

+1+1+1+1+1454 

CHAPTER 19.  RANDOM PROCESSES 

One can think of this equation as x7  sending half its probability to x2  and the other 
half to x4 . The page x2  sends all of its probability to x4 . 
There’s one aspect of the web graph described thus far that doesn’t mesh with 
the  user  experience  —some  pages  have  no  hyperlinks  out.  Under  the  current 
model,  the  user  cannot  escape  these  pages.  In  reality,  however,  the  user  doesn’t 
fall off the end of the web into a void of nothingness.  Instead, he restarts his web 
journey. 
To model  this aspect of  the web, Sergey and Larry added a supervertex  to  the 
web graph  and had  every page with no hyperlinks point  to  it.  Moreover,  the  su­
pervertex  points  to  every  other  vertex  in  the  graph,  allowing  you  to  restart  the 
walk  from a  random place.  For example, below  left  is a graph and below right  is 
the same graph after adding the supervertex xN +1 . 

The  addition  of  the  supervertex  also  removes  the  possibility  that  the  value 
1/outdegree(x) might involve a division by zero. 

19.2.3  Stationary Distribution & Page Rank 
The basic idea of page rank is just a stationary distribution over the web graph, so 
let’s deﬁne a stationary distribution. 
Suppose  each  vertex  is  assigned  a probability  that  corresponds,  intuitively,  to 
the  likelihood  that  a  random walker  is  at  that  vertex  at  a  randomly  chosen  time. 
� 
We assume that the walk never leaves the vertices in the graph, so we require that 
Pr {at x} = 1. 
vertices  x 

(19.9) 

Deﬁnition 19.2.1.  An assignment of probabililties to vertices in a digraph is a sta­
tionary distribution if for all vertices x 
Pr {at x} = Pr {go to x at next step} 

Sergey and Larry deﬁned their page ranks to be a stationary distribution. They 
did  this  by  solving  the  following  system  of  linear  equations:  ﬁnd  a  nonnegative 
number, PR(x), for each vertex, x, such that 

x1x2x311/21/2xN+1x1x2x3455 

(19.11) 

, 

(19.10)

PR(x) = 

PR(y)
outdegree(y)

19.2.  RANDOM WALKS ON GRAPHS 
� 
edges  y x→
corresponding to the intuitive equations given in (19.8).  These numbers must also 
� 
satisfy the additional constraint corresponding to (19.9): 
PR(x) = 1. 
vertices  x 
So  if  there  are  n  vertices,  then  equations  (19.10)  and  (19.11)  provide  a  system 
of  n + 1  linear  equations  in  the  n  variables,  PR(x).  Note  that  constraint  (19.11) 
is  needed  because  the  remaining  constraints  (19.10)  could  be  satisﬁed  by  letting 
PR(x) ::= 0 for all x, which is useless. 
Sergey and Larry were smart fellows, and they set up their page rank algorithm 
so  it would  always  have  a meaningful  solution.  Their  addition  of  a  supervertex 
ensures  there  is  always  a  unique  stationary  distribution.  Moreover,  starting  from 
any vertex and taking a sufﬁciently long random walk on the graph, the probability 
of being at each page will get closer and closer to the stationary distribution. Note 
that general digraphs without supervertices may have neither of these properties: 
there may  not  be  a  unique  stationary  distribution,  and  even when  there  is,  there 
may be starting points from which the probabilities of positions during a random 
walk do not converge to the stationary distribution. 
Now just keeping track of the digraph whose vertices are billions of web pages 
is  a  daunting  task.  That’s  why  Google  is  building  power  plants.  Indeed,  Larry 
and  Sergey  named  their  system  Google  after  the  number  10100  —which  called  a 
“googol” —to reﬂect the fact that the web graph is so enormous. 
Anyway, now you can see how 6.042 ranked ﬁrst out of 378,000 matches.  Lots 
of other universities used our notes and presumably have  links  to  the 6.042 open 
courseware  site,  and  the  university  sites  themselves  are  legitimate,  which  ulti­
mately leads to 6.042 getting a high page rank in the web graph. 

19.2.4  Problems 
Class Problems 

Problem 19.2. 
Consider the following random-walk graph: 

xy11456 

CHAPTER 19.  RANDOM PROCESSES 

(a)  Find a stationary distribution. 

(b)  If  you  start  at  node  x  and  take  a  (long)  random  walk,  does  the  distribution 
over nodes ever get close to the stationary distribution? Explain. 
Consider the following random-walk graph: 

(c)  Find a stationary distribution. 

(d)  If  you  start  at  node  w  and  take  a  (long)  random walk,  does  the  distribution 
over  nodes  ever  get  close  to  the  stationary  distribution?  We  don’t  want  you  to 
prove anything here, just write out a few steps and see what’s happening. 
Consider the following random-walk graph: 

(e)  Describe the stationary distributions for this graph. 

(f)  If you start at node b and take a long random walk, the probability you are at 
node d will be close to what fraction? Explain. 

Homework Problems 

Problem 19.3. 
A  digraph  is  strongly  connected  iff  there  is  a  directed  path  between  every  pair  of 
distinct  vertices.  In  this  problem we  consider  a  ﬁnite  random walk  graph  that  is 
strongly connected. 
(a)  Let d1  and d2  be distinct distributions for the graph, and deﬁne the maximum 
dilation, γ , of d1  over d2  to be 

d1 (x)
γ  ::= max 
x∈V  d2 (x) 
→
Call a vertex, x, dilated if d1 (x)/d2 (x) = γ .  Show that there is an edge, y
z , from 
an undilated vertex y to a dilated vertex, z . Hint: Choose any dilated vertex, x, and 

. 

wz10.90.1ab1c1/21/21/21d1/219.2.  RANDOM WALKS ON GRAPHS 

457 

consider the set, D , of dilated vertices connected to x by a directed path (going to 
x)  that only uses dilated vertices.  Explain why D  =� V , and  then use  the  fact  that 
the graph is strongly connected. 

(b)  Prove  that  the graph has at most one stationary distribution.  (There always  is 
a  stationary  distribution,  but we’re  not  asking  you  prove  this.)  Hint:  Let  d1  be  a 
stationary distribution and d2  be a different distribution.  Let z  be the vertex from 
That is, d�2 (z ) =�
part  (a).  Show  that starting  from d2 ,  the probability of z  changes at  the next step. 
d2 (z ). 
Exam Problems 

Problem 19.4. 
For which of the following graphs is the uniform distribution over nodes a station­
ary distribution?  The edges are labeled with transition probabilities.  Explain your 
reasoning. 

0.50.50.50.50.50.50.50.50.50.51110.50.51458 

CHAPTER 19.  RANDOM PROCESSES 

Chapter 20 

Random Variables 

So far we focused on probabilities of events —that you win the Monty Hall game; 
that you have a rare medical condition, given that you tested positive; . . . . Now we 
focus on quantitative questions:  How many contestants must play  the Monty Hall 
game  until  one  of  them  ﬁnally  wins?  . . . How  long  will  this  condition  last?  How 
much will I lose playing 6.042 games all day? Random variables are the mathemat­
ical tool for addressing such questions. 

20.1  Random Variable Examples 

Deﬁnition  20.1.1.  A  random  variable,  R,  on  a  probability  space  is  a  total  function 
whose domain is the sample space. 

The  codomain  of  R  can  be  anything,  but  will  usually  be  a  subset  of  the  real 
numbers.  Notice  that  the  name  “random  variable”  is  a misnomer;  random  vari­
ables are actually functions! 
For example, suppose we toss three independent, unbiased coins.  Let C  be the 
number of heads that appear. Let M  = 1 if the three coins come up all heads or all 
tails, and let M  = 0 otherwise. Now every outcome of the three coin ﬂips uniquely 
determines the values of C  and M . For example, if we ﬂip heads, tails, heads, then 
C  = 2 and M  = 0.  If we ﬂip  tails,  tails,  tails,  then C  = 0 and M  = 1.  In effect, C 
counts the number of heads, and M  indicates whether all the coins match. 
Since  each  outcome  uniquely  determines  C  and  M ,  we  can  regard  them  as 
functions mapping  outcomes  to  numbers.  For  this  experiment,  the  sample  space 
is: 

S  =  {HHH, HH T , H T H, H T T , T HH, T H T , T T H, T T T } . 

Now C  is a  function  that maps each outcome  in  the sample space  to a number as 

459 

460 

follows: 

CHAPTER 20.  RANDOM VARIABLES 

C (HHH ) = 3 
C (HH T ) = 2 
C (H T H ) = 2 
C (H T T ) = 1 

C (T HH ) = 2 
C (T H T ) = 1 
C (T T H ) = 1 
C (T T T ) = 0. 

Similarly, M  is a function mapping each outcome another way: 

M (HHH ) = 1 
M (HH T ) = 0 
M (H T H ) = 0 
M (H T T ) = 0 

M (T HH ) = 0 
M (T H T ) = 0 
M (T T H ) = 0 
M (T T T ) = 1. 

So C  and M  are random variables. 

20.1.1  Indicator Random Variables 
An  indicator  random  variable  is  a  random  variable  that maps  every  outcome  to  ei­
ther 0 or 1.  These are also called Bernoulli variables.  The random variable M  is an 
example.  If all three coins match, then M  = 1; otherwise, M  = 0. 
Indicator  random  variables  are  closely  related  to  events.  In  particular,  an  in­
dicator  partitions  the  sample  space  into  those  outcomes  mapped  to  1  and  those 
outcomes mapped to 0.  For example, the indicator M  partitions the sample space 
into two blocks as follows: 
�� 
��
�
�
� 
� 
HHH  T T T  HH T  H T H  H T T  T HH  T H T  T T H .
M  = 1 
M  = 0 
In the same way, an event, E , partitions the sample space into those outcomes 
in  E  and  those  not  in  E .  So  E  is  naturally  associated  with  an  indicator  random 
variable,  IE ,  where  IE (p) = 1  for  outcomes  p  ∈  E  and  IE (p) = 0  for  outcomes 
p /∈ E . Thus, M  = IF  where F  is the event that all three coins match. 

20.1.2  Random Variables and Events 
There is a strong relationship between events and more general random variables 
as well. A random variable that takes on several values partitions the sample space 
into several blocks.  For example, C  partitions the sample space as follows: 
� �� � 
�� 
�� 
� �� �
�
� 
�
� 
T T H  T H T  H T T  T HH  H T H  HH T  HHH .
T T T
C  = 1 
C  = 2 
C  = 3 
C  = 0 
Each  block  is  a  subset  of  the  sample  space  and  is  therefore  an  event.  Thus,  we 
can regard an equation or inequality involving a random variable as an event.  For 
example,  the  event  that C  = 2  consists  of  the  outcomes T HH , H T H ,  and HH T . 
The event C  ≤ 1 consists of the outcomes T T T , T T H , T H T , and H T T . 

20.1.  RANDOM VARIABLE EXAMPLES 

461 

Naturally enough, we can talk about the probability of events deﬁned by prop­
erties of random variables.  For example, 
Pr {C  = 2}  =  Pr {T HH } + Pr {H T H } + Pr {HH T }
3 
1
1
1
= 
+ + = 
.
8
8
8
8 

20.1.3  Independence 
The notion of independence carries over from events to random variables as well. 
Random  variables R1  and R2  are  independent  iff  for  all  x1  in  the  codomain  of R1 , 
and x2  in the codomain of R2 , we have: 
Pr {R1  = x1  AND R2  = x2} = Pr {R1  = x1 } · Pr {R2  = x2} . 
As with events, we can formulate independence for random variables in an equiv­
alent and perhaps more  intuitive way:  random variables R1  and R2  are  indepen­
dent if for all x1  and x2 
Pr {R1  = x1  |  R2  = x2 } = Pr {R1  = x1} . 
whenever the lefthand conditional probability is deﬁned, that is, whenever Pr {R2  = x2} > 
0. 

As  an  example,  are C  and M  independent?  Intuitively,  the  answer  should  be 
“no”.  The  number  of  heads,  C ,  completely  determines  whether  all  three  coins 
match;  that  is,  whether M  = 1.  But,  to  verify  this  intuition,  we must  ﬁnd  some 
x1 , x2  ∈ R such that: 
Pr {C  = x1  AND M  = x2} =� Pr {C  = x1} · Pr {M  = x2 } . 
One appropriate choice of values is x1  = 2 and x2  = 1.  In this case, we have: 
1 3
· 
Pr {C  = 2 AND M  = 1} = 0 =�
= Pr {M  = 1} · Pr {C  = 2} . 
8
4 
The ﬁrst probability is zero because we never have exactly two heads (C  = 2) when 
all three coins match (M  = 1). The other two probabilities were computed earlier. 
On the other hand, let H1  be the indicator variable for event that the ﬁrst ﬂip is 
a Head, so 
[H1  = 1] = {HHH, H T H, HH T , H T T } . 
Then H1  is independent of M , since 
Pr {M  = 1} = 1/4 = Pr {M  = 1  |  H1  = 1} = Pr {M  = 1  |  H1  = 0}
Pr {M  = 0} = 3/4 = Pr {M  = 0  |  H1  = 1} = Pr {M  = 0  |  H1  = 0} 
This example is an instance of a simple lemma: 

Lemma 20.1.2.  Two events are independent iff their indicator variables are independent. 

462 

CHAPTER 20.  RANDOM VARIABLES 

As with events, the notion of independence generalizes to more than two ran­
dom variables. 

Deﬁnition 20.1.3.  Random variables R1 , R2 , . . . , Rn  are mutually independent iff 
Pr {R1  = x1  AND R2  = x2  AND 
AND Rn  = xn}
· · · 
=  Pr {R1  = x1 } · Pr {R2  = x2} · · · Pr {Rn  = xn} . 

for all x1 , x2 , . . . , xn . 

It is a simple exercise to show that the probability that any subset of the variables 
takes a particular set of values  is equal to the product of the probabilities that the 
individual  variables  take  their  values.  Thus,  for  example,  if  R1 , R2 , . . . , R100  are 
mutually independent random variables, then it follows that: 
Pr {R1  = 7 AND R7  = 9.1 AND R23  = π} = Pr {R1  = 7}·Pr {R7  = 9.1}·Pr {R23  = π} . 

20.2  Probability Distributions 

A random variable maps outcomes to values, but random variables that show up 
for different spaces of outcomes wind up behaving in much the same way because 
they have  the  same probability of  taking any given value.  Namely,  random vari­
ables  on  different  probability  spaces  may  wind  up  having  the  same  probability 
density function. 

Deﬁnition  20.2.1.  Let R  be  a  random  variable with  codomain  V .  The  probability 
→ 
� 
density function (pdf) of R is a function PDFR  : V 
[0, 1] deﬁned by: 
Pr {R = x}
if x ∈ range (R) , 
PDFR (x) ::= 
if x  /∈ range (R) . 
0 
� 
A consequence of this deﬁnition is that 
x∈range(R) 

PDFR (x) = 1. 

This follows because R has a value for each outcome, so summing the probabilities 
over all outcomes  is  the  same as  summing over  the probabilities of  each value  in 
the range of R. 
As  an  example,  let’s  return  to  the  experiment of  rolling  two  fair,  independent 
dice.  As before,  let T  be  the  total of  the  two  rolls.  This  random variable  takes on 
values  in  the  set  V  =  {2, 3, . . . , 12}.  A  plot  of  the  probability  density  function  is 
shown below: 

20.2.  PROBABILITY DISTRIBUTIONS 

463 

�6/36 

PDFR (x) 

3/36 

2 

3 

4 

5 

6 

8 
7 
x ∈ V 

� 

9

10

11

12 

The lump in the middle indicates that sums close to 7 are the most likely. The total 
area of all the rectangles is 1 since the dice must take on exactly one of the sums in 
V  = {2, 3, . . . , 12}. 
A  closely-related  idea  is  the  cumulative  distribution  function  (cdf)  for  a  random 
→ 
variable R whose codomain is real numbers.  This is a function CDFR  : R 
[0, 1] 
deﬁned by: 
CDFR (x) = Pr {R ≤ x}
As an example,  the cumulative distribution function for the random variable T  is 
shown below: 

�1 

CDFR (x) 

1/2 

0 

2 

3 

4 

5 

6 

8 
7 
x ∈ V 

� 

9

10

11

12 

The  height  of  the  i-th  bar  in  the  cumulative  distribution  function  is  equal  to  the 
sum  of  the  heights  of  the  leftmost  i  bars  in  the  probability density  function.  This 
follows from the deﬁnitions of pdf and cdf: 
� 
CDFR (x) = Pr {R ≤ x} 
Pr {R = y}
� 
= 
y≤x 
PDFR (y) 
y≤x 

= 

In summary, PDFR (x) measures the probability that R = x and CDFR (x) mea­
sures  the  probability  that  R  ≤  x.  Both  the  PDFR  and  CDFR  capture  the  same 

464 

CHAPTER 20.  RANDOM VARIABLES 

information  about  the  random  variable  R—  you  can  derive  one  from  the  other 
—but  sometimes  one  is  more  convenient.  The  key  point  here  is  that  neither  the 
probability density function nor the cumulative distribution function involves the 
sample space of an experiment. 
We’ll now look at three important distributions and some applications. 

20.2.1  Bernoulli Distribution 
Indicator  random  variables  are  perhaps  the  most  common  type  because  of  their 
close association with events. The probability density function of an indicator ran­
dom variable, B , is always 

PDFB (0) = p 
PDFB (1) = 1 − p 

where 0 ≤ p ≤ 1. The corresponding cumulative distribution function is: 
CDFB (0) = p 
CDFB (1) = 1 

20.2.2  Uniform Distribution 
A random variable  that  takes on each possible value with  the same probability  is 
called uniform.  For example, the probability density function of a random variable 
U  that is uniform on the set {1, 2, . . . , N } is: 

PDFU (k) = 

1
N 

And the cumulative distribution function is: 

k
N 
Uniform distributions come up all  the time.  For example,  the number rolled on a 
fair die is uniform on the set {1, 2, . . . , 6}. 

CDFU (k) = 

20.2.3  The Numbers Game 
Let’s  play  a  game!  I  have  two  envelopes.  Each  contains  an  integer  in  the  range 
0, 1, . . . , 100, and the numbers are distinct.  To win the game, you must determine 
which envelope contains the  larger number.  To give you a ﬁghting chance,  I’ll  let 
you  peek  at  the  number  in  one  envelope  selected  at  random.  Can  you  devise  a 
strategy that gives you a better than 50% chance of winning? 
For example, you could just pick an envelope at random and guess that it con­
tains the larger number. But this strategy wins only 50% of the time. Your challenge 
is to do better. 

20.2.  PROBABILITY DISTRIBUTIONS 

465 

So you might try to be more clever.  Suppose you peek in the left envelope and 
see  the  number  12.  Since  12  is  a  small  number,  you  might  guess  that  that  other 
number  is  larger.  But  perhaps  I’m  sort  of  tricky  and  put  small  numbers  in  both 
envelopes. Then your guess might not be so good! 
An  important point here  is  that  the numbers  in  the envelopes may not be ran­
dom.  I’m  picking  the  numbers  and  I’m  choosing  them  in  a way  that  I  think will 
defeat your guessing strategy.  I’ll only use randomization  to choose  the numbers 
if that serves my end: making you lose! 

Intuition Behind the Winning Strategy 

Amazingly,  there  is a  strategy  that wins more  than 50% of  the  time,  regardless of 
what numbers I put in the envelopes! 
Suppose  that  you  somehow  knew  a number  x  between my  lower number  and 
higher  numbers.  Now  you  peek  in  an  envelope  and  see  one  or  the  other.  If  it  is 
bigger than x, then you know you’re peeking at the higher number.  If it is smaller 
than  x,  then  you’re  peeking  at  the  lower  number.  In  other words,  if  you  know  a 
number x between my lower and higher numbers, then you are certain to win the 
game. 
The only ﬂaw with this brilliant strategy is that you do not know x. Oh well. 
But what  if  you  try  to  guess  x?  There  is  some  probability  that  you  guess  cor­
rectly.  In  this  case,  you  win  100%  of  the  time.  On  the  other  hand,  if  you  guess 
incorrectly,  then  you’re  no worse  off  than  before;  your  chance  of winning  is  still 
50%.  Combining  these  two  cases,  your  overall  chance  of  winning  is  better  than 
50%! 
Informal arguments about probability, like this one, often sound plausible, but 
do not hold up under close scrutiny.  In contrast, this argument sounds completely 
implausible— but is actually correct! 

Analysis of the Winning Strategy 
For generality,  suppose  that  I  can  choose numbers  from  the  set {0, 1, . . . , n}.  Call 
the lower number L and the higher number H . 
Your goal is to guess a number x between L and H . To avoid confusing equality 
� 
� 
cases, you select x at random from among the half-integers: 
1 
1
,  1
2 
2 

1 
,  . . . ,  n − 
2 

1
,  2
2 

But what probability distribution should you use? 
The uniform distribution turns out to be your best bet. An informal justiﬁcation 
is  that  if  I  ﬁgured  out  that  you  were  unlikely  to  pick  some  number—  say  50 1
2 — 
then I’d always put 50 and 51 in the evelopes. Then you’d be unlikely to pick an x 
between L and H  and would have less chance of winning. 
After you’ve  selected  the number x,  you peek  into  an  envelope  and  see  some 
number  p.  If  p > x,  then  you  guess  that  you’re  looking  at  the  larger  number.  If 

466 

CHAPTER 20.  RANDOM VARIABLES 

p < x, then you guess that the other number is larger. 
All that remains is to determine the probability that this strategy succeeds. We 
can do this with the usual four step method and a tree diagram. 
Step 1: Find the sample space.  You either choose x too low (< L), too high (> H ), 
or just right (L < x < H ). Then you either peek at the lower number (p = L) or the 
higher number (p = H ). This gives a total of six possible outcomes. 

Step  2:  Deﬁne  events  of  interest.  The  four  outcomes  in  the  event  that  you win 
are marked in the tree diagram. 
Step 3:  Assign outcome probabilities.  First, we assign edge probabilities.  Your 
guess x is too low with probability L/n, too high with probability (n − H )/n, and 
just right with probability (H − L)/n. Next, you peek at either the lower or higher 
number with equal probability. Multiplying along root-to-leaf paths gives the out­
come probabilities. 
Step 4:  Compute event probabilities.  The probability of  the event  that you win 
is the sum of the probabilities of the four outcomes in that event: 
n − H 
H − L  + 
H − L  + 
L  + 
Pr {win} = 
2n 
2n 
2n 
2n 
1  H − L 
= +
2n 
2
1 
1
≥ 
2
2n 
The ﬁnal inequality relies on the fact that the higher number H  is at least 1 greater 
than the lower number L since they are required to be distinct. 
Sure  enough,  you  win  with  this  strategy  more  than  half  the  time,  regardless 
of  the  numbers  in  the  envelopes!  For  example,  if  I  choose  numbers  in  the  range 
0, 1, . . . , 100, then you win with probability at least  1  +  1  = 50.5%. Even better, if 
2 
200 
I’m allowed only numbers in the range 0, . . . , 10, then your probability of winning 
rises to 55%! By Las Vegas standards, those are great odds! 

+

x just right1/21/21/21/21/21/2L/n(H−L)/n(n−H)/nchoice of x# peeked atresultprobabilitywinwinx too highx too lowwinlosewinloseL/2nL/2n(H−L)/2n(H−L)/2n(n−H)/2n(n−H)/2np=Hp=Lp=Hp=Lp=Hp=L20.2.  PROBABILITY DISTRIBUTIONS 

467 

20.2.4  Binomial Distribution 
The binomial distribution plays an important role in Computer Science as it does in 
most other sciences.  The standard example of a random variable with a binomial 
distribution is the number of heads that come up in n independent ﬂips of a coin; 
� � 
call  this  random  variable Hn .  If  the  coin  is  fair,  then Hn  has  an  unbiased  binomial 
density function: 
�  � 
2−n . 
n
PDFHn (k) = 
k 
This follows because there are  n
k  sequences of n coin tosses with exactly k heads, 
and each such sequence has probability 2−n . 
Here  is  a  plot  of  the  unbiased  probability  density  function  PDFHn (k)  corre­
sponding to n  =  20 coins ﬂips.  The most  likely outcome  is k  =  10 heads, and the 
probability falls off rapidly for larger and smaller values of k . These falloff regions 
to the left and right of the main hump are usually called the tails of the distribution. 

0.18 

0.16 

0.14 

0.12 

0.1 

0.08 

0.06 

0.04 

0.02 

0 
0 

5 

10

15

20 

In many  ﬁelds,  including  Computer  Science,  probability  analyses  come  down  to 
getting  small bounds on  the  tails of  the binomial distribution.  In  the  context of a 
problem,  this  typically means  that  there  is  very  small  probability  that  something 
bad  happens,  which  could  be  a  server  or  communication  link  overloading  or  a 
randomized  algorithm  running  for  an  exceptionally  long  time  or  producing  the 
wrong result. 
As an example, we can calculate the probability of ﬂipping at most 25 heads in 
100 tosses of a fair coin and see that it is very small, namely, less than 1 in 3,000,000. 
In  fact,  the  tail  of  the  distribution  falls  off  so  rapidly  that  the  probability  of 
ﬂipping exactly 25 heads  is nearly  twice  the probability of ﬂipping  fewer  than 25 

468 

CHAPTER 20.  RANDOM VARIABLES 

heads!  That  is,  the  probability  of  ﬂipping  exactly  25  heads  —small  as  it  is  —is 
still  nearly  twice  as  large  as  the  probability  of  ﬂipping  exactly  24  heads  plus  the 
probability of ﬂipping exactly 23 heads plus . . . the probability of ﬂipping no heads. 

The General Binomial Distribution 

PDFJ (k) = 

Now  let J  be  the number of heads  that  come up on n  independent  coins,  each of 
which is heads with probability p. Then J  has a general binomial density function: 
�  � 
p k (1 − p)n−k . 
n
k 

�  � 
As before, there are  n  sequences with k heads and n − k  tails, but now the prob­
ability of each such sequence is pk (1 − p)n−k . 
k 
As an example, the plot below shows the probability density function PDFJ (k) 
corresponding to ﬂipping n = 20 independent coins that are heads with probabilty 
p  = 0.75.  The  graph  shows  that we  are most  likely  to  get  around  k  =  15  heads, 
as  you might  expect.  Once  again,  the  probability  falls  off  quickly  for  larger  and 
smaller values of k . 

0.25 

0.2 

0.15 

0.1 

0.05 

0 
0 

5 

10

15

20 

20.2.  PROBABILITY DISTRIBUTIONS 

469 

20.2.5  Problems 
Class Problems 

Team 1: 

Guess the Bigger Number Game 

•  Write different integers between 0 and 7 on two pieces of paper. 

•  Put the papers face down on a table. 

Team 2: 

•  Turn over one paper and look at the number on it. 

•  Either stick with this number or switch to the unseen other number. 

Team 2 wins if it chooses the larger number. 

Problem 20.1. 
In  section  20.2.3,  Team  2 was  shown  to  have  a  strategy  that wins  4/7  of  the  time 
no matter how Team 1 plays.  Can Team 2 do better?  The answer is “no,” because 
Team 1 has a strategy that guarantees that it wins at least 3/7 of the time, no matter 
how Team 2 plays. Describe such a strategy for Team 1 and explain why it works. 

Problem 20.2. 
Suppose X1 , X2 ,  and X3  are  three mutually  independent  random variables,  each 
having the uniform distribution 
Pr {Xi  = k}  equal to 1/3 for each of k = 1, 2, 3. 

Let  M  be  another  random  variable  giving  the  maximum  of  these  three  random 
variables. What is the density function of M ? 

Homework Problems 

Problem 20.3. 
A  drunken  sailor  wanders  along main  street,  which  conveniently  consists  of  the 
points  along  the  x  axis  with  integral  coordinates.  In  each  step,  the  sailor moves 
one unit  left or right along  the x axis.  A particular path  taken by  the sailor can be 

470 

CHAPTER 20.  RANDOM VARIABLES 

described  by  a  sequence  of  “left”  and  “right”  steps.  For  example,  �left,left,right�
describes the walk that goes left twice then goes right. 
We model  this  scenario with  a  random walk  graph whose  vertices  are  the  in­
tegers  and with  edges  going  in  each  direction  between  consecutive  integers.  All 
edges are labelled 1/2. 
The sailor begins his random walk at the origin.  This is described by an initial 
distribution which  labels  the origin with probability  1  and  all other vertices with 
probability  0.  After one  step,  the  sailor  is  equally  likely  to be  at  location  1 or −1, 
so the distribution after one step gives label 1/2 to the vertices 1 and −1 and labels 
all other vertices with probability 0. 
(a)  Give  the  distributions  after  the  2nd,  3rd,  and  4th  step  by  ﬁlling  in  the  table 
of  probabilities  below,  where  omitted  entries  are  0.  For  each  row,  write  all  the 
nonzero entries so they have the same denominator. 
location 
0 
-1 
1 
1/2  0  1/2 
? 
? 
? 
? 
? 
? 
? 
? 
? 

initially 
after 1 step 
after 2 steps 
after 3 steps 
after 4 steps 

? 
? 
? 

? 
? 
? 

? 
? 

? 
? 

-4

-3

-2 

1 

2

3

4 

? 

? 

(b) 

1.  What is the ﬁnal location of a t-step path that moves right exactly i times? 
2.  How many different paths are there that end at that location? 
3.  What is the probability that the sailor ends at this location? 

(c)  Let L be the random variable giving the sailor ’s location after t steps, and let 
B ::= (L + t)/2. Use the answer to part (b) to show that B has an unbiased binomial 
density function. 

. 

< 

1
2 

(d)  Again  let  L  be  the  random  variable  giving  the  sailor ’s  location  after  t  steps, 
� 
� 
where t is even.  Show that 
√
t 
|L| < 
Pr 
2 

√
t/2 steps from 
So there is a better than even chance that the sailor ends up at least 
where he started. 
Hint: Work in terms of B .  Then you can use an estimate that bounds the binomial 
distribution.  Alternatively, observe that the origin is the most likely ﬁnal location 
� 
and then use the asymptotic estimate 
2 
.
πt 

Pr {L = 0} = Pr {B = t/2} ∼ 

20.3.  AVERAGE & EXPECTED VALUE 

471 

20.3  Average & Expected Value 

The  expectation  of  a  random  variable  is  its  average  value,  where  each  value  is 
weighted  according  to  the  probability  that  it  comes  up.  The  expectation  is  also 
called the expected value or the mean of the random variable. 
For example, suppose we select a student uniformly at random from the class, 
and let R be the student’s quiz score. Then E [R] is just the class average —the ﬁrst 
thing  everyone  wants  to  know  after  getting  their  test  back!  For  similar  reasons, 
the ﬁrst  thing you usually want  to know  about  a  random variable  is  its  expected 
value. 

Deﬁnition 20.3.1. 

� 
x  Pr {R = x} 
· 
� 
E [R] ::= 
x∈range(R) 
· 
x  PDFR (x).
x∈range(R) 

= 

(20.1)

Let’s work  through an example.  Let R be  the number  that comes up on a  fair, 
six-sided die. Then by (20.1), the expected value of R is: 
6� 
k · 
k=1 
1
1
1
1
1
· 
· 
· 
· 
· 
· 
= 1  + 2  + 3  + 4  + 5  + 6 
6 
6 
6 
6 
6 
7 = 
2 

E [R] = 

1
6 

1
6 

This  calculation  shows  that  the  name  “expected  value”  is  a  little misleading;  the 
random variable might never actually take on that value.  You don’t ever expect to 
roll a 3 1
2  on an ordinary die! 
There is an even simpler formula for expectation: 
Theorem 20.3.2.  If R is a random variable deﬁned on a sample space, S , then 
� 
ω∈S 

R(ω) Pr {ω} 

E [R] = 

(20.2) 

The proof of Theorem 20.3.2,  like many of the elementary proofs about expec­
tation  in  this  chapter,  follows  by  judicious  regrouping  of  terms  in  the  deﬁning 
sum (20.1): 

472 

CHAPTER 20.  RANDOM VARIABLES 

Proof. 

= 

= 

= 

= 

(Def 20.3.1 of expectation) 

� 
x  Pr {R = x} 
· 
x∈range(R)  ⎛
⎞

E [R] ::= 
�

� 
Pr {ω}⎠ 
x ⎝ 
�  � 
ω∈[R=x] 
x∈range(R) 
x Pr {ω} 
�  � 
x∈range(R) ω∈[R=x] 
R(ω) Pr {ω} 
� 
x∈range(R) ω∈[R=x] 
R(ω) Pr {ω}
ω∈S 
The last equality follows because the events [R = x] for x ∈ range (R) partition the 
sample space, S , so summing over the outcomes in [R = x] for x ∈ range (R) is the 
same as summing over S . 
� 

(distributing x over the inner sum) 

(def of Pr {R = x}) 

(def of the event [R = x]) 

In general, the deﬁning sum (20.1) is better for calculating expected values and 
has  the  advantage  that  it  does  not  depend  on  the  sample  space,  but  only  on  the 
density function of the random variable. On the other hand, the simpler sum over 
all outcomes (20.2)is sometimes easier to use in proofs about expectation. 

20.3.1  Expected Value of an Indicator Variable 
The expected value of an indicator random variable for an event is just the proba­
bility of that event. 

Lemma 20.3.3.  If IA  is the indicator random variable for event A, then 
E [IA ] = Pr {A} . 

Proof. 

E [IA ] = 1  Pr {IA  = 1} + 0  Pr {IA  = 0}
·
· 
= Pr {IA  = 1} 
= Pr {A} . 

(def of IA ) 

� 

For example,  if A is the event that a coin with bias p comes up heads, E [IA ] = 
Pr {IA  = 1} = p. 

20.3.  AVERAGE & EXPECTED VALUE 

473 

20.3.2  Conditional Expectation 

Just like event probabilities, expectations can be conditioned on some event. 
Deﬁnition  20.3.4.  The  conditional  expectation, E [R  | A],  of  a  random  variable,  R, 
� 
given event, A, is: 
r · Pr {R = r  |  A} . 
E [R  | A] ::= 
r∈range(R) 

(20.3) 

In other words, it is the average value of the variable R when values are weighted 
by their conditional probabilities given A. 
For  example, we  can  compute  the  expected  value  of  a  roll  of  a  fair  die,  given, 
for  example,  that  the  number  rolled  is  at  least  4.  We  do  this  by  letting  R  be  the 
outcome of a roll of the die. Then by equation (20.3), 
� 
6
i · Pr {R = i  |  R ≥ 4} = 1 · 0 + 2 · 0 + 3 · 0 + 4 · 1  + 5 · 1  + 6 · 1  = 5.
3 
3
3
i=1 

E [R  | R ≥ 4] = 

The  power  of  conditional  expectation  is  that  it  lets  us  divide  complicated  ex­
pectation  calculations  into  simpler  cases.  We  can ﬁnd  the desired  expectation  by 
calculating  the  conditional  expectation  in  each  simple  case  and  averaging  them, 
weighing each case by its probability. 
For  example,  suppose  that  49.8%  of  the people  in  the world  are male  and  the 
rest  female —which  is  more  or  less  true.  Also  suppose  the  expected  height  of  a 
randomly  chosen male  is  5� 11�� , while  the  expected  height  of  a  randomly  chosen 
female is 5� 5�� .  What is the expected height of a randomly chosen individual?  We 
can calculate  this by averaging  the heights of men and women.  Namely,  let H  be 
the height  (in  feet) of  a  randomly  chosen person,  and  let M  be  the  event  that  the 
person is male and F  the event that the person is female. We have 
E [H ] = E [H  | M ] Pr {M } + E [H  | F ] Pr {F }
·
· 
= (5 + 11/12)  0.498 + (5 + 5/12)  0.502
= 5.665 

which is a little less that 5’ 8”. 
The Law of Total Expectation justiﬁes this method. 

Rule (Law of Total Expectation). 

Theorem 20.3.5.  Let A1 , A2 , . . .  be a partition of the sample space. Then 
� 
E [R  | Ai ] Pr {Ai } . 
i 

E [R] = 

474 

CHAPTER 20.  RANDOM VARIABLES 

Proof. 

= 

= 

= 

� 
r  Pr {R = r} 
· 
�  � � � � � � 
E [R] ::= 
r∈range(R) 
r · 
Pr {R = r  |  Ai } Pr {Ai} 
i 
r
r · Pr {R = r  |  Ai } Pr {Ai} 
i 
r
r · Pr {R = r  |  Ai } Pr {Ai } 
� 
r 
i
Pr {Ai } 
r · Pr {R = r  |  Ai} 
� 
r 
i
Pr {Ai } E [R  | Ai ] . 
i 

= 

= 

(Def 20.3.1 of expectation) 

(Law of Total Probability) 

(distribute constant r) 

(exchange order of summation) 
(factor constant Pr {Ai }) 

(Def 20.3.4 of cond. expectation) 

� 

20.3.3  Mean Time to Failure 
A computer program crashes at the end of each hour of use with probability p, if it 
has not crashed already. What is the expected time until the program crashes? 
If  we  let  C  be  the  number  of  hours  until  the  crash,  then  the  answer  to  our 
problem  is E [C ].  Now  the probability  that,  for  i >  0,  the ﬁrst  crash occurs  in  the 
ith  hour  is  the  probability  that  it  does  not  crash  in  each  of  the  ﬁrst  i −  1  hours 
and  it does crash  in  the  ith hour, which  is  (1 − p)i−1p.  So  from  formula  (20.1)  for 
� 
expectation, we have 
i  Pr {R = i}
· 
� 
i∈N 
i(1 − p)i−1 p 
� 
i∈N+ 
= p
i∈N+ 

i(1 − p)i−1 

E [C ] = 

= 

1 
= p 
(1 − (1 − p))2 
1 = 
p 

(by (17.1))

A  simple  alternative  derivation  that  does  not  depend  on  the  formula  (17.1) 
(which  you  remembered,  right?)  is  based  on  conditional  expectation.  Given  that 
the  computer  crashes  in  the  ﬁrst  hour,  the  expected  number  of  hours  to  the  ﬁrst 
crash  is  obviously  1!  On  the  other  hand,  given  that  the  computer  does  not  crash 
in  the ﬁrst hour,  then  the  expected  total number of hours  till  the ﬁrst  crash  is  the 

20.3.  AVERAGE & EXPECTED VALUE 

475 

expectation of one plus the number of additional hours to the ﬁrst crash.  So, 
E [C ] = p  1 + (1 − p) E [C + 1] = p + E [C ] − p E [C ] + 1 − p,
· 

from which we immediately calculate that E [C ] = 1/p. 
So,  for example,  if  there  is a 1% chance  that  the program crashes at  the end of 
each hour, then the expected time until the program crashes is 1/0.01 = 100 hours. 
As  a  further  example,  suppose  a  couple  really wants  to  have  a  baby  girl.  For 
simplicity assume there is a 50% chance that each child they have is a girl, and the 
genders of their children are mutually independent.  If the couple insists on having 
children until they get a girl, then how many baby boys should they expect ﬁrst? 
This  is  really  a  variant  of  the  previous  problem.  The  question,  “How  many 
hours  until  the  program  crashes?”  is  mathematically  the  same  as  the  question, 
“How many  children must  the  couple  have  until  they  get  a  girl?”  In  this  case,  a 
crash  corresponds  to  having  a  girl,  so  we  should  set  p  = 1/2.  By  the  preceding 
analysis, the couple should expect a baby girl after having 1/p = 2 children.  Since 
the last of these will be the girl, they should expect just one boy. 
Something  to  think about:  If every  couple  follows  the  strategy of having  chil­
dren until they get a girl, what will eventually happen to the fraction of girls born 
in this world? 

20.3.4  Linearity of Expectation 
Expected values obey a simple, very helpful rule called Linearity of Expectation.  Its 
simplest form says that the expected value of a sum of random variables is the sum 
of the expected values of the variables. 

Theorem 20.3.6.  For any random variables R1  and R2 , 

E [R1  + R2 ] = E [R1 ] + E [R2 ] . 

T (ω) · Pr {ω} 

Proof.  Let T ::= R1 + R2 . The proof follows straightforwardly by rearranging terms 
in the sum (20.2) � 
� 
E [T ] = 
ω∈S 
(R1 (ω) + R2 (ω)) · Pr {ω} 
� 
� 
ω∈S 
R2 (ω) Pr {ω} 
R1 (ω) Pr {ω} + 
ω∈S 
ω∈S 
= E [R1 ] + E [R2 ] . 

(rearranging terms) 

(Theorem 20.3.2) 

= 

= 

(Theorem 20.3.2) 

(def of T ) 

A small extension of this proof, which we leave to the reader, implies 

� 

476 

CHAPTER 20.  RANDOM VARIABLES 

Theorem 20.3.7 (Linearity of Expectation).  For random variables R1 , R2  and constants 
a1 , a2  ∈ R, 

E [a1R1  + a2R2 ] = a1 E [R1 ] + a2 E [R2 ] . 

In  other words,  expectation  is  a  linear  function.  A  routine  induction  extends 
the result to more than two variables: 
Corollary 20.3.8.  For any random variables R1 , . . . , Rk  and constants a1 , . . . , ak  ∈ R, 
� � 
� 
� 
k
k
aiRi  = 
ai E [Ri ] . 
E 
i=1 
i=1 

The great thing about linearity of expectation is that no independence is required. 
This  is  really  useful,  because  dealing with  independence  is  a  pain,  and we  often 
need to work with random variables that are not independent. 

Expected Value of Two Dice 

What is the expected value of the sum of two fair dice? 
Let  the  random  variable  R1  be  the  number  on  the  ﬁrst  die,  and  let  R2  be  the 
number on the second die.  We observed earlier that the expected value of one die 
is 3.5. We can ﬁnd the expected value of the sum using linearity of expectation: 

E [R1  + R2 ] = E [R1 ] + E [R2 ] = 3.5 + 3.5 = 7. 

Notice  that  we  did  not  have  to  assume  that  the  two  dice  were  independent. 
The expected sum of two dice is 7, even if they are glued together (provided each 
individual  die  remainw  fair  after  the  gluing).  Proving  that  this  expected  sum  is 
7  with  a  tree  diagram  would  be  a  bother:  there  are  36  cases.  And  if  we  did  not 
assume that the dice were independent, the job would be really tough! 

The Hat-Check Problem 

There is a dinner party where n men check their hats. The hats are mixed up during 
dinner, so that afterward each man receives a random hat.  In particular, each man 
gets his own hat with probability 1/n.  What  is  the expected number of men who 
get their own hat? 
Letting  G  be  the  number  of  men  that  get  their  own  hat,  we  want  to  ﬁnd  the 
expectation of G.  But all we know about G  is  that  the probability  that a man gets 
his own hat back  is 1/n.  There are many different probability distributions of hat 
permutations with this property, so we don’t know enough about the distribution 
of  G  to  calculate  its  expectation  directly.  But  linearity  of  expectation  makes  the 
problem really easy. 
The trick is to express G as a sum of indicator variables.  In particular, let Gi  be 
an  indicator  for  the event  that  the  ith man gets his own hat.  That  is, Gi  = 1  if he 

20.3.  AVERAGE & EXPECTED VALUE 

477 

gets his own hat, and Gi  = 0 otherwise. The number of men that get their own hat 
is the sum of these indicators: 

· · · 
+ Gn . 
G = G1  + G2  +
(20.4)
These indicator variables are not mutually independent.  For example, if n − 1 men 
all get their own hats, then the last man is certain to receive his own hat. But, since 
we plan to use linearity of expectation, we don’t have worry about independence! 
Now since Gi  is an indicator, we know 1/n = Pr {Gi  = 1} = E [Gi ] by Lemma 20.3.3. 
Now we can take the expected value of both sides of equation (20.4) and apply lin­
earity of expectation: 

· · · 
+ Gn ]
E [G] = E [G1  + G2  +
· · ·  � �
= E [G1 ] + E [G2 ] +  + E [Gn ]
1
1 
1
1 
· · · 
= + +  + = n 
n 
n 
n
n

= 1. 

So even though we don’t know much about how hats are scrambled, we’ve ﬁgured 
out that on average, just one man gets his own hat back! 

Expectation of a Binomial Distribution 

But 

Suppose that we independently ﬂip n biased coins, each with probability p of com­
ing up heads. What is the expected number that come up heads? 
Let  J  be  the  number  of  heads  after  the  ﬂips,  so  J  has  the  (n, p)-binomial  dis­
tribution.  Now  let  Ik  be  the  indicator  for  the  kth  coin  coming  up  heads.  By 
Lemma 20.3.3, we have 
E [Ik ] = p. 
� 
n
J  = 
Ik , 
�
� 
k=1 
� 
�  � 
n
n
n
p = pn. 
Ik  = 
E [J ] = E 
E [Ik ] = 
k=1 
k=1 
k=1 
In short, the expectation of an (n, p)-binomially distributed variable is pn. 

so by linearity 

The Coupon Collector Problem 

Every  time  I  purchase  a  kid’s  meal  at  Taco  Bell,  I  am  graciously  presented  with 
a miniature  “Racin’  Rocket”  car  together with  a  launching  device which  enables 
me to project my new vehicle across any tabletop or smooth ﬂoor at high velocity. 
Truly, my delight knows no bounds. 
There are n different types of Racin’ Rocket car (blue, green, red, gray, etc.). The 
type  of  car  awarded  to me  each  day  by  the  kind woman  at  the  Taco  Bell  register 

478 

CHAPTER 20.  RANDOM VARIABLES 

appears  to  be  selected  uniformly  and  independently  at  random.  What  is  the  ex­
pected number of kid’s meals that I must purchase in order to acquire at least one 
of each type of Racin’ Rocket car? 
The same mathematical question shows up in many guises:  for example, what 
is the expected number of people you must poll in order to ﬁnd at least one person 
with each possible birthday? Here, instead of collecting Racin’ Rocket cars, you’re 
collecting birthdays.  The general question is commonly called the coupon collector 
problem after yet another interpretation. 
A clever application of linearity of expectation leads to a simple solution to the 
coupon collector problem.  Suppose there are ﬁve different types of Racin’ Rocket, 
and I receive this sequence: 

blue  green  green 

red  blue  orange  blue  orange  gray 

Let’s partition the sequence into 5 segments: 
� �� �
�� 
�� 
�� 
� �� �
� 
� 
�
� 
�
� 
blue
green
green  red  blue  orange  blue  orange  gray
X0 
X1 
X2 
X3 
X4 

The rule is that a segment ends whenever I get a new kind of car.  For example, the 
middle  segment  ends when  I  get  a  red  car  for  the  ﬁrst  time.  In  this way,  we  can 
break the problem of collecting every type of car into stages. Then we can analyze 
each stage individually and assemble the results using linearity of expectation. 
Let’s  return  to  the general  case where  I’m  collecting n Racin’ Rockets.  Let Xk 
be the length of the kth segment.  The total number of kid’s meals I must purchase 
to get all n Racin’ Rockets is the sum of the lengths of all these segments: 

T  = X0  + X1  +

· · · 
+ Xn−1

Now  let’s  focus  our  attention  on  Xk ,  the  length  of  the  kth  segment.  At  the 
beginning of segment k , I have k different types of car, and the segment ends when 
I acquire a new  type.  When  I own k  types,  each kid’s meal  contains a  type  that  I 
already have with probability k/n. Therefore, each meal contains a new type of car 
with probability 1 − k/n  = (n − k)/n.  Thus,  the  expected number of meals until 
I get a new kind of car  is n/(n − k) by the “mean time to failure” formula.  So we 
have: 

E [Xk ] = 

n
n − k 

Linearity of expectation, together with this observation, solves the coupon col­

20.3.  AVERAGE & EXPECTED VALUE 

479 

lector problem: 

· · · 
+ Xn−1 ]
E [T ] = E [X0  + X1  +
· · · 
= E [X0 ] + E [X1 ] +  + E [Xn−1 ]
� 
� 
n 
n 
n 
· · · 
n
n
= 
+ 
+
+ + + 
n − 1 
n − 0 
2
3
1 
� 
� 
1
1
1 
1 
1 
· · · 
+  + + + 
+ 
= n 
n − 1 
3
1 
2
n
1
1 
1 
1
1
· · · 
+ 
+ + +
n 
n − 1 
1
2
3 
n 
= nHn  ∼ n ln n. 

+

Let’s use this general solution to answer some concrete questions. For example, 
the expected number of die rolls required to see every number from 1 to 6 is: 

6H6  = 14.7 . . . 

And the expected number of people you must poll to ﬁnd at least one person with 
each possible birthday is: 

365H365  = 2364.6 . . . 

20.3.5  The Expected Value of a Product 

While the expectation of a sum is the sum of the expectations, the same is usually 
not true for products.  But it is true in an important special case, namely, when the 
random variables are independent. 
For  example,  suppose  we  throw  two  independent,  fair  dice  and  multiply  the 
numbers that come up. What is the expected value of this product? 
Let  random  variables R1  and R2  be  the  numbers  shown  on  the  two  dice.  We 
can compute the expected value of the product as follows: 

E [R1  · R2 ] = E [R1 ]  E [R2 ] = 3.5 3.5 = 12.25. 
·
· 
� 
� 
Here the ﬁrst equality holds because the dice are independent. 
At  the  other  extreme,  suppose  the  second  die  is  always  the  same  as  the  ﬁrst. 
Now R1  = R2 , and we can compute the expectation, E  R1
2  , of the product of the 

(20.5)

480 

CHAPTER 20.  RANDOM VARIABLES 

=

+

+

+

= 

32 
6

+

42 
6

+

= 

52 
6

62 
6 

� � 
� 
dice explicitly, conﬁrming that it is not equal to the product of the expectations. 
E [R1  · R2 ] = E  R1
� 
� 
2 
6
· 
i2  Pr  R1
2  = i2
� 
i=1

6

i2  Pr {R1  = i}
· 
i=1 
12 
22 
6
6
= 15 1/6 
= 12 1/4 
· 
= E [R1 ]  E [R2 ] .
Theorem 20.3.9.  For any two independent random variables R1 , R2 , 
E [R1  · R2 ] = E [R1 ]  E [R2 ] .
· 
· 
Proof.  The  event  [R1  R2  =  r ]  can  be  split  up  into  events  of  the  form  [R1  = 
r1  and  R2  = r2 ] where r1  · r2  = r .  So 
� 
E [R1  · R2 ] 
r  Pr {R1  · R2  = r}
· 
� 
::= 
r∈range(R1 ·R2 ) 
r1 r2  · Pr {R1  = r1  and  R2  = r2} 
� 
� 
ri∈range(Ri ) 
r1 r2  · Pr {R1  = r1  and  R2  = r2} 
� 
� 
r1∈range(R1 ) r2∈range(R2 ) 
r1 r2  · Pr {R1  = r1} · Pr {R2  = r2} 
⎞

⎛
�

� 
r1∈range(R1 ) r2∈range(R2 )
r2 Pr {R2  = r2}⎠ 
⎝r1 Pr {R1  = r1} · 
� 
r1∈range(R1 ) 
r2∈range(R2 ) 
r1 Pr {R1  = r1} · E [R2 ] 
� 
r1∈range(R1 ) 
r1 Pr {R1  = r1} 
· 
= E [R2 ] 
r1∈range(R1 ) 
· 
= E [R2 ]  E [R1 ] . 

= 

= 

= 

= 

= 

(def of E [R1 ])
� 
Theorem 20.3.9 extends routinely to a collection of mutually independent vari­
ables. 

(ordering terms in the sum) 

(indep. of R1 , R2 ) 

(factoring out r1 Pr {R1  = r1}) 

(def of E [R2 ]) 

(factoring out E [R2 ])

�
20.3.  AVERAGE & EXPECTED VALUE 
� � 
� 
Corollary 20.3.10.  If random variables R1 , R2 , . . . , Rk  are mutually independent, then 
� 
k
k
E [Ri ] . 
Ri  = 
E 
i=1 
i=1 

481 

20.3.6  Problems 
Practice Problems 

Problem 20.4. 
MIT students sometimes delay laundry for a few days. Assume all random values 
described below are mutually independent. 
(a)  A  busy  student  must  complete  3  problem  sets  before  doing  laundry.  Each 
problem  set  requires  1  day with  probability  2/3  and  2  days with  probability  1/3. 
Let B be the number of days a busy student delays laundry. What is E [B ]? 
Example:  If the ﬁrst problem set requires 1 day and the second and third problem 
sets each require 2 days, then the student delays for B = 5 days. 

(b)  A relaxed student rolls a fair, 6-sided die in the morning.  If he rolls a 1, then he 
does his laundry immediately (with zero days of delay).  Otherwise, he delays for 
one day and repeats the experiment the following morning.  Let R be the number 
of days a relaxed student delays laundry. What is E [R]? 
Example:  If the student rolls a 2 the ﬁrst morning, a 5 the second morning, and a 1 
the third morning, then he delays for R = 2 days. 

(c)  Before doing laundry, an unlucky student must recover from illness for a num­
ber  of  days  equal  to  the  product  of  the  numbers  rolled  on  two  fair,  6-sided  dice. 
Let U  be the expected number of days an unlucky student delays laundry. What is 
E [U ]? 
Example:  If the rolls are 5 and 3, then the student delays for U  = 15 days. 

(d)  A  student  is  busy with  probability  1/2,  relaxed with  probability  1/3,  and  un­
lucky with probability 1/6. Let D be the number of days the student delays laundry. 
What is E [D]? 

Problem 20.5. 
Each 6.042 ﬁnal exam will be graded according to a rigorous procedure: 

2  it is graded 
7  the exam is graded by a TA,with probability  7
•	 With probability  4
1 ,  it  is  accidentally  dropped  behind  the 
by  a  lecturer,  and  with  probability  7
radiator and arbitrarily given a score of 84. 

•	 TAs score an exam by scoring each problem individually and then taking the 
sum. 

482 

CHAPTER 20.  RANDOM VARIABLES 

–	 There  are  ten  true/false  questions  worth  2  points  each.  For  each,  full 
credit is given with probability  3
4 , and no credit is given with probability 
1 .4 
–	 There  are  four  questions  worth  15  points  each.  For  each,  the  score  is 
determined by rolling two fair dice, summing the results, and adding 3. 
–	 The single 20 point question is awarded either 12 or 18 points with equal 
probability. 

•	 Lecturers  score  an  exam  by  rolling  a  fair  die  twice,  multiplying  the  results, 
and then adding a “general impression”score. 

–	 With probability  4  , the general impression score is 40. 
10 
–	 With probability  3  , the general impression score is 50. 
10 
–	 With probability  3  , the general impression score is 60. 
10 

Assume all random choices during the grading process are independent. 
(a)  What is the expected score on an exam graded by a TA? 

(b)  What is the expected score on an exam graded by a lecturer? 

(c)  What is the expected score on a 6.042 ﬁnal exam? 

Class Problems 

Problem 20.6. 
Let’s  see  what  it  takes  to  make  Carnival  Dice  fair.  Here’s  the  game  with  payoff 
parameter k : make three independent rolls of a fair die.  If you roll a six 

•	 no times, then you lose 1 dollar. 

•	 exactly once, then you win 1 dollar. 

•	 exactly twice, then you win two dollars. 

•	 all three times, then you win k dollars. 

For what value of k  is this game fair? 

Problem 20.7. 
A classroom has sixteen desks arranged as shown below. 

20.3.  AVERAGE & EXPECTED VALUE 

483 

If there is a girl in front, behind, to the left, or to the right of a boy, then the two of 
them ﬂirt.  One student may be in multiple ﬂirting couples; for example, a student 
in a corner of the classroom can ﬂirt with up to two others, while a student in the 
center  can ﬂirt with  as many  as  four  others.  Suppose  that desks  are  occupied  by 
boys  and  girls  with  equal  probability  and  mutually  independently.  What  is  the 
expected number of ﬂirting couples? Hint: Linearity. 

Problem 20.8. 
Here are seven propositions: 

x1 
x5 
x2 
x4 
x3 
x9 
x3 

OR 
OR 
OR 
OR 
OR 
OR 
OR 

x3 
x6 
x4 
x5 
x5 
x8 
x9 

OR 
OR 
OR 
OR 
OR 
OR 
OR 

x7 
x7 
x6 
x7 
x8 
x2 
x4 

Note that: 

1.  Each proposition  is  the disjunction  (OR) of  three  terms of  the  form xi  or  the 
form xi . 

2.  The variables in the three terms in each proposition are all different. 

Suppose  that we  assign  true/false  values  to  the  variables  x1 , . . . , x9  indepen­
dently and with equal probability. 

484 

CHAPTER 20.  RANDOM VARIABLES 

(a)  What is the expected number of true propositions? 

Hint: Let Ti  be an indicator for the event that the i-th proposition is true. 

(b)  Use your answer to prove that for any set of 7 propositions satisfying the con­
ditions  1.  and  2.,  there  is  an  assignment  to  the  variables  that  makes  all  7  of  the 
propositions true. 

Problem 20.9.  (a)  Suppose  we  ﬂip  a  fair  coin  until  two  Tails  in  a  row  come  up. 
What  is  the  expected  number,  NTT ,  of  ﬂips  we  perform?  Hint:  Let  D  be  the  tree 
· 
·
· 
diagram for this process.  Explain why D  = H D + T  (H D + T ).  Use the Law 
of Total Expectation 20.3.5 

(b)  Suppose we ﬂip a fair coin until a Tail immediately followed by a Head come 
up. What is the expected number, NTH , of ﬂips we perform? 

(c)  Suppose we now play a game: ﬂip a fair coin until either TT or TH ﬁrst occurs. 
You win if TT comes up ﬁrst,  lose if TH comes up ﬁrst.  Since TT takes 50% longer 
on  average  to  turn  up,  your  opponent  agrees  that  he  has  the  advantage.  So  you 
tell him you’re willing to play if you pay him $5 when he wins, but he merely pays 
you a 20% premium, that is, $6, when you win. 

If you do this, you’re sneakily taking advantage of your opponent’s untrained in­
tuition,  since  you’ve  gotten  him  to  agree  to  unfair  odds.  What  is  your  expected 
proﬁt per game? 

Problem 20.10. 
Justify each line of the following proof that if R1  and R2  are independent, then 

E [R1  · R2 ] = E [R1 ]  E [R2 ] .
· 

20.3.  AVERAGE & EXPECTED VALUE 

485 

Proof. 

= 

= 

= 

= r1


r1 r2  · 
Pr {R1 

= r1


and  R2  = r2}

and  R2  = r2 }

� 
E [R1  · R2 ] 
r  Pr {R1  · R2  = r}
· 
� 
= 
r∈range(R1 ·R2 ) 
r1 r2  · 
Pr {R1 
� 
� 
ri∈range(Ri )

� 
� 
r1∈range(R1 ) r2∈range(R2 )

r1 r2  · Pr {R1  = r1 } · Pr {R2  = r2 } 
⎛
⎞ 
� 
� 
r1∈range(R1 ) r2∈range(R2 )
⎝r1 Pr {R1  = r1 } · 
r2 Pr {R2  = r2 }⎠ 
� 
r1∈range(R1 ) 
r2 ∈range(R2 ) 
r1 Pr {R1  = r1} · E [R2 ] 
� 
r1∈range(R1 ) 
r1 Pr {R1  = r1 }
· 
= E [R2 ] 
r1∈range(R1 ) 
· 
= E [R2 ]  E [R1 ] .

= 

= 

� 

Problem 20.11. 
Here are seven propositions: 

∨ 
x1 
¬x5  ∨ 
∨ ¬
x2 
¬x4  ∨ 
∨ ¬
x3 
∨ ¬
x9 
¬x3  ∨ 

∨ ¬
x7
x3 
x6  ∨ 
x7 
∨ 
x4 
x6
x5  ∨ ¬x7 
∨ ¬
x8
x5 
∨

x8 
x2
x9  ∨ 
x4


Note that: 
1.  Each proposition is the OR of three terms of the form xi  or the form  xi .¬
2.  The variables in the three terms in each proposition are all different. 

Suppose that we assign true/false values to the variables x1 , . . . , x9  independently 
and with equal probability. 
(a)  What is the expected number of true propositions? 

486 

CHAPTER 20.  RANDOM VARIABLES 

(b)  Use your answer to prove that there exists an assignment to the variables that 
makes all of the propositions true. 

Problem 20.12. 
A literal is a propositional variable or its negation.  A k-clause is an OR  of k  literals, 
with no variable occurring more than once in the clause.  For example, 

is a 4-clause, but 

P  OR Q OR R OR V , 

V  OR Q OR X  OR V , 

is not, since V  appears twice. 
Let  S  be  a  set  of  n  distinct  k-clauses  involving  v  variables.  The  variables  in 
different k-clauses may overlap or be completely different, so k ≤ v ≤ nk . 
A random assignment of true/false values will be made independently to each 
of  the  v  variables, with  true  and  false  assignments  equally  likely.  Write  formulas 
in n, k , and v  in answer to the ﬁrst two parts below. 
(a)  What  is  the  probability  that  the  last  k-clause  in  S  is  true  under  the  random 
assignment? 
(b)  What is the expected number of true k-clauses in S ? 

(c)  A  set  of  propositions  is  satisﬁable  iff  there  is  an  assignment  to  the  variables 
that makes all of the propositions true. Use your answer to part (b) to prove that if 
n < 2k , then S  is satisﬁable. 

Problem 20.13. 
A  gambler  bets  $10  on  “red”  at  a  roulette  table  (the  odds  of  red  are  18/38 which 
slightly less than even) to win $10.  If he wins, he gets back twice the amount of his 
bet and he quits. Otherwise, he doubles his previous bet and continues. 
(a)  What is the expected number of bets the gambler makes before he wins? 

(b)  What is his probability of winning? 

(c)  What is his expected ﬁnal proﬁt (amount won minus amount lost)? 

(d)  The  fact  that  the  gambler ’s  expected  proﬁt  is  positive,  despite  the  fact  that 
the game  is biased  against him,  is known  as  the St.  Petersberg  paradox.  The para­
dox  arises  from  an  unrealistic,  implicit  assumption  about  the  gambler ’s  money. 
Explain. 
Hint: What is the expected size of his last bet? 

20.3.  AVERAGE & EXPECTED VALUE 

487 

Homework Problems 

Problem 20.14. 
Let R and S  be independent random variables, and f  and g be any functions such 
that domain (f ) = codomain (R) and domain (g) = codomain (S ). Prove that f (R) 
and  g(S )  are  independent  random  variables.  Hint:  The  event  [f (R) =  a]  is  the 
disjoint union of all the events [R = r ] for r such that f (r) = a. 

488 

CHAPTER 20.  RANDOM VARIABLES 

Chapter 21 

Deviation from the Mean 

21.1  Why the Mean? 

In  the  previous  chapter we  took  it  for  granted  that  expectation  is  important,  and 
we developed a bunch of  techniques  for  calculating  expected  (mean) values.  But 
why should we care about the mean? After all, a random variable may never take 
a value anywhere near its expected value. 
The most  important  reason  to  care  about  the mean  value  comes  from  its  con­
nection to estimation by sampling.  For example, suppose we want to estimate the 
average age, income, family size, or other measure of a population.  To do this, we 
determine  a  random  process  for  selecting  people —say  throwing  darts  at  census 
lists.  This process makes  the  selected person’s age,  income,  and  so on  into a  ran­
dom variable whose mean equals the actual average age or income of the population. 
So we  can  select  a  random  sample  of  people  and  calculate  the  average  of  people 
in  the  sample  to  estimate  the  true  average  in  the  whole  population.  Many  fun­
damental  results  of  probability  theory  explain  exactly  how  the  reliability  of  such 
estimates improves as the sample size increases, and in this chapter we’ll examine 
a few such results. 
In  particular,  when  we  make  an  estimate  by  repeated  sampling,  we  need  to 
know how much conﬁdence we should have that our estimate is OK. Technically, 
this  reduces  to  ﬁnding  the  probability  that  an  estimate  deviates  a  lot  from  its  ex­
pected value. This topic of deviation from the mean is the focus of this ﬁnal chapter. 

21.2  Markov’s Theorem 

Markov’s  theorem  is  an  easy  result  that  gives  a  generally  rough  estimate  of  the 
probability that a random variable takes a value much larger than its mean. 
The idea behind Markov’s Theorem can be explained with a simple example of 
intelligence quotient, IQ. This quantity was devised so that the average IQ measure­
ment would be 100. Now from this fact alone we can conclude that at most 1/3 the 

489 

490 

CHAPTER 21.  DEVIATION FROM THE MEAN 

population can have an IQ of 300 or more, because if more than a third had an IQ 
of 300, then the average would have to be more than (1/3)300 = 100, contradicting 
the fact that the average  is 100.  So the probability that a randomly chosen person 
has  an  IQ  of  300  or more  is  at most  1/3.  Of  course  this  is  not  a  very  strong  con­
clusion;  in  fact  no  IQ  of  over  300  has  ever  been  recorded.  But  by  the  same  logic, 
we can also conclude  that at most 2/3 of  the population can have an  IQ of 150 or 
more.  IQ’s of over 150 have certainly been recorded, though again, a much smaller 
fraction than 2/3 of the population actually has an IQ that high. 
But although these conclusions about IQ are weak, they are actually the strongest 
general conclusions that can be reached about a random variable using only the fact 
that it is nonnegative and its mean is 100. For example, if we choose a random vari­
able equal to 300 with probability 1/3, and 0 with probability 2/3, then its mean is 
100, and the probability of a value of 300 or more really is 1/3.  So we can’t hope to 
get a better upper bound based solely on this limited amount of information. 

Theorem 21.2.1  (Markov’s Theorem).  If R  is a nonnegative random variable,  then  for 
all x > 0 

Pr {R ≥ x} ≤ 

[R] 
E 
.
x 

Proof.  For any x > 0 

(21.1) 
� 

Dividing the ﬁrst and last expression (21.1) by x gives the desired result. 

Our focus is deviation from the mean, so it’s useful to rephrase Markov’s The­
orem this way: 
Corollary 21.2.2.  If R is a nonnegative random variable, then for all c ≥ 1 
1
c

Pr {R ≥ c · E [R]} ≤ 

(21.2) 

. 

This Corollary follows immediately from Markov’s Theorem(21.2.1) by letting 
· 
x be c  E [R].

≥ 

≥ 

� 
y Pr {R = y} 
� 
E [R] ::= 
y∈range(R) 
y Pr {R = y} 
� 
y≥x,

y∈range(R)

� 
y≥x,

y∈range(R)

= x 
y≥x,

y∈range(R)

= x Pr {R ≥ x} . 

x Pr {R = y}

Pr {R = y}

(because R ≥ 0) 

21.2.  MARKOV’S THEOREM 

491 

= 

21.2.1  Applying Markov’s Theorem 
Let’s consider the Hat-Check problem again.  Now we ask what the probability is 
that x or more men get the right hat, this is, what the value of Pr {G ≥ x} is. 
We  can  compute  an  upper  bound  with  Markov’s  Theorem.  Since  we  know 
E [G] = 1, Markov’s Theorem implies 
Pr {G ≥ x} ≤ 

1 
[G] 
E 
.
x 
x 
For  example,  there  is  no  better  than  a  20%  chance  that  5  men  get  the  right  hat, 
regardless of the number of people at the dinner party. 
The  Chinese  Appetizer  problem  is  similar  to  the  Hat-Check  problem.  In  this 
case, n people are eating appetizers arranged on a  circular,  rotating Chinese ban­
quet  tray.  Someone  then  spins  the  tray  so  that  each  person  receives  a  random 
appetizer. What is the probability that everyone gets the same appetizer as before? 
There are n  equally  likely orientations  for  the  tray after  it  stops  spinning.  Ev­
eryone  gets  the  right  appetizer  in  just  one  of  these  n  orientations.  Therefore,  the 
correct answer is 1/n. 
But what probability do we get from Markov’s Theorem? Let the random vari­
able,  R,  be  the  number  of  people  that  get  the  right  appetizer.  Then  of  course 
E [R] = 1 (right?), so applying Markov’s Theorem, we ﬁnd: 
[R] 
1 
E 
Pr {R ≥ n} ≤ 
n 
n 
So for the Chinese appetizer problem, Markov’s Theorem is tight! 
On the other hand, Markov’s Theorem gives the same 1/n bound for the prob­
ability  everyone  gets  their  hat  in  the Hat-Check  problem  in  the  case  that  all  per­
mutations are equally likely.  But the probability of this event is 1/(n!).  So for this 
case, Markov’s Theorem gives a probability bound that is way off. 

= 

.

21.2.2  Markov’s Theorem for Bounded Variables 
Suppose  we  learn  that  the  average  IQ  among  MIT  students  is  150  (which  is  not 
true, by the way). What can we say about the probability that an MIT student has 
an IQ of more than 200? Markov’s theorem immediately tells us that no more than 
150/200 or 3/4 of  the  students  can have  such a high  IQ.  Here we  simply applied 
Markov’s  Theorem  to  the  random  variable,  R,  equal  to  the  IQ  of  a  random MIT 
student to conclude: 

=

Pr {R > 200} ≤ 

E [R] 
150 
3 
.
200 
200 
4 
But let’s observe an additional fact (which may be true): no MIT student has an 
IQ less than 100. This means that if we let T  ::= R − 100, then T  is nonnegative and 
E [T ] = 50, so we can apply Markov’s Theorem to T  and conclude: 
1 
50  =
E [T ]
Pr {R > 200} = Pr {T > 100} ≤ 
.
100 
100 
2 

= 

= 

492 

CHAPTER 21.  DEVIATION FROM THE MEAN 

So only half, not 3/4, of  the students can be as amazing as  they  think  they are.  A 
bit of a relief! 
More generally, we can get better bounds applying Markov’s Theorem to R − l 
instead of R for any lower bound l > 0 on R. 
Similarly, if we have any upper bound, u, on a random variable, S , then u − S 
will be a nonnegative random variable, and applying Markov’s Theorem to u − S 
will allow us to bound the probability that S  is much less than its expectation. 

21.2.3  Problems 
Class Problems 

Problem 21.1. 
A  herd  of  cows  is  stricken  by  an  outbreak  of  cold  cow  disease.  The  disease  lowers 
the normal body  temperature of a cow, and a cow will die  if  its  temperature goes 
below 90 degrees F. The disease epidemic is so intense that it lowered the average 
temperature  of  the  herd  to  85  degrees.  Body  temperatures  as  low  as  70  degrees, 
but no lower, were actually found in the herd. 
(a)  Prove that at most 3/4 of the cows could have survived. 
Hint: Let T  be the temperature of a random cow. Make use of Markov’s bound. 

(b)  Suppose  there  are  400  cows  in  the  herd.  Show  that  the  bound  of  part  (a)  is 
best  possible  by  giving  an  example  set  of  temperatures  for  the  cows  so  that  the 
average herd temperature is 85, and with probability 3/4, a randomly chosen cow 
will have a high enough temperature to survive. 

21.3  Chebyshev’s Theorem 

There’s  a  really  good  trick  for  getting  more  mileage  out  of  Markov’s  Theorem: 
instead of applying it to the variable, R, apply it to some function of R. One useful 
choice of functions to use turns out to be taking a power of |R|. 
In particular, since |R α  is nonnegative, Markov’s inequality also applies to the 
|
event [|R| ≥ xα ]. But this event is equivalent to the event [|R| ≥ x], so we have: 
α 
Lemma 21.3.1.  For any random variable R, α ∈ R+ , and x > 0, 
| α ] 
|R
E [
Pr {|R| ≥ x} ≤ 
. 
α
x
Rephrasing (21.3.1) in terms of the random variable, |R − E [R]|, that measures 
R’s deviation from its mean, we get 
E [(R − 
E [R])α ] 
Pr {|R − E [R]| ≥ x} ≤ 
. 
xα 
The  case when  α  = 2  is  turns  out  to  be  so  important  that  numerator  of  the  right 
hand side of (21.3) has been given a name: 

(21.3) 

21.3.  CHEBYSHEV’S THEOREM 

493 

� 
� 
Deﬁnition 21.3.2.  The variance, Var [R], of a random variable, R, is: 
Var [R] ::= E  (R − E [R])2 . 
The restatement of (21.3) for α = 2 is known as Chebyshev’s Theorem. 
Theorem 21.3.3 (Chebyshev).  Let R be a random variable and x ∈ R+ . Then 
Var [R] 
� 
� 
Pr {|R − E [R]
| ≥ x} ≤ 
.
x2 
The expression E  (R − E [R])2  for variance  is a bit  cryptic;  the best approach 
is  to work  through  it  from  the  inside out.  The  innermost expression, R − E [R],  is 
precisely the deviation of R above its mean.  Squaring this, we obtain, (R − E [R])2 . 
This is a random variable that is near 0 when R is close to the mean and is a large 
positive number when R deviates far above or below the mean.  So  if R  is always 
close to the mean, then the variance will be small.  If R is often far from the mean, 
then the variance will be large. 

21.3.1  Variance in Two Gambling Games 
The  relevance  of  variance  is  apparent when we  compare  the  following  two  gam­
bling games. 
Game A: We win $2 with probability 2/3 and lose $1 with probability 1/3. 
Game  B: We  win  $1002  with  probability  2/3  and  lose  $2001  with  probability 
1/3. 
Which  game  is  better  ﬁnancially?  We  have  the  same  probability,  2/3,  of win­
ning  each  game,  but  that  does  not  tell  the whole  story.  What  about  the  expected 
return  for  each  game?  Let  random  variables A  and B  be  the  payoffs  for  the  two 
games.  For example, A  is 2 with probability 2/3 and  -1 with probability 1/3.  We 
can compute the expected payoff for each game as follows: 
1
2
E [A] = 2 · 
+ (−1) · 
3 
3 
1
2
+ (−2001) · 
E [B ] = 1002 · 
3 
3 
The  expected  payoff  is  the  same  for  both  games,  but  they  are  obviously  very 
different!  This difference  is  not  apparent  in  their  expected  value,  but  is  captured 
� 
by  variance.  We  can  compute  the  Var [A]  by  working  “from  the  inside  out”  as 
follows: 
� 

= 1, 

= 1. 

1  with probability  3
2 
A − E [A] = 
−2  with probability  3
1 
1  with probability  2 
(A − E [A])2  =
�
� 
3 
4  with probability  1
3 
2
1
E  (A − E [A])2 = 1 · 
+ 4 · 
3

3 
Var [A] = 2.


494 
CHAPTER 21.  DEVIATION FROM THE MEAN 
Similarly, we have for Var [B ]:  � 
B − E [B ]  =  � 
1001 
2 
with probability
−2002 
3
1 
with probability
3 
1, 002, 001 
with probability 2 
(B − E [B ])2  = 
�
� 
3
4, 008, 004  with probability
1 
3
1
2
E  (B − E [B ])2 = 1, 002, 001 · 
+ 4, 008, 004 · 
3 
3 
Var [B ] = 2, 004, 002. 

The  variance  of  Game  A  is  2  and  the  variance  of  Game  B  is  more  than  two 
million!  Intuitively,  this means  that  the  payoff  in Game A  is  usually  close  to  the 
expected  value  of  $1,  but  the  payoff  in  Game  B  can  deviate  very  far  from  this 
expected value. 
High  variance  is  often  associated with  high  risk.  For  example,  in  ten  rounds 
of  Game  A,  we  expect  to  make  $10,  but  could  conceivably  lose  $10  instead.  On 
the  other  hand,  in  ten  rounds  of  game  B,  we  also  expect  to make  $10,  but  could 
actually lose more than $20,000! 

21.3.2  Standard Deviation 
Because of its deﬁnition in terms of the square of a random variable, the variance of 
a random variable may be very far from a typical deviation from the mean. For ex­
ample, in Game B above, the deviation from the mean is 1001 in one outcome and 
-2002  in  the other.  But  the variance  is a whopping 2,004,002.  From a dimensional 
analysis viewpoint, the “units” of variance are wrong:  if the random variable is in 
dollars, then the expectation is also in dollars, but the variance is in square dollars. 
For this reason, people often describe random variables using standard deviation 
instead of variance. 
Deﬁnition 21.3.4.  The standard deviation, σR , of a random variable, R, is the square 
� 
� 
root of the variance: 
σR  ::=  Var [R] =  E [(R − E [R])2 ]. 
So  the  standard  deviation  is  the  square  root  of  the mean  of  the  square  of  the 
deviation,  or  the  root mean  square  for  short.  It has  the  same units —dollars  in our 
example —as  the  original  random  variable  and  as  the mean.  Intuitively,  it mea­
sures  the average deviation  from  the mean,  since we  can  think of  the  square  root 
on the outside as canceling the square on the inside. 
� 
� 
Example 21.3.5.  The standard deviation of the payoff in Game B is: 
2, 004, 002 ≈ 1416. 
σB  =  Var [B ] = 
The random variable B actually deviates from the mean by either positive 1001 
or negative 2002; therefore, the standard deviation of 1416 describes this situation 
reasonably well. 

21.3.  CHEBYSHEV’S THEOREM 

495 

Figure 21.1: The standard deviation of a distribution indicates how wide the “main 
part” of it is. 

Intuitively, the standard deviation measures the “width” of the “main part” of 
the distribution graph, as illustrated in Figure 21.1. 
It’s useful to rephrase Chebyshev’s Theorem in terms of standard deviation. 

Corollary 21.3.6.  Let R be a random variable, and let c be a positive real number. 
Pr {|R − E [R]| ≥ cσR } ≤ 

1 
.
c2 
Here we see explicitly how the “likely” values of R are clustered in an O(σR )­
sized  region  around  E [R],  conﬁrming  that  the  standard  deviation measures  how 
spread out the distribution of R is around its mean. 

Proof.  Substituting x = cσR  in Chebyshev’s Theorem gives: 

Pr {|R − E [R]| ≥ cσR } ≤ 

Var [R] 
(cσR )2 

=

σ2 
R 
(cσR )2 

= 

1
. 
c2 

� 

The IQ Example 

Suppose  that,  in addition  to  the national average  IQ being 100, we also know  the 
standard deviation of IQ’s is 10. How rare is an IQ of 300 or more? 
Let  the  random  variable,  R,  be  the  IQ  of  a  random  person.  So  we  are  sup­
posing  that  E [R]  =  100,  σR  =  10,  and  R  is  nonnegative.  We  want  to  compute 
Pr {R ≥ 300}. 
We  have  already  seen  that  Markov’s  Theorem  21.2.1  gives  a  coarse  bound, 
namely, 

Pr {R ≥ 300} ≤ 

1
. 
3 

mean0100stdev496 

CHAPTER 21.  DEVIATION FROM THE MEAN 

Now we apply Chebyshev’s Theorem to the same problem: 
1 
102 
Var [R]
Pr {R ≥ 300} = Pr {|R − 100 ≥ 200} ≤ 
| 
.
400 
2002 
2002 
So Chebyshev’s Theorem implies that at most one person in four hundred has 
an  IQ of 300 or more.  We have gotten a much  tighter bound using  the additional 
information, namely the variance of R, than we could get knowing only the expec­
tation. 

= 

=

� 
� 
21.4  Properties of Variance 
The  deﬁnition  of  variance  of  R  as  E  (R − E [R])2  may  seem  rather  arbitrary.  A 
direct measure of average deviation would be E [ |R − E [R]| ].  But the direct mea­
sure doesn’t have the many useful properties that variance has, which is what this 
section is about. 

21.4.1  A Formula for Variance 
Applying  linearity of  expectation  to  the  formula  for variance yields  a  convenient 
�
� 
alternative formula. 
Lemma 21.4.1. 
Var [R] = E  R2 − E2  [R] , 

for any random variable, R. 
Here we use the notation E2  [R] as shorthand for (E [R])2 . 
� 
� 
Proof.  Let µ = E [R]. Then 
� 
� 
Var [R] = E  (R − E [R])2
� 
� 
= E  (R − µ)2
� 
� 
= E  R2  − 2µR + µ 2
� 
� 
= E  R2 − 2µ E [R] + µ 2 
� 
� 
= E  R2 − 2µ 2  + µ 2 
� 
� 
= E  R2 − µ 2 
= E  R2 − E2  [R] . 

(Def 21.3.2 of variance) 
(def of µ) 

(linearity of expectation) 
(def of µ) 

(def of µ) 

� 

For example, if B  is a Bernoulli variable where p ::= Pr {B = 1}, then 
Lemma 21.4.2. 

Var [B ] = p − p 2  = p(1 − p). 
(21.4) 
Proof.  By Lemma 20.3.3, E [B ] = p.  But since B  only takes values 0 and 1, B 2  = B . 
� 
So Lemma 21.4.2 follows immediately from Lemma 21.4.1. 

21.4.  PROPERTIES OF VARIANCE 

497 

21.4.2  Variance of Time to Failure 
According  to section 20.3.3,  the mean  time  to  failure  is 1/p  for a process  that  fails 
during  any  given  hour with  probability  p.  What  about  the  variance?  That  is,  let 
C  be  the hour of  the ﬁrst  failure,  so Pr {C  = i}  =  (1 − p)i−1p.  We’d  like  to ﬁnd a 
� 
� 
formula for Var [C ]. 
By Lemma 21.4.1, 
� 
� 
Var [C ] = E  C 2 − (1/p)2 
�  � 
� 
so all we need is a formula for E  C 2  : 
i2 (1 − p)i−1 p 
� 
E  C 2 ::= 
i≥1 
i2 x i−1 
i≥1 
But (17.2) gives the generating function x(1+x)/(1−x)3  for the nonnegative integer 
squares, and this implies that the generating function for the sum in (21.6) is (1 + 
x)/(1 − x)3 .  So, � 
C 2 � 
E 

(where x = 1 − p). 

(where x = 1 − p) 

(21.5) 

(21.6) 

= p

= p 

= p

(1 + x)
(1 − x)3 
2 + p
p3 
−
1 
p  + 
2 
p

=

1 
2 , 
p

(21.7) 

(21.8) 

Combining (21.5) and (21.7) gives a simple answer: 
−
1 
2 
p

Var [C ] = 

. 

p

It’s  great  to  be  able  apply  generating  function  expertise  to  knock  off  equa­
tion  (21.8)  mechanically  just  from  the  deﬁnition  of  variance,  but  there’s  a  more 
elementary, and memorable, alternative.  In section 20.3.3 we used conditional ex­
pectation  to  ﬁnd  the mean  time  to  failure,  and  a  similar  approach  works  for  the 
variance.  Namely,  the  expected  value  of C 2  is  the  probability,  p,  of  failure  in  the 
ﬁrst hour times 12 , plus (1 − p) times the expected value of (C + 1)2 .  So 
� 
� 
� 
� 
� 
�
�
� 
E  C 2 = p  12  + (1 − p) E  (C + 1)2
· 
2 
= p + (1 − p)  E  C 2 +  + 1 
, 
p 

which directly simpliﬁes to (21.7). 

498 

CHAPTER 21.  DEVIATION FROM THE MEAN 

21.4.3  Dealing with Constants 
It helps to know how to calculate the variance of aR + b: 

Theorem 21.4.3.  Let R be a random variable, and a a constant. Then 

(21.9) 

Var [aR] = a 2 Var [R] . 
Proof.  Beginning with the deﬁnition of variance and repeatedly applying linearity 
� 
� 
of expectation, we have: 
� 
� 
Var [aR] ::= E  (aR − E [aR])2
� 
� 
= E  (aR)2  − 2aR E [aR] + E2  [aR] 
� 
� 
= E  (aR)2 − E [2aR E [aR]] + E2  [aR] 
� 
� 
= a 2 E  R2 − 2 E [aR] E [aR] + E2  [aR] 
� 
�  � 
� 
= a 2 E  R2 − a 2E2  [R] 
= a 2  E  R2 − E2  [R] 
= a 2 Var [R] 

(by Lemma 21.4.1) 

� 

It’s even simpler to prove that adding a constant does not change the variance, 
as the reader can verify: 

Theorem 21.4.4.  Let R be a random variable, and b a constant. Then 

Var [R + b] = Var [R] . 

(21.10) 

Recalling that the standard deviation is the square root of variance, this implies 
that the standard deviation of aR + b is simply |a| times the standard deviation of 
R: 

Corollary 21.4.5. 

σaR+b  = |a| σR . 

21.4.4  Variance of a Sum 
In  general,  the  variance  of  a  sum  is  not  equal  to  the  sum  of  the  variances,  but 
variances  do  add  for  independent  variables.  In  fact,  mutual  independence  is  not 
necessary:  pairwise independence will do. This is useful to know because there are 
some  important  situations  involving  variables  that  are pairwise  independent  but 
not mutually independent. 

Theorem 21.4.6.  If R1  and R2  are independent random variables, then 

Var [R1  + R2 ] = Var [R1 ] + Var [R2 ] . 

(21.11) 

21.4.  PROPERTIES OF VARIANCE 

499 

Proof.  We may assume  that E [Ri ] = 0  for  i  = 1, 2,  since we  could always  replace 
� 
� 
� 
� 
Ri  by Ri − E [Ri ] in equation (21.11). This substitution preserves the independence 
of the variables, and by Theorem 21.4.4, does not change the variances. 
Now by Lemma 21.4.1, Var [Ri ] =  E  Ri 
2  and Var [R1  + R2 ] =  E  (R1  + R2 )2  , 
� 
� 
� 
� 
� 
� 
so we need only prove 
2  + E  R2
2  . 
E  (R1  + R2 )2 = E  R1
But (21.12) follows from linearity of expectation and the fact that 
E [R1R2 ] = E [R1 ] E [R2 ] 
� 
� 
� 
� 
since R1  and R2  are independent: 
� 
� 
� 
� 
2 
2  + 2R1R2  + R2
E  (R1  + R2 )2 = E  R1
� 
� 
� 
� 
2 
1  + 2 E [R1R2 ] + E  R2
= E  R2
� 
� 
� 
� 
1  + 2 E [R1 ] E [R2 ] + E  R2
= E  R2
�  1 � 
· � 
· � 
2 
= E  R2  + 2  0  0 + E  R2 
2 
2 
= E  R2
1  + E  R2

(by (21.13)) 

(21.13) 

(21.12) 

� 
An independence condition is necessary.  If we ignored independence, then we 
would conclude that Var [R + R] = Var [R] + Var [R]. However, by Theorem 21.4.3, 
the left side is equal to 4 Var [R], whereas the right side is 2 Var [R]. This implies that 
Var [R] = 0, which, by the Lemma above, essentially only holds if R is constant. 
The  proof  of  Theorem  21.4.6  carries  over  straightforwardly  to  the  sum  of  any 
ﬁnite number of variables.  So we have: 
Theorem  21.4.7.  [Pairwise  Independent  Additivity  of  Variance]  If  R1 , R2 , . . . , Rn  are 
pairwise independent random variables, then 
· · · 
· · · 
Var [R1  + R2  +
+ Rn ] = Var [R1 ] + Var [R2 ] +  + Var [Rn ] . 
�
Now  we  have  a  simple  way  of  computing  the  variance  of  a  variable,  J ,  that 
n 
has  an  (n, p)-binomial distribution.  We  know  that  J  = 
=1 Ik  where  the  Ik  are 
mutually  independent  indicator  variables with  Pr {Ik  = 1}  =  p.  The  variance  of 
k
each Ik  is p(1 − p) by Lemma 21.4.2, so by linearity of variance, we have 
Lemma (Variance of the Binomial Distribution).  If J  has the (n, p)-binomial distribu­
tion, then 
Var [J ] = n Var [Ik ] = np(1 − p). 

(21.15) 

(21.14)

21.4.5  Problems 
Practice Problems 

Problem 21.2. 
A gambler plays 120 hands of draw poker, 60 hands of black jack, and 20 hands of 

500 

CHAPTER 21.  DEVIATION FROM THE MEAN 

stud poker per day. He wins a hand of draw poker with probability 1/6, a hand of 
black jack with probability 1/2, and a hand of stud poker with probability 1/5. 
(a)  What is the expected number of hands the gambler wins in a day? 

(b)  What  would  the Markov  bound  be  on  the  probability  that  the  gambler  will 
win at least 108 hands on a given day? 

(c)  Assume  the  outcomes  of  the  card  games  are  pairwise  independent.  What  is 
the variance in the number of hands won per day? 

(d)  What  would  the  Chebyshev  bound  be  on  the  probability  that  the  gambler 
will  win  at  least  108  hands  on  a  given  day?  You  may  answer  with  a  numerical 
expression that is not completely evaluated. 

Class Problems 

Problem 21.3. 
The  hat-check  staff  has  had  a  long  day  serving  at  a  party,  and  at  the  end  of  the 
party they simply return people’s hats at random.  Assume that n people checked 
hats at the party. 
Let  Xi  =  �

(a)	 What is the expected number of people who get their own hat back?

1  be  the  indicator  variable  for  the  ith  person  getting  their  own  hat 
n
back. Let Sn  = 
i=1 Xi , so Sn  is the total number of people who get their own hat 
back. 
j . Hint: What is Pr {Xj  = 1  |  Xi  = 1}? 
(b)  Write a simple formula for E [XiXj ] for i =�
� 
� 
(c)  Explain why you cannot use the variance of sums formula to calculate Var [Sn ]. 
2  = 2. Hint: Xi 
2  = Xi . 
(d)  Show that E  Sn 
(e)  What is the variance of Sn ? 

(f)  Use the Chebyshev bound to show that the probability that 11 or more people 
get their own hat back is at most 0.01. 

Problem 21.4. 
For any random variable, R, with mean, µ, and standard deviation, σ , the Cheby­
shev Bound says that for any real number x > 0, � σ �2 
Pr {|R − µ| ≥ x} ≤ 
.
x 
Show  that  for any  real number,  µ,  and  real numbers x  ≥  σ >  0,  there  is an R  for 
which the Chebyshev Bound is tight, that is,  � σ �2 
Pr {|R| ≥ x} = 
x

(21.16) 

. 

21.5.  ESTIMATION BY RANDOM SAMPLING 

501 

Hint:  First assume µ = 0 and let R only take values 0, −x, and x. 

Problem 21.5. 
Let R be a positive integer valued random variable such that 
1 
fR (n) = 
, 
cn3 
� 
∞
c ::= 
n=1 

1 
. 
n3 

where 

(a)  Prove that E [R] is ﬁnite. 

(b)  Prove that Var [R] is inﬁnite. 

Homework Problems 

Problem 21.6. 
There is a “one-sided” version of Chebyshev’s bound for deviation above the mean: 

Lemma (One-sided Chebyshev bound). 
Var [R] 
Pr {R − E [R] ≥ x} ≤ 
.
x2  + Var [R] 
� 
� 
Hint:  Let  Sa  ::=  (R − E [R] + a)2 ,  for  0  ≤  a  ∈  R.  So  R − E [R]  ≥  x  implies 
Sa  ≥ (x+a)2 . Apply Markov’s bound to Pr  Sa  ≥ (x + a)2  . Choose a to minimize 
this last bound. 

Problem 21.7. 
A man  has  a  set  of  n  keys,  one  of which  ﬁts  the  door  to  his  apartment.  He  tries 
the keys until he ﬁnds  the  correct one.  Give  the  expectation  and variance  for  the 
number of trials until success if 
(a)  he tries the keys at random (possibly repeating a key tried earlier) 

(b)  he chooses keys randomly from among those he has not yet tried. 

21.5  Estimation by Random Sampling 

Polling again 

Suppose we had wanted an advance estimate of the fraction of the Massachusetts 
voters who  favored Scott Brown over everyone else  in  the  recent Democratic pri­
mary election to ﬁll Senator Edward Kennedy’s seat. 

502 

CHAPTER 21.  DEVIATION FROM THE MEAN 

Let p be  this unknown  fraction,  and  let’s suppose we have some  random pro­
cess —say throwing darts at voter registration lists —which will select each voter 
with  equal  probability.  We  can  deﬁne  a  Bernoulli  variable,  K ,  by  the  rule  that 
K  = 1 if the random voter most prefers Brown, and K  = 0 otherwise. 
Now  to  estimate  p,  we  take  a  large  number,  n,  of  random  choices  of  voters1 
and count the fraction who favor Brown.  That  is, we deﬁne variables K1 , K2 , . . . , 
where Ki  is  interpreted  to be  the  indicator variable  for  the event  that  the  ith cho­
sen  voter prefers Brown.  Since  our  choices  are made  independently,  the Ki ’s  are 
independent.  So  formally, we model  our  estimation process by  simply  assuming 
we have mutually independent Bernoulli variables K1 , K2 , . . . , each with the same 
probability, p, of being equal to 1. Now let Sn  be their sum, that is, 
� 
n
Sn  ::=  Ki . 
i=1 

(21.17) 

So Sn  has  the binomial distribution with parameter n, which we  can  choose,  and 
unknown parameter p. 
The  variable  Sn/n  describes  the  fraction  of  voters  we  will  sample  who  favor 
Scott Brown.  Most people  intuitively  expect  this  sample  fraction  to  give  a useful 
approximation  to  the unknown fraction, p —and  they would be right.  So we will 
use  the  sample  value,  Sn/n,  as  our  statistical  estimate  of  p  and  use  the  Pairwise 
Independent Sampling Theorem 21.5.1 to work out how good an estinate this is. 

21.5.1  Sampling 
Suppose we want our estimate to be within 0.04 of the Brown favoring fraction, p, 
����� 
����
� 
at least 95% of the time. This means we want 
≤ 0.04  ≥ 0.95 . 
− p 
Sn 
Pr 
n 
So we better determine the number, n, of times we must poll voters so that inequal­
ity (21.18) will hold. 
Now Sn  is binomially distributed, so from (21.15) we have 

(21.18) 

Var [Sn ] = n(p(1 − p)) ≤ n · 

1 
n
4 
4
The bound of 1/4 follows from the fact that p(1 − p) is maximized when p = 1 − p, 
that is, when p = 1/2 (check this yourself!). 

=

1We’re choosing a random voter n  times with replacement.  That  is, we don’t remove a chosen voter 
from the set of voters eligible to be chosen later; so we might choose the same voter more than once in 
n tries! We would get a slightly better estimate if we required n different people to be chosen, but doing 
so complicates both the selection process and its analysis, with little gain in accuracy. 

503 

(21.19)

Var [Sn

] 

(by (21.9)) 

21.5.  ESTIMATION BY RANDOM SAMPLING 
�21
� 
�  �
Next, we bound the variance of Sn/n: 
�
n �21 
Sn  = 
Var 
n
n 
1 
4n 
����
����� 
� 
Now from Chebyshev and (21.19) we have: 
− p  ≥ 0.04  ≤ 
Sn 
Pr 
n 
To  make  our  our  estimate  with  95%  conﬁdence,  we  want  the  righthand  side 
of (21.20) to be at most 1/20.  So we choose n so that 
≤ 

Var [Sn/n] 
(0.04)2 

1 
4n(0.04)2 

156.25 
n 

(by (21.5.1)) 

=

= 

(21.20)

n 
4 

≤ 

= 

156.25 
n 

1 
, 
20 

that is, 

n ≥ 3, 125. 
A more exact calculation of the tail of this binomial distribution shows that the 
above sample size is about four times larger than necessary, but it is still a feasible 
size to sample.  The fact that the sample size derived using Chebyshev’s Theorem 
was unduly pessimistic should not be surprising. After all, in applying the Cheby­
shev Theorem, we only used the variance of Sn .  It makes sense that more detailed 
information  about  the  distribution  leads  to  better  bounds.  But working  through 
this example using only  the variance has  the virtue of  illustrating an approach  to 
estimation that is applicable to arbitrary random variables, not just binomial vari­
ables. 

21.5.2  Matching Birthdays 
There  are  important  cases  where  the  relevant  distributions  are  not  binomial  be­
cause the mutual independence properties of the voter preference example do not 
hold.  In  these  cases,  estimation  methods  based  on  the  Chebyshev  bound  may 
be  the  best  approach.  Birthday Matching  is  an  example.  We  already  saw  in  Sec­
tion  18.5  that  in  a  class  of  85  students  it  is  virtually  certain  that  two  or more  stu­
dents will have the same birthday. This suggests that quite a few pairs of students 
are likely to have the same birthday. How many? 
So as before, suppose there are n students and d days in the year, and let D be 
the  number  of  pairs  of  students  with  the  same  birthday.  Now  it  will  be  easy  to 
calculate the expected number of pairs of students with matching birthdays. Then 
we  can  take  the  same  approach  as  we  did  in  estimating  voter  preferences  to  get 

504 

CHAPTER 21.  DEVIATION FROM THE MEAN 

an  estimate  of  the  probability  of  getting  a  number  of  pairs  close  to  the  expected 
number. 
Unlike the situation with voter preferences, having matching birthdays for dif­
ferent  pairs  of  students  are  not mutually  independent  events,  but  the matchings 
are pairwise independent, as explained in Section 18.5. as we did for voter preference. 
Namely, let B1 , B2 , . . . , Bn  be the birthdays of n independently chosen people, and 
let Ei,j  be  the  indicator  variable  for  the  event  that  the  ith  and  j th  people  chosen 
have  the  same  birthdays,  that  is,  the  event  [Bi  =  Bj ].  So  our  probability model, 
the Bi ’s are mutually  independent variables,  the Ei,j ’s are pairwise  independent. 
Also, the expectations of Ei,j  for i =�
j equals the probability that Bi  = Bj , namely, 
1/d. 
Now,  D ,  the  number  of  matching  pairs  of  birthdays  among  the  n  choices  is 
� 
simply the sum of the Ei,j ’s: 
D ::= 
Ei,j . 
1≤i<j≤n 
⎤ 
⎡
So by linearity of expectation 
� 
E [D] = E ⎣  � 
Ei,j ⎦ = 
E [Ei,j ] = 
1≤i<j≤n 
1≤i<j≤n 
⎤ 
⎡ 
� 
Var [D] = Var ⎣ 
Ei,j ⎦ 
� 
1≤i<j≤n 
� 
�  �  � 
= 
Var [Ei,j ] 
1≤i<j≤n 
1 
1
n 
· 
1 − 
. 
2 
d 
d

�  � 
n 
· 
2 

(by Theorem 21.4.7) 

=

(byLemma 21.4.2) 

(21.21) 

1 
. 
d 

Similarly, 

In particular, for a class of n = 85 students with d = 365 possible birthdays, we 
have E [D] ≈ 9.7 and Var [D ] < 9.7(1 − 1/365) < 9.7.  So by Chebyshev’s Theorem 
9.7 
Pr {|D − 9.7| ≥ x} <
.
x2 
Letting  x  = 5,  we  conclude  that  there  is  a  better  than  50%  chance  that  in  a 
class  of  85  students,  the number  of pairs  of  students with  the  same birthday will 
be between 5 and 14. 

21.5.3  Pairwise Independent Sampling 
The  reasoning we used above  to analyze voter polling and matching birthdays  is 
very similar. We summarize it in slightly more general form with a basic result we 

21.5.  ESTIMATION BY RANDOM SAMPLING 

505 

Then 

= 

(21.22) 

.

(def of Sn ) 

(linearity of expectation) 

call  the  Pairwise  Independent  Sampling  Theorem.  In  particular,  we  do  not  need 
to restrict ourselves to sums of zero-one valued variables, or to variables with the 
same distribution.  For simplicity, we state the Theorem for pairwise independent 
variables with  possibly  different  distributions  but with  the  same mean  and  vari­
ance. 
Theorem 21.5.1 (Pairwise Independent Sampling).  Let G1 , . . . , Gn  be pairwise inde­
� 
pendent variables with the same mean, µ, and deviation, σ . Deﬁne 
n
Sn  ::= 
Gi . 
����
���� 
�
� 
1 � σ �2
i=1 
≥ x  ≤ 
− µ 
Sn 
Pr 
n 
n x
� �
� 
� 
� 
Proof.  We observe ﬁrst that the expectation of Sn/n is µ: 
n  Gi
�
Sn
= E 
i=1
E 
n 
n
�
n 
i=1 E [Gi ] 
n 
n 
i=1 µ
= 
n 
nµ=
= µ. 
n 
The second important property of Sn/n is that its variance is the variance of Gi 
� 
�  �
�21
divided by n: 
� �  � 
Sn  =
Var [Sn ] 
Var 
n 
n
n
1 
Var 
Gi 
� 
n2 
i=1 
n
1 
Var [Gi ] 
n2 
i=1 
1 
σ2 
n2  · 
nσ2  = 
. 
n 
����
����� 
� 
This is enough to apply Chebyshev’s Theorem and conclude: 
Var [Sn/n] 
Sn  − µ 
≥ x  ≤ 
Pr 
.
n 
x2
�
1  σ �2 
σ2/n
x2 
n  x 

(pairwise independent additivity) 

(Chebyshev’s bound) 

(by (21.23)) 

= 

= 

= 

(by (21.9)) 

(def of Sn )

= 

= 

. 

(21.23) 

506 

CHAPTER 21.  DEVIATION FROM THE MEAN 

� 
The Pairwise Independent Sampling Theorem provides a precise general state­
ment  about  how  the  average  of  independent  samples  of  a  random  variable  ap­
proaches  the  mean.  In  particular,  it  proves  what  is  known  as  the  Law  of  Large 
Numbers2  :  by  choosing  a  large  enough  sample  size, we  can get  arbitrarily  accu­
rate estimates of the mean with conﬁdence arbitrarily close to 100%. 
Corollary 21.5.2.  [Weak Law of Large Numbers] Let G1 , . . . , Gn  be pairwise independent 
�
variables with the same mean, µ, and the same ﬁnite deviation, and let 
n  Gi
i=1 
n 

Sn  ::= 

. 

Then for every � > 0, 

lim  Pr {|Sn  − µ| ≤ �} = 1. 
n→∞ 

21.6  Conﬁdence versus Probability 

So Chebyshev’s Bound implies that sampling 3,125 voters will yield a fraction that, 
95% of the time, is within 0.04 of the actual fraction of the voting population who 
prefer Brown. 
Notice  that  the  actual  size  of  the  voting  population was  never  considered  be­
cause it did not matter. People who have not studied probability theory often insist 
that the population size should matter.  But our analysis shows that polling a little 
over  3000  people  people  is  always  sufﬁcient,  whether  there  are  ten  thousand,  or 
million, or billion  . . . voters.  You should  think about an  intuitive explanation  that 
might persuade someone who thinks population size matters. 
Now  suppose  a pollster  actually  takes  a  sample of  3,125  random voters  to  es­
timate the fraction of voters who prefer Brown, and the pollster ﬁnds that 1250 of 
them prefer Brown.  It’s tempting, but sloppy, to say that this means: 
False Claim.  With probability 0.95, the fraction, p, of voters who prefer Brown is 1250/3125±
0.04.  Since 1250/3125 − 0.04 >  1/3, there is a 95% chance that more than a third of the 
voters prefer Brown to all other candidates. 
What’s objectionable about  this  statement  is  that  it  talks about  the probability 
or  “chance”  that  a  real  world  fact  is  true,  namely  that  the  actual  fraction,  p,  of 
voters favoring Brown is more than 1/3. But p is what it is, and it simply makes no 
sense to talk about the probability that it is something else.  For example, suppose 
p is actually 0.3; then it’s nonsense to ask about the probability that it is within 0.04 
of 1250/3125 —it simply isn’t. 
This  example  of  voter  preference  is  typical:  we  want  to  estimate  a  ﬁxed,  un­
known real-world quantity.  But being unknown does not make this quantity a random 
variable, so it makes no sense to talk about the probability that it has some property. 

2 This is the Weak Law of Large Numbers. As you might suppose, there is also a Strong Law, but it’s 
outside the scope of 6.042. 

21.6.  CONFIDENCE VERSUS PROBABILITY 

507 

A more careful summary of what we have accomplished goes this way: 

We have described a probabilistic procedure for estimating the value of 
the actual  fraction,  p.  The probability  that  our  estimation procedure will 
yield a value within 0.04 of p is 0.95. 

This  is  a  bit  of  a  mouthful,  so  special  phrasing  closer  to  the  sloppy  language  is 
commonly used. The pollster would describe his conclusion by saying that 

At  the  95%  conﬁdence  level,  the  fraction  of  voters who  prefer  Brown  is 
1250/3125 ± 0.04. 
So conﬁdence levels refer to the results of estimation procedures for real-world 
quantities. The phrase “conﬁdence level” should be heard as a reminder that some 
statistical procedure was used to obtain an estimate, and in judging the credibility 
of the estimate, it may be important to learn just what this procedure was. 

21.6.1  Problems 
Practice Problems 

Problem 21.8. 
You  work  for  the  president  and  you  want  to  estimate  the  fraction  p  of  voters  in 
the  entire  nation  that  will  prefer  him  in  the  upcoming  elections.  You  do  this  by 
random  sampling.  Speciﬁcally,  you  select n voters  independently  and  randomly, 
ask  them who  they are going  to vote  for,  and use  the  fraction P  of  those  that  say 
they will vote for the President as an estimate for p. 
(a)  Our theorems about sampling and distributions allow us to calculate how con­
ﬁdent we  can  be  that  the  random  variable,  P ,  takes  a  value  near  the  constant,  p. 
This calculation uses some facts about voters and the way they are chosen. Which 
of the following facts are true? 

1.  Given a particular voter, the probability of that voter preferring the President 
is p. 
2.  Given a particular voter, the probability of that voter preferring the President 
is 1 or 0. 
3.  The probability that some voter is chosen more than once in the sequence goes 
to zero as n increases. 
4.  All  voters  are  equally  likely  to  be  selected  as  the  third  in  our  sequence  of  n 
choices of voters (assuming n ≥ 3). 
5.  The  probability  that  the  second  voter  chosen will  favor  the  President,  given 
that the ﬁrst voter chosen prefers the President, is greater than p. 
6.  The  probability  that  the  second  voter  chosen will  favor  the  President,  given 
that the second voter chosen is from the same state as the ﬁrst, may not equal 
p. 

508 

CHAPTER 21.  DEVIATION FROM THE MEAN 

(b)  Suppose that according to your calculations, the following is true about your 
polling: 
Pr {|P  − p| ≤ 0.04} ≥ 0.95. 

You do the asking, you count how many said they will vote for the President, you 
divide  by  n,  and  ﬁnd  the  fraction  is  0.53.  You  call  the  President,  and  . . . what  do 
you say? 

1.  Mr. President, p = 0.53! 
2.  Mr. President, with probability at least 95 percent, p is within 0.04 of 0.53. 
3.  Mr.  President, either p is within 0.04 of 0.53 or something very strange (5-in­
100) has happened. 
4.  Mr. President, we can be 95% conﬁdent that p is within 0.04 of 0.53. 

Class Problems 

Problem 21.9. 
A  recent Gallup poll  found  that  35% of  the  adult population of  the United  States 
believes that the theory of evolution  is “well-supported by the evidence.”  Gallup 
polled 1928 Americans selected uniformly and independently at random. Of these, 
675  asserted  belief  in  evolution,  leading  to  Gallup’s  estimate  that  the  fraction  of 
Americans who believe in evolution is 675/1928  ≈  0.350.  Gallup claims a margin 
of error of 3 percentage points, that is, he claims to be conﬁdent that his estimate is 
within 0.03 of the actual percentage. 
(a)  What is the largest variance an indicator variable can have? 

(b)  Use  the Pairwise  Independent Sampling Theorem  to determine a  conﬁdence 
level with which Gallup can make his claim. 

(c)  Gallup  actually  claims  greater  than  99%  conﬁdence  in  his  estimate.  How 
might  he  have  arrived  at  this  conclusion?  (Just  explain  what  quantity  he  could 
calculate; you do not need to carry out a calculation.) 

(d)  Accepting  the  accuracy  of  all  of  Gallup’s  polling  data  and  calculations,  can 
you conclude  that  there  is a high probability  that  the number of adult Americans 
who believe in evolution is 35 ± 3 percent? 

Problem 21.10. 
Suppose  there  are n  students  and  d days  in  the  year,  and  let D  be  the  number  of 
pairs of students with the same birthday.  Let B1 , B2 , . . . , Bn  be the birthdays of n 
independently  chosen  people,  and  let Ei,j  be  the  indicator  variable  for  the  event 
[Bi  = Bj ]. 
(a)  What are E [Ei,j ] and Var [Ei,j ]? 

21.6.  CONFIDENCE VERSUS PROBABILITY 

509 

(b)  What is E [D]? 

(c)  What is Var [D]? 

(d)  In a 6.01 class of 500 students, the youngest student was born in 1995 and the 
oldest  in  1975.  Let  S  be  the  number  of  students  in  the  class  who  were  born  on 
exactly  the  same  day.  What  is  the  probability  that  4  ≤  S  ≤  32?  (For  simplicity, 
assume that the distribution of birthdays is uniform over the 7305 days in the two 
decade interval from 1975 to 1995.) 

Problem 21.11. 
A defendent in trafﬁc court is trying to beat a speeding ticket on the grounds that 
—since virtually everybody speeds on the turnpike —the police have unconstitu­
tional  discretion  in  giving  tickets  to  anyone  they  choose.  (By  the  way,  we  don’t 
recommend this defense :-) ) 
To  support  his  argument,  the  defendent  arranged  to  get  a  random  sample  of 
trips  by  3,125  cars  on  the  turnpike  and  found  that  94%  of  them  broke  the  speed 
limit  at  some  point  during  their  trip.  He  says  that  as  a  consequence  of  sampling 
theory (in particular, the Pairwise Independent Sampling Theorem), the court can 
be 95% conﬁdent that the actual percentage of all cars that were speeding is 94±4%. 
The  judge  observes  that  the  actual  number  of  car  trips  on  the  turnpike  was 
never considered in making this estimate. He is skeptical that, whether there were 
a thousand, a million, or 100,000,000 car trips on the turnpike, sampling only 3,125 
is sufﬁcient to be so conﬁdent. 
Suppose  you were were  the defendent.  How would  you  explain  to  the  judge 
why  the  number  of  randomly  selected  cars  that  have  to  be  checked  for  speeding 
does not depend on the number of recorded trips? Remember that judges are not trained 
to understand  formulas,  so you have  to provide an  intuitive,  nonquantitative  ex­
planation. 

Problem 21.12. 
The  proof  of  the  Pairwise  Independent  Sampling  Theorem  21.5.1  was  given  for 
a  sequence  R1 , R2 , . . .  of  pairwise  independent  random  variables  with  the  same 
mean and variance. 
The  theorem  generalizes  straighforwardly  to  sequences  of  pairwise  indepen­
dent  random  variables,  possibly  with  different  distributions,  as  long  as  all  their 
variances are bounded by some constant. 

Theorem  (Generalized  Pairwise  Independent  Sampling).  Let  X1 , X2 , . . .  be  a  se­
quence  of pairwise  independent  random variables  such  that Var [Xi ]  ≤  b  for  some  b  ≥  0 

510 

CHAPTER 21.  DEVIATION FROM THE MEAN 

and all i ≥ 1.  Let 

X1  + X2  + · · · + Xn , 
An  ::= 
n 
µn  ::= E [An ] . 

Then for every � > 0, 

b  1
�2  · 
Pr {|An  − µn | > �} ≤ 
n
(a)  Prove the Generalized Pairwise Independent Sampling Theorem. 

. 

(21.24) 

(b)  Conclude that the following holds: 
Corollary (Generalized Weak Law of Large Numbers).  For every � > 0, 
lim  Pr {|An  − µn | ≤ �} = 1. 
n→∞ 

Problem 21.13. 
An  International  Journal  of  Epidemiology  has  a  policy  that  they  will  only  publish 
the results of a drug  trial when  there were enough patients  in  the drug  trial  to be 
sure that the conclusions about the drug’s effectiveness hold at the 95% conﬁdence 
level.  The editors of the Journal reason that under this policy, their readership can 
be conﬁdent that at most 5% of the published studies will be mistaken. 
Later, the editors are astonished and embarrassed to learn that every one of the 
20  drug  trial  results  they  published  during  the  year  was  wrong.  This  happened 
even  though  the editors and reviewers had carefully checked  the submitted data, 
and  every  one  of  the  trials  was  properly  performed  and  reported  in  the  published 
paper. 
The editors  thought  the probability of  this was negligible  (namely,  (1/20)20  < 
10−25 ).  Explain what’s wrong with their reasoning and how it could be that all 20 
published studies were wrong. 

Exam Problems 

Problem 21.14. 
Yesterday, the programmers at a local company wrote a large program. To estimate 
the  fraction,  b,  of  lines  of  code  in  this  program  that  are  buggy,  the QA  team will 
take a small sample of lines chosen randomly and independently (so it is possible, 
though unlikely,  that the same line of code might be chosen more than once).  For 
each  line  chosen,  they  can  run  tests  that  determine  whether  that  line  of  code  is 
buggy, after which they will use the fraction of buggy lines in their sample as their 
estimate of the fraction b. 
The company statistician can use estimates of a binomial distribution to calcu­
late  a  value,  s,  for  a  number  of  lines  of  code  to  sample  which  ensures  that  with 
97%  conﬁdence,  the  fraction  of  buggy  lines  in  the  sample will  be within  0.006  of 
the actual fraction, b, of buggy lines in the program. 

21.6.  CONFIDENCE VERSUS PROBABILITY 

511 

Mathematically,  the program  is an actual outcome  that already happened.  The 
sample  is a random variable deﬁned by  the process  for randomly choosing s  lines 
from  the  program.  The  justiﬁcation  for  the  statistician’s  conﬁdence  depends  on 
some  properties  of  the  program  and  how  the  sample  of  s  lines  of  code  from  the 
program  are  chosen.  These  properties  are  described  in  some  of  the  statements 
below.  Indicate which of these statements are true, and explain your answers. 

1.  The probability that the ninth line of code in the program is buggy is b. 

2.  The probability that the ninth line of code chosen for the sample is defective, 
is b. 

3.  All lines of code in the program are equally likely to be the third line chosen 
in the sample. 

4.  Given  that  the  ﬁrst  line  chosen  for  the  sample  is  buggy,  the  probability  that 
the second line chosen will also be buggy is greater than b. 

5.  Given that the last line in the program is buggy, the probability that the next-
to-last line in the program will also be buggy is greater than b. 

6.  The expectation of  the  indicator variable  for  the  last  line  in  the sample being 
buggy is b. 

7.  Given that the ﬁrst two lines of code selected in the sample are the same kind 
of statement —they might both be assignment statements, or both be condi­
tional  statements,  or  both  loop  statements,. . . —the  probability  that  the  ﬁrst 
line is buggy may be greater than b. 

8.  There is zero probability that all the lines in the sample will be different. 

Index 

−, set difference, 52 
(k1 , k2 , . . . , km )-split of A, 353 
<B , 158 
<G , 158 
Cn , 180 
IE , indicator for event E , 460 
K3,3 , 234, 245 
K5 , 234, 242, 245 
Kn , 171 
Θ(), 325 
bij, 62 
|S | (size of set S ), 333 
C, 52 
| (divides relation), 273 
∅, 52 
::=, 16 
≡  (mod  n), 289 
∃, 74 
E [R], expectation of R, 471 
E2  [R], 496 
∀, 16 
∈, 16 
inj, 62, 66 
Z, 52 
∩, 52 
λ, 55 
N, 16, 52 
A, 52 
Z+ , 17 
P (A), 53 
Q, 52 
R, 52 
R− , 52 
R+ , 52 
∼, 322 

∼ (asymptotic equality), 315 
strict, 62 
⊂, 52 
⊆, 52 
surj, 62 
∪, 52 
k-coloring, 197 
k-combinations, 355 
k-to-1 function, 347 
k-way independent, 441 
n + 1-bit adder, 101 
r-permutation, 351 
IQ, 489, 495 
2-D Array, 269 
2-Layer Array, 269 
2-colorable, 199 
2-dimensional array, 257 
5-Colorability, 243 

acyclic, 187 
Addition  Rule  (for  generating  func­
tions), 387 
adjacent, 168 
Adleman, 300 
Agrawal, 275 
annuity, 307 
antecedents, 19 
antichain, 114, 116, 121 
a posteriori, 434 
approximations, 314 
arrows, 129 
asymmetry, 110 
asymptotically equal, 315 
asymptotically smaller, 323 
asymptotic relations, 327 

512 

INDEX 

average, 489

average degree, 170, 192

axiomatic method, 19

Axiom of Choice, 84

axioms, 14, 18


Banach-Tarski, 84

base case, 94

basis step, 94

Bayes’ Rule, 435

Bene ˘s nets, 261

Bernoulli variable, 496

Bernoulli variables, 460

biased, 446

Big Oh, 326

bijection, 378

Bijection Rule, 333

bijective, 60

binary predicate, 77

binary relation, 58

binary relations, 57

binary trees, 221

binomial, 376

binomial coefﬁcient, 377

binomial coefﬁcients, 340

binomial distribution, 467, 477, 499

Binomial Theorem, 377, 398

bipartite graph, 198, 199, 206

bipartite matching, 199

birthday principle, 444

Bookkeeper Rule, 401

Book Stacking, 311

Boole’s inequality, 421

Boolean variables, 38

bottleneck, 202

bridge, 236

buildup error, 183

busy, 481

butterﬂy, 259

butterﬂy net, 272


Cancellation, 294

Cantor, 84

Cantor ’s paradise, 85

cardinality, 333


513 

carry bit, 46

chain, 116, 120

chain of “iff ”, 24

Chebyshev’s bound, 501

Chebyshev’s Theorem, 493, 503, 505

Chebyshev bound, 500

Chinese Appetizer problem, 491

Choice axiom, 82

chromatic number, 193

Church-Turing thesis, 287

closed form, 308, 314, 386, 392

CML, 270, 271

codomain, 55, 58

Cohen, 84

colorable, 193

coloring, 193, 197

combinatorial proof, 333, 381, 384

complement, 52

Complement Rule, 421

complete binary tree, 253

complete bipartite, 159

complete bipartite graph, 234

complete digraph, 133

complete graph, 171

components, 55

composing, 57

composite, 274

composition, 57, 115, 131

conclusion, 19, 39

conditional expectation, 473, 474

conditional probability, 425

conﬁdence level, 507

congestion, 257, 272

congestion for min-latency, 270, 271

congestion of the network, 257

congruence, 289

congruent, 289

connected, 180, 184

connected components, 180

consequent, 19

consistent, 85

Continuum Hypothesis, 84

contrapositive, 22, 43

convergence, 385

converse, 43


514 

INDEX 

convolution, 390

Convolution Counting Principle, 401

Convolution Rule, 399

corollary, 18

countable, 64, 65, 85

countably inﬁnite, 65

counter model, 78

coupon collector problem, 478

cover, 132

covering edge, 133

critical path, 120, 121

cumulative distribution function (cdf),

463

cycle, 131, 179


DAG, 133

degree, 168

degree-constrained, 202, 358, 361

degree sequence, 378

depth, 120

derivative, 388

Derivative Rule, 389

describable, 87

deviation from the mean, 489

diagonal argument, 85

diameter, 255

Difference Rule, 421

digraph, 129

directed acyclic graph (DAG), 131

directed edges, 129

directed graph, 129

discrete faces, 237

disjoint, 53

Distributive Law, 54, 76

divides, 273

Division Rule, 348

Division Theorem, 276

domain, 55, 58, 76

domain of discourse, 76

dongles, 236

double summations, 319


edge connected, 181

edges, 168

elements, 51


Elkies, 16

empty graph, 171

empty relation, 112, 114, 125

empty sequence, 55

empty string, 79, 207

end of chain, 120

end of path, 178

Enigma, 291

erasable, 220

Euclid, 18, 274, 283

Euclid’s Algorithm, 282

Euclidean algorithm, 141

Euler, 16, 283

Euler ’s φ function, 300

Euler ’s constant, 315

Euler ’s Formula, 240

Euler ’s formula, 246

Euler ’s Theorem, 301, 302

Euler ’s theorem, 306

Euler circuits, 185

evaluation function, 214

event, 413, 420

events, 459

execution, 137

existential, 73

expectation, 471

expected value, 471, 472

exponentially, 45

exponential time, 85

Extended Euclidean GCD, 282

Extensionality, 82


face-down four-card trick, 361

factorial, 320

factorials, 340

Factoring, 275

fair game, 445

fast exponentiation, 151

father, 339

favorite, 159

Fermat’s Last Theorem, 275

Fermat’s Little Theorem, 295

Fermat’s theorem, 299

Fibonacci, 390

Fifteen Puzzle, 150


INDEX 

515 

formal proof, 14

Foundation, 82

Four-Color Theorem, 17

four-step method, 436

Frege, 81, 84

function, 55

Fundamental Theorem of Arithmetic,

283


G ¨odel, 84, 85

Gale, 162

game tree, 224

Gauss, 275, 289

GCD, 278

GCD algorithm, 141

Generalized Pigeonhole Principle, 342

Generalized Product Rule, 345

generating function, 394, 401

Generating Functions, 385

geometric series, 386

geometric sum, 308

Goldbach’s Conjecture, 17, 75, 76

Goldbach Conjecture, 275

good count, 209, 223, 396, 406

Google, 445

graph coloring problem, 193

graph of R, 58

Greatest Common Divisor, 279

grid, 257


half-adder, 46

Hall’s matching condition, 358

Hall’s Matching Theorem, 200

Hall’s Theorem, 202, 361

Hall’s theorem, 206

Halting Problem, 85

Handshake Lemma, 171

Hardy, 273, 287

Harmonic number, 313

Hat-Check problem, 491

hypothesis, 39


identity relation, 114

image, 57, 59

implications, 20

incident, 168


Inclusion-Exclusion, 369, 371

inclusion-exclusion  for  probabilities,

421

Inclusion-Exclusion Rule, 368

increasing subsequence, 126

independence, 439

independent, 498

independent random variables, 461

indicator random variable, 460

indicator variable, 464, 472

indicator variables, 461

indirect proof, 26

Induction, 91

Induction Axiom, 107

induction hypothesis, 93

inductive step, 94

inefﬁciency, 85

inference rules, 19

Inﬁnity axiom, 82

inﬁx notation, 58

injection relation, 66

injective, 60

integer linear combination, 277

Integral Method, 313, 321

interest rate, 311

intersection, 52

Invariant, 276

inverse image, 59

isomorphic, 111, 173

isomorphism, 173


Kayal, 275

known-plaintext attack, 297

Kuratowksi, 245


latency, 256

latency for min-congestion, 270, 271

Latin square, 203

lattice basis reduction, 332

Law of Large Numbers, 506

leaf, 188

Lehman, 332

lemma, 18

length of path, 178

length of the cycle, 179


516 

INDEX 

linear combination, 277

Linear Combinations, 278

Linearity of Expectation, 475, 476

line graph, 172

literal, 486

LMC, 270, 271

logarithm, 321

logical deductions, 14

lowest terms, 31


Mapping Rule, 333, 341

Markov’s bound, 501

Markov’s Theorem, 489, 490

marriage assignment, 158

Marriage Problem, 158

matched string, 207

matching, 200, 202

matching birthdays, 504

matching condition, 200

matrix multiplication, 325

maximal, 118

maximum, 118

maximum dilation, 456

mean, 24, 471, 489

Menger, 181

minimal, 118

minimum, 118

minor, 245

modulo, 289

modus ponens, 19

multinomial coefﬁcient, 377

multinomials, 377

Multinomial Theorem, 383

multiple, 273

multiplicative inverse, 293

Multiplicative Inverses, 293

multisets, 51

mutual independence, 498

mutually  independent, 440, 443, 462,

504

mutually recursive, 395


neighbors, 176, 202

network latency, 256

nodes, 169


nonconstructive proof, 343

numbered tree, 338

numbered trees, 378

number of processors, 120

Number theory, 273


o(), asymptotically smaller, 323

O(), big oh, 324

o(), little oh, 322

one-sided Chebyshev bound, 501

onto, 60

optimal spouse, 161

ordinary generating function, 385

ordinary induction, 92

outcome, 411, 420

outer face, 240

outside face, 235

overhang, 311


packet, 254

Page, Larry, 451

page rank, 452, 454

Pairing, 82

pairwise disjoint, 420

pairwise independence, 498

pairwise  independent,  441,  443,  499,

504

Pairwise Independent Additivity, 499

Pairwise Independent Sampling, 505,

509

parallel schedule, 119

parallel time, 121

parity, 151

partial fractions, 392

partial functions, 56

Pascal’s Identity, 381

path, 130, 178, 186, 449, 469

perfect matching, 158

perfect number, 273, 283

permutation, 242, 295, 340, 347

pessimal spouse, 161

Pigeonhole Principle, 341

pigeonhole principle, 333

planar, 239

planar embedding, 237


INDEX 

517 

planar embeddings, 237

planar graph, 234

planar subgraph, 243

pointwise, 57

Polyhedra, 245

polyhedron, 245

population size, 506

potential, 107

power set, 53, 83

Power Set axiom, 82

Power sets, 83

predicate, 18

prefers, 158

preserved invariant, 138

preserved under isomorphism, 173

Primality, 275

prime, 16, 274

prime factorization, 283

Prime Factorization Theorem, 35

Prime Number Theorem, 298

probability density function (pdf), 462

probability function, 420, 424

probability of an event, 420

probability space, 420

product of sets, 55

Product Rule, 335, 429

Product Rule (for generating functions),

390

proof, 18

proof by contradiction, 26

proposition, 14, 15

public key, 300

public key cryptography, 300

Pulverizer, 282, 283, 299

Pythagoreans, 245


quotient, 276


random variable, 459

random variables, 460

random walk, 449, 453, 470

Random Walks, 445

range, 57

rank, 340

rational, 26


reachable, 137

recognizer, 86

recognizes, 86

Recursive data types, 207

recursive deﬁnitions, 207

reﬂexive transitive closure, 130

regular polyhedron, 245

relation on a set, 58

Relations, 57

relatively prime, 300

relaxed, 481

remainder, 276

Replacement axiom, 82

Riemann Hypothesis, 298

right-shift, 388

Right-Shift Rule, 388

ripple-carry, 47

ripple-carry circuit, 101

Rivest, 300

rogue couple, 158

root mean square, 494

routing, 254


routing problem, 254


RSA, 300, 301, 305

RSA  public  key  encryption  scheme,

303

Russell, 81, 84

Russell’s Paradox, 81, 83


same size, 63

sample space, 411, 420

SAT, 45

satisﬁable, 46, 486

sat-solvers, 45

Saxena, 275

Scaling Rule, 387

scheduled at step k , 120

Schr ¨oder-Bernstein, 64

secret key, 300

sequence, 55

serenade, 159

set, 51

set difference, 52

Shamir, 300


518 

INDEX 

Shapley, 162

simple, 178

simple cycle, 131, 172, 179, 180

simple cycle of a graph, 180

simple graph, 168

simple graphs, 167

size, 333

smallest counterexample, 35

solution, 158

solves, 254

sound, 19

spanning tree, 189

St. Petersberg paradox, 486

stable, 158

stable matching, 156

standard deviation, 494, 495, 498

start of path, 178

state graph, 135

stationary distribution, 454

Stirling’s Approximation, 321, 322

Stirling’s Formula, 321

strictly bigger, 63, 83, 84, 85

string, 66

string-->string, 66

string procedure, 86

strong induction, 102

strongly connected, 456

subgraph, 179, 243

subsequence, 125

subset, 52

substitution function, 215

suit, 340

summation notation, 34

Sum Rule, 335, 420

surjection relation, 66

surjective, 60

switches, 254

symmetric, 131


tails, 467

tails of the distribution, 467

terminals, 254

terms, 55

theorems, 18

The Riemann Hypothesis, 298


topological sort, 118

total, 60

Total Expectation, 473

total function, 56

totient, 300

Towers of Hanoi, 394

transition, 135

transition relation, 135

transitive closure, 130

transitivity, 110

Traveling Salesman Problem, 186

traversed, 178

traverses, 130

tree, 187

tree diagram, 411, 436

truth tables, 38

Turing, 286, 287, 297

Turing’s code, 287, 291, 296

Twin Prime Conjecture, 275


unbiased, 445

uniform, 464

union, 52

Union axiom, 82

Union Bound, 421

unique factorization, 283

universal, 73

unlucky, 481


valid, 47, 76

valid coloring, 193

value of an annuity, 309

variance, 493, 500, 503

vertices, 168


Weak Law of Large Numbers, 506, 510

Well Ordering, 103

Well  Ordering  Principle,  31,  92,  107,

181

width, 197

wrap, 397, 406


Zermelo, 84

Zermelo-Frankel, 19

Zermelo-Frankel Set Theory, 81

ZFC, 19, 81, 84, 85


INDEX 

ZFC axioms, 84 

519 

MIT OpenCourseWare
http://ocw.mit.edu 

6.042J / 18.062J Mathematics for Computer Science 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

