Chapter 3 

Propositional Formulas 

It  is  amazing  that  people manage  to  cope with  all  the  ambiguities  in  the  English 
language. Here are some sentences that illustrate the issue: 

1.  “You may have cake, or you may have ice cream.” 

2.  “If pigs can ﬂy, then you can understand the Chebyshev bound.” 

3.  “If  you  can  solve  any problem we  come up with,  then you  get  an A  for  the 
course.” 

4.  “Every American has a dream.” 

What  precisely  do  these  sentences mean?  Can  you  have  both  cake  and  ice  cream 
or  must  you  choose  just  one  dessert?  If  the  second  sentence  is  true,  then  is  the 
Chebyshev  bound  incomprehensible?  If  you  can  solve  some  problems  we  come 
up with but not all, then do you get an A for the course? And can you still get an A 
even  if you can’t solve any of  the problems?  Does  the  last sentence  imply  that all 
Americans have the same dream or might some of them have different dreams? 
Some uncertainty is tolerable in normal conversation. But when we need to for­
mulate  ideas  precisely —as  in mathematics  and  programming —the  ambiguities 
inherent  in  everyday  language  can  be  a  real  problem.  We  can’t  hope  to make  an 
exact argument  if we’re not sure exactly what  the statements mean.  So before we 
start  into mathematics,  we  need  to  investigate  the  problem  of  how  to  talk  about 
mathematics. 
To  get  around  the  ambiguity  of  English,  mathematicians  have  devised  a  spe­
cial  mini-language  for  talking  about  logical  relationships.  This  language  mostly 
uses  ordinary  English  words  and  phrases  such  as  “or ”,  “implies”,  and  “for  all”. 
But mathematicians endow  these words with deﬁnitions more precise  than  those 
found  in  an  ordinary  dictionary.  Without  knowing  these  deﬁnitions,  you  might 
sometimes get the gist of statements in this language, but you would regularly get 
misled about what they really meant. 

37 

38 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

Surprisingly,  in  the midst  of  learning  the  language  of  logic, we’ll  come  across 
the most important open problem in computer science —a problem whose solution 
could change the world. 

3.1  Propositions from Propositions 

In  English,  we  can modify,  combine,  and  relate  propositions with words  such  as 
“not”,  “and”,  “or ”,  “implies”,  and “if-then”.  For  example, we  can  combine  three 
propositions into one like this: 

If all humans are mortal and all Greeks are human, then all Greeks are mortal. 

For  the next while, we won’t be much  concerned with  the  internals of propo­
sitions —whether they involve mathematics or Greek mortality —but rather with 
how propositions are combined and related. So we’ll frequently use variables such 
as P  and Q in place of speciﬁc propositions such as “All humans are mortal” and 
“2 + 3 = 5”.  The understanding is that these variables, like propositions, can take 
on only the values T (true) and F (false).  Such true/false variables are sometimes 
called Boolean variables after their inventor, George —you guessed it —Boole. 

3.1.1  “Not”, “And”, and “Or ” 
We  can  precisely  deﬁne  these  special  words  using  truth  tables.  For  example,  if 
P  denotes  an  arbitrary  proposition,  then  the  truth  of  the  proposition  “NO T P ”  is 
deﬁned by the following truth table: 

P  NO T P 
F 
T 
F 
T 

The ﬁrst row of the table indicates that when proposition P  is true, the proposition 
“NOT P ”  is  false.  The  second  line  indicates  that when P  is  false,  “NO T P ”  is  true. 
This is probably what you would expect. 
In general, a truth table indicates the true/false value of a proposition for each 
possible  setting  of  the  variables.  For  example,  the  truth  table  for  the  proposition 
“P  AND Q” has four lines, since the two variables can be set in four different ways: 

P Q 
T  T 
T  F 
F  T 
F  F 

P  AND Q 
T 
F 
F 
F 

According to this table, the proposition “P  AND Q” is true only when P  and Q are 
both true. This is probably the way you think about the word “and.” 

3.1.  PROPOSITIONS FROM PROPOSITIONS 

39 

There is a subtlety in the truth table for “P  OR Q”: 

P Q 
T  T 
T  F 
F  T 
F  F 

P  OR Q 
T 
T 
T 
F 

The  third  row of  this  table  says  that  “P  OR  Q”  is  true when  even  if  both P  and Q 
are  true.  This  isn’t always  the  intended meaning of “or ”  in everyday speech, but 
this is the standard deﬁnition in mathematical writing.  So if a mathematician says, 
“You may have  cake,  or you may have  ice  cream,”  he means  that you  could have 
both. 
If  you want  to  exclude  the  possibility  of  having  both  having  and  eating,  you 
should use “exclusive-or ” (XOR): 

P Q 
T  T 
T  F 
F  T 
F  F 

P  XOR Q 
F 
T 
T 
F 

3.1.2  “Implies” 
The  least  intuitive  connecting word  is  “implies.”  Here  is  its  truth  table, with  the 
lines labeled so we can refer to them later. 

P Q 
T T 
T F 
F T 
F F 

P  IM P L I E S Q 
T 
F 
T 
T 

(tt) 
(tf) 
(ft) 
(ff) 

Let’s experiment with this deﬁnition. For example, is the following proposition 
true or false? 
“If Goldbach’s Conjecture is true, then x2  ≥ 0 for every real number x.” 
Now, we told you before that no one knows whether Goldbach’s Conjecture is true 
or  false.  But  that  doesn’t  prevent  you  from  answering  the  question!  This  propo­
sition has  the  form P  −→  Q where  the hypothesis, P ,  is “Goldbach’s Conjecture  is 
true” and the conclusion, Q, is “x2  ≥  0 for every real number x”.  Since the conclu­
sion  is deﬁnitely  true, we’re on either  line  (tt) or  line  (ft) of  the  truth  table.  Either 
way, the proposition as a whole is true! 
One  of  our  original  examples  demonstrates  an  even  stranger  side  of  implica­
tions. 

“If pigs ﬂy, then you can understand the Chebyshev bound.” 

40 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

Don’t take this as an  insult; we  just need to ﬁgure out whether this proposition is 
true or false.  Curiously, the answer has nothing to do with whether or not you can 
understand  the  Chebyshev  bound.  Pigs  do  not  ﬂy,  so we’re  on  either  line  (ft)  or 
line (ff) of the truth table.  In both cases, the proposition is true! 
In contrast, here’s an example of a false implication: 

“If the moon shines white, then the moon is made of white cheddar.” 

Yes, the moon shines white. But, no, the moon is not made of white cheddar cheese. 
So we’re on line (tf) of the truth table, and the proposition is false. 
The truth table for implications can be summarized in words as follows: 

An implication is true exactly when the if-part is false or the then-part is true. 

This  sentence  is  worth  remembering;  a  large  fraction  of  all  mathematical  state­
ments are of the if-then form! 

3.1.3  “If and Only If” 
Mathematicians  commonly  join  propositions  in  one  additional  way  that  doesn’t 
arise in ordinary speech. The proposition “P  if and only if Q” asserts that P  and Q 
are logically equivalent; that is, either both are true or both are false. 

P Q 
T  T 
T  F 
F  T 
F  F 

P  I FF Q 
T 
F 
F 
T 

The following if-and-only-if statement is true for every real number x: 
|
− 4 ≥ 0 
| ≥ 2 
iff  x
For  some  values  of  x,  both  inequalities  are  true.  For  other  values  of  x,  neither  in­
equality is true .  In every case, however, the proposition as a whole is true. 

x2 

3.1.4  Problems 
Class Problems 

Problem 3.1. 
When the mathematician says to his student, “If a function is not continuous, then 
it is not differentiable,” then letting D  stand for “differentiable” and C  for contin­
uous, the only proper translation of the mathematician’s statement would be 

or equivalently, 

NO T(C )  IM P L I E S  NO T(D), 

D  IM P L I E S  C. 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

41 

But  when  a  mother  says  to  her  son,  “If  you  don’t  do  your  homework,  then 
you  can’t  watch  TV,”  then  letting  T  stand  for  “watch  TV”  and  H  for  “do  your 
homework,” a reasonable translation of the mother ’s statement would be 

or equivalently, 

NO T(H )  I FF  NOT(T ), 

H  I FF  T . 

Explain why it is reasonable to translate these two IF-THEN statements in dif­
ferent ways into propositional formulas. 

Problem 3.2. 
Prove by truth table that OR  distributes over AND : 

[P  OR  (Q  AND  R)] 

is equivalent to 

[(P  OR  Q)  AND  (P  OR  R)] 

(3.1) 

Homework Problems 

Problem 3.3. 
Describe  a  simple  recursive procedure which,  given  a positive  integer  argument, 
n,  produces  a  truth  table whose  rows  are  all  the  assignments of  truth values  to n 
propositional variables.  For example, for n = 2, the table might look like: 

T  T 
T  F 
F  T 
F  F 

Your description  can be  in English,  or a  simple program  in  some  familiar  lan­
guage (say Scheme or Java), but if you do write a program, be sure to include some 
sample output. 

3.2  Propositional Logic in Computer Programs 

Propositions and logical connectives arise all the time in computer programs.  For 
example, consider the following snippet, which could be either C, C++, or Java: 

if  (  x  >  0  ||  (x  <=  0  &&  y  >  100)  ) 
. . . 
(further instructions) 

The  symbol  ||  denotes  “or ”,  and  the  symbol  &&  denotes  “and”.  The  further  in­
structions are carried out only if the proposition following the word if is true. On 
closer inspection, this big expression is built from two simpler propositions. Let A 

42 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

be  the proposition  that x > 0,  and  let B  be  the proposition  that y  >  100.  Then 
we can rewrite the condition this way: 

A or ((not A) and B ) 

(3.2) 

A truth table reveals that this complicated expression is logically equivalent to 

A or B . 

(3.3) 

A  B  A or ((not A) and B )  A or B 
T 
T 
T  T 
T 
T 
T  F 
T 
T 
F  T 
F  F 
F 
F 

This means that we can simplify the code snippet without changing the program’s 
behavior: 

if  (  x  >  0  ||  y  >  100  ) 
. . . 
(further instructions) 

The equivalence of (3.2) and (3.3) can also be conﬁrmed reasoning by cases: 

A is T.	 Then  an  expression  of  the  form  (A or anything)  will  have  truth  value  T. 
Since  both  expressions  are  of  this  form,  both  have  the  same  truth  value  in 
this case, namely, T. 

A is F.	 Then  (A or P )  will  have  the  same  truth  value  as  P  for  any  proposition,  P . 
So  (3.3)  has  the  same  truth  value  as  B .  Similarly,  (3.2)  has  the  same  truth 
value as ((not F) and B ), which also has the same value as B .  So in this case, 
both expressions will have the same truth value, namely, the value of B . 

Rewriting  a  logical  expression  involving many  variables  in  the  simplest  form 
is both difﬁcult and important.  Simplifying expressions in software might slightly 
increase the speed of your program. But, more signiﬁcantly, chip designers face es­
sentially the same challenge.  However, instead of minimizing && and || symbols 
in a program, their job is to minimize the number of analogous physical devices on 
a  chip.  The payoff  is potentially  enormous:  a  chip with  fewer devices  is  smaller, 
consumes less power, has a lower defect rate, and is cheaper to manufacture. 

3.2.1	 Cryptic Notation 
Programming  languages use  symbols  like &&  and  !  in place  of words  like  “and” 
and  “not”.  Mathematicians  have  devised  their  own  cryptic  symbols  to  represent 
these words, which are summarized in the table below. 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

43 

Cryptic Notation 
English 
¬
(alternatively, P )
not P
P 
P  ∧ Q 
P  and Q
P  ∨ Q 
P  or Q
P  implies Q P  −→ Q 
P  −→ Q 
if P  then Q
Q←→ 
iff  Q
P 
P 

For example, using this notation, “If P  and not Q, then R” would be written: 
(P  ∧ Q) −→ R 

This  symbolic  language  is helpful  for writing  complicated  logical  expressions 
compactly.  But words such as “OR” and “IM P L I E S ,” generally serve just as well as 
the  cryptic  symbols  ∨  and −→,  and  their meaning  is  easy  to  remember.  So we’ll 
use the cryptic notation sparingly, and we advise you to do the same. 

3.2.2  Logically Equivalent Implications 

Do these two sentences say the same thing? 

If I am hungry, then I am grumpy.

If I am not grumpy, then I am not hungry.


We can settle the issue by recasting both sentences in terms of propositional logic. 
Let  P  be  the  proposition  “I  am  hungry”,  and  let  Q  be  “I  am  grumpy”.  The  ﬁrst 
sentence  says  “P  implies Q”  and  the  second  says  “(not Q)  implies  (not  P )”.  We 
can compare these two statements in a truth table: 

Q  P  IM P L I E S Q  Q IM P L I E S P 
P 
T  T 
T 
T 
F 
F 
T  F 
F  T 
T 
T 
T 
T 
F  F 

Sure enough, the columns of truth values under these two statements are the same, 
which precisely means they are equivalent.  In general, “(NOT Q) IM P L I E S (NO T P )” 
is  called  the  contrapositive  of  the  implication  “P  IM P L I E S  Q.”  And,  as  we’ve  just 
shown, the two are just different ways of saying the same thing. 
In  contrast,  the  converse  of  “P  IM P L I E S  Q”  is  the  statement  “Q  IM P L I E S  P ”.  In 
terms of our example, the converse is: 

If I am grumpy, then I am hungry. 

44 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

This sounds like a rather different contention, and a truth table conﬁrms this sus­
picion: 

P  IM P L I E S Q  Q IM P L I E S P 
Q 
P 
T 
T 
T 
T 
T 
F 
F 
T 
T 
F 
T 
F 
T 
T 
F 
F 
Thus, an implication is logically equivalent to its contrapositive but is not equiva­
lent to its converse. 
One ﬁnal relationship:  an implication and its converse together are equivalent 
to an iff statement, speciﬁcally, to these two statements together.  For example, 

If I am grumpy, then I am hungry. 
If I am hungry, then I am grumpy. 

are equivalent to the single statement: 

I am grumpy iff I am hungry. 

Once again, we can verify this with a truth table: 

P  Q  (P 
T  T 
T  F 
F  T 
F  F 

IM P L I E S  Q)  AND 
T 
T 
F 
F 
F 
T 
T 
T 

(Q 

IM P L I E S  P ) 
T 
T 
F 
T 

Q 

I FF  P 
T

F

F

T


The underlined operators have the same column of truth values, proving that the 
corresponding formulas are equivalent. 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

45 

SAT 

A proposition is satisﬁable if some setting of the variables makes the proposition 
true.  For  example,  P  AND  Q  is  satisﬁable  because  the  expression  is  true when P 
is  true  and Q  is  false.  On  the  other  hand,  P  AND  P  is  not  satisﬁable  because  the 
expression as a whole  is  false  for both  settings of P .  But determining whether or 
not  a  more  complicated  proposition  is  satisﬁable  is  not  so  easy.  How  about  this 
one? 

(P  OR Q OR R) AND  (P  OR Q) AND  (P  OR R) AND  (R OR Q) 

The general problem of deciding whether a proposition is satisﬁable is called SAT. 
One  approach  to  SAT  is  to  construct  a  truth  table  and  check whether  or  not  a  T 
ever appears. But this approach is not very efﬁcient; a proposition with n variables 
has a truth table with 2n  lines, so the effort required to decide about a proposition 
grows exponentially with  the number of variables.  For a proposition with  just 30 
variables, that’s already over a billion! 
Is  there  a more  efﬁcient  solution  to  SAT?  In  particular,  is  there  some,  presumably 
very ingenious, procedure that determines in a number of steps that grows polyno­
mially —like n2  of n14  —instead  of  exponentially, whether  any  given proposition 
is satiﬁable or not? No one knows. And an awful lot hangs on the answer. An efﬁ­
cient solution to SAT would immediately imply efﬁcient solutions to many, many 
other important problems involving packing, scheduling, routing, and circuit ver­
iﬁcation,  among other  things.  This would be wonderful,  but  there would also be 
worldwide  chaos.  Decrypting  coded  messages  would  also  become  an  easy  task 
(for most codes).  Online ﬁnancial transactions would be insecure and secret com­
munications could be read by everyone. 
Recently  there  has  been  exciting  progress  on  sat-solvers  for  practical  applications 
like  digital  circuit  veriﬁcation.  These  programs  ﬁnd  satisfying  assignments with 
amazing  efﬁciency  even  for  formulas  with  millions  of  variables.  Unfortunately, 
it’s  hard  to  predict  which  kind  of  formulas  are  amenable  to  sat-solver  methods, 
and  for  formulas  that  are NOT  satisﬁable,  sat-solvers  generally  take  exponential 
time to verify that. 
So no one has a good idea how to solve SAT more efﬁciently or else to prove that no 
efﬁcient solution exists —researchers are completely stuck. This is the outstanding 
unanswered question in theoretical computer science. 

46 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

3.2.3  Problems 
Class Problems 

Problem 3.4. 
This problem1  examines whether the following speciﬁcations are satisﬁable: 

1.  If the ﬁle system is not locked, then 

(a)  new messages will be queued. 
(b)  new messages will be sent to the messages buffer. 
(c)  the system is functioning normally, and conversely, if the system is func­
tioning normally, then the ﬁle system is not locked. 

2.  If new messages are not queued, then they will be sent to the messages buffer. 

3.  New messages will not be sent to the message buffer. 

(a)  Begin by  translating  the ﬁve speciﬁcations  into propositional  formulas using 
four propositional variables: 

L 
Q 
B 
N 

::=  ﬁle system locked,

::=  new messages are queued,

::=  new messages are sent to the message buffer, 

::=  system functioning normally.


(b)  Demonstrate that this set of speciﬁcations is satisﬁable by describing a single 
truth assignment for the variables L, Q, B , N  and verifying that under this assign­
ment, all the speciﬁcations are true. 

(c)  Argue that the assignment determined in part (b) is the only one that does the 
job. 

Problem 3.5. 
Propositional logic comes up in digital circuit design using the convention that T 
corresponds  to  1  and  F  to  0.  A  simple  example  is  a  2-bit  half-adder  circuit.  This 
circuit  has  3  binary  inputs,  a1 , a0  and  b,  and  3  binary  outputs,  c, o1 , o0 .  The  2-bit 
word  a1a0  gives  the binary  representation  of  an  integer,  k ,  between  0  and  3.  The 
3-bit word cs1 s0  gives the binary representation of k + b. The third output bit, c, is 
called the ﬁnal carry bit. 
So if k  and b were both 1, then the value of a1a0  would be 01 and the value of 
the output cs1 s0  would 010, namely, the 3-bit binary representation of 1 + 1. 

1 From Rosen, 5th edition, Exercise 1.1.36 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

47 

In fact, the ﬁnal carry bit equals 1 only when all three binary inputs are 1, that 
is, when k = 3 and b = 1.  In that case, the value of cs1 s0  is 100, namely, the binary 
representation of 3 + 1. 
This 2-bit half-adder could be described by the following formulas: 

c0  = b 
s0  = a0  XOR  c0 
c1  = a0  AND  c0 
s1  = a1  XOR  c1 
c2  = a1  AND  c1 
c = c2 . 

the carry into column 1 

the carry into column 2 

(a)  Generalize  the  above  construction  of  a  2-bit  half-adder  to  an  n + 1  bit  half-
adder  with  inputs  an , . . . , a1 , a0  and  b  for  arbitrary  n  ≥  0.  That  is,  give  simple 
formulas  for  si  and  ci  for  0  ≤  i  ≤  n + 1, where  ci  is  the  carry  into  column  i  and 
c = cn+1 . 

(b)  Write similar deﬁnitions for the digits and carries in the sum of two n + 1-bit 
binary numbers an  . . . a1a0  and bn  . . . b1 b0 . 
Visualized as digital circuits,  the above adders consist of a sequence of single-
digit half-adders or adders strung together in series. These circuits mimic ordinary 
pencil-and-paper addition, where a carry into a column is calculated directly from 
the  carry  into  the  previous  column,  and  the  carries  have  to  ripple  across  all  the 
columns  before  the  carry  into  the  ﬁnal  column  is  determined.  Circuits  with  this 
design  are  called  ripple-carry  adders.  Ripple-carry  adders  are  easy  to understand 
and remember and require a nearly minimal number of operations. But the higher-
order output bits and the ﬁnal carry take time proportional to n to reach their ﬁnal 
values. 
(c)  How  many  of  each  of  the  propositional  operations  does  your  adder  from 
part (b) use to calculate the sum? 

Problem 3.6.  (a)  A propositional formula is valid iff it is equivalent to T. Verify by 
truth table that 

(P  IM P L I E S  Q)  OR  (Q  IM P L I E S  P ) 

is valid. 

(b)  Let  P  and Q  be  propositional  formulas.  Describe  a  single  propositional  for­
mula, R, involving P  and Q such that R is valid iff P  and Q are equivalent. 

(c)  A propositional formula is satisﬁable iff there is an assignment of truth values 
to its variables —an environment —which makes it true. Explain why 

P  is valid iff NO T(P ) is not satisﬁable. 

48 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

(d)  A set of propositional formulas P1 , . . . , Pk  is consistent  iff there  is an environ­
ment in which they are all true. Write a formula, S , so that the set P1 , . . . , Pk  is not 
consistent iff S  is valid. 

Homework Problems 

Problem 3.7. 
Considerably faster adder circuits work by computing the values in later columns 
for  both  a  carry  of  0  and  a  carry  of  1,  in  parallel.  Then,  when  the  carry  from  the 
earlier columns ﬁnally arrives,  the pre-computed answer can be quickly selected. 
We’ll illustrate this idea by working out the equations for an n + 1-bit parallel half-
adder. 
Parallel half-adders are built out of parallel “add1” modules. An n + 1-bit add1 
module takes as input the n + 1-bit binary representation, an  . . . a1a0 , of an integer, 
s, and produces as output the binary representation, c pn  . . . p1 p0 , of s + 1. 
(a)  A  1-bit  add1  module  just  has  input  a0 .  Write  propositional  formulas  for  its 
outputs c and p0 . 

(b)  Explain how  to build an n + 1-bit parallel half-adder  from an n + 1-bit add1 
module  by  writing  a  propositional  formula  for  the  half-adder  output,  oi ,  using 
only the variables ai , pi , and b. 
We can build a double-size add1 module with 2(n + 1) inputs using two single-
size add1 modules with n+1 inputs. Suppose the inputs of the double-size module 
are a2n+1 , . . . , a1 , a0  and the outputs are c, p2n+1 , . . . , p1 , p0 . The setup is illustrated 
in Figure 3.1. 
Namely,  the  ﬁrst  single  size  add1 module  handles  the  ﬁrst  n + 1  inputs.  The 
inputs to this module are the low-order n + 1 input bits an , . . . , a1 , a0 , and its out­
puts will  serve as  the ﬁrst n + 1 outputs pn , . . . , p1 , p0  of  the double-size module. 
Let c(1)  be the remaining carry output from this module. 
The  inputs  to  the  second  single-size module  are  the  higher-order  n + 1  input 
bits a2n+1 , . . . , an+2 , an+1 . Call its ﬁrst n + 1 outputs rn , . . . , r1 , r0  and let c(2)  be its 
carry. 
(c)  Write a formula for the carry, c, in terms of c(1)  and c(2) . 

(d)  Complete the speciﬁcation of the double-size module by writing propositional 
formulas for the remaining outputs, pi , for n + 1 ≤  i ≤  2n + 1.  The formula for pi 
should only involve the variables ai , ri−(n+1) , and c(1) . 

(e)  Parallel half-adders are exponentially faster than ripple-carry half-adders. Con­
ﬁrm  this by determining  the  largest number of propositional operations  required 
to  compute  any  one  output  bit  of  an  n-bit  add module.  (You may  assume  n  is  a 
power of 2.) 

3.2.  PROPOSITIONAL LOGIC IN COMPUTER PROGRAMS 

49


Figure 3.1:  Structure of a Double-size Add1 Module. 

a0a1ana2n+1an+1an+2c(1)c(2)(n+1)‐bit add1module(n+1)‐bit add1dlmodulemoduler0r1rnc2(n+2)‐bit add1 modulepnp1p0p2n+1pn+1pn+2n10n+1n+250 

CHAPTER 3.  PROPOSITIONAL FORMULAS 

MIT OpenCourseWare
http://ocw.mit.edu 

6.042J / 18.062J Mathematics for Computer Science 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

