Chapter 20 

Random Variables 

So far we focused on probabilities of events —that you win the Monty Hall game; 
that you have a rare medical condition, given that you tested positive; . . . . Now we 
focus on quantitative questions:  How many contestants must play  the Monty Hall 
game  until  one  of  them  ﬁnally  wins?  . . . How  long  will  this  condition  last?  How 
much will I lose playing 6.042 games all day? Random variables are the mathemat­
ical tool for addressing such questions. 

20.1  Random Variable Examples 

Deﬁnition  20.1.1.  A  random  variable,  R,  on  a  probability  space  is  a  total  function 
whose domain is the sample space. 

The  codomain  of  R  can  be  anything,  but  will  usually  be  a  subset  of  the  real 
numbers.  Notice  that  the  name  “random  variable”  is  a misnomer;  random  vari­
ables are actually functions! 
For example, suppose we toss three independent, unbiased coins.  Let C  be the 
number of heads that appear. Let M  = 1 if the three coins come up all heads or all 
tails, and let M  = 0 otherwise. Now every outcome of the three coin ﬂips uniquely 
determines the values of C  and M . For example, if we ﬂip heads, tails, heads, then 
C  = 2 and M  = 0.  If we ﬂip  tails,  tails,  tails,  then C  = 0 and M  = 1.  In effect, C 
counts the number of heads, and M  indicates whether all the coins match. 
Since  each  outcome  uniquely  determines  C  and  M ,  we  can  regard  them  as 
functions mapping  outcomes  to  numbers.  For  this  experiment,  the  sample  space 
is: 

S  =  {HHH, HH T , H T H, H T T , T HH, T H T , T T H, T T T } . 

Now C  is a  function  that maps each outcome  in  the sample space  to a number as 

459 

460 

follows: 

CHAPTER 20.  RANDOM VARIABLES 

C (HHH ) = 3 
C (HH T ) = 2 
C (H T H ) = 2 
C (H T T ) = 1 

C (T HH ) = 2 
C (T H T ) = 1 
C (T T H ) = 1 
C (T T T ) = 0. 

Similarly, M  is a function mapping each outcome another way: 

M (HHH ) = 1 
M (HH T ) = 0 
M (H T H ) = 0 
M (H T T ) = 0 

M (T HH ) = 0 
M (T H T ) = 0 
M (T T H ) = 0 
M (T T T ) = 1. 

So C  and M  are random variables. 

20.1.1  Indicator Random Variables 
An  indicator  random  variable  is  a  random  variable  that maps  every  outcome  to  ei­
ther 0 or 1.  These are also called Bernoulli variables.  The random variable M  is an 
example.  If all three coins match, then M  = 1; otherwise, M  = 0. 
Indicator  random  variables  are  closely  related  to  events.  In  particular,  an  in­
dicator  partitions  the  sample  space  into  those  outcomes  mapped  to  1  and  those 
outcomes mapped to 0.  For example, the indicator M  partitions the sample space 
into two blocks as follows: 
�� 
��
�
�
� 
� 
HHH  T T T  HH T  H T H  H T T  T HH  T H T  T T H .
M  = 1 
M  = 0 
In the same way, an event, E , partitions the sample space into those outcomes 
in  E  and  those  not  in  E .  So  E  is  naturally  associated  with  an  indicator  random 
variable,  IE ,  where  IE (p) = 1  for  outcomes  p  ∈  E  and  IE (p) = 0  for  outcomes 
p /∈ E . Thus, M  = IF  where F  is the event that all three coins match. 

20.1.2  Random Variables and Events 
There is a strong relationship between events and more general random variables 
as well. A random variable that takes on several values partitions the sample space 
into several blocks.  For example, C  partitions the sample space as follows: 
� �� � 
�� 
�� 
� �� �
�
� 
�
� 
T T H  T H T  H T T  T HH  H T H  HH T  HHH .
T T T
C  = 1 
C  = 2 
C  = 3 
C  = 0 
Each  block  is  a  subset  of  the  sample  space  and  is  therefore  an  event.  Thus,  we 
can regard an equation or inequality involving a random variable as an event.  For 
example,  the  event  that C  = 2  consists  of  the  outcomes T HH , H T H ,  and HH T . 
The event C  ≤ 1 consists of the outcomes T T T , T T H , T H T , and H T T . 

20.1.  RANDOM VARIABLE EXAMPLES 

461 

Naturally enough, we can talk about the probability of events deﬁned by prop­
erties of random variables.  For example, 
Pr {C  = 2}  =  Pr {T HH } + Pr {H T H } + Pr {HH T }
3 
1
1
1
= 
+ + = 
.
8
8
8
8 

20.1.3  Independence 
The notion of independence carries over from events to random variables as well. 
Random  variables R1  and R2  are  independent  iff  for  all  x1  in  the  codomain  of R1 , 
and x2  in the codomain of R2 , we have: 
Pr {R1  = x1  AND R2  = x2} = Pr {R1  = x1 } · Pr {R2  = x2} . 
As with events, we can formulate independence for random variables in an equiv­
alent and perhaps more  intuitive way:  random variables R1  and R2  are  indepen­
dent if for all x1  and x2 
Pr {R1  = x1  |  R2  = x2 } = Pr {R1  = x1} . 
whenever the lefthand conditional probability is deﬁned, that is, whenever Pr {R2  = x2} > 
0. 

As  an  example,  are C  and M  independent?  Intuitively,  the  answer  should  be 
“no”.  The  number  of  heads,  C ,  completely  determines  whether  all  three  coins 
match;  that  is,  whether M  = 1.  But,  to  verify  this  intuition,  we must  ﬁnd  some 
x1 , x2  ∈ R such that: 
Pr {C  = x1  AND M  = x2} =� Pr {C  = x1} · Pr {M  = x2 } . 
One appropriate choice of values is x1  = 2 and x2  = 1.  In this case, we have: 
1 3
· 
Pr {C  = 2 AND M  = 1} = 0 =�
= Pr {M  = 1} · Pr {C  = 2} . 
8
4 
The ﬁrst probability is zero because we never have exactly two heads (C  = 2) when 
all three coins match (M  = 1). The other two probabilities were computed earlier. 
On the other hand, let H1  be the indicator variable for event that the ﬁrst ﬂip is 
a Head, so 
[H1  = 1] = {HHH, H T H, HH T , H T T } . 
Then H1  is independent of M , since 
Pr {M  = 1} = 1/4 = Pr {M  = 1  |  H1  = 1} = Pr {M  = 1  |  H1  = 0}
Pr {M  = 0} = 3/4 = Pr {M  = 0  |  H1  = 1} = Pr {M  = 0  |  H1  = 0} 
This example is an instance of a simple lemma: 

Lemma 20.1.2.  Two events are independent iff their indicator variables are independent. 

462 

CHAPTER 20.  RANDOM VARIABLES 

As with events, the notion of independence generalizes to more than two ran­
dom variables. 

Deﬁnition 20.1.3.  Random variables R1 , R2 , . . . , Rn  are mutually independent iff 
Pr {R1  = x1  AND R2  = x2  AND 
AND Rn  = xn}
· · · 
=  Pr {R1  = x1 } · Pr {R2  = x2} · · · Pr {Rn  = xn} . 

for all x1 , x2 , . . . , xn . 

It is a simple exercise to show that the probability that any subset of the variables 
takes a particular set of values  is equal to the product of the probabilities that the 
individual  variables  take  their  values.  Thus,  for  example,  if  R1 , R2 , . . . , R100  are 
mutually independent random variables, then it follows that: 
Pr {R1  = 7 AND R7  = 9.1 AND R23  = π} = Pr {R1  = 7}·Pr {R7  = 9.1}·Pr {R23  = π} . 

20.2  Probability Distributions 

A random variable maps outcomes to values, but random variables that show up 
for different spaces of outcomes wind up behaving in much the same way because 
they have  the  same probability of  taking any given value.  Namely,  random vari­
ables  on  different  probability  spaces  may  wind  up  having  the  same  probability 
density function. 

Deﬁnition  20.2.1.  Let R  be  a  random  variable with  codomain  V .  The  probability 
→ 
� 
density function (pdf) of R is a function PDFR  : V 
[0, 1] deﬁned by: 
Pr {R = x}
if x ∈ range (R) , 
PDFR (x) ::= 
if x  /∈ range (R) . 
0 
� 
A consequence of this deﬁnition is that 
x∈range(R) 

PDFR (x) = 1. 

This follows because R has a value for each outcome, so summing the probabilities 
over all outcomes  is  the  same as  summing over  the probabilities of  each value  in 
the range of R. 
As  an  example,  let’s  return  to  the  experiment of  rolling  two  fair,  independent 
dice.  As before,  let T  be  the  total of  the  two  rolls.  This  random variable  takes on 
values  in  the  set  V  =  {2, 3, . . . , 12}.  A  plot  of  the  probability  density  function  is 
shown below: 

20.2.  PROBABILITY DISTRIBUTIONS 

463 

�6/36 

PDFR (x) 

3/36 

2 

3 

4 

5 

6 

8 
7 
x ∈ V 

� 

9

10

11

12 

The lump in the middle indicates that sums close to 7 are the most likely. The total 
area of all the rectangles is 1 since the dice must take on exactly one of the sums in 
V  = {2, 3, . . . , 12}. 
A  closely-related  idea  is  the  cumulative  distribution  function  (cdf)  for  a  random 
→ 
variable R whose codomain is real numbers.  This is a function CDFR  : R 
[0, 1] 
deﬁned by: 
CDFR (x) = Pr {R ≤ x}
As an example,  the cumulative distribution function for the random variable T  is 
shown below: 

�1 

CDFR (x) 

1/2 

0 

2 

3 

4 

5 

6 

8 
7 
x ∈ V 

� 

9

10

11

12 

The  height  of  the  i-th  bar  in  the  cumulative  distribution  function  is  equal  to  the 
sum  of  the  heights  of  the  leftmost  i  bars  in  the  probability density  function.  This 
follows from the deﬁnitions of pdf and cdf: 
� 
CDFR (x) = Pr {R ≤ x} 
Pr {R = y}
� 
= 
y≤x 
PDFR (y) 
y≤x 

= 

In summary, PDFR (x) measures the probability that R = x and CDFR (x) mea­
sures  the  probability  that  R  ≤  x.  Both  the  PDFR  and  CDFR  capture  the  same 

464 

CHAPTER 20.  RANDOM VARIABLES 

information  about  the  random  variable  R—  you  can  derive  one  from  the  other 
—but  sometimes  one  is  more  convenient.  The  key  point  here  is  that  neither  the 
probability density function nor the cumulative distribution function involves the 
sample space of an experiment. 
We’ll now look at three important distributions and some applications. 

20.2.1  Bernoulli Distribution 
Indicator  random  variables  are  perhaps  the  most  common  type  because  of  their 
close association with events. The probability density function of an indicator ran­
dom variable, B , is always 

PDFB (0) = p 
PDFB (1) = 1 − p 

where 0 ≤ p ≤ 1. The corresponding cumulative distribution function is: 
CDFB (0) = p 
CDFB (1) = 1 

20.2.2  Uniform Distribution 
A random variable  that  takes on each possible value with  the same probability  is 
called uniform.  For example, the probability density function of a random variable 
U  that is uniform on the set {1, 2, . . . , N } is: 

PDFU (k) = 

1
N 

And the cumulative distribution function is: 

k
N 
Uniform distributions come up all  the time.  For example,  the number rolled on a 
fair die is uniform on the set {1, 2, . . . , 6}. 

CDFU (k) = 

20.2.3  The Numbers Game 
Let’s  play  a  game!  I  have  two  envelopes.  Each  contains  an  integer  in  the  range 
0, 1, . . . , 100, and the numbers are distinct.  To win the game, you must determine 
which envelope contains the  larger number.  To give you a ﬁghting chance,  I’ll  let 
you  peek  at  the  number  in  one  envelope  selected  at  random.  Can  you  devise  a 
strategy that gives you a better than 50% chance of winning? 
For example, you could just pick an envelope at random and guess that it con­
tains the larger number. But this strategy wins only 50% of the time. Your challenge 
is to do better. 

20.2.  PROBABILITY DISTRIBUTIONS 

465 

So you might try to be more clever.  Suppose you peek in the left envelope and 
see  the  number  12.  Since  12  is  a  small  number,  you  might  guess  that  that  other 
number  is  larger.  But  perhaps  I’m  sort  of  tricky  and  put  small  numbers  in  both 
envelopes. Then your guess might not be so good! 
An  important point here  is  that  the numbers  in  the envelopes may not be ran­
dom.  I’m  picking  the  numbers  and  I’m  choosing  them  in  a way  that  I  think will 
defeat your guessing strategy.  I’ll only use randomization  to choose  the numbers 
if that serves my end: making you lose! 

Intuition Behind the Winning Strategy 

Amazingly,  there  is a  strategy  that wins more  than 50% of  the  time,  regardless of 
what numbers I put in the envelopes! 
Suppose  that  you  somehow  knew  a number  x  between my  lower number  and 
higher  numbers.  Now  you  peek  in  an  envelope  and  see  one  or  the  other.  If  it  is 
bigger than x, then you know you’re peeking at the higher number.  If it is smaller 
than  x,  then  you’re  peeking  at  the  lower  number.  In  other words,  if  you  know  a 
number x between my lower and higher numbers, then you are certain to win the 
game. 
The only ﬂaw with this brilliant strategy is that you do not know x. Oh well. 
But what  if  you  try  to  guess  x?  There  is  some  probability  that  you  guess  cor­
rectly.  In  this  case,  you  win  100%  of  the  time.  On  the  other  hand,  if  you  guess 
incorrectly,  then  you’re  no worse  off  than  before;  your  chance  of winning  is  still 
50%.  Combining  these  two  cases,  your  overall  chance  of  winning  is  better  than 
50%! 
Informal arguments about probability, like this one, often sound plausible, but 
do not hold up under close scrutiny.  In contrast, this argument sounds completely 
implausible— but is actually correct! 

Analysis of the Winning Strategy 
For generality,  suppose  that  I  can  choose numbers  from  the  set {0, 1, . . . , n}.  Call 
the lower number L and the higher number H . 
Your goal is to guess a number x between L and H . To avoid confusing equality 
� 
� 
cases, you select x at random from among the half-integers: 
1 
1
,  1
2 
2 

1 
,  . . . ,  n − 
2 

1
,  2
2 

But what probability distribution should you use? 
The uniform distribution turns out to be your best bet. An informal justiﬁcation 
is  that  if  I  ﬁgured  out  that  you  were  unlikely  to  pick  some  number—  say  50 1
2 — 
then I’d always put 50 and 51 in the evelopes. Then you’d be unlikely to pick an x 
between L and H  and would have less chance of winning. 
After you’ve  selected  the number x,  you peek  into  an  envelope  and  see  some 
number  p.  If  p > x,  then  you  guess  that  you’re  looking  at  the  larger  number.  If 

466 

CHAPTER 20.  RANDOM VARIABLES 

p < x, then you guess that the other number is larger. 
All that remains is to determine the probability that this strategy succeeds. We 
can do this with the usual four step method and a tree diagram. 
Step 1: Find the sample space.  You either choose x too low (< L), too high (> H ), 
or just right (L < x < H ). Then you either peek at the lower number (p = L) or the 
higher number (p = H ). This gives a total of six possible outcomes. 

Step  2:  Deﬁne  events  of  interest.  The  four  outcomes  in  the  event  that  you win 
are marked in the tree diagram. 
Step 3:  Assign outcome probabilities.  First, we assign edge probabilities.  Your 
guess x is too low with probability L/n, too high with probability (n − H )/n, and 
just right with probability (H − L)/n. Next, you peek at either the lower or higher 
number with equal probability. Multiplying along root-to-leaf paths gives the out­
come probabilities. 
Step 4:  Compute event probabilities.  The probability of  the event  that you win 
is the sum of the probabilities of the four outcomes in that event: 
n − H 
H − L  + 
H − L  + 
L  + 
Pr {win} = 
2n 
2n 
2n 
2n 
1  H − L 
= +
2n 
2
1 
1
≥ 
2
2n 
The ﬁnal inequality relies on the fact that the higher number H  is at least 1 greater 
than the lower number L since they are required to be distinct. 
Sure  enough,  you  win  with  this  strategy  more  than  half  the  time,  regardless 
of  the  numbers  in  the  envelopes!  For  example,  if  I  choose  numbers  in  the  range 
0, 1, . . . , 100, then you win with probability at least  1  +  1  = 50.5%. Even better, if 
2 
200 
I’m allowed only numbers in the range 0, . . . , 10, then your probability of winning 
rises to 55%! By Las Vegas standards, those are great odds! 

+

x just right1/21/21/21/21/21/2L/n(H−L)/n(n−H)/nchoice of x# peeked atresultprobabilitywinwinx too highx too lowwinlosewinloseL/2nL/2n(H−L)/2n(H−L)/2n(n−H)/2n(n−H)/2np=Hp=Lp=Hp=Lp=Hp=L20.2.  PROBABILITY DISTRIBUTIONS 

467 

20.2.4  Binomial Distribution 
The binomial distribution plays an important role in Computer Science as it does in 
most other sciences.  The standard example of a random variable with a binomial 
distribution is the number of heads that come up in n independent ﬂips of a coin; 
� � 
call  this  random  variable Hn .  If  the  coin  is  fair,  then Hn  has  an  unbiased  binomial 
density function: 
�  � 
2−n . 
n
PDFHn (k) = 
k 
This follows because there are  n
k  sequences of n coin tosses with exactly k heads, 
and each such sequence has probability 2−n . 
Here  is  a  plot  of  the  unbiased  probability  density  function  PDFHn (k)  corre­
sponding to n  =  20 coins ﬂips.  The most  likely outcome  is k  =  10 heads, and the 
probability falls off rapidly for larger and smaller values of k . These falloff regions 
to the left and right of the main hump are usually called the tails of the distribution. 

0.18 

0.16 

0.14 

0.12 

0.1 

0.08 

0.06 

0.04 

0.02 

0 
0 

5 

10

15

20 

In many  ﬁelds,  including  Computer  Science,  probability  analyses  come  down  to 
getting  small bounds on  the  tails of  the binomial distribution.  In  the  context of a 
problem,  this  typically means  that  there  is  very  small  probability  that  something 
bad  happens,  which  could  be  a  server  or  communication  link  overloading  or  a 
randomized  algorithm  running  for  an  exceptionally  long  time  or  producing  the 
wrong result. 
As an example, we can calculate the probability of ﬂipping at most 25 heads in 
100 tosses of a fair coin and see that it is very small, namely, less than 1 in 3,000,000. 
In  fact,  the  tail  of  the  distribution  falls  off  so  rapidly  that  the  probability  of 
ﬂipping exactly 25 heads  is nearly  twice  the probability of ﬂipping  fewer  than 25 

468 

CHAPTER 20.  RANDOM VARIABLES 

heads!  That  is,  the  probability  of  ﬂipping  exactly  25  heads  —small  as  it  is  —is 
still  nearly  twice  as  large  as  the  probability  of  ﬂipping  exactly  24  heads  plus  the 
probability of ﬂipping exactly 23 heads plus . . . the probability of ﬂipping no heads. 

The General Binomial Distribution 

PDFJ (k) = 

Now  let J  be  the number of heads  that  come up on n  independent  coins,  each of 
which is heads with probability p. Then J  has a general binomial density function: 
�  � 
p k (1 − p)n−k . 
n
k 

�  � 
As before, there are  n  sequences with k heads and n − k  tails, but now the prob­
ability of each such sequence is pk (1 − p)n−k . 
k 
As an example, the plot below shows the probability density function PDFJ (k) 
corresponding to ﬂipping n = 20 independent coins that are heads with probabilty 
p  = 0.75.  The  graph  shows  that we  are most  likely  to  get  around  k  =  15  heads, 
as  you might  expect.  Once  again,  the  probability  falls  off  quickly  for  larger  and 
smaller values of k . 

0.25 

0.2 

0.15 

0.1 

0.05 

0 
0 

5 

10

15

20 

20.2.  PROBABILITY DISTRIBUTIONS 

469 

20.2.5  Problems 
Class Problems 

Team 1: 

Guess the Bigger Number Game 

•  Write different integers between 0 and 7 on two pieces of paper. 

•  Put the papers face down on a table. 

Team 2: 

•  Turn over one paper and look at the number on it. 

•  Either stick with this number or switch to the unseen other number. 

Team 2 wins if it chooses the larger number. 

Problem 20.1. 
In  section  20.2.3,  Team  2 was  shown  to  have  a  strategy  that wins  4/7  of  the  time 
no matter how Team 1 plays.  Can Team 2 do better?  The answer is “no,” because 
Team 1 has a strategy that guarantees that it wins at least 3/7 of the time, no matter 
how Team 2 plays. Describe such a strategy for Team 1 and explain why it works. 

Problem 20.2. 
Suppose X1 , X2 ,  and X3  are  three mutually  independent  random variables,  each 
having the uniform distribution 
Pr {Xi  = k}  equal to 1/3 for each of k = 1, 2, 3. 

Let  M  be  another  random  variable  giving  the  maximum  of  these  three  random 
variables. What is the density function of M ? 

Homework Problems 

Problem 20.3. 
A  drunken  sailor  wanders  along main  street,  which  conveniently  consists  of  the 
points  along  the  x  axis  with  integral  coordinates.  In  each  step,  the  sailor moves 
one unit  left or right along  the x axis.  A particular path  taken by  the sailor can be 

470 

CHAPTER 20.  RANDOM VARIABLES 

described  by  a  sequence  of  “left”  and  “right”  steps.  For  example,  �left,left,right�
describes the walk that goes left twice then goes right. 
We model  this  scenario with  a  random walk  graph whose  vertices  are  the  in­
tegers  and with  edges  going  in  each  direction  between  consecutive  integers.  All 
edges are labelled 1/2. 
The sailor begins his random walk at the origin.  This is described by an initial 
distribution which  labels  the origin with probability  1  and  all other vertices with 
probability  0.  After one  step,  the  sailor  is  equally  likely  to be  at  location  1 or −1, 
so the distribution after one step gives label 1/2 to the vertices 1 and −1 and labels 
all other vertices with probability 0. 
(a)  Give  the  distributions  after  the  2nd,  3rd,  and  4th  step  by  ﬁlling  in  the  table 
of  probabilities  below,  where  omitted  entries  are  0.  For  each  row,  write  all  the 
nonzero entries so they have the same denominator. 
location 
0 
-1 
1 
1/2  0  1/2 
? 
? 
? 
? 
? 
? 
? 
? 
? 

initially 
after 1 step 
after 2 steps 
after 3 steps 
after 4 steps 

? 
? 
? 

? 
? 
? 

? 
? 

? 
? 

-4

-3

-2 

1 

2

3

4 

? 

? 

(b) 

1.  What is the ﬁnal location of a t-step path that moves right exactly i times? 
2.  How many different paths are there that end at that location? 
3.  What is the probability that the sailor ends at this location? 

(c)  Let L be the random variable giving the sailor ’s location after t steps, and let 
B ::= (L + t)/2. Use the answer to part (b) to show that B has an unbiased binomial 
density function. 

. 

< 

1
2 

(d)  Again  let  L  be  the  random  variable  giving  the  sailor ’s  location  after  t  steps, 
� 
� 
where t is even.  Show that 
√
t 
|L| < 
Pr 
2 

√
t/2 steps from 
So there is a better than even chance that the sailor ends up at least 
where he started. 
Hint: Work in terms of B .  Then you can use an estimate that bounds the binomial 
distribution.  Alternatively, observe that the origin is the most likely ﬁnal location 
� 
and then use the asymptotic estimate 
2 
.
πt 

Pr {L = 0} = Pr {B = t/2} ∼ 

20.3.  AVERAGE & EXPECTED VALUE 

471 

20.3  Average & Expected Value 

The  expectation  of  a  random  variable  is  its  average  value,  where  each  value  is 
weighted  according  to  the  probability  that  it  comes  up.  The  expectation  is  also 
called the expected value or the mean of the random variable. 
For example, suppose we select a student uniformly at random from the class, 
and let R be the student’s quiz score. Then E [R] is just the class average —the ﬁrst 
thing  everyone  wants  to  know  after  getting  their  test  back!  For  similar  reasons, 
the ﬁrst  thing you usually want  to know  about  a  random variable  is  its  expected 
value. 

Deﬁnition 20.3.1. 

� 
x  Pr {R = x} 
· 
� 
E [R] ::= 
x∈range(R) 
· 
x  PDFR (x).
x∈range(R) 

= 

(20.1)

Let’s work  through an example.  Let R be  the number  that comes up on a  fair, 
six-sided die. Then by (20.1), the expected value of R is: 
6� 
k · 
k=1 
1
1
1
1
1
· 
· 
· 
· 
· 
· 
= 1  + 2  + 3  + 4  + 5  + 6 
6 
6 
6 
6 
6 
7 = 
2 

E [R] = 

1
6 

1
6 

This  calculation  shows  that  the  name  “expected  value”  is  a  little misleading;  the 
random variable might never actually take on that value.  You don’t ever expect to 
roll a 3 1
2  on an ordinary die! 
There is an even simpler formula for expectation: 
Theorem 20.3.2.  If R is a random variable deﬁned on a sample space, S , then 
� 
ω∈S 

R(ω) Pr {ω} 

E [R] = 

(20.2) 

The proof of Theorem 20.3.2,  like many of the elementary proofs about expec­
tation  in  this  chapter,  follows  by  judicious  regrouping  of  terms  in  the  deﬁning 
sum (20.1): 

472 

CHAPTER 20.  RANDOM VARIABLES 

Proof. 

= 

= 

= 

= 

(Def 20.3.1 of expectation) 

� 
x  Pr {R = x} 
· 
x∈range(R)  ⎛
⎞

E [R] ::= 
�

� 
Pr {ω}⎠ 
x ⎝ 
�  � 
ω∈[R=x] 
x∈range(R) 
x Pr {ω} 
�  � 
x∈range(R) ω∈[R=x] 
R(ω) Pr {ω} 
� 
x∈range(R) ω∈[R=x] 
R(ω) Pr {ω}
ω∈S 
The last equality follows because the events [R = x] for x ∈ range (R) partition the 
sample space, S , so summing over the outcomes in [R = x] for x ∈ range (R) is the 
same as summing over S . 
� 

(distributing x over the inner sum) 

(def of Pr {R = x}) 

(def of the event [R = x]) 

In general, the deﬁning sum (20.1) is better for calculating expected values and 
has  the  advantage  that  it  does  not  depend  on  the  sample  space,  but  only  on  the 
density function of the random variable. On the other hand, the simpler sum over 
all outcomes (20.2)is sometimes easier to use in proofs about expectation. 

20.3.1  Expected Value of an Indicator Variable 
The expected value of an indicator random variable for an event is just the proba­
bility of that event. 

Lemma 20.3.3.  If IA  is the indicator random variable for event A, then 
E [IA ] = Pr {A} . 

Proof. 

E [IA ] = 1  Pr {IA  = 1} + 0  Pr {IA  = 0}
·
· 
= Pr {IA  = 1} 
= Pr {A} . 

(def of IA ) 

� 

For example,  if A is the event that a coin with bias p comes up heads, E [IA ] = 
Pr {IA  = 1} = p. 

20.3.  AVERAGE & EXPECTED VALUE 

473 

20.3.2  Conditional Expectation 

Just like event probabilities, expectations can be conditioned on some event. 
Deﬁnition  20.3.4.  The  conditional  expectation, E [R  | A],  of  a  random  variable,  R, 
� 
given event, A, is: 
r · Pr {R = r  |  A} . 
E [R  | A] ::= 
r∈range(R) 

(20.3) 

In other words, it is the average value of the variable R when values are weighted 
by their conditional probabilities given A. 
For  example, we  can  compute  the  expected  value  of  a  roll  of  a  fair  die,  given, 
for  example,  that  the  number  rolled  is  at  least  4.  We  do  this  by  letting  R  be  the 
outcome of a roll of the die. Then by equation (20.3), 
� 
6
i · Pr {R = i  |  R ≥ 4} = 1 · 0 + 2 · 0 + 3 · 0 + 4 · 1  + 5 · 1  + 6 · 1  = 5.
3 
3
3
i=1 

E [R  | R ≥ 4] = 

The  power  of  conditional  expectation  is  that  it  lets  us  divide  complicated  ex­
pectation  calculations  into  simpler  cases.  We  can ﬁnd  the desired  expectation  by 
calculating  the  conditional  expectation  in  each  simple  case  and  averaging  them, 
weighing each case by its probability. 
For  example,  suppose  that  49.8%  of  the people  in  the world  are male  and  the 
rest  female —which  is  more  or  less  true.  Also  suppose  the  expected  height  of  a 
randomly  chosen male  is  5� 11�� , while  the  expected  height  of  a  randomly  chosen 
female is 5� 5�� .  What is the expected height of a randomly chosen individual?  We 
can calculate  this by averaging  the heights of men and women.  Namely,  let H  be 
the height  (in  feet) of  a  randomly  chosen person,  and  let M  be  the  event  that  the 
person is male and F  the event that the person is female. We have 
E [H ] = E [H  | M ] Pr {M } + E [H  | F ] Pr {F }
·
· 
= (5 + 11/12)  0.498 + (5 + 5/12)  0.502
= 5.665 

which is a little less that 5’ 8”. 
The Law of Total Expectation justiﬁes this method. 

Rule (Law of Total Expectation). 

Theorem 20.3.5.  Let A1 , A2 , . . .  be a partition of the sample space. Then 
� 
E [R  | Ai ] Pr {Ai } . 
i 

E [R] = 

474 

CHAPTER 20.  RANDOM VARIABLES 

Proof. 

= 

= 

= 

� 
r  Pr {R = r} 
· 
�  � � � � � � 
E [R] ::= 
r∈range(R) 
r · 
Pr {R = r  |  Ai } Pr {Ai} 
i 
r
r · Pr {R = r  |  Ai } Pr {Ai} 
i 
r
r · Pr {R = r  |  Ai } Pr {Ai } 
� 
r 
i
Pr {Ai } 
r · Pr {R = r  |  Ai} 
� 
r 
i
Pr {Ai } E [R  | Ai ] . 
i 

= 

= 

(Def 20.3.1 of expectation) 

(Law of Total Probability) 

(distribute constant r) 

(exchange order of summation) 
(factor constant Pr {Ai }) 

(Def 20.3.4 of cond. expectation) 

� 

20.3.3  Mean Time to Failure 
A computer program crashes at the end of each hour of use with probability p, if it 
has not crashed already. What is the expected time until the program crashes? 
If  we  let  C  be  the  number  of  hours  until  the  crash,  then  the  answer  to  our 
problem  is E [C ].  Now  the probability  that,  for  i >  0,  the ﬁrst  crash occurs  in  the 
ith  hour  is  the  probability  that  it  does  not  crash  in  each  of  the  ﬁrst  i −  1  hours 
and  it does crash  in  the  ith hour, which  is  (1 − p)i−1p.  So  from  formula  (20.1)  for 
� 
expectation, we have 
i  Pr {R = i}
· 
� 
i∈N 
i(1 − p)i−1 p 
� 
i∈N+ 
= p
i∈N+ 

i(1 − p)i−1 

E [C ] = 

= 

1 
= p 
(1 − (1 − p))2 
1 = 
p 

(by (17.1))

A  simple  alternative  derivation  that  does  not  depend  on  the  formula  (17.1) 
(which  you  remembered,  right?)  is  based  on  conditional  expectation.  Given  that 
the  computer  crashes  in  the  ﬁrst  hour,  the  expected  number  of  hours  to  the  ﬁrst 
crash  is  obviously  1!  On  the  other  hand,  given  that  the  computer  does  not  crash 
in  the ﬁrst hour,  then  the  expected  total number of hours  till  the ﬁrst  crash  is  the 

20.3.  AVERAGE & EXPECTED VALUE 

475 

expectation of one plus the number of additional hours to the ﬁrst crash.  So, 
E [C ] = p  1 + (1 − p) E [C + 1] = p + E [C ] − p E [C ] + 1 − p,
· 

from which we immediately calculate that E [C ] = 1/p. 
So,  for example,  if  there  is a 1% chance  that  the program crashes at  the end of 
each hour, then the expected time until the program crashes is 1/0.01 = 100 hours. 
As  a  further  example,  suppose  a  couple  really wants  to  have  a  baby  girl.  For 
simplicity assume there is a 50% chance that each child they have is a girl, and the 
genders of their children are mutually independent.  If the couple insists on having 
children until they get a girl, then how many baby boys should they expect ﬁrst? 
This  is  really  a  variant  of  the  previous  problem.  The  question,  “How  many 
hours  until  the  program  crashes?”  is  mathematically  the  same  as  the  question, 
“How many  children must  the  couple  have  until  they  get  a  girl?”  In  this  case,  a 
crash  corresponds  to  having  a  girl,  so  we  should  set  p  = 1/2.  By  the  preceding 
analysis, the couple should expect a baby girl after having 1/p = 2 children.  Since 
the last of these will be the girl, they should expect just one boy. 
Something  to  think about:  If every  couple  follows  the  strategy of having  chil­
dren until they get a girl, what will eventually happen to the fraction of girls born 
in this world? 

20.3.4  Linearity of Expectation 
Expected values obey a simple, very helpful rule called Linearity of Expectation.  Its 
simplest form says that the expected value of a sum of random variables is the sum 
of the expected values of the variables. 

Theorem 20.3.6.  For any random variables R1  and R2 , 

E [R1  + R2 ] = E [R1 ] + E [R2 ] . 

T (ω) · Pr {ω} 

Proof.  Let T ::= R1 + R2 . The proof follows straightforwardly by rearranging terms 
in the sum (20.2) � 
� 
E [T ] = 
ω∈S 
(R1 (ω) + R2 (ω)) · Pr {ω} 
� 
� 
ω∈S 
R2 (ω) Pr {ω} 
R1 (ω) Pr {ω} + 
ω∈S 
ω∈S 
= E [R1 ] + E [R2 ] . 

(rearranging terms) 

(Theorem 20.3.2) 

= 

= 

(Theorem 20.3.2) 

(def of T ) 

A small extension of this proof, which we leave to the reader, implies 

� 

476 

CHAPTER 20.  RANDOM VARIABLES 

Theorem 20.3.7 (Linearity of Expectation).  For random variables R1 , R2  and constants 
a1 , a2  ∈ R, 

E [a1R1  + a2R2 ] = a1 E [R1 ] + a2 E [R2 ] . 

In  other words,  expectation  is  a  linear  function.  A  routine  induction  extends 
the result to more than two variables: 
Corollary 20.3.8.  For any random variables R1 , . . . , Rk  and constants a1 , . . . , ak  ∈ R, 
� � 
� 
� 
k
k
aiRi  = 
ai E [Ri ] . 
E 
i=1 
i=1 

The great thing about linearity of expectation is that no independence is required. 
This  is  really  useful,  because  dealing with  independence  is  a  pain,  and we  often 
need to work with random variables that are not independent. 

Expected Value of Two Dice 

What is the expected value of the sum of two fair dice? 
Let  the  random  variable  R1  be  the  number  on  the  ﬁrst  die,  and  let  R2  be  the 
number on the second die.  We observed earlier that the expected value of one die 
is 3.5. We can ﬁnd the expected value of the sum using linearity of expectation: 

E [R1  + R2 ] = E [R1 ] + E [R2 ] = 3.5 + 3.5 = 7. 

Notice  that  we  did  not  have  to  assume  that  the  two  dice  were  independent. 
The expected sum of two dice is 7, even if they are glued together (provided each 
individual  die  remainw  fair  after  the  gluing).  Proving  that  this  expected  sum  is 
7  with  a  tree  diagram  would  be  a  bother:  there  are  36  cases.  And  if  we  did  not 
assume that the dice were independent, the job would be really tough! 

The Hat-Check Problem 

There is a dinner party where n men check their hats. The hats are mixed up during 
dinner, so that afterward each man receives a random hat.  In particular, each man 
gets his own hat with probability 1/n.  What  is  the expected number of men who 
get their own hat? 
Letting  G  be  the  number  of  men  that  get  their  own  hat,  we  want  to  ﬁnd  the 
expectation of G.  But all we know about G  is  that  the probability  that a man gets 
his own hat back  is 1/n.  There are many different probability distributions of hat 
permutations with this property, so we don’t know enough about the distribution 
of  G  to  calculate  its  expectation  directly.  But  linearity  of  expectation  makes  the 
problem really easy. 
The trick is to express G as a sum of indicator variables.  In particular, let Gi  be 
an  indicator  for  the event  that  the  ith man gets his own hat.  That  is, Gi  = 1  if he 

20.3.  AVERAGE & EXPECTED VALUE 

477 

gets his own hat, and Gi  = 0 otherwise. The number of men that get their own hat 
is the sum of these indicators: 

· · · 
+ Gn . 
G = G1  + G2  +
(20.4)
These indicator variables are not mutually independent.  For example, if n − 1 men 
all get their own hats, then the last man is certain to receive his own hat. But, since 
we plan to use linearity of expectation, we don’t have worry about independence! 
Now since Gi  is an indicator, we know 1/n = Pr {Gi  = 1} = E [Gi ] by Lemma 20.3.3. 
Now we can take the expected value of both sides of equation (20.4) and apply lin­
earity of expectation: 

· · · 
+ Gn ]
E [G] = E [G1  + G2  +
· · ·  � �
= E [G1 ] + E [G2 ] +  + E [Gn ]
1
1 
1
1 
· · · 
= + +  + = n 
n 
n 
n
n

= 1. 

So even though we don’t know much about how hats are scrambled, we’ve ﬁgured 
out that on average, just one man gets his own hat back! 

Expectation of a Binomial Distribution 

But 

Suppose that we independently ﬂip n biased coins, each with probability p of com­
ing up heads. What is the expected number that come up heads? 
Let  J  be  the  number  of  heads  after  the  ﬂips,  so  J  has  the  (n, p)-binomial  dis­
tribution.  Now  let  Ik  be  the  indicator  for  the  kth  coin  coming  up  heads.  By 
Lemma 20.3.3, we have 
E [Ik ] = p. 
� 
n
J  = 
Ik , 
�
� 
k=1 
� 
�  � 
n
n
n
p = pn. 
Ik  = 
E [J ] = E 
E [Ik ] = 
k=1 
k=1 
k=1 
In short, the expectation of an (n, p)-binomially distributed variable is pn. 

so by linearity 

The Coupon Collector Problem 

Every  time  I  purchase  a  kid’s  meal  at  Taco  Bell,  I  am  graciously  presented  with 
a miniature  “Racin’  Rocket”  car  together with  a  launching  device which  enables 
me to project my new vehicle across any tabletop or smooth ﬂoor at high velocity. 
Truly, my delight knows no bounds. 
There are n different types of Racin’ Rocket car (blue, green, red, gray, etc.). The 
type  of  car  awarded  to me  each  day  by  the  kind woman  at  the  Taco  Bell  register 

478 

CHAPTER 20.  RANDOM VARIABLES 

appears  to  be  selected  uniformly  and  independently  at  random.  What  is  the  ex­
pected number of kid’s meals that I must purchase in order to acquire at least one 
of each type of Racin’ Rocket car? 
The same mathematical question shows up in many guises:  for example, what 
is the expected number of people you must poll in order to ﬁnd at least one person 
with each possible birthday? Here, instead of collecting Racin’ Rocket cars, you’re 
collecting birthdays.  The general question is commonly called the coupon collector 
problem after yet another interpretation. 
A clever application of linearity of expectation leads to a simple solution to the 
coupon collector problem.  Suppose there are ﬁve different types of Racin’ Rocket, 
and I receive this sequence: 

blue  green  green 

red  blue  orange  blue  orange  gray 

Let’s partition the sequence into 5 segments: 
� �� �
�� 
�� 
�� 
� �� �
� 
� 
�
� 
�
� 
blue
green
green  red  blue  orange  blue  orange  gray
X0 
X1 
X2 
X3 
X4 

The rule is that a segment ends whenever I get a new kind of car.  For example, the 
middle  segment  ends when  I  get  a  red  car  for  the  ﬁrst  time.  In  this way,  we  can 
break the problem of collecting every type of car into stages. Then we can analyze 
each stage individually and assemble the results using linearity of expectation. 
Let’s  return  to  the general  case where  I’m  collecting n Racin’ Rockets.  Let Xk 
be the length of the kth segment.  The total number of kid’s meals I must purchase 
to get all n Racin’ Rockets is the sum of the lengths of all these segments: 

T  = X0  + X1  +

· · · 
+ Xn−1

Now  let’s  focus  our  attention  on  Xk ,  the  length  of  the  kth  segment.  At  the 
beginning of segment k , I have k different types of car, and the segment ends when 
I acquire a new  type.  When  I own k  types,  each kid’s meal  contains a  type  that  I 
already have with probability k/n. Therefore, each meal contains a new type of car 
with probability 1 − k/n  = (n − k)/n.  Thus,  the  expected number of meals until 
I get a new kind of car  is n/(n − k) by the “mean time to failure” formula.  So we 
have: 

E [Xk ] = 

n
n − k 

Linearity of expectation, together with this observation, solves the coupon col­

20.3.  AVERAGE & EXPECTED VALUE 

479 

lector problem: 

· · · 
+ Xn−1 ]
E [T ] = E [X0  + X1  +
· · · 
= E [X0 ] + E [X1 ] +  + E [Xn−1 ]
� 
� 
n 
n 
n 
· · · 
n
n
= 
+ 
+
+ + + 
n − 1 
n − 0 
2
3
1 
� 
� 
1
1
1 
1 
1 
· · · 
+  + + + 
+ 
= n 
n − 1 
3
1 
2
n
1
1 
1 
1
1
· · · 
+ 
+ + +
n 
n − 1 
1
2
3 
n 
= nHn  ∼ n ln n. 

+

Let’s use this general solution to answer some concrete questions. For example, 
the expected number of die rolls required to see every number from 1 to 6 is: 

6H6  = 14.7 . . . 

And the expected number of people you must poll to ﬁnd at least one person with 
each possible birthday is: 

365H365  = 2364.6 . . . 

20.3.5  The Expected Value of a Product 

While the expectation of a sum is the sum of the expectations, the same is usually 
not true for products.  But it is true in an important special case, namely, when the 
random variables are independent. 
For  example,  suppose  we  throw  two  independent,  fair  dice  and  multiply  the 
numbers that come up. What is the expected value of this product? 
Let  random  variables R1  and R2  be  the  numbers  shown  on  the  two  dice.  We 
can compute the expected value of the product as follows: 

E [R1  · R2 ] = E [R1 ]  E [R2 ] = 3.5 3.5 = 12.25. 
·
· 
� 
� 
Here the ﬁrst equality holds because the dice are independent. 
At  the  other  extreme,  suppose  the  second  die  is  always  the  same  as  the  ﬁrst. 
Now R1  = R2 , and we can compute the expectation, E  R1
2  , of the product of the 

(20.5)

480 

CHAPTER 20.  RANDOM VARIABLES 

=

+

+

+

= 

32 
6

+

42 
6

+

= 

52 
6

62 
6 

� � 
� 
dice explicitly, conﬁrming that it is not equal to the product of the expectations. 
E [R1  · R2 ] = E  R1
� 
� 
2 
6
· 
i2  Pr  R1
2  = i2
� 
i=1

6

i2  Pr {R1  = i}
· 
i=1 
12 
22 
6
6
= 15 1/6 
= 12 1/4 
· 
= E [R1 ]  E [R2 ] .
Theorem 20.3.9.  For any two independent random variables R1 , R2 , 
E [R1  · R2 ] = E [R1 ]  E [R2 ] .
· 
· 
Proof.  The  event  [R1  R2  =  r ]  can  be  split  up  into  events  of  the  form  [R1  = 
r1  and  R2  = r2 ] where r1  · r2  = r .  So 
� 
E [R1  · R2 ] 
r  Pr {R1  · R2  = r}
· 
� 
::= 
r∈range(R1 ·R2 ) 
r1 r2  · Pr {R1  = r1  and  R2  = r2} 
� 
� 
ri∈range(Ri ) 
r1 r2  · Pr {R1  = r1  and  R2  = r2} 
� 
� 
r1∈range(R1 ) r2∈range(R2 ) 
r1 r2  · Pr {R1  = r1} · Pr {R2  = r2} 
⎞

⎛
�

� 
r1∈range(R1 ) r2∈range(R2 )
r2 Pr {R2  = r2}⎠ 
⎝r1 Pr {R1  = r1} · 
� 
r1∈range(R1 ) 
r2∈range(R2 ) 
r1 Pr {R1  = r1} · E [R2 ] 
� 
r1∈range(R1 ) 
r1 Pr {R1  = r1} 
· 
= E [R2 ] 
r1∈range(R1 ) 
· 
= E [R2 ]  E [R1 ] . 

= 

= 

= 

= 

= 

(def of E [R1 ])
� 
Theorem 20.3.9 extends routinely to a collection of mutually independent vari­
ables. 

(ordering terms in the sum) 

(indep. of R1 , R2 ) 

(factoring out r1 Pr {R1  = r1}) 

(def of E [R2 ]) 

(factoring out E [R2 ])

�
20.3.  AVERAGE & EXPECTED VALUE 
� � 
� 
Corollary 20.3.10.  If random variables R1 , R2 , . . . , Rk  are mutually independent, then 
� 
k
k
E [Ri ] . 
Ri  = 
E 
i=1 
i=1 

481 

20.3.6  Problems 
Practice Problems 

Problem 20.4. 
MIT students sometimes delay laundry for a few days. Assume all random values 
described below are mutually independent. 
(a)  A  busy  student  must  complete  3  problem  sets  before  doing  laundry.  Each 
problem  set  requires  1  day with  probability  2/3  and  2  days with  probability  1/3. 
Let B be the number of days a busy student delays laundry. What is E [B ]? 
Example:  If the ﬁrst problem set requires 1 day and the second and third problem 
sets each require 2 days, then the student delays for B = 5 days. 

(b)  A relaxed student rolls a fair, 6-sided die in the morning.  If he rolls a 1, then he 
does his laundry immediately (with zero days of delay).  Otherwise, he delays for 
one day and repeats the experiment the following morning.  Let R be the number 
of days a relaxed student delays laundry. What is E [R]? 
Example:  If the student rolls a 2 the ﬁrst morning, a 5 the second morning, and a 1 
the third morning, then he delays for R = 2 days. 

(c)  Before doing laundry, an unlucky student must recover from illness for a num­
ber  of  days  equal  to  the  product  of  the  numbers  rolled  on  two  fair,  6-sided  dice. 
Let U  be the expected number of days an unlucky student delays laundry. What is 
E [U ]? 
Example:  If the rolls are 5 and 3, then the student delays for U  = 15 days. 

(d)  A  student  is  busy with  probability  1/2,  relaxed with  probability  1/3,  and  un­
lucky with probability 1/6. Let D be the number of days the student delays laundry. 
What is E [D]? 

Problem 20.5. 
Each 6.042 ﬁnal exam will be graded according to a rigorous procedure: 

2  it is graded 
7  the exam is graded by a TA,with probability  7
•	 With probability  4
1 ,  it  is  accidentally  dropped  behind  the 
by  a  lecturer,  and  with  probability  7
radiator and arbitrarily given a score of 84. 

•	 TAs score an exam by scoring each problem individually and then taking the 
sum. 

482 

CHAPTER 20.  RANDOM VARIABLES 

–	 There  are  ten  true/false  questions  worth  2  points  each.  For  each,  full 
credit is given with probability  3
4 , and no credit is given with probability 
1 .4 
–	 There  are  four  questions  worth  15  points  each.  For  each,  the  score  is 
determined by rolling two fair dice, summing the results, and adding 3. 
–	 The single 20 point question is awarded either 12 or 18 points with equal 
probability. 

•	 Lecturers  score  an  exam  by  rolling  a  fair  die  twice,  multiplying  the  results, 
and then adding a “general impression”score. 

–	 With probability  4  , the general impression score is 40. 
10 
–	 With probability  3  , the general impression score is 50. 
10 
–	 With probability  3  , the general impression score is 60. 
10 

Assume all random choices during the grading process are independent. 
(a)  What is the expected score on an exam graded by a TA? 

(b)  What is the expected score on an exam graded by a lecturer? 

(c)  What is the expected score on a 6.042 ﬁnal exam? 

Class Problems 

Problem 20.6. 
Let’s  see  what  it  takes  to  make  Carnival  Dice  fair.  Here’s  the  game  with  payoff 
parameter k : make three independent rolls of a fair die.  If you roll a six 

•	 no times, then you lose 1 dollar. 

•	 exactly once, then you win 1 dollar. 

•	 exactly twice, then you win two dollars. 

•	 all three times, then you win k dollars. 

For what value of k  is this game fair? 

Problem 20.7. 
A classroom has sixteen desks arranged as shown below. 

20.3.  AVERAGE & EXPECTED VALUE 

483 

If there is a girl in front, behind, to the left, or to the right of a boy, then the two of 
them ﬂirt.  One student may be in multiple ﬂirting couples; for example, a student 
in a corner of the classroom can ﬂirt with up to two others, while a student in the 
center  can ﬂirt with  as many  as  four  others.  Suppose  that desks  are  occupied  by 
boys  and  girls  with  equal  probability  and  mutually  independently.  What  is  the 
expected number of ﬂirting couples? Hint: Linearity. 

Problem 20.8. 
Here are seven propositions: 

x1 
x5 
x2 
x4 
x3 
x9 
x3 

OR 
OR 
OR 
OR 
OR 
OR 
OR 

x3 
x6 
x4 
x5 
x5 
x8 
x9 

OR 
OR 
OR 
OR 
OR 
OR 
OR 

x7 
x7 
x6 
x7 
x8 
x2 
x4 

Note that: 

1.  Each proposition  is  the disjunction  (OR) of  three  terms of  the  form xi  or  the 
form xi . 

2.  The variables in the three terms in each proposition are all different. 

Suppose  that we  assign  true/false  values  to  the  variables  x1 , . . . , x9  indepen­
dently and with equal probability. 

484 

CHAPTER 20.  RANDOM VARIABLES 

(a)  What is the expected number of true propositions? 

Hint: Let Ti  be an indicator for the event that the i-th proposition is true. 

(b)  Use your answer to prove that for any set of 7 propositions satisfying the con­
ditions  1.  and  2.,  there  is  an  assignment  to  the  variables  that  makes  all  7  of  the 
propositions true. 

Problem 20.9.  (a)  Suppose  we  ﬂip  a  fair  coin  until  two  Tails  in  a  row  come  up. 
What  is  the  expected  number,  NTT ,  of  ﬂips  we  perform?  Hint:  Let  D  be  the  tree 
· 
·
· 
diagram for this process.  Explain why D  = H D + T  (H D + T ).  Use the Law 
of Total Expectation 20.3.5 

(b)  Suppose we ﬂip a fair coin until a Tail immediately followed by a Head come 
up. What is the expected number, NTH , of ﬂips we perform? 

(c)  Suppose we now play a game: ﬂip a fair coin until either TT or TH ﬁrst occurs. 
You win if TT comes up ﬁrst,  lose if TH comes up ﬁrst.  Since TT takes 50% longer 
on  average  to  turn  up,  your  opponent  agrees  that  he  has  the  advantage.  So  you 
tell him you’re willing to play if you pay him $5 when he wins, but he merely pays 
you a 20% premium, that is, $6, when you win. 

If you do this, you’re sneakily taking advantage of your opponent’s untrained in­
tuition,  since  you’ve  gotten  him  to  agree  to  unfair  odds.  What  is  your  expected 
proﬁt per game? 

Problem 20.10. 
Justify each line of the following proof that if R1  and R2  are independent, then 

E [R1  · R2 ] = E [R1 ]  E [R2 ] .
· 

20.3.  AVERAGE & EXPECTED VALUE 

485 

Proof. 

= 

= 

= 

= r1


r1 r2  · 
Pr {R1 

= r1


and  R2  = r2}

and  R2  = r2 }

� 
E [R1  · R2 ] 
r  Pr {R1  · R2  = r}
· 
� 
= 
r∈range(R1 ·R2 ) 
r1 r2  · 
Pr {R1 
� 
� 
ri∈range(Ri )

� 
� 
r1∈range(R1 ) r2∈range(R2 )

r1 r2  · Pr {R1  = r1 } · Pr {R2  = r2 } 
⎛
⎞ 
� 
� 
r1∈range(R1 ) r2∈range(R2 )
⎝r1 Pr {R1  = r1 } · 
r2 Pr {R2  = r2 }⎠ 
� 
r1∈range(R1 ) 
r2 ∈range(R2 ) 
r1 Pr {R1  = r1} · E [R2 ] 
� 
r1∈range(R1 ) 
r1 Pr {R1  = r1 }
· 
= E [R2 ] 
r1∈range(R1 ) 
· 
= E [R2 ]  E [R1 ] .

= 

= 

� 

Problem 20.11. 
Here are seven propositions: 

∨ 
x1 
¬x5  ∨ 
∨ ¬
x2 
¬x4  ∨ 
∨ ¬
x3 
∨ ¬
x9 
¬x3  ∨ 

∨ ¬
x7
x3 
x6  ∨ 
x7 
∨ 
x4 
x6
x5  ∨ ¬x7 
∨ ¬
x8
x5 
∨

x8 
x2
x9  ∨ 
x4


Note that: 
1.  Each proposition is the OR of three terms of the form xi  or the form  xi .¬
2.  The variables in the three terms in each proposition are all different. 

Suppose that we assign true/false values to the variables x1 , . . . , x9  independently 
and with equal probability. 
(a)  What is the expected number of true propositions? 

486 

CHAPTER 20.  RANDOM VARIABLES 

(b)  Use your answer to prove that there exists an assignment to the variables that 
makes all of the propositions true. 

Problem 20.12. 
A literal is a propositional variable or its negation.  A k-clause is an OR  of k  literals, 
with no variable occurring more than once in the clause.  For example, 

is a 4-clause, but 

P  OR Q OR R OR V , 

V  OR Q OR X  OR V , 

is not, since V  appears twice. 
Let  S  be  a  set  of  n  distinct  k-clauses  involving  v  variables.  The  variables  in 
different k-clauses may overlap or be completely different, so k ≤ v ≤ nk . 
A random assignment of true/false values will be made independently to each 
of  the  v  variables, with  true  and  false  assignments  equally  likely.  Write  formulas 
in n, k , and v  in answer to the ﬁrst two parts below. 
(a)  What  is  the  probability  that  the  last  k-clause  in  S  is  true  under  the  random 
assignment? 
(b)  What is the expected number of true k-clauses in S ? 

(c)  A  set  of  propositions  is  satisﬁable  iff  there  is  an  assignment  to  the  variables 
that makes all of the propositions true. Use your answer to part (b) to prove that if 
n < 2k , then S  is satisﬁable. 

Problem 20.13. 
A  gambler  bets  $10  on  “red”  at  a  roulette  table  (the  odds  of  red  are  18/38 which 
slightly less than even) to win $10.  If he wins, he gets back twice the amount of his 
bet and he quits. Otherwise, he doubles his previous bet and continues. 
(a)  What is the expected number of bets the gambler makes before he wins? 

(b)  What is his probability of winning? 

(c)  What is his expected ﬁnal proﬁt (amount won minus amount lost)? 

(d)  The  fact  that  the  gambler ’s  expected  proﬁt  is  positive,  despite  the  fact  that 
the game  is biased  against him,  is known  as  the St.  Petersberg  paradox.  The para­
dox  arises  from  an  unrealistic,  implicit  assumption  about  the  gambler ’s  money. 
Explain. 
Hint: What is the expected size of his last bet? 

20.3.  AVERAGE & EXPECTED VALUE 

487 

Homework Problems 

Problem 20.14. 
Let R and S  be independent random variables, and f  and g be any functions such 
that domain (f ) = codomain (R) and domain (g) = codomain (S ). Prove that f (R) 
and  g(S )  are  independent  random  variables.  Hint:  The  event  [f (R) =  a]  is  the 
disjoint union of all the events [R = r ] for r such that f (r) = a. 

488 

CHAPTER 20.  RANDOM VARIABLES 

MIT OpenCourseWare
http://ocw.mit.edu 

6.042J / 18.062J Mathematics for Computer Science 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

