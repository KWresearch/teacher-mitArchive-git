Massachusetts  Institute  of  Technology 
6.854J/18.415J: Advanced  Algorithms 
David  Karger 

Handout  17 
Wednesday,  November  2,  2005 

Problem   Set   9  

Due:  Wednesday,  November  9,  2005. 

In  class  we  used  a  “rescaling”  argument  to  show  that  if  one  had  an  absolute 
Problem  1. 
approximation  algorithm  for  maximum  independent  set  (MIS),  one  could  transform  it  into 
a  better  absolute  approximation  algorithm  for  the  problem  (and  in  fact,  solve  the  problem 
exactly).  In  this  problem,  we  will  show  that  a  similar  result  holds  true  for  relative  approx-
imation:  that  any  constant-factor  relative  approximation  algorithm  can  be  improved  to  a 
better  constant  factor  relative  approximation. 
Suppose  one  has  an  α-(relative)  approximation  algorithm  for  MIS.  Consider  the  following 
“graph  product”  operation  for  a  graph G.  Create  a  distinct  copy  Gv  of G  for  each  vertex  v 
of  G.  Then  connect  up  the  copies  as  follows:  if  (u, v ) is  an  edge  of  G,  then  connect  every 
vertex  in  Gu  to  every  vertex  in Gv . 

(a)   Prove  that  if  there  is an  independent  set  of  size k  in G,  then  there  is an  indepen
-
dent  set  of  size  k2  in  the  product  graph.

√ 
(b)   Prove  that  given  an  independent  set  of  size  s  in  the  product  graph,  one  can  ﬁnd 
an  independent  set  of  size  s  in  G. 
(c)	 Prove  that  if  there  is  an  α-approximation  for  MIS  for  some   ﬁxed  α,  then  there

is  a  polynomial  approximation  scheme  for MIS. 


Since MIS was shown to be MAX-SNP-hard, meaning there is some constant to within which 
it  cannot   be  approximated  (unless  P  =  N P )  this  proves  that  MIS  has  no   constant-factor 
relative  approximation. 

The  Steiner   Tree   Problem   presents  an  undi-
NONCOLLABORATIVE   Problem   2.  
rected  graph  G  with  edge  costs  ce ,  and  a  subset  T  of  the  vertices  called  terminals. The 
goal  is  to  construct  a minimum  cost  tree  spanning  all  the  terminals  (it may  also  include  any 
desired  subset  of  the  non-terminals;  these  included  vertices  are  called  Steiner   points ). 

(a)   Suppose  you  compute  all-pairs  shortest  paths  in G,  and  create  a  complete  graph

(cid:1)  on  the terminals T  where each edge cost  is equal  to the shortest path between

G
its  (terminal)  endpoints  in  G.  Relate  the  cost  of  the  minimum  spanning  tree  in

this  graph  to  the  cost  of  the  optimum  steiner  tree  in  G.

(b)   Give  a  2-approximation  algorithm  for  the  Steiner  tree  problem. 

2 

Handout  17:  Problem  Set  9 

The  following  is  the  NP-hard  problem  of  bin  packing: Given  n  items  with 
Problem  3. 
sizes  a1 ,...,an  ∈  (0, 1],  ﬁnd  a  packing  of  the  items  into  unit-sized  bins  that  minimizes  the 
∗
number of bins used.  Let B denote the optimum number of bins  for the given  instance.  Bin 
packing  is  a  lot  like  P ||Cmax ,  but  somewhat  more  diﬃculty  because  you  have  no  ﬂexibility 
to  increase  the  bin  sizes. 

(a)   Suppose that there are only k distinct  item sizes  for some constant k .  Argue that

you  can  solve  bin-packing  in  polynomial  time.  Hint:   no  new  algorithm  needed

here!

(b)   Suppose  that you have  packed  all  items  of  size greater  than    into B  bins.  Argue

that  in  linear  time  you  can  add  the  remaining  small  items  to  achieve  a  packing

∗
using  at most  max B , 1 + (1 + )B bins. 
(c)	 For P ||Cmax , we  reduced  to the previous  case by rounding each  job size up to  the

next  power  of  (1 + ).  Why  doesn’t  that  work  for  bin  packing?

(d)   Consider  instead  the  following  grouping   procedure.  Fix  some  constant  k . Order

the  items  by  size.  Let  S1  denote  the  largest  n/k  items,  S2  the  next  largest  n/k ,

and  so  on.  Suppose  that  you  increase  the  size  of  each  item  to  equal  the  largest

size  in  its group,  so  that  there are only k  distinct  sizes.  Argue  that this  increases

the  optimal  number  of  bins  by  at  most  n/k .  Hint:  
imagine  setting  aside  the

jobs  in  S1 .  Argue  that  the  remaining  items,  with  their  increased  sizes,  can  still

ﬁt  into  the  bins  used  by  the  original  packing.

(e)   By  applying  the  grouping  procedure  to  items  of  size  greater  than  /2,  solving

the  result  optimally,  and  then  adding  the  small  items,  devise  a  polynomial  time

∗
scheme  that  uses  at most  (1 + )B + 1  bins. 

Observe  that  the  algorithm  above  just  misses  the  deﬁnition  of  polynomial  approximation 
scheme,  because  of  the  additive  error  of  1  bin.  In  practice,  of  course,  this  is  unlikely  to 
matter.  The  above  scheme  is  known  as  an  asymptotic   PAS   since  its  approximation  ratio  is 
(1 + )  in  the  limit  as  the  optimum  value  grows. 
The  techniques  above  have  been  augmented  to  give  an  algorithm  that  ﬁnds  a  packing  using 
B ∗ +O(log2  B ) bins—giving asymptotic approximation ratio 1.  Indeed, at present it remains 
∗
∗
concievable  that  we  might  achieve  B + O(1)  bins  in  polynomial  time! 

You  are  given  a  collection  of  jobs,  each  with  a  processing   time   pj . There  are 
Problem  4. 
also  precedence  constraints : job  j  cannot  be  started  until  after  all  jobs  in  its  precedence  set 
A(j )  have  been  completed.  Each  job  gets  a weight   wj .  Our  goal  is  to minimize  the weighted  
� wj Cj  (where  Cj  is  the  time  job  j  completes).  In  other  words, 
average   completion   time  
we  are  looking  at  the  problem  1  |  prec   | 
� wj Cj .  Assuming  that  the  pj  are  polynomially-
bounded  integers,  we will  give  a  constant-factor  approximation  for  this  problem  via  a  linear 
programming  relaxation.  Deﬁne  variables  xj t   for  each  (integer)  time  step  t, denoting  the 
“indicator”  that  job  j  completed  at  time  t. 

Handout  17:  Problem  Set  9 

3 

(a)   Write  down  constraints  forcing  the  ILP  to  solve  the  problem.  In  particular,

enforce  that  only  every  job  completes,  that  a  job  is  not  processed  before  ites

predecesors,  and  (most  subtly)  that  the  total  processing  time  of  jobs  completed

before  time  t  is  at most  t.

(b)   The LP relaxation of this ILP is a kind of “timesharing” schedule  for jobs.  Deﬁne

�
the  fractional   commpletion   time   of  job  j  to  be  C j  = 
t  txj t . To  turn  it  into  an

actual  order,  consider  the  halfway   point   hj  of  each  job:  this  is  the  time  at which

half  the  job  is  completed.  Prove  that C j  ≥ hj /2.

(c)	 Consider  the  schedule  that processes  jobs  in  order  of  their  halfway points.  Prove

that  no  job  runs  before  its  predecessors.

(d)   Prove  that  for  the  given  order,  the  actual  completion  time  for  job  j  is  at  most

2C j .

(e)	 Conclude  that  you  have  a  constant-factor  approximation  for  1 | prec   | 
� Cj . 
OPTIONAL  (f ) 	 Suppose  that  each  job  comes  with  a  release   date   rj  before  which

it  cannot  be  processed.  Generalize  your  algorithm  to  handle  this  case  (with  a

slightly  worse  constant).


