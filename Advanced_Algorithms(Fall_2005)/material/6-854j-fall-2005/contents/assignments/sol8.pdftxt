Massachusetts  Institute  of  Technology 
6.854J/18.415J: Advanced  Algorithms 
David  Karger 

Handout  18 
Wednesday,  November  2,  2005 

Problem   Set   8   Solutions  

1 
1 
. . 
. 
1 

. . .  0

1 ) , 

(cid:1) 
πi  = 1.  This 

Its  dual  is 

Problem  1. 
We  want  to  show  that  there  exists  a  vector  π  ≥  0  such  that  πP  =  π , and 
can  be  formulated  as  the  following  linear  program: 
⎞ 
⎛ 
min  0, 
⎟ ⎠  = ( 0  0 
⎜ ⎝  P  − I 
π 
π  ≥  0. 
⎛ ⎞ 
⎞  x1 ⎜ x2  ⎟ 
max  y , 
⎜ ⎟ 
1 ⎟ 
⎟  ≤  0. 
.  ⎠ ⎜  .. 
1 
.  ⎜ ⎟ 
⎠ 
⎝ xn 
. 
. 
1 
y 
The  dual  is  obviously  feasible  (x  = 0,  y  =  0),  and  we  will  show  that  y  cannot  be  greater 
than  0.  Fix  an  arbitrary  vector  x, and  let  k  be  an  integer  such  that  xk  = mini xi . If  we 
consider  the  k th  constraint,  it  looks  like 
pk ,1x1  + · · · + pk ,k−1xk−1  + (pk ,k  − 1)xk  + pk ,k+1xk1  + · · · pn,nxn  + y ≤ 0, 
(cid:10) 
(cid:8)
(cid:9) 
and  we  can  transform  it  into 
pk ,ixi  − xk  ≤ −y . 
i 
Since all pk ,i  are nonnegative,  and their sum equals 1, the sum  in the  inequality  is a weighted 
average of xi ’s,  and  is not  less  than xk ,  so  the  left hand  side of  the  inequality  is nonnegative, 
0 ≤ −y , 

⎛ 
⎜ 
⎝  P  − I 

and  eventually, 

y ≤ 0. 
We  have  shown  that  y ,  which  we  maximize,  is  bounded  by  0  for  any  x,  what  together  with 
the  feasibility  of  the  dual  implies  feasibility  of  the  primal,  and  the  required  π  exists. 

2 

Handout  18:  Problem  Set  8  Solutions 

Problem  2. 
(a)   If  Alice’s  mixed  strategy  is  known,  then  for  each  Bob’s  mixed  strategy,  Bob’s  payoﬀ  is 
a  weighted  average  of  Bob’s  payoﬀs  for  pure  strategies.  This  implies  that  Bob  can  simply 
choose  the  pure  strategy  of  the maximum  payoﬀ,  and  it  serves  as  his  best  response. 

(b) &   (c)   By  part  (a)  the  ﬁrst  of  the  two  problems  turns  into: 

min  (maximum  of  columns  of  xA). 
P
xi=1  

We  create  an  additional  variable  γ ,  an  upper  bound  on  all  columns.  The  following  linear 
program  describes  our  situation: 

min γ , 
(cid:9) 
xA  ≤ (γ  γ  . . . γ ) , 
xi  = 1, 
x  ≥ 0. 
Two  last  constraints  guarantee  that  x  is  a  mixed  strategy.  The  ﬁrst  one  says  that  γ  is  an 
upper bound on all columns, what  in turn means that  it  is not smaller  than the maximum of 
all  columns  of  xA.  Since  we  minimize  γ ,  it  will  actually  equal  the  maximum  of  all  columns 
of  xA,  and  we  will  choose  such  x  that  this maximum  is minimum. 
The  second  problem  (by  analogous  argumentation)  turns  into: 
⎛ ⎞ 
max δ, 
δ ⎜ δ ⎟ ⎜ ⎟
Ay  ≥  ⎝ .. ⎠ , 
(cid:9) 
. 
δ 
yi  = 1, 
y  ≥ 0. 

(d)   If  we  take  the  dual  of  the  ﬁrst  linear  program,  we  get 
max δ, ⎛ ⎞ 
δ ⎜ δ ⎟ ⎜ ⎟
Ay  ≤ − ⎝ .. ⎠ , 
(cid:9) 
. 
δ 
− 
yi  = 1, 
y  ≤ 0, 

Handout  18:  Problem  Set  8  Solutions 

3 

which after the substitution y := −y  is the second linear program.  Since both linear programs 
are  obviously  feasible,  by  strong  duality  optimum  γ  and  δ  must  be  equal. 

Problem  3. 

(a)   We  will  create  consecutive  clusters.  Let  S  be  the  set  of  points  that  have  not  been 
assigned  yet  to  any  cluster.  If  S  is  empty,  all  remaining  clusters  will  be  empty.  Otherwise, 
pick  arbitrary  point  p  in  S ,  remove  it  with  all  points  that  are  at  most  d  far  from  it,  and 
create  of  them  a  new  cluster. 
There  is some optimal clustering C .  Any point that does not belong at some point to clusters 
that  we  have  already  created,  has  to  belong  to  a  diﬀerent  cluster  in  C  than  any  point  that 
we  have  picked  up  as  a  center  so  far.  Since  there  are  k  clusters  in  C , after  k  rounds  S  must 
be  empty. 

Furthermore,  by  the  triangle  inequality  the  distance  between  any  two  points  in  the  same 
created  cluster  is  not  greater  than  2d,  and  therefore,  we  achieve  a  2-approximation. 

(b)   As  long  as  there  is  a  point  that  is  farther  than  d  from  each  center  chosen  so  far,  it 
belongs  to  a  diﬀerent  cluster  in  C ,  and  if  there  exists  such  a  point,  it  must  be  the  point  of 
the  maximum  distance  from  already  chosen  centers,  and  since  there  are  k  clusters  in  C , no 
point  will  be  farther  than  d  from  all  centers  after  k  turns.  This  yields  2-approximation. 

Problem  4. 

(a)   If  jobs,  in  a  feasible  set  of  jobs,  are  not  scheduled  in  order  of  increasing  deadline,  there 
are  two  adjacent  that  are  not  in  this  order,  and  it  is  enough  to  show  that  they  can  switch 
their  positions.  If  we  interchange  them,  the  number  of  inversions  will  decrease  by  1,  and 
repeating  this  procedure,  ﬁnally  we  get  a  scheduling  in  the  required  order. 
Let  A  and  B  be  the  two  aforementioned  jobs  of  due  dates,  respectively,  dA , and  dB , where 
d
A  > dB , and  job A precedes  job B . If we  switch A  and B , B  will  still  be done  on  time,  and 
job A  will  be  done  before  the  deadline  for B ,  so  before  the  deadline  for  itself  as  well. 

(b)   Assume  that  jobs  have  assigned  numbers  from  1  to  n, where  n  is  the  number  of  jobs,  in 
order  of  increasing  deadline.  Jobs  that  will  be  completed  on  time  can  be  processed  in  this 
(cid:1) 
order,  the  other  can  be  completed  at  the  end,  since  they miss  their  deadlines  anyway. 
Let  A(j, w),  where  0 ≤  j  ≤  n  and  0 ≤ w  ≤  wi ,  be  the  minimum  processing  time  of  ﬁrst 
j  jobs  under  a  penalty w .  Jobs  responsible  for w  are  scheduled  somewhere  far  in  the  future, 
and we  pay  due  penalties  for  them.  A(j, w)  can  be  recursively  described  as  the minimum  of 
the  following  two  numbers 
A(j − 1, w − wj ) —  we  do  not  schedule  job  j , 

�

 

4 

Handout  18:  Problem  Set  8  Solutions 

 

�

A(j  − 1, w) + pj  —  if  we  schedule  job  j ,  and  we  consider  this  option  only  if  A(j  − 
1, w) + pj  ≤ dj ,  i.e.  job  j  does  not miss  its  deadline. 
(cid:1) 
We  can  assume  that  boundary  A’s  have  value  ∞,  except  A(0, 0)  which  is  equal  to  0.  The 
table  of  numbers  A(·, ·)  can  be  computed  dynamically  in  time  O(n · 
pj ).  Next  we  ﬁnd 
ﬁnite  A(n, w)  of  the  minimum  value  w , and  A(n, w)  is  the  fastest  completing  time  of  some 
feasible  subset  of  the  maximum  weight  (which  corresponds  to  the  minimum  cost  of  the 
jobs  completed  after  deadlines).  Using  table  A,  we  can  quickly  reconstruct  the  appropriate 
feasible  set. 

∗
∗
(c)   Let w  be  the  optimum  total  penalty.  We  can  assume  that w > 0.  It  can  be  checked  in 
∗
the beginning whether the set of all jobs is a feasible set,  to avoid the situation when w  = 0. 
We  scale  each  penalty  wj  to  εw∗ wj ,  and  round  down  to  (cid:4) 
εw∗ wj (cid:5). 
n
n
The  optimum  penalty  will 
n
be  ﬁrst  scaled  to  ε ,  and  since  rounding  down  decreases  the  penalty  of  any  scheduling  by 
less  than  n,  the  optimum  solution  under  the  modiﬁed  weights  has  had,  before  the  rounding 
down, a penalty of at most  n + n = (1 + ε) n 
ε , so ﬁnding the optimum penalty for the modiﬁed 
ε 
weights,  we  ﬁnd  a  good  approximation  for  the  original  problem. 
2 
We  can  ﬁnd  the  exact  solution  for  the  modiﬁed  weights  in  time  O( n
ε  ),  using  the  dynamic 
programming  from  part  (b). 
∗
We  do  not  know  w  ,  but  we  can  quickly  determine  its  good  approximation,  using  binary 
search, as we did for other problems in class.  We know that w  ≥ min wj , and w 
∗  ≤ n max wj , 
∗
so  we  need  only  a  polynomial,  in  size  of  representations  of  numbers,  number  of  guesses  to 
get  into  1 ± ε  of  w 
∗ . 

