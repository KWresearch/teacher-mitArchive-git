Midterm  Examination 

15.084J/6.252J:  Nonlinear  Programming 

March  19,  1998 

Name: 

This  is  a  closed  book  exam. 

Please  write  your  solutions  in  the  white  exam  books  provided.  Be  clear.  Your  grade  will 
depend  in  part  on  the  clarity  of  your  answers. 

The  point  count  for  each  question  is  given  next  to  the  question. 

1


Question   1:   (10   points)  

In  the  lectures,  we  have  spent  considerable  time  developing  and  discussing  two  methods 
for  unconstrained  optimization:  the method  of  steepest  descent,  and  Newton’s method. 

(a) List several advantages that the method of steepest descent has over Newton’s method. 
Please  give  only  a  brief   explanation  of  each  advantage. 

(b) List several advantages that Newton’s method has over the method of steepest descent. 
Please  give  only  a  brief   explanation  of  each  advantage. 

2


Question   2:   (15   points)  
Suppose  that  f (x)  is  a  diﬀerentiable  convex  function  on (cid:1)n  .  Prove  that  for  any  x,  y  ∈ (cid:1) , 
n
that 

(∇f (x) − ∇f (y))
T 

(x  − y) ≥ 0. 

3


Question   3:   (15   points)  

Consider  the  problem  (P ): 

(P )  :  minimize 

−x1  − x2 

s.t. 

−x1  + 6x1  − 9x1  + x2  − 10 ≤ 0 
3
2
−x2  + 14 ≤ 0 
x1  − 5 ≤ 0. 

(a) Does the point (x1 , x2 ) = (1, 14) satisfy the Karush-Kuhn-Tucker and/or the Fritz John 
necessary  conditions  for  a  local minimum?  Why  or  why  not? 

¯
(b)  Consider  the  general  program  ( P ): 

¯(P ) :  minimize  f (x) 

s.t. 

gi (x) ≤ 0  ,
x ∈ (cid:1) . 
n

i = 1, . . . , m  

¯
Suppose  that  ¯x  is  the  unique  point  satisfying  the Karush-Kuhn-Tucker  conditions  for  ( P ). 
¯
Is  ¯x  the  optimal  solution  to  ( P )?  Support  your  answer. 

4 

Question   4:   (15   points)  

x  satisfy  A ¯
Let  ¯
x  = b  in  the  problem: 

minimize  f (x) 

s.t. 

Ax   = b 
x  ∈ (cid:1) , 
n

where f (x) is a continuously diﬀerentiable function.  Let ∇f ( ¯x) denote the gradient of f (x) 
at  x  = ¯x. 

(a) Write  down  the  direction  ﬁnding  problem  for  the  pro jected  steepest  descent  algorithm 
at  x  = ¯x,  in  the  case  that  the matrix Q  is Q = I . 

(b)  Consider  the  following  Euclidean  pro jection  problem: 
2 ((cid:6) − ∇f ( ¯x) − d(cid:6))
2 
1 

P roj ( ¯x)  :  minimize 
d 

s.t. 

Ad   = 0. 

What  are  the  Karush-Kuhn-Tucker  conditions  for  P roj ( ¯x)  ?  Are  these  conditions  neces-
sary  and  suﬃcient?  Why  or  why  not? 

¯
(c)  Let  d  denote  the  pro jected  steepest  descent  direction  and  let  d˜ denote  the  solution  to 
P roj ( ¯x).  Show  that  these  two  directions  are  the  same  (up  to  a  scalar multiple). 

5 

Question   5:   (15   points)  

Consider  the  steepest  descent  algorithm  applied  to  the  problem: 

(P )  :  minimizex 

1 
2 x

T  Qx  + c x 
T

where Q  is  a  symmetric  and  positive  deﬁnite matrix. 

(a) Consider a linear transformation of the variables y  = M x   where M  is an invertible n × n 
matrix.  Rewrite (P ) as a minimization problem over the variables y .  Call this transformed 
problem  (PM ).  What  is  the marix  of  the  quadratic  ob jective  function  of  (PM ) ? 

(b)  In  running  the  steepest  descent  algorithm,  the  convergence  rate  is  sensitive  to  the 
eigenvalue  structure  of  the  matrix  Q.  Suppose  that  you  know  this  eigenvalue  structure, 
that  is,  you  know  an  orthonormal matrix R  and  a  diagonal matrix D  for  which 

Q  = RDRT  . 

Devise  a matrix M  based  on R  and D  for which  the  transformed  problem  (PM )  has  a  real 
“nice”  eigenvalue  structure,  and  for  which  the  steepest  descent  algorithm  will  converge  in 
just  one  step. 

6


Question   6:   (15   points)  
Let  X  be  an  open  set  in  (cid:1)n  .  Suppose  that  that  h(x)  is  a  nonnegative  convex  function  for 
all  x  ∈ X , and  that  g(x)  is  strictly  positive  concave  function  for  all  x  ∈ X .  Show  that  the 
function: 

f (x) = 

h(x)
g(x) 

is  a  quasiconvex  function  on X . 

HINT:  Look  at  the  level  sets  of  the  function  f (x). 

7 

