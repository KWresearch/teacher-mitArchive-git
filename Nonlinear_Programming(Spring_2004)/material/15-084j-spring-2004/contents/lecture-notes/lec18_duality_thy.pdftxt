Duality Theory  of Constrained Optimization 

Robert M.  Freund 

March,  2004 

2004 Massachusetts Institute of Technology.

1 

2 

1 Overview 

•	 The  Practical  Importance  of  Duality 
•	 Deﬁnition  of  the  Dual  Problem 
•	 Steps  in  the  Construction  of  the  Dual  Problem 
•	 Examples  of  Dual  Constructions 
•	 The  Column  Geometry  of  the  Primal  and  Dual  Problems 
•	 The  Dual  is  a  Concave Maximization  Problem 
•	 Weak  Duality 
•	 Saddlepoint  Optimality  Criteria 
•	 Strong  Duality  for  Convex  Problems 
•	 Duality  Strategies 
•	 Illustration  of  Lagrange  Duality  in  Discrete  Optimization 
•	 Conic  Duality 

2  The  Practical  Importance  of  Duality 

Duality arises in nonlinear (and linear) optimization models in a wide variety 
of  settings.  Some  immediate  examples  of  duality  are  in: 

•	 Models  of  electrical  networks.  The current ﬂows are “primal vari-
ables” and the voltage diﬀerences are the “dual variables” that arise in 
consideration of optimization  (and equilibrium)  in electrical networks. 
•	 Models  of  economic  markets.   In  these models,  the  “primal”  vari-
ables  are  production  levels  and  consumption  levels,  and  the  “dual” 
variables  are  prices  of  goods  and  services. 

3 

•	 Structural  design.  In  these  models,  the  tensions  on  the  beams  are 
“primal”  variables,  and  the  nodal  displacements  are  the  “dual”  vari-
ables. 

Nonlinear (and linear) duality is very useful.  For example, dual problems 
and  their  solutions  are  used  in  connection  with: 

•	 Identifying   near-optimal  solutions.  A  good  dual  solution  can  be 
used  to  bound  the  values  of  primal  solutions,  and  so  can  be  used  to 
actually  identify  when  a  primal  solution  is  near-optimal. 
•	 Proving  optimality.  Using  a  strong  duality  theorem,  one  can  prove 
optimality  of  a  primal  solution  by  constructing  a  dual  solution  with 
the  same  ob jective  function  value. 
•	 Sensitivity analysis   of the  primal   problem.  The dual variable on 
a  constraint  represents  the  incremental  change  in  the optimal  solution 
value  per  unit  increase  in  the  RHS  of  the  constraint. 
•	 Karush-Kuhn-Tucker  (KKT)  conditions.  The  optimal  solution 
to  the  dual  problem  is  a  vector  of  KKT multipliers. 
•	 Convergence  of  improvement  algorithms.  The  dual  problem  is 
often  used  in  the  convergence  analysis  of  algorithms. 
•	 Good  Structure.   Quite  often,  the  dual  problem  has  some  good 
mathematical,  geometric,  or  computational  structure  that  can  ex-
ploited  in  computing  solutions  to  both  the  primal  and  the  dual  prob-
lem. 
•	 Other  uses,   too  .  .  .  .  

3  The  Dual  Problem 
3.1  Warning:  Conventions  involving  ±∞ 

4 

Suppose  that  we  have  a  problem: 
∗
(P) :  z  = maximumx  f (x) 
x ∈ S . 

We  could  deﬁne  the  function: 

s.t. 
(cid:1) 
f (x) if  x ∈ S 
h(x) :=  −∞  if  x /∈ S . 
Then  we  can  rewrite  our  problem  as: 
∗
(P) :  z  = maximumx  h(x) 
x ∈ IRn  . 
s.t. 
Conversely,  suppose  that we have a  function k(·)  that  takes on  the value 
−∞  outside  of  a  certain  region  S ,  but  that  k(·)  is  ﬁnite  for  all  x ∈ S .  Then 
the  problem: 
∗
(P) :  z  = maximumx  k(x) 
x ∈ IRn 

s.t. 

is  equivalent  to: 

∗
(P) :  z  = maximumx  k(x) 
x ∈ S . 
s.t. 
Similar logic applies to minimization problems over domains where the func-
tion  values might  take  on  the  value  +∞. 

3.2  Deﬁning  the  Dual  Problem 

Recall  the  basic  constrained  optimization  model: 

5 

OP  :  minimumx 

f (x) 

s.t. 

≤  0, 
= ≥ 

≤  0, 

g1 (x) 
· · 
. . . 

gm (x) 
x ∈ X, 

In this model, we have f (x) : IRn  (cid:6)
→ IR and gi (x) : IRn  (cid:6)
→ IR, i = 1, . . . , m. 
Of  course,  we  can  always  convert  the  constraints  to  be  “≤”,  and  so  for 
now  we  will  presume  that  our  problem  is  of  the  form: 

∗
OP :  z  = minimumx 

f (x) 

s.t. 

g1 (x)  ≤  0, 

. . . 
gm (x)  ≤  0, 
x ∈ X, 

Here  X  could  be  any  set,  such  as: 
•  X  = IRn 

6 

•  X  = {x  |  x ≥ 0} 
•  X  = {x  |  gi (x) ≤ 0, i = m + 1, . . . , m + k} 
(cid:2) 
(cid:3) 
•  X  =  x  |  x ∈ Z n 
+ 
•  X  = {x  |  Ax ≤ b} 
∗
Let  z  denote  the  optimal  ob jective  value  of  OP.


For  a  nonnegative  vector  u,  form  the  Lagrangian  function:

(cid:4) 
m 
T
L(x, u) := f (x) + u g(x) = f (x) + 
uigi (x) 
i=1 

by  taking  the  constraints out  of  the body of  the model,  and placing  them  in 
the  ob jective  function  with  costs/prices/multipliers  ui  for  i = 1, . . . , m. 

We  then  solve  the  presumably  easier  problem: 

∗
L (u) 

:=  minimumx  L(x, u) = minimumx  f (x) + uT g(x) 
x ∈ X 
x ∈ X 

s.t. 

s.t. 

∗
The  function  L (u)  is  called  the  dual  function. 
∗
We  presume  that  computing  L (u) is an easy task.


The  dual  problem  is  then  deﬁned  to  be:


∗
∗
D :  v  = maximumu  L (u) 
u ≥ 0 

s.t. 

4  Steps  in  the  Construction  of  the  Dual  Problem 

7 

We  start  with  the  primal  problem: 

∗
OP :  z  = minimumx 

f (x) 

s.t. 

gi (x)  ≤  0,
x ∈ X, 

i = 1, . . . , m, 

Constructing  the  dual  involves  a  three-step  process: 

•  Step  1.  Create  the  Lagrangian 

T
L(x, u) := f (x) + u g(x)  . 
•  Step  2.  Create  the  dual  function: 
∗
L (u)  :=  minimumx  f (x) + uT g(x) 
x ∈ X 

s.t. 

•  Step  3.  Create  the  dual  problem: 
∗
∗
D :  v  = maximumu  L (u) 
u ≥ 0 

s.t. 

5	 Examples  of  Dual  Constructions  of  Optimiza-
tion  Problems 

8 

5.1  The  Dual  of  a  Linear  Problem 

Consider  the  linear  optimization  problem: 

LP :  minimumx 

s.t. 

T
c x 
Ax ≥ b 

What  is  the  dual  of  this  problem? 

(cid:1) 
L(x, u) = c x + u T (b − Ax) = u T b + (c − AT u)T x. 
T
if  AT u  (cid:8)= c 
−∞, 
∗	
L  (u) =  inf  L(x, u) = 
x∈IR n 
uT b, 
if  AT u = c
The  dual  problem  (D)  is: 
(u) = max u T b  s.t.  AT u = c,  u ≥ 0. 
∗
(D)  max L 
u≥0 

5.2  The  Dual  of  a  Binary  Integer  Problem 

Consider  the  binary  integer  problem: 

IP : 

minimumx 

s.t. 
xj  ∈ {0, 1}, j  = 1, . . . , n  . 

T
c x 
Ax ≥ b 

What  is  the  dual  of  this  problem? 

9 

5.3  The  Dual  of  a  Log-Barrier  Problem 

Consider  the  following  logarithmic  barrier  problem: 

(cid:5) 
BP :  minimumx1 ,x2 ,x3  5x1  + 7x2  − 4x3  − 
3 
ln(xj ) 
j=1 

s.t.	

x1  + 3x2  + 12x3  = 37 

x1  > 0, x2  > 0, x3  > 0  . 

What  is  the  dual  of  this  problem? 

5.4  The  Dual  of  a  Quadratic  Problem 

Consider  the  quadratic  optimization  problem: 

QP  :  minimumx 

s.t.	

1 
T
2 xT Qx + c x 
Ax ≥ b 

where  Q  is  SPSD  (symmetric  and  positive  semi-deﬁnite). 

What  is  the  dual  of  this  problem? 

L(x, u) = 

x T Qx + c T x + u T (b − Ax) = u T b + (c − AT u)T x +  x  Qx.
1  T
1 
2	
2 
∗
L  (u) =  inf  L(x, u). 
x∈IR n 

10 

Assuming  that  Q  is  positive  deﬁnite,  we  solve:  Q ˜x  =  −(c − AT u),  i.e., 
˜x = −Q
−1 (c − AT u) and 
L  (u) = L( ˜x, u) = − 
1
∗
2
The  dual  problem  (D)  is: 
(u) = max − 
1
∗
(D)  max L 
u≥0 
u≥0 
2

(c − AT u)T Q
−1 (c − AT u) + u T b. 

(c − AT u)T Q
−1 (c − AT u) + u T b. 

5.5	 Remarks  on  Problems  with  Diﬀerent  Formats  of  Con-
straints 

Suppose  that  our  problem  has  some  inequality  and  equality  constraints. 
Then  just  as  in  the  case  of  linear  optimization,  we  assign  nonnegative  dual 
variables  ui  to  constraints  of  the  form  gi (x) ≤ 0,  unrestricted  dual  variables 
ui  to  equality  constraints  gi (x)  =  0,  and  non-positive  dual  variables  ui  to 
constraints  of  the  form  gi (x) ≥ 0.  For  example,  suppose  our  problem  is: 

OP  :	 minimumx 

f (x) 

s.t. 

gi (x)  ≤  0,
gi (x)  ≥  0,

gi (x)  = 0,

i ∈ L 
i ∈ G 
i ∈ E 

x ∈ X, 

Then  we  form  the  Lagrangian: 

(cid:4) 
(cid:4) 
(cid:4) 
T
uigi (x) 
uigi (x) + 
uigi (x) + 
L(x, u) := f (x) + u g(x) = f (x) + 
i∈E 
i∈G
i∈L

11 

∗
and  construct  the  dual  function  L (u): 

∗
L (u) :=  minimumx  f (x) + uT g(x) 
x ∈ X 

s.t. 

The  dual  problem  is  then  deﬁned  to  be: 

D :  maximumu 

∗
L (u) 

s.t. 

ui  ≥ 0,
ui  ≤ 0,

> 
ui  <,

i ∈ L 
i ∈ G 
i ∈ E 

For  simplicity,  we  presume  that  the  constraints  of  OP  are  of  the  form 
gi (x) ≤ 0.  This is only for ease of notation, as the results we develop pertain 
to  the  general  case  just  described. 

6	 The  Column  Geometry  of  the  Primal  and  Dual 
Problems 

Let  us  consider  the  primal  problem  from  a  “resource-cost”  point  of  view. 
For  each  x ∈ X ,  we  have  an  array  of  resources  and  costs  associated  with  x, 
namely: 

12 

(cid:6)  (cid:7) 
s 
z 

⎞ ⎛ 
⎞ 
⎛ 
⎟ ⎜  g2 (x) ⎟ 
⎜  s2 
⎜ ⎟ ⎜ 
⎟ 
g1 (x) 
s1 
⎜  .  ⎟ ⎜ 
.  ⎟ 
= ⎜  ..  ⎟ = ⎜ 
.  ⎟ = 
.  ⎟ 
⎜  ⎟ ⎜ 
⎝  ⎠ ⎝ gm (x) ⎠
sm 
f (x) 
z

(cid:6) 
(cid:7) 
g(x)
f (x) 

. 

We  can  think  of  each  of  these  arrays  as  an  array  of  resources  and  cost  in 
(cid:14) 
(cid:15) 
IRm+1 .  Deﬁne  the  set  I : 
I  :=  (s, z ) ∈ IRm+1  |  there  exists  x ∈ X  for  which  s ≥ g(x) and  z ≥ f (x) 

. 

This  region  is  illustrated  in  Figure  1. 

z 

I 

-u 

H(u,α) 

s 

Figure  1:  The  set  I . 

Proposition  6.1  If  X  is  a  convex  set,  and  f (·), g1 (·), . . . , gm (·)  are  convex 
functions  on  X ,  then  I  is  a  convex  set. 

13 

Let  Hu,α  = {(s, z ) ∈ IRm+1  : u s + z = α}.

T
We  call  Hu,α  is  a  lower  support  of  I  if  uT s + z ≥ α  for  all  (s, z ) ∈ I .

Let  L = {(s, z ) ∈ IRm+1  : s = 0}.  Note  that  Hu,α  ∩ L = {(0, α)}.

The  problem  of  determining  a  hyperplane  Hu,α  that  is  a  lower  support

of  I ,  and  whose  intersection  with  L  is  the  highest  is: 

14 

maximumu,α 

α 

s.t. 

Hu,α  is  a  lower  support  of  I 

=  maximumu,α 

s.t. 

α 
Tu s + z ≥ α 

for  all  (s, z ) ∈ I 

= maximumu≥0,α 

s.t. 

α 
Tu s + z ≥ α 

for  all  (s, z ) ∈ I 

= maximumu≥0,α 

s.t. 

α 
uT g(x) + f (x) ≥ α 

for  all  x ∈ X 

= maximumu≥0,α 

s.t. 

α 
L(x, u) ≥ α 

for  all  x ∈ X 

= maximumu≥0,α 

s.t. 

α 
inf x∈X  L(x, u) ≥ α 

= maximumu≥0,α 

s.t. 

α 
L (u) ≥ α 
∗

=  maximumu 

s.t. 

∗
L (u) 
u ≥ 0  . 

15 

This  last  expression  is  exactly  the  dual  problem.  Therefore: 

The dual problem corresponds to ﬁnding a hyperplane Hu,α  that is a lower 
support of I , and whose  intersection with L  is  the highest.  This highest value 
∗
is  exactly  the  value  of  the  dual  problem,  namely  v  . 

7  The  Dual  is  a  Concave  Maximization  Problem 

We  start  with  the  primal  problem: 

OP  :  minimumx 

f (x) 

s.t. 

gi (x)  ≤  0,
x ∈ X, 

i = 1, . . . , m 

We  create  the  Lagrangian: 

T
L(x, u) := f (x) + u g(x) 

and  the  dual  function: 

∗
L (u) :=  minimumx  f (x) + uT g(x) 
x ∈ X 

s.t. 

The  dual  problem  then  is: 

16 

∗
D :  maximumu  L (u) 
u ≥ 0 

s.t. 

∗
Theorem  7.1  The  dual  function  L (u)  is  a  concave  function. 

Proof:   Let  u1  ≥  0 and  u2  ≥  0  be  two  values  of  the  dual  variables,  and  let 
u = λu1  + (1 − λ)u2 ,  where  λ ∈ [0, 1].  Then 
∗
L (u) = minx∈X  f (x) + uT g(x) 
(cid:17) 
(cid:16) 
(cid:17) 
(cid:16) 
= minx∈X  λ f (x) + u1 g(x)  + (1 − λ)  f (x) + u2 g(x) 
T
T
(cid:16) 
(cid:16) 
(cid:17) 
(cid:17) 
≥  λ  minx∈X  f (x) + u1 g(x)  + (1 − λ)  minx∈X (f (x) + u2 g(x) 
T
T
=  λL (u1 ) + (1 − λ)L (u2 )  . 
∗
∗

∗
Therefore  we  see  that  L (u)  is  a  concave  function. 

8  Weak  Duality 

∗
∗  and  v  be  the  optimal  values  of  the  primal  and  the  dual  problems: 
Let  z 

17 

∗
OP  :  z  = minimumx 

s.t.	

f (x) 
gi (x)  ≤  0,
x ∈ X, 

i = 1, . . . , m 

D : 

∗	
∗
v  = maximumu  L (u) 
u ≥ 0 

s.t.	

Theorem  8.1   Weak  Duality  Theorem:  If  ¯	
u  is
x  is  feasible  for  OP  and  ¯
feasible  for  D,  then 
x) ≥ L 
∗
f ( ¯
u) 
( ¯
z  ≥ v . 
∗ 
∗

In  particular, 

u)  . 
( ¯

u  is  feasible  for  D,  then 
Proof:   If  ¯
x  is  feasible  for  OP  and  ¯
x) ≥ min f (x) + ¯ g(x) = L 
x) ≥ f ( ¯
∗
T 
T	
x) + ¯ g( ¯	
f ( ¯
u
u
x∈X

Therefore  z  ≥ v  . 
∗

∗
Corollary  8.1  If  x  is  feasible  for  OP  and  u  ≥  0  is  feasible  for  D,  and 
¯
¯
∗
x  and  ¯
u),  then  ¯
u  are  optimal  solutions  of OP  and D,  respectively. 
x) = L ( ¯
f ( ¯
Corollary   8.2   If  z  = −∞,  then  D  has  no  feasible  solution. 
∗
Corollary   8.3  If  v  = +∞,  then  OP  has  no  feasible  solution. 
∗

Unlike  in  linear  optimization,  strong  duality  theorem  cannot  necessarily 
be  established  for  general  nonlinear  optimization  problems. 

18 

9  Saddlepoint  Optimality  Criteria 

x  ∈  X , 
The  pair  ( ¯ u)  is  called  a  sadd lepoint  of  the  Lagrangian  L(x, u) if  ¯
x, ¯
¯u ≥ 0,  and 

u)  for  all  x ∈ X  and  u ≥ 0  .
x, u) ≤ L( ¯ u) ≤ L(x, ¯
L( ¯
x, ¯

Theorem  9.1  A pair  ( ¯ u)  is  a  sadd lepoint  of  the  Lagrangian  if  and  only 
x, ¯
if 

∗
1.  L( ¯ u) = L ( ¯
u)
x, ¯
2.  g( ¯x) ≤ 0, and 
3.  uT g( ¯
x) = 0.
¯

Moreover,  ( ¯ u)  is  a  sadd lepoint  if  and  only  if  x  and  u  are,  respectively, 
x, ¯
¯
¯
∗
optimal  solutions  of  OP  and  D  with  no  duality  gap,  that  is,  z  =  f ( ¯x) = 
∗
∗
L ( ¯u) = v  . 

Proof:   Suppose  that  ( ¯ u)  is  a  saddlepoint.  By  deﬁnition,  condition  (1.) 
x, ¯
must  be  true.  Also,  for  any  u ≥ 0, 
x) ≥ f ( ¯
T
T
x).
x) + u g( ¯
x) + ¯ g( ¯
f ( ¯
u
This  implies  that  g( ¯x)  ≤  0,  since  otherwise  the  above  inequality  can  be 
violated  by  picking  u  ≥  0  appropriately.  This  establishes  (2.).  Taking 
x) ≥ 0;  hence,  ¯T g( ¯
uT g( ¯
x) = 0,  establishing  (3.). 
u = 0,  we  get  ¯
u
Also,  note  that  from  the  above  observations  that  x  and  u  are  feasible 
¯
¯
∗
x) =  L( ¯ u) =  L ( ¯
u),  which  implies 
for  OP  and  D,  respectively,  and  f ( ¯
x, ¯
that  they  are  optimal  solutions  of  their  respective problems,  and  there  is no 
duality  gap. 
Suppose  now  that  x  and  u  ≥  0  satisfy  conditions  (1.)–(3.).  Then 
¯
¯
L( ¯ u) ≤ L(x, ¯
u)  for  all  x ∈ X  by  (1.).  Furthermore, 
x, ¯
x, u)  ∀u ≥ 0.
x) ≥ L( ¯
L( ¯ u) = f ( ¯
x, ¯

19 

Thus  ( ¯ u)  is  a  saddlepoint. 
x, ¯

Finally,  suppose  x  and  u  are  optimal  solutions  of  OP  and  D  with  no 
¯
¯
duality  gap.  Primal  and  dual  feasibility  implies  that 
x) + ¯T  x) ≤ f ( ¯
u) ≤ f ( ¯
∗
( ¯
u g( ¯
x). 
L 
Since there is no duality gap, equality holds throughout, implying conditions 
(1.)–(3.),  and  hence  ( ¯ u)  is  a  saddlepoint. 
x, ¯

Remark   1   Note  that  up  until  this  point,  we  have  made  no  assumptions 
about  the  functions  f (x), g1 (x), . . . , gm (x)  or  the  structure  of  the  set  X . 

Suppose  that  our  constrained  optimization problem OP  is  a  convex pro-
gram, namely f (x), g1 (x), . . . , gm (x) are convex functions, and that X  = IRn : 

∗
OP :  z  = minimumx 

f (x) 

s.t. 

≤  0, 

g(x) 
x ∈ IRn  . 

x  together  with  ¯
Suppose  that  ¯
u  satisfy  the  KKT  conditions: 
x) + ¯T ∇g( ¯
(i)  ∇f ( ¯
x) = 0
u
g( ¯x) ≤ 0 
u ≥ 0
¯

(iii) 

(ii) 

¯T g( ¯
x) = 0  .
(iv) 
u
Then  because  f (x), g1 (x), . . . , gm (x)  are  convex  functions,  condition  (i) is 
∗
equivalent  to  “L( ¯ u) = minx L(x, ¯
x, ¯
u)”.  Therefore  the  KKT  condi-
u) = L ( ¯
tions  imply  conditions  (1.)–(3.)  of  Theorem  9.1,  and  so  we  have: 

20 

Theorem  9.2  Suppose X  = IRn , and  f (x), g1 (x), . . . , gm (x)  are  convex  dif-
ferentiable  functions,  and  x  together  with  u  satisfy  the  KKT  conditions. 
¯
¯
Then  ¯
u  are  optimal  solutions  of  OP  and  D,  with  no  duality  gap. 
x  and	 ¯

10	 Strong Duality  for Convex Optimization Prob-
lems 

We  now  assume  throughout  this  section  that  X  is  an  open  convex  set  and 
f (x), g1 (x), . . . , gm (x)  are  convex  functions.  In  this  section  we  will  explore 
and state suﬃcient conditions that will guarantee that the dual problem will 
have  an  optimal  solution  with  no  duality  gap. 

10.1	 The Perturbation Function and the Strong Duality The-
orem 

We begin with the concept of perturbing the RHS vector of the optimization 
problem  OP.  Our  standard  optimization  problem  OP  is: 
∗
OP  :	 z  = minimumx 

s.t. 

i = 1, . . . , m 

f (x) 
gi (x)  ≤  0,
x ∈ X . 

For a given vector y = (y1 , . . . , ym ), we perturb the RHS and obtain the new 
problem  OPy : 

∗
OPy  :	 z  (y) = minimumx 

s.t. 

f (x) 
gi (x)  ≤  yi ,
x ∈ X . 

i = 1, . . . , m 

∗
We  call  OPy  the  perturbed  primal  problem  and  z  (y)  the  perturbation  func-
∗
∗
tion.  Note  that  our  original  problem  OP  is  just  OP0  and  that  z  = z  (0). 

21 

Next  deﬁne 
Y  := {y ∈ IRm  | there  exists  x ∈ X  for  which  g(x) ≤ y} . 

Lemma   10.1   Y  is  a  convex  set,  and  z (y)  is  a  convex  function  whose  do-
main  is  Y . 

Proof:   Let  y , y2  ∈ Y  and  let  y3  =  λy1  + (1 − λ)y2  where  λ  ∈ [0, 1].  Let 
1
x , x2  ∈  X  satisfy  y1  ≥  g(x1 ),  y2  ≥  g(x2 ) and  let  x3  =  λx1  + (1 − λ)x . 
1
2
Then  g(x3 ) ≤ y3 ,  whereby  y3  ∈ Y ,  proving  that  Y  is  convex. 
To  show  that  z (y)  is  a  convex  function,  let  y , y2 , y3  be  as  given  above. 
1
The  aim  is  to  show  that  z (y3 )  ≤ λz (y1 ) + (1 − λ)z (y2 ).  First  assume  that 
z (y1 ) and  z (y2 )  are  ﬁnite.  For  any   >  0,  there  exist  x1  and  x2  for  which 
x1 , x2  ∈ X , g(x1 ) ≤ y1 , g(x2 ) ≤ y2 , and |z (y1 )− f (x1 )| ≤ , |z (y2 )− f (x2 )| ≤
. Now  let  x3  =  λx1  + (1 − λ)x .  Then  g(x3 )  ≤  λg(x1 ) + (1 − λ)g(x2 )  ≤ 
2
λy1  + (1 − λ)y2  = y3 , and 
z (y 3 ) ≤ f (x 3 ) ≤ λf (x 1 ) + (1 − λ)f (x 2 ) ≤ λ(z (y 1 ) + ) + (1 − λ)(z (y 2 ) + ) 
= λz (y 1 ) + (1 − λ)z (y 2 ) +  . 
As  this  is  true  for  any   >  0,  z (y3 )  ≤  λz (y1 ) + (1 − λ)z (y2 ),  and  so  z (y) 
is  convex.  If  z (y1 )  and/or  z (y2 )  is  not  ﬁnite,  the  proof  goes  through  with 
appropriate  modiﬁcations. 

The  perturbation  function  z (y)  is  illustrated  in  Figure  2. 

1.  z (y)  is  continuous  on  intY 
Corollary  10.1 
� (y ; d)  exists  wherever  z (y)  is  ﬁnite 
2.  z 
3.  for  every  y¯ ∈ intY  there  exists  a  subgradient  of  z (·)  at  y = ¯y 
4.  the  subgradient  of  z (y)  at  y  = ¯y  is  unique  if  and  only  if  z (·)  is  diﬀer-
entiable  at  y = ¯y . 

22 

z 

0 

z(y) 

-u 

H(u,α) 

y 

Figure  2:  The  perturbation  function  z (y). 

Theorem  10.1  (Strong  Duality  Theorem)  Suppose  that  X  is  an  open 
convex  set  and  f (x), g1 (x), . . . , gm (x)  are  convex  functions.  Under  the  hy-
pothesis  that  ∂ z (0)  (cid:8)= ∅,  then: 
1.  D  attains  its  otimum  at  some  ¯u ≥ 0. 
2.  u  is  an  optimal  solution  of  D  if  and  only  if  (− ¯
u) ∈ ∂ z (0). 
¯
∗
∗
3.  z  = v 

4.  Let  ¯u be any dual optimal solution.  The set of primal optimal solutions 
(if  any)  is  characterized  as  the  intersection  S 1  ∩ S 2 ,  where: 
S 1  =  {x ∈ X  |  g(x) ≤ 0, ¯u g(x) = 0}
T
S 2  =  {x ∈ X  |  L(x, ¯
u)}  .
∗
u) = L ( ¯
Proof:   Since  ∂ z (0)  (cid:8)
= ∅, let  − ¯
u ∈ ∂ z (0).  Then 
z (y) ≥ z (0) − ¯u T (y − 0). 

Noting  that  z (y)  is  non-increasing  in  y , let  e denote  the  ith  unit  vector, 
i
and  observe: 

23 

z (0) ≥ z (e i ) ≥ z (0) − ¯
−T (e i  − 0) = z (0) − ¯
u 
ui , 
which  shows  that  ¯ ≥ 0.  Thus  ¯
u is  feasible  for D . 
u
Next,  note  that  for  any  x ∈ X , 
inf ˜
z (g(x)) = 
x 
s.t.

≤ f (x) 

f ( ˜
x) 
g( ˜x) ≤ g(x) 
˜ ∈ Xx

which  implies  that 
f (x) ≥ z (g(x)) ≥ z (0) − ¯u T (g(x) − 0), 

that  is, 

z (0) ≤ f (x) + ¯u g(x). 
T 

Thus 

u)  .
( ¯

z = z (0) ≤  inf {f (x) + ¯ g(x)} = L 
∗ 
∗
T u
x∈X
By  weak  duality,  however,  z ≥  L ( ¯
∗
∗
∗
∗
u) and  so  ¯ is  optimal 
u),  so  z =  L ( ¯
u
for  D .  This  shows  (i)  and  (iii)  and  (⇐)  of  (ii). 
We  now  show  (⇒)  of  (ii).  Suppose  ¯ is  optimal  for  D .  Then  from  (iii) 
u
we  have 
u g(x)} = L 
{f
∗
∗  = z (0)  . 
T
( ¯
u) = z 
(x) + ¯
inf 
x∈X
Thus,  f (x) + ¯T g(x) ≥ z (0)  for  every  x ∈ X . 
u
For  any  given  ﬁxed  y , if  x ∈ X and  g(x) ≤ y ,  then 
f (x) + ¯ y ≥ f (x) + ¯ g(x) ≥ z (0). 
T 
T
u
u

Thus  for  ﬁxed  y , 

uT y + z (y) = 
¯

inf x  f (x) + ¯T y ≥ z (0)  , 
u
g(x) ≤ y 
s.t.
x ∈ X 

24 

that  is, 

z (y) ≥ z (0) − ¯u T (y − 0), 
and  so  ¯u ∈ ∂ z (0).  This  completes  (ii). 
We  now  show  (iv).  Suppose  x  ∈  S 1  ∩  S 2 .  Then  u  ≥  0,  x  satisﬁes
¯
¯
¯	
∗
u) =  L( ¯ u),  and  ¯T g( ¯
L ( ¯
x, ¯
x)  =  0,  whereby  ( ¯ u)  satisfy  the  conditions  of 
x, ¯
u
Theorem 9.1 and hence  ¯x  is optimal  for  the primal problem OP. Conversely, 
∗
∗
suppose  ¯x  is  optimal  for  the  primal  problem.  Then  z  =  v  ,  and  so  again 
x)  ≤  0, L ( ¯
∗
uT g( ¯
invoking  Theorem  9.1  we  have  g( ¯
u) =  L( ¯ u),  and  ¯
x, ¯
x) = 0. 
Therefore  ¯x ∈ S1  ∩ S2 . 

10.2  Stability 

The  only  hypothesis  of  the  Strong  Duality  Theorem  is  that  z (y)  has  a  sub-
gradient  at  y  =  0,  or  equivalently,  ∂ z (0)  (cid:8)=  ∅.  We  call  an  optimization 
problem  OP  stable  if  ∂ z (0)  (cid:8)=  ∅.  An  equivalent  and  generally  more  useful 
characterization  of  stability  is  given  in  the  following: 
Lemma   10.2 	 Let  h(y) : Y  → IR ∪ {−∞, +∞}  be  a  convex  function.  If  h(y) 
y ,  then  ∂h( ¯ = ∅  if  and  only  if  there  exists  a  positive  scalar 
y)  (cid:8)
is  ﬁnite  at  y = ¯
M  for  which: 
h( ¯y) − h(y)  ≤ M  for  al l  y ∈ Y , y  (cid:8)
(cid:16)y − y¯(cid:16) 
y)  (cid:8)
Proof:   First  suppose  that  ∂h( ¯ = ∅. Let  ¯
γ  ∈ ∂h( ¯
y).  Then 
h(y) ≥ h( ¯
γ T (y − y¯)  for  all  y ∈ Y , 
y) + ¯
and  so  h(y) > −∞  for  all  y ∈ Y . Let M  = (cid:16)γ¯(cid:16).  Then 
γ (cid:16) (cid:16)y¯ − y(cid:16)
(cid:16)¯
y − y) 
y) − h(y) 
γ T ( ¯
≤
≤ 
= (cid:16)¯γ (cid:16) = M . 
¯
h( ¯	
(cid:16)y − y¯(cid:16)
(cid:16)y − y¯(cid:16)
(cid:16)y − y¯(cid:16) 
To prove the reverse implication, we suppose that there exists a scalar M > 0 
satisfying  the  stated  inequality.  Then  h(y) > −∞  for  all  y  ∈ Y .  Deﬁne  the 
sets 
S  = {(y , z ) ∈ Rm+1  |  y ∈ Y  and  h(y) + z ≤ h( ¯y)} 

y .= ¯

25 

and 

T  = {(y , z ) ∈ R
| M (cid:16)y − y¯(cid:16) < z} . 
m+1
It  is  easy  to  see  that  S  and  T  are  convex  sets,  and  that  if  (y , z )  ∈ S ,  then 
∈ T . As S ∩ T  = ∅,  there exists a 
M (cid:16)y − y¯(cid:16) ≥ h( ¯
y) − h(y) ≥ z ,  so  that  (y , z )  /
γ , ρ)  (cid:8)
hyperplane  H  separating  S  and  T .  That  is,  there  exists  (¯
= (0, 0)  and 
α  such  that 
(y , z ) ∈ S ⇒ ¯γ T y + ρz ≤ α 

and 

(y , z ) ∈ T  ⇒ ¯γ T y + ρz ≥ α . 
In  particular  ( ¯y , 0) ∈ S  which  implies  that 
¯γ T y¯ ≤ α . 
y , θ) ∈ T  for any θ > 0 which  implies  that  ¯
γ T y¯ + ρθ > α which  implies 
Also  ( ¯
γ T y¯ ≥ α, and  so  ¯
γ T y¯ = α.  This  also  implies  that  ρ ≥ 0. 
that  ¯
If  ρ >  0  we  can  assume  without  loss  of  generality  that  ρ  = 1.  Now  for 
any  y ∈ Y , let  z = h( ¯y) − h(y).  Then  (y , z ) ∈ S  and  so 
y) − h(y) ≤ ¯ y , 
γ¯T y + h( ¯
γ T ¯

and  so 

h(y) ≥ h( ¯
γ T (y − y¯),  so  ¯
γ  ∈ ∂h( ¯
y) + ¯
y)  , 
which  proves  the  result  in  this  case. 

It  remains  to  prove  that  ρ = 0  is  not  possible.  To  see  this,  assume  that 
ρ  =  0.  For  any  y  ∈  Y , let  z  =  M (cid:16)y − y¯(cid:16) + 1.  Then  (y , z )  ∈  T  and  so 
γ T y  ≥ α  = ¯
γ T y¯.  As  this  is  true  for  any  y  ∈ Y ,  it  follows  that 
γ¯T y + ρz  = ¯
γ¯ = 0  and  so  (¯γ , ρ) = (0, 0),  which  is  a  contradiction. 

Therefore,  we  can  equivalently  say  that  an  optimization  problem  OP 
∗
is  stable  if  z  =  z (0)  is  ﬁnite  and  there  is  a  scalar  M >  0  for  which  the 
perturbation  function  z (y)  satisﬁes: 
z (0) − z (y)  ≤ M  for  all  y ∈ Y , y  (cid:8)= 0  . 
(cid:16)y(cid:16) 
This  alternative  characterization  of  stability  says  that  OP  is  stable  if  the 
function z (y) does not decrease  inﬁnitely  steeply  in any direction away  from 
y = 0. 

26 

10.3  Slater  Points  and  Stability 

Now  consider  the  problem: 
∗
OPE :  z  = minimumx 

f (x) 

s.t. 

≤  0 
g(x) 
Ax − b  = 0 
x ∈ IRn  , 
where  we  assume  here  that  A  has  full  row  rank  and  f (x), g1 (x), . . . , gm (x) 
are  convex  functions  as  before.  A  point  x0  is  called  a  Slater  point  of OPE  if 
x0  satisﬁes: 

•  g(x0 ) < 0 and 
•  Ax0  = b  . 

We  now  state  and  prove  the  following  result  which  shows  that  the  exis-
tence  of  a  Slater  point  in  a  convex  problem  implies  stability,  which  in  turn 
implies  strong  duality. 

Lemma   10.3   Suppose  that  f (x), g1 (x), . . . , gm (x)  are  al l  convex  functions, 
∗
that A has  ful l  row  rank,  and problem OPE has a Slater point.  If z  is ﬁnite, 
then  problem  OPE  is  stable. 

Proof:   We  can  rewrite  OPE  as  OPE0  where  OPEy  is: 
∗
OPEy  :  z  (y) = minimumx 

s.t. 

where  X  = {x ∈ IRn  |  Ax = b}. 

f (x) 
g(x)  ≤  y 
x ∈ X , 

27 

We  are  concerned  with  ﬁnding  an M  such  that

z (0) − z (y)
 ≤ M . 
(cid:16)y(cid:16) 
Let  h() =  z (, . . . , ) =  z (y)  where  y  = (, . . . , ).  As  z (·)  is  convex,  so  is 
h().  There  exists  ¯ >  0  such  that  || ≤ ¯ implies  g(x0 ) <  (, . . . , ),  and  so 
x0  is  feasible  for  OPEy =OPE(,...,) ,  whereby 
h() = z (, . . . , ) ≤ f (x 0 ). 
)  ≥  2z  −
∗	 =  h(0)  ≤  1 h(¯
) +  1 h(−¯)  ≤  1 h(¯	
∗
) +  1 f (x0 ).  Thus,  h(¯
Also  z 
f (x0 )  >  −∞,  and  therefore  || ≤  ¯  implies  h()  ≥  h(¯)  >  −∞, so  h() is 
2 
2 
2	
2
convex and ﬁnite for all  satisfying || ≤ ¯.  Therefore, h() has a subgradient 
at   = 0,  i.e.,  there  is  a K  such  that 
h() ≥ h(0) + K ( − 0). 
Let M  =  |K |,  and  for  any  y  deﬁne  ˜y = maxi  |yi |. We  have 
h(0) − h( ˜y)  −K y˜ M y˜
z (0) − z (y) 
≤ M . 
≤ 
≤
≤
(cid:16)y(cid:16)
(cid:16)y(cid:16)
(cid:16)y(cid:16)
(cid:16)y(cid:16) 
Thus  OPE  is  stable. 

11  Duality  Strategies 

11.1	 Dualizing  “Bad”  Constraints 

Suppose  we  wish  to  solve: 

T
OP  :  minimumx  c x 
Ax  ≤ 
b 
N x  ≤  g . 

s.t.	

28 

Suppose  that  optimization  over  the  constraints  “N x  ≤  g”  is  easy,  but 
that the addition of the constraints “Ax ≤ b” makes the problem much more 
diﬃcult.  This  can happen,  for  example, when  the  constraints  “N x ≤ g” are 
network constraints,  and when “Ax ≤ b” are non-network  constraints  in  the 
model. 

Let


and  re-write  OP  as: 

X  = {x  |  N x ≤ g}


T
OP  :  minimumx  c x 
Ax  ≤ 
b 
x  ∈  X . 

s.t. 

The  Lagrangian  is: 
L(x, u) = c x + u T (Ax − b) = −u T b + (c T  + u T A)x , 
T

and  the  dual  function  is: 
L (u) :=  minimumx  −uT b + (cT  + uT A)x 
∗
x ∈ X , 

s.t. 

which  is 

L (u) :=  minimumx  −uT b + (cT  + uT A)x 
∗
N x ≤ g . 

s.t. 

∗
Notice  that  L (u)  is  easy  to  evaluate  for  any  value  of  u, and  so  we  can 
attempt  to  solve  OP  by  designing  an  algorithm  to  solve  the  dual  problem: 

29 

∗
D :  maximumu  L (u) 
u ≥ 0  . 

s.t. 

11.2  Dualizing  A  Large  Problem  into Many  Small  Problems 

Suppose  we  wish  to  solve: 

OP :  minimum 1
x ,x

2 

(c1 )T x1  +(c2 )T x
2

s.t. 

B 1 1 
x

+B 2x
2

A1 1x

A2 2x

≤  d 
≤  b1 
≤  b2 

Notice  here  that  if  it  were  not  for  the  constraints  “B 1x1  + B 2x2  ≤  d”, 
that  we  would  be  able  to  separate  the  problem  into  two  separate  problems. 
(cid:14) 
(cid:15) 
Let  us  dualize  on  these  constraints.  Let: 
X  = (x  , x 2 )  |  A1 x 1  ≤ b1 , A2 x 2  ≤ b2 
1
and  re-write  OP  as: 

OP :  minimumx1 ,x2 

(c1 )T x1  +(c2 )T x
2

s.t. 

B 1 1 
x

≤  d 

+B 2x
2
(x1 , x2 ) ∈ X 

30 

The  Lagrangian  is: 
L(x, u) = (c1 )T x1  + (c2 )T x2  + uT (B 1x1  + B 2x2  − d) 
=  −uT d + ((c1 )T  + uT B 1 )x1  + ((c2 )T  + uT B 2 )x , 
2
and  the  dual  function  is: 
L (u) =  minimum 1 ,x2  −uT d + ((c1 )T  + uT B 1 )x1  + ((c2 )T  + uT B 2 )x
∗
2
x
(x1 , x2 ) ∈ X 

s.t. 

which  can  be  re-written  as: 

∗
L (u) = 

−uT d 

+  minimumA1 x1≤b1 

((c1 )T  + uT B 1 )x
1

+  minimumA2 x2≤b2 

((c2 )T  + uT B 2 )x
2

∗
Notice  once  again  that  L (u)  is  easy  to  evaluate  for  any  value  of  u, and 
so  we  can  attempt  to  solve  OP  by  designing  an  algorithm  to  solve  the  dual 
problem: 

∗
D :  maximumu  L (u) 
u ≥ 0 

s.t. 

31 

12	

Illustration of Lagrange Duality in Discrete Op-
timization 

In  order  to  suggest  the  computational  power  of  duality  theory  and  to  illus-
trate  duality  constructs  in  discrete  optimization,  let  us  consider  the  simple 
constrained  shortest  path  problem  portrayed  in  Figure  3. 

1 

1 

1 

2 

1 

3 

1 

3 

2 

4 

1 

5 

1 

3 

6 

Figure  3:  A  constrained  shortest  path  problem. 

The  ob jective  in  this  problem  is  to  ﬁnd  the  shortest  (least  cost)  path 
from  node  1  to  node  6  sub ject  to  the  constraint  that  the  chosen  path  uses 
exactly  four  arcs.  In  an  applied  context  the  network might  contain millions 
of  nodes  and  arcs  and  billions  of  paths.  For  example,  in  one  application 
setting  that can be  solved using  the  ideas considered  in  this discussion,  each 
arc  would  have  both  a  travel  cost  and  travel  time  (which  for  our  example 
is  1  for  each  arc).  The  ob jective  is  to  ﬁnd  the  least  cost  path  between  a 
given  pair  of  nodes  from  all  those  paths  whose  travel  time  does  not  exceed 
a  prescribed  limit  (which  in  our  example  is  4  and  must  be met  exactly). 

Table  1  shows  that  only  three  paths,  namely  1-2-3-4-6,  1-2-3-5-6,  and 
1-3-5-4-6  between  nodes  1  and  6  contain  exactly  four  arcs.  Since  path  1-3-
5-4-6  has  the  least  cost  of  these  three  paths  (at  a  cost  of  5),  this  path  is  the 
optimal  solution  of  the  constrained  shortest  path  problem. 

32 

Path 
1-2-4-6 
1-3-4-6 
1-3-5-6 
1-2-3-4-6 
1-2-3-5-6 
1-3-5-4-6 
1-2-3-5-4-6 

Number  of  Arcs  Cost 
3 
3 
3 
5 
6 
3 
6 
4 
7 
4 
4 
5 
6 
5 

Table  1:  Paths  from  node  1  to  node  6. 

Now  suppose  that  we  have  available  an  eﬃcient  algorithm  for  solving 
(unconstrained) shortest path problems (indeed, such algorithms are readily 
available  in  practice),  and  that  we  wish  to  use  this  algorithm  to  solve  the 
given  problem. 

Let us ﬁrst formulate the constrained shortest path problem as an integer 
program: 

33 


C SP P  : 
∗  = minxij  x12  +x13  +x23  +x24  +3x34  +2x35  +x54  +x46  +3x56 
z 

s.t. 

x12  +x13  +x23  +x24  +x34  +x35  +x54  +x46  +x56  = 4 

x12  +x13 

x12 

−x23  −x24 

x13  +x23 

−x34  −x35 

= 1 

= 0 

= 0 

x24  +x34 

+x54  −x46 
x35  −x54 

= 0 
−x56  = 0 

x46  +x56  = 1 

xij  ∈ {0, 1} for  all  xij 

. 

In  this  formulation,  xij  is  a  binary  variable  indicating  whether  or  not 
arc  i − j  is  chosen  as  part  of  the  optimal  path.  The  ﬁrst  constraint  in  this 
formulation  speciﬁes  that  the  optimal  path  must  contain  exactly  four  arcs. 
The  remaining  constraints  are  the  familiar  constraints  describing  a  shortest 
path problem.  They  indicate that one unit of ﬂow  is available at node 1 and 
must  be  sent  to  node  6;  nodes  2,  3,  4,  and  5  act  as  intermediate  nodes  that 
neither  generate  nor  consume  ﬂow.  Since  the  decision  variables  xij  must 
be  integer,  any  feasible  solution  to  these  constraints  traces  out  a  path  from 
node  1  to  node  6.  The  ob jective  function  determines  the  cost  of  any  such 
path. 

Notice  that  if  we  eliminate  the  ﬁrst  constraint  from  this  problem,  then 
the  problem  becomes  an  unconstrained  shortest  path  problem  that  can  be 
solved  by  our  available  algorithm.  Suppose,  for  example,  that  we  dualize 

34 

the ﬁrst (the complicating) constraint by moving it to the ob jective function 
⎞ ⎠
⎛
multiplied by a Lagrange multiplier u.  The ob jective function then becomes: 
(cid:4) 
(cid:4) 
cij xij  + u ⎝4 − 
xij 
i,j 
i,j 
and  collecting  the  terms,  the  modiﬁed  problem  becomes: 

minimumxij 

∗
L (u) = minxij 

s.t. 

(1 − u)x12  + (1 − u)x13  + (1 − u)x23

+(1 − u)x24  + (3 − u)x34  + (2 − u)x35

+(1 − u)x54  + (1 − u)x46  + (3 − u)x56  + 4u


x12  +x13 

x12 

−x23  −x24 

x13  +x23 

−x34  −x35 

= 1 

= 0 

= 0 

x24  +x34 

+x54  −x46 
x35  −x54 

= 0 
−x56  = 0 

x46  +x56  = 1 

xij  ∈ {0, 1} for  all  xij 

. 

∗
Let  L (u)  denote  the  optimal  ob jective  function  value  of  this  problem, 
for  any  given  multiplier  u. 

Notice  that  for  a  ﬁxed  value  of  u, 4u  is  a  constant  and  the  problem 
becomes  a  shortest  path  problem  with  modiﬁed  arc  costs  given  by 
= cij  − u .

� 
cij 

35 

Note  that  for  a  ﬁxed  value  of  u,  this  problem  can  be  solved  by  our 
available  algorithm  for  the  shortest  path  problem.  Also  notice  that  for  any 
∗
∗
ﬁxed value of u, L (u)  is a  lower bound on  the optimal ob jective value z  to 
the  constrained  shortest  path  problem  deﬁned  by  the  original  formulation. 
To  obtain  the  best  lower  bounds,  we  need  to  solve  the  Lagrangian  dual 
problem: 

∗
∗
D :  v  = maximumu  L (u) 

s.t. 

< 
u > 0 

To  relate  this  problem  to  the  earlier material  on  duality,  let  the  decision 
set  X  be  given  by  the  set  of  feasible  paths,  namely  the  solutions  of: 

x12  +x13 

x12 

−x23  −x24 

x13  +x23 

−x34  −x35 

= 1 

= 0 

= 0 

x24  +x34 

+x54  −x46 
x35  −x54 

= 0 
−x56  = 0 

x46  +x56  = 1 

xij  ∈ {0, 1} for  all  xij 

. 

Of  course,  this  set  will  be  a  ﬁnite  (discrete)  set.  That  is,  P  is  the  set  of 
paths  connecting node 1  to node 6.  Suppose  that we plot  the  cost z  and  the 
number  of  arcs  r  used  in  each  of  these  paths,  see  Figure  4. 

36 

conv(
S) 

z* = 5 
v* = 4.5 

 
)
t
s
o
c
(
 
z

7 
6 
5 
4 
3 
2 
1 

1

2
7
6
5
4
3
r (number of arcs) 

 

Figure  4:  Resources  and  costs. 

We obtain  the  seven dots  in  this ﬁgure  corresponding  to  the  seven paths 
listed  in  Table  1.  Now,  because  our  original  problem  was  formulated  as  a 
minimization  problem,  the  geometric  dual  is  obtained  by  ﬁnding  the  line 
that  lies  on  or  below  these  dots  and  that  has  the  largest  intercept  with 
the  feasibility  line.  Note  from Figure  4  that  the  optimal  value  of  the  dual  is 
∗ v  = 4.5, whereas the optimal value of the original primal problem is z 
∗  = 5. 
In  this example, because  the  cost-resource  set  is not convex  (it  is  simply  the 
seven  dots),  we  encounter  a  duality  gap.  In  general,  integer  optimization 
models  will  usually  have  such  duality  gaps,  but  they  are  typically  not  very 
large  in  practice.  Nevertheless,  the  dual  bounding  information  provided  by 
v  ≤  z  can  be  used  in  branch  and  bound  procedures  to  devise  eﬃcient 
∗
∗ 
algorithms  for  solving  integer  optimization  models. 

It  might  be  useful  to  re-cap.  The  original  constrained  shortest  path 
problem  might  be  very  diﬃcult  to  solve  directly  (at  least  when  there  are 
hundreds  of  thousands  of  nodes  and  arcs).  Duality  theory  permits  us  to 
relax  (eliminate)  the  complicating  constraint  and  to  solve  a  much  easier 
�  =  cij  − u. 
Lagrangian  shortest  path  problem  with  modiﬁed  arc  costs  cij 
∗
∗  to  the 
Solving  for  any  u  generates  a  lower  bound  L (u) on the  value  z 

37 

∗
original  problem.  Finding  the  best  lower  bound  maxu L (u)  requires  that 
we  develop  an  eﬃcient  procedure  for  solving  for  the  optimal  u.  Duality 
theory permits us to replace a single and diﬃcult problem (in this instance, a 
constrained shortest-path problem) with a sequence of much easier problems 
(in  this  instance,  a  number  of  unconstrained  shortest  path  problems),  one 
for  each  value  of  u  encountered  in  our  search  procedure.  Practice  on  a 
wide  variety  of  problem  applications  has  shown  that  the  dual  problem  and 
subsequent branch and bound procedures can be extremely eﬀective in many 
applications. 

To conclude this discussion, note from Figure 4 that the optimal value for 
u  in  the dual problem  is u = 1.5.  Also note  that  if we  subtract u = 1.5 from 
the  cost  of  every  arc  in  the  network,  then  the  shortest  path  (with  respect 
to  the  modiﬁed  costs)  has  cost  −1.5.  Both  paths  1-2-4-6  and  1-2-3-5-4-6 
are  shortest  paths  for  this  modiﬁed  problem.  Adding  4u  = 4 × 1.5 = 6 
to  the  modiﬁed  shortest  path  cost  of  −1.5  gives  a  value  of  6 − 1.5 = 4.5 
∗
which  equals  v  .  Note  that  if we  permitted  the  ﬂow  in  the  original  problem 
to  be  split  among  multiple  paths  (i.e.,  formulate  the  problem  as  a  linear 
optimization  problem  instead  of  as  an  integer  optimization  problem),  then 
the  optimal  solution  would  send  one  half  of  the  ﬂow  on  both  paths  1-2-4-6 
and  1-2-3-5-4-6  and  incur  a  cost  of: 

× 3 +  × 6 = 4.5  .
1 
1
2 
2
In  general,  the  value  of  the  dual  problem  is  always  identical  to  the  value  of 
the  original  (primal)  problem  if  we  permit  convex  combinations  of  primal 
solutions.  This  equivalence  between  convexiﬁcation  and  dualization  is  easy 
to  see  geometrically. 

13  Conic  Duality 

13.1  Cones  and  Conic  Convex  Optimization 
We  say  that K  ⊂ IRn  is  a  convex  cone  if: 

38 

x, y ∈ K  and  α, β  ≥ 0  ⇒  αx + β y ∈ K . 

Some  examples  of  convex  cones  that  are  useful  to  us  are: 
•  IRn  := {x ∈ IRn  |  xj  ≥ 0, j  = 1, . . . , n}
(cid:14) 
(cid:15) 
(cid:18) 
(cid:5) 
+ 
•  Q =  x ∈ IRn  |  x1  ≥ 
n 
n	
2
j=2 xj 
•  IRn 
• {0}n  ∈ IRn 
•  S k×k  = {X  ∈ S k×k  |  vT X v ≥ 0  for  all  v ∈ IRn}
+ 
•  K  = K1 × K2 × · · · × Kl  where Kj  is a  closed  convex  cone,  j  = 1, . . . , l 

We  consider  the  following  convex  optimization  problem  in  conic  form: 

∗	
T
CP  :  z  = minimumx  c x 

s.t.	

Ax = b 
x ∈ K , 

where K  is  a  closed  convex  cone. 

13.2  Dual  Cones  and  the  Conic  Dual  Problem 
Let K denote  the dual  cone of  the  closed  convex  cone K  ⊂ IRn ,  deﬁned by: 
∗
K  := {y ∈ IRn  |  y x ≥ 0  for  all  x ∈ K }  . 
∗	
T

Proposition  13.1   If  K  is  a  nonempty  closed  convex  cone,  then  K
nonempty  closed  convex  cone. 

∗  is  a 

39 

Proof:   Notice  that  0 ∈ K ,  which  shows  that K (cid:8)
= ∅. If  y1 , y2  ∈ K ,  then 
∗
∗
∗ 
for every x ∈ K  and every α, β  ≥ 0 we have (αy1 + β y2 )T x ≥ 0, which shows 
that K is  a  convex  cone.  Suppose  that  y , y2 , . . . ∈ K and  limj→∞ y j  = ¯y . ∗ 
∗ 
∗ 
1
Then  for every x ∈ K  we have  (y j )T x ≥ 0 and  so  ¯
yT x ≥ 0, whereby  ¯
y ∈ K , 
∗  is  closed. 
which  shows  that K

∗
∗ )
Proposition  13.2  If K  is a nonempty closed convex cone, then (K = K . 

Proof:   We  have 

∗  := {y ∈ IRn  |  y T x ≥ 0  for  all  x ∈ K } 
K 

and 

∗  := {z  ∈ IRn  |  z y ≥ 0  for  all  y ∈ K 
∗ }  . 
∗
T
)
(K 
For  every  x  ∈  K  we  have  xT y  ≥  0  for  all  y  ∈  K ,  which  shows  that 
∗
K  ⊂  (K .  Suppose  that  K  (cid:8)= (K .  Then  there  exists  z¯ ∈  (K
∗
∗
∗ 
∗ )
∗ )
∗ )
for 
¯ ∈  K . Since  z /
¯ ∈  K  and  K  is  a  closed  convex  set,  there  exists  a 
which  z /
hyperplane  that  separates  z¯ from  K .  Thus  there  exists  y  (cid:8)=  0  and  α  for 
which  y z <  α  and  yT x > α  for  all  x  ∈  K .  But  since  K  is  a  cone  this 
T ¯
means  that  α  = 0,  and  so  y  ∈  K .  However,  y z <  α  =  0,  which  implies 
∗ 
T ¯
that  ¯ ∈ (Kz /
∗
∗
∗ )
∗ )
,  which  is  a  contradiction.  Therefore  (K = K . 
Here  are  the  dual  cones  associated  with  the  above  examples: 
(cid:19)
(cid:20)∗ 
•  IRn  = IRn 
+
+ 
•  (Qn )
∗  = Q
n
∗  = {0}
•  (IRn )
n
•  ({0}n )
∗  = IRn 
(cid:21)
(cid:22)∗

•  S k×k 
= S n×n

+ 
+
•  (K1  × K2  × · · · × Kl )
∗  = K1 
∗

× · · · × Kl 
∗ 

× K2 
∗ 

We  form  the  Lagrangian: 

40 

L(x, u) := c x + u T (b − Ax)  . 
T

We  deﬁne  the  dual  function  by: 

L  (u) := min  L(x, u) = min  c x + u T (b − Ax)  . 
∗
T
x∈K
x∈K 

Then  notice  that 
L (u) = minx∈K  cT x + uT (b − Ax) 
∗
= uT b + minx∈K  (cT  − uT A)x 
⎧ 
⎪  bT u 
⎨ 
if  c − AT u ∈ K
∗ 
= ⎪ 
⎩  −∞ 
if  c − AT u /∈ K . 
∗
From  this  we  write  down  the  dual  problem: 

∗
CD  :  v  = maximumu,s  bT u 

s.t. 

AT u + s = c 
s ∈ K . 
∗ 

Proposition  13.3  (Weak  Duality)  If  x  is  feasible  for  CP  and  (u, s)  is 
feasible  for  CD,  then  cT x ≥ bT u.  Consequently,  z  ≤ v  .

∗
∗

Proof:   If x  is feasible  for CP and (u, s)  is feasible for CD, then cT x − bT u =

uT Ax + sT x − bT u = sT x ≥ 0  because  x ∈ K  and  s ∈ K . 
∗ 

Remark   1   The  conic  dual  of  CD  is  CP. 

41 


13.3  Slater  Points  and  Strong  Duality 

A  Slater  point  for  CP  is  a  point  x0  that  satisﬁes: 

Ax0  = b  and  x 0  ∈ intK . 

Theorem  2   (Strong  Duality  Theorem)  If  CP  has  a  Slater  point,  then 
∗
∗ 
v  = z  and  the  dual  attains  its  optimum. 
(cid:15) 
(cid:14) 
Proof:   Deﬁne  the  following  set: 
S  :=  (w, λ, α)  | there  exists  x  for  which  Ax = b − w, x + λ ∈ K, c T x < z  + α , 
∗ 

and  notice  that  S  is  a  nonempty  convex  set.  Also  notice  that  (w, λ, α) = 
(0, 0, 0)  /∈ S ,  and  so  there  is  a  hyperplane  separating  (0, 0, 0)  from  S .  This 
means  that  there  exists  (u, s, θ)  (cid:8)= 0  for  which 
T u w + s T λ + θα ≥ 0  for  all  (w, λ, α) ∈ S . 

This  is  the  same  as 
u T (b − Ax) + s T (v − x) + θ(c x − z  + δ) ≥ 0  for  all  x,  v ∈ K,  δ > 0  . 
∗ 
T 

Rearranging  terms  we  have 
u T b + (θc − AT u − s)T x + s v + θ(δ − z 
) ≥ 0  for  all  x,  v ∈ K,  δ > 0  . 
∗
T 
This then implies that θ ≥ 0, AT u + s = θc and s ∈ K
∗ . If θ > 0 then we can 
assume  (by  rescaling  if  necessary)  that  θ  = 1,  whereby  we  see  that  (u, s) is 
feasible  for  the dual problem and  in also  from  the above  that  bT u − z  ≥ −δ 
∗
for  all  δ >  0.  This  in  turn  implies  that  v  ≥  bT u  ≥  z  ,  which  by  weak 
∗
∗
∗
∗
duality,  shows that z  = v  and that (u, s)  is an optimal solution of the dual 
problem. 
If  instead  θ  =  0  then  we  have  AT u + s  =  0.  Therefore  0  ≤  s x = 
T  0
−uT Ax0  =  −uT b  ≤  0,  and  so  sT x0  =  0.  Then  since  x0  ∈  intK  and  there 
exists   >  0  for  which  x0  − s  ∈  K , we  have  0  ≤  sT (x0  − s) =  −sT s 
which  implies  that  s  =  0.  But  then  u  =  0  since  we  can  assume  without 

42 

loss  of  generality  that A  has  full  row  rank,  and  then  (u, s, θ) = 0, which  is  a 
contradiction.  Thus  θ > 0  and  the  proof  is  complete. 
A  Slater  point  for  CD  is  a  point  (u0 , s0 )  that  satisﬁes: 

AT u 0  + s  = c  and  s 0  ∈ intK . 
∗ 
0	

∗
∗
Corollary   3  If  CD  has  a  Slater  point,  then  v  = z  and  the  primal  attains 
its  optimum. 

∗
∗  and  the 
Corollary   4  If  CP  and  CD  each  have  a  Slater  point,  then  v  = z 
primal  and  dual  problems  attain  their  optima. 

14  Duality  Theory  Exercises 

1.  Consider  the  problem 

√
(P)  minx f (x) = −  x 
g(x) = x ≤ 0 
x ∈ X  = [0, ∞)  . 

s.t. 

Formulate  the  dual  of  this  problem. 

2.  Consider  the  problem 

T
(P)  minx c x 
s.t.  b − Ax ≤ 0 
x ≥ 0  . 

a.	 Formulate  a  dual  based  on  g(x) = b − Ax,  X  = {x ∈  IRn  :  x ≥ 
0}. 

43 

b.  Formulate  a  dual  based  on  g(x) = (¯g(x), g˜(x))  =  (b − Ax, −x) 
and X  = IRn . 

3.  Consider  the  two  equivalent  problems 
(P 1 ) minx  (cid:16)x(cid:16) 
1  T
(P 2 ) minx  x x
b − Ax ≤ 0 
b − Ax ≤ 0 
2 
x ∈ IRn  . 
x ∈ IRn 
Derive  the  dual  problems  (D1 ) and  (D2 ) of (P 1 ) and  (P 2 ).  What  is 
the  relation  between  (D1 ) and  (D2 )? 

Py 

4.  Let  P  be  given  as  a  function  of  the  parameter  y : 
z  (y) = min  −x1  + 5x2  − 7x3 
∗
x1  − 3x2  + x3  − y ≤ 0, 
s.t. 
x ∈ X  = {x ∈ IR3  :  xj  = 0  or  1, j  = 1, 2, 3}. 
Construct  the  dual  Dy  for  all  y  ∈  [0, 8].  Graph  the  function  z  (y) in 
∗
(y , z )  space.  For  what  values  of  y  is  there  a  duality  gap? 

5.  Consider  the  problem 

(P)  minx cT x +  1 xT Qx
2 
b − Ax ≤ 0  . 

s.t. 

where  Q  is  symmetric  and  positive  semideﬁnite. 

a.   What  is  the  dual? 
b.  Show  that  the  dual  of  the  dual  is  the  primal. 

6.  Consider  the  program 

(P ) minx  f (x) 
s.t.	 gi (x) ≤ 0  , i = 1, . . . , m 
x ∈ X , 

where  f (·) and  gi (·)  are  convex  functions  and  the  set  X  is  a  convex 
set.  Consider  the  matrix  below: 

44 

Property  of D 
∗  ﬁnite 
∗  ﬁnite 
∗  ﬁnite 
∗  ﬁnite 
v 
v 
v 
v 
∗  = +∞  v 
∗  = −∞ 
attained  not  attained  attained  not  attained  v 
∗ 
∗ 
∗ 
∗ 
∗ 
∗ 
∗ 
∗ 
v  = z 
v  = z 
v  < z 
v  < z 
1 
5 
9 
13 

17 

21 

2 

3 
4 

6 

7 
8 

10 

11 
12 

14 

15 
16 

18 

19 
20 

22 

23 
24 

Property  of  P 
∗  ﬁnite 
z 
P  stable 
∗  ﬁnite 
z 
P  not  stable 
∗  = −∞ 
z 
∗  = +∞ 
z 
(infeasible) 

Prove  by  citing  relevant  theorems  from  the  notes,  etc.,  that  the  following 
cases  cannot  occur:  2,  3,  4,  5,  7,  8,  9,  11,  13,  15,  17,  18,  19,  and  21. 
7.  Let  X  ⊂  IRn ,  Y  ⊂  IRm ,  f (x, y) : (X  × Y )  →  IR.  A  sadd lepoint  ( ¯ y) of 
x, ¯
f (x, y) is a point ( ¯ y) ∈ X × Y  such  that 
x, ¯
x, y) ≤ f ( ¯ y) ≤ f (x, y¯), 
x, ¯
f ( ¯
for  any  x  ∈  X  and  y  ∈  Y .  Prove  the  equivalence  of  the  following  three 
results: 

(a)  There  exists  a  saddlepoint  ( ¯ y) of  f (x, y).
x, ¯
x ∈ X, y¯ ∈ Y  for  which  maxy∈Y  f ( ¯
x, y) = minx∈x f (x, y¯) . 
(b)  There  exists  ¯	
(c)   minx∈X (maxy∈Y  f (x, y)) = maxy∈Y  (minx∈X  f (x, y)). 
(cid:5) 
8.  Consider  the  logarithmic  barrier  problem: 
c x − θ 
n 
T 
j=1  

P (θ) :  minimizex 

ln(xj ) 

s.t.	

Ax = b 
x > 0  . 

Compute  a  dual  of  P (θ)  by  dualizing  on  the  constraints  “Ax =  b.”  What  is 
the relationship between this dual and the dual of the original linear program 
(without  the  logarithmic  barrier  function)? 

45 

(cid:5) 
9.  Consider  the  program 
P (γ ) :  minimizex  − 
n 
j=1  

ln(xj ) 

s.t.	

Ax = b 
Tc x = γ 
x > 0  . 

T
Compute a dual of P (γ ) by dualizing on the constraints Ax = b and c x = γ . 
What  is  the  relationship  between  the  optimality  conditions  of  P (θ) in the 
previous  exercise  and  P (γ )? 
(cid:5) 
Consider  the  program 
P (δ) :  minimizex  − 
n 
j=1  

ln(xj ) − ln(δ − cT x) 

s.t.	

Ax = b 
cT x < δ 
x > 0  . 
Compute a dual of P (δ) by dualizing on  the constraints Ax = b.  What  is  the 
relationship between  the optimality  conditions of P (δ) and P (θ) and P (γ ) of 
the  previous  two  exercises? 

10.  Consider  the  conic  form  problem  CP  of  convex  optimization 
∗	
CP :  z  = minimumx 

T
c x 

s.t. 

and  the  associated  conic  dual  problem: 
∗
CD :  v  = maximumu,s 

Ax = b 
x ∈ K , 

bT u 

s.t. 

AT y + s = c 
s ∈ K , 
∗ 
where  K  is  a  closed  convex  cone.  Show  that  “the  dual  of  the  dual  is  the 
primal,”  that  is,  that  the  conic  dual  of  CD  is  CP. 

46 

11.  Prove  Corollary  3,  which  asserts  that  the  existence  of  Slater  point  for  the 
conic  dual  problem  guarantees  strong  duality  and  that  the  primal  attains  its 
optimum. 

12.  Consider  the  following  “minimax”  problems: 

min  max  φ(x, y) and  max  min  φ(x, y) 
x∈X y∈Y
y∈Y x∈X 
where  X  and  Y  are  nonempty  compact  convex  sets  in  IRn  and  IRm ,  respec-
tively,  and  φ(x, y) is convex in  x  for  ﬁxed  y ,  and  is  concave  in  y  for  ﬁxed 
x. 
(a)  Show  that  minx∈X  maxy∈Y  φ(x, y)  ≥  maxy∈Y  minx∈X  φ(x, y) in 
the  absence  of  any  convexity/concavity  assumptions  on  X ,  Y ,  and/or 
φ(·, ·). 
(b)  Show  that  f (x) := maxy∈Y  φ(x, y)  is  a  convex  function  in  x  and  that 
g(y) := minx∈X  φ(x, y)  is  a  concave  function  in  y . 
(c)  Use  a  separating  hyperplane  theorem  to  prove: 

min  max  φ(x, y) = max  min  φ(x, y)  . 
x∈X y∈Y
y∈Y x∈X 
13.  Let X  and Y  be nonempty  sets  in  IRn , and  let f (·), g(·) : IRn  → IR.  Consider 
the  following  conjugate  functions  f (·) and  g  (·)  deﬁned  as  follows: 
∗
∗
{f (x) − u x}  , 
∗
t
f  (u) :=  inf 
x∈X

and 

g  (u) :=  sup {f (x) − u x}  . 
∗
t 
x∈X
(a)  Construct  a  geometric  interpretation  of  f (·) and  g  (·). 
∗
∗
∗ (u) > −∞}, and 
(b)  Show  that f (·)  is a concave  function on X := {u  | f
∗
∗
∗ (u) < +∞}. 
g  (·)  is  a  convex  function  on  Y := {u  |  g 
∗
∗ 
(c)  Prove  the  following weak  duality  theorem  between  the  conjugate  primal 
problem  inf {f (x) − g(x)  |  x ∈ X ∩ Y }  and  the  conjugate  dual  problem 
sup{f (u) − g  (u)  |  u ∈ X ∩ Y }: 
∗
∗
∗
∗
(u) − g  (u)  |  u ∈ X 
∗  ∩ Y  }  . 
inf {f (x) − g(x)  |  x ∈ X ∩ Y } ≥ sup{f 
∗
∗
∗
(d)  Now  suppose  that  f (·)  is  a  convex  function,  g(·)  is  a  concave  function, 
intX  ∩  intY  (cid:8)=  ∅, and  inf {f (x) − g(x)  |  x  ∈  X  ∩ Y }  is  ﬁnite.  Show 
that  equality  in  part  (13c)  holds  true  and  that  sup{f (u) − g  (u)  |  u ∈ 
∗
∗
X ∩ Y }  is  attained  for  some  u = u  . 
∗
∗
∗

(e)  Consider a standard inequality constrained nonlinear optimization prob-
lem  using  the  following  notation: 

47 

s.t.	

OP  :  minimumx 

f¯(x) 
g¯1 (x)  ≤  0, 
. . . 
g¯m (x)  ≤  0, 
x ∈ X . 
¯ 
By  suitable  choices  of  f (·), g(·), X , and  Y ,  formulate  this  problem  as 
an  instance  of  the  conjugate  primal  problem  inf {f (x)  −  g(x)  |  x  ∈ 
X  ∩ Y }.  What  is  the  form  of  the  resulting  conjugate  dual  problem 
sup{f	 (u) − g  (u)  |  u ∈ X ∩ Y }? 
∗	
∗
∗
∗
14.  Consider  the  following  problem: 
∗ z  = min  x1  + x2 
2
2
s.t.	
x1  + x2  = 4, 
−2x1  − x2  ≤ 4  . 

(a)  Formulate  the  Lagrange  dual  of  this  problem  by  incorporating  both 
constraints  into  the  ob jective  function  via  multipliers  u1 , u2 . 
∗
(b)  Compute  the  gradient  of  L (u) at the  point  ¯u = (1, 2). 
(c)  Starting  from  ¯u  = (1, 2),  perform  one  iteration  of  the  steepest  ascent 
method for the dual problem.  In particular, solve the following problem 
where  d ¯ = ∇L ( ¯u): 
∗

maxα  L ( ¯∗
u + αd¯) 
u + αd ¯ ≥ 0  , 
s.t.	
¯
α ≥ 0  . 

