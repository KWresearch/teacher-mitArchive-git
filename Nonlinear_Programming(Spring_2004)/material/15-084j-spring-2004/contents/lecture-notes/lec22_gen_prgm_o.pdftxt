Subgradient Optimization, Generalized 
Programming,  and Nonconvex Duality 

Robert M.  Freund 

May,  2004 

2004 Massachusetts Institute of Technology.

1 

1  Subgradient  Optimization 

1.1	 Review  of  Subgradients 
Recall  the  following  facts  about  subgradients  of  convex  functions.  Let  S  ⊂ 
IRn  be  a  given  nonempty  convex  set,  and  let  f (·) :  S  →  IR  be  a  convex 
function.  Then  then  ξ  ∈ IRn  is  a  subgradient  of  f (·) at  ¯x ∈ S  if 

x)  for  all  x ∈ S .
x) + ξ T (x − ¯
f (x) ≥ f ( ¯
x ∈  intS ,  then  there  exists  a  subgradient  of  f (·) at  ¯
If  ¯
x.  The  collection 
of  subgradients  of  f (·) at  x  is  denoted  by  ∂ f (x),  and  the  operator  ∂ f (·) is 
called  the  subdiﬀerential  of  f (·).  Recall  that  if  x  ∈  intS ,  then  ∂ f (x) is a 
nonempty  closed  convex  set. 
If  f (·)  is  diﬀerentiable  at  x  = ¯
x)  (cid:7)
x  and  ∇f ( ¯ = 0  ,  then  −∇f ( ¯
x) is a 
descent  direction  of  f (·) at  ¯
x.  However,  if  f (·)  is  not  diﬀerentiable  at  x = ¯
x 
and  ξ  is  a  subgradient,  then −ξ  is not  necessarily  a descent direction  of  f (·) 
at  ¯x. 

1.2 	 Computing  a  Subgradient 

Subgradients  play  a  very  important  role  in  algorithms  for  non-diﬀerentiable 
optimization.  In  these  algorithms,  we  typically  have  a  subroutine  that  re-
ceives  as  input  a  value  x,  and  has  output  ξ  where  ξ  is  some  subgradient  of 
f (x). 

1.3	 The Subgradient Method for Minimizing a Convex Func-
tion 
Suppose  that  f (·)  is  a  convex  function,  and  that  we  seek  to  solve: 
∗
P  :  z  = minimizex  f (x) 
x ∈ IRn  . 

s.t. 

2 

	
The  following  algorithm  generalizes  the  steepest  descent  algorithm  and  can 
be  used  to  minimize  a  nondiﬀerentiable  convex  function  f (x). 

Subgradient  Method 

Step  0:  Initialization.  Start  with  any  point  x1  ∈  IRn .  Choose  an 
inﬁnite  sequence  of  positive  step-size  values  {αk }∞  . Set  k = 1. 
k=1
Step  1:  Compute  a  subgradient.  Compute  ξ  ∈  ∂ f (xk ).  If  ξ  = 0, 
STOP.  xk  solves  P . 

Step  2:  Compute  step-size.  Compute  step-size  αk  from  the  step-
size  series. 
Step  3:  Update  Iterate.  Set  xk+1  ←  xk  − αk (cid:3)ξ(cid:3) . Set  k  ←  k + 1 
ξ
and  go  to  Step  1. 

Note  in  this  algorithm  that  the  step-size  αk  at  each  iteration  is  deter-
mined  without  a  line-search,  and  in  fact  is  predetermined  in  Step  0.  One 
reason  for  this  is  that  a  line-search  might  not  be  worthwhile,  since  −ξ  is 
not  necessarily  a  descent  direction.  As  it  turns  out,  the  viability  of  the 
subgradient  method  depends  critically  on  the  sequence  of  step-sizes: 

Theorem  1	 Suppose  that  f (·)  is  a  convex  function  whose  domain  D ⊂ IRn 
= ∅.  Suppose  that  {αk }∞ 
satisﬁes  intD  (cid:7)
satisﬁes:
∞ (cid:1) 
k=1 
αk  = ∞  . 
k=1 

lim  αk  = 0 
k→∞ 

and 

Let  x1 , x2 , . . . ,  be  the  iterates  generated  by  the  subgradient  method.  Then 
∗
inf f (x k ) = z . 
k 

Proof:  Suppose  that  the  result  is  not  true.  Then  there  exists   >  0 such 
that  f (xk )  ≥  z  +   for  all  k  = 1, . . .. Let  T  =  {x  ∈  IRn  |  f (x)  ≤  z  + }. 
∗	
∗
x, ρ) ⊂ T , where B ( ˆ
x, ρ) := {x ∈ 
Then  there exists  ˆ
x and ρ > 0  for which B ( ˆ

3 

	
IRn  | (cid:12)x − ˆx(cid:12) ≤  ρ}. Let  ξ k  be  the  subgradient  chosen  by  the  subgradient 
method  for  the  iterate  x .  By  the  subgradient  inequality  we  have  for  all 
k
(cid:2) 
(cid:2) 
(cid:3) 
(cid:3) 
k = 1, . . .: 
≥ f (x k ) + (ξ k )T  x + ρ 
f (x k ) ≥ z  +  ≥ f x + ρ 
ξ k 
ξ k 
∗ 
(cid:12)ξ k (cid:12)
(cid:12)ξ k (cid:12)
ˆ
ˆ

) − x
k

,

which  upon  rearranging  yields: 
(ξ k )T ( ˆx − x k ) ≤ −ρ

(ξ k )T ξ k 
(cid:12)ξ k (cid:12) 

= −ρ(cid:12)ξ k (cid:12) . 

We  also  have  for  each  k :

x(cid:12)2  =  (cid:12)xk  − αk (cid:3)ξk (cid:3) 
k+1  − ˆ
(cid:12)x
− ˆx(cid:12)2 
ξk

(ξk )T  (xk− ˆ
x(cid:12)2  + α2  − 2αk 
=  (cid:12)xk  − ˆ
x)
(cid:3)ξk (cid:3) 
k
≤ (cid:12)xk  − ˆ
x(cid:12)2  + α2  − 2αk ρ
k 
=  (cid:12)xk  − ˆx(cid:12)2  + αk (αk  − 2ρ)  . 
For  k  suﬃciently  large,  say  for  all  k ≥ K , we have  αk  ≤ ρ,  whereby: 
(cid:12)x k+1  − ˆ
x(cid:12)2  ≤ (cid:12)x k  − ˆ
x(cid:12)2  − ραk  . 
However,  this  implies  by  induction  that  for  all  j  ≥ 1 we have: 
(cid:1) 
K+j 
αk  . 
k=K+1 

x(cid:12)2  ≤ (cid:12)x K  − ˆ
(cid:12)x K+j  − ˆ
x(cid:12)2  − ρ

(cid:4) 
Now  for  j  suﬃciently  large  the  right-hand  side  expression  is  negative,  since 
∞ 
αk  =  ∞,  which  yields  a  contradiction  since  the  left-hand  side  must  be 
k=1 
nonnegative. 

4 

1.4  The  Subgradient  Method  with  Pro jections 

Problem  P  posed  at  the  start  of  Subsection  1.3  generalizes  to  the  following 
problem: 
∗
PS  :  z  = minimizex  f (x) 
x ∈ S , 

s.t. 

where S  is  a  given  closed  convex  set.  We  suppose  that S  is  a  simple  enough 
set  that we  can  easily  compute pro jections  onto S .  This means  that  for  any 
point  c ∈ IRn ,  we  can  easily  compute: 
ΠS (c) := arg  min (cid:12)c − x(cid:12)  . 
x∈S 
The  following  algorithm  is  a  simple  extension  of  the  subgradient  method 
presented  in  Subsection  1.3,  but  includes  a  pro jection  computation  so  that 
all  iterate  values  xk  satisfy  xk  ∈ S . 

Pro jected  Subgradient  Method 
Step  0:  Initialization.  Start  with  any  point  x1  ∈  S .  Choose  an 
inﬁnite  sequence  of  positive  step-size  values  {αk }∞  . Set  k = 1. 
k=1
Step  1:  Compute  a  subgradient.  Compute  ξ  ∈  ∂ f (xk ).  If  ξ  = 0, 
STOP.  xk  solves  P . 

Step  2:  Compute  step-size.  Compute  step-size  αk  from  the  step-
(cid:5) 
(cid:6) 
size  series. 
Step  3:  Update  Iterate.  Set  xk+1  ←  ΠS  xk  − αk (cid:3)ξ(cid:3)  . Set  k  ← 
ξ
k + 1  and  go  to  Step  1. 

Similar  to  Theorem  1,  we  have: 
Theorem  2  Suppose  that  f (·)  is  a  convex  function  whose  domain  D ⊂ IRn 
satisﬁes  intD ∩ S  (cid:7)= ∅.  Suppose  that  {αk }∞ 
∞ (cid:1) 
satisﬁes:
k=1 
αk  = ∞  . 
k=1 

lim  αk  = 0 
k→∞ 

and 

5


Let  x , x2 , . . . ,  be  the  iterates  generated  by  the  projected  subgradient method. 
1
Then 
∗
inf f (x k ) = z . 
k 

The proof of Theorem 2 relies on the following “non-expansive” property 
of  the  pro jection  operator  ΠS (·): 
Lemma  3  Let  S  be  a  closed  convex  set  and  let  ΠS (·)  be  the  projection  op-
erator  onto  S .  Then  for  any  two  vectors  c1 , c2  ∈ IRn , 
(cid:12)ΠS (c 1 ) − ΠS (c 1 )(cid:12) ≤ (cid:12)c 1  − c 2(cid:12) . 

c1  = ΠS (c1 ) and  let  ¯
c2  = ΠS (c1 ).  Then  from  Theorem  4  of  the 
Proof:  Let  ¯
Constrained  Optimization  notes  (the  basic  separating  hyperplane  theorem) 
we  have: 
(c 1  − c¯1 )T (x − c¯1 ) ≤ 0 
for  all  x ∈ S , 

and 

(c 2  − c¯2 )T (x − c¯2 ) ≤ 0 
for  all  x ∈ S . 
c1  ∈ S  it  follows  that: 
c2  ∈ S  and  ¯
In  particular,  because  ¯
(c 2  − c¯2 )T (¯
(c 1  − c¯1 )T (¯
c 1  − c¯2 ) ≤ 0  .
c 2  − c¯1 ) ≤ 0 
and 
Then  note  that 
(cid:12)c1  − c2(cid:12)2  =  (cid:12)c¯1  − c¯2  + (c1  − c¯1  − c2  + ¯c2 )(cid:12)
2
c1  − c¯2 )T (c1  − c¯1  − c2  + ¯
=  (cid:12)c¯1  − c¯2(cid:12)2  + (cid:12)c1  − c¯1  − c2  + ¯
c2(cid:12)2  + 2(¯
c2 ) 
≥ (cid:12)c¯1  − c¯2(cid:12)2  + 2(¯
c1  − c¯2 )T (−c2  + ¯
c1  − c¯2 )T (c1  − c¯1 ) + 2(¯
c2 ) 
≥ (cid:12)c¯1  − c¯2(cid:12) , 
2
from  which  it  follows  that  (cid:12)c1  − c2(cid:12) ≥ (cid:12)c¯1  − c¯2(cid:12). 
The  proof  of  Theorem  2  can  easily  be  constructed  by  using  Lemma  3 
and  by  following  the  logic  used  in  the  proof  of  Theorem  1,  and  is  left  as  an 
Exercise. 

6 

1.5  Solving  the  Lagrange  Dual  via  the  Subgradient  Method 

We  start  with  the  primal  problem: 

∗
OP  :  z  = minimumx 

s.t.	

f (x) 
gi (x)  ≤  0,
x ∈ X . 

i = 1, . . . , m 

We  create  the  Lagrangian 

L(x, u) := f (x) + u g(x)  .

T

The  dual  function  is  given  by:


∗
L (u) :=  minimumx  f (x) + uT g(x) 
x ∈ X .


s.t. 

The  dual  problem  is:


∗
∗	
D :  v  = maximumu  L (u) 
u ≥ 0  . 

s.t.	

∗
Recall  that  L (u)  is  a  concave  function.  For  concave  functions  we  work 
with supergradients. If f (·) is a concave function whose domain is the convex 
set  S ,  then  g ∈ IRn  is  a  supergradient  of  f (·) at  ¯x ∈ S  if 

x) + g T (x − ¯
f (x) ≤ f ( ¯
x) 

for  all  x ∈ S . 

∗
The  premise  of Lagrangian  duality  is  that  it  is  “easy”  to  compute L ( ¯u) for 
x ∈ X  of 
any  given  ¯	
u.  That  is,  it  is  easy  to  compute  an  optimal  solution  ¯

∗
u) :=  minimumx∈X  f (x) + ¯T g(x) =  f ( ¯
x) + ¯T g( ¯
x)  , 
L ( ¯	
u
u

7 

for  any  given  ¯u.  It  turns  out  that  computing  supergradients  of L (·)  is  then 
∗
also  easy.  We  have: 

Proposition  4  Suppose  that  u  is  given  and  that  x  ∈  X  is  an  optimal  so-
¯
¯
∗
uT g(x).  Then  g  :=  g( ¯
lution  of  L ( ¯
x)  is  a  supergradient  of 
u) = min f (x) +  ¯
x∈X 
L (·)  at  u = ¯u. 
∗

Proof:  For  any  u ≥ 0 we have 
∗
(u) =  min f (x) + u T g(x) 
L 
x∈X 
≤ 
T 
x) + u g( ¯
f ( ¯
x) 
x) + (u − ¯
u)T g( ¯
T 
x) + ¯
f ( ¯
= 
x)
u g( ¯
x)T (u − ¯
u T 
=  min f (x) + ¯ g(x) + g( ¯
u)
x∈X ∗
u) + g T (u − ¯
= 
u)  .
L  ( ¯
Therefore  g  is  a  supergradient  of  L (·) at  ¯u. 
∗
q.e.d. 

The  Lagrange  dual  problem  D  is  in  the  same  format  as  problem  PS  of 
Subsection  1.4,  with  S  = IRm 
+ .  In  order  to  apply  the  pro jected  subgradient 
method  to  this  problem,  we  need  to  be  able  to  conveniently  compute  the 
pro jection  of  any  vector  v  ∈  IRm  onto  S  = IRm 
+ .  This  indeed  is  easy.  Let 
u ∈ IRn  be  given,  and  deﬁne  u+  to  be  the  vector  each  of  whose  components 
is  the  positive  part  of  the  respective  component  of  v .  For  example,  if  u  = 
(2, −3, 0, 1, −5), then u+  = (2, 0, 0, 1, 0).  Then  it  is easy to see that ΠS (u) = 
u+ .  We can now state the subgradient method for solving the Lagrange dual 
problem: 

Subgradient  Method  for  Solving  the  Lagrange  Dual  Problem 

Step  0:  Initialization.  Start  with  any  point  u1  ∈  IRn 
+ .  Choose  an 
inﬁnite  sequence  of  positive  step-size  values  {αk }∞  . Set  k = 1. 
k=1

8 

Step  1:  Compute  a  supergradient.  Solve  for  an  optimal  solution 
∗
x  of  L (uk ) = min f (x) + (uk )T g(x).  Set  g  :=  g( ¯
¯	
x).  If  g  =  0,  STOP. 
x∈X

xk  solves  D.


Step  2:  Compute  step-size.  Compute  step-size  αk  from  step-size 
(cid:6)+ 
(cid:5)	
series. 
Step  3:  Update  Iterate.  Set uk+1  ←  uk  + αk (cid:3)g(cid:3) 
. Set k ← k + 1 
g
and  go  to  Step  1. 

Notice  in  Step  3  that  the  “(u)+”  operation  is  simply  the  pro jection  of  u 
onto  the  nonnegative  orthant  IRn 
+ . 

2	 Generalized  Programming  and  Nonconvex  Du-
ality 

2.1	 Geometry  of  nonconvex  duality  and  the  equivalence  of 
convexiﬁcation  and  dualization 

We  start  with  the  primal  problem: 

∗
OP  :	 z  = minimumx 

s.t.	

f (x) 
gi (x)  ≤  0,
x ∈ X . 

i = 1, . . . , m 

We  create  the  Lagrangian 

L(x, u) := f (x) + u g(x)  .

T

The  dual  function  is  given  by:


∗
L (u) :=  minimumx  f (x) + uT g(x) 
x ∈ X . 

s.t.	

9 

The  dual  problem  is: 

∗
∗
D :  v  = maximumu  L (u) 
u ≥ 0  . 
s.t. 
Herein  we  will  assume  that  f (·) and  g1 (·), . . . , gm (·)  are  continuous  and 
X  is  a  compact  set.  We  will  not  assume  any  convexity. 
(cid:7) 
(cid:8) 
Recall  the  deﬁnition  of  I : 
I  :=  (s, z ) ∈ IRm+1  |  there  exists  x ∈ X  for  which  s ≥ g(x) and  z ≥ f (x) 

. 

Let 

Let  C  be  the  convex  hull  of  I .  That  is,  C  is  the  smallest  convex  set 
containing  I .  From  the  assumption  that  X  is  compact  and  that  f (·) and 
g1 (·), . . . , gm (·)  are  continuous,  it  follows  that  C  is  a  closed  convex  set.  Let 
zˆ := min{z  : (0, z ) ∈ C }  , 
(cid:9)  (cid:10) 
i.e.,  ˆz  is the optimal value of the convexiﬁed primal problem, which has been 
s  of  resources  and  costs. 
convexiﬁed  in  the  column  geometry 
z 
H (u) := {(s, z ) ∈ IRm+1  : u s + z = L  (u)}  . 
∗
T 
Then  we  say  that  H (u)  supports  I  (or  C ) if  uT s +  z  ≥  L
∗ (u)  for  every 
∗ (u)  for  some  (s, z ) ∈ I  (or  C ). 
(s, z ) ∈ I  (or  C ),  and  uT s + z = L
Lemma  5  If  u ≥ 0,  then  H (u)  supports  I  and  C . 
Proof:  Let  (s, z )  ∈  I .  Then  uT s + z  ≥  uT g(x) + f (x)  for  some  x  ∈  X . 
Thus  uT s + z  ≥  inf x∈X  uT g(x) + f (x) =  L (u).  Furthermore,  setting  ¯x  = 
∗
arg  minx∈X {f (x) + u g(x)}  and  (s, z ) = (g( ¯
T 
x), f ( ¯
x)),  we  have  u s + z  = 
T
∗
L (u).  Thus  H (u)  supports  I .  But  then  H (u)  also  supports  C , since  C  is 
the  convex  hull  of  I . 
Lemma  6  (Weak  Duality)  zˆ ≥ v  . 
∗

10 

z* 

v* 

I,C 

-u 

H(u) = {(s,z)|uTs + z = L*(u)} 

Figure  1:  I ,  C , and H (u). 

Proof:  If  ˆz  = +∞,  then  we  are  done.  Otherwise,  let  (0, z )  ∈  C .  For  any 
u  ≥  0,  H (u)  supports  I  from  Lemma  5.  Therefore  L (u)  ≤  uT 0 + z  =  z . 
∗
Thus 
v  = sup L  (u) ≤ 
∗
∗
u≥0 

inf  z = ˆz . 
(0,z )∈C 

∗
Lemma  7  (Strong  Duality)  zˆ = v  . 

z  =  −∞, 
z  ≤  v 
∗ . If  ˆ
Proof:  In  view  of  Lemma  6,  it  suﬃces  to  show  that  ˆ
we  are  done.  If  not,  let  r < zˆ be  given.  Then  (0, r)  (cid:7)∈  C ,  and  so  there 
u, α)  (cid:7)
is  a  hyperplane  separating  (0, r) from  C .  Thus  there  exists  ( ¯
= (0, 0) 
and  θ  such  that  uT 0 + αr  <  θ  and  uT s + αz  ≥  θ  for  all  (s, z )  ∈  C .  This 
¯
¯

11 

u ≥  0,  α ≥  0.  If  α  (cid:7)
immediately  implies  ¯
=  0,  we  can  re-scale  so  that  α = 1. 
Then 
T¯u s + z ≥ θ > r 
for  all  (s, z ) ∈ C .  In  particular, 
for  all  x ∈ X, 
T¯u g(x) + f (x) ≥ θ > r 
(cid:7) 
(cid:8) 
∗
u) = inf x∈X  uT g(x) + f (x)  > r . Since  r  is  an 
¯
which  implies  that  L ( ¯
arbitrary  value  with  r < zˆ, we have  v  ≥ L ( ¯u) ≥ zˆ. 
∗
∗
It  remains  to  analyze  the  case  when  α  =  0.  In  this  case  we  have  θ >  0 
and  ¯uT s  ≥  θ >  0  for  all  (s, z )  ∈  C . With  (s, z ) = (g(x), f (x))  for  a  given 
x ∈ X ,  we  have  for  all  λ ≥ 0: 
L  (u) + λθ ≤ f (x) + u g(x) + λ ¯	
∗	
T u g(x) = f (x) + (u + λ ¯
u)T g(x)  . 
T
Then 

L  (u) + λθ ≤  inf	
{f (x) + (u + λ ¯
u)T g(x)} = L  (u + λ ¯
∗
∗
u)  .
x∈X
Since θ > 0 and λ was any nonnegative scalar, L (u + λ ¯u) → +∞ as λ → ∞, 
∗
and  so  v  ≥ L (u + λ ¯u)  implies  v  = +∞. Thus,  v 
∗  ≥ zˆ. 
∗
∗	
∗

2.2 	 The  Generalized  Programming  Algorithm 

Consider  the  following  algorithm: 

Generalized  Programming  Algorithm  for  Solving  the  Lagrange 
Dual  Problem 
Step  0  E k  = {x , . . . , x },  LB = −∞,  UB = +∞. 
1
k
Step  1  Solve  the  following  linear  program  (values  in  brackets  are  the  dual 
(cid:4)
variables): 
i=1 λif (xi ) 
k
(cid:4)
(cid:4)
=1 λig(xi ) ≤ 0 (u) 
k 
i
k 
i=1 λi  = 1 
(θ) 
λ ≥ 0  , 

(LPk ):  minλ

s.t.	

12 

for  λk ,  uk ,  θk ,  and  also  deﬁne: 
(cid:1) 
(cid:1)	
k	
k
k x ,  s˜k  := 
i
λi
i=1 
i=1 

˜x k  := 

k g(x i ),
λi

z˜k  := 

(cid:1) 
k 
k f (x i ) = θk . 
λi
i=1 

Step  2  (Dual  function  evaluation.)  Solve: 
{f (x) + (u k )T g(x)} 
∗
(Dk ):	 L  (u k ) = min 
x∈X 

k+1
. 
for  x
Step  3  UB := min{UB, z˜ = θk }, LB := max{LB, L (uk )}. 
∗
k	
If  UB − LB ≤ ,  stop.  Otherwise,  go  to  Step  4. 
Step  4  E k+1  := E k  ∪ {x
}, k  := k + 1,  go  to  Step  1. 
k+1

Notice  that  the  linear  programming  dual  of  (LPk ) is: 
(DPk ):  maxu,θ  θ 
−uT g(xi ) + θ ≤ f (xi )  i = 1, . . . , k 
u ≥ 0  , 

s.t.	

which  equivalently  is: 
(DPk ):  maxu,θ  θ 
θ ≤ f (xi ) + uT g(xi )  i = 1, . . . , k 
u ≥ 0  . 

s.t.	

This  can  be  re-written  as: 
(DPk ):  max  min {f (x) + u g(x)}  . 
T
u≥0  x∈E k

∗
Note that (uk+1 , θk+1 ) is always feasible in (DPk ) and (u, θ) = (u, L (u)) 
is  always  feasible  for  (DPk ) for  u ≥ 0. 
Geometrically,  the  generalized  programming  algorithm  can  be  viewed 
as  an  “inner  convexiﬁcation”  process  for  the  primal  (see  Figure  2),  and  as 
an  “outer  convexiﬁcation”  process  via  supporting  hyperplanes  for  the  dual 
problem  (see  Figure  2). 

13 

z 

C 

(g(x4), f(x4)) 

(g(x3), f(x3)) 

(g(x1), f(x1)) 

(g(x5), f(x5)) 

(g(x2), f(x2)) 

y 

Figure  2:  The  primal  geometry  of  the  generalized  programming  algorithm. 

(i)  θk  are  decreasing  in  k 

Proposition  8 
(ii)  (˜ , z˜k ) ∈ C
k
s
(iii)  uk  is  feasible  for  (D) 
(iv)  L (uk ) ≤ v
z ≤ z˜ = θk . 
∗
∗  = ˆ
k
(v)  If  f (·)  and  g1 (·), . . . , gm (·)  are  convex  functions  and X  is  a  convex  set, 
xk  is  feasible  for  (P)  and  zˆ =  z  ≤  f ( ˜
xk )  ≤  θk ,  where  z 
∗ 
∗  is  the 
then  ˜
optimal  value  of  (P). 

Proof: 

14 

V 

θ4 

f(x1)+uTg(x1) 

f(x3)+uTg(x3) 
f(x2)+uTg(x2) 
f(x4)+uTg(x4) 

f(x5)+uTg(x5) 

u4 

Figure  3:  The  dual  geometry  of  the  generalized  programming  algorithm. 

(i)  follows  since  (DPk+1 )  has  one  extra  constraint  compared  to  (DPk ),  so 
θk+1  ≤ θk . 
(ii)  follows  since  (˜ , z˜k )  is  in  the  convex  hull  of  I ,  which  is  C .
k
s
(iii)  follows  since  by  deﬁnition,  uk  ≥ 0. 
(iv) L (uk ) ≤ v  by deﬁnition of v  , and v
z by Lemma 7.  Since (˜ , z˜k ) ∈
∗  = ˆ
∗
∗ 
∗
k
s
C , and  ˜ ≤  0,  (0, z˜k )  ∈  C , and  so  ˆ
z  ≤  z˜ .  Furthermore,  z k  =  θk  follows 
sk 
k
(cid:4)
from  linear  programming  duality. 
(cid:4)
(v) Since each xi  ∈ X,  i = 1, . . . , k , then ˜
xk  ∈ X , and f ( ˜
xk ) ≤ 
i f (xi ) ≤ 
k
i=1 λk
k g(xi )  ≤  0.  Thus,  ˜k  is  feasible  for  P  and  so 
xk )  ≤ 
θk , and  g( ˜
k
x
i=1 λi
∗ z  ≤ f ( ˜xk ). 

Theorem  9  (Convergence  of  the  generalized  programming  algorithm) 
Suppose  u , u2 , . . . ,  are  the  iterate  values  of  u  computed  by  the  generalized 
1
programming  algorithm,  and  suppose  that  there  is  a  convergent  subsequence 

15 

∗
1
of  u , u2 , . . . ,  converging  to  u  .  Then 

∗
1.  u  solves  (D),  and 
∗
2.  limk→∞ θk  = ˆ = v  .
z 
Proof:  For  any  j  ≤ k  we  have 

k )T g(xj ) ≥ θk  ≥ v 
∗ 
f (xj ) + (u
Taking  limits  as  k → ∞,  we  obtain:


.


f (xj ) + (u  )T g(xj ) ≥ θ ¯ ≥ v , 
∗ 
∗
where θ ¯ := limk→∞ θk .  (This limit exists since θk  are a monotone decreasing 
sequence bounded below by v  .)  Since gi (·)  is continuous and X  is compact, 
∗
there  exists  B > 0  for  which  |gi (x)| ≤ B  for  all  x ∈ X ,  i = 1, . . . , m. Thus 
(cid:1) 
m 
, u  )| = |(u k  − u  )T g(x k+1 )| ≤ B 
|u k  − ui | .
, u k ) − L(x 
|L(x 
∗ 
∗
∗
k+1 
k+1 
i 
i=1 

For  any   >  0  and  for  k  suﬃciently  large,  the  RHS  is  bounded  above  by  . 
Thus 
k+1 )− ≥  ¯ 
θ− . 
, u  )− = f (x k+1 )+(u  )T g(x
, u k ) ≥ L(x 
∗
∗
∗
k+1 
k+1 
L  (u k ) = L(x 
Thus  in  the  limit  L (u  )  ≥  θ ¯  ≥  v
)  ≤  v  , 
∗
∗  = ˆ
∗ (u 
∗
∗
∗
z .  Therefore  since  L
∗ (u 
∗ ) = θ ¯ = v
∗  = ˆ
z . 
L

Corollary  10  If  OP  has  a  known  Slater  point  x0  and  x0  ∈ E k  for  some  k , 
then  the  sequence  of  uk  are  bounded  and  so  have  a  convergent  subsequence. 

Proof:  Without loss of generality we can assume that x0  ∈ E k  for the initial 
set  E k .  Then  for  all  k  we  have: 
g(x 0 ) + θk  ≤ f (x 0 )  , 
−(u

k )T

16 

and  g(x0 ) < 0,  from  which  it  follows  that 
∗−v	 + f (x0 )
0 ≤ (u k )i  ≤ −θk  + f (x0 )  ≤ −gi (x0 ) 
−gi (x0 ) 
Therefore u , u2 , . . . ,  lies  in a bounded  set, whereby  there must be a conver-
1
1
2
gent  subsequence  of  u , u , . . .. 

i = 1, . . . , m  . 

,

3	 Exercises  based  on  Generalized  Programming 
and  Subgradient  Optimization 

1.  Consider  the  primal  problem: 

OP :  minimumx 

T
c x 
Ax − b ≤ 0 
x ∈ {0, 1} . 
n
Here  g(x) = Ax − b  and  P  = {0, 1} = {x  | xj  = 0  or  1, j  = 1, . . . , n}. 
n

s.t. 

We  create  the  Lagrangian: 
L(x, u) := c x + u T (Ax − b)

T
and  the  dual  function:


∗
L (u)  :=  minimumx∈{0,1}n 

cT x + uT (Ax − b) 

The  dual  problem  then  is: 

∗
D :	 maximumu  L (u) 
u ≥ 0 

s.t. 

17 

u ≥  0.  Notice  that  an  optimal  solution  ¯
∗
Now  let  us  choose  ¯
u)
x  of  L ( ¯
is: 
(cid:11) 

for  j  = 1, . . . , n. Also, 

xj  = 
¯

0 if  (c − AT ¯u)j  ≥ 0 
1 if  (c − AT ¯u)j  ≤ 0 
n  (cid:12)
(cid:1) 
x − b) = − ¯
u T b − 
∗
u T (A ¯
u) = c T ¯
x + ¯
L  ( ¯
j=1 

(cid:13)−
(c − AT ¯
u)j 

. 

Also


x − b

g  := g( ¯
x) = A ¯
∗
is  a  subgradient  of  L ( ¯u). 
Now  consider  the  following  data  instance  of  this  problem: 
⎛ 
⎞
⎛
⎞ 
⎟ 
⎜
⎜ 
⎟
7  −8 
⎜ −1 ⎟ 
⎜ −2  −2 ⎟
12 
⎜ 
⎟
⎜
⎟
A = ⎜  6
5  ⎟  , b = ⎜  45 ⎟ 
⎜ 
⎟
⎜
⎟ 
⎝ −5
⎝  20 ⎠ 
6  ⎠
42 
12 
3 

and 

T c  = ( −4 1 )  . 
Solve the Lagrange dual problem of this instance using the subgradient 
algorithm  starting  at  u1  = (1, 1, 1, 1, 1)T ,  with  the  following  step-size 
choices: 
•  αk  =  k  for  k = 1, . . .. 
1
•  αk  =  √1
for  k = 1, . . .. 
k 
•  αk  = 0.2 × (0.75)k  for  k = 1, . . .. 
•  a  step-size  rule  of  your  own. 
2.  Prove Theorem  2  of  the  notes  by  using Lemma  3  and  by  following  the 
logic  used  in  the  proof  of  Theorem  1. 

18 

3.  The generalized programming algorithm assumes that the user is given 
start  vectors  x1 , . . . , xk  ∈ X  for  which 
(cid:1) 
k 
λig(x i ) ≤ 0 
i=1 
has  a  solution  for  some  λ1  ≥ 0, . . . , λk  ≥ 0  satisfying 
(cid:1) 
k 
λi  = 1  . 
i=1 

Here  we  describe  an  algorithm  for  ﬁnding  such  a  set  of  start  vectors. 
Step  0  Choose  any  k  vectors  x1 , . . . , xk  ∈ X . 
Step  1  Solve the  following  linear program, where the values  in brack-
ets  are  the  dual  variables: 

s.t. 

(LPk ) minλ,σ  σ 
(cid:4) 
λig(xi ) − eσ ≤ 0 (u) 
k 
i=1 
(cid:4) 
k 
λi  = 1 
i=1 
λ ≥ 0, σ ≥ 0


(ω) 

for  λk , σk , uk , ωk .

The  dual  of  (LPk ) is (DPk ):


s.t.	

(DPk ) maxu,ω  ω

ω ≤ uT g(xi ), i = 1, . . . , k 
eT u ≤ 1 
u ≥ 0 

19 

(cid:5) (cid:6)
Step  2  If  σk  = 0,  STOP.  Otherwise,  solve  the  optimization  problem: 
min  u
k
x∈X 

g(x)  , 

T

and  let  xk+1  be  an  optimal  solution  of  this  problem. 
Step  3  k ← k + 1.  Go  to  Step  1. 

Prove  the  following: 

a.	 LP k  and  DP k  are  always  feasible. 
b. 	 If  the  algorithm  stops,  then  it  provides  a  feasible  start  for  the 
regular  generalized  programming  problem. 
c. 	 The  sequence  of  σk  values  is  nonincreasing. 
d. 	 The  uk  vectors  all  lie  in  a  closed  and  bounded  convex  set.  What 
is  this  set? 
e. 	 There  exists  a  convergent  subsequence  of  the  uk  vectors. 
f.  Deﬁne  D (u) = minx∈X {uT g(x)}.  Show  that D (uk ) ≤ σk . 
∗	
∗

20 

