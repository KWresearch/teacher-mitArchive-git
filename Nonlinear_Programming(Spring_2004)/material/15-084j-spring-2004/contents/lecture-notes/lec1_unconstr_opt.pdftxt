Introduction  to  Optimization,  and  Optimality  
Conditions  for  Unconstrained  Problems 

Robert   M.   Freund  

February,  2004 

2004 Massachusetts Institute of Technology.

1 

1	 Preliminaries 

1.1	 Types  of  optimization  problems 

Unconstrained  Optimization  Problem: 

(P)  minx 

s.t.	

f (x) 
x ∈ X, 

where  x = (x1 , . . . , xn ) ∈ (cid:3)n ,  f (x) : (cid:3)n  → (cid:3), and X  is  an  open  set  (usually 
X  = (cid:3)n ). 
We  say  that  x  is  a  feasible  solution  of  (P)  if  x ∈ X . 
Constrained  Optimization  Problem: 

(P)	 minx 

s.t.	

f (x) 
gi (x) ≤ 0 

i = 1, . . . , m 

hi (x) = 0  i = 1, . . . , l 
x ∈ X, 

where  g1 (x), . . . , gm (x), h1 (x), . . . , hl (x) : (cid:3)n  → (cid:3). 
Let  g(x) = (g1 (x), . . . , gm (x))  :  (cid:3)n  → (cid:3)m ,  h(x) = (h1 (x), . . . , hl (x))  : 

2 

(cid:3)n  → (cid:3)l .  Then  (P)  can  be  written  as 
(P)  minx  f (x) 
g(x) ≤ 0 

s.t.	

h(x) = 0 
x ∈ X. 

(1) 

We  say  that  x  is  a  feasible  solution  of  (P)  if  g(x)  ≤  0, h(x)  =  0,  and 
x ∈ X . 

1.2 	 Local,  Global,  and  Strict  Optima 

The  bal l  centered  at  ¯x  with  radius    is  the  set: 
x, ) := {x|(cid:6)x − ¯
x(cid:6) ≤}. 
B ( ¯
Consider  the  following  optimization  problem  over  the  set  F :

f (x)

P  : minx  or  maxx 
x ∈ F 

s.t. 

We  have  the  following  deﬁnitions  of  local/global,  strict/non-strict  min-
ima/maxima. 

Deﬁnition  1.1  x  ∈ F  is  a  local  minimum  of  P  if  there  exists   >  0  such 
that  f (x) ≤ f (y)  for  al l  y ∈ B (x, ) ∩ F . 

Deﬁnition  1.2  x  ∈ F  is  a  global  minimum  of  P  if  f (x)  ≤  f (y)  for  al l 
y ∈ F . 

3 

Deﬁnition  1.3  x ∈ F  is  a  strict  local  minimum  of  P  if  there  exists   >  0 
such  that  f (x) < f (y)  for  al l  y ∈ B (x, ) ∩ F ,  y  (cid:8)= x. 
Deﬁnition  1.4  x  ∈ F  is  a  strict  global  minimum  of  P  if  f (x)  < f (y)  for 
al l  y ∈ F ,  y  (cid:8)= x. 
Deﬁnition  1.5  x  ∈ F  is  a  local  maximum  of  P  if  there  exists   >  0  such 
that  f (x) ≥ f (y)  for  al l  y ∈ B (x, ) ∩ F . 
Deﬁnition  1.6  x  ∈ F  is  a  global  maximum  of  P  if  f (x)  ≥  f (y)  for  al l 
y ∈ F . 
Deﬁnition  1.7  x ∈ F  is  a  strict  local  maximum  of  P  if  there  exists   > 0 
such  that  f (x) > f (y)  for  al l  y ∈ B (x, ) ∩ F ,  y  (cid:8)= x. 
Deﬁnition  1.8  x ∈ F  is  a  strict  global  maximum  of  P  if  f (x) > f (y)  for 
al l  y ∈ F ,  y  (cid:8)= x. 

1.3  Gradients  and  Hessians 
Let  f (x) : X  → (cid:3),  where  X  ⊂ (cid:3)n  is  open.  f (x) is  diﬀerentiable  at  ¯x  ∈ X 
if  there  exists  a  vector ∇f ( ¯
x)  (the  gradient  of  f (x) at  ¯
x)  such  that  for  each 
x ∈ X 

x) + ∇f ( ¯
x, x − ¯
x) + (cid:6)x − ¯
x(cid:6)α( ¯
x)t (x − ¯
f (x) = f ( ¯
x),

and  limy→0  α( ¯x, y) = 0.  f (x) is  diﬀerentiable  on  X  if  f (x)  is  diﬀerentiable 
for  all  ¯x ∈ X .  The  gradient  vector  is  the  vector  of  partial  derivatives: 
(cid:2)t 
(cid:1)

∇f ( ¯x) = 

. 

x) 
∂ f ( ¯
, . . . , 
∂x1 

∂ f ( ¯
x)
∂xn 

(cid:3)
Example   1   Let  f (x) = 3(x1 )2 (x2 )3  + (x2 )2 (x3 )3  .  Then 
∇f (x) =  6(x1 )(x2 )3  , 9(x1 )2 (x2 )2  + 2(x2 )(x3 )3  , 3(x2 )2 (x3 )2 

(cid:4)T 

. 

4 

The  directional  derivative  of  f (x) at  ¯x  in  the  direction  d  is: 
x + λd) − f ( ¯
= ∇f ( ¯
f ( ¯
x) 
x)td
lim 
λ→0 
λ 
The  function f (x) is  twice  diﬀerentiable at  ¯x ∈ X  if  there  exists a vector 
∇f ( ¯
x) and an n × n symmetric matrix H ( ¯
x)  (the Hessian of f (x) at  ¯
x) such 
that  for  each  x ∈ X 

x)t (x − ¯
x) + ∇f ( ¯
x) + 
f (x) = f ( ¯

(x − ¯
x, x − ¯
x) + (cid:6)x − ¯
x(cid:6)2α( ¯
x)(x − ¯
1 
x)tH ( ¯
x),
2

and  limy→0  α( ¯x, y) = 0.  f (x) is  twice  diﬀerentiable  on  X  if  f (x) is twice 
diﬀerentiable  for  all  x  ∈  X .  The  Hessian  is  the  matrix  of  second  partial 
¯
derivatives: 

H ( ¯x)ij  = 

∂ 2f ( ¯
x) 
. 
∂xi∂xj 

⎛ 
Example   2   Continuing  Example  1,  we  have 
H (x) = ⎝ 18(x1 )(x2 )2 
6(x2 )3 
0 

18(x1 )(x2 )2 
18(x1 )2 (x2 ) + 2(x3 )3 
6(x2 )(x3 )2 

⎞ 
6(x2 )(x3 )2  ⎠  . 
0 
6(x2 )2 (x3 ) 

1.4  Positive   Semideﬁnite  and  Positive  Deﬁnite   Matrices 
An  n × n  matrix M  is  called 

•  positive  deﬁnite  if  xtM x > 0  for  all  x ∈ (cid:3)n , x  (cid:8)= 0 
•  positive  semideﬁnite  if  xtM x ≥ 0  for  all  x ∈ (cid:3)
n
•  negative  deﬁnite  if  xtM x < 0  for  all  x ∈ (cid:3)n , x  (cid:8)= 0 
•  negative  semideﬁnite  if  xtM x ≤ 0  for  all  x ∈ (cid:3)n , x  (cid:8)= 0 

5 

•  indeﬁnite  if  there  exists  x, y ∈ (cid:3)n  for  which  xtM x > 0 and  y tM y < 0 

We say that M  is SPD if M  is symmetric and positive deﬁnite.  Similarly, 
we  say  that M  is  SPSD  if M  is  symmetric  and  positive  semi-deﬁnite. 
(cid:2) 
(cid:1) 
2
0 
M  =  0
3 

Example   3  

is  positive  deﬁnite. 

Example   4  

(cid:1) 
(cid:2) 
8  −1 
M  =  −1
1 
is  positive  deﬁnite.  To  see  this,  note  that  for  x  (cid:8)= 0, 
x T M x = 8x1  − 2x1x2  + x  = 7x1  + (x1  − x2 )2  > 0  .
2
2 
2 
2 

1.5  Existence  of  Optimal  Solutions 

Most  of  the  topics  of  this  course  are  concerned  with 
•  existence  of  optimal  solutions, 
•  characterization  of  optimal  solutions,  and 
•  algorithms  for  computing  optimal  solutions. 

To illustrate the questions arising in the ﬁrst topic, consider the following 
optimization  problems: 
• 

1 + x
(P)  minx 
2x 
s.t.  x ≥ 1  . 

6 

• 

• 

Here  there  is  no  optimal  solution  because  the  feasible  region  is  un-
bounded 

(P)  minx 

1
x 
1 ≤ x <2  . 
s.t. 
Here  there  is  no  optimal  solution  because  the  feasible  region  is  not 
closed. 

f (x) 
1 ≤ x ≤ 2  ,


(P)  minx 
s.t. 
(cid:9)


where 

1/x,  x < 2 
f (x) = 
1,
x = 2  . 
Here  there  is  no  optimal  solution  because  the  function  f (·) is not 
suﬃciently  smooth. 

Theorem   1   (Weierstrass’   Theorem   for   sequences)   Let  {xk }, k → ∞ 
be  an  inﬁnite  sequence  of  points  in  the  compact  (i.e.,  closed  and  bounded) 
set  F .  Then  some  inﬁnite  subsequence  of  points  xkj  converges  to  a  point 
contained  in  F . 

Theorem  2   (Weierstrass’  Theorem  for  functions)  Let  f (x)  be  a  con-
tinuous  real-valued  function  on  the  compact  nonempty  set  F  ⊂ (cid:3)n .  Then  F 
contains  a  point  that  minimizes  (maximizes)  f (x)  on  the  set  F . 

Proof:   Since  the  set  F  is  bounded,  f (x)  is  bounded  below  on  F . Since 
F  (cid:8)=  ∅,  there  exists  v  = inf x∈F  f (x).  By  deﬁnition,  for  any   >  0,  the  set 
F  = {x ∈ F  : v ≤ f (x) ≤ v + } is non-empty.  Let k  → 0 as k → ∞, and let 
xk  ∈ F . Since F  is bounded, there exists a subsequence of {xk } converging 
k
x ∈ F .  By  continuity  of  f (x),  we  have  f ( ¯
x) =  limk→∞ f (xk ),  and, 
to  some  ¯
since  v ≤ f (xk ) ≤ v + k ,  it  follows  that  f ( ¯x) =  limk→∞ f (xk ) = v . 

7 

The assumptions of Weierstrass’ Theorem can be somewhat relaxed.  For 
example,  for  a minimization  problem,  we  can  assume  that 
(cid:4) )}  is  compact  for  some  x
(cid:4)  ∈ F , and 
•	 the  set  {x ∈ F  : f (x) ≤ f (x
•	 f (x) is  lower  semi-continuous,  i.e.,  for any constant c,  the set {x ∈ F  : 
f (x) ≤ c}  is  closed. 

The  proof  is  similar  to  the  proof  of  the Weierstrass’  Theorem. 

8 

2	 Optimality  Conditions  for  Unconstrained  Prob­
lems 

(P)  min 
f (x) 
s.t.	 x ∈ X, 

where  x = (x1 , . . . , xn ) ∈ (cid:3)n ,  f (x) : (cid:3)n  → (cid:3), and X  is  an  open  set  (usually 
X  = (cid:3)n ). 

Deﬁnition  2.1  The direction d ¯ is cal led a descent direction of f (x) at x = ¯x 
if 

x + d¯) < f ( ¯
f ( ¯
x)  for  all   > 0  and  suﬃciently  small  . 

A necessary  condition  for  local optimality  is a  statement of  the  form:  “if 
¯
x must satisfy . . . ”  Such a condition helps 
x is a local minimum of (P), then  ¯
us  identify  all  candidates  for  local  optima. 

Theorem  3   Suppose  that  f (x)  is  diﬀerentiable  at  ¯x.  If  there  is  a  vector  d 
such  that ∇f ( ¯
x)td < 0,  then  for al l λ > 0 and  suﬃciently  smal l,  f ( ¯
x + λd) <
x.
x),  and  hence  d  is  a  descent  direction  of  f (x)  at  ¯
f ( ¯

Proof:   We  have: 

x)td + λ(cid:6)d(cid:6)α( ¯
x) + λ∇f ( ¯
x, λd),
f ( ¯
x + λd) = f ( ¯
where  α( ¯x, λd) → 0 as  λ → 0.  Rearranging,

x + λd) − f ( ¯
= ∇f ( ¯
x)td + (cid:6)d(cid:6)α( ¯
f ( ¯
x)

x, λd).
λ 
x + λd) − f ( ¯
x, λd) → 0 as  λ → 0,  f ( ¯
Since ∇f ( ¯
x)td < 0 and  α( ¯
x) < 0  for  all 
λ > 0  suﬃciently  small. 

Corollary  4   Suppose  f (x)  is  diﬀerentiable  at  ¯
x  is  a  local  minimum, 
x. If  ¯
then  ∇f ( ¯x) = 0. 

9 

Proof:   If it were true that ∇f ( ¯ = 0, then d = −∇f ( ¯
x)  (cid:8)
x) would be a descent 
direction,  whereby  ¯x  would  not  be  a  local minimum. 

The  above  corollary  is  a  ﬁrst  order  necessary  optimality  condition  for 
an  unconstrained minimization  problem.  The  following  theorem  is  a  second 
order  necessary  optimality  condition 
Theorem  5  Suppose that f (x) is twice continuously diﬀerentiable at  ¯x ∈ X . 
x  is  a  local  minimum,  then  ∇f ( ¯
If  ¯
x) = 0  and  H ( ¯
x)  is  positive  semideﬁnite. 
Proof:   From the ﬁrst order necessary condition, ∇f ( ¯
x) = 0.  Suppose H ( ¯
x)
is  not  positive  semi-deﬁnite.  Then  there  exists  d  such  that  dtH ( ¯x)d <  0. 
We  have: 

x)d + λ2(cid:6)d(cid:6)2α( ¯
x) + λ∇f ( ¯
1 
x)td +  λ2dtH ( ¯
x, λd)
f ( ¯
x + λd) = f ( ¯
2 
x)d + λ2(cid:6)d(cid:6)2α( ¯
1 
x) +  λ2dtH ( ¯
x, λd),
= f ( ¯
2 
where  α( ¯x, λd) → 0 as  λ → 0.  Rearranging, 
x + λd) − f ( ¯
x)d + (cid:6)d(cid:6)2α( ¯
1 
f ( ¯
x)
=  dtH ( ¯
x, λd). 
λ2 
2 
x + λd) − f ( ¯
x, λd) → 0 as  λ → 0,  f ( ¯
Since  dtH ( ¯
x)d < 0 and  α( ¯
x) < 0  for  all 
λ > 0  suﬃciently  small,  yielding  the  desired  contradiction. 

Example   5   Let 

Then 

and 

, 

f (x) = 

∇f (x) = 

2  − 4x1  − 4x2  − x 3 
1 
1  + x1x2  + 2x 2 
x 2 
2  . 
2 
(cid:4)T 
(cid:3) 
x1  + x2  − 4, x1  + 4x2  − 4 − 3x 2 
(cid:1) 1 
(cid:2) 
2 
1 
4 − 6x2 
H (x) = 
.
1
∇f (x) = 0  has  exactly  two  solutions:  x = (4, 0)  and  ˜
(cid:1) 
(cid:2) 
x = (3, 1). But 
¯
1 
1
H ( ˜x) =  1  −2 

10 

is  indeﬁnite,  therefore,  the  only  possible  candidate  for  a  local  minimum  is 
¯x = (4, 0). 

A  suﬃcient  condition  for  local  optimality  is  a  statement  of  the  form:  “if 
¯
x  is  a  local  minimum  of  (P).”  Such  a  condition  allows 
x  satisﬁes  . . . ,  then  ¯
us  to  automatically  declare  that  ¯x  is  indeed  a  local minimum. 

Theorem  6  Suppose  that  f (x)  is  twice  diﬀerentiable  at  x. If  ∇f ( ¯
x) = 0
¯
x  is  a  (strict)  local  minimum. 
and  H ( ¯
x)  is  positive  deﬁnite,  then  ¯

Proof:  

f (x) = f ( ¯
x) + 

(x − ¯
x, x − ¯
x) + (cid:6)x − ¯
x(cid:6)2α( ¯
x)(x − ¯
1 
x)tH ( ¯
x). 
2
Suppose  that  ¯x  is  not  a  strict  local minimum.  Then  there  exists  a  sequence 
xk  →  ¯
x  such  that  xk  (cid:8) x  and  f (xk )  ≤  f ( ¯
xk− ¯
x 
x)  for  all  k . Deﬁne  dk  =  (cid:5)xk− ¯ .
= ¯
x(cid:5) 
(cid:2) 
(cid:1) 
Then 
x, xk  − ¯
1 
dt 
k H ( ¯
x)dk  + α( ¯
x) 
2 

x) + (cid:6)xk  − ¯
x(cid:6)2 
f (xk ) = f ( ¯

,

and  so 

f (xk ) − f ( ¯x)
≤ 0  .
x, xk  − ¯
1 
dt 
(cid:6)xk  − ¯
x(cid:6)2
x)dk  + α( ¯
x) = 
k H ( ¯
2 
Since  (cid:6)dk (cid:6) = 1  for  any  k ,  there  exists  a  subsequence  of  {dk }  converging  to 
some  point  d  such  that  (cid:6)d(cid:6)  =  1.  Assume  without  loss  of  generality  that 
dk  → d.  Then 
x, xk  − ¯
0 ≥  lim  k H ( ¯
1 
dt 
x) =  dtH ( ¯
x)dk  + α( ¯
x)d, 
k→∞ 
2 

which  is  a  contradiction  of  the  positive  deﬁniteness  of H ( ¯x). 

Note: 
•  If ∇f ( ¯
x) is negative deﬁnite, then  ¯
x) = 0 and H ( ¯
x is a local maximum. 
•  If  ∇f ( ¯
x)  is  positive  semideﬁnite,  we  cannot  be  sure  if 
x) = 0  and  H ( ¯

¯
x  is  a  local minimum. 

11 

(cid:2) 
(cid:1) 
Example   6   Continuing  Example  5,  we  compute 
1 
1
H ( ¯x) =  1
4 
is  positive  deﬁnite.  To  see  this,  note  that  for  any  d = (d1 , d2 ),  we  have 
2  > 0  for  al l  d  (cid:8)
dT H ( ¯
x)d = d2  + 2d1d2  + 4d2
2  = (d1  + d2 )2  + 3d2 
= 0  .
1 
Therefore,  x  satisﬁes  the  suﬃcient  conditions  to  be  a  local  minimum,  and 
¯
so  ¯x  is  a  local  minimum. 

Example   7   Let 

, 

and 

Then 

3
2
f (x) = x1  + x2  . 
(cid:3)
(cid:4)T
∇f (x) =  3x1 , 2x2 
2
(cid:2) 
(cid:1)
0 
6x1 
H (x) = 
2

0
(cid:2) 
(cid:1) 
x = (0, 0),  we  have  ∇f ( ¯

At  ¯
x) = 0  and 
0 
0
H ( ¯x) =  0
2 
is  positive  semi-deﬁnite,  but  x  is  not  a  local  minimum,  since  f (−, 0)  = 
¯
−3  < 0 =f (0, 0) = f ( ¯x) for  al l   > 0. 

.

Example   8   Let 

, 

and 

Then 

2
4
f (x) = x1  + x2  . 
(cid:4)T
(cid:3)
∇f (x) =  4x1 , 2x2 
3
(cid:1)
(cid:2)
2 
0 
12
x1 
H (x) = 
2 
0 
(cid:2) 
(cid:1) 
x = (0, 0),  we  have  ∇f ( ¯
At  ¯
x) = 0  and 
0 
0
H ( ¯x) =  0
2 
is  positive  semi-deﬁnite.  Furthermore,  ¯x  is  a  local  minimum,  since  for  al l  x 
we  have  f (x) ≥ 0 = f (0, 0) = f ( ¯x). 

. 

12 

2.1  Convexity  and  Minimization 

•	 Let x, y ∈ (cid:3)n .  Points of  the  form λx + (1 − λ)y  for λ ∈ [0, 1] are  called 
convex  combinations  of  x  and  y  . 
•	 A set  S  ⊂ (cid:3)n  is  called  a  convex  set  if  for  all  x, y  ∈ S  and  for  all 
λ ∈ [0, 1]  it  holds  that  λx + (1 − λ)y ∈ S . 
•	 A  function  f (x) :  S  → (cid:3),  where  S  is  a  nonempty  convex  set,  is  a 
convex  function  if 
f (λx + (1 − λ)y) ≤ λf (x) + (1 − λ)f (y)

for  all  x, y ∈ S  and  for  all  λ ∈ [0, 1].

•	 A  function  f (x)  as  above  is  called  a  strictly  convex  function  if  the 
inequality  above  is  strict  for  all  x  (cid:8)= y  and  λ ∈ (0, 1). 
•	 A  function  f (x) :  S  → (cid:3),  where  S  is  a  nonempty  convex  set,  is  a 
concave  function  if 
f (λx + (1 − λ)y) ≥ λf (x) + (1 − λ)f (y)

for  all  x, y ∈ S  and  for  all  λ ∈ [0, 1].

•	 A  function  f (x)  as  above  is  called  a  strictly  concave  function  if  the 
inequality  above  is  strict  for  all  x  (cid:8)= y  and  λ ∈ (0, 1). 

Consider  the  problem: 

f (x) 
(CP)  minx 
s.t.  x ∈ S . 

13 

Theorem  7  Suppose  S  is  a  convex  set,  f (x) : S → (cid:3) is  a  convex  function, 
and  ¯
x  is  a  global minimum  of  f (x)  over
x  is  a  local minimum  of  (CP). Then  ¯
S . 
Proof:   Suppose  ¯x is not a global minimum, i.e., there exists y ∈ S  for which 
x + (1 − λ)y ,  which  is  a  convex  combination  of 
f (y)  < f ( ¯
x).  Let  y(λ) :=  λ ¯
¯x  and  y  for  λ  ∈  [0, 1]  (and  therefore,  y(λ)  ∈  S  for  λ  ∈  [0, 1]).  Note  that 
y(λ) → ¯x  as  λ → 0. 
From  the  convexity  of  f (x), 
x+(1−λ)y) ≤ λf ( ¯	
x)+(1−λ)f ( ¯
x)+(1−λ)f (y) < λf ( ¯
f (y(λ)) = f (λ ¯	
x) 
x) = f ( ¯
for  all  λ  ∈ (0, 1).  Therefore,  f (y(λ))  < f ( ¯	
x)  for  all  λ  ∈ (0, 1),  and  so  ¯
x  is
not  a  local minimum,  resulting  in  a  contradiction. 

Note: 
•	 If  f (x)  is  strictly  convex,  a  local  minimum  is  the  unique  global  mini-
mum. 
•	 If  f (x)  is  concave,  a  local maximum  is  a  global  maximum. 
•	 If  f (x)  is  strictly  concave,  a  local maximum  is  the  unique  global max-
imum. 
Theorem  8   Suppose  S  is  a  non-empty  open  convex  set,  and  f (x) : S → (cid:3) 
is  diﬀerentiable.  Then  f (x)  is  a  convex  function  if  and  only  if  f (x)  satisﬁes 
the  fol lowing  gradient  inequality: 

f (y) ≥ f (x) + ∇f (x)t (y − x)  for  al l  x, y ∈ S. 
Proof:   Suppose  f (x)  is  convex.  Then  for  any  λ ∈ [0, 1], 

f (λy + (1 − λ)x) ≤ λf (y) + (1 − λ)f (x) 
which  implies  that 
f (x + λ(y − x)) − f (x)  ≤ f (y) − f (x)  . 
λ 

14 

Letting  λ  →  0,  we  obtain:  ∇f (x)t (y − x)  ≤  f (y) − f (x),  establishing  the 
“only  if ”  part. 
Now,  suppose  that  the  gradient  inequality  holds  for  all  x, y  ∈ S . Let  w 
and  z  be  any  two  points  in  S . Let  λ  ∈  [0, 1],  and  set  x  =  λw + (1 − λ)z . 
Then 

f (w) ≥ f (x) + ∇f (x)t (w − x) and  f (z ) ≥ f (x) + ∇f (x)t (z − x). 
Taking  a  convex  combination  of  the  above  inequalities,  we  obtain 

λf (w) + (1 − λ)f (z )  ≥  f (x) + ∇f (x)t (λ(w − x) + (1 − λ)(z − x)) 
=  f (x) + ∇f (x)t0 
=  f (λw + (1 − λ)z )  , 
which  shows  that  f (x)  is  convex. 
Theorem  9  Suppose  S  is  a  non-empty  open  convex  set,  and  f (x) : S → (cid:3) 
is  twice  diﬀerentiable.  Let  H (x)  denote  the  Hessian  of  f (x).  Then  f (x)  is 
convex  if  and  only  if  H (x)  is  positive  semideﬁnite  for  al l  x ∈ S . 
Proof:   Suppose  f (x)  is  convex.  Let  ¯x  ∈ S  and  d  be  any  direction.  Then 
for  λ > 0  suﬃciently  small,  ¯x + λd ∈ S . We  have: 

x)(λd) + (cid:6)λd(cid:6)2α( ¯
x) + ∇f ( ¯
1 
(λd)tH ( ¯
x)t (λd) + 
x, λd), 
f ( ¯
x + λd) = f ( ¯
2
where  α( ¯x, y) → 0 as  y → 0.  Using  the  gradient  inequality,  we  obtain 
(cid:1) 
(cid:2) 
x)d + (cid:6)d(cid:6)2α( ¯
x, λd)  ≥ 0.
1 
λ2 
dtH ( ¯
2 
Dividing  by  λ2  > 0  and  letting  λ → 0,  we  obtain  dtH ( ¯x)d ≥ 0,  proving  the 
“only  if ”  part. 

15 

Conversely,  suppose  that H (z )  is  positive  semideﬁnite  for  all  z  ∈ S . Let 
x, y ∈ S  be arbitrary.  Invoking the second-order version of Taylor’s theorem, 
we  have: 

f (y) = f (x) + ∇f (x)t (y − x) + 
(y − x)tH (z )(y − x) 
1 
2
for  some  z  which  is  a  convex  combination  of  x  and  y  (and  hence  z  ∈ S ). 
Since  H (z )  is  positive  semideﬁnite,  this  means  that 
f (y) ≥ f (x) + ∇f (x)t (y − x)  . 

Therefore  the  gradient  inequality  holds,  and  hence  f (x)  is  convex. 

Returning  to  the  optimization  problem  (P),  knowing  that  the  function 
f (x)  is  convex  allows  us  to  establish  a  global  optimality  condition  that  is 
both  necessary  and  suﬃcient: 

Theorem  10   Suppose  f (x) :  X  → (cid:3) is  convex  and  diﬀerentiable  on  X . 
x ∈ X  is  a  global  minimum  if  and  only  if  ∇f ( ¯
Then  ¯
x) = 0. 

Proof:   The  necessity  of  the  condition ∇f ( ¯x) = 0 was  established  in Corol-
lary  4  regardless  of  the  convexity  of  the  function  f (x). 
Suppose  ∇f ( ¯x)  =  0.  Then  by  the  gradient  inequality  we  have  f (y)  ≥ 
x)  for all y ∈ X , and  so  ¯
x)t (y − x) = f ( ¯
x) + ∇f ( ¯
¯
x  is a global minimum. 
f ( ¯
(cid:1) 
(cid:2) 
Example   9   Continuing  Example  5,  recal l  that 
1 
1
4 − 6x2 
H (x) =  1
. 
Suppose  that  the  domain  of  of  f (·)  is  X  = {(x1 , x2 )  | x2  < 0}.  Then  f (·)  is 
a  convex  function  on  this  domain. 

Example  10  Let 
f (x) = − ln(1 − x1  − x2 ) − ln x1  − ln x2  . 

16 

⎡ 
⎢
∇f (x) = ⎣
(cid:4)2 

(cid:3)

1 
1−x1−x2 

⎤ 
⎥
⎦ , 

−  1 
x1 
−  1 
(cid:3) 
x2 
1 
1−x1−x2 
(cid:4)2

Then 

and 

1 
1−x1−x2 
(cid:3) (cid:4)2 
1
+ 
(cid:4)2 
x1 

⎡
⎢ 
⎢
H (x) = ⎢
⎣

⎤ 
(cid:4)2
⎥ 
⎥
⎥ . 
1 
1−x1−x2 
(cid:3) 
(cid:3) 
(cid:3) (cid:4)2  ⎦
1 
1
1 
+ 
1−x1−x2 
1−x1−x2 
x2 
(cid:3) 
(cid:4) 
It  is  actual ly  easy  to  prove  that  f (x)  is  a  strictly  convex  function,  and  hence 
that  H (x)  is  positive  deﬁnite  on  its  domain  X  =  {(x1 , x2 )  |  x1  >  0, x2  > 
0, x1  + x2  <  1}. At  ¯
1 1  we  have  ∇f ( ¯
x) = 0, and  so  ¯
x  is  the  unique 
x =  3 ,
3 
global  minimum  of  f (x). 

3  Exercises  on  Unconstrained  Optimization 

1.  Find points satisfying necessary conditions for extrema (i.e., local min-
ima  or  local  maxima)  of  the  function 

f (x) = 

x1  + x2 
2
3 + x2  + x2  + x1x2 
1 

. 

Try  to  establish  the  nature  of  these  points  by  checking  suﬃcient  con-
ditions. 

2.  Find  minima  of  the  function 
f (x) = (x2  − x1 )2 
2
among  all  the  points  satisfying  necessary  conditions  for  an  extremum. 
3.  Consider  the  problem  to  minimize  (cid:6)Ax − b(cid:6)2 ,  where  A  is  an  m × n 
matrix  and  b  is  an m  vector. 
a.   Give  a  geometric  interpretation  of  the  problem. 
b.  Write  a  necessary  condition  for  optimality  .  Is  this  also  a  suﬃcient 
condition? 

17 

c. 	 Is  the  optimal  solution  unique?  Why  or  why  not? 
d.  Can you give a closed form solution of the optimal solution?  Specify 
any  assumptions  that  you may  need. 
⎛ ⎞ 
⎛ 
⎞
e.	 Solve  the  problem  for  A  and  b  given  below: 
⎜ 
⎟
⎜ ⎟ 
1	 −1 0 
⎜	 0 
2 1  ⎟
⎜  1  ⎟
2 
⎟ , b = ⎜ ⎟ . 
A = ⎜
⎝  1  ⎠ 
1 0  ⎠
⎝	 0 
1
0 1 
0 
4.  Let  S  be  a  nonempty  set  in  (cid:3)n .  Show  that  S  is  convex  if  and  only  if 
for  each  integer  k ≥ 2  the  following  holds  true: 
(cid:18) 
k 
λj xj  ∈ S 
j=1 
(cid:19) 
k 
j=1


whenever  λ1 , . . . , λk  satisfy  λ1 , . . . , λk  ≥ 0 and 
∗
5.  Bertsekas,  Exercise  1.1.1,  page  16.  (Note:  x 
point  of  f (·) if ∇f (x  ) = 0.) 
∗
6.  Bertsekas,  Exercise  1.1.2,  page  16,  parts  (a),  (b),  (c),  and  (d).  (Note: 
is  called  a  stationary  point  of  f (·) if ∇f (x  ) = 0.) 
∗	
∗
x	

1 x  , . . . , x k  ∈ S  ⇒ 

λj  = 1.


is  called  a  stationary 

18 

