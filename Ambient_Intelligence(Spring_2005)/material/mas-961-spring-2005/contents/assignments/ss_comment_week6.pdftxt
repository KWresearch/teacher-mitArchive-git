Sajid Sadi 

Comments for Week 6  
Generic User Modeling Systems Link  

Even though the authors mention this rather early, I will point out one of the flaws of 
these early system shared by much of AI research: the systems are designed as reasoning 
engines, meant to answer specific queries about users. This would be a hard task even for 
a real human, never mind the primitive imitations of human intellect we can muster up 
even today. This is reflected in the fact that these systems are based around stereotype-
based reasoning. I would not go so far as to say that it’s a bad way to approach the 
problem, but over-dependence on stereotypes is indicative of rejection of the very 
individuality that is of most interest to such modeling systems. However, it is difficult to 
answer queries against data one does not possess, and given the limitations on what data 
these sorts of systems can possess today, it is a required tool for anything to get done at 
all. Another artifact of this approach is the lack of ability to handle incongruencies 
between different inputs (which would of course play havoc with a logical inference 
system). Those paper represented here that do not go quite so far (i.e., Kay, 1995) are 
considerably simpler systems, and I have a feeling that they are merely meant as backend 
to the sort of inference engines the others incorporate directly. These methods may be 
quite successful with expert systems, but I am (at least prima fascia) quite leery of them 
in this context.  

In terms of the commercialized systems, I believe that they ultimately suffer from the 
same flaws that I mentioned last week during my presentation. Essentially, the existence 
of these models remove control of the user’s data from the user, and to me this is 
absolutely the wrong way to go in terms of privacy and accessibility of the information. 
At the end of the day, if the user is not in control of the data, then the data may as well 
not exist at all, because it might just cease to exist, and the user will have neither control 
nor warning over that. Additionally, trusting a business with something that can make 
them a lot of money if they misused it is like having the fox guard the chicken coop… 
eventually one fox or another will have a nice dinner at the user’s expense. Instead, 
revenue models need to be explored that center around the privacy of the user, because 
when (and only when) the user has control of the data will enough of this data that now 
hides in proprietary nooks and crannies become available for us to be able to do some 
actual work with it, and focus on the service provided by these systems and companies, 
instead of worrying about who is hoarding the most data first. 

