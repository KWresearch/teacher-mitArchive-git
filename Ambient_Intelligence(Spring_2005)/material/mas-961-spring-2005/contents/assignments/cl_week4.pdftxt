Christine Liu 

week 4 :: common sense 

Beating Common Sense into Interactive Applications, Lieberman et. al.  

Common-sense reasoning seems to put the everyday human knowledge base into 
computers, enabling more realistic and rational reasoning + problem-solving. I think this 
is useful for basic logic-based chaining and more 'unbiased' material, but putting it into 
the realm of personal communication and more artistic + poetic arenas makes me really 
uncomfortable. Some examples:  

•	

•	

•	

art-, film-, music-makers. The DJ application is completely redundant. The 
artistry is precisely in choosing "what kind of music particular groups like" and 
seeing the reaction of the people on the dance floor. It's a subtle skill... a lot more 
than superficial things are taken into account, like the type of club + location, the 
hour of the evening, smiles on people's faces, and special circumstances like 
guests or occasions. Increased/decreased activity isn't the only crucial dancefloor 
feedback; there's a rhythmic ebb + flow to keep things interesting, unpredictable, 
human. For the same artistically-blind reasons, I feel that rule-based algorithms 
(no matter how context-aware or common-sense) detract much depth-plumbing 
humanity from crafting films, art, literature, etc.  
predictive typing for messaging. I have never used the predictive word-
completion utility on my phone txtmsg because it never writes what I want! Even 
if it does "make perfect sense." Maybe it's just me, but I'd rather have slower, 
fuller control than short spurts of correctness interspersed with an exasperatingly 
wrong word. Even in the paper, the image features a grossly erroneous grammatic 
error: "i am am at the train st." Why doesn't the application realize that's 
senseless? 
empathetic email. I don't understand why the affective faces interacting with an 
email-composer assist the user. Perhaps it might point out newbie mistakes ("all (cid:173)
caps indicates shouting," "avoid emoticons and txtmsg abbreviations in a business 
message"), but the agent cannot readily detect more sophisticated aspects of 
language such as sarcasm, poetry, and the nuanced relationship between writer 
and reader. Modeling point-of-view and personality might help, but it's still 
difficult to accommodate individual complexities on the level of communication. 
Amazon recommending a book is one thing; telling me how my best friend might 
react to my email is another.  

Because many tasks are underconstrained and "a little bit of knowledge is better than 
nothing," I agree that common-sense applications can help steer the user into the right 
direction (a la funnelcake). However, I'm still very skeptical. AskJeeves seemed to invite 
more casual search queries like "how do I [verb] [object]?", but it still returned results of 
mixed quality or relevance. I suppose the challenge is to highlight the helpful while 
hiding the horrible. Somehow we are trained to take a real-life human's words with a 
grain of salt, but we put incredible trust into machines. Can we build forgiveness into the 
system? 

