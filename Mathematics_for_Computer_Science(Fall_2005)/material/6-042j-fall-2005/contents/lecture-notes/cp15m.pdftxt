Massachusetts Institute of Technology 
6.042J/18.062J, Fall ’05: Mathematics for Computer Science 
Prof. Albert R. Meyer and Prof. Ronitt Rubinfeld 

December 12 
revised December 12, 2005, 1019 minutes 

In­Class Problems Week 15, Mon. 

Problem 1.  The Pairwise Independent Sampling Theorem generalizes easily to sequences 
of pairwise  independent  random variables, possibly with different means and variances, 
as long as their variances are bounded by some constant: 

Theorem (Generalized Pairwise Independent Sampling).  Let X1 , X2 , . . .  be a sequence of 
pairwise independent random variables such that Var [Xi ] ≤ b for some b ≥ 0  and all i ≥ 1.  Let 
· · ·

+  Xn

, 

An  ::= 

X1  +  X2  +
n 

µn  ::=  E [Sn ] . 

Then for every � > 0, 

�2  · 
b 
(a)  Prove the Generalized Pairwise Independent Sampling Theorem.  Hint:  The proof of 
the Pairwise Independent Sampling Theorem from the Notes is repeated in the Appendix. 

Pr {|An  − µ | > �} ≤ 
n

(1)

1 
n 

. 

(b)  Conclude 

Corollary (Generalized Weak Law of Large Numbers).  For every � > 0, 
lim  Pr {|An  − µn > �} = 0.
|
n→∞ 

Problem 2.  Write out a proof that 

Var [aR] =  a 2  Var [R] . 

Problem 3.  Finish discussing the “Explain sampling to a jury question” from last Friday. 

Copyright © 2005, Prof. Albert R. Meyer and Prof. Ronitt Rubinfeld. 

In­Class Problems Week 15, Mon. 
1  Appendix 

1.1  Chebyshev’s Theorem 

2 

Theorem (Chebyshev).  Let R be a random variable, and let x be a positive real number. Then 
Pr {|R − E [R]| ≥ x} ≤ 

. 

(2)

Var [R] 
x2 

1.2  Pairwise Independent Sampling 

Var [R1  +  R2  +

Theorem  (Pairwise  Independent  Linearity  of  Variance).  If  R1 , R2 , . . . , Rn  are  pairwise 
independent random variables, then 
· · ·
+  Rn ] =  Var [R1 ] +  Var [R2 ] + 
� 
Theorem (Pairwise Independent Sampling).  Let 
n  Gi
i=1 
n 
� σ �2  1 
where G1 , . . . , Gn  are pairwise  independent random variables with the same mean, µ, and devia­
tion, σ . Then 
· 
x 
n 

+  Var [Rn ] .

An  ::= 

· · ·

(3)

. 

= 

E [ 

=  µ. 

nµ 
n 

Pr {|An  − µ| > x} ≤ 
� 
� 
Proof.  By linearity of expectation, 
n
n
E [Gi ]
Gi ]
E [An ] = 
i=1
i=1 
= 
n
n 
� 
��n
� �2 
Since the Gi ’s are pairwise independent, their variances will also add, so 
1
� �2  �1 
Var 
n 
i=1 
n
� �21 
n 
i=1  
n

σ2

n 

Var [An ] = 

Var [Gi ] 

nσ 2 

Gi 

= 

= 

= 

. 

(Var [aR] =  a 2  Var [R])  

(linearity of variance) 

Now letting R be An  in Chebyshev’s Bound (2) yields (3), as required. 

