1
00:00:08 --> 00:00:13.13
OK, this is the lecture on
linear transformations.

2
00:00:13.13 --> 00:00:18
Actually, linear algebra
courses used to begin with this

3
00:00:18 --> 00:00:24
lecture, so you could say I'm
beginning this course again by

4
00:00:24 --> 00:00:27
talking about linear
transformations.

5
00:00:27 --> 00:00:31
In a lot of courses,
those come first before

6
00:00:31 --> 00:00:33
matrices.

7
00:00:33 --> 00:00:37
The idea of a linear
transformation makes sense

8
00:00:37 --> 00:00:42
without a matrix,
and physicists and other --

9
00:00:42 --> 00:00:45
some people like it better that
way.

10
00:00:45 --> 00:00:48
They don't like coordinates.

11
00:00:48 --> 00:00:51
They don't want those numbers.

12
00:00:51 --> 00:00:57
They want to see what's going
on with the whole space.

13
00:00:57 --> 00:01:01
But, for most of us,
in the end, if we're going to

14
00:01:01 --> 00:01:04.35
compute anything,
we introduce coordinates,

15
00:01:04.35 --> 00:01:08
and then every linear
transformation will lead us to a

16
00:01:08 --> 00:01:08
matrix.

17
00:01:08 --> 00:01:13
And then, to all the things
that we've done about null space

18
00:01:13 --> 00:01:15
and row space,
and determinant,

19
00:01:15 --> 00:01:19
and eigenvalues -- all will
come from the matrix.

20
00:01:19 --> 00:01:28
But, behind it -- in other
words, behind this is the idea

21
00:01:28 --> 00:01:32
of a linear transformation.

22
00:01:32 --> 00:01:40
Let me give an example of a
linear transformation.

23
00:01:40 --> 00:01:42
So, example.

24
00:01:42 --> 00:01:43
Example one.

25
00:01:43 --> 00:01:47.19
A projection.

26
00:01:47.19 --> 00:01:53
I can describe a projection
without telling you any matrix,

27
00:01:53 --> 00:01:55
anything about any matrix.

28
00:01:55 --> 00:02:01
I can describe a projection,
say, this will be a linear

29
00:02:01 --> 00:02:05
transformation that takes,
say, all of R^2,

30
00:02:05 --> 00:02:11
every vector in the plane,
into a vector in the plane.

31
00:02:11 --> 00:02:17.03
And this is the way people
describe, a mapping.

32
00:02:17.03 --> 00:02:21
It takes every vector,
and so, by what rule?

33
00:02:21 --> 00:02:26
So, what's the rule,
is, I take a -- so here's the

34
00:02:26 --> 00:02:32.5
plane, this is going to be my
line, my line through my line,

35
00:02:32.5 --> 00:02:37
and I'm going to project every
vector onto that line.

36
00:02:37 --> 00:02:45.06
So if I take a vector like b --
or let me call the vector v for

37
00:02:45.06 --> 00:02:51
the moment -- the projection --
the linear transformation is

38
00:02:51 --> 00:02:54
going to produce this vector as
T(v).

39
00:02:54 --> 00:02:57
So T -- it's like a function.

40
00:02:57 --> 00:03:00
Exactly like a function.

41
00:03:00 --> 00:03:05
You give me an input,
the transformation produces the

42
00:03:05 --> 00:03:07
output.

43
00:03:07 --> 00:03:10
So transformation,
sometimes the word map,

44
00:03:10 --> 00:03:11.98
or mapping is used.

45
00:03:11.98 --> 00:03:14
A map between inputs and
outputs.

46
00:03:14 --> 00:03:18
So this is one particular map,
this is one example,

47
00:03:18 --> 00:03:22
a projection that takes every
vector -- here,

48
00:03:22 --> 00:03:26
let me do another vector v,
or let me do this vector w,

49
00:03:26 --> 00:03:27
what is T(w)?

50
00:03:27 --> 00:03:28
You see?

51
00:03:28 --> 00:03:32
There are no coordinates here.

52
00:03:32 --> 00:03:36
I've drawn those axes,
but I'm sorry I drew them,

53
00:03:36 --> 00:03:41
I'm going to remove them,
that's the whole point,

54
00:03:41 --> 00:03:46
is that we don't need axes,
we just need -- so guts -- get

55
00:03:46 --> 00:03:49
it out of there,
I'm not a physicist,

56
00:03:49 --> 00:03:52
so I draw those axes.

57
00:03:52 --> 00:03:55
So the input is w,
the output of the projection

58
00:03:55 --> 00:03:58
is, project on that line,
T(w).

59
00:03:58 --> 00:03:58
OK.

60
00:03:58 --> 00:04:02
Now, I could think of a lot of
transformations T.

61
00:04:02 --> 00:04:06
But, in this linear algebra
course, I want it to be a linear

62
00:04:06 --> 00:04:07
transformation.

63
00:04:07 --> 00:04:12
So here are the rules for a
linear transformation.

64
00:04:12 --> 00:04:16
Here, see, exactly,
the two operations that we can

65
00:04:16 --> 00:04:19
do on vectors,
adding and multiplying by

66
00:04:19 --> 00:04:25
scalars, the transformation does
something special with respect

67
00:04:25 --> 00:04:27
to those operations.

68
00:04:27 --> 00:04:30
So, for example,
the projection is a linear

69
00:04:30 --> 00:04:34
transformation because --
for example,

70
00:04:34 --> 00:04:40
if I wanted to check that one,
if I took v to be twice as

71
00:04:40 --> 00:04:44
long, the projection would be
twice as long.

72
00:04:44 --> 00:04:50
If I took v to be minus -- if I
changed from v to minus v,

73
00:04:50 --> 00:04:53
the projection would change to
a minus.

74
00:04:53 --> 00:04:57
So c equal to two,
c equal minus one,

75
00:04:57 --> 00:04:59
any c is OK.

76
00:04:59 --> 00:05:04
So you see that actually,
those combine,

77
00:05:04 --> 00:05:08
I can combine those into one
statement.

78
00:05:08 --> 00:05:14
What the transformation does to
any linear combination,

79
00:05:14 --> 00:05:20
it must produce the same
combination of T(v) and T(w).

80
00:05:20 --> 00:05:26
Let's think about some --
I mean, it's like,

81
00:05:26 --> 00:05:33
not hard to decide,
is a transformation linear or

82
00:05:33 --> 00:05:35
is it not.

83
00:05:35 --> 00:05:43.25
Let me give you an example so
you can tell me the answer.

84
00:05:43.25 --> 00:05:52
Suppose my transformation is --
here's another example two.

85
00:05:52 --> 00:05:55
Shift the whole plane.

86
00:05:55 --> 00:06:03
So here are all my vectors,
my plane, and every vector v in

87
00:06:03 --> 00:06:11
the plane, I shift it over by,
let's say, three by some vector

88
00:06:11 --> 00:06:12
v0.

89
00:06:12 --> 00:06:15
Shift whole plane by v0.

90
00:06:15 --> 00:06:24
So every vector in the plane --
this was v, T(v) will be v+v0.

91
00:06:24 --> 00:06:26
There's T(v).

92
00:06:26 --> 00:06:27
Here's v0.

93
00:06:27 --> 00:06:29
There's the typical v.

94
00:06:29 --> 00:06:31
And there's T(v).

95
00:06:31 --> 00:06:34
You see what this
transformation does?

96
00:06:34 --> 00:06:37
Takes this vector and adds to
it.

97
00:06:37 --> 00:06:40
Adds a fixed vector to it.

98
00:06:40 --> 00:06:45
Well, that seems like a pretty
reasonable, simple

99
00:06:45 --> 00:06:49
transformation,
but is it linear?

100
00:06:49 --> 00:06:53
The answer is no,
it's not linear.

101
00:06:53 --> 00:06:56.54
Which law is broken?

102
00:06:56.54 --> 00:06:59
Maybe both laws are broken.

103
00:06:59 --> 00:07:01
Let's see.

104
00:07:01 --> 00:07:08.82
If I double the length of v,
does the transformation produce

105
00:07:08.82 --> 00:07:13
something double -- do I double
T(v)?

106
00:07:13 --> 00:07:15
No.

107
00:07:15 --> 00:07:18
If I double the length of v,
in this transformation,

108
00:07:18 --> 00:07:22
I'm just adding on the same one
-- same v0, not two v0s,

109
00:07:22 --> 00:07:26
but only one v0 for every
vector, so I don't get two times

110
00:07:26 --> 00:07:27
the transform.

111
00:07:27 --> 00:07:29.23
Do you see what I'm saying?

112
00:07:29.23 --> 00:07:32
That if I double this,
then the transformation starts

113
00:07:32 --> 00:07:37.41
there and only goes one v0 out
and doesn't double T(v).

114
00:07:37.41 --> 00:07:43
In fact, a linear
transformation -- what is T of

115
00:07:43 --> 00:07:43
zero?

116
00:07:43 --> 00:07:50
That's just like a special
case, but really worth noticing.

117
00:07:50 --> 00:07:56
The zero vector in a linear
transformation must get

118
00:07:56 --> 00:07:59
transformed to zero.

119
00:07:59 --> 00:08:04
It can't move,
because, take any vector V here

120
00:08:04 --> 00:08:10
--
well, so you can see why T of

121
00:08:10 --> 00:08:12
zero is zero.

122
00:08:12 --> 00:08:19
Take v to be the zero vector,
take c to be three.

123
00:08:19 --> 00:08:27
Then we'd have T of zero vector
equaling three T of zero vector,

124
00:08:27 --> 00:08:32
the T of zero has to be zero.

125
00:08:32 --> 00:08:32
OK.

126
00:08:32 --> 00:08:39
So, this example is really a
non-example.

127
00:08:39 --> 00:08:45
Shifting the whole plane is not
a linear transformation.

128
00:08:45 --> 00:08:51
Or if I cooked up some formula
that involved squaring,

129
00:08:51 --> 00:08:56
or the transformation that,
also non-example,

130
00:08:56 --> 00:09:03
how about the transformation
that, takes any vector and

131
00:09:03 --> 00:09:06
produces its length?

132
00:09:06 --> 00:09:10
So there's a transformation
that takes any vector,

133
00:09:10 --> 00:09:15
say, any vector in R^3,
let me just -- I'll just get a

134
00:09:15 --> 00:09:18
chance to use this notation
again.

135
00:09:18 --> 00:09:23
Suppose I think of the
transformation that takes any

136
00:09:23 --> 00:09:27
vector in R^3 and produces this
number.

137
00:09:27 --> 00:09:30
So that, I could say,
is a member of R^1,

138
00:09:30 --> 00:09:34
for example,
if I wanted.

139
00:09:34 --> 00:09:36
Or just real numbers.

140
00:09:36 --> 00:09:39
That's certainly not linear.

141
00:09:39 --> 00:09:44
It's true that the zero vector
goes to zero.

142
00:09:44 --> 00:09:49
But if I double a vector,
it does double the length,

143
00:09:49 --> 00:09:51
that's true.

144
00:09:51 --> 00:09:56
But suppose I multiply a vector
by minus two.

145
00:09:56 --> 00:10:00
What happens to its length?

146
00:10:00 --> 00:10:01
It just doubles.

147
00:10:01 --> 00:10:04.59
It doesn't get multiplied by
minus two.

148
00:10:04.59 --> 00:10:09
So when c is minus two in my
requirement, I'm not satisfying

149
00:10:09 --> 00:10:10
that requirement.

150
00:10:10 --> 00:10:15
So T of minus v is not minus v
-- minus, the length,

151
00:10:15 --> 00:10:16
it's just the length.

152
00:10:16 --> 00:10:19
OK, so that's another
non-example.

153
00:10:19 --> 00:10:23
Projection was an example,
let me give you another

154
00:10:23 --> 00:10:25
example.

155
00:10:25 --> 00:10:36
I can stay here and have a --
this will be an example that is

156
00:10:36 --> 00:10:43
a linear transformation,
a rotation.

157
00:10:43 --> 00:10:48
Rotation by -- what shall we
say?

158
00:10:48 --> 00:10:51
By 45 degrees.

159
00:10:51 --> 00:10:53
OK?

160
00:10:53 --> 00:10:57.32
So again, let me choose this,
this will be a mapping,

161
00:10:57.32 --> 00:11:01
from the whole plane of
vectors, into the whole plane of

162
00:11:01 --> 00:11:05
vectors, and it just -- here is
the input vector v,

163
00:11:05 --> 00:11:09
and the output vector foam this
45 degree rotation is just

164
00:11:09 --> 00:11:12
rotate that thing by 45 degrees,
T(v).

165
00:11:12 --> 00:11:14
So every vector got rotated.

166
00:11:14 --> 00:11:19
You see that I can describe
this without any coordinates.

167
00:11:19 --> 00:11:22
And see that it's linear.

168
00:11:22 --> 00:11:28
If I doubled v,
the rotation would just be

169
00:11:28 --> 00:11:30
twice as far out.

170
00:11:30 --> 00:11:35
If I had v+w,
and if I rotated each of them

171
00:11:35 --> 00:11:44
and added, the answer's the same
as if I add and then rotate.

172
00:11:44 --> 00:11:49
That's what the linear
transformation is.

173
00:11:49 --> 00:11:52
OK, so those are two examples.

174
00:11:52 --> 00:11:57
Two examples,
projection and rotation,

175
00:11:57 --> 00:12:04
and I could invent more that
are linear transformations where

176
00:12:04 --> 00:12:08
I haven't told you a matrix yet.

177
00:12:08 --> 00:12:13.25
Actually, the book has a
picture of the action of linear

178
00:12:13.25 --> 00:12:17
transformations -- actually,
the cover of the book has it.

179
00:12:17 --> 00:12:22.1
So, in this section seven point
one, we can think of a --

180
00:12:22.1 --> 00:12:26
actually, here let's take this
linear transformation,

181
00:12:26 --> 00:12:30
rotation, suppose I have,
as the cover of the book has,

182
00:12:30 --> 00:12:32
a house in R^2.

183
00:12:32 --> 00:12:37
So instead of this,
let me take a small house in

184
00:12:37 --> 00:12:37
R^2.

185
00:12:37 --> 00:12:41
So that's a whole lot of
points.

186
00:12:41 --> 00:12:44.4
The idea is,
with this linear

187
00:12:44.4 --> 00:12:49
transformation,
that I can see what it does to

188
00:12:49 --> 00:12:52
everything at once.

189
00:12:52 --> 00:12:58
I don't have to just take one
vector at a time and see what T

190
00:12:58 --> 00:13:03
of V is, I can take all the
vectors on the outline of the

191
00:13:03 --> 00:13:06
house, and see where they all
go.

192
00:13:06 --> 00:13:12
In fact, that will show me
where the whole house goes.

193
00:13:12 --> 00:13:18
So what will happen with this
particular linear

194
00:13:18 --> 00:13:19
transformation?

195
00:13:19 --> 00:13:24
The whole house will rotate,
so the result,

196
00:13:24 --> 00:13:29
if I can draw it,
will be, the house will be

197
00:13:29 --> 00:13:30
sitting there.

198
00:13:30 --> 00:13:31
OK.

199
00:13:31 --> 00:13:37
And, but suppose I give some
other examples.

200
00:13:37 --> 00:13:44
Oh, let me give some examples
that involve a matrix.

201
00:13:44 --> 00:13:51
Example three -- and this is
important -- coming from a

202
00:13:51 --> 00:13:55
matrix at -- we always call A.

203
00:13:55 --> 00:14:00
So the transformation will be,
multiply by A.

204
00:14:00 --> 00:14:06.22
There is a linear
transformation.

205
00:14:06.22 --> 00:14:11
And a whole family of them,
because every matrix produces a

206
00:14:11 --> 00:14:16
transformation by this simple
rule, just multiply every vector

207
00:14:16 --> 00:14:19
by that matrix,
and it's linear,

208
00:14:19 --> 00:14:19
right?

209
00:14:19 --> 00:14:24
Linear, I have to check that
A(v) -- A times v plus w equals

210
00:14:24 --> 00:14:29
Av plus A w, which is fine,
and I have to check that A

211
00:14:29 --> 00:14:32
times vc equals c A(v).

212
00:14:32 --> 00:14:32.81
Check.

213
00:14:32.81 --> 00:14:34
Those are fine.

214
00:14:34 --> 00:14:38.29
So there is a linear
transformation.

215
00:14:38.29 --> 00:14:44
And if I take my favorite
matrix A, and I apply it to all

216
00:14:44 --> 00:14:49
vectors in the plane,
it will produce a bunch of

217
00:14:49 --> 00:14:50
outputs.

218
00:14:50 --> 00:14:55
See, the idea is now worth
thinking of, like,

219
00:14:55 --> 00:14:58
the big picture.

220
00:14:58 --> 00:15:01
The whole plane is transformed
by matrix multiplication.

221
00:15:01 --> 00:15:04
Every vector in the plane gets
multiplied by A.

222
00:15:04 --> 00:15:07
Let's take an example,
and see what happens to the

223
00:15:07 --> 00:15:08
vectors of the house.

224
00:15:08 --> 00:15:11.03
So this is still a
transformation from plane to

225
00:15:11.03 --> 00:15:14.07
plane, and let me take a
particular matrix A -- well,

226
00:15:14.07 --> 00:15:17
if I cooked up a rotation
matrix, this would be the right

227
00:15:17 --> 00:15:18
picture.

228
00:15:18 --> 00:15:24
If I cooked up a projection
matrix, the projection would be

229
00:15:24 --> 00:15:25.26
the picture.

230
00:15:25.26 --> 00:15:28.48
Let me just take some other
matrix.

231
00:15:28.48 --> 00:15:32
Let me take the matrix one zero
zero minus one.

232
00:15:32 --> 00:15:36
What happens to the house,
to all vectors,

233
00:15:36 --> 00:15:41
and in particular,
we can sort of visualize it if

234
00:15:41 --> 00:15:48
we look at the house --
so the house is not rotated any

235
00:15:48 --> 00:15:51
more, what do I get?

236
00:15:51 --> 00:15:59
What happens to all the vectors
if I do this transformation?

237
00:15:59 --> 00:16:03
I multiply by this matrix.

238
00:16:03 --> 00:16:08
Well, of course,
it's an easy matrix,

239
00:16:08 --> 00:16:11
it's diagonal.

240
00:16:11 --> 00:16:16
The x component stays the same,
the y component reverses sign,

241
00:16:16 --> 00:16:19
so that like the roof of that
house, the point,

242
00:16:19 --> 00:16:23
the tip of the roof,
has an x component which stays

243
00:16:23 --> 00:16:27
the same, but its y component
reverses, and it's down here.

244
00:16:27 --> 00:16:30.17
And, of course,
what we get is,

245
00:16:30.17 --> 00:16:33
the house is,
like, upside down.

246
00:16:33 --> 00:16:37
Now, I have to put -- where
does the door go?

247
00:16:37 --> 00:16:42
I guess the door goes upside
down there, right?

248
00:16:42 --> 00:16:46
So here's the input,
here's the input house,

249
00:16:46 --> 00:16:48
and this is the output.

250
00:16:48 --> 00:16:49
OK.

251
00:16:49 --> 00:16:54
This idea of a linear
transformation is like kind of

252
00:16:54 --> 00:17:00
the abstract description of
matrix multiplication.

253
00:17:00 --> 00:17:03
And what's our goal here?

254
00:17:03 --> 00:17:09
Our goal is to understand
linear transformations,

255
00:17:09 --> 00:17:16
and the way to understand them
is to find the matrix that lies

256
00:17:16 --> 00:17:17
behind them.

257
00:17:17 --> 00:17:20
That's really the idea.

258
00:17:20 --> 00:17:26
Find the matrix that lies
behind them.

259
00:17:26 --> 00:17:30
Um, and to do that,
we have to bring in

260
00:17:30 --> 00:17:31
coordinates.

261
00:17:31 --> 00:17:34
We have to choose a basis.

262
00:17:34 --> 00:17:40
So let me point out what's the
story -- if we have a linear

263
00:17:40 --> 00:17:44
transformation -- so start with
-- start.

264
00:17:44 --> 00:17:49
Suppose we have a linear
transformation.

265
00:17:49 --> 00:17:53.03
Let -- from now on,
let T stand for linear

266
00:17:53.03 --> 00:17:54
transformations.

267
00:17:54 --> 00:17:58
I won't be interested in the
nonlinear ones.

268
00:17:58 --> 00:18:02
Only linear transformations I'm
interested in.

269
00:18:02 --> 00:18:02.97
OK.

270
00:18:02.97 --> 00:18:06
I start with a linear
transformation T.

271
00:18:06 --> 00:18:11
Let's suppose its inputs are
vectors in R^3.

272
00:18:11 --> 00:18:11
OK?

273
00:18:11 --> 00:18:16
And suppose its outputs are
vectors in R^2,

274
00:18:16 --> 00:18:17
for example.

275
00:18:17 --> 00:18:17
OK.

276
00:18:17 --> 00:18:22
What's an example of such a
transformation,

277
00:18:22 --> 00:18:25
just before I go any further?

278
00:18:25 --> 00:18:29
Any matrix of the right size
will do this.

279
00:18:29 --> 00:18:35
So what would be the right
shape of a matrix?

280
00:18:35 --> 00:18:42
So, for example -- I'm wanting
to give you an example,

281
00:18:42 --> 00:18:46
just because,
here, I'm thinking of

282
00:18:46 --> 00:18:53
transformations that take
three-dimensional space to

283
00:18:53 --> 00:18:57.74
two-dimensional space.

284
00:18:57.74 --> 00:19:03
And I want them to be linear,
and the easy way to invent them

285
00:19:03 --> 00:19:06
is a matrix multiplication.

286
00:19:06 --> 00:19:10
So example, T of v should be
any A v.

287
00:19:10 --> 00:19:15
Those transformations are
linear, that's what 18.06 is

288
00:19:15 --> 00:19:16.18
about.

289
00:19:16.18 --> 00:19:21.55
And A should be what size,
what shape of matrix should

290
00:19:21.55 --> 00:19:23
that be?

291
00:19:23 --> 00:19:30
I want V to have three
components, because this is what

292
00:19:30 --> 00:19:36
the inputs have -- so here's the
input in R^3,

293
00:19:36 --> 00:19:40
and here's the output in R^2.

294
00:19:40 --> 00:19:43
So what shape of matrix?

295
00:19:43 --> 00:19:49
So this should be,
I guess, a two by three matrix?

296
00:19:49 --> 00:19:50
Right?

297
00:19:50 --> 00:19:54
A two by three matrix.

298
00:19:54 --> 00:19:59
A two by three matrix,
we'll multiply a vector in R^3

299
00:19:59 --> 00:20:04
-- you see I'm moving to
coordinates so quickly,

300
00:20:04 --> 00:20:07.26
I'm not a true physicist here.

301
00:20:07.26 --> 00:20:12
A two by three matrix,
we'll multiply a vector in R^3

302
00:20:12 --> 00:20:17
an produce an output in R^2,
and it will be a linear

303
00:20:17 --> 00:20:20
transformation,
and OK.

304
00:20:20 --> 00:20:24
So there's a whole lot of
examples, every two by three

305
00:20:24 --> 00:20:27
matrix give me an example,
and basically,

306
00:20:27 --> 00:20:31
I want to show you that there
are no other examples.

307
00:20:31 --> 00:20:35
Every linear transformation is
associated with a matrix.

308
00:20:35 --> 00:20:40
Now, let me come back to the
idea of linear transformation.

309
00:20:40 --> 00:20:47
Suppose I've got this linear
transformation in my mind,

310
00:20:47 --> 00:20:51
and I want to tell you what it
is.

311
00:20:51 --> 00:20:58
Suppose I tell you what the
transformation does to one

312
00:20:58 --> 00:21:00
vector.

313
00:21:00 --> 00:21:00
OK.

314
00:21:00 --> 00:21:03.81
You know one thing,
then.

315
00:21:03.81 --> 00:21:05
All right.

316
00:21:05 --> 00:21:12
So this is like the -- what I'm
speaking about now is,

317
00:21:12 --> 00:21:20.59
how much information is needed
to know the transformation?

318
00:21:20.59 --> 00:21:26
By knowing T,
I -- to know T of v for all v.

319
00:21:26 --> 00:21:29
All inputs.

320
00:21:29 --> 00:21:35
How much information do I have
to give you so that you know

321
00:21:35 --> 00:21:39
what the transformation does to
every vector?

322
00:21:39 --> 00:21:44
OK, I could tell you what the
transformation -- so I could

323
00:21:44 --> 00:21:48
take a vector v1,
one particular vector,

324
00:21:48 --> 00:21:52
tell you what the
transformation does to it --

325
00:21:52 --> 00:21:54
fine.

326
00:21:54 --> 00:21:59
But now you only know what the
transformation does to one

327
00:21:59 --> 00:21:59
vector.

328
00:21:59 --> 00:22:02
So you say, OK,
that's not enough,

329
00:22:02 --> 00:22:06
tell me what it does to another
vector.

330
00:22:06 --> 00:22:08
So I say, OK,
give me a vector,

331
00:22:08 --> 00:22:13
you give me a vector v2,
and we see, what does the

332
00:22:13 --> 00:22:16
transformation do to v2?

333
00:22:16 --> 00:22:20
Now, you only know -- or do you
only know what the

334
00:22:20 --> 00:22:22
transformation does to two
vectors?

335
00:22:22 --> 00:22:27
Have I got to ask you -- answer
you about every vector in the

336
00:22:27 --> 00:22:30
whole input space,
or can you, knowing what it

337
00:22:30 --> 00:22:34
does to v1 and v2,
how much do you now know about

338
00:22:34 --> 00:22:36.98
the transformation?

339
00:22:36.98 --> 00:22:42
You know what the
transformation does to a larger

340
00:22:42 --> 00:22:49
bunch of vectors than just these
two, because you know what it

341
00:22:49 --> 00:22:53.57
does to every linear
combination.

342
00:22:53.57 --> 00:22:59
You know what it does,
now, to the whole plane of

343
00:22:59 --> 00:23:03
vectors, with bases v1 and v2.

344
00:23:03 --> 00:23:07
I'm assuming v1 and v2 were
independent.

345
00:23:07 --> 00:23:11
If they were dependent,
if v2 was six times v1,

346
00:23:11 --> 00:23:16
then I didn't give you any new
information in T of v2,

347
00:23:16 --> 00:23:20.48
you already knew it would be
six times T of v1.

348
00:23:20.48 --> 00:23:24
So you can see what I'd headed
for.

349
00:23:24 --> 00:23:30
If I know what the
transformation does to every

350
00:23:30 --> 00:23:34
vector in a basis,
then I know everything.

351
00:23:34 --> 00:23:42
So the information needed to
know T of v for all inputs is T

352
00:23:42 --> 00:23:45
of v1, T of v2,
up to T of vm,

353
00:23:45 --> 00:23:51
let's say, or vn,
for any basis -- for a basis v1

354
00:23:51 --> 00:23:53.73
up to vn.

355
00:23:53.73 --> 00:24:05
This is a base for any -- can I
call it an input basis?

356
00:24:05 --> 00:24:12
It's a basis for the space of
inputs.

357
00:24:12 --> 00:24:20
The things that T is acting on.

358
00:24:20 --> 00:24:25
You see this point,
that if I have a basis for the

359
00:24:25 --> 00:24:32
input space, and I tell you what
the transformation does to every

360
00:24:32 --> 00:24:38
one of those basis vectors,
that is all I'm allowed to tell

361
00:24:38 --> 00:24:43
you, and it's enough to know T
of v for all v-s,

362
00:24:43 --> 00:24:46
because why?

363
00:24:46 --> 00:24:51.53
Because every v is some
combination of these basis

364
00:24:51.53 --> 00:24:56.65
vectors, c1v1+...+cnvn,
that's what a basis is,

365
00:24:56.65 --> 00:24:57
right?

366
00:24:57 --> 00:24:59
It spans the space.

367
00:24:59 --> 00:25:05
And if I know what T does to
this, and what T does to v2,

368
00:25:05 --> 00:25:11
and what T does to vn,
then I know what T does to V.

369
00:25:11 --> 00:25:16
By this linearity,
it has to be c1 T of v1 plus O

370
00:25:16 --> 00:25:20
one plus cn T of vn.

371
00:25:20 --> 00:25:22
There's no choice.

372
00:25:22 --> 00:25:29
So, the point of this comment
is that if I know what T does to

373
00:25:29 --> 00:25:36
a basis, to each vector in a
basis, then I know the linear

374
00:25:36 --> 00:25:37
transformation.

375
00:25:37 --> 00:25:45
The property of linearity tells
me all the other vectors.

376
00:25:45 --> 00:25:47
All the other outputs.

377
00:25:47 --> 00:25:47
OK.

378
00:25:47 --> 00:25:52
So now, we got -- so that light
we now see, what do we really

379
00:25:52 --> 00:25:57
need in a linear transformation,
and we're ready to go to a

380
00:25:57 --> 00:25:57
matrix.

381
00:25:57 --> 00:25:58
OK.

382
00:25:58 --> 00:26:03
What's the step now that takes
us from a linear transformation

383
00:26:03 --> 00:26:08
that's free of coordinates to a
matrix that's been created with

384
00:26:08 --> 00:26:11
respect to coordinates?

385
00:26:11 --> 00:26:17
The matrix is going to come
from the coordinate system.

386
00:26:17 --> 00:26:20
These are the coordinates.

387
00:26:20 --> 00:26:23
Coordinates mean a basis is
decided.

388
00:26:23 --> 00:26:30
Once you decide on a basis --
this is where coordinates come

389
00:26:30 --> 00:26:30
from.

390
00:26:30 --> 00:26:35
You decide on a basis,
then every vector,

391
00:26:35 --> 00:26:40.5
these are the coordinates in
that basis.

392
00:26:40.5 --> 00:26:47
There is one and only one way
to express v as a combination of

393
00:26:47 --> 00:26:53
the basis vectors,
and the numbers you need in

394
00:26:53 --> 00:26:57
that combination are the
coordinates.

395
00:26:57 --> 00:27:00
Let me write that down.

396
00:27:00 --> 00:27:03
So what are coordinates?

397
00:27:03 --> 00:27:06
Coordinates come from a basis.

398
00:27:06 --> 00:27:11
Coordinates come from a basis.

399
00:27:11 --> 00:27:18
The coordinates of v,
the coordinates of v are these

400
00:27:18 --> 00:27:25
numbers that tell you how much
of each basis vector is in v.

401
00:27:25 --> 00:27:31
If I change the basis,
I change the coordinates,

402
00:27:31 --> 00:27:32
right?

403
00:27:32 --> 00:27:39
Now, we have always been
assuming that were working with

404
00:27:39 --> 00:27:43
a standard basis,
right?

405
00:27:43 --> 00:27:46
The basis we don't even think
about this stuff,

406
00:27:46 --> 00:27:51
because if I give you the
vector v equals three two four,

407
00:27:51 --> 00:27:55
you have been assuming
completely -- and probably

408
00:27:55 --> 00:27:59
rightly -- that I had in mind
the standard basis,

409
00:27:59 --> 00:28:03
that this vector was three
times the first coordinate

410
00:28:03 --> 00:28:07
vector, and two times the
second, and four times the

411
00:28:07 --> 00:28:08
third.

412
00:28:08 --> 00:28:17
But you're not entitled -- I
might have had some other basis

413
00:28:17 --> 00:28:19
in mind.

414
00:28:19 --> 00:28:23.83
This is like the standard
basis.

415
00:28:23.83 --> 00:28:32
And then the coordinates are
sitting right there in the

416
00:28:32 --> 00:28:34
vector.

417
00:28:34 --> 00:28:37
But I could have chosen a
different basis,

418
00:28:37 --> 00:28:41
like I might have had
eigenvectors of a matrix,

419
00:28:41 --> 00:28:45.42
and I might have said,
OK, that's a great basis,

420
00:28:45.42 --> 00:28:50
I'll use the eigenvectors of
this matrix as my basis vectors.

421
00:28:50 --> 00:28:56
Which are not necessarily these
three, but some other basis.

422
00:28:56 --> 00:29:00
So that was an example,
this is the real thing,

423
00:29:00 --> 00:29:05
the coordinates are these
numbers, I'll circle them again,

424
00:29:05 --> 00:29:07
the amounts of each basis.

425
00:29:07 --> 00:29:08
OK.

426
00:29:08 --> 00:29:13
So, if I want to create a
matrix that describes a linear

427
00:29:13 --> 00:29:17.91
transformation,
now I'm ready to do that.

428
00:29:17.91 --> 00:29:19
OK, OK.

429
00:29:19 --> 00:29:28
So now what I plan to do is
construct the matrix A that

430
00:29:28 --> 00:29:37
represents, or tells me about,
a linear transformation,

431
00:29:37 --> 00:29:42
linear transformation T.

432
00:29:42 --> 00:29:42
OK.

433
00:29:42 --> 00:29:51
So I really start with the
transformation --

434
00:29:51 --> 00:29:57.97
whether it's a projection or a
rotation, or some strange

435
00:29:57.97 --> 00:30:04
movement of this house in the
plane, or some transformation

436
00:30:04 --> 00:30:10.85
from n-dimensional space to --
or m-dimensional space to

437
00:30:10.85 --> 00:30:15
n-dimensional space.
n to m, I guess.

438
00:30:15 --> 00:30:19
Usually, we'll have T,
we'll somehow transform

439
00:30:19 --> 00:30:22
n-dimensional space to
m-dimensional space,

440
00:30:22 --> 00:30:26
and the whole point is that if
I have a basis for n-dimensional

441
00:30:26 --> 00:30:29.48
space -- I guess I need two
bases, really.

442
00:30:29.48 --> 00:30:32
I need an input basis to
describe the inputs,

443
00:30:32 --> 00:30:36
and I need an output basis to
give me coordinates -- to give

444
00:30:36 --> 00:30:40
me some numbers for the output.

445
00:30:40 --> 00:30:43
So I've got to choose two
bases.

446
00:30:43 --> 00:30:50
Choose a basis v1 up to vn for
the inputs, for the inputs in --

447
00:30:50 --> 00:30:53.17
they came from R^n.

448
00:30:53.17 --> 00:31:00
So the transformation is taking
every n-dimensional vector into

449
00:31:00 --> 00:31:03
some m-dimensional vector.

450
00:31:03 --> 00:31:10
And I have to choose a basis,
and I'll call them w1 up to wn,

451
00:31:10 --> 00:31:13
for the outputs.

452
00:31:13 --> 00:31:16
Those are guys in R^m.

453
00:31:16 --> 00:31:23
Once I've chosen the basis,
that settles the matrix -- I

454
00:31:23 --> 00:31:27
now working with coordinates.

455
00:31:27 --> 00:31:33
Every vector in R^n,
every input vector has some

456
00:31:33 --> 00:31:34
coordinates.

457
00:31:34 --> 00:31:39
So here's what I do,
here's what I do.

458
00:31:39 --> 00:31:43
Can I say it in words?

459
00:31:43 --> 00:31:45
I take a vector v.

460
00:31:45 --> 00:31:48
I express it in its basis,
in the basis,

461
00:31:48 --> 00:31:50
so I get its coordinates.

462
00:31:50 --> 00:31:55
Then I'm going to multiply
those coordinates by the right

463
00:31:55 --> 00:32:00
matrix A, and that will give me
the coordinates of the output in

464
00:32:00 --> 00:32:02
the output basis.

465
00:32:02 --> 00:32:07
I'd better write that down,
that was a mouthful.

466
00:32:07 --> 00:32:15
What I want -- I want a matrix
A that does what the linear

467
00:32:15 --> 00:32:18
transformation does.

468
00:32:18 --> 00:32:25
And it does it with respecting
these bases.

469
00:32:25 --> 00:32:33
So I want the matrix to be --
well, let's suppose -- look,

470
00:32:33 --> 00:32:38.5
let me take an example.

471
00:32:38.5 --> 00:32:41
Let me take the projection
example.

472
00:32:41 --> 00:32:44
The projection example.

473
00:32:44 --> 00:32:49
Suppose I take -- because we've
got that -- we've got that

474
00:32:49 --> 00:32:53
projection in mind -- I can fit
in here.

475
00:32:53 --> 00:32:56
Here's the projection example.

476
00:32:56 --> 00:33:02
So the projection example,
I'm thinking of n and m as two.

477
00:33:02 --> 00:33:08
The transformation takes the
plane, takes every vector in the

478
00:33:08 --> 00:33:13
plane, and, let me draw the
plane, just so we remember it's

479
00:33:13 --> 00:33:18
a plane -- and there's the thing
that I'm projecting onto,

480
00:33:18 --> 00:33:23
that's the line I'm projecting
onto -- so the transformation

481
00:33:23 --> 00:33:30.16
takes every vector in the plane
and projects it onto that line.

482
00:33:30.16 --> 00:33:34
So this is projection,
so I'm going to do projection.

483
00:33:34 --> 00:33:34
OK.

484
00:33:34 --> 00:33:39
But, I'm going to choose a
basis that I like better than

485
00:33:39 --> 00:33:41.22
the standard basis.

486
00:33:41.22 --> 00:33:45
My basis -- in fact,
I'll choose the same basis for

487
00:33:45 --> 00:33:49
inputs and for outputs,
and the basis will be -- my

488
00:33:49 --> 00:33:53
first basis vector will be right
on the line.

489
00:33:53 --> 00:33:57
There's my first basis vector.

490
00:33:57 --> 00:33:59
Say, a unit vector,
on the line.

491
00:33:59 --> 00:34:03
And my second basis vector will
be a unit vector perpendicular

492
00:34:03 --> 00:34:04
to that line.

493
00:34:04 --> 00:34:08
And I'm going to choose that as
the output basis,

494
00:34:08 --> 00:34:08
also.

495
00:34:08 --> 00:34:11
And I'm going to ask you,
what's the matrix?

496
00:34:11 --> 00:34:13
What's the matrix?

497
00:34:13 --> 00:34:16
How do I describe this
transformation of projection

498
00:34:16 --> 00:34:19
with respect to this basis?

499
00:34:19 --> 00:34:20
OK?

500
00:34:20 --> 00:34:22
So what's the rule?

501
00:34:22 --> 00:34:28.53
I take any vector v,
it's some combination of the

502
00:34:28.53 --> 00:34:34
first basis ve- vector,
and the second basis vector.

503
00:34:34 --> 00:34:37
Now, what is T of v?

504
00:34:37 --> 00:34:43
Suppose the input is -- well,
suppose the input is v1.

505
00:34:43 --> 00:34:48
What's the output?
v1, right?

506
00:34:48 --> 00:34:51
The projection leaves this one
alone.

507
00:34:51 --> 00:34:57
So we know what the projection
does to this first basis vector,

508
00:34:57 --> 00:34:59
this guy, it leaves it.

509
00:34:59 --> 00:35:04
What does the projection do to
the second basis vector?

510
00:35:04 --> 00:35:07
It kills it,
sends it to zero.

511
00:35:07 --> 00:35:11
So what does the projection do
to a combination?

512
00:35:11 --> 00:35:14
It kills this part,
and this part,

513
00:35:14 --> 00:35:17
it leaves alone.

514
00:35:17 --> 00:35:23
Now, all I want to do is find
the matrix.

515
00:35:23 --> 00:35:30
I now want to find the matrix
that takes an input,

516
00:35:30 --> 00:35:37
c1 c2, the coordinates,
and gives me the output,

517
00:35:37 --> 00:35:39
c1 0.

518
00:35:39 --> 00:35:44
You see that in this basis,
the coordinates of the input

519
00:35:44 --> 00:35:49.33
were c1, c2, and the coordinates
of the output are c1,

520
00:35:49.33 --> 0.


521
0. --> 00:35:49


522
00:35:49 --> 00:35:53
And of course,
not hard to find a matrix that

523
00:35:53 --> 00:35:54
will do that.

524
00:35:54 --> 00:35:58
The matrix that will do that is
the matrix one,

525
00:35:58 --> 00:36:01
zero, zero, zero.

526
00:36:01 --> 00:36:09
Because if I multiply input by
that matrix A -- this is A times

527
00:36:09 --> 00:36:16
input coordinates -- and I'm
hoping to get the output

528
00:36:16 --> 00:36:18
coordinates.

529
00:36:18 --> 00:36:23
And what do I get from that
multiplication?

530
00:36:23 --> 00:36:28.37
I get the right answer,
c1 and zero.

531
00:36:28.37 --> 00:36:32
So what's the point?

532
00:36:32 --> 00:36:35
So the first point is,
there's a matrix that does the

533
00:36:35 --> 00:36:36
job.

534
00:36:36 --> 00:36:39
If there's a linear
transformation out there,

535
00:36:39 --> 00:36:41
coordinate-free,
no coordinates,

536
00:36:41 --> 00:36:45
and then I choose a basis for
the inputs, and I choose a basis

537
00:36:45 --> 00:36:48.44
for the outputs,
then there's a matrix that does

538
00:36:48.44 --> 00:36:48
the job.

539
00:36:48 --> 00:36:50
And what's the job?

540
00:36:50 --> 00:36:53
It multiplies the input
coordinates and produces the

541
00:36:53 --> 00:36:56
output coordinates.

542
00:36:56 --> 00:37:01
Now, in this example -- let me
repeat, I chose the input basis

543
00:37:01 --> 00:37:04
was the same as the output
basis.

544
00:37:04 --> 00:37:08
The input basis and output
basis were both along the line,

545
00:37:08 --> 00:37:11
and perpendicular to the line.

546
00:37:11 --> 00:37:16
They're actually the
eigenvectors of the projection.

547
00:37:16 --> 00:37:22
And, as a result,
the matrix came out diagonal.

548
00:37:22 --> 00:37:27
In fact, it came out to be
lambda.

549
00:37:27 --> 00:37:31
This is like,
the good basis.

550
00:37:31 --> 00:37:38
So the good -- the eigenvector
basis is the good basis,

551
00:37:38 --> 00:37:45
it leads to the matrix --
the diagonal matrix of

552
00:37:45 --> 00:37:50
eigenvalues lambda,
and just as in this example,

553
00:37:50 --> 00:37:56
the eigenvectors and
eigenvalues of this linear

554
00:37:56 --> 00:38:01
transformation were along the
line, and perpendicular.

555
00:38:01 --> 00:38:08
The eigenvalues were one and
zero, and that's the matrix that

556
00:38:08 --> 00:38:09
we got.

557
00:38:09 --> 00:38:10
OK.

558
00:38:10 --> 00:38:13
So that's a,
like, the great choice of

559
00:38:13 --> 00:38:17
matrix, that's the choice a
physicist would do when he had

560
00:38:17 --> 00:38:21
to finally -- he or she had to
finally bring coordinates in

561
00:38:21 --> 00:38:25
unwillingly, the coordinates to
be chosen, the good coordinates

562
00:38:25 --> 00:38:28
are the eigenvectors,
because, if I did this

563
00:38:28 --> 00:38:32
projection in the standard basis
-- which I could do,

564
00:38:32 --> 00:38:33
right?

565
00:38:33 --> 00:38:40.46
I could do the whole thing in
the standard basis -- I better

566
00:38:40.46 --> 00:38:43
try, if I can do that.

567
00:38:43 --> 00:38:50
What are we calling -- so I'll
have to tell you now which line

568
00:38:50 --> 00:38:53
we're projecting on.

569
00:38:53 --> 00:38:56
Say, the 45 degree line.

570
00:38:56 --> 00:39:03
So say we're projecting onto 45
degree line, and we use not the

571
00:39:03 --> 00:39:08
eigenvector basis,
but the standard basis.

572
00:39:08 --> 00:39:12
The standard basis,
v1, is one, zero,

573
00:39:12 --> 00:39:15
and v2 is zero,
one.

574
00:39:15 --> 00:39:22
And again, I'll use the same
basis for the outputs.

575
00:39:22 --> 00:39:26
Then I have to do this -- I can
find a matrix,

576
00:39:26 --> 00:39:30
it will be the matrix that we
would always think of,

577
00:39:30 --> 00:39:33
it would be the projection
matrix.

578
00:39:33 --> 00:39:37
It will be, actually,
it's the matrix that we learned

579
00:39:37 --> 00:39:41
about in chapter four,
it's what I call the matrix --

580
00:39:41 --> 00:39:45.52
do you remember,
P was A, A transpose over A

581
00:39:45.52 --> 00:39:47
transpose A?

582
00:39:47 --> 00:39:51
And I think,
in this example,

583
00:39:51 --> 00:39:55
it will come out,
one-half, one-half,

584
00:39:55 --> 00:39:57.76
one-half, one-half.

585
00:39:57.76 --> 00:40:04
I believe that's the matrix
that comes from our formula.

586
00:40:04 --> 00:40:10
And that's the matrix that will
do the job.

587
00:40:10 --> 00:40:17
If I give you this input,
one, zero, what's the output?

588
00:40:17 --> 00:40:21
The output is one-half,
one-half.

589
00:40:21 --> 00:40:26
And that should be the right
projection.

590
00:40:26 --> 00:40:33.33
And if I give you the input
zero, one, the output is,

591
00:40:33.33 --> 00:40:40
again, one-half,
one-half, again the projection.

592
00:40:40 --> 00:40:44
So that's the matrix,
but not diagonal of course,

593
00:40:44 --> 00:40:49
because we didn't choose a
great basis, we just chose the

594
00:40:49 --> 00:40:50
handiest basis.

595
00:40:50 --> 00:40:54
Well, so the course has
practically been about the

596
00:40:54 --> 00:40:57
handiest basis,
and just dealing with the

597
00:40:57 --> 00:41:00
matrix that we got.

598
00:41:00 --> 00:41:03
And it's not that bad a matrix,
it's symmetric,

599
00:41:03 --> 00:41:08
and it has this P squared equal
P property, all those things are

600
00:41:08 --> 00:41:09
good.

601
00:41:09 --> 00:41:13
But in the best basis,
it's easy to see that P squared

602
00:41:13 --> 00:41:17
equals P, and it's symmetric,
and it's diagonal.

603
00:41:17 --> 00:41:21
So that's the idea then,
is, do you see now how I'm

604
00:41:21 --> 00:41:25
associating a matrix to the
transformation?

605
00:41:25 --> 00:41:31
I'd better write the rule down,
I'd better write the rule down.

606
00:41:31 --> 00:41:34
The rule to find the matrix A.

607
00:41:34 --> 00:41:36
All right, first column.

608
00:41:36 --> 00:41:40
So, a rule to find A,
we're given the bases.

609
00:41:40 --> 00:41:45
Of course, we don't -- because
there's no way we could

610
00:41:45 --> 00:41:51
construct the matrix until we're
told what the bases are.

611
00:41:51 --> 00:41:58.34
So we're given the input basis,
and the output basis,

612
00:41:58.34 --> 00:42:00
v1 to vn, w1 to wm.

613
00:42:00 --> 00:42:02
Those are given.

614
00:42:02 --> 00:42:10
Now, in the first column of A,
how do I find that column?

615
00:42:10 --> 00:42:15
The first column of the matrix.

616
00:42:15 --> 00:42:21
So that should tell me what
happens to the first basis

617
00:42:21 --> 00:42:22
vector.

618
00:42:22 --> 00:42:27
So the rule is,
apply the linear transformation

619
00:42:27 --> 00:42:28
to v1.

620
00:42:28 --> 00:42:31
To the first basis vector.

621
00:42:31 --> 00:42:37
And then, I'll write it -- so
that's the output,

622
00:42:37 --> 00:42:38
right?

623
00:42:38 --> 00:42:43.46
The input is v1,
what's the output?

624
00:42:43.46 --> 00:42:48.55
The output is in the output
space, it's some combination of

625
00:42:48.55 --> 00:42:53
these guys, and it's that
combination that goes into the

626
00:42:53 --> 00:42:57
first column -- so,
let me -- I'll put this word --

627
00:42:57 --> 00:43:00
right, I'll say it in words
again.

628
00:43:00 --> 00:43:02.77
How to find this matrix.

629
00:43:02.77 --> 00:43:06
Take the first basis vector.

630
00:43:06 --> 00:43:11
Apply the transformation,
then it's in the output space,

631
00:43:11 --> 00:43:16
T of v1, so it's some
combination of these outputs,

632
00:43:16 --> 00:43:17
this output basis.

633
00:43:17 --> 00:43:21
So that combination,
the coefficients in that

634
00:43:21 --> 00:43:26
combination will be the first
column -- so a1,

635
00:43:26 --> 00:43:28
a row 2, column 1,
w2, am1, wm.

636
00:43:28 --> 00:43:35
There are the numbers in the
first column of the matrix.

637
00:43:35 --> 00:43:41
Let me make the point by doing
the second column.

638
00:43:41 --> 00:43:44
Second column of A.

639
00:43:44 --> 00:43:47
What's the idea,
now?

640
00:43:47 --> 00:43:55
I take the second basis vector,
I apply the transformation to

641
00:43:55 --> 00:44:03
it, that's in -- now I get an
output, so it's some combination

642
00:44:03 --> 00:44:11
in the output basis --
and that combination is the

643
00:44:11 --> 00:44:17
bunch of numbers that should go
in the second column of the

644
00:44:17 --> 00:44:18
matrix.

645
00:44:18 --> 00:44:18
OK.

646
00:44:18 --> 00:44:20
And so forth.

647
00:44:20 --> 00:44:25
So I get a matrix,
and the matrix I get does the

648
00:44:25 --> 00:44:26.43
right job.

649
00:44:26.43 --> 00:44:32
Now, the matrix constructed
that way, and following the

650
00:44:32 --> 00:44:37
rules of matrix multiplication.

651
00:44:37 --> 00:44:43
The result will be that if I
give you the input coordinates,

652
00:44:43 --> 00:44:49
and I multiply by the matrix,
so the outcome of all this is A

653
00:44:49 --> 00:44:56
times the input coordinates
correctly reproduces the output

654
00:44:56 --> 00:44:57
coordinates.

655
00:44:57 --> 00:44:59
Why is this right?

656
00:44:59 --> 00:45:02
Let me just check the first
column.

657
00:45:02 --> 00:45:09
Suppose the input coordinates
are one and all zeros.

658
00:45:09 --> 00:45:11
What does that mean?

659
00:45:11 --> 00:45:12
What's the input?

660
00:45:12 --> 00:45:16
If the input coordinates are
one and other -- and the rest

661
00:45:16 --> 00:45:19
zeros, then the input is v1,
right?

662
00:45:19 --> 00:45:23
That's the vector that has
coordinates one and all zeros.

663
00:45:23 --> 00:45:24
OK?

664
00:45:24 --> 00:45:27
When I multiply A by the one
and all zeros,

665
00:45:27 --> 00:45:32
I'll get the first column of A,
I'll get these numbers.

666
00:45:32 --> 00:45:35
And, sure enough,
those are the output

667
00:45:35 --> 00:45:37.19
coordinates for T of v1.

668
00:45:37.19 --> 00:45:40
So we made it right on the
first column,

669
00:45:40 --> 00:45:44
we made it right on the second
column, we made it right on all

670
00:45:44 --> 00:45:48
the basis vectors,
and then it has to be right on

671
00:45:48 --> 00:45:49.42
every vector.

672
00:45:49.42 --> 00:45:49
OK.

673
00:45:49 --> 00:45:53
So there is a picture of the
matrix for a linear

674
00:45:53 --> 00:45:55
transformation.

675
00:45:55 --> 00:46:01.97
Finally, let me give you
another -- a different linear

676
00:46:01.97 --> 00:46:03
transformation.

677
00:46:03 --> 00:46:10
The linear transformation that
takes the derivative.

678
00:46:10 --> 00:46:13
That's a linear transformation.

679
00:46:13 --> 00:46:21
Suppose the input space is all
combination c1 plus c2x plus c3

680
00:46:21 --> 00:46:23
x squared.

681
00:46:23 --> 00:46:27
So the basis is these simple
functions.

682
00:46:27 --> 00:46:30
Then what's the output?

683
00:46:30 --> 00:46:32
Is the derivative.

684
00:46:32 --> 00:46:38
The output is the derivative,
so the output is c2+2c3 x.

685
00:46:38 --> 00:46:44
And let's take as output basis,
the vectors one and x.

686
00:46:44 --> 00:46:49
So we're going from a
three-dimensional space of

687
00:46:49 --> 00:46:54
inputs to a two-dimensional
space of outputs by the

688
00:46:54 --> 00:46:57
derivative.

689
00:46:57 --> 00:47:07.56
And I don't know if you ever
thought that the derivative is

690
00:47:07.56 --> 00:47:08
linear.

691
00:47:08 --> 00:47:18
But if it weren't linear,
taking derivatives would take

692
00:47:18 --> 00:47:21
forever, right?

693
00:47:21 --> 00:47:25
We are able to compute
derivatives of functions exactly

694
00:47:25 --> 00:47:27
because we know it's a linear
transformation,

695
00:47:27 --> 00:47:31
so that if we learn the
derivatives of a few functions,

696
00:47:31 --> 00:47:34
like sine x and cos x and e to
the x, and another little short

697
00:47:34 --> 00:47:38
list, then we can take all their
combinations and we can do all

698
00:47:38 --> 00:47:40
the derivatives.

699
00:47:40 --> 00:47:42
OK, now what's the matrix?

700
00:47:42 --> 00:47:44
What's the matrix?

701
00:47:44 --> 00:47:49
So I want the matrix to
multiply these input vectors --

702
00:47:49 --> 00:47:53
input coordinates,
and give these output

703
00:47:53 --> 00:47:54
coordinates.

704
00:47:54 --> 00:47:58
So I just think,
OK, what's the matrix that does

705
00:47:58 --> 00:47:59
it?

706
00:47:59 --> 00:48:02.5
I can follow my rule of
construction,

707
00:48:02.5 --> 00:48:06
or I can see what the matrix
is.

708
00:48:06 --> 00:48:10
It should be a two by three
matrix, right?

709
00:48:10 --> 00:48:13
And the matrix -- so I'm just
figuring out,

710
00:48:13 --> 00:48:15
what do I want?

711
00:48:15 --> 00:48:17.75
No, I'll -- let me write it
here.

712
00:48:17.75 --> 00:48:20
What do I want from my matrix?

713
00:48:20 --> 00:48:22
What should that matrix do?

714
00:48:22 --> 00:48:26.14
Well, I want to get c2 in the
first output,

715
00:48:26.14 --> 00:48:29
so zero, one,
zero will do it.

716
00:48:29 --> 00:48:32
I want to get two c3,
so zero, zero,

717
00:48:32 --> 00:48:33.21
two will do it.

718
00:48:33.21 --> 00:48:37
That's the matrix for this
linear transformation with those

719
00:48:37 --> 00:48:39
bases and those coordinates.

720
00:48:39 --> 00:48:43
You see, it just clicks,
and the whole point is that the

721
00:48:43 --> 00:48:47
inverse matrix gives the inverse
to the linear transformation,

722
00:48:47 --> 00:48:51
that the product of two
matrices gives the right matrix

723
00:48:51 --> 00:48:54
for the product of two
transformations --

724
00:48:54 --> 00:49:03
matrix multiplication really
came from linear

725
00:49:03 --> 00:49:06
transformations.

726
00:49:06 --> 00:49:17
I'd better pick up on that
theme Monday after Thanksgiving.

727
00:49:17 --> 00:49:24
And I hope you have a great
holiday.

728
00:49:24 --> 00:49:30
I hope Indian summer keeps
going.

729
00:49:30 --> 00:49:33
OK, see you on Monday.

