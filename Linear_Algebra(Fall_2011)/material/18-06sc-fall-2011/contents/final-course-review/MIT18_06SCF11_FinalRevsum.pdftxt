Final  course  review 

Once  more,  we  review  questions  from  a  previous  exam  to  prepare  ourselves 
for  an  upcoming  exam. 

no  solution,  and  Ax  = 

has  exactly one  solution.


0

1 
0


" 

1 
0 
0 

# 

has 

contains 

The  fact  that  Ax  = 

,  so  r is  not  zero:  1  ≤  r < 3.


has  no  solution  tells  us  that  the  column 

1.  Suppose we know that  A  is  an  m by  n matrix  of  rank  r,  Ax  = 
# 
" 
a)  What can  we  say  about  m,  n and  r?

The product  Ax  is  a  vector in  three dimensions,  so  m = 3.

1 
# 
" 
0 
0 
space  is  not  all  of  R3 .  In  addition,  we  know  that  the  column  space 
0

# 
" 
1 
0

The  fact  that  Ax  = 

0 
" 
# 
1 
0 
nullspace  of  A  contains  only  the  zero  vector  and  so  n  =  r.  Hence 
1  ≤  n < 3. 
b)  Write down an example of  a matrix  A that  ﬁts this description. 
 

0 
The  vector    1    must  be  in  the  column  space,  so  we’ll  make  it  a 
0 
column  of  A.  The  simplest  way  to  answer  this  question  is  to  stop 
here. 

 
0 
  1    . 
0 
In  this  solution,  n = r = 1 and  m = 3. 
To  ﬁnd  a  solution  in  which  n  =  r  =  2,  add  a  second  column.  Make 
1

# 
" 
0 
0


has  exactly  one  solution  tells  us  that  the 

sure that 

is not in the column space:


A = 


 
0 0 
  1 0    . 
0 1 
There  are  many  other  correct  answers  to  this question. 

A = 

1 

c)  Cross out all  statements that  are false about  any  matrix with  the given 
properties (which are 1  ≤  r = n,  m = 3). 
i.  det AT A = det A AT 
ii.  AT A is invertible 
iii.  A AT  is positive deﬁnite 
One good approach to  this problem is to  use  our  sample  matrix to  test 
each  statement. 

i.  If we leave this part to last,  we can quickly  answer it (false) using 
what  we learn  while  answering  the following  two parts. 
ii.  The  matrix  AT A  is invertible if  r  =  n; i.e.  if the  columns  of  A are 
independent. 
The  nullspace  of our  A contains  only  the  zero  vector,  so  this  state-
ment is  true. 
For  each  of  our  sample  matrices,  AT A  equals the identity  and  so 
is invertible. 
Note  that  this  means det AT A  6= 0. 
iii.  We  know  that  m  =  3  and  r  <  3,  so  A AT  will be  a 3 by 3  ma­
trix  with  rank  less  than  3;  it  can’t  be positive  deﬁnite. (It  is  true 
that  for  any  matrix  A  with  real  valued  entries,  A AT  is  positive 
semideﬁnte.) 
For  our  test  matrices,  A AT  has  at least one  row  that’s  all  zeros,  so 
0 is  an  eigenvalue (and is  not positive). 
Note  also  that  det A AT  =  0  and  so  statement (i)  must be false. 
(However, if A and  B are square matrices then det  B A = det AB = 
det A det B.) 
d)  Prove  that  AT y  = c  has  at least  one  solution for  every  right hand  side 
c,  and in fact has inﬁnitely  many  solutions for  every  c.

We  know  AT  is  an  n  by  m matrix  with  m  =  3  and  rank  r  =  n  <  m.

If  AT  has  full  row  rank,  the  equation  AT y  =  c  is  always  solvable.

We  have  n  rows  and  rank  r  =  n,  so  AT  has  full  row  rank.  Therefore

AT y  = c  has  a  solution for  every vector  c.

The  solvable  system  AT y  =  c  will  have  inﬁnitely  many  solutions  if

the  nullspace  of  AT  has positive dimension.  We know dim(N ( AT )) =

m − r > 0,  so  AT y  = c  has inﬁnitely  many  solutions for  every  c.


2.  Suppose  the  columns  of  A are  v1 ,  v2  and  v3 . 

a)  Solve  Ax  = v1  − v2  + v3 . 
This is just the  “column method”  of multiplying  matrices from the 
1

# 
" 
ﬁrst lecture.  Choose  x  =  −1
1


.


2 

True.  Any  scalar  multiple  of  x  = 

if  v1  −  v2  + v3  =  0, then the  solution to (2a)  is  not 
b)  True  or  false: 
unique.  Explain your  answer. 

 
1 
−1    will be  a  solution. 
 
1 
Another  way of  answering this is to  note that  AT  has  a  nontrivial null­
space,  and we  can  always  add  any  vector in the  nullspace to  a  solution 
x  to get  a different  solution. 

c)  Suppose v1 ,  v2  and  v3  are  orthonormal (forget  about (2b)). What  com­
bination  of  v1  and  v2  is  closest  to  v3 ?

If  we  imagine  the  right  triangle  out  from  the  origin  formed  by  av1  +

bv2  and  v3 ,  the Pythagorean  theorem  tells  us  that 0v1  + 0v2  =  0 is  the

closest point  to  v3  in  the plane  spanned by  v1  and  v2 .


3.  Suppose  we  have  the  Markov  matrix 
 
 
.3 
.3    . 
 
.4 
Note  that  the  sum  of  the  ﬁrst  two  columns  of  A  equals  twice  the  third 
column  of  A. 

.4 
.2 
.4 

A = 

.2 
.4 
.4 

a)  What are  the  eigenvalues  of  A? 
Zero is an eigenvalue because the columns  of  A are dependent. (A  is

singular.)

One is  an  eigenvalue because  A is  a Markov  matrix.

The  third  eigenvalue  is  −.2  because  the  trace  of  A  is  .8.  So  λ  =

0, 1, −.2. 

b)  Let  uk  =  Ak u(0).  If  u(0) = 

0 
# 
" 
10 
0 
We’ll start by  computing  uk  and then  ﬁnd the steady  state. This means 
ﬁnding  a general  expression  of  the form: 

, what is limk→∞ uk ? 

uk  = c1 λ

k x1  + c2λ
1

k x2  + c3 λ
2

k x3 . 
3

When  we plug in  the  eigenvalues  we found in part (3a), this becomes 

uk  = 0 + c2 x2  + c3 (−.2)k x3 . 

We  see  that  as  k  approaches  inﬁnity,  c2 x2  is  the  only  term  that  does 
not go  to  zero.

The key eigenvector in  any Markov process is the  one  with  eigenvalue

one.


3 

To  ﬁnd  x2 ,  solve  ( A − 1 I )x2  = 0: 
 

−.8 
.3 
.4 
.3    x2  =  0. 
.4  −.8 
 
.4  −.6 
.4 
The best way to  solve this  might be by  elimination.  However, because 
the  ﬁrst  two  columns  look  like  multiples  of  4  and  the  third  column 
3 
# 
" 
3
4 

looks like  a  multiple  of 3,  we  might get lucky  and guess  x2  = 
3 
# 
" 
3 
4 
sum  of  the  entries  of  uk  is  the  same for  all  k.  The  sum  of  the  entries  of 
3

# 
" 
3
4


. We know that in a Markov process, the 

u(0) is 10,  so  c2  = 1 and  u∞  = 

This gives  us  u∞  =  c2 

. 

.


4.  Find  a two by  two matrix that: 

. 

4 
−3 

a)  projects onto the line spanned by a  = 

(cid:20) 
(cid:21) 
Taa
The formula for  this  matrix is  P = 
.  This gives  us 
Ta a 
(cid:20) 
(cid:21) 
(To  test  this  answer,  we  can quickly check  that det P = 0.) 

16/25  −12/25 
−12/25 
9/25 

P = 

. 

. 

1
2

2 
1 

1
2

1
2

and 

x2  = 

A  = 

0 0 
0 3 

b)  has  eigenvalues  λ1  =  0  and  λ2  =  3  and  eigenvectors  x1  = 
(cid:20) 
(cid:21) 
2 
1 
Here the formula  we  need is  A = SΛS−1 .

(cid:21) (cid:20) 
(cid:21) (cid:20) 
(cid:20) 
(cid:21)  (cid:20) 
(cid:21)  (cid:20) 
(cid:20) 
(cid:21) 
(cid:20) 
4  −2 
2  −1 
If time permits,  we  can  check  this by  computing  the products  Ax i . 
c)  has real entries and  cannot be factored  as  BT B for  any  B. 
We know  that  BT B will  always be  symmetric,  so  any  asymmetric  ma­
(cid:21) 
(cid:20) 
0 
0
1
0 

(cid:21)−1

−1/3 
2/3 
2/3  −1/3 

trix has this property. For example, we could  choose 

0 0 
0 3 

A  = 

2 
1 

2 
1 

(cid:21) 

= 

1 
2 

(cid:20) 

(cid:21) 

. 

. 

4 

d)  is not  symmetric, but has orthogonal  eigenvectors. 
We know that  symmetric  matrices have orthogonal  eigenvectors, but 
so do other types of  matrices (e.g.  skew symmetric and  orthogonal)

when  we  allow  complex  eignevectors.

Two possible  answers  are:

(cid:20) 
(cid:21) 
cos  θ	 − sin  θ 
sin  θ 
cos  θ 

(skew  symmetric) 

(orthogonal). 

0
−1

1 
0 

(cid:20) 
(cid:21) 
5.  Applying  the least  squares method  to the system 

 

 
0 
1
3 
1   
  1
  4   
1
2 
1 
(cid:21) 
(cid:21) 
(cid:20) 
(cid:20) 
cˆ
= 
. 
gives the best  ﬁt vector 
dˆ 
a)  What is the projection  p of  b  = 

(cid:21) 
11/3 
−1 
# 

c 
d 

(cid:20)

= 

= b 

3

4 
1


onto  the  column  space  of


" 
" 
# 
We  know  that  11/3  times  the  ﬁrst  column  minus  1  times  the  second 
3 
# 
" 
4 
1 

column  is  the  closest  point  P  in  the  column  space  to 

,  so  the 

A =	

1
1
1

0 
1
2 

? 

answer is 

= 

= 

cˆ
dˆ

11 
3 

 


 
 
1 
0 
11/3 
(cid:20)
(cid:21) 
A 
−
  1   
  1   
8/3    . 
 
1 
2 
5/3 
b)  Draw the straight line problem that corresponds to this system. 
Plotting  the  entries  of  the  second  column  of  A against  the  entries  of  b 
we get the three points shown in Figure 1. The best  ﬁt line is  cˆ + dtˆ . 
6=  0  ∈  R3  so that the least  squares solution is 
c)  Find a different  vector  b 
(cid:20) 
(cid:21) 
(cid:21) 
(cid:20) 
cˆ
0 
dˆ  = 
. 
0
(cid:21) 
(cid:20) 
cˆ
We know that 
dˆ 
get a zero projection we need to  ﬁnd  a vector  orthogonal to the columns. 

is the projection of b onto the  column  space,  so to 

5 

4 

P1 

3 

(0, 3) 

(1, 4) 

P2 

b =  11  − t 
3 

2


1


P3 

(2, 1) 

−1 

0 
0 

−1


1

2

3


4 

Figure 1: Three data points and  their  “best ﬁt” line  11  − t.

3


1

# 
" 
We  could get  the  answer  b  =  −2 
1

the cross product  of  the columns to  ﬁnd  a value for  b. 

by inspection, or we could  use


Thank you for  taking  this  course! 

6


MIT OpenCourseWare 
http://ocw.mit.edu 

18.06SC Linear Algebra 
Fall 2011 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

