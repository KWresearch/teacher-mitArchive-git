Chapter  3 

Decision Making  under  Uncertainty


In  the  previous  lecture,  we  considered  decision  problems  in  which  the  decision  maker 
does  not  know  the  consequences  of  his  choices  but  he  is  given  the  probability  of  each 
consequence  under  each  choice.  In  most  economic  applications,  such  a  probability  is 
not  given.  For  example,  in  a  given  game,  a  player  cares  not  only  about  what  he  plays 
but  also  about  what  other  players  play.  Hence,  the  description  of  consequences  include 
the  strategy  proﬁles.  In  that  case,  in  order  to  ﬁt in that framework,  we would  need  to 
give other players’ mixed strategy proﬁles  in the description of  the game, making Game 
Theoretical  analysis  moot.  Likewise  in  a  market,  the  price  is  formed  according  to  the 
collective actions of all market participants, and hence the price distribution is not given. 

In all these problems, the decision makers hold sub jective beliefs about the unknown 
aspects  of  the  problem  and  use  these  beliefs  in  making  their  decisions.  For  example,  a 
player  chooses  his  strategy  according  to  his  beliefs  about  what  other  players may  play, 
and he  may  reach these  beliefs  through a combination of  reasoning  and the  knowledge 
of  past  behavior.  This  is  called decision making  under uncertainty. 

As  established  by  Savage  and  the  others,  under  some  reasonable  assumptions,  such 
sub jective beliefs  can be  represented by a probability distribution,  in  the  sense  that  the 
decision  maker  ﬁnds  an  event  more  likely  than  another  if  and  only  if  the  probability 
distribution  assigns  higher  probability  to  the  former  event  than  latter.  In  that  case, 
using the probability distribution, one can convert a decision problem under uncertainty 
to a decision problem under risk,  and apply  the analysis  of  the previous  lecture.  In  this 
lecture,  I will  describe  this  program  in  detail.  In particular,  I will  describe 

21 

22	

CHAPTER 3.  DECISION MAKING UNDER UNCERTAINTY 

•  the  conditions  such  consistent  beliefs  impose  on  the  preferences, 
•  the  elicitation  of  the  beliefs  from  the  preferences,  and 
•  the  representation  of  the  beliefs  by  a  probability  distribution. 

3.1	 Acts,  States,  Consequences,  and  Expected Util-
ity  Representation 

Consider a ﬁnite set C  of consequences.  Let S  be the set of all states of the world.  Take 
a  set  F  of  acts  f  : S → C  as  the  set  of  alternatives  (i.e.,  set X  = F ).  Each  state  s ∈ S 
describes  all  the  relevant  aspects  of  the  world,  hence  the  states  are mutually  exclusive. 
Moreover,  the consequence f (s) of act f  depends on the true state of the world.  Hence, 
the  decision  maker  may  be  uncertain  about  the  consequences  of  his  acts.  Recall  that 
the  decision maker  cares  only  about  the  consequences,  but  he  needs  to  choose  an  act. 

Example  1  (Game  as  a  Decision  Problem)  Consider a complete information game 
with  set  N  =  {1, . . . , n}  of  players  in  which  each  player  i  ∈ N  has  a  strategy  space  Si . 
The  decision  problem  of  a  player  i  can  be  described  as  fol lows.  Since  he  cares  about  the 
strategy  proﬁles,  the  set  of  consequences  is  C  = S1  × · · · × Sn . Since  he  does  not  know 
Q
what  the  other  players  play,  the  set  of  states  is  S  =  S−i  ≡ 
i Sj . Since  he  chooses 
j=6
among  his  strategies,  the  set  of  acts  is F  = Si , where  each  strategy  si  is  represented as  a 
function s−i  7
(si , s−i ). (Here,  (si , s−i)  is  the strategy proﬁle  in which  i  plays si  and  the 
→ 
others play s−i .)  Traditional ly, a complete-information game is deﬁned by also including 
the  VNM  utility  function  ui  :  S1  × · · · × Sn  → R  for  each  player.  Fixing  such  a  utility 
function  is  equivalent  to  ﬁxing  the  preferences  on  al l  lotteries  on  S1  × · · · × Sn . 
We would  like  to  represent  the decision maker’s preference  relation º on F  by  some 
R  such  that 
→

U  : F	

U (f ) ≡ E [u f ]

◦ 
R  is  a  “utility  function”  on  C  and  E  is  an 
(in  the  sense  of  (OR))  where  u  :  C 
→ 
expectation  operator  on  S . That  is, we want 

f  º g  ⇐⇒  U (f ) ≡ E [u ◦ f ] ≥ E [u ◦ g ] ≡ U (g) . 

(EUR) 

3.2.  ANSCOMBE-AUMANN MODEL 

23 

In the  formulation of Von Neumann and Morgenstern,  the probability distribution (and 
hence  the  expectation  operator  E )  is  ob jectively  given.  In  fact,  acts  are  formulated  as 
lotteries,  i.e.,  probability  distributions  on  C .  In  such  a  world,  as  we  have  seen  in  the 
last  lecture,  º  is  representable  in  the  sense  of  (EUR)  if  and  only  if  it  is  a  continuous 
preference  relation  and  satisﬁes  the  Independence Axiom. 
For  the  cases  of  our  concern  in  this  lecture,  there  is  no  ob jectively  given  probability 
distribution  on  S .  We  therefore  need  to  determine  the  decision  maker’s  (sub jective) 
probability assessment  on S .  This  is done  in  two  important  formulations.  First,  Savage 
carefully  elicits  the  beliefs  and  represents  them  by  a  probability  distribution  in  a world 
with  no  ob jective  probability  is  given.  Second,  Anscombe  and  Aumann  simply  uses 
indiﬀerence  between  some  lotteries  and  acts  to  elicit  preferences.  I  will  ﬁrst  describe 
Anscombe  and  Aumann’s  tractable model,  and  then  present  Savage’s  deeper  and more 
useful  analysis. 

3.2  Anscombe-Aumann Model 

Anscombe  and  Aumann  consider  a  tractable  model  in  which  the  decision  maker’s  sub-
jective  probability  assessments  are  determined  using  his  attitudes  towards  the  lotteries 
(with  ob jectively  given  probabilities)  as  well  as  towards  the  acts  with  uncertain  conse-
quences.  To  do  this,  they  consider  the  decision maker’s  preferences  on  the  set  P S  of  all 
“acts” whose outcomes are  lotteries on C , where P  is the set of all  lotteries (probability 
distributions  on C ).  In  the  language  deﬁned  above,  they  assume  that  the  consequences 
and  the decision maker’s pereferences on the  set of  consequences have  the  special  struc-
ture  of Von-Neuamann  and Morgenstern model. 
In  this  set  up,  it  is  straightforward  to  determine  the  decision  maker’s  probability 
assessments.  Consider  a  subset  A  of  S  and  any  two  consequences  x, y  ∈  C  with  x  Â 
y . Consider  the  act  fA  that  yields  the  sure  lottery  of  x  on  A,1  and  the  sure  lottery 
of  y  on  S\A.  (See  Figure  3.1.)  Under  some  continuity  assumptions  (which  are  also 
necessary  for  representability),  there  exists  some  πA  ∈  [0, 1]  such  that  the  decision 
maker  is  indiﬀerent  between  fA  and  the  act  gA  that  always  yield  the  lottery  pA  that 
gives x with probability πA  and y  with probability 1 − πA .  Then, πA  is  the  (sub jective) 
1 That  is,  fA (s) = x whenever  s ∈ A where  the  lottery  x  assigns  probability  1  to  the  consequence  x. 

24 

CHAPTER 3.  DECISION MAKING UNDER UNCERTAINTY 

fA 
6 

x 

y 

gA 
6

PA 

A

A 

d 
d 

1  - x 
x 

1  - y 
y 

πA  * x 
©©©©©©
d
HHHHHH
1 − πA 
j y 
PA 

-

S \ A


-

S \ A 

Figure  3.1:  Figure  for Anscombe  and Aumann 

3.3.  SAVAGE MODEL 

25 

probability  the  decision  maker  assigns  to  the  event  A  –  under  the  assumption  that 
πA  does  not  depend  on  which  alternatives  x  and  y  are used.  In  this  way,  one obtains 
a  probability  distribution  on  S .  Using  the  theory  of  Von  Neumann  and  Morgenstern, 
one  then  obtains  a  representation  theorem  in  this  extended  space  where  we  have  both 
sub jective  uncertainty  and  ob jectively  given  risk. 
While  this  is  a  tractable  model,  it  has  two  ma jor  limitation.  First,  the  analysis 
generates  little insights  into how one should think about the sub jective beliefs and their 
representation  through  a  probability  distribution.  Second,  in  many  decision  problems 
there may  not  be  relevant  intrinsic  events  that  have  ob jectively  given  probabilities  and 
rich enough to determine the beliefs on the events the decision maker is uncertain about. 

3.3  Savage Model 

Savage  develops  a  theory with  purely  sub jective  uncertainty.  Without  using  any  ob jec-
tively given probabilities, under certain  assumptions  of  “tightness”,  he derives  a unique 
probability  distribution  on  S  that  represent  the  decision  maker’s  beliefs  embedded  in 
his preferences,  and  then using  the  theory of Von Neumann and Morgenstern he  obtain 
a  representation  theorem –  in  which  both  utility  function  and  the  beliefs  are  derived 
from  the  preferences. 
Take a set S  of states  s of the world, a ﬁnite set C  of consequences  (x, y , z ), and take 
the  set F  = C S  of  acts  f  : S
C  as  the  set  of  alternatives.  Fix a  relation º  on F . We 
→ 
would  like to ﬁnd necessary and suﬃcient conditions on º  so that º can be represented 
by some U  in the sense of (EUR);  i.e., U (f ) = E [u f ].  In this representation, both the 
◦ 
utility  function  u  : C
R  and  the  probability  distribution  p  on  S  (which  determines 
→ 
E )  are  derived  from º.  Theorems  2  and  3  give  us  the  ﬁrst  necessary  condition: 
P 1  º  is  a  preference  relation. 
The  second  condition  is  the  central  piece  of  Savage’s  theory: 

3.3.1  The  Sure-thing  Principle 

The  Sure-thing  Principle  If  a  decision  maker  prefers  some  act  f  to  some  act  g 
when  he  knows  that  some  event  A ⊂ S  occurs,  and  if  he  prefers  f  to  g  when  he  knows 

26 

CHAPTER 3.  DECISION MAKING UNDER UNCERTAINTY 

that  A  does  not  occur,  then  he  must  prefer  f  to  g  when  he  does  not  know  whether  A 
occurs  or  not. 
This  is  the  informal  statement  of  the  sure-thing  principle.  Once  we  determine  the 
decision maker’s  probability  assessments,  the  sure-thing  principle will  give  us  the  Inde-
pendence Axiom,  Axiom  4,  of  Von Neumann  and Morgenstern.  The  following  formula-
tion of Savage, P2, not only implies this informal statement, but also allows us to state it 
formally,  by  allowing  us  to  deﬁne  conditional  preferences.  (The  conditional  preferences 
are  also used to deﬁne  the  beliefs.) 

P 2  Let  f , f 0 , g , g 0  ∈ F  and  B ⊂ S  be  such  that 
f (s) = f 0  (s)  and  g (s) = g 0 (s)  at  each  s ∈ B 

and 

f (s) = g (s)  and  f 0  (s) = g 0  (s)  at  each  s ∈6 B . 
If  f  º g, then  f 0  º g 0 . 

3.3.2  Conditional  preferences 

Using  P2,  we  can  deﬁne  the  conditional  preferences  as  follows.  Given  any  f , g , h  ∈  F 
and B ⊂ S , deﬁne  acts  f
B  and  g
B  by 
h
h
|
|
B  (s) = ( 
h
f
|
( 
if  s ∈ B 
g (s) 
h (s)  otherwise 
That  is, f
B  and g
B  agree with f  and g , respectively, on B , but when B  does not occur, 
h
h
|
|
they  yield  the  same  default  act  h. 

if  s ∈ B 
f (s) 
h (s)  otherwise 

and 

g h
B  (s) =
|

.

Deﬁnition  6  (Conditional  Preferences)  f  º g  given B  iﬀ  f
B . 
B  º g
h
h
|
|
P2  guarantees  that  f  º  g  given  B  is  well-deﬁned,  i.e.,  it  does  not  depend  on  the 
0  and  g
0  accordingly.  Check 
default  act  h.  To  see  this,  take  any  h0  ∈  F , and  deﬁne  f
h
h
B 
B 
|
|
that 

0 
h
h
B  (s) ≡ f (s) ≡ f
f
B 
|
|

0 
h
h
(s)  and  g
B  (s) ≡ g (s) ≡ g
B 
|
|

(s)  at  each  s ∈ B 

3.3.  SAVAGE MODEL 

and 

27 

f

0 
(s) ≡ h0  (s) ≡ g
h
B 
|

(s)  at  each  s ∈6 B . 

0 
h
h
h
B  (s)  and  f
B  (s) ≡ h (s) ≡ g
B 
|
|
|
0  º g
0  . 
Therefore,  by P2,  f
B  iﬀ  f
B  º g
h
h
h
h
B 
B
|
|
|
|
Note  that P2 precisely  states  that  f  º g  given B  is well-deﬁned.  To  see  this,  take  f 
0  . Moreover,  the 
and  g 0  arbitrarily.  Set  h = f  and  h0  = g 0 .  Clearly,  f  = f
B  and  g 0  = g
h
h
B
|
|
0  and  g  =  g
conditions  in  P2  deﬁne  f 0  and  g  as  f 0  =  f
B . Thus,  the  conclusion  of  P2, 
h
h
B 
|
|
0  º g
0  . 
“if  f  º g , then  f 0  º g 0”,  is  the same as “if  f
B , then  f
B  º g
h
h
h
h
B 
B
|
|
|
|
Exercise  2  Show  that  the  informal  statement  of  the  sure-thing  principle  is  formal ly 
true:  given  any  f1 , f2  ∈ F , and  any  B ⊆ S , 
[(f1  º f2  given  B )  and  (f1  º f2  given  S \B )] ⇒ [f1  º f2 ] . 
f
f
f
f
f
f
S\B ,  f 0  := f1
S \B ,  g 0  := f2  = f2
S \B , and 
[Hint:  deﬁne  f  := f1  = f1
B  = f2
B  = f2
B  = f1
1 
1 
2 
2 
2 
1 
|
|
|
|
|
|
f
f
S\B .  Notice  that  you  do  not  need  to  invoke  P2  (explicitly).] 
g  := f2
B  = f1
1 
2 
|
|
Null Events  Imagine that the decision maker remains indiﬀerence towards any changes 
made  to an action within an event B .  Namely,  for any acts f  and g ,  the decision maker 
remains indiﬀerent between f  and g , so long as f  and g  are identical on S\B , no matter 
how  widely  diﬀer  on  B .  In  that  case,  it  is  plausible  to  deduce  that  the  decision  maker 
does  not  think  that  event B  obtains.  Such  events  are  called  nul l. 
Deﬁnition  7  An event B  is said to be  null  if and only  if f  ∼ g  given B  for al l f , g ∈ F . 
Recall  that  our  aim  is  to  develop  a  theory  that  relates  the  preferences  on  the  acts 
with  uncertain  consequences  to  the  preferences  on  the  consequences.  (The  preference 
relation  º  on  F  is  extended  to  C  by  embedding  C  into  F  as  constant  acts.  That  is, 
we  say  x  º  x0  iﬀ  f  º  f 0  where  f  and  f 0  are  constant  acts  that  take  values  x  and  x0 , 
respectively.)  The  next  postulate  does  this  for  conditional  preferences: 
P 3  Given  any  f , f 0  ∈  F ,  x, x0  ∈ C , and  B  ⊂  S , if  f  ≡  x,  f 0  ≡  x0 , and  B  is  not  nul l, 
then 

f  º f 0  given  B  ⇐⇒  x º x0 . 
For B = S , P3  is rather trivial, a matter of deﬁnition of a consequence as a constant 
act.  When  B  = S ,  P3  is  needed  as  an  independent  postulate.  Because  the  conditional 
preferences are deﬁned by setting the outcomes of the acts to the same default act when 
the  event  does  not  occur,  and  two  distinct  constant  acts  cannot  take  the  same  value. 

6
28 

CHAPTER 3.  DECISION MAKING UNDER UNCERTAINTY 

3.3.3  Representing  beliefs  with  qualitative  probabilities 

We  want  to  determine  the  decision  maker’s  beliefs  reﬂected  in  º.  Towards  this  end, 
given  any  two  events  A  and  B ,  we want to  determine  which event  the decision maker 
thinks  is more  likely.  To do  this,  take  any  two  consequences  x, x0  ∈ C  with  x Â x0 . The 
decision maker  is  asked  to  choose  between  the  two  gambles  (acts)  fA  and  fB  with 
(
( 
If  the  decision  maker  prefers  fA  to  fB , we  can  infer  that  he  ﬁnds  event  A  more  likely 
than  event  B ,  for  he  prefers  to  get  the  “prize”  when  A  occurs,  rather  than  when  B 
occurs. 

if  s ∈ A
x 
x0  otherwise 
if  s ∈ B 
x 
x0  otherwise 

fB  (s) =

fA (s) =

(3.1) 

. 

, 

Deﬁnition  8  Take  any  x, x0  ∈ C  with  x Â x0 . Given  any  A, B  ⊆ S ,  A  is  said  to  be  at 
least  as  likely  as B  (denoted  by  Aº˙ B ) if and  only  if  fA  º fB , where  fA  and  fB  deﬁned 
by  (3.1). 

We want  to make  sure  that  this  yields well-deﬁned beliefs.  That  is,  it  should not  be 
the  case  that, when we  use  some  x  and  x0 , we  infer  that  decision maker  ﬁnds A  strictly 
more likely than B , but when we use some other y and y 0 , we infer that he ﬁnds B strictly 
more  likely  than A.  Then  next  assumption  guaranties  that º˙
is  indeed well-deﬁned. 
P 4  Given  any  x, x0 , y , y 0  ∈ C  with  x Â x0  and  y Â y 0 , deﬁne  fA , fB , gA , gB  by 
(
(
if  s ∈ A 
if  s ∈ A
y 
x 
y 0  otherwise 
x0  otherwise 
(
(
if  s ∈ B 
if  s ∈ B
y 
x 
y 0  otherwise 
x0  otherwise 

fB  (s) =

fA (s) =

gB  (s) =

gA (s) =

. 

,

,

Then, 

fA  º fB  ⇐⇒  gA  º gB . 
Finally, make  sure  that we  can  ﬁnd  x  and  x0  with  x Â x0 : 

3.3.  SAVAGE MODEL 

29 

P 5  There  exist  some  x, x0  ∈ C  such  that  x Â x0 . 

We  have  now  a well-deﬁned  relation º˙ that  determines which  of  two  events  is more 
likely.  It  turns  out  that, º˙
is  a  qualitative  probability, deﬁned  as  follows: 

Deﬁnition  9  A relation º˙ between  the  events  is  said  to  be  a  qualitative probability  iﬀ 

1.  º˙ is  complete  and  transitive; 
2.  for  any  B , C, D ⊂ S  with  B ∩ D = C ∩ D = ∅ ,

B  ˙
ºC  ⇐⇒  B ∪ Dº˙ C ∪ D; 

3.  Bº˙ ∅  for  each  B ⊂ S , and  SÂ˙ ∅ . 

Exercise  3  Show  that, under  the postulates P1-P5,  the  relation º˙ deﬁned  in Deﬁnition 
8  is  a  qualitative  probability. 

3.3.4  Quantifying  the  qualitative  probability  assessments 

Savage  uses  ﬁnitely-additive  probability  measures  on  the  discrete  sigma-algebra : 

Deﬁnition  10  A  probability measure  is  any  function  p : 2S 

[0, 1]  with 

→ 

1.  if  B ∩ C  = ∅ , then  p (B ∪ C ) = p (B ) + p (C ), and 
2.  p (S ) = 1. 

We would  like  to represent our qualitative probability º˙ with a  (quantitative) prob-
ability measure  p  in  the  sense  that 

Bº˙ C  ⇐⇒  p (B ) ≥ p (C ) 

∀ B , C  ⊆ S. 

(QPR) 

Exercise  4  Show  that,  if  a  relation º˙ can  be  represented  by a  probability measure,  then 
º˙ must  be  a  qualitative  probability. 

30 

CHAPTER 3.  DECISION MAKING UNDER UNCERTAINTY 

When S  is  ﬁnite,  since º˙
is  complete  and  transitive,  by Theorem 2,  it  can be  repre-
sented by some function p, but there might be no such function satisfying the condition 1 
in  the  deﬁnition  of  probability measure.  Moreover,  S  is  typically  inﬁnite.  (Incidentally, 
the  theory  that  follows  requires  S  to  be  inﬁnite.) 
We  are  interested  in  the  preferences  that  can  be  considered  coming  from  a  decision 
maker  who  evaluates  the  acts  with  respect  to  their  expected  utility,  using  a  utility 
function  on  C  and  a  probability  measure  on  S  that  he  has  in  his  mind.  Our  task 
at  this  point  is  to  ﬁnd  what  probability  p (B )  he  assigns  to  some  arbitrary  event  B . 
Imagine that we ask this person whether p (B ) ≥ 1/2.  Depending on his sincere answer, 
we  determine  whether  p (B )  ∈  [1/2)  or  p (B )  ∈  [0, 1/2, 1]. Given  the  interval,  we  ask 
whether  p (B )  is  in  the  upper  half  or  the  lower  half  of  this  interval,  and  depending  on 
his  answer,  we  obtain  a  smaller  interval  that  contains  p (B ). We  do  this  ad  inﬁnitum. 
Since  the  length  of  the  interval  at  the  nth  iteration  is  1/2n , we  learn  p (B )  at  the  end. 
For  example,  let’s  say  that  p (B ) = 0.77. We  ﬁrst  ask  if  p (B )  ≥  1/2.  He  says  Yes. 
We  ask  now  if  p (B )  ≥  3/4.  He  says  Yes.  We  then  ask  if  p (B )  ≥  7/8. He  says  No. 
Now,  we  ask  if  p (B )  ≥  13/16  =  (3/4 + 7/8) /2. He  says  No  again. We  now  ask  if 
p (B )  ≥  25/32  =  (3/4 + 7/8) /2.  He says No.  Now  we ask  if  p (B )  ≥  49/64. He  says 
Yes now.  At this point  we  know  that  49/64 ˜=0.765 ≤  p (B ) <  25/32 ˜=0.781.  As we ask 
further we  get  a better  answer. 
This  is what we  will  do,  albeit  in  a  very  abstract  setup.  Assume  that  S  is  inﬁnitely 
divisible  under  º˙ . That  is,  S  has 

2  = S  and D1
1  ∪ D1
2 , 
•	 a  partition  {D1
2} with D1
1∼˙ D1
1 , D1
1∪D2  = D1
4  = D1
1 , D2
4 ,
a partition {D2
4} with D2
2 , and D2
• 
1∼˙ D2∼˙ D2
1 , D2 , D2
3∼˙ D2
3∪D2
3 , D2
2	
2 
2
. . .• 
©
1 ,
a  partition  Dn
•	
· · ·

2n ,

1 ∼˙ · · · ∼˙ Dn 
and Dn 
. . .• 
ad  inﬁnitum. 

ª 
2n  with Dn 
2k  = Dn
2k−1  ∪ Dn 
2  = Dn
1  ∪ Dn 
1 
k 
−1 ,  . . . ,  Dn 
−1 ,  . . .,
, Dn 

3.3.  SAVAGE MODEL 

31 

S 

D2 
2
. . . 

D1 
1
D1 
2
. . . 

D2 
1 
D3 
2
. . . 

D4 
2 
. . . 

,

Exercise  5  Check that, if º˙ is represented by some p, then we must have p (Dn
r ) = 1/2 . 
n
Given any  event B , for  each n, deﬁne 
(
[ )
r
i 
k (n, B ) = max r B  ˙
| º 
Dn
i=1 
where we  use  the  convention  that ∪r  Di  = ∅ whenever  r < 1. Deﬁne
i=1 n 
k (n, B ) 
. 
p (B ) :=  lim 
2n 
n→∞ 
Check that k (n, B ) /2 ∈ [0, 1] is non-decreasing  in n.  Therefore,  limn→∞ k (n, B ) /2 is 
n
n
well-deﬁned. 
is  transitive,  if  Bº˙ C , then  k (n, B ) ≥  k (n, C )  for  each  n,  yielding  p (B ) ≥ 
Since  º˙
p (C ). This  proves  the  =  part  of  (QPR)  under  the  assumption  that  S  is  inﬁnitely-
⇒ 
divisibile.  The  other  part  (
)  is  implied  by  the  following  assumption: 
⇐
P 6’  If  BÂ˙ C , then  there exists a ﬁnite partition  {D1 , . . . , Dn} of  S  such  that  BÂ˙ C ∪ 
Dr  for  each  r. 
Under  P1-P5,  P6’  also  implies  that  S  is  inﬁnitely-divisibile.  (See  the  deﬁnition  of 
“tight” and  Theorems  3 and  4 in Savage.)  Therefore,  P1-P6’ imply  (QPR),  where  p  is 
deﬁned  by  (3.2). 

(3.2) 

Exercise  6  Check  that,  if  º˙ is  represented  by  some  p0 , then 
k (n, B ) + 1
k (n, B ) 
≤ p0  (B ) < 
2n 
2n 
at  each  B . Hence,  if  both  p  and  p0  represent  º˙ , then  p = p0 . 
Postulate  6  will  be  somewhat  stronger  than  P6’.  (It  is  also  used  to  obtain  the 
continuity  axiom  of Von Neumann  and Morgenstern.) 

32 

CHAPTER 3.  DECISION MAKING UNDER UNCERTAINTY 

P 6  Given any x ∈ C , and any g , h ∈ F  with g Â h, there exists a partition {D1 , . . . , D
of  S  such  that 

n} 

g Â hx
i

and  g x
i Â h


for  each  i ≤ n  where 
(

h

x
i (s) =


Take 

and

g =

h

f
B

if  s ∈ Di 
x

s)  otherwise 
h (


(

(deﬁned in (3.1)) to obtain P6’. 

x
and  g 
i

(s) =


=

f
C 

if  s ∈ Di
x

s)  otherwise 
g (


.


Theorem 5  Under P1-P6, there exists a unique probability measure 

p 

such that 

˙
B C 
º

⇐⇒ 

p

(B )

≥

p

(C ) 

B , C  S.
⊆
∀

(QPR) 

3.3.5  Expected Utility Representation 

In Chapter 5, Savage shows that, when 
is ﬁnite, Postulates P1-P6 imply Axioms 2-4 
C 
of Von Neumann and Morgenstern –as well as their modeling assumptions such as only 
the probability distributions on the set of prizes matter.  In this way, he obtains the 
following Theorem:2 

Theorem 6  Assume that 
is ﬁnite.  Under P1-P6, there exist a utility function 
C 
R  and  a  probability measure  p : 2
→ [0
, 1] such  that 
C

S
→
X 
X
p ({s|f (s) = c}) u (c) ≥ 
p ({s|g (s) = c}) u (c) 
c∈C 
c∈C

f  º g  ⇐⇒ 

:u 

for  each  f , g ∈ F . 

2 For  the  iniﬁnte  C , we need  the inﬁnite  version  of  the  sure-thing  principle: 

P 7  If  we  have  f  º  g (s)  given  B  for  each  s ∈ B , then  f  º g  given  B .  Likewise,  if  f (s) º  g  given  B 
for  each  s ∈ B , then  f  º g  given  B . 
Under  P1-P7,  we  get  the  expected  utility  representation  for  general  case. 

MIT OpenCourseWare
http://ocw.mit.edu 

14.123 Microeconomic Theory III

Spring 2010 


For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

