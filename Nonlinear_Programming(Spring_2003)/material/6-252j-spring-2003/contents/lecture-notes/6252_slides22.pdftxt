6.252 NONLINEAR PROGRAMMING 


LECTURE 22:  ADDITIONAL DUAL METHODS


LECTURE OUTLINE


•  Cutting Plane Methods 
•	 Decomposition 

******************************** 
•  Consider the primal problem 

minimize  f (x)

gj (x) ≤ 0,
subject to  x ∈ X, 
assuming −∞ < f  
∗  < ∞. 
•	 Dual problem:  Maximize 

j = 1, . . . , r,


q(µ) =  inf  L(x, µ) =  inf 
x∈X 
x∈X
subject to µ ∈ M = {µ | µ ≥ 0, q(µ) > −∞}.


{f (x) +  µ g(x)}
(cid:3) 

CUTTING PLANE METHOD 
(cid:1) 
(cid:2) 
•  kth iteration, after µi  and g i  = g  xµi
 have been

generated for i = 0, . . . , k  − 1:  Solve 

max Qk (µ)

µ∈M


where 

Set


(cid:3) 
q(µ i ) + (µ − µ i )
Qk (µ) =   min 
i=0,...,k−1 

(cid:4) 
(cid:3) g
i
 .


k  = arg max

Qk (µ).

µ

µ∈M 

q(µ0) + (µ  −  µ0)'g(x µ0 
)

q(µ1) + (µ  −  µ1)'g(x

µ1)


q(µ) 

µ0 

µ3  µ* 

µ2

µ1

M


µ 

POLYHEDRAL CASE


(cid:4) 
(cid:3) 
(cid:3) 
q(µ) =  min  aiµ + bi 
i∈I 
where I  is a ﬁnite  index set, and ai  ∈ (cid:5)r  and bi  are 
given. 
•  Then subgradient gk  in the cutting plane method 
is a vector aik  for which the minimum is attained. 
•  Finite termination expected. 

q(µ) 

µ0 

µ3 

µ2

µ1

M 

µ4 =


µ*

µ 

CONVERGENCE


•  Proposition:  Assume that the min of Qk  over M 
is  attained  and  that  q  is  real-valued.  Then  every 
limit  point  of  a  sequence  {µk }  generated  by  the 
cutting plane method is a dual optimal solution. 
Proof:  g i  is a subgradient of q at µi , so 
∀  µ ∈ M ,  
(cid:3) g i  ≥ q(µ), 
q(µ i ) + (µ − µ i )
∀  µ ∈ M .  
Qk (µ k ) ≥ Qk (µ) ≥ q(µ), 
(1) 
µ.  Then,  µ  ∈  M , 
•  Suppose  {µk }K  converges  to  ¯
¯
and from (1), we obtain for all k and i < k, 
(cid:3) g i  ≥ Qk (µ k ) ≥ Qk ( ¯  
µ) ≥ q( ¯  
q(µ i ) + (µ k − µ i )
µ).

•  Take the limit as i → ∞, k → ∞, i ∈ K , k ∈ K , 

lim  Qk (µ k ) =  q( ¯µ). 
k→∞, k∈K 

Combining with (1), q( ¯µ) =  maxµ∈M  q(µ). 

LAGRANGIAN RELAXATION


•  Solving the dual of the separable problem 

minimize 

(cid:5) 
J 
fj (xj ) 

j=1 
subject to  xj  ∈ Xj ,

j

 = 1, . . . , J, 

(cid:5) 
J 
Aj xj  = b. 

j=1 

•  Dual function is 
(cid:5) 
(cid:3) 
J 
(cid:3)
min  fj (xj ) +  λ
q(λ) =  
xj ∈Xj 
j=1 
(cid:5) (cid:3)  (cid:1) 
(cid:2) 
J 
fj  xj (λ) + λ
= 

(cid:3)

(cid:4) 
Aj xj  − λ
(cid:3)

b 

(cid:4) 
Aj xj (λ)  − λ
(cid:3)

b 

j=1 

where xj (λ) attains the min.  A subgradient at λ is 

(cid:5) 
J

Aj xj (λ) − b. 
gλ  = 
j=1 

DANTSIG-WOLFE DECOMPOSITION


•  D-W  decomposition method  is  just  the  cutting 
plane applied to the dual problem maxλ q(λ). 
•  At  the  kth  iteration, we solve  the  “appro ximate 
dual ” 
(cid:3) 
λk  = arg max Qk (λ) ≡  min 
q(λi ) + (λ − λi )
λ∈(cid:6)r 
i=0,...,k−1 

(cid:4) 
(cid:3) g i  . 

•  Equivalent linear program in v and λ 
maximize  v

subject to  v ≤ q(λi ) + (λ − λi )

(cid:3) g i ,

 = 0, . . . , k  − 1


i

The dual of this (called master problem ) is 

minimize 

k−1 
(cid:5)  (cid:1) 
(cid:2) 
ξ i  q(λi ) − λi (cid:3) 
g i 

i=0 
k−1 
(cid:5) 
ξ i  = 1,

k−1 
(cid:5) 
ξ i g i  = 0, 

subject to 

i=0 
ξ i  ≥ 0,

i=0 
 = 0, . . . , k  − 1,


i

DANTSIG-WOLFE DECOMPOSITION (CONT.)


•  The master problem is written as 
(cid:7) 
(cid:6) 
k−1 
(cid:5)  (cid:5) 
(cid:1) 
(cid:2) 
J
ξ i fj  xj (λi ) 

minimize 

i=0 

j=1 
k−1 
(cid:5) 
ξ i  = 1,

(cid:6) 
k−1 
(cid:5)  (cid:5) 
J
ξ i xj (λi ) = b, 
Aj 

(cid:7) 

subject to 

i=0 
ξ i  ≥ 0,

j=1 
 = 0, . . . , k  − 1. 

i

i=0 

•  The  primal  cost  function  terms  fj (xj )  are  ap-
proximated by 

k−1 
(cid:5) 
(cid:1) 
(cid:2) 
ξ i fj  xj (λi ) 

i=0 

•  Vectors xj  are expressed as 
k−1 
(cid:5) 
ξ i xj (λi ) 

i=0 

GEOMETRICAL INTERPRETATION 


•  Geometric interpretation of the master problem 
(the  dual  of  the  approximate  dual  solved  in  the 
cutting plane method) is inner linearization . 

f j(xj) 

xj(λ 0) 

xj(λ 2) 

x

j(λ 3) 

x

j(λ 1)

0 

Xj 

xj 

•  This  is  a  “dual”  operation  to  the  one  involved 
in  the cutting plane approximation, which can be 
viewed as outer linearization . 

