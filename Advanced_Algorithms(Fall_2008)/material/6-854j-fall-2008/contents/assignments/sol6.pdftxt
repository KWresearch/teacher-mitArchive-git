MIT OpenCourseWare
http://ocw.mit.edu 

6.854J / 18.415J Advanced Algorithms 
Fall 2008
��

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

18.415/6.854  Advanced Algorithms 

Problem   Set  Solution 6 
Lecturer:  Michel  X .   Goemans  

1 .   The  betweenness  prob lem   is  defined  as  follows:  We  are  given  n  and  a  set  T  of  m 
triples of  t h e  elements of  (1,. . . ,n ) .   We  say tha t   an ordering 7r  of  (1, . . . ,n )   satisfies 
a  triple  (i,j, k ) ,   if  j  is between i  and  k in n .   (For example, the  ordering  ( 5 , 3 , 1 , 2 , 4 )  
satisfies the  triples  ( 5 , 1 , 2 )  and  (1,3,5),but  not  ( 3 , 2 , 1 ) ) .  The question  is t o  find an  
ordering  of  (1, . . .,n )   tha t   satisfies the  maximum number  of  triples  in T .  
This  problem  is  known  to  be  NP-hard,  even  if  we  restrict  to   instances  for  which 
an  ordering  tha t   satisfies all t h e  triples  exist. 

( a )   Use  randomization  to  find a simple  ;-approximation  algorithm for  this prob- 
lem.  Prove  t h e  correctness  of  your  algorithm. 
Let  7r  be  a n  ordering of  (1,.. . ,n )   chosen from  the   set  of  all such  orderings uniformly  a t  
random.  For  every  fixed  triple  ( i ,  j, k )   in  T ,  the   ordering  n  induces  a  random  ordering 
on  the  elements  i ,  j ,  k.  Therefore  th e  probability  t h a t   7r  satisfies th is  triple is  the  same a s  
th e  probability  t h a t   t h e  induced  ordering is  one of  ( i ,  j ,  k) and   (k ,  j ,  i ) .   Thus ,  7r  satisfies 
any  fixed  triple  in  T  with  probability  113.  Therefore, by  t h e   linearity  of  expectation,  a 
random  ordering  satisfies  $IT[ triples.  Since  IT1  is  an   upper  bound  on  t h e   number  of 
triples  t h a t   can  be  satisfied,  th e   algorithm  t h a t  ou tpu ts   a  random  ordering of  ( 1 , .  . . ,n )  
is  a  ;-approximation. 

(b )   Use  the  method  of  conditional expectations to  derandomize your  algorithm. 
We  want  t o  find  an   ordering n l  ,7 r2 ,   . . . ,n,  t h a t   satisfies a t  least  one  th i rd   of  the   triples. 
The  idea is  t o  pick  a value for Ti  t h a t  maximizes the  conditional expectation of  th e  num- 
ber  of  satisfied  triples  assuming  the   choices  t h a t   we  have  already  made  for  T I , .  . . ,ni-1 
(Th e  expectation is over the  random  choice of  th e  rest of  the  ordering).  Here's the  sketch 
of  the   algorithm: 

for  i  := 1 t o n  do  

mas  := 0;  

for j  := 1 t o n  do  

if  j $ { n l ,  7r2,. . .,ni-1)  then 
E  := Exp(  number  of  satisfied  triples  I 
The  first  i  elements  of  th e  ordering a re  T I ,  n2, . . .,xi-1,  j  ) ; 
if  E > mas  then   

rnaz  := E; 

7ri  := j; 


endfor 

endfor 


To compute  the   conditional expectations  of  the  number  of  satisfied  triples  assuming t h a t  
t h e  first  i  elements  of  th e  ordering a re  7r1, ~ 2 , .. . ,xi-1,  j ,  we  use  the  following algorithm: 
We  divide  t h e  triples  (q ,  r , s )  of  T  into th ree  categories: 

I{q , r , s )  n { ~ 1 , ~ 2 , . . . , ~ i - l , j ) l> 2: 
In  this  case  the   probability  t h a t   the   triple  is  satisfied  is  either  0  or  1, because  the  
s t a tu s  of  the   triple is  completely  determined  and  does not  depend  on  fu tu re  choices. 
Let  m l   be  th e  number  of  triples  in  this  category which  are  satisfied. 
I
~ 
)
s
,
~
,
Q
{
{ n l , n 2 , . . - , n i - l , j ) l   = 1: 
In  th is   case, if  {q, r, s )  n { r l ,  7 r 2 ,   . . . ,ri-1, j) = { r ) ,   th e  probability  t h a t  th e  triple  is 
satisfied is 0, otherwise, this probability  is  $.  Let m2  be th e  number  of  triples  (q, r ,  s )  
in  th is   category for  which  { q , r, s )  fl{ n l ,  n2 , .  . . ,7ri-1,  j )  #  { r ) .  
I { Q , ~ , s )
 
- .- , n i - i , j ) l   = 0: 
n { ~ 1 , ~ 2 ,
For  every  triple  in  this  category,  t h e  probability  t h a t   i t   is  satisfied  is  exactly  Q. Let 
ms  be  th e  number  of  triples  in this  category. 
By th e   linearity of  expectation, th e  conditional expected value of  t h e  number  of  satisfied 
triples  is  exactly  m l  + 7 + y.Furthermore,  for  a  given  sequence  n l ,  n2, . . . ,ni-1,  j, 
one  can  easily compute  the   values of  m l ,  ma, ms.  Therefore, t h e  above  algorithm  can be 
implemented  efficiently. 

(c)  Assume there is an ordering that satisfies all the triples in T .   Prove that  there 
are  vectors u l ,  . . .,vn  E Rn  such that 

for  all  i  # j ,  
for  all  ( i ,j, k) E T 

Consider an  ordering n1, 7~2,.. . ,nn  t h a t  satisfies all th e  triples.  Therefore if  ai denotes the  
position  of  i  in this ordering, then  for every triple  (i,j ,  I c )   E T ,  (ai- a j) (ak- aj)< 0.  Let 
th e  vector  vi  be  th e  vector  t h a t   has  ai  in  i ts  first coordinate  and  0 elsewhere.  Therefore, 
(vi-2rj)(uk-uj)  = ( ~ i - ~ j ) ( ~ k - ~ j )< 0.  Also, for e v e r y i  # j,  llui-ujll  = lai-a.13  -> I .  
Therefore, U ~ ' S  constitute  a  feasible solution for  th e  program  (1 ) .  

Show how  we  can  find  such v l ,  . . . ,u,  using semidefinite programming. 

Let  Y  be  an  n  x  n  matrix  defined by 

We  know  t h a t   such  a  ma t r ix   is  positive  semidefinite.  Conversely,  for  every  positive 
semidefinite ma t r ix  Y ,  we know how t o  find ui's satisfying  (2). The  constraints I  lui -v j   1  1  > 
1 and   ( ~ i- u ~ ) ( u ~- ~ j )5 0  can  be  written  in  terms  of  Y  as  yii  + Y j j   - 2yij  > 1 and  
Y i k  +y j j  - yij - yjk  < 0.  Therefore, program  (1) is equivalent t o  the  following semidefinite 
program.  (Here we  only need  a  feasible solution, so we  can take  a n  a rb i t ra ry  function  as 
t h e  objective function). 

for  all i # j, 
for  all  ( i ,j ,  k )   E T 

(d )   	 Give an  example where t h e  program  ( I )is satisfiable, bu t  there  is no ordering 
tha t   satisfies all  the  triples in T. 

Let  n = 4 and  T  = { ( 1 , 2 , 3 ) ,  ( 2 , 3 , 4 ) ,  ( 3 , 4 , 1 ) ) .  Assume the re  is  an ordering of  { 1 , 2 , 3 , 4 )  
satisfying th e  triples in T .  We may assume, without  loss of  generality, t h a t   1 comes before 
2  in  this  ordering.  Therefore,  since  the   triple  ( 1 , 2 , 3 )  is  satisfied,  3  must  come  after  2, 
and  since t h e  triple  ( 2 , 3 , 4 )  is satisfied, 4 must  come after 3.  Therefore, th e  ordering does 
not  satisfy the   triple  ( 3 , 4 , 1 ) .  This  shows t h a t   the   above  instance is not  satisfiable. 
Now,  let  vi's be  defined  as follows: 

I t   is easy  t o  verify  t h a t   vl ,v2 ,  VQ ,vq  is a  feasible solution t o  t h e  program  (1). 

(e)  	 Assume  tha t   vl , . . . ,v,  E  Rn  is  a  solution  of  t h e   program  (1). Choose  r  uni-
formly a t   random  from  {p E  Rn  : 1  lpll  = 11, and  consider  the  ordering obtained 
by  sorting  the   elements  of  { I ,. . . ,n }  with  respect  to   the ir   rTvi  value.  Show 
t h a t   in expectation  this  ordering satisfies a t   least  half  the  constraints  in T. 

We  prove  t h a t   in  t h e   ordering  t h a t   is  obtained  by  sorting  rTv i 's ,  t h e   probability  t h a t  
any  fixed  triple  in  T  is  satisfied  is  a t   least  112.  This,  by  the   linearity  of  expectation 
implies  t h a t   the   expected  number  of  satisfied  triples  is  a t   least  + T .  Therefore, what  we 
need  t o   prove  is  t h a t   for  every  triple  ( i ,  j ,  k )   E  T ,   if  we  pick  r  a t   random,  then   with 
probability  a t   least  112, we  either have  r.v;  < r .v j   < r.vk  or  r.vk  < r .v j  < r.vi.  In  other 
words,  we  need  t o  prove  t h a t   with  probability  a t  least  112, r.vi  - r.vj  = r.(vi  - v j )   and  
r.vk  - r.Vj  = r . (vk  - vj)  have  different  signs.  Let  z  := vi  - v j   and   y  := vk  - vj.  In 
other  words,  we  would  like  t o   compute  the   probability  t h a t   the   hyperplane  normal  t o  
r  separates x  from  y .   In  class,  we  have  seen  t h a t   this  probability  is  equal  t o   the   angle 
between  x  and   y  divided  by  27r.  Since this  angle  is  a t   least  n / 2   because  of  th e   program 
( I ) ,we  a re  done. 

Consider  the   following  scheduling  problem.  We  are  given  n  jobs  tha t   are  all 
available a t   time  0  and  t h a t   can  be  processed  on  any  of  r n   machines.  Each job 
has a processing t ime  p j  which represents  t h e  amount  of  t ime  a machine  (any one 
of  them)  needs  t o  process  i t   (without  interruption).  A machine can  only  process 
one job  a t   a  time.  This  scheduling problem  is  t o   assign  each job  to   a  machine 
and  schedule the  jobs  so  as  t o  minimize C jp jC j   where  C j   represents  the   t ime  a t  
which  the   processing  of  job  j  completes.  (For example,  if  we  have  5 jobs  of  unit 
processing  t ime   and  3 machines,  there   are  many  ways  of  obtaining  an  objective 
function  value  of  1+ 1+ 1+ 2 + 2 = 7.) 
( a )   Show  tha t   t h e  problem  is  equivalent  to  minimizing EL1M:  where  Mi  is  the  
to ta l  amount  of  processing t ime  assigned t o  machine i .  
Consider  a  solution  SOL ,  and   let  a i l ,  a i2 , .  . . ,ail,  be  th e   list  of  jobs  t h a t   are  scheduled 
on  th e   i ' t h  machine  in  this  solution.  We  have 

Therefore, 

Therefore, since  C jp;  does  not  depend  on  SO L ,  minimizing C jp j C j   is  equivalent  t o  
minimizing C z l M;  . 
(b )   Let  L  = A C jp j  be  the average  load of  any  machine.  Show that  any  optimum 
solution for  C:=,  Mf  will  be  such  that  each  machine  i  either  satisfy Mi  < 2L 
or  processes a single job  j with p j  > 2L. 

Consider  a n  optimum  solution  SO L  and   assume  there  is  a machine  i  with  Mi  > 2L  t h a t  
processes more  t h a n  one job.  Let  j be  the   shortest job  running  on  th is  machine.  By  the  
definition of  L ,  the re  is a machine  k  with Mk  < L.  Now,  consider th e  solution  SOL '  t h a t  
is obtained  from  SO L  by  running job  j on t h e  machine  k instead of  the  machine  i .   If  M: 
denotes t h e  to ta l   amount  of  processing  time  assigned  t o  machine  i  in  SOL ' ,  we  have 

Therefore, 

But  since j is t h e  shortest job  on machine  i ,  we  have p j  < M i /2 ,  and  therefore, p j  - Mi + 
Mk  5  -Mi12  + Mk  < -2L/2  + L  = 0.  Thus, C ~i~ is  smaller  th an   C M f ,  which  is  a 
contradiction  with  the   assumption  t h a t   SO L  is  optimal. 

(c)  	 Assume that p j  2 a L  for  some constant a > 0  for  every job j, and assume that 
all p j ' s   can  only  take  k  different values, where  k  is a fixed  constant.  Design a 
polynomial- time algorithm for  this  case. 
We  use  dynamic  programming  t o   solve  this  problem.  Let  f m ( n l ,  n2 , .  . . ,n k )  denote  the  
minimum  value  of  C M;  for  scheduling  n l   jobs  with  processing  time  p l ,   n2  jobs  with 
processing time p2,  . . . , and  nk  jobs with processing time pk  on m machines.  The  number 

of  such  subproblems  is  a t  most  mn"  which  is  a  polynomial  in  n  and   m.  Now  we  only 
need  t o  find  a  recurrence  for  computing  th e  values of  f m  ( n l ,  n2, . . . ,n k ) .  
Since pj's  are a t  least  a L  and  each machine  i either processes only  one job,  or  processes 
more th an  one job with to ta l  processing time a t  most 2L, therefore in any optimal solution, 
t h e  number  of  jobs  on  each machine  is  a t  most  2 / a .   Assume t h a t   in  an  optimal solution 
machine  rn  processes  r j  jobs  of  processing  time  p j ,   for  j  =  1 , .. . ,k .   By  the   above 
argument,  xizlr j   5  2 / a .   Also,  by  th e   definition  of  f ,  t h e   value  of  th e   solution  is 
r j p j ) 2 + fm-1 ( n l  - r l ,  n2 - r2, . . .,nk  - r k )  On th e  other hand, for every sequence 
(Cj,l 
k 
?'  E R = { ( r l , . . . ,r r  )  : zFZ1 
5 n i   for  every i , there  is a  solution of  cost 
r i   5 2 / a )   with 
+ f m - l ( i i   - 3- Thus, 
k(Cjzl 

The   size of  R  is  a t   most  ( 2 / a ) <   which  is  a  constant.  Therefore, we  can  use  the   above 
recurrence t o  compute f m  (n ') in constant time given t h e  values of  frn-1   (G-F). For th e  base 
case,  i t   is  clear  t h a t   f1(G) = (C jn jp j )2 .   Therefore, we  can  use  dynamic  programming 
t o  solve th e  problem  in  polynomial  time. 
(d )   Assume  that  p j   >  a L   for  some  constant  a  >  0  for  every  job  j.  Design  a 
polynomial-time approximation scheme for  this  case. 

Let  I denote t h e   instance  of  the   problem  t h a t   is  given  as th e   input.  F i rs t ,  for  every job 

j  with  a  processing  time  greater  th an   2L, we  assign  a  machine  t o  process  this job  (and  

no  other  job).  Then  we  solve  th e   problem  recursively  for  th e   set  of  remaining jobs  and   

remaining  machines.  By  pa r t   ( b ) ,  we  know  t h a t   assigning  a  job  with  processing  time  

more th an  2L  t o  a machine  t h a t  only processes th is  job  does not  increase t h e  value of  the   

optimum.  Therefore, we  a re  not  losing any  approximation  factor  here. 

Now,  we  know  t h a t   for  every j, a L  5 p j  5 2L.  We  define p i   as follows:  p i   := min{ (1  + 

E ' ) ~:  (1  + E ' ) ~> pj},  where  E'  is  such  t h a t   (1  + E ' ) ~5  (1+ E )   and ,   say,  greater  th an   

1+ ~ / 2 .  In other words, p i   is th e  smallest  power of  (1  + E ' )   greater th an  p j .   Let  I' denote  

t h e   instance  of  the   problem  with p j 's  instead  of  pj's.  I t   is  clear  form  the   definition  t h a t   

p j  5 p j  5  (1+ &')pj. Also,  since all pj's  a re  between  a L  and   2L, p j 's  can  take  a t  most 

, ( 2 / a )  + 1 = O(1) values.  Therefore, using  the   algorithm  in pa r t   (c ) ,  we  can  

k  := log(,+ &.I
find  th e  optimal solution  SOL '  for  I' in polynomial  time.  

Now  consider  an  optimal  solution  SO L  of  cost  O P T  for  I, and   evaluate  it  as  a  solution  

t o   It. Since  for  each  j ,   th e   new  value  of  C j   with  respect  t o  p i ' s   is  a t   most  ( 1  + E') 

times  its  value with  respect  t o  pj's,  therefore  t h e  cost  of  SO L  with  respect  t o  p j ' s  is  a t   

most  (1+ E ' ) ~ O P T5  (1+ & ) O P T .  This  shows t h a t   there  is  a  solution  of  cost  a t  most 

( 1  + & ) O P T  for I t .  Therefore, th e  cost of  SO L  with respect  t o  p j ' s  is a t  most  ( 1  + & ) O P T .   

However, since p i   2 p j  for every j, th e  cost of  SO L  with  respect t o  p j ' s  is upper bounded  

by  i ts  cost with  respect  t o  p i ' s ,  which  is  a t  most  (1  + & )O P T .   


