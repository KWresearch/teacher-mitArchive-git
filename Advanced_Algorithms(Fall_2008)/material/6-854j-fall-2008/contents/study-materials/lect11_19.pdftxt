MIT OpenCourseWare
http://ocw.mit.edu 

6.854J / 18.415J Advanced Algorithms 
Fall 2008
��

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

18.415/6.854  Advanced Algorithms 

November  19, 2001 

Lecturer:  Michel  X .   Goernans 

Scribe:  Steven Richman,  Matt  Peters 

Lecture   17 

1  Refresher  of  Last  Lecture 

We  continue  our  description of  approximation  algorithms  and  design.  Last  lecture  we  were looking 
a t   the   problem  of  Vertex  Cover. 

Vertex  Cover  (VC): 
Given undirected  graph G  = (V,E) and  nonegative  weights  on  each  vertex  w(u) 2 0  Vv  E V ,  
find a vertex cover S of  minimum to ta l  weight EVESw (v). A vertex cover satisfies V(u, v)  E E{u ,  u} n 
S f 0 .  

Last  time,  we  introduced  th e   two-step  lower  bound  technique  t o   analyze  approximation  algo- 
rithms.  This  technique  can  be  generalized  t o  apply  t o  maximization  problems,  bu t   in  this  lecture 
we  will  restrict  our  discussion t o  minimization  problems.  The  first  s tep  in  t h e  technique is  t o  find  a 
lower bound LB on th e  optimum solution, and  the  second s tep  is t o  show t h a t  th e  analyzed algorithm 
re tu rns  a  solution  a t  most  a x LB. 
We  will  use  the   lower  bound  technique  t o  analyze  our  algorithm  for  Vertex  Cover.  For  this,  we 
will first  formulate th e  vertex cover problem  as an  integer  program  ( a  linear program with integrality 
constraints).  Then we  will  remove t h e  integrality  constraints  t o  obtain  a  linear program; this  is our 
linear  programming  relaxation.  Since, for  this  linear program,  we  are optimizing  over  a  set  P'  t h a t  
contains  th e   set  P of  all  integer  solutions  t o  our  integer program, we  obtain  a  lower  bound  LB  on 
t h e  optimum  vertex  cover  value. 
For  Vertex  Cover, we  can  describe  th e  optimal solution  as 
min  C w (v )x (v )  

Using linear  relaxation,  we  get  a  lower bound: 
min  C w (u) x (u) 

We  can  find  a  solution  t o   Vertex  Cover  a t   most  twice  this  lower  bound  using  th e   rounding 
algorithm  of  Hochbaum  (around  1981).  This  algorithm  proceeds  by  first  obtaining  the   solution 
x*  (v) of  th e   linear  program  described  in  (2 ) .   A  2-approximation  solution  t o  Vertex  Cover  is  then  
given  by 

(Proof t h a t   this  is  a  2-approximation solution  was  given in  t h e  last  lecture.) 

We  now  have  a n  algorithm,  shown  using  th e   lower  bound  technique  t o  satisfy 
5  O P T  
(i)  LB 
(ii)  ~ v , s w ( v )   5  2LB  1  2 0 P T  

Th e  drawback  of  this  algorithm  is t h a t   i t   requires  solving a linear  program.  Though  i t   is polyno- 
mial time, i t  may  still be more  costly t h a n  desired.  We  will  s t a r t  th e  new material in this lecture by 
giving a n  a l te rna te  approach  using  duality, and   again  analyze it  using  t h e  lower  bound  technique. 

2  Bar -  Yehuda and  Even Vertex  Cover 

2.1  Duality 
We  take  the   dual program  of  t h e  linear program  described  in  (2 ) :  

LB is equal t o  th e  solution  of  th is  program by  duality.  For  any y  feasible in th e  dual LP, we  have 

-< LB  5 O PT ,  

and  we  need  only  find  such  a  y t o  have  a  lower  bound  on  OPT .  

2.2  2-Approximation Algorithm  (Bar-Yehuda and Even) 

Algorithm  S t a r t   with  a n   empty  S and   with  y  initialized  t o   0.  Find  a n   edge  ( u , v )  t h a t   is  not 
covered, and  increase  y (u ,  v)  until  one of 

becomes tight.  (Since we  a re  increasing  y,  i t  will  remain  nonegative  and  thus  will  be feasible.)  Add 
t h e   vertex  for  which  the   equation  becomes  tight  t o   S, and   proceed,  stopping  when  S is  a  vertex 
cover. 

y ( u , v )  t 0  V (u ,v )  E E 
s t 0  
w h i l e  S leaves an  edge  (u ,  v )   not  covered  do   { 

increase  y (u ,  v) 

until 3 z  E {u, v}  : x e , x )EEy ( z , I)  = w (z )   

s t s u  { x }   


Proof of  Correctness: 
(i) At  each  step,  an   uncovered  edge  is  found  and   covered.  Thus  the   algorithm  terminates  in  O (m )  
steps. 
(ii) S is a  vertex  cover, since th e   algorithm  does no t   terminate  until  this  is  t rue .  
(iii)  y  is  feasible  in  the   dual  LP   given  in  ( 4 ) ,  since we  s t a r t   with  a  feasible y  = 0  and   a t   each  s tep  
increase  y (u ,  v)  only  to  th e   limit  of  feasibility. 
(iv) When  adding  z  t o   S  in  the   algorithm, the   satisfied  equality  gives  us  Ce,,,E E   y ( z , x )  = w ( z ). 
This  value  is  never  altered  by  the   algorithm  afterwards,  since  th e   algorithm  only  alters  y (u ,  v)  for 
u  @  S and  v @  S.  Therefore  on  termination we  have 

Using this  s ta temen t ,  we  can  reexpress  t h e  weight  of  S as 

(8) is  t ru e   because  each  edge  can  be  counted  a t  most  twice  (once for  v  = a  in  t h e  outer  sum  and  
once for  v = b) .   (9) was  shown  t o  be t ru e  in  (5). 

Th e   above  algorithm  is  often  referred  to   as  a  p r im a l - d u a l   algorithm  since  i t   constructs bo th   a 
(primal) integer  solution  and   a  dual  solution  for  th e   linear  programming  relaxation.  We  will  now 
consider  a more  complicated  example based  on  this  primal-dual  paradigm. 

3  Generalized Steiner Tree  Problem 

Note:  Our  appromixation  solution  of  t h e  generalized Steiner t ree  problem  will  basically be  identical 
t o  th e  t rea tmen t  of  t h e  matching problem  in th e  approximation notes, with  "generalized Steiner tree 
problem"  substituted  for  "matching"  (and  a  few  other  small  differences). 

3.1  Problem Formulation 
The  generalized  Steiner  tree  problem  (GSTP )  is:  Given  a  graph with  edge  costs  and   a  set  of  pairs 
of  vertices  in  t h e  graph  t h a t   you  wish  t o  connect, find  a  minimum  cost  subgraph where  all pairs  in 
t h e  set  are connected.  Formally:  Given a  graph G = (V, E ) , costs  c(e) > 0 Ve  E  E, and  vertex pairs 
T & V  x  V ,   find  a  subgraph F of  minimum  cost  such t h a t  V(s, t )  E T : s and   t  are  connected  in  F. 
GSTP   is  NP-hard.  The   best  known  solution  is  a  2-approximation  algorithm.  There  are  two 
major  variations  of  GSTP   2-approximation:  one  is  due  t o   Goemans  and  Williamson,  th e   other  t o  
Ja in .   This lecture will  focus mostly  on  th e   algorithm  of  Goemans and  Williamson. 
F i rs t ,  let's formulate GSTP   as a n  integer  program: 

where our  objective function  is: 

Min C c (e )x (e )  
e E E  

We  can express  connectivity  for a  vertex pair  ( s ,  t )  E T  a s  follows:  Given any  s - t  cut  S, one of 
t h e  edges in  th e  coboundary  (i.e., one of  the   edges t h a t   crosses th e   cu t )  must  be  in  F .  

So if  we  define th e   set  of  all such  cuts  as F: 

F = {S : IS  n { s , t ) l   = 1 for  some  ( s ,  t )  E  T )  
then  we  can express t h e  connectivity  constraint  with one inequality for each set in F , and  our GSTP  
Min x c (e )x  (e )  
integer program  becomes: 
e E E  

I t  should  be  clear t h a t  this  is  a  correct formulation of  GSTP.  If  th is  program yields an  infeasible 
solution  for  GSTP,  then  the re   will  be  some  unsatisfied  pair  ( s , t )  E  T  t h a t   is  not  connected.  But 
this means  the re  is  some s - t cut  for which  no  coboundary  edge  is present  in  F ,  which  contradicts 
(10). 
This  integer  program  solves  GSTP,  so  i t   is  NP-hard.  We  can  make  i t   solvable  in  polynomial 
time, however, by  applying linear  relaxation. 

3.2  Linear Relaxation 
Relax  t h e  integrality  constraint t o  obtain: 

LB = M i n x  c (e )x (e )  5 OPT 
e E E  

3.2.1  Solution with  the  Ellipoid Algorithm 

The  relaxed  program  seems t o  still be hard  t o  solve, because  the re  a re  exponentially many  inequal- 
ities.  However, recall  t h a t   we  can  use  the   ellipsoid algorithm  t o  solve programs with  large numbers 
of  inequalities  if  we  can find an  efficient way  t o  do separation, i.e.,  if  we  can determine  in polynomial 
time  a  violated  inequality for  a  point, if  one  exists. 
An  efficient  separation  algorithm  for  GSTP   works  by  computing  the   maximum  flow  between 
pairs:  our  g o d   is  t o   identify  violated  cuts  with  value  less  th an   one,  and   we  know  t h a t   maximum 
flow  is  th e  dual problem  of  minimum  cut.  Begin  by  setting x  as  the   capacity  on  every edge.  Then ,  
for  every  pair  of  vertices  ( s ,  t )   E  T ,  compute  the   max  flow  between  s and   t .   If  th e   max  flow  is  a t  
least  one, then   th e  pair  is  satisfied.  Otherwise, th e  flow gives a min  cut  S E  F t h a t   is not  satisified. 
So, t h e   relaxed  program  can  be  solved in  polynomial  time  with  t h e  ellipsoid  algorithm.  Jain's 
algorithm  repeatedly  solves  t h e   linear  programming  relaxtion  t o   optimality.  We  will  devote  the  
remainder of  our discussion t o  a different approximation algorithm  (due t o  Goemans and  Williamson) 
t h a t   is primal-dual  and  constructs simultaneously  a good  integer  solution  and  a dual solution  t o  the  
relaxed  program. 

Note  t h a t   our program's constraints a re  formulated  in  terms of  cuts, bu t   alternatively  we  could 
have  written  our  program  in  terms  of  flows.  This  alternative  program  would  have  a  polynomial 
number  of  variables  and   constraints. 

3 .2 .2   Solution with Duality 

The  dual of  t h e  relaxed  program  is: 

Max C Ys 
S E T  

T h a t   is,  for  any  edge  e,  for  every  set  S t h a t   e  crosses,  th e   sum  of  the   weights  placed  on  e  by  the  
ys's  such  t h a t   e  is  in  th e  coboundary  of  S cannot  exceed  e's cost. 
We  don't need  t o  solve for  th e  optimum  of  the  dual:  any feasible solution  y  is a  lower  bound  on 
OPT .  Th e  algorithm we  will  present  constructs: 
1. Y  2 0 : C sE r :eE s ( s )Y s  5 c(e) 
2 .   a  feasible set  of  edges F 
such t h a t :  

S E T  
The  first inequality will hold because of  how our algorithm constructs F and  y.  The  second inequality 
holds  because  of  strong  duality.  We'll  construct  y  and   F simultaneously,  but  initially  with  more 
emphasis placed  on  y. 

Algorithm  S t a r t  with  a n  empty F and  with  y  intialized  t o  zero.  Consider  t h e  connected  compo- 
nent s defined by F (initially, the  only connected  components will be th e  individual vertices)  t h a t  are 
in F (i.e., the  components t h a t   cut one or more vertex pairs).  Increase y  for edges adjacent  t o  these 
y,  5 c(e) constraints.  Add  the  
connected  components as much  as possible without  violating any 
edge t h a t  becomes tight  t o  F, and  proceed,  stopping when  the re  a re  no more  connected  components 
in F. 

y s t O   V S E F  
F t 0   

i t 1   

connected  components C = {{v}  : v E  V} 
w h i l e  C  fl F # 0 do  { 
increase  y s   V S  E  (C  f l  F) 
u n t i l  a  new  edge e  satisfies c(e) = Cstr:eta(s)y s  
ei t e 

F t F U  {ei)  

iti+l 

upda te   connected  components C 

Th e   y  computed  by  this  algorithm  is  exactly  the   y  t h a t   we  seek  t o   construct.  F, however,  is 
not  quite what  we  need:  i t   has  too  many  edges.  Therefore, we  perform  another  s tep  t h a t   considers 
t h e  edges  in  F in  t h e  reverse  order  of  how  F was  constructed.  If  a n  edge  can  be  removed  from  F 
without  violating  pair  connectivity,  i t   is  removed. 

for k

 i - 1 down  t o  1 
t
i f  F \ {ek )  is  feasible t h e n  
F + F \ {ek) 

Proof of Correctness  I t   is  clear  t h a t   y  is feasible because  of  how  i t   is  constructed:  y  is  initially 
feasible, and  when  we  increase some y s   by  E ,  we  s top  if  a  cost  constraint  becomes tight. 
In order  t o  show t h a t   F is  feasible, we  need  a  lemma. 
Lemma  1  L e t  C  be  t h e   connected   c om p o n e n t s   of  F. If  C nF = 0 ,   t h e n  F i s  feasible. 
Proof of Lemma 1:  Assume not.  Then ZIC, F s.t. C nF = 0 and  F is not  feasible.  Since F is no t  
feasible,  3 ( s , t )  E  T s . t .   s, t  not  connected.  Let  Cs  # Ct  be  connected  components of F containing 
s and  t ,  respectively.  Cs is a  set t h a t   forms a n  s - t  cut  (since s  is  in  Cs and  t  is no t ) ,  and ,  likewise, 
Ct  is  a  set  t h a t   forms  a  t - s cu t .   So C s , Ct  E  F + C n F # 0. Contradiction. 
The  build  step of  the   algorithm  terminates with  t h e  condition  t h a t   C n F = 0 ,  so we  know  from 
Lemma  1 t h a t   F is  feasible a t  this  point.  Th e  edge  removal  step of  t h e  algorithm  only  removes an  
edge  from  F if  doing  so maintains  t h e  feasibility  of  F .   So F must  be  feasible when  th e   algorithm 
terminates. 
All  t h a t   remains  t o  be  shown is  t h a t   th e   cost  of  th e   solution  is  not  much more  th an   th e   cost  of 
th e   dual  solution.  If  we  call  th e   F t h a t   we  compute  after  th e   initial  build  s tep  F and   th e   F after 
excess edges have been  removed F ' ,  then   this  can be  expressed  as: 

We  can remove costs  from  th e   inequality as follows: 

(12) holds  because  each edge e  E  F' satsifies c(e) = CstF:etd(s)y s  when i t   is first  added t o  F ,  and  
we  never  change  th e   value  of  y s   for  a  set  S : e  E  S (S )  later  in  th e   execution  of  the   algorithm.  To 
see why  t h e  value  of y s   never  subsequently changes,  observe t h a t   th e   inclusion  of  e  in F' creates  a 
new  connected  component  with  e in  i ts  interior,  and  this  component  will  now  no  longer be  equal t o  
any  cut  S for which  e  is  a  coboundary  edge.  (13) holds  because  in  (12) we  count  each  y s   for  every 
edge t h a t   belongs  t o  bo th   F' and  6 (S ) .  
In  the   next  lecture we  will  show  t h a t   th e   coefficients of  t h e  ys's,  considered  under  some  sort  of 
averaging,  a re  less  th an   two.  This will prove  (11) and   complete  our  correctness proof  of  t h e  GSTP  
algorithm. 

