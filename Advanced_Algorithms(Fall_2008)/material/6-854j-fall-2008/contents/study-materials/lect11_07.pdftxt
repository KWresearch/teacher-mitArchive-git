MIT OpenCourseWare
http://ocw.mit.edu 

6.854J / 18.415J Advanced Algorithms 
Fall 2008
��

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

18.415/6.854  Advanced Algorithms 

November  7, 2001 

Lecturer:  Michel  X .   Goemans 

Lecture   16  
Scribes:  Nicole  Immorlica  and  Mana  Taghdiri 

Today we  begin  our  discussion of  approximation  algorithms.  We  will  ta lk   abou t :  

NP-hard  Optimization  Problems 

Inapproximability 

Analysis  of  Approximation Algorithms 

1  NP-hard  Optimization Problems 

Many  of  the   algorithms  in  th is   world  of  ours  deal  with  optimization.  Some of  these  problems  we 
can  solve exactly  in  polynomial  time.  We  spent  th e  whole  first  half  of  this  te rm   dealing  with  these 
types  of  problems  (linear  programming,  circulations).  Other  optimization  problems  a re   impossible 
t o  solve in  polynomial  time  unless  P=NP .   We  now  focus  our  a t ten t ion  on  handling  these  NP-hard 
optimization  problems. 

Definition  1  An  optimization problem  is NP-hard  if  the corresponding  decision problem  is NP-hard, 
i.e.  a polynomial-time  algorithm finding  the  exact  optimum  would  imply P  = N P .  

There  are  many  examples  of  NP-hard  optimization  problems.  In  fact,  you  can  find  a  ra the r  
comprehensive and  up-to-date  list  of  these problems  along with  known  results  a t :  

We  will  see  three  examples  of  NP-hard  optimization  problems  today. 

a  Vertex  Coloring:  Given  a  graph  G  =  (V, E )   assign  colors  t o   t h e   vertices  so  t h a t   for  all 
(u, w )   E E, u  is  not  th e   same color  as w .   Minimize th e  number  of  colors used. 

LIN-k-MOD-q:  All  t h e   computation  in  this  problem  is  considered  in  Z q .   Given  a  set  of 
variables X  and  a  set of  equations E each  in  lc  of  the  variables  in X ,  find an  assignment  of  X .  
Maximize th e  number  of  equations in  E t h a t   are satisfied  by  this  assignment  of  X .  

Scheduling:  Given  a  set  of  jobs,  a  processing  time  for  each  job,  and   a  set  of  processors, 
assign t h e  jobs  to  t h e  processors.  Minimize the   time  it  takes t o  complete  all the  jobs  assuming 
a  processor  can  only  process  one job  a t   a  time. 

In  order  t o   prove  t h a t   these  are  NP-hard  optimization  problems,  we  must  prove  their  corre-
sponding decision problems  a re  NP-complete.  For  example, t o  prove vertex coloring is NP-hard, we 
must  show t h a t   t o  decide whether  a given graph is colorable with  less th an   k colors is NP-complete. 
As  complexity  theory  is  not  a  pre-requisite  for  this  course,  we  will  just  take  these  facts  on  faith. 
However  th e   interested  reader  can  find  a  nice  t rea tmen t   of  NP-completeness  in  [2,  1, 31.  A  proof 
t h a t   k-colorability  is NP-complete  can be  found  in  th e  exercises in  each of  these  books. 
As  these  problems  a re  NP-hard,  we  must  abandon  all  hope  of  solving  them  exactly.  Instead, 
we  find  ways  t o   cope  with  their  intractability.  A  common  method  used  in  practice  is  t o   design 
heuristic  algorithms  and   analyze  their  performance  empirically.  As  th e   below  definitions  for  the  
words  heuristic  and   empirical  indicate,  we  won't  be  able  t o   study  th is   method  in  this  theoretical 
class.  To see a  t rea tmen t   of  this  approach, take  artificial  intelligence. 

heu.ris.tic \hyu.-'ris-tik\  aj  [ G   heuristisch, fr. NL  heuristicus, fr. 
Gk heuriskein to disclover; akin to OIr fu-ar I have found  :  serving to 
guide, discover, or reveal; specif  :  valuable for empirical research but 
unproved or incapable of  proof 

em.pir.i.ca1 or em.pir.ic \-i-k*l\ \-ik\ \-i-k(*-)le-\  aj  1:  relying on 

experience or observation alone often without due regard for system and 

theory 2: originating in or based on observation or experience 3: capable 

of  being verified or disproved by  observation or experiment (" laws)  -
em.pir.i.cal.1~av 


Instead,  we  will  design  polynomial  time  algorithms  t h a t   approximately  solve  these  NP-hard 
optimization problems.  We will analyze th e  solutions returned by these  algorithms in th e  worst-case 
(i.e.  th e   input  for which  th e   solution  is farthest  from  the   optimum  solution).  These  algorithms  a re  
called approximation  algorithms. 

Definition  2  Let  cOPT(x) be  the  optimal  solution  of  a  minimization  problem  P  on  input  x .   An 
a-approximation  algorithm  for  P  is  a  polynomial  time  algorithm  that  is  guaranteed  to  deliver  a 
solution  such  that for  all  inputs x  the  uahe  o f   the  solution  cH (x )   is  cH (x )  5 a copT (x ) .   I f  P  is  a 
maximization problem,  we  require  CH  (x )  2 a c o p ~(x ) . 

2 

Inapproximability 

The   problems  we  are  trying  to   approximate  are  NP-hard.  Therefore  we  can't  hope  to   find  an  
a-approximation  algorithm  for  which  a  = 1.  But  this  does  not  imply  t h a t   a  must  be  bounded 
away  from  one,  and   in  fact  for  some  problems  we  can  find  a  = 1 + e  for  all  E  >  0  (or  e  <  0 
if  i t 's   a  maximization  problem).  Of  course,  in  these  cases  th e   running  time  often  depends  on 
c .   However,  we  are  not  always  so  lucky.  Sometimes  we  can  prove  t h a t   i t   is  NP-hard  t o   find  an  
approximation  algorithm  with  a < p ( n )  for  some  function p ( n )   (often constant).  Such  results  a re  
called  inapproxima bility  results. 
Traditionally,  inapproximability  of  a n  NP-hard  optimization  problem  is  derived  from  th e   NP- 
completeness  proof  of  the   decision  problem.  We  can  use  this  method  t o   prove  vertex  coloring  is 
inapproximable within  4/3.  This  is  because  k-colorability  (for  k  > 2)  is  NP-complete.  Therefore, 
given  a  graph  G ,   i t   is  hard  t o   distinguish  whether  i t   can  be  colored with  a t   most  3  colors or  if  i t  
needs  a t   least  4  colors.  If  we  were  able  t o   find  a  4 / 3  - e  approximation  algorithm,  we  could  call 
this  algorithm  on G.  If  G needs  a t  most  three  colors, our  algorithm will  find a  coloring t h a t  uses  a t  
most  a c o pT   5 3 (4 /3  - c)  < 4  colors.  But  if  G needs  more  th an   th ree   colors,  our  algorithm  must 
re tu rn  a  coloring t h a t  uses  a t  least four  colors.  Therefore, this polynomial  time  algorithm  solves the  
problem  we  claimed  is  NP-complete!  This  can  not  be,  unless  P=NP .   There  are  actually  stronger 
(non-constant)  inapproximability results  for th is  problem. 
Since  1992,  another  approach  t o   proving  inapproximability  has  emerged.  This  approach  uses 
PC P s   (i.e.  probabilistically  checkable  proofs,  not  t h e   Communist  P a r ty   of  Peru  or  phencyclidine 
or  People  for  a  Clearer  Ph ish ) .   As  a n   example,  consider  th e   LIN-3-MOD-2  problem.  Recall  in 
this  problem  we  have  a  set  of  variables  xi  and   rn   equations  each  in  three  of  these  variables.  All 
computation takes  place  in  Z2. For  example, we  might  have 

We  t ry   t o  maximize  the   number  of  satisfied  equations.  First  we  present  a  trivial approximation 
algorithm  for  this  problem.  Take  xO identically  zero  and   x1 identically  one.  Note  for  any  given 
equation, either  x0 or  x1 satisfies  i t .   Therefore,  either  so or  x1 must  satisfy m / 2   of  th e   equations. 
As  th e   optimal  solution  can  satisfy  a t  most  rn  equations,  this  is  a  112-approximation algorithm. 
Johan   HQstad used  PC P s   to   prove  the re   is  no  (112 + €)-approximation  algorithm  for  any  E  > 0 
[4].  As  a  side  note,  Hiistad's  theorem  does  not  hold  for  LIN-2-MOD-2.  Notice  our  approximation 
algorithm  works  only  for  LIN-k-MOD-2  where  k is  odd.  Can  you  find  a n  algorithm  t h a t   works for 
LIN-2-MOD-2? Wha t 's  its  approximation  factor? 

3  Analysis  of  Approximation  Algorithms 
it's  often  quite  hard  t o   prove  t h a t   CH  5  a c o p ~ ,directly 
Since  it's  hard  t o   characterize  COPT, 
(Assume we're solving  a  minimization  problem.)  Instead,  we'll find  a  good  lower  bound  on  COPT 
(say L B )  and   then  prove th a t :  

Following problems  a re  examples  of  using  such  an   analysis  method. 

3.1  Scheduling Problem 
Given  m  machines  and   n  jobs,  each  with  a  certain  processing  time  length  p j ,   we're  supposed  t o  
minimize 

CmaZ   = maX  C j  
3 
where  c j  is  t h e  completion  time of  Qth  job,  such  t h a t   each job  be  assigned t o  exactly one machine  -
no  ma t te r   which  one - and  no  2 jobs  can overlap on  t h e  same machine. 
The  problem  is NP-Hard  even in  case of  2 machines.  In  t h a t   case we  have n jobs  with 

and  we  need  t o  determine whether  there's a  S  {1 ,2 ,  . . . ,n )  s . t .  

or  no t ,  which  is  the   partition  problem, known  t o  be  NP-complete. 
As  a n  approximation  algorithm, we  introduce  Graham's List  Scheduling algorithm: 

a  Consider jobs  in  any  order 

P u t  job  j  on  t h e  first  available machine. 

Claim  1  Graham's List  Scheduling is  a  (2 - 1 lm ) -app ros ima t ion  algorithm. 

Proof: 
let 

Trivially  COPT   2 L B .   If  c~  is  t h e   solution  found  by  Graham's  algorithm,  let  j  be  th e   job  s.t. 
c j  = C H .  SO, a t  time  c~  - p j  all machines were busy.  Bu t   then 

3.2  Vertex  Covering Problem 
Given  a  graph  G  = (V, E )  and   a  weight  function  w  which  maps  each  vertex  v  t o   a  non-negative 
weight  w (v ) ,  we  have  t o  find  a  vertex  cover  S  V  s.t. 

is minimized,  where  S  & V  is  a  vertex  cover  iff 
V ( i , j )  E E,  {i,j) n S  # 0 
The   VC  problem  is  NP-hard  (bu t   i t   is  polynomial-time  solvable  if  G  is  b ipa r t i te ) .   We'll use 
linear  programming t o  find  an  approximation  algorithm. 
In  order  t o  use  LP   t o  find  a  lower  bound  (LB )  in  general, a  "relaxation"  is  used.  Let  Q  c Rn 
denote  th e   characteristic  vectors  of  all feasible solutions  (in  our  case,  vertex  covers of  G ) .   Let  f (x )  
be t h e  function we  a re  trying t o  optimize.  Instead of  optimizing  over Q ,  we  optimize over a polytope 
P such t h a t   Q  P. We  know  t h a t  
L B  = 	min f (x )  5 min f (x )  = COPT  
X E P  
x € Q  
so L B  is our  lower  bound.  Finally, we  have t o  find  a  feasible integer  solution which will  be within  a 
constant  factor  of  L B .  
So first, we  have t o  formulate th e  problem  as a n  integer  program.  For  t h e  above example we  can 
define: 

and  then  t r y  t o  find 


with  the   idea of 

The  L P  relaxation  is: 


min C w (u )  z (u )   

{  1  V E S
x (v )  = 
0 
O .W .   

min C w ( u ) x ( u )  = LB  5 COPT   


x ( u )  + x ( v )  > 1  V (u ,v )  E  E
{  l > x ( ) >  
V u E V  
which  can  be  solved  in  polynomial  time.  After  solving  th e   corresponding LP,  we  have  LB  and  
O  5 z * ( u )  5 1. But  z * ( u )  is  not  always O  or  1 ,  e.g.  in  graph K g  given w(v) = 1 Vv  E V ,   C O P T   = 4 
bu t   L B  = 2.5 with  x * ( u )  = 112.  We'll solve this  problem  by  rounding: 
Ou tpu t   : S = {u lx* (u )  > 1/21. 

Claim 2  This  is  a 2-approximation algorithm. 

Proof: 
V(U,V )   E E, x* (u ) + x* (v )  > 1 ++  m ax (x* (u ) ,  x* (v ) )  > 112 so, a t  least  one of  them  is  in  S, thus ,  
S is  a  vertex  cover  and: 

Remark  1  No  (2 - c)-approximation algorithm  is known. 

But  in  this  approach, you  always have t o  solve t h e  corresponding  LP,  exactly.  Although  i t 's  not 
ha rd  in  this problem,  bu t   in general i t  may be a bottleneck  itself.  In  t h e  next  session we'll show how 
t o  use  duality  t o  overcome this  deficiency. 

References 

[I] Thomas  H.  Cormen,  Charles  E.  Leiserson,  and   Ronald  L.  Rivest.  Introduction  to  Algorithms. 
The  MIT  Press,  1990. 

[2] 	 Michael R.  Garey  and  David  S. Johnson.  Computers  and  Intractability:  A  Guide  to  the  Theory 
of  NP-Completeness.  WH  Freeman  & Co.,  1979. 

[3] Michael  Sipser.  Introduction  to  the  Theory of  Computation.  PWS  Publishing  Company,  1997. 

[4]  Johan  H i s t ad .   Some optimal inapproximability results.  ECCC Report  TR97-037, 1997. 

