MIT OpenCourseWare
http://ocw.mit.edu 

6.854J / 18.415J Advanced Algorithms 
Fall 2008
��

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

18.415/6.854  Advanced Algorithms 

October  1, 2001 

Lecturer:  Michel  X .   Goernans 

Scribe:  B in   Song  and  Hanson  Zhou 

Lecture  6 

1  Issues with  the  Ellipsoid Algorithm 

As  shown  in  th e   last  lecture, t h e  upda te   formulae  contain  a  square root  in  b  = L A k c .
 This
JG 
is  problematic  as we  do  not  have  infinite  bits  t o   represent  t h e   result  of  th e   square root.  Without 
going into  detail, this  can be  solved  by  rounding  t o  a  new  center,  taking  a  slightly  bigger ellipsoid, 
and   showing  t h a t   th e   new  ellipsoid  is  still  small  enough  t o   satisfy  th e   required  ra t io   of  volumes 
inequality.  Another  issue  is  t h a t   a t   each  iteration  of  th e   algorithm,  th e   number  of  bits  we  need  t o  
represent  our  ellipsoid may  grow too  fast.  Again,  th is  may  be  handled  by  rounding  and  perturbing, 
t h e  details  of  which  we  shall forego. 

2  Optimization and  Separation 

So fa r ,  we  have  seen  th ree  kinds  of  linear programming algorithms: 

1. Simplex - not  known  t o  be  polynomial,  bu t   works  well  in practice. 

2.  Ellipsoid - polynomial,  bu t  works poorly  in practice a s  th e  ra t io  of  volumes bound  is very close 
t o  a  lower bound  as well. 

3 .   Interior  Point  - polynomial,  works  well  in  practice. 

The  Ellipsoid algorithm does have a redeeming quality in t h a t  i t  only requires us t o  solve a separation 
problem:  given x ,  either  claim t h a t  x  E  P or ou tpu t   a n  inequality cT y 5 d such t h a t  cT r  > d  (i.e., x 
does not  satisfy th is  inequality)  and  P  {x  : c T x  5 d )  (i.e., P satisfies the   inequality).  Therefore, 
we  do  not  need  t o   list  all  of  t h e   inequalities  of  th e   linear  program  in  order  t o  be  able  t o  use  the  
ellipsoid method  t o  solve i t .   This  is an   important  feature of  the   ellipsoid algorithm,  and  enables  us 
t o  solve some exponential  size linear programs. 

In  summary, th e  Ellipsoid  algorithm  requires  th ree  things: 

1. P bounded,  P 
[-24,  2QIn 
2.  If  P is  non-empty,  then   x + [-2-Q,  2-QIn  & P', where  is  x  is  a  solution  of  t h e  original  (non- 
inflated) problem,  and  P' is  th e  inflated  polyhedron. 

3 .   Polynomial  time  algorithm  for  th e  separation problem. 

Given these, we  can  find in  O (n2Q ) calls t o  th e   separation  algorithm  a point  in  P'  or  claim  t h a t   P 
is empty. 

Here  is  a  simple  example  of  th e   use  of  such  a  separation  algorithm.  Suppose  we  would  like  t o  
optimize  over  the  following linear  program  (where n  is  even): 

where 

> 1 for all  S C1 1 , - - - , n )  with  IS1  = n / 2 , x j   > O f o r   a l l j  

There a re   (" 1 2  " )  constraints and  this is exponential in n .   If  we  are given this linear program implicitly 
(saying every subset of  size n / 2   should  sum t o  a t  least  I ) ,  th e  size of  th e  input would be of  th e  order 
of  sixe(c)  (which is  > n ) ,  and   thus  we  can't afford t o  write  down  explicitly  th e   linear  program  and  
then  use  a polynomial-time  algorithm  for  linear programming  (polynomial  in t h e  size of  th e  explicit 
linear  program,  and  not  just  s ixe (c ) ) .  
However,  we  can  use  t h e   ellipsoid  algorithm  t o   find  a  point  in  say  P n {x  : cTx 5  A ) .  
Indeed  t o  
check  whether  a  point  ( the  center  of  a n  ellipsoid)  is  in  P, we  do not  need  t o  explicitly  check  every 
inequality.  We  can  simply  sort  t h e  xi's, take  the   n / 2   smallest,  and   verify whether  they  sum  t o  a t  
least  1.  If  they  do, every  inequality  in  th e   description of  P is  satisfied,  otherwise  we  take  as S the  
indices  of  t h e  n / 2   smallest values of  x  and  use  the   inequality  over  S .  This  requires  only  O (n1ogn )  
time  (we  do  not  even  need  t o  use  sorting,  we  can  simply  use  a  linear-time  algorithm  for  selecting 
th e  n /2 - th   element; this would  take  O ( n )  time). 
To  decide which  ellipsoid  t o   s t a r t   with,  we  can  use  the   fact  t h a t   we  can  assume  x j  5  1 (if  one  of 
t h e   cj's is  negative  th e   problem  is  unbounded  and   thus  the re   exists  an   x  of  cost  below  t h e   value 
A;  otherwise  any  value  greater  th an   1 can  be  reduced  t o   1 without  increasing  the   cost  or  losing 
feasibility).  To  transform  P into  P' t o  guarantee  the   existence  of  a  small  ball  within  i t ,   we  can 
consider vertices of  P n {x  : cTx 5 A).  Using Crarner's rule a s  usual, we  can express any such vertex 
as  (F,7 ,- . - , F)where  t h e  pi's and   q  a re  bounded  by  2Q where Q = O ( n  log n + c,,,). 
(Indeed, 
th e  matrices  involved in  th e  calculations will be square matrices of  dimensions a t  most  n  x n  and  all 
entries will be 0 or 1except  in one of  th e  rows in which they will be cj's, so such determinants will be 
intersect  it  with  cTx 5 X + *.Now, we  can use  th e  ellipsoid algorithm  t o  decide if  the re  is a point 
Thus instead  of  P ,  we  consider P' in which  the   inequalities  C j tsx j  > 1 
bounded  by  (fi)"nc,,,.) 
a re  replaced  by  CjEsx j  2 1- &, and   instead  of  intersecting  i t   with  the   inequality  cTx 5 A ,   we 
in  P' n {x  : cTx 5 X  + & using  O ( n 2Q )  = O ( n 3  log n + n cm aX )  iterations  (each  involving a rank-1 
upda te   and  a  call t o  th e   separation routine). 
A  simple O (n1ogn )   time  algorithm  t o  solve this  linear  program  is  left  as  a n  exercise  ( the  solution 
given  in  lecture was  incorrect). 

3 

Interior  Point  algorithms 

Karmarkar  '84 gave  an   interior  point  algorithm,  which  stays  inside  th e   polytope  and   converges t o  
a n  optimal point  on  the   boundary.  I t  considers t h e  problem: 

min 
cTx 
s . t .   A x = b , x > O .  

Note  t h a t   th e   inequality  is  s t r ic t .   To  enforce  this,  we  add   a  logarithmic  barrier  function  t o   the  
objective function: 

Figure 1: A  strictly convex function 

Note  th a t   this  approaches  ca as  xj  + 0.  Effectively, t h i s   enforces a  > 0  by  imposing an infinite 
penalty whenever  an x  component  is 0. 

Definition 1  A  f u n c t i o n   f 
i s   said  t o   be  s t d c t l y   convex  i f   i t s   d om a i n   i s   convex   and  for  e v e r y  
x(')  # 
in t h e   d om a i n   o f f ,  and   eve ry   0 < A  < 1 ,  

f (Ax'"  + ( 1 - A ) x ( ~ ) )< Af ( J 1 ) )+ ( 1 - A)f ( x ( ~ ) ) .  

Figure  1illustrates a  strictly  convex function. 
Lemma  1  c T x  - p x jl n ( x j ) ,p  > 0  i s  s t r i c t l y   convex   ove r  x  > 0 .  

Proof of  lemma 1:  This is more or  less clear from th e  graph of  the  logarithmic barrier  function. 

Lemma  2  If  t h e   barrier   problem   B P ( p )  i s  feasible  and   i t s   va lue  finite   t h e n   the re   e x i s t s   a  u n i q u e  
s o l u t i o n   t o  it: M i n im i z e   c T z  - p C jln (a   ) ,p  > 0  s . t. A z  = b , x  > 0 

Proof of  lemma 2:  Assume 3 d 1 ) # d 2 ) ,f (dl))  = f  ( d 2 ) )= B P ( p ) . Then 
Ax(') + ( 1- x ) x ( ~ ) ,0 < x < 1 
is feasible since {x  : Ax   = b ,  x  > 0)  is  convex, and 
< xf ( x ( l ) )+ (1- A ) f ( x ( ~ ) )= B P ( p ) ,  
f  (Ax ( ' )+ (1-
which  is in  contradiction  with  the  minimality  of  B P ( p ) .  Therefore, th e  solution  is  unique. 

3.1  Optimality  Condition 

Lemma  3  For  any  p  > 0,  x  is  optimum for  B P ( p ) ,   if  and  only  if, 33, s ,   such  that 

Proof  of lemma  3:  Let  f (x )  = cTx + p x jln (x j ) .  
By  Lemma  1, f (x )  is  strictly  convex, thus  a  local minimum  is  also global minimum.  By  Lemma  2, 
such minimum  is unique. 
Under  th e   constraint  Ax  = b ,   x  is  optimum  for  f (x ), if  and   only  if,  V f (x )   is  orthogonal  t o   th e  
constraint  space  {x  : Ax  = 0).  Since  th e   column  space  of  AT  is  orthogonal  t o   th e   null-space  of 
A,  Vf  (x )  must  be   in  th e   column  space  of  AT.  Thus,  x  is  optimum,  if  and   only  if,  3y,  such  t h a t  
V f (x )  = ATy .  
Since 

we  obtain  t h a t ,  x  is  optimum, if  and  only  if, 3y ,  such  t h a t ,   c - p ~ - ' e  = ATy ,  where 

and  e  is  th e   n-dimensional  column  vector  with  each  entry  equal t o  1. 

Let  s j  = p / x j ,   we  conclude out  proof. 

Equations  1 ,  2, and  3 are  called Karush-Kuhn-Tucker  optimality  conditions. 
Note  t h a t ,  since x  > 0 and  p  > 0, we  must  have  s  > 0.  Equation  2 represents  th e   condition of  the  
dual problem  of  our  original  problem.  The  duality  gap  is 

cTx - bTY  = x T s  = C x j ~ j= p n .  
j 

As  p  + 0, the   duality  gap  tends  t o  0, and   thus  cTx and   bTy   tend   to   t h e  optimal value  of  ( P )  and  
(D).  

For a given p ,  it  is no t  easy t o  solve th e  equations  1, 2 ,  and  3, since equation  3 is not  linear.  Instead, 
we  will  use  a n  iterative method  t o  find  the   solutions.  We  s t a r t   a t  some pg.  For  each  step i, we  will 
go from p i   t o  some p i+ l   < p i .   We  show t h a t  if  we  are close enough  t o  p i   before th e  step, then  after 
t h e  step, we  will  be   close enough  t o  p i + l -  
The  iterative step  is  as follows.  Suppose we  a re  a t   ( x ,  y , s ) , where 

We  replace  x  by  x + Ax ,  y  by  y + Ay , and   s  by  s + A s .   We  get 
A A x = O  
A ( x + A x ) = b  
A ~ A ~ + A S = O  
A ~ ( ~ + A ~ ) + ( S + A S ) = C  
+  A x j s j  + A s j x j  = p - X j S j   ,  V j .
( x j  + A x j ) ( s j  + A s j )  = p 
l inear ize  

The  equations we  obtained  above are all  linear, and  can be  solved in polynomial  time.  Then we  will 
move  t o  t h e  next  s tep  with  th e  new  x ,  y,  s .  We  will  show t h a t  with  properly  chosen p i ,  x  converges 
t o  the   optimal solution  in  polynomial  time. 

