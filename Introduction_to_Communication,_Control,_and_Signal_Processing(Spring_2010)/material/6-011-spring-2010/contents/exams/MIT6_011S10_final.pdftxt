Massachusetts  Institute  of  Technology 
Department  of  Electrical  Engineering  and  Computer  Science

6.011:  Introduction  to  Communication,  Control  and  Signal  Processing

FINAL  EXAM  Question  Booklet, May  18,  2010


Your  Full  Name: 

Recitation  Instructor  &  Time  : 

at 

o’clock 

• 

• 

• 
• 

This  exam  is  closed  book,  but  4  sheets  of  notes  are  allowed.  Calculators  and  other 
electronic  aids  will  not  be  necessary  and  are  not  allowed.


Check  that  this  question  booklet  has  pages  numbered  up  to  10.  The  accompanying

answer  booklet  contains  spaces  for  all  relevant  reasoning  and  answers;  DO  NOT  use 
this  question  booklet  for  answers! 

Neat  work  and  clear  explanations  count;  show  all  relevant  work  and  reasoning! 

There are 5 problems, weighted as shown,  for a total of 100 points.  (The indicated 
weightings  on  subparts  of  problems  are  nominal,  and may  be  altered  slightly  prior  to  the 
start  of  grading.) 

1


Problem  1  (17  points) 

y [n] = h[n] ∗ x[n] ;


In  the  block  diagram  in  Figure  1, 

x[n] = xc (nT1 ) ; 
� 
∞
−∞ 
Also,  assume  the  continuous-time  input  xc (t)  is  bandlimited  to  frequencies  |ω | < 2π × 103 ,  so 
|ω | ≥ 2π × 103  . 
for 
Xc (jω) = 0 
Take  h[n]  to  be  the  unit  sample  response  of  an  ideal  lowpass  ﬁlter,  with  frequency  response 
H (ejΩ )  that  is  1  in  the  passband  |Ω| < (π/2),  and  0  for  (π/2) ≤ |Ω| ≤ π ,  as  shown  in  Figure  2. 

y [n]p(t − nT2 ) ; 

q [n] = r(nT2 ) . 

r(t) = 

Note  that  part  (d)  below  does  not  require  the  answers  to  parts  (a)–(c),  and  can 
therefore  be  done  independently  of  them. 

xc (t)  - C/D 
6 
T1 

-x[n] 

h[n] 

-y [n] 

PAM 

-r(t) 

6 
p(t), T2 
Figure  1:  Block  diagram.


6H (ejΩ ) 
1 

q [n] = r(nT2 ) 
-

C/D 

6 
T2 

−π  − 2
π 
Figure  2:  Frequency  response H (ejΩ )  of  the  LTI  ﬁlter. 

Ω 

π 
2 

π

-

(a)  (4  points)  Determine  the  largest  value  of  T1  to  ensure  that 

y [n] = xc (nT1 ) . 

2


(b)  (6  points) With  T1  picked  as  in  (a),  determine  a  choice  for  T2  and  p(t)  to  ensure  that 

r(t) = xc (t) . 

(It is ﬁne — especially if you are not sure of your answer in (a)!  — to leave your expressions 
for T2  and p(t)  in  terms of T1 ,  instead of  substituting  in  the numerical value you obtained 
in  (a)  for  T1 .) 
Also  determine  if  there  is  another  choice  of  T2  and  p(t)  that  could  ensure  the  equality 
r(t) = xc (t).  Explain  your  answer  carefully. 

(c)  (3  points)  With  T1  picked  as  in  (a),  how  would  you  modify  your  choice  of  T2  and  p(t) 
from  (b)  to  ensure  that


r(t) = xc (2.7t) .


(d)  (4 points) Assume that p(t)  is now chosen so that  its CTFT, P (jω),  is as shown  in Figure 
3.  Determine  a  value  of  T2  to  ensure  that  q [n] = y [n]. 

P (jω)
6

10−3 

2π × 103 
−2π × 103 
Figure  3:  Transform  P (jω)  of  p(t),  for  part  (d). 

ω 

-

3


Problem  2  (18  points) 

For  each  of  the  following  parts, write  down whether  the  statement  is True  or False,  giving 
a  clear  explanation  or  counterexample. 
Caution:  The  fact  that  these  are  True/False  questions  does  not  mean  that  a  quick  and 
intuitive answer will suﬃce!  — you will need to think carefully and present your answer clearly. 
Your  explanation/counterexample  is  an  essential  part  of  your  answer,  and may  take more  than 
a  sentence.  Sloppy  work  here  will  mean  you  lose  18%  of  your  points  on  the  exam  —  consider 
yourself  adequately  warned! 

(a)  (4  points)  Suppose  x[n]  is  a  zero-mean  discrete-time  (DT)  wide-sense  stationary  (WSS) 
random  process.  If  its  autocorrelation  function  Rxx [m]  is  0  for  |m| ≥  2  but  nonzero  for 
m = −1, 0, 1,  then the  linear minimum mean-square-error (LMMSE) estimator of x[n + 1] 
from measurements  of  x[n]  and  x[n − 1],  namely 
x�[n + 1] = a0x[n] + a1x[n − 1] , 

will  necessarily  have  a1  = 0. 

(b)  (4  points)  If  the  power  spectral  density  Syy (jω)  of  a  continuous-time  (CT) WSS  random 
process  y(t)  is  given  by


Syy (jω) = 

17 + ω2

23 + ω2 
then  the  mean  value  of  the  process  is  zero,  i.e.,  µy  = E [y(t)] = 0. 
� 1 �|
(c)  (4  points)  If  the  autocovariance  function  Cvv [m]  of  a  DT  WSS  random  process  v [n]  is 
given  by 
Cvv [m] = 
3 
� 
�  ∞
� 
then  the  LMMSE  estimator  of  v [n + 1]  from  all  past  measurements,  which  we  write  as 
v�[n + 1] = 
hk v [n − k ]
+ d , 
k=0 
will  have  hk  = 0  for  all  k ≥ 1,  i.e.,  only  the  coeﬃcients  h0  and  d  can  be  nonzero. 

| 
m

,

(d)  (3  points)  The  process  v [n]  in  (c)  is  ergodic  in mean  value. 

(e)  (3  points)  If  z [n] = v [n] + W ,  where  v [n]  is  the  process  in  (c),  and  where W  is  a  random 
variable with mean 0 and variance σ2  > 0, then the process z [n] is ergodic in mean value. 
W 

4 

Problem  3  (25  points) 

A  causal  discrete-time  system  is  governed  by  the  following  state  evolution  equation  and 
associated  output  equation: 

where 

� 

�

,


q1 [n] 
q2 [n] 

q[n] =


q[n + 1]  =  Aq[n] + bx[n] + hw[n]  , 
y [n] =  cT q[n] + v [n] . 
� 
� 
� 
�

�
,  h = 
,


b =


A =


1 
2 
0

3
4
2


� 
,  cT  = 

� 

� 
, 

0 1 

0 
1


1 
2 
1

Here  x[n]  denotes  a  known  (i.e.,  available  or  accessible)  input  signal, while w[n]  is  an  unknown

(i.e., unavailable or inaccessible) disturbance  input signal that is modeled as a (zero-mean) wide­

sense  stationary  (WSS)  white-noise  process,  with  variance  σ

at  each  instant.  The  unknown

2
w 
(unavailable or  inaccessible) measurement  noise v [n]  is also modeled as (zero-mean) WSS white 

·
·
noise,  with  variance  σ
2 
v  at  each  instant.  We  also  assume  the  noise  processes  v [ ]  and  w[ ]  are 
uncorrelated  with  each  other. 

(a)  (8  points)  Determine  the  two  natural  frequencies  of  the  system  (i.e.,  the  eigenvalues  λ1 
and  λ2  of  A),  and  for  each  of  them  specify  whether  the  associated  mode  satisﬁes  the 
following  properties: 

(i)  decays  asymptotically  to  0  in  the  zero-input  response; 
(ii)  is  reachable  from  the  input  x[n]  (with  w[n]  kept  at  zero); 
(iii)  is  reachable  from  the  input  w[n]  (with  x[n]  kept  at  zero); 
(iv)  is  observable  from  the  output  y [n]. 
ask  a  friend  for  advice.  Your  friend,  who  denotes  the  state  estimate  by  q�f [n],  suggests 
(b)  (2 points) Suppose you wish to  implement an observer to estimate the state q[n], and you 
q�f [n + 1] = Aq�f [n] + bx[n] + hw[n] − � ( y [n] − cT q�f [n] − v [n] )  , 
the  following  (causal)  speciﬁcation  for  the  observer: 
� 
�
�1 
denotes  the observer gain vector.  Write down what you  think  is  the ap­
where  � = 
�2 
propriate  speciﬁcation  of  an  observer  that you  can  implement,  explaining your  reasoning. 
Here  and  for  the  rest  of  this  problem,  use  the  notation  q�[n]  to  denote  the  state 
(Agreeing  with  your  friend  is  one  option,  of  course.) 
estimate  in  your  observer  (whether  or  not  you  agree  with  your  friend’s  speciﬁcation). 

5


�
− �
q�
�
�
] = 
(c) (2 points) Denote the state estimation error by 
[
[
[
]. Now explain carefully 
]
q
q
q
n
n
n
�
[
why the components 
] and 
] at time  are uncorrelated with the noise terms 
[
] of 
[
q n
q n
n
n
1
2
(or — equivalently, of course!  — explain why the components of 
[
] and 
[
] at time 
n 
w n
v n
[ + 1] are uncorrelated with 
[ + 1] and 
[ + 1]). 
q n
v n 
w n
q�[n + 1] = Bq�[n] + f w[n] + gv [n] . 
(d) (4 points) The state estimation error in (c) is governed by a state-space model of the form 
in terms of previously speciﬁed quantities. 

Determine

, 
B f

and

g

(e)  (5  points)  Is  it  possible  to  arbitrarily  vary  the  natural  frequencies  of  the  state  estimation 
error  evolution  equation  in  (d)  by  controlling  the  observer  gains  �1  and  �2?  Explicitly 
note  how  your  answer  here  is  consistent  with  your  answer  to  (a)(iv).  Also  specify  what 
constraints, if any, on 
and must be satisﬁed to make the error evolution equation 
�
�
2 
1
asymptotically stable. In particular, would the choice  = 0 allow you to obtain a good 
�2
state  estimate?  —  explain. 

� = −1
If you have done things correctly, you should ﬁnd that choosing 
makes the matrix 
3
−
4
in part (d) a diagonal matrix. 
, and also 
for the rest of this problem
B
Keep
ﬁxed at 
3
�
1 
4

is chosen so that the error evolution equation is asymptotically stable (you should 
assume  2
�
� = −
ﬁnd that this is possible by proper choice of 
, even with 
).
3
�
2
1
4 

�
�
(f ) (4 points) Under the preceding assumption of asymptotic stability, and assuming that 
=  −∞
the system and the observer have been running since 
, it turns out that the 
n 
mean-squared estimation errors 
[
]) attain constant steady-state values 
(
]) and 
[
(
2
2
q n
E
E
q n
2

1
; denote these constant values by 
at any ﬁnite 
and
respectively.  Find explicit 
2
2
2 [n + 1]) = E (q�2
2 [n])  and  E (q�2
2 [n + 1]) = E (q�1
E (q�1
n
σ
σ
q
2 
1 
q
,  expressing  them  as  functions  of  �2 . [Hint:  At  steady  state, 
expressions for 
and
2
2
σ
σq
1q

2
2 [n]).] 

6


Problem  4  (20  points) 

Assume  we  have  to  decide  between  hypotheses  H0  and  H1  based  on  a  measured  random 
variable X .  The  conditional densities  for X  given H0  and H1  respectively are  shown Figure  4. 
|
f (x|H0 ) 
f (x H1 )
6 
6 
1 
2 

−2 

1 
4 
-
2  x 

−1

1 

-
x

Figure  4:  The  conditional  densities  for X  given H0  and H1 . 

We  would  like  to  design  a  decision  rule  that  will  maximize  the  conditional  probability  of 
|
“detection”  PD  =  P (‘H1 ’ H1 ),  sub ject  to  the  conditional  probability  of  “false  alarm”  PF A  =
|
P (‘H1 ’ H0 )  not  exceeding  some  limit  β .  The  Neyman-Pearson  result  tells  us  that  the  optimal 
test  will,  on  obtaining  the measurement X  = x,  compute  the  likelihood  ratio 
fX |H (x|H1 ) 
fX |H (x|H0 ) 
and announce  ‘H1 ’  if Λ(x) > η , ‘H0 ’  if Λ(x) < η  for some suitably chosen threshold η .  However, 
as this problem shows, a closer look may be needed in the case where Λ(x) — or, more correctly, 
Λ(X ) —  can  be  exactly  at  the  threshold  η  with  a  nonzero  probability. 
(a)  (4  points)  Sketch  Λ(x)  as  a  function  of  x  for  −2  < x <  2.  (You  needn’t  spend  time 
|
|
wondering what Λ(x)  is  at  the  edges  of  the  pdf ’s  or  for  x > 2,  since  the  probability  that 
X  will  take  any  of  these  speciﬁc  values  is  0.) 

Λ(x) = 

(b)  (6  points)  For  η  ﬁxed  at  some  value  in  each  of  the  following  ranges,  specify  the  corre­
sponding  PD  and  PF A : 
(i)  η  at  some  value  strictly  above  2; 
(ii)  η  at  some  value  strictly  between  0  and  2; 
(iii)  η  at  some  value  strictly  below  0. 

(c)  (2 points)  If  the  speciﬁed  limit on PF A  is β  = 0.3, which of  the choices  in  (b) can we pick, 
and  what  is  the  associated  PD ? 

The  reason  we  don’t  seem  to  be  able  to  do  too  well  in  (c)  is  that  with  η  restricted  to  the 
ranges  in  (b),  we  will  only  get  three  possible  values  of  PF A ,  with  the  three  values  of  PD  that 
go  along  with  these.  In  other  words,  the  “receiver  operating  characteristic”  (ROC)  that  plots 
PD  as  a  function  of  PF A  will  only  have  three  points  on  it.  Here’s  how  to  do  better: 

7 

(d)  (8  points)  Suppose we  choose  η = 0.  What  is  the  probability  that we  get  Λ(X ) = 0  if H0 
holds?  And  what  is  the  probability  we  get  Λ(X ) = 0  if H1  holds? 

With  η  =  0,  we  will  of  course  never  get  Λ(x)  < η  (as  the  likelihood  ratio  in  always 
nonnegative),  but  we  might  well  get  Λ(x) =  η  or  Λ(x)  > η .  Suppose  we  announce  ‘H0 ’ 
when  Λ(x) = 0;  however,  when  Λ(x) > 0  we  shall  announce  ‘H1 ’  with  probability  α,  and 
otherwise  announce  ‘H0 ’.  What  are  PD  and  PF A  with  this  randomized  decision  rule? 

Note  how  the  choice  of  α  can  give  you  new  points  on  the  ROC,  between  the  points  you 
found  in (b)(i) and (b)(ii).  What choice of α will allow you to maximize PD  while keeping 
PF A  ≤ 0.3  with  this  decision  rule? 

8


Problem  5  (20  points) 

The  diagram  in  Figure  5  represents  a  received  signal  r[n]  as  the  sum  of  two  components. 
Parts  (a)  and  (b)  of  this  problem  have  distinct  speciﬁcations  for  what  these  two  components 
are,  so  read  the  problem  statements  carefully!  In  both  cases,  assume  the  parameter  µ  that 
|
| 
deﬁnes  the  transfer  function K (z )  is  known  to  you,  and  satisﬁes  the  condition  µ < 1.

x[n] 

- K (z ) = 1 − µz−1 

r [n]
-

- + 
6 

y [n] 

Figure  5:  Generation  of  the  received  signal  r[n]. 

(a)  (10  points)  Suppose  x[n]  is  a  signal  that  we  are  interested  in,  while  y [n]  is  a  zero-mean, 
i.i.d.,  Gaussian  noise  process,  with  variance  σ2  at  each  instant  of  time.  The  block  in 
the  ﬁgure  denotes  a  communication  channel  —  modeled  as  LTI  with  transfer  function 
K (z ) = 1− µz−1  — through which x[n] has to pass.  We have the following two hypotheses 
regarding  the  signal  x[n]: 

H0  : x[n] = 0 ,
H1  : x[n] =  δ [n] ,

P (H0 ) = p0  , 
P (H1 ) = p1  = 1 − p0  . 
You are  to design a  receiver  that  takes r[n] as  input and decides between H0  and H1  with 
minimum  probability  of  error  (MPE).  We  have  shown  that  optimum  processing  at  the 
receiver  involves  the  sequence  of  steps  shown  in  Figure  6:  LTI  (but  possibly  noncausal) 
ﬁltering  of  r [n]  using  a  ﬁlter  with  unit  sample  response  f [n];  sampling  the  output  g [n]  of 
the ﬁlter  at  some  appropriate  time n0 ;  and deciding  in  favor of H0  or H1 ,  based  on where 
the  sample  value  is  relative  to  a  threshold  γ . 

r[n] 
-

f [n], F (z ) 

g [n]  � n = n0  -
g [n0 ] 

Threshold  γ

‘H1 ’ 
>
- < 
‘H0 ’ 

Figure  6:  Structure  of  optimal  receiver  for  this  problem. 

(i)  Fully  specify  the  MPE  receiver  in  Figure  6  when  n0  =  0,  i.e.,  specify  f [n]  or  F (z ) 
and  the  value  of  γ . 

9 

|
(ii)  Write  down  an  expression  for  P (‘H1 ’ H0 )  and  for  the  minimum  probability  of  error 
�  ∞ 
in the case where the two hypotheses are equally  likely, p0  = p1 .  You can write these 
in  terms  of  the  standard  function 
1 
√
2π  α 

e−  2  dt
2
t

Q(α) = 

(iii)  If  the value  of µ  is  changed  to  a new value µ = µ/2, we  can  get  the  same probability 
of  error  as  prior  to  the  change  if  the  noise  variance  changes  to  some  new  value  σ2 . 
Express  σ  in  terms  of  σ . 

(b)  (10 points) Suppose now that x[n] in Figure 5 is a zero-mean, i.i.d., Gaussian noise process, 
with  variance  σ2  at  each  instant  of  time,  and  that  y [n]  is  the  signal  we  are  interested  in. 
We  have  the  following  two  hypotheses  regarding  y [n]: 

H0  : y [n] = 0 ,
H1  : y [n] =  δ [n] ,

P (H0 ) = p0  , 
P (H1 ) = p1  = 1 − p0  . 
Fully  specify  the MPE  receiver  in Figure 6 when n0  = 0,  i.e.,  specify f [n] or F (z ) and  the 
value of γ  for  this case.  Also write down  (in  terms of µ and σ)  the  relevant “signal energy 
to  noise  power”  ratio  that  governs  the  performance  of  this  system.  Be  sure  to  explain 
your  reasoning  throughout! 

10


MIT OpenCourseWare
http://ocw.mit.edu 

6.011  Introduction to Communication, Control, and Signal Processing 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

