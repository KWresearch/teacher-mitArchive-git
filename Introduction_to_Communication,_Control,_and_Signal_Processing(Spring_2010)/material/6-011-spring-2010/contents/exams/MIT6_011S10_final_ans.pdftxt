Massachusetts  Institute  of  Technology 
Department  of  Electrical  Engineering  and  Computer  Science

6.011:  Introduction  to  Communication,  Control  and  Signal  Processing

FINAL  EXAM, May  18,  2010

ANSWER  BOOKLET 

Your  Full  Name: 

Recitation  Time  : 

o’clock 

• 

• 

• 

• 

This  exam  is  closed  book,  but  4  sheets  of  notes  are  allowed.  Calculators  and  other 
electronic  aids  will  not  be  necessary  and  are  not  allowed. 

Check  that  this  ANSWER  BOOKLET  has  pages  numbered  up  to  26.  The  booklet 
contains  spaces  for  all  relevant  reasoning  and  answers. 

Neat work and clear explanations count;  show all relevant work and reasoning! 
You  may  want  to  ﬁrst  work  things  through  on  scratch  paper  and  then  neatly  transfer  to 
this  booklet  the  work  you  would  like  us  to  look  at.  Let  us  know  if  you  need  additional 
scratch  paper.  Only  this  booklet  will  be  considered  in  the  grading;  no  additional  an­
swer  or  solution  written  elsewhere  will  be  considered.  Absolutely  no  exceptions! 

There  are  5  problems,  weighted  as  shown,  for  a  total  of  100  points.  (The  points 
indicated  on  the  following  pages  for  the  various  subparts  of  the  problems  are  our  best 
guess  for  now,  but  may  be modiﬁed  slightly  when  we  get  to  grading.) 

Your  Score 

Problem 

1  (17  points) 

2  (18  points) 

3  (25  points) 

4  (20  points) 

5  (20  points) 

Total  (100  points) 

1


Problem  1  (17  points) 
Note  that  1(d)  does  not  depend  on  your  answers  to  1(a)-(c),  and  can  be  done 
independently  of  them. 

Xc (jω) = 0 

for 

|ω | ≥ 2π × 103  . 

xc (t)  - C/D 
6 
T1 

-x[n] 

h[n] 

-y [n] 

PAM 

6 
p(t), T2 

-r(t) 

C/D 

6 
T2 

q [n] = r(nT2 ) 
-

6H (ejΩ ) 
1 

−π  − π 
2 

π 
2 

π 

-

Ω 

1(a)  (3  points)  Determine  the  largest  value  of  T1  to  ensure  that  y [n] = xc (nT1 ) . 

Largest  possible  T1  is: 

2 

1(b)  (6  points) With  T1  picked  as  in  1(a),  determine  a  choice  for  T2  and  p(t)  to  ensure  that 

r(t) = xc (t) . 

(You  can  leave  your  expressions  for  T2  and  p(t)  in  terms  of  T1 ,  instead  of  substituting  in 
the  numerical  value  you  obtained  in  1(a)  for  T1 .) 

T2  = 

p(t) = 

(Continue  1(b)  on  next  page:) 

3 

1(b)  (continued) Also  determine  if  there  is  another  choice  of T2  and  p(t)  that  could  ensure  the 
equality  r(t) = xc (t).  Explain  your  answer  carefully. 

Is  there  another  possible  choice  of T2?  If  you  answer  “Yes”,  then  specify  such  an  alterna­
tive  T2 . 

Is  there  another  possible  choice  of  p(t)?  If  you  answer  “Yes”,  then  specify  such  an  alter­
native  p(t). 

4


1(c)  (3  points)  With  T1  picked  as  in  1(a),  how  would  you  modify  your  choice  of  T2  and  p(t) 
from  1(b)  to  ensure  that 

r(t) = xc (2.7t) . 

Modiﬁed  T2  = 

Modiﬁed  p(t) = 

5 

1(d)  (4  points)  Assume  that  p(t)  is  now  chosen  so  that  its  CTFT,  P (jω),  is  as  shown  below. 
Determine  a  value  of  T2  to  ensure  that  q [n] = y [n]. 

P (jω)
6

10−3 

−2π × 103 

2π × 103 

-

ω 

An  appropriate  choice  is  T2  = 

6 

Problem  2  (18  points) 

For  each  of  the  following  parts,  write  down  whether  the  statement  is True  or  False  (circle 
whichever  is  appropriate),  giving  a  clear  explanation  or  counterexample.  (Take  care with  this!) 

2(a)  (4  points)  Suppose  x[n]  is  a  zero-mean  discrete-time  (DT)  wide-sense  stationary  (WSS) 
random  process.  If  its  autocorrelation  function  Rxx [m]  is  0  for  |m| ≥  2  but  nonzero  for 
m = −1, 0, 1,  then the  linear minimum mean-square-error (LMMSE) estimator of x[n + 1] 
from measurements  of  x[n]  and  x[n − 1],  namely 
x�[n + 1] = a0x[n] + a1x[n − 1] , 

will  necessarily  have  a1  = 0. 

TRUE 

FALSE 

Explanation/counterexample: 

7


2(b)  (4  points)  If  the  power  spectral  density  Syy (jω)  of  a  continuous-time  (CT) WSS  random 
process  y(t)  is  given  by 

17 + ω2 
23 + ω2

then  the  mean  value  of  the  process  is  zero,  i.e.,  µy  = E [y(t)] = 0.


Syy (jω) = 

TRUE 

FALSE 

Explanation/counterexample: 

8


� 1 �|
2(c)  (4  points)  If  the  autocovariance  function  Cvv [m]  of  a  DT  WSS  random  process  v [n]  is 
given  by 
Cvv [m] = 
3 
� 
�  ∞
� 
then  the  LMMSE  estimator  of  v [n + 1]  from  all  past  measurements,  which  we  write  as 
v�[n + 1] = 
hk v [n − k ]
+ d , 
k=0 
will  have  hk  = 0  for  all  k ≥ 1,  i.e.,  only  the  coeﬃcients  h0  and  d  can  be  nonzero. 

| 
m

,

TRUE 

FALSE 

Explanation/counterexample: 

9


2(d)  (3  points)  The  process  v [n]  in  2(c)  is  ergodic  in mean  value. 

TRUE 

FALSE 

Explanation/counterexample: 

2(e)  (3  points)  If  z [n] = v [n] + W , where  v [n]  is  the  process  in  2(c),  and where W  is  a  random 
variable with mean 0 and variance σ2  > 0, then the process z [n] is ergodic in mean value. 
W 

TRUE 

FALSE 

Explanation/counterexample: 

10


Problem  3  (25  points) 

where 

� 

�

,


q1 [n] 
q2 [n] 

q[n] =


q[n + 1]  =  Aq[n] + bx[n] + hw[n]  , 
y [n] =  cT q[n] + v [n] . 
� 
� 
�
� 
�
,  h = 
,  b = 

A =


1

2

0

3

4

2


� 
,  cT  = 

� 

� 
,

0 1 

0 
1 

1

2

1

3(a)  Determine  the  two  natural  frequencies  of  the  system  (i.e.,  the  eigenvalues  of A),  and  for 
each  of  them  specify  whether  the  associated  mode  satisﬁes  the  properties  listed  on  the 
next  page. 

(Write  your  answers  on  the  next  page.) 

11 

3(a)  (continued)(8  points)


The  two  eigenvalues  are: 

λ1  = 

λ2  = 

List  below  whichever  of  the  eigenvalues,  if  either,  has  an  associated  mode  that  satisﬁes 
the  indicated  condition: 

(i)  decays  asymptotically  to  0  in  the  zero-input  response: 

(ii)  is  reachable  from  the  input  x[n]  (with  w[n]  kept  at  zero): 

(iii)  is  reachable  from  the  input  w[n]  (with  x[n]  kept  at  zero): 

(iv)  is  observable  from  the  output  y [n]: 

12 

3(b)  (2  points)  Your  speciﬁcation  of  the  observer,  to  obtain  an  estimate  q�[n]  of  the  state  q[n] 
(explain  your  choice): 

3(c)  (2  points) With  q�[n] = q[n] − q�[n],  explain  carefully  why  the  components  q�1 [n]  and  q�2 [n] 
of  q�[n]  at  time  n  are  uncorrelated  with  the  noise  terms  w[n]  and  v [n]  at  time  n  (or  — 
equivalently,  of  course!  —  explain  why  the  components  of  q�[n + 1]  are  uncorrelated  with 
w[n + 1]  and  v [n + 1]): 

13


q�[n + 1] = Bq�[n] + f w[n] + gv [n] . 
3(d)  (4  points)  The  state  estimation  error  in  3(c)  is  governed  by  a  state-space  model  of  the 
form 
Determine B,  f  and  g  in  terms  of  previously  speciﬁed  quantities. 

B =

, 

f  =

, 

g = 

14 

3(e)  (5  points)  Is  it  possible  to  arbitrarily  vary  the  natural  frequencies  of  the  state  estimation 
error  evolution  equation  in  3(d)  by  controlling  the  observer  gains  �1  and  �2?  Explicitly 
note  how  your  answer  here  is  consistent  with  your  answer  to  3(a)(iv). 

What  constraints,  if  any,  on  �1  and  �2  must  be  satisﬁed  to  make  the  error  evolution 
equation  asymptotically  stable? 

Would  the  choice  �2  = 0  allow  you  to  obtain  a  good  state  estimate?  —  explain. 

If  you  have  done  things  correctly,  you  should  ﬁnd  that  choosing  �1  = − 4
3  makes  the matrix 
B  in  part  3(d)  a  diagonal matrix.  Keep  �1  ﬁxed  at  − 3  for  the  rest  of  this  problem,  and 
4 
also  assume  �2  is  chosen  so  that  the  error  evolution  equation  is  asymptotically  stable. 

15


stant  steady-state  values,  E (�
and  E (�
3(f )  (4  points)  Under  the  given  assumptions,  the  mean-squared  estimation  errors  attain  con­

2 
2 
2 . 
[n])

=

[n])

=

Find  explicit  expres­

2
2
q

σ

q

σ

qE (�2
1 [n + 1]) = E (q�2
1 [n])  and  E (q�2
2 [n + 1]) = E (q�2
1
2
q
q
1
2 
2 
expressing  them  as  functions  of  �2 .
sions  for  σ 1
and  σ

2 , 
[Hint:  At  steady  state, 
q
q
2 [n]).]


2 
qσ 1 

= 

2 
σ 2  =

q

16


Problem  4  (20  points) 


−2 

f (x|H0 ) 
6 

1

4

-
2  x 

|
f (x H1 )
6 
1

2


−1

1 

-
x


4(a)  (4  points)  Sketch  Λ(x) =  fX |H (x|H1 )  as  a  function  of  x  for  −2 < x < 2:
fX |H (x|H0 ) 

17


4(b)  (6  points) 

(i)  For  threshold  η  at  some  value  strictly  above  2,  determine  PD  and  PF A : 

PD  = 

PF A  = 

(ii)  For  η  at  some  value  strictly  between  0  and  2,  determine  PD  and  PF A : 

PD  = 

PF A  = 

18


4(b)  (continued) 
(iii)  For  η  at  some  value  strictly  below  0,  determine  PD  and  PF A : 

PD  = 

PF A  = 

4(c)  (2  points)  If  the  speciﬁed  limit  on  PF A  is  β  = 0.3,  which  of  the  choices  in  4(b)  can  we 
pick,  and  what  is  the  associated  PD ? 

19


4(d)  (8  points)  What  is  the  probability  that  we  get  Λ(X )  =  0  if  H0  holds?  And  what  is  the 
probability  we  get  Λ(X ) = 0  if H1  holds? 

|
P (Λ(X ) = 0  H0 ) = 

| 
P (Λ(X ) = 0  H1 ) = 

Announce  ‘H0 ’  when  Λ(x) =  0.  When  Λ(x) >  0,  announce  ‘H1 ’  with  probability  α,  and 
otherwise  announce  ‘H0 ’.  What  are  PD  and  PF A  with  this  randomized  decision  rule? 

PD  = 

PF A  =


To maximize  PD  while  keeping  PF A  ≤ 0.3  with  this  decision  rule,  choose  α =


20 

Problem  5  (20  points) 

x[n] 

- K (z ) = 1 − µz−1 

r [n]
-

- + 
6 

y [n] 

r[n] 
-

f [n], F (z ) 

g [n]  � n = n0  -
g [n0 ] 

Threshold  γ

‘H1 ’ 
>
- <
‘H0 ’

5(a)  (10  points)  Suppose  x[n]  is  a  signal  that  we  are  interested  in,  while  y [n]  is  a  zero-mean, 
i.i.d.,  Gaussian  noise  process,  with  variance  σ2  at  each  instant  of  time. 

H0  : x[n] = 0 ,
H1  : x[n] =  δ [n] ,

P (H0 ) = p0  ,

P (H1 ) = p1  = 1 − p0  .


(i)  Fully  specify  the MPE  receiver when  n0  = 0,  i.e.,  specify  f [n]  or  F (z )  and  the  value 
of  γ . 

(Write  your  answers  on  the  next  page.) 

21 

5(a)(i)  (continued)


Specify  f [n]  or  F (z ): 

Threshold  γ  = 

22 

|
5(a)(ii)  Write  down  an  expression  for  P (‘H1 ’ H0 )  and  for  the  minimum  probability  of  error 
�  ∞ 
in the case where the two hypotheses are equally  likely, p0  = p1 .  You can write these 
in  terms  of  the  standard  function 
1 
√
2π  α 

e− 
2
t
2  dt

Q(α) = 

|
P (‘H1 ’ H0 ) = 

The minimum  probability  of  error  is: 

23 

5(a)(iii)  If  the value  of µ  is  changed  to  a new value µ = µ/2, we  can  get  the  same probability 
of  error  as  prior  to  the  change  if  the  noise  variance  changes  to  some  new  value  σ2 . 
Express  σ  in  terms  of  σ : 

σ = 

24 

5(b)  (10  points)  Suppose  now  that  x[n]  is  a  zero-mean,  i.i.d.,  Gaussian  noise  process,  with 
variance  σ2  at  each  instant  of  time,  and  that  y [n]  is  the  signal  we  are  interested  in.  We 

x[n] 

- K (z ) = 1 − µz−1 

r [n]
-

- + 
6 

y [n] 

r[n] 
-

f [n], F (z ) 

g [n]  � n = n0  -
g [n0 ] 

Threshold  γ

‘H1 ’ 
>
- <
‘H0 ’

have  the  following  two  hypotheses  regarding  y [n]: 

H0  : y [n] = 0 ,
H1  : y [n] =  δ [n] ,

P (H0 ) = p0  ,

P (H1 ) = p1  = 1 − p0  .

Fully  specify  the MPE  receiver  when  n0  = 0,  i.e.,  specify  f [n]  or  F (z )  and  the  value  of  γ 
for  this  case. 

(Write  your  answers  on  the  next  page.) 

25 

5(b)  (continued)


Specify  f [n]  or  F (z ):


Threshold  γ  =


Also  write  down  (in  terms  of  µ  and  σ)  the  relevant  “signal  energy  to  noise  power”  ratio

that  governs  the  performance  of  this  system:


26


MIT OpenCourseWare
http://ocw.mit.edu 

6.011 Introduction to Communication, Control, and Signal Processing 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

