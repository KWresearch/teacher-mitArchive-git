Massachusetts  Institute  of  Technology 

Department  of  Electrical  Engineering   and  Computer   Science


6.011:  Introduction  to  Communication,  Control  and  Signal  Processing 

2
QUIZ , April 21, 2010

ANSWER  BOOKLET 

Your  Full  Name:


Recitation  Time  : 

SOLUTIONS 

o’clock


•	 This  quiz  is  closed  book,  but  3  sheet  of  notes  are  allowed.  Calculators  will  not  be 
necessary  and  are  not  allowed. 
•	 Check  that  this  ANSWER  BOOKLET  has  pages  numbered  up  to  14.  The  booklet 
contains  spaces  for  all  relevant  reasoning  and  answers. 
•	 Neat work and clear explanations count;  show all relevant work and reasoning! 
You  may  want  to  ﬁrst  work  things  through  on  scratch  paper  and  then  neatly  transfer  to 
this  booklet  the  work  you  would  like  us  to  look  at.  Let  us  know  if  you  need  additional 
scratch paper.  Only  this  booklet  will  be  considered  in  the  grading;  no  additional  an­
swer  or  solution  written  elsewhere  will  be  considered.  Absolutely  no  exceptions! 
•	 There  are  4  problems,  weighted  as  shown.  (The  points  indicated  on  the  following 
pages  for  the  various  subparts  of  the  problems  are  our  best  guess  for  now,  but  may  be 
modiﬁed  slightly  when  we  get  to  grading.) 

Your  Score 

Problem	

1  (6  points)


2  (15  points)


3  (15  points)


4  (14  points)


Total  (50  points)


1


Problem  1  (6  points) 

For  each  of  the  following  statements,  specify  whether  the  statement  is  true  or  false  and 
give  a brief (at  most  a few lines) justiﬁcation  or  counterexample. 

(1a)  (1.5  points)  If  X  and  Y  are  independent  random  variables,  the  unconstrained  MMSE 
estimator  Y� of  Y  given  X  =  x  is  Y� =  µY  . 

True: The unconstrained MMSE  estimator takes the form  E [Y |X ] =  � yfY |X dy . Since  Y 
and  X  are independent,  we know that  fY |X  =  fY  .  This implies  E [Y |X ] =  µY  =  � yfY  dy . 

(1b) (1.5 points) The following  random process is  strict  sense  stationary:  x(t) =  A  where  A  is 
a  continuous  random  variable  with  a  pdf  uniform  between  ±1. 

True: Intuitively, you can conclude that the process  x(t) is strict sense stationary because 
there is  no way  to tell  where on the time  axis you  are by  looking  at  any  set  of  samples,  no 
matter  at what times they  are taken.  Mathematically, this intuition is captured by  saying 
that PDF’s of  all  orders are shift invariant, or  fx(t1 ),x(t2 ),...,x(tN )  =  fx(t1+τ ),x( t2+τ ),...,x(tN +τ ) 
for  all  N  and  τ . 

(1c)  (1.5  points) The  following  random  process  is  ergodic  in  the  mean:  x(t) =  A  where  A  is  a 
continuous  random  variable  with  a  pdf  uniform  between  ±1. 

False: The process is  not  ergodic in the  mean because the  ensemble  mean does  not  equal 
the  time-average  of  a  realization  of  the  process  x(t).  The  ensemble  mean  of  the  process 
x(t)  is  0.  The  time-average  of  a  realization  of  the  process  x(t)  is  the  particular  value  of 
A  obtained  in  that  realization 

2 

(1d)  (1.5  points) If  the  input  to  a  stable  LTI  system  is  WSS  then  the  output  is  guaranteed  to 
be WSS. 

True:  If  a  WSS  process  x(t)  with  mean  µx  and  autocorrelation  function  Rxx(τ )  is  the 
input to a stable LTI  system with frequency  response  H (jω), then the output process has 
h  ∗ ←
−h  ∗ Rxx(τ ).  Since  the 
mean  µy  =  H (j0)µx  and  autocorrelation  function  Ryy (τ ) = 
output  process  has  a  constant  mean  and  autocorrelation  function  that  depends  only  on 
the lag  τ , the process  y(t) is  also  WSS. 

3


Problem  2  (15  points) 

Suppose  x(t)  and  v(t)  are  two  independent  WSS  random  processes  with  autocorrelation 
functions  respectively  Rxx(τ ) and  Rvv (τ ). 

(2a) (3 points) Using x(t) and  v(t), show how you would construct  a random process  g(t) whose 
autocorrelation function  Rgg (τ )  is  that  shown  in  Eq.  (2.1).  Be  sure  to  demonstrate 
that  the  resulting  process  g(t)  has  the  desired  autocorrelation  function. 

Rgg (τ ) =  Rxx (τ )Rvv (τ ) 

(2.1) 

Solution:  Choose  g(t) =  x(t)v(t).  For  this  choice  the  autocorrelation  function  of  g(t) is 

Rgg (τ ) =  E [x(t  +  τ )v(t  +  τ )x(t)v(t)] 
=  E [x(t  +  τ )x(t)]E [v(t  +  τ )v(t)] 
=  Rxx (τ )Rvv (τ ) 

4


For  the  remainder  of  this  problem  assume  that  Rxx (τ ) and  Rvv (τ ) are  known  to  be 

Rxx (τ ) = 2e−|τ | 

Rvv (τ ) =  e −3|τ | 

You  can  also  invoke  the  Fourier  transform  identity 

e −β |τ |  ⇐⇒ 

β 2 

2
β
+ 

ω2 

(2.2) 

(2.3) 

(2b) (6 points)  Let  w(t)  denote  a  third  WSS  random  process  with  autocorrelation  function 
Rww (τ ) =  δ(τ ).  Suppose  w(t)  is  the  input  to  a  ﬁrst-order,  stable,  causal  LTI  system  for 
which  the  linear  constant  coeﬃcient  diﬀerential  equation  is 

dx(t)
dt 

+  ax(t) =  bw(t) 

(2.4) 

Determine  the  values  of  a  and  b  so  that  the  autocorrelation  of  the  output  x(t) is  Rxx(τ ) 
as given in Eq.  (2.2). 

Solution:  The  transfer  function  H (s) representing  this  linear,  constant  coeﬃcient  diﬀer­
ential  equation  is  given  by 

The PSD (function of  jω) and  complex PSD (function of  s) of  the output process  x(t) are 

H (s) = 

b 
s  +  a 

Sxx(jω)  = 

4 
1 + ω2 
4 
(1 + s)(1 − s) 
We  know  that  the  complex  PSDs  of  the  input  process  w(t)  and  the  output  process  x(t) 
are  related  as  follows: 

Sxx(s)  = 

Sxx (s) =  H (s)H (−s)Sww (s) 

Since  the  complex  PSD  of  the  input  process  w(t) is  Sww (s) = 1,  we  can  write 

5 

Sxx(s) =  H (s)H (−s) 
b2 
4 
= 
(a  +  s)(a  − s) 
(1 + s)(1 − s)
From  the  above  we  recognize  that  b  =  ±2  and  a  = 1. 

6


(2c)  (6  points)  Is  it  possible  to  have  a  WSS  process  z (t)  whose  autocorrelation  function 
Rzz (τ ) =  Rxx (τ ) ∗ Rvv (τ ),  i.e.,  Rzz (τ )  is  the  result  of  convolving  the  autocorrelation 
functions  Rxx (τ ) and  Rvv (τ ) given in Eq.  (2.2)?  If no,  why  not?  If yes,  show how to gen­
erate  z (t) starting from a WSS process  w(t) with  autocorrelation  function  Rww (τ ) =  δ(τ ) 
(you  can  perform  any necessary  causal  LTI  ﬁltering  operations). 

Solution:  We  would like to form  a process  z (t) whose  autocorrelation  function  and  PSD 
are 

Rzz (τ ) =  Rxx (τ ) ∗ Rvv (τ ) 
Szz (jω) =  Sxx(jω)Svv (jω) 

Suppose  we  ﬁlter  the  process  w(t)  through  a  causal,  LTI  ﬁlter  with  frequency  response 
H (jω).  Then  we  will  obtain  the  following  relation  between  the  Sww  and  Szz 

|H (jω)| 2  Sww (jω) 
Szz (jω) = 
Szz (s) =  H (s)H (−s)Sww (s) 

Since  the  complex  PSD  of  the  input  process  w(t) is  Sww (s) = 1,  we  can  write 

Szz (s) =  H (s)H (−s) 
Sxx(s)Svv (s) =  H (s)H (−s) 
6 
2
H (s)H (−s) 
= 
(1 + s)(1 − s) (3 + s)(3 − s) 
Associating  with  H (s) the  poles  in  the  left  half  plane  we  obtain 

H (s) = 

2√3 
(1 + s)(3 + s) 

7


Problem  3  (15  points) 

A  DT  wide-sense  stationary  random  process  s[n]  has  zero  mean  and  the  autocovariance 
[m] = 0 for  |m| ≥ 5. 
function  Css [m] shown  in  Figure  3.1.  Css

 
]
m
[
s
s
C

15 
14 
13 
12 
11 
10 
9 
8 
7 
6 
5 
4 
3 
2 
1 
0 
−1 
−2 
−3 
−4 

−4 

−3 

−2 

−1 

1 

2 

3 

4 

0 
m 

Figure 3.1 

The process  s[n] is transmitted through  a communication  channel  that introduces noise  and 
a  one-step  delay.  The  received  process  r [n]  is  related  to  s[n]  as  indicated  by  Eq.  (3.1).  The 
noise process  w[n] has  zero  mean,  autocovariance  function  Cww [m] = 3δ [m].  Furthermore,  the 
noise process  w[ ] is  uncorrelated  with  the  process  s[ ]. 
·
·
r [n] =  s[n  − 1] + w[n] 
(3.1) 
We  wish  to  design  an  estimator  s�[n] for  s[n].  Throughout  this  problem  the  ob jective  is  to 
choose  the  parameters  in  the  estimator  to  minimize  the  mean  squared  error  E  deﬁned  as 
E  � E {(s[n] − s�[n])2  } 

8


(3a)  (2  points)  Express  the  covariance  functions  Crs [m]  and  Crr [m]  in  terms  of  the  given 
autocovariance functions  Css [m] and  Cww [m]? 

Solution:  Since  both  s[n]  and  w[n]  are  zero  mean,  auto  and  cross  covariance  functions 
will  equal  auto  and  cross  correlation  functions. 

Crs [m] =  Rrs [m] 
=  E [r [n  +  m]s[n]] 
=  E [(s[n  +  m  − 1] + w[n  +  m])s[n]] 
=  Rss [m  − 1] 
=  Css [m  − 1] 

Crr [m] =  Rrr [m] 
=  E [r(n  +  m)r(n)] 
=  E [(s[n  +  m  − 1] + w[n  +  m])(s[n  − 1] + w[n])] 
=  Rss [m] + Rww [m] 
=  Css [m] + Cww [m] 

9


(3b)  (3  points) If  the  estimator  is  restricted  to  be  of  the  form 

s�[n] =  a0 r [n] + a1 r [n  − 1] 
will  E  be  minimized  with  the  parameter  values  a0  = 0  and  a1  = 5? 

Circle:  Yes/No 

Clearly  show  how  you  arrived  at  your  conclusion. 

Solution:  No.  If  s�[n] minimizes  E ,  then  the  estimation  error  must  be  orthogonal  to  both 
the  data  samples  r [n]  and  r [n  − 1].  We  will  show  that  orthogonality  is  not  satisﬁed  for 
the  choice  a0  = 0  and  a1  = 5. 

E [(s[n] − s�[n])r [n]]

E [(s[n] − a0r [n] − a1 r [n  − 1])r [n]]

E [(s[n] − a1 r [n  − 1])r [n]]

Rsr [0] − a1Rrr [1]

−4 − 5(−4)  =6
0


Alternatively,  note  that  if  a0  =  0  in  the  minimum,  then  a1  must  be  the  coeﬃcient  that 
minimizes  the  MSE  when  we  use  an  estimator  of  the  form  s�[n] =  a1r [n  − 1],  but  then  we 
would  need 
5 
Css [−2] 
Csr [1] 
= 
= 
a1  =
Crr [0] 
Crr [0] 
18 

10


(3c)  (5  points) If  the  estimator  is  restricted  to  be  of  the  form 

s[n] =  a2 r [n] 
�
determine  the  value  of  a2  that  minimizes  E . 

Solution:  The  value  of  a2  that  minimizes  E  is given by 

a2  = 

=

Csr [0] 
Crr [0] 
Rsr [0] 
Rss [0] + Rww [0] 

= 

−2 
9 

11


(3d)  (5  points) If  the  estimator  is  of  the  form 

1 
r [n  − no ] 
s[n] = 
�
2 
with  no  ≥ 0,  determine  the  value  of  no  that  minimizes  E . 

Solution:  Express  the  estimation  error  E  in  terms  of  no 

1 
r [n  − no ])2 ] 
E  =  E [(s[n] − 
2
1 
=  E [s 2 [n] − s[n]r [n  − no ] + 
4 
1 
=  Rss [0] − Rsr [no ] +  Rrr [0] 
4 
1 
=  Rss [0] − Rrs [−no ] +  Rrr [0] 
4 
1 
=  Rss [0] − Rss [n0  + 1] +  Rrr [0] 
4 

r [n  − no ]2 ]

To minimize  E ,  we  need  to  choose  no  so that  Rss [n0 + 1] is as large as possible and  no  ≥ 0. 
Looking  at  Figure  3.1,  we  see  that  n0  =  3  minimizes  E  while  satisfying  the  constraint 
no  ≥ 0. 
Note  that  the  choice  of  no  =  3  minimizes  E ,  but  does  not  result  in  an  estimation  error 
that is orthogonal  to  r [n − 3].  The reason we lost orthogonality  is because  s�[n] =  1  r [n − 3] 
2
is  not  the  LMMSE  estimator  of  s[n] given  r [n  − 3].  The  LMMSE  estimator  of  s[n] given 
r [n  − 3]  is  s�[n] =  Csr [3]  r [n  − 3]  =  1  r [n  − 3]. 
3
Crr [0]

12


Problem  4  (14  points) 

Note:  Nothing  on  this  problem  assumes  or  requires  that  you  attended  today’s 
lecture. 

��������� 

�����

��

���� 
�

��
��
� 
�

���� 

����������������� 

��

����������������� 

�����

����

��

��

��

����� 

�����

Figure 4.1 

D/A  converters  utilizing  oversampled  noise  shaping  often  use  the  structure  in  Figure  4.1  to 
quantize the output sequence to a 1-bit bitstream for which D/A  conversion is then very  simple. 
Its  eﬀectiveness  assumes  that  x[n] is  highly  oversampled  and  that  most  of  the  error  introduced 
by  the  quantizer  falls  outside  the  signal  band. 
In  Figure  4.1  the  quantizer  error  is  modeled  as  an  additive,  zero  mean  i.i.d  sequence  e[n] 
that  is  uniformly  distributed  in  amplitude  between  ± △  at  each  time  instant  n.  Furthermore, 
2 
e[n]  and  x[n]  are  assumed  to  be  independent.  The  input  x[n]  has  mean  µx  =  0  and  variance 
2  =  1.  Moreover,  the  input  x[n]  is  bandlimited,  i.e.,  the  power  spectral  density  Sxx(ejΩ ) is 
σx 
zero for  π  <  Ω < π .
|
|
2 
The  output  y [n]  is  composed  of  two  components:  yx [n]  due  solely  to  x[n],  and  ye [n] due 
solely  to  e[n].  Similarly,  w[n] =  wx [n] +  we [n].  Note  that  the  transfer  function  from  x[n]  to 

13


yx [n] is  unity,  and  the  transfer  function  from  e[n] to  ye [n] is (1 − az−1 ). 
| 
(4a)  (7  points) Determine  the  power  spectral  density  of  ye [n] as  a  function  of  Ω  for  Ω < π .
|

Solution:  We  know  that  the  PSD  of  e[n] and  the  PDS  of  ye [n] are  related  as  follows 

Sye ye (ejΩ ) =  Hye (ejΩ )Hye (e −jΩ )See (ejΩ )


Substituting  Hye (ejΩ ) = (1 − ae−jΩ) we  get


Sye ye  (ejΩ )  = (1 − ae −jΩ )(1 − aejΩ )See (ejΩ ) 
2 
(1 + a 2  − 2a cos(Ω)) △ 
Sye ye  (ejΩ )  = 
12 

14


2 [n]},  E {we
2 [n]},  and  the  value  of  the  gain  constant  “a”  that 
(4b) (7 points)  Determine  E {wx
maximizes the  signal-to-noise  ratio (SN R) of  w[n] deﬁned  as 

SN R  = 

2 [n]}
E {wx
2 [n]} 
E {we

Solution: 

2 [n]}  = 
E {wx

π

=

= 

1  �
2π  −π 
1  �
π 
2π  −π 
�

π 
1

2 
2π  −π 
2 
�

π 
1

2 
2π  −π 
2 
=  σ2 
x 
= 1 

= 

Swxwx (ejΩ ) dΩ 
��HLP F (ejΩ )��2 
Syx yx (ejΩ ) dΩ

Syxyx (ejΩ ) dΩ 

Sxx (ejΩ ) dΩ

2 [n]} 
E {we

π

= 

= 

=

Swewe (ejΩ ) dΩ 
��HLP F (ejΩ )�� Sye ye  (ejΩ ) dΩ 
2
Sye ye  (ejΩ ) dΩ

1  �
2π  −π 
1  �
π
2π  −π 
�

π 
1

2 
2π  −π 
2 
�

2
△

2
1 +
 a  − 2a cos(Ω) dΩ
=

24π  −π 
2 
=  △ 2  �π(1 + a 2 ) − 4a� 
24π 

π
2

The  SN R  is given by 

SN R  = 

1 
△2 
24π  (π(1 + a2 ) − 4a) 

15


To  maximize  the  SN R  we  select  the  gain  constant  a  that  minimizes  the  expression 
π(1 +  a2 ) −  4a.  Diﬀerentiating  with  respect  to  a  and  setting  the  derivative  equal  to  0  re­
sults in  a  =  2
2 
.  We  know  the  value  of  a  =  minimizes  the  denominator  because  the  second 
π
π 
derivative  of  π(1 + a2 ) − 4a  is  greater  than  zero  for  this  choice  of  a. 

16


MIT OpenCourseWare
http://ocw.mit.edu 

6.011 Introduction to Communication, Control, and Signal Processing 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

