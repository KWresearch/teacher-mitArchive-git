Massachusetts  Institute  of  Technology 
Department  of  Electrical  Engineering  and  Computer  Science

6.011:  Introduction  to  Communication,  Control  and  Signal  Processing

FINAL  EXAM, May  18,  2010

ANSWER  BOOKLET 

Your  Full  Name: 

SOLUTIONS 

Recitation  Time  : 

o’clock 

•	 This  exam  is  closed  book,  but  4  sheets  of  notes  are  allowed.  Calculators  and  other 
electronic  aids  will  not  be  necessary  and  are  not  allowed. 
•	 Check  that  this  ANSWER  BOOKLET  has  pages  numbered  up  to  26.  The  booklet 
contains  spaces  for  all  relevant  reasoning  and  answers. 
•	 Neat work and clear explanations count;  show all relevant work and reasoning! 
You  may  want  to  ﬁrst  work  things  through  on  scratch  paper  and  then  neatly  transfer  to 
this  booklet  the  work  you  would  like  us  to  look  at.  Let  us  know  if  you  need  additional 
scratch  paper.  Only  this  booklet  will  be  considered  in  the  grading;  no  additional  an­
swer  or  solution  written  elsewhere  will  be  considered.  Absolutely  no  exceptions! 
•	 There  are  5  problems,  weighted  as  shown,  for  a  total  of  100  points.  (The  points 
indicated  on  the  following  pages  for  the  various  subparts  of  the  problems  are  our  best 
guess  for  now,  but may  be modiﬁed  slightly  when  we  get  to  grading.) 

Your  Score 

Problem 

1  (17  points) 

2  (18  points) 

3  (25  points) 

4  (20  points) 

5  (20  points) 

Total  (100  points) 

1


Problem  1  (17  points)


Note  that  1(d)  does  not  depend  on  your  answers  to  1(a)-(c),  and  can  be  done

independently  of  them. 

xc (t)  � 

C/D 

� 
T1 

Xc (jω) = 0 
x[n]  � 

h[n] 

|ω | � 2π × 103  . 
for 
y [n]  �  PAM 
�r(t) 
� 
p(t), T2 

C/D 

� 
T2 

q [n] = r(nT2 ) 
� 

�H (ejΩ ) 
1 

−π 

− � 
2 

� 
Ω 

� 
2 

π

1(a)  (3  points)  Determine  the  largest  value  of  T1  to  ensure  that  y [n] = xc (nT1 ) . 

Solution:  For y [n] = xc (nT1 ) = x[n], we need to choose T1  so that X (ejΩ )  is bandlimited 
to  π/2.  You  might  anticipate  that  this  will  require  sampling  at  twice  the  Nyquist  rate. 
After  sampling  (and  assuming no  aliasing —  a  good  assumption  if we will be  sampling  at 
twice the Nyquist rate), we know X (ejΩ ) is related to its continuous counterpart as follows 
(cid:12)(cid:12)(cid:12)

in  the  interval  |Ω| < π  (and  repeats  periodically  with  period  2π  outside  this  interval): 
1 
Xc (jω) 
T1 
Ω
�= 
T1 
Since Xc (jω) is bandlimited to 2π × 103 , we know from the above relation that the highest 
frequency  in X (ejΩ ) is Ωo  = (2π × 103 )T1 .  Since we  require  |Ωo | � π/2, we  conclude  that 
T1  �  2.5 × 10
−4 .  This  does  indeed  correspond  to  sampling  at  twice  the  Nyquist  rate  for 
the  signal  xc (t). 

X (ejΩ ) = 

. 

2 

1(b)  (6  points) With  T1  picked  as  in  1(a),  determine  a  choice  for  T2  and  p(t)  to  ensure  that 

r(t) = xc (t)  . 

(You  can  leave  your  expressions  for  T2  and  p(t)  in  terms  of  T1 ,  instead  of  substituting  in 
the  numerical  value  you  obtained  in  1(a)  for  T1 .) 

∑ 
Solution:  For  r(t) = xc (t),  with  the  PAM  relation 
y [n]p(t − nT2 )  , 
n 

r(t) = 

we need to perfectly reconstruct xc (t) from the samples y [n].  Since we chose T1  in part 1(a) 
to  ensure  that  y [n] = x[n],  attaining  the  equality  r(t) = xc (t)  amounts  to  using  the  PAM 
block  in  the  ﬁgure  to  perfectly  reconstruct  xc (t)  from  the  samples  y [n] = x[n] = x(nT1 ). 
This  is possible,  by  the  sampling  theorem,  since  the  samples  are  collected  at  greater  than 
the Nyquist  rate.  Speciﬁcally, perfect  reconstruction can be achieved by  interpolating  the 
∑ 
samples  y [n]  with  interval  T1  using  a  sinc  function  (i.e.,  using  an  ideal  D/C  converter), 
as  follows: 
sin( �  (t − nT1 )) 
T1 
(t − nT1 )
y [n] 
�
T1 
n
(This  is  the  standard  sampling-theorem  reconstruction  of  a  bandlimited  signal  from  sam­
ples  taken  at  a  suﬃciently  high  rate.)  Hence  we  can  choose  T2  =  T1  and  use  the  PAM 
pulse 

� 
sin( 
T
p(t) = 
. 
1 
�
tT1 
Note  for  future  reference  that  P (jω) = T1  in  the  interval  |ω | < (π/T1 ),  and  0  elsewhere. 

t) 

r(t) = 

. 

(Continue  1(b)  on  next  page:) 

3 

y [n]p(t − nT2 ) 

1(b)  (continued) Also  determine  if  there  is  another  choice  of T2  and  p(t)  that  could  ensure  the 
equality  r(t) = xc (t).  Explain  your  answer  carefully. 
(cid:12)(cid:12)(cid:12) 
(cid:12)(cid:12)
(cid:12) 
Solution:  Since  our  samples  were  obtained  at  twice  the  Nyquist  rate,  we  can  actually 
|
| 
(cid:12)(cid:12)(cid:12)

use  any  interpolating  pulse  whose  transform  P (jω) 
T1  in the interval  ω < π/(2T ),
=

1
where X (ejΩ ) 
jΩ )
is  nonzero,  and  0  wherever  else X (e

is nonzero; the choice 
Ω=�T1 
Ω=�T1 
of  P (jω)  in  intervals  where  X (ejΩ ) 
=  0  is  arbitrary.  To  see  this  more  concretely, 
∑

Ω=�T1 
note  that  the  PAM  relation 
r(t) = 
n 
translates  in  the  frequency  domain  to
∑

)

n(

−j�nT2 P (jω) 
∑

R(jω) = 
y [n]e
(cid:12)(cid:12)(cid:12)

−j�nT2
y [n]e
n 
Y (ejΩ ) 
P (jω)

Ω=�T2 
(cid:12)(cid:12)(cid:12)

We  chose  T1  in  part  1(a)  to  ensure  that  y [n] = x(nT1 ) = x[n],  so  we  can  write 
R(jω) = X (ejΩ ) 
P (jω) . 
Ω=�T2 
(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)

To  get  r(t) = xc (t),  we must  ensure  R(jω) = Xc (jω),  so  we  require 
P (jω) = X (e
jΩ ) 
X (e
jΩ ) 
T1 
Ω=�T1 
Ω=�T2 
for  |ω | < π/(2T1 ),  and  require  the  left  side  to  be  0  for  |ω | > π/(2T1 ). 
(cid:12)(cid:12)(cid:12) 
The  above  expression  implies  the  constraints  T2  =  T1  and  P (jω) =  T1  for  |ω | �  2
�
Moving to higher values of  |ω |, note that since X (ejΩ )|Ω=�T1 
T1 
replicates at multiples of  2�
T1 
−

(cid:12)(cid:12)(cid:12) 
2�
�
jΩ )
at

we  need  P (jω)  to  be  zero  before  the  ﬁrst  replication  edge  of X (e

=

2T1
T1 
(One  can  have  P (jω)  change  back  to  nonzero  values  at  yet  higher  |ω |  for  which

Ω=�T1 
3� 
.

2T1 
X (ejΩ ) 
goes  to  0  again,  but  we  don’t  pursue  this  here.) 
Ω=�/T1 
If  we  stick  to  sinc  functions  for  p(t),  then  we  achieve  r(t) = xc (t)  if  we  use  a  PAM  block 
with  T2  = T1  and 

P (jω)


. 
, 

=


=


� 
sin( T
3 
� 
tT1 

t) 

, 

p(t) = 

4 

where 

or


� 

,

� 

π 
3π 
π
2T1 
T3 
2T1

2T1  � T3  � 2T1  . 
3 

1(c)  (3  points)  With  T1  picked  as  in  1(a),  how  would  you  modify  your  choice  of  T2  and  p(t) 
from  1(b)  to  ensure  that 

r(t) = xc (2.7t)  . 

Solution:  From part (b) we know one choice of PAM parameters that ensures r(t) = xc (t) 
� 
t) 
sin( 
∑ 
T
.  This  allows  us  to  express  r(t) = xc (t)  as 
is  T2  = T1  and  p(t) = 
2 
�
t
T2 
sin(π(  t  − n)) 
T1 
π(  t  − n)
y [n] 
T1 
n

r(t) = xc (t) = 

For  r(t)  to  equal  xc (2.7t),  we  subsitute  2.7t  for  t  in  the  above  relation  to  get 
∑ 
sin(π( 2.7t  − n)) 
∑ 
T
− n) 
y [n] 
1 
t 
π( 2.7
T1 
n
sin(π(  t  − n)) 
T2 
π(  t  − n)
y [n] 
T2 
n

r(t) = xc (2.7t) = 

= 

where T2  = T1/2.7.  So,  a PAM block with T2  = T1/2.7 and p(t) = 
r(t) = xc (2.7t). 

) 

�t 
sin( 
T
2 
�t 
T2 

will  ensure  that 

1(d)  (4  points)  Assume  that  p(t)  is  now  chosen  so  that  its  CTFT,  P (jω),  is  as  shown  below. 
Determine  a  value  of  T2  to  ensure  that  q [n] = y [n]. 

P (jω) 
� 

−3 

10

−2π × 103 

2π × 103 

� 
ω 

5 

Solution:  To  ensure  that  q [n] =  y [n],  we  must  choose  T2  so  that  the  pulse  P (jω)  satisﬁes 
the  Nyquist  condition  for  zero  ISI.  In  the  frequency  domain,  this  condition  requires  that  the 
∑ 
� 
sum  of  replicas  of  P (jω)  centered  at  integer multiples  of  2
adds  up  to  T2 : 
T
2 
P (j (ω − 
2π 
T2  = 
k))
T2
k 
For  the  given  pulse  P (jω),  choosing  2�  = 2π × 103  or  T2  =  10
−3  allows  us  to  satisfy  the 
T2 
Nyquist  condition  for  zero  ISI.  Note  that  this  T2  is  four  times  the  T2  picked  in  (b),  but  this  is 
because  now  we  are  only  trying  to  preserve  the  samples,  not  the  CT  waveform. 

6


Problem  2  (18  points) 

For  each  of  the  following  parts,  write  down  whether  the  statement  is True  or  False  (circle 
whichever  is  appropriate),  giving  a  clear  explanation  or  counterexample.  (Take  care with  this!) 

2(a)  (4  points)  Suppose  x[n]  is  a  zero-mean  discrete-time  (DT)  wide-sense  stationary  (WSS) 
random  process.  If  its  autocorrelation  function  Rxx [m]  is  0  for  |m| �  2  but  nonzero  for 
m = −1, 0, 1,  then the  linear minimum mean-square-error (LMMSE) estimator of x[n + 1] 
from measurements  of  x[n]  and  x[n − 1],  namely 
xb[n + 1] = a0x[n] + a1x[n − 1]  , 

will  necessarily  have  a1  = 0. 

TRUE 

FALSE 

Explanation/counterexample:


Solution:  FALSE.

Since  the  mean  of  x[n]  is  zero,  Rxx [m] =  Cxx [m].  The  coeﬃcients  a0  and  a1  are  formed

]
[ 
]
] [ 
[ 
by  solving  the  normal  equations:


Cxx [0]  Cxx [1] 
Cxx [−1]  Cxx [0] 
This matrix  equation  cannot  be  solved  with  a1  = 0. 

a0 
a1 

Cxx [−1]
0 

= 

7


2(b)  (4  points)  If  the  power  spectral  density  Syy (jω)  of  a  continuous-time  (CT) WSS  random 
process  y(t)  is  given  by 

17 + ω2 
23 + ω2 
then  the mean  value  of  the  process  is  zero,  i.e.,  µy  = E [y(t)] = 0. 

Syy (jω) = 

TRUE 

FALSE 

Explanation/counterexample: 

Solution:  TRUE.

In  general,  Cyy (τ )  ≤  Dyy (jω) =  Syy (jω) − µy
2 2πδ (ω),  and  Dyy (jω)  �  0.  For  the  given

Syy (jω),  the  inequality  Dyy (jω) �  0  cannot  be  satisﬁed  unless  µy  =  0  since  Syy (jω)  has

no  impulses  at  ω = 0.


8


(
)|m|
2(c)  (4  points)  If  the  autocovariance  function  Cvv [m]  of  a  DT  WSS  random  process  v [n]  is 
given  by 
1
Cvv [m] = 
3
(  �
) 
∑ 
then  the  LMMSE  estimator  of  v [n + 1]  from  all  past measurements,  which  we  write  as 
vb[n + 1] = 
hk v [n − k ] + d , 
k=0 
will  have  hk  = 0  for  all  k � 1,  i.e.,  only  the  coeﬃcients  h0  and  d  can  be  nonzero. 

,

TRUE 

FALSE 

Explanation/counterexample: 

Solution:  TRUE.

The  claim  is  that  the  LMMSE  estimator  of  v [n + 1]  has  the  form:

vb[n + 1] = h0v [n] + d 
To  verify  this  claim,  we  need  to  show  that  the  estimation  error  is  orthogonal  to  1  (i.e., 
that  the  estimator  is  unbiased)  and  to  v [n],  for  some  appropriately  chosen  h0  and  d. 
Orthogonality  to  v [n]  implies: 
E [(v [n + 1] − bv [n + 1])v [n]]  =  0 
Rvv [1] − h0Rvv [0] − dµv  = 0 
Cvv [1] − h0Cvv [0] + (1 − h0 )µv 
2  − dµv  = 0 
− h0  + (1 − h0 )µv  − dµv  = 0 
1 
2 
3 

Orthogonality  to  1  implies: 

E [(v [n + 1] − vb[n + 1])]  =  0 
µv  − h0µv  − d  = 0 
3 µv .  Hence,  bv [n + 1] =  1
3 v [n] +  2
These  equalities  are  satisﬁed when  h0  =  1
3  and  d =  2
3 µv  is 
the  LMMSE  estimator  of  v [n + 1]. 

9 

2(d)  (3  points)  The  process  v [n]  in  2(c)  is  ergodic  in mean  value. 

TRUE 

FALSE 

Explanation/counterexample: 

Solution:  TRUE. 
Since  the  covariance  function  Cxx [m]  goes  to  zeros  as  m ∗ ≥,  we  can  conclude  that  the 
process  v [n]  is  ergodic  in  the mean. 

2(e)  (3  points)  If  z [n] = v [n] + W , where  v [n]  is  the  process  in  2(c),  and where W  is  a  random 
variable with mean 0 and variance σ2  > 0, then the process z [n] is ergodic in mean value. 
W 

TRUE 

FALSE 

Explanation/counterexample: 

Solution:  FALSE. 
The ensemble average of z [n] is E [z [n]] = µv .  However, the time-average of any particular 
realization  of  z [n]  will  be  µv  + w,  where  w  is  the  particular  realization  of  W  in  that 
outcome.  Since  the  time-average of  z [n] does not  equal  its  ensemble average, we  conclude 
that  the  process  z [n]  is  not  ergodic  in  the mean. 

10 

Problem  3  (25  points) 

where 

[ 

]

q1 [n] 
q2 [n] 

q[n] = 

,  A =

q[n + 1]  =  Aq[n] + bx[n] + hw[n]  , 
y [n] =  c T q[n] + v [n]  . 
[ 
[  1
]
[  1 
]
2 
2 
1 
0 

,  b =

3 
4 
2 

,  h =

0 
1 

] 
[
,  c T  =  0 1 

]

, 

3(a)  Determine  the  two  natural  frequencies  of  the  system  (i.e.,  the  eigenvalues  of  A),  and  for 
each  of  them  specify  whether  the  associated  mode  satisﬁes  the  properties  listed  on  the 
next  page. 

Solution:. 
The  matrix  A  is  upper  triangular,  so  its  eigenvalues  are  its  diagonal  entries.  Hence, 
1  and λ2  = 2.  The eigenvector associated with λ1  is v1  =  [1  0]T  and  the eigenvector 
λ1  =  2
2  1]T . 
associated  with  λ2  is  v2  = [ 1

(Write  your  answers  on  the  next  page.) 

11 

3(a)  (continued)(8  points)


The  two  eigenvalues  are: 

λ1  =  1
2 

λ2  = 2 

List  below  whichever  of  the  eigenvalues,  if  either,  has  an  associated  mode  that  satisﬁes 
the  indicated  condition: 

(i)  decays  asymptotically  to  0  in  the  zero-input  response:

λ1  since  |λ1 | < 1

[
]
(ii)  is  reachable  from  the  input  x[n]  (with  w[n]  kept  at  zero): 
−1b =
0 
1 

[
]
(iii)  is  reachable  from  the  input  w[n]  (with  x[n]  kept  at  zero): 
−
1 
−1h = 
2
1 

λ2  since V

λ1  and  λ2  since V

(iv)  is  observable  from  the  output  y [n]: 
λ2  since  cT V = [0  1] 

12 

3(b)  (2  points)  Your  speciﬁcation  of  the  observer,  to  obtain  an  estimate  qb[n]  of  the  state  q[n] 
(explain  your  choice): 

Solution:.

Since  w[n]  and  v [n]  are  noise  processes  that  are  not  accessible  to  us,  our  observer  takes

the  form:

qb[n + 1] = Aqb[n] + bx[n] − l(y [n] − c T qb[n]) 
i.e.,  qb[n + 1] = Aqb[n] + bx[n] − l(c T q[n] + v [n] − c T qb[n]) 
3(c)  (2  points) With  qe[n] = q[n] − qb[n],  explain  carefully  why  the  components  qe1 [n]  and  qe2 [n] 
of  qe[n]  at  time  n  are  uncorrelated  with  the  noise  terms  w[n]  and  v [n]  at  time  n  (or  — 
equivalently,  of  course!  —  explain  why  the  components  of  qe[n + 1]  are  uncorrelated  with 
w[n + 1]  and  v [n + 1]): 

The  state  vector  q[n + 1]  depends  on w[k ]  for  k � n.  The  estimated  state  vector  qb[n + 1]

Solution:.

depends  on  v [k ]  for  k � n,  and  on  w[j ]  for  j  � n − 1  since  qb[n + 1]  is  a  function  of  q[n].

Hence, qe[n + 1] = q[n + 1] − qb[n + 1] depends only on v [k ]  for k � n and on w[k ]  for k � n. 

w[n + 1]  and  v [n + 1]  are  uncorrelated  with  qe[n + 1]. 
Since the processes w[n] and v [n] are white and uncorrelated with each other, we know that

each  of  w[n + 1]  and  v [n + 1]  is  uncorrelated  with w[k ]  and  v [k ]  for  k � n.  Consequently, 

13


qe[n + 1] = Bqe[n] + f w[n] + gv [n]  . 
3(d)  (4  points)  The  state  estimation  error  in  3(c)  is  governed  by  a  state-space  model  of  the 
form 
Determine  B,  f  and  g  in  terms  of  previously  speciﬁed  quantities. 

Solution:. 
q˜[n + 1]	 =  q[n] − qb[n] 
=  Aq[n] + hw[n] + bx[n] − (Aqb[n] + bx[n] − l(y [n] − c T qb[n])) 
=  Aq[n] + hw[n] + bx[n] − (Aqb[n] + bx[n] − l(c T q[n] + v [n] − c T qb[n])) 
= (A + lcT )q˜[n] + hw[n] + lv [n] 
]
]
[
]
[
[

=  B˜q[n] + f w[n] + gv [n] 
,  f  = 

So  B = A + lcT  =


,  and  g = 

l1 
l2 

1 
2 
0


3 
+ l1 
4
2 + l2 

0 
1 

14


3(e)  (5  points)  Is  it  possible  to  arbitrarily  vary  the  natural  frequencies  of  the  state  estimation 
error  evolution  equation  in  3(d)  by  controlling  the  observer  gains  ℓ1  and  ℓ2?  Explicitly 
note  how  your  answer  here  is  consistent  with  your  answer  to  3(a)(iv). 

Solution:  The  eigenvalues  of  the  matrix  B,  which  governs  the  state  estimation  error 
dynamics, are  1
2  and 2 + l2 .  So, only one of the eigenvalues can be arbitrarily placed using 
the  observer  gain  vector  l.  This  is  consistent  with  λ2  being  the  only  mode  observable 
from  the  output  y [n]. 

What  constraints,  if  any,  on  ℓ1  and  ℓ2  must  be  satisﬁed  to  make  the  error  evolution 
equation  asymptotically  stable? 

Solution:  For  the  error  evolution  equation  to  be  asymptotically  stable,  we  need  the 
eigenvalues  of  the matrix B  to be within  the unit  circle.  One  eigenvalue  is  already within 
1 .  For  the  second  eigenvalue  to  be  within  the  unit  circle  we 
the  unit  circle  and  ﬁxed  at  2
need  |2 + l2 | < 1  or  −3 < l2  < −1.  There  is  no  constraint  on  the  value  of  l1 . 

Would  the  choice  ℓ2  = 0  allow  you  to  obtain  a  good  state  estimate?  —  explain. 

Solution:  No.  Choosing  l2  = 0 would  result  in  a  exponentially  growing  error  in  estimat­
ing  the  state  q2 [n]. 

15 

If  you  have  done  things  correctly,  you  should  ﬁnd  that  choosing  ℓ1  = −
3  makes  the matrix 
B  in  part  3(d)  a  diagonal matrix.  Keep  ℓ1  ﬁxed  at  − 3  for  the  rest  of  this  problem,  and 
4
4 
also  assume  ℓ2  is  chosen  so  that  the  error  evolution  equation  is  asymptotically  stable. 
stant  steady-state  values,  E (qe
and  E (qe
3(f )  (4  points)  Under  the  given  assumptions,  the  mean-squared  estimation  errors  attain  con­
2 [n])  and  E (qe
E (qe
2 [n + 1]) = E (qe
2 [n + 1]) = E (qe
2 
σ2
2σq
2
1 [n]) 
=

2 [n]) 
=

2 . 
Find  explicit  expres­

1 
q
sions  for  σ2

and  σ2
[Hint:  At  steady  state, 
2 ,  expressing  them  as  functions  of  ℓ2 .
q1 
q
2 [n]).]

2
2
1
1
] 
[ 
[ 
] 
] 
[  −
Solution:  With  l1  = −
3  the  error  evolution  equation  becomes 
4
3 
v [n] 
w[n] + 
q˜[n] + 
4
l2 

1
0 
2
0  2 + 
l2 

q˜[n + 1] = 

0
1 

For  the  state  ˜q1 [n]  we  have 

q1 [n] − 
1 
2 [n + 1]]  =  E [(
E [ ˜q1
2
1 
2 
=

[
E [
q n1
2 [n + 1]) = E (qe
In  steady  state  we  have  E (qe
4

2 [n])  so 
1
1

]] + 

3 
2 
E [ ˜q1 [n]]  = 
4 

σ2 
q1 

= 

9 
2σv 
16 
3 
2σv 
4 

3 
v [n])2 ]
4 
9 
16


2
v 

σ

For  the  state  ˜q2 [n]  we  have 

2 
E [((2 + l2 )q2 [n] + w[n] + l2v [n])2 ]
E [ ˜q2 [n + 1]]  = 
2 [n + 1]) = E (qe
In  steady  state  we  have  E (qe
(2 + l2 )2E [q 2
2
2 2
=

l σ+  2 v 
]] + σ
[
n2
w
2 [n])  so 
2
2

σ2  = 
q2 

2σw
2 2
l σ+  2 v
1 − (2 + l2 )2 

16 

Problem  4  (20  points)


−2 

f (x|H0 ) 
� 

1 
4 
� 
x2 

f (x|H1 ) 
� 
1 
2 

−1 

� 
x 

1 

4(a)  (4  points)  Sketch  Λ(x) = 

fX |H (x|H1 )
fX |H (x|H0 ) 

as  a  function  of  x  for  −2 < x < 2:

Solution: 

Λ(x) 
� 
2 

−1

� 
x 

1 

17


4(b)  (6  points) 

(i)  For  threshold  η  at  some  value  strictly  above  2,  determine  PD  and  PF A : 

Solution:  In  this  case,  we  will  always  declare  ‘H0 ’  since  Λ(x)  < η .  Consequently, 
PD  = 0  and  PF A  = 0. 

(ii)  For  η  at  some  value  strictly  between  0  and  2,  determine  PD  and  PF A : 

Solution:  In  this  case,  we  will  declare  ‘H1 ’  for  |x| �  1  and  ‘H0 ’  for  |x|  >  2. 
1 . 
Consequently,  PD  = 1  and  PF A  =  2

18


4(b)  (continued) 
(iii)  For  η  at  some  value  strictly  below  0,  determine  PD  and  PF A : 

Solution:  In  this  case,  we  will  always  declare  ‘H1 ’  since  Λ(x)  > η .  Consequently, 
PD  = 1  and  PF A  = 1. 

4(c)  (2  points)  If  the  speciﬁed  limit  on  PF A  is  β  = 0.3,  which  of  the  choices  in  4(b)  can  we 
pick,  and  what  is  the  associated  PD ? 

Solution:  Only  η > 2,  i.e.  always  declare  ‘H0 ’,  results  in  PF A  < 0.3.  However,  PD  = 0. 

19


4(d)  (8  points)  What  is  the  probability  that  we  get  Λ(X )  =  0  if  H0  holds?  And  what  is  the 
probability  we  get  Λ(X ) = 0  if H1  holds? 

Solution:  Under  the  hypothesis  H0 ,  Λ(X ) = 0  when 1  <  |x|  <  2.  The  value  of  x  falls 
2 ,  so P (Λ(X ) = 0 | H0 ) =  1
within  this  range with probability  1
2 .  Under  the hypothesis H1 , 
Λ(X )  never  equals  0  since  |x| � 1.  So,  P (Λ(X ) = 0 | H1 ) = 0 

Announce  ‘H0 ’  when  Λ(x) =  0.  When  Λ(x) >  0,  announce  ‘H1 ’  with  probability  α,  and 
otherwise  announce  ‘H0 ’.  What  are  PD  and  PF A  with  this  randomized  decision  rule? 

Solution: 

PD  = αP (‘H1 ’|H1 ) = αP (Λ > 0|H1 ) = α 

PF A  = αP (‘H1 ’|H0 ) = P (Λ > 0|H0 ) = 

α 
2 

To maximize  PD  while  keeping  PF A  � 0.3  with  this  decision  rule,  choose  α  as  follows 
Solution: 
PF A  =  �  �  0.3  so  α  �  0.6.  Since  PD  =  α,  we  choose  α  = 0.6  to  maximize  PD  while
2 
satisfying  the  constraint  on  PF A . 

20


Problem  5  (20  points) 

x[n] 

�  K (z ) = 1 − µz

−1 

r [n]
� 

�  + 
� 

y [n] 

r [n] 
� f [n], F (z ) 

g [n]  � n = n0  � 
g [n0 ] 

Threshold  γ

‘H1 ’ 
�  > 
<
‘H0 ’

5(a)  (10  points)  Suppose  x[n]  is  a  signal  that  we  are  interested  in,  while  y [n]  is  a  zero-mean, 
i.i.d.,  Gaussian  noise  process,  with  variance  σ2  at  each  instant  of  time. 

H0  : x[n] = 0  ,
H1  : x[n] =  δ [n] ,

P (H0 ) = p0  ,

P (H1 ) = p1  = 1 − p0  .


(i)  Fully  specify  the MPE  receiver when  n0  = 0,  i.e.,  specify  f [n]  or  F (z )  and  the  value 
of  γ . 

Solution:  The received signal r [n] takes the  following values under each hypothesis: 

H0  : r [n] =  y [n]

H1  : r [n] =  δ [n] − µδ [n − 1] + y [n]


Since  y [n]  is  an  i.i.d.  process,  we  know  the MPE  receiver  will  employ  a  ﬁlter  whose 
impluse  response  is  a  time-reversed  replica  of  the  pulse  to  be  detected.  So  f [n] = 
δ [n] − µδ [n + 1]  and  F (z ) = 1 − µz . 
To  compute  the  threshold  γ ,  we  need  to  apply  the  MAP  detection  rule.  The  distri­
bution  of  g [0]  conditioned  on  each  hypothesis  is 

fg [0]|H0  = N (0, σ2 (1 + µ 2 )) 
fg [0]|H1  = N (1 + µ 2 , σ2 (1 + µ 2 )) 

The MAP  detection  rule  in  this  case  declares  ‘H1 ’  when 

21 

fg [0]|H1 p1  > fg [0]|H0 p0 

− 
(g [0]−(1+µ2 ))2 
1 
2�2 (1+µ2 ) 
e
− 
1 
(g [0])2 
2�2 (1+µ2 ) 
e

>

p0 
p1 

g [0]  > σ2  ln(

p0 ) + 
p1 

1 + µ2 
2 

g [0]  > γ 

5(a)(ii)  Write  down  an  expression  for  P (‘H1 ’|H0 )  and  for  the  minimum  probability  of  error 
∫ 
in the case where the two hypotheses are equally  likely, p0  = p1 .  You can write these 
in  terms  of  the  standard  function 
→
1 
2π  � 

−  2  dt
2
t

Q(α) = 

� 

e

.  In  this  case  P (‘H1 ’|H0 )  is 
µ2 
Solution:  When  p0  =  p1 ,  then  γ  =  1+
2 
P (g [0] > γ H0 ) =  P (  √ 
>  √ 
µ2 
1+
|
g [0] 
2 
=  Q(  √  2 
σ  1 + µ2 
σ  1 + µ
2
1+µ2 
) 
σ  1 + µ2 
The  probability  of  error  Pe  is  given  by 

|
H0 )

Pe  =  p0P (‘H1 ’|H0 ) + p1P (‘H0 ’|H1 ) 
√
√
−  2 
1+µ2 
1+µ2 
(1 − Q( 
1 
1
2 
) + 
Q( 
))
=
) +  Q(  √ 
=  Q(  √ 
2
2
σ  1 + µ2 
σ  1 + µ2 
µ2 
µ2 
1+
1+
1 
1 
2 
2 
)
=  Q(  √  2 
2
2
σ  1 + µ2 
σ  1 + µ2 
1+µ2 
) 
σ  1 + µ2 

22 

5(a)(iii)  If  the value  of µ  is  changed  to  a new value µ = µ/2, we  can  get  the  same probability 
of  error  as  prior  to  the  change  if  the  noise  variance  changes  to  some  new  value  σ2 . 
Express  σ  in  terms  of  σ : 

Solution:  With  the  new  parameters  µ  and  σ2 ,  we  require  that  the  probability  of 
error  remain  equal  to  that  in  part  5(a)(ii),  this  implies 
) =  Q(  √  2 
Q(  √  2 
1+µ2 
1+µ2 
) 
=  √  2 
√  2 
σ  1 + µ2 
σ  1 + µ2 
1+µ2 
1+µ2 
σ  1 + µ2 
σ  1 + µ2 

Since  µ = µ/2 

√  2 
1+µ2 
σ  1 + µ2 

=  √  2 
2 
1+ µ 
√ 
2
σ  1 +  µ 2 
2 
1 + ( µ )2 
2 
σ  =  σ 
1 + µ2 

23


5(b)  (10  points)  Suppose  now  that  x[n]  is  a  zero-mean,  i.i.d.,  Gaussian  noise  process,  with 
variance  σ2  at  each  instant  of  time,  and  that  y [n]  is  the  signal  we  are  interested  in.  We 

x[n] 

�  K (z ) = 1 − µz

−1 

r [n]
� 

�  + 
� 

y [n] 

r [n] 
� f [n], F (z ) 

g [n]  � n = n0 
� Threshold  γ 
g [n0 ] 

‘H1 ’ 
>
�  < 
‘H0 ’ 

have  the  following  two  hypotheses  regarding  y [n]: 

H0  : y [n] = 0 ,
H1  : y [n] =  δ [n]  ,

P (H0 ) = p0  , 
P (H1 ) = p1  = 1 − p0  . 
Fully  specify  the MPE  receiver  when  n0  = 0,  i.e.,  specify  f [n]  or  F (z )  and  the  value  of  γ 
for  this  case. 
Solution:  The  received  signal  r [n]  takes  the  following  values  under  each  hypothesis: 

H0  : r [n] =  v [n] 
H1  : r [n] =  δ [n] + v [n] 

−1 )σ2 .  In  this  scenario,  the 
where  v [n]  is  a  colored  noise  process  with  Svv (z ) = K (z )K (z
1
MPE  receiver ﬁrst passes  the  signal r [n]  through a whitening ﬁlter Hw (z ) =  K
(z )  in order 
to  transform  the  problem  into  one  of  detecting  a  known  pulse  in  a  white  noise  process. 
After  applying  the  whitening  ﬁlter,  the  hypothesis  testing  problem  becomes 

H0  : r [n] � hw [n] =  v [n] � hw [n] = x[n] 
H1  : r [n] � hw [n] =  δ [n] � hw [n] + v [n] � hw [n] = µ n u[n] + x[n] 

Now  the  receiver will  employ  a  ﬁlter whose  impluse  response  is  a  time-reversed  replica  of 
−nu[−n]  and  Hm (z ) = 
1 
the  new  pulse.  So  hm [n] = µ
.  Overall,  the MPE  receiver  is 
K (z−1 ) 
a  cascade  of  a whitening ﬁlter  and  a matched ﬁlter  that  is  followed by  a  threshold  test  on 
the  output  at  n0  = 0. 

24 

F (z ) = Hw (z )Hm (z ) = 

1 
1
K (z ) K (z−1 ) 

= 

σ2 
Svv (z ) 

To  compute  the  threshold  γ ,  we  need  to  apply  the MAP  detection  rule.  The  distribution 
of  g [0]  conditioned  on  each  hypothesis  is 

fg [0]|H0  = N (0, 

fg [0]|H1  = N (

1 
1 − µ2 , 

σ2 
1 − µ
)2 
σ2 
1 − µ2 ) 

The MAP  detection  rule  in  this  case  declares  ‘H1 ’  when 

fg [0]|H1 p1  > fg [0]|H0 p0 

)2 

2  (g [0]− 
− 
1−1 
1
2 
µ
2  �
1−µ2 
e 
1− 
2  �2  (g [0])2 
1−µ2 
e 

>

p0 
p1 

g [0]  > σ2  ln(

p0 ) + 
p1 

1 
2(1 − µ2 ) 

g [0]  > γ 

The  relevant  “signal  energy  to  noise  power”  ratio  that  governs  the  performance  of  this 
system  is 

1 
1−µ2 
σ2 

= 

1 
σ2 (1 − µ2 ) 

25


MIT OpenCourseWare
http://ocw.mit.edu

6.011 Introduction to Communication, Control, and Signal Processing
Spring 2010

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 

