SIGNALS, 

SYSTEMS,

and  INFERENCE 

—

Class Notes  for

6.011:  Introduction  to

Communication,  Control  and

Signal  Processing

Spring  2010


Alan  V.  Oppenheim  and  George  C.  Verghese 
Massachusetts  Institute  of  Technology 

° 
c Alan  V.  Oppenheim  and  George  C.  Verghese  2010 

2 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Contents 

1  Introduction	

2  Signals  and  Systems	

9


21


2.1  Signals, Systems, Models, Properties  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  21 


2.1.1	

System/Model Properties  . . . . . . . . . . . . . . . . . . . .  22 


2.2  Linear, Time-Invariant Systems  . . . . . . . . . . . . . . . . . . . . .  24 


2.2.1	

Impulse-Response  Representation  of  LTI  Systems  .  .  .  .  .  .  .  24 


2.2.2	 Eigenfunction  and  Transform  Representation  of  LTI  Systems 

26 


2.2.3	 Fourier Transforms  . . . . . . . . . . . . . . . . . . . . . . . .  29 


2.3  Deterministic  Signals  and  their  Fourier  Transforms  .  .  .  .  .  .  .  .  .  .  30 


2.3.1	

Signal  Classes  and  their  Fourier  Transforms  .  .  .  .  .  .  .  .  .  .  30 


2.3.2	 Parseval’s  Identity,  Energy  Spectral  Density,  Deterministic

Autocorrelation  . . . . . . . . . . . . . . . . . . . . . . . . . .  32 

2.4  The  Bilateral  Laplace  and  Z -Transforms  . . . . . . . . . . . . . . . .  35 

2.4.1  The  Bilateral  Z -Transform 
. . . . . . . . . . . . . . . . . . .  35 

2.4.2	 The  Inverse  Z -Transform 
. . . . . . . . . . . . . . . . . . . .  38 

2.4.3	 The Bilateral Laplace Transform  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  39 


2.5  Discrete-Time  Processing  of  Continuous-Time  Signals 

.  .  .  .  .  .  .  .  40 


2.5.1	 Basic  Structure  for  DT  Processing  of  CT  Signals  .  .  .  .  .  .  .  40 


2.5.2	 DT  Filtering,  and  Overall  CT  Response  .  .  .  .  .  .  .  .  .  .  .  .  42 


2.5.3	 Non-Ideal D/C converters  . . . . . . . . . . . . . . . . . . . .  45 


3  Transform  Representation  of  Signals  and  LTI  Systems 

47


3.1  Fourier Transform Magnitude and Phase  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  47 


3.2  Group  Delay  and  The  Eﬀect  of  Nonlinear  Phase 

.  .  .  .  .  .  .  .  .  .  .  50 


3.3  All-Pass and Minimum-Phase Systems  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  57 


3.3.1	 All-Pass Systems  . . . . . . . . . . . . . . . . . . . . . . . . .  58 


3.3.2	 Minimum-Phase Systems 

. . . . . . . . . . . . . . . . . . . .  60 


3.4  Spectral Factorization  . . . . . . . . . . . . . . . . . . . . . . . . . .  63 


c	
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

3

4 

4  State-Space  Models	

65


4.1 

Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  65


4.2 

Input-output  and  internal  descriptions  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  66


4.2.1	 An RLC circuit  . . . . . . . . . . . . . . . . . . . . . . . . . .  66 


4.2.2	 A delay-adder-gain system  . . . . . . . . . . . . . . . . . . . .  68


4.3  State-Space Models  . . . . . . . . . . . . . . . . . . . . . . . . . . . .  70


4.3.1	 DT State-Space Models  . . . . . . . . . . . . . . . . . . . . .  70


4.3.2	 CT State-Space Models  . . . . . . . . . . . . . . . . . . . . .  71


4.3.3	 Characteristics  of  State-Space Models 

.  .  .  .  .  .  .  .  .  .  .  .  .  72


4.4	 Equilibria  and  Linearization  of 

Nonlinear State-Space Models  . . . . . . . . . . . . . . . . . . . . . .  73 


4.4.1	 Equilibrium  . . . . . . . . . . . . . . . . . . . . . . . . . . . .  74 


4.4.2	 Linearization  . . . . . . . . . . . . . . . . . . . . . . . . . . .  75


4.5  State-Space Models  from  Input–Output Models  .  .  .  .  .  .  .  .  .  .  .  .  80


4.5.1	 Determining  a  state-space  model  from  an  impulse  response

or transfer function  . . . . . . . . . . . . . . . . . . . . . . . .  80 


4.5.2	 Determining  a  state-space  model  from  an  input–output  dif­

. . . . . . . . . . . . . . . . . . . . . . . . .  83 

ference equation 

5  Properties  of  LTI  State-Space  Models	

85


5.1 

Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  85 


5.2  The  Zero-Input  Response  and Modal  Representation  .  .  .  .  .  .  .  .  .  85


5.2.1	 Modal representation of the ZIR  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  87


5.2.2	 Asymptotic stability  . . . . . . . . . . . . . . . . . . . . . . .  89


5.3  Coordinate Transformations  . . . . . . . . . . . . . . . . . . . . . . .  89


5.3.1	 Transformation  to Modal  Coordinates  .  .  .  .  .  .  .  .  .  .  .  .  .  90


5.4	 The Complete Response  . . . . . . . . . . . . . . . . . . . . . . . . .  91


5.5	 Transfer  Function,  Hidden Modes,

. . . . . . . . . . . . . . . . . . . . . . .  92

Reachability, Observability 

6  State  Observers  and  State  Feedback	

101


6.1  Plant and Model  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  101


6.2  State  Estimation  by  Real-Time  Simulation .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  102


6.3  The State Observer  . . . . . . . . . . . . . . . . . . . . . . . . . . . .  103 


c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

5 

6.4  State Feedback Control 

. . . . . . . . . . . . . . . . . . . . . . . . .  108


6.4.1  Proof  of  Eigenvalue  Placement  Results  .  .  .  .  .  .  .  .  .  .  .  .  .  116


6.5  Observer-Based Feedback Control  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  117


7  Probabilistic  Models	

121 


7.1  The Basic Probability Model 

. . . . . . . . . . . . . . . . . . . . . .  121


7.2	 Conditional  Probability,  Bayes’  Rule,  and  Independence  .  .  .  .  .  .  .  122


7.3	 Random Variables 

. . . . . . . . . . . . . . . . . . . . . . . . . . . .  124 


7.4	 Cumulative Distribution, Probability Density,  and Probability Mass

Function For Random Variables  . .  . .  . . .  . .  . .  .  . .  . .  . . .  . .  125 


7.5	 Jointly Distributed Random Variables  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  127


7.6	 Expectations, Moments and Variance  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  129


7.7	 Correlation  and  Covariance  for  Bivariate  Random  Variables  .  .  .  .  .  132


7.8	 A Vector-Space Picture for Correlation Properties of Random Variables137 

8  Estimation  with  Minimum  Mean  Square  Error	

139 


8.1  Estimation  of  a  Continuous  Random  Variable  .  .  .  .  .  .  .  .  .  .  .  .  .  140


8.2  From Estimates to an Estimator 

. . . . . . . . . . . . . . . . . . . .  145


8.2.1  Orthogonality  . . . . . . . . . . . . . . . . . . . . . . . . . . .  150 


8.3  Linear Minimum Mean  Square  Error  Estimation 

.  .  .  .  .  .  .  .  .  .  .  150


9  Random  Processes	

161


9.1  Deﬁnition  and  examples  of  a  random  process 

.  .  .  .  .  .  .  .  .  .  .  .  .  161


9.2  Strict-Sense Stationarity  . . . . . . . . . . . . . . . . . . . . . . . . .  166 


9.3  Wide-Sense Stationarity  . . . . . . . . . . . . . . . . . . . . . . . . .  167 


9.3.1  Some Properties of WSS Correlation  and Covariance Functions168 

9.4  Summary of Deﬁnitions and Notation 

.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  169


9.5  Further Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  170


9.6  Ergodicity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  172


9.7  Linear Estimation of Random Processes  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  173


9.7.1  Linear Prediction  . . . . . . . . . . . . . . . . . . . . . . . . .  174 


9.7.2  Linear FIR Filtering  . . . . . . . . . . . . . . . . . . . . . . .  175


9.8  The Eﬀect of LTI Systems on WSS Processes  .  .  .  .  .  .  .  .  .  .  .  .  .  176


c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6 

10  Power  Spectral  Density 

183


10.1  Expected  Instantaneous  Power  and  Power  Spectral  Density 

.  .  .  .  .  183


10.2  Einstein-Wiener-Khinchin Theorem on Expected Time-Averaged Power185 

10.2.1  System  Identiﬁcation  Using  Random  Processes  as  Input  .  .  .  186


10.2.2  Invoking Ergodicity 

. . . . . . . . . . . . . . . . . . . . . . .  187


10.2.3  Modeling  Filters  and Whitening  Filters 

.  .  .  .  .  .  .  .  .  .  .  .  188


10.3  Sampling  of  Bandlimited  Random  Processes  .  .  .  .  .  .  .  .  .  .  .  .  .  .  190


11 Wiener  Filtering 

195


11.1 Noncausal DT Wiener Filter 

. . . . . . . . . . . . . . . . . . . . . .  196


11.2  Noncausal CT Wiener Filter  . .  . . .  . .  . .  .  . .  . .  . . .  . .  . . .  .  203


11.2.1  Orthogonality Property 

. . . . . . . . . . . . . . . . . . . . .  205


11.3 Causal Wiener Filtering  . . . . . . . . . . . . . . . . . . . . . . . . .  205


11.3.1  Dealing with Nonzero Means 

. . . . . . . . . . . . . . . . . .  209


12  Pulse Amplitude Modulation (PAM), Quadrature Amplitude Mod­
211 

ulation  (QAM) 

12.1 Pulse Amplitude Modulation 

. . . . . . . . . . . . . . . . . . . . . .  211


12.1.1  The Transmitted Signal  . . . . . . . . . . . . . . . . . . . . .  211


12.1.2  The Received Signal  . . . . . . . . . . . . . . . . . . . . . . .  213 


12.1.3  Frequency-Domain  Characterizations  .  .  .  .  .  .  .  .  .  .  .  .  .  .  213


12.1.4  Inter-Symbol  Interference  at  the  Receiver  .  .  .  .  .  .  .  .  .  .  .  215


12.2 Nyquist Pulses 

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  217 


12.3  Carrier Transmission  .  .  . .  . .  .  . .  . .  . .  .  . .  . .  .  . .  . .  .  . .  .  219


12.3.1  FSK  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  220 


12.3.2  PSK  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  220


12.3.3  QAM 

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  222


13  Hypothesis  Testing 

227


13.1  Binary  Pulse  Amplitude Modulation  in  Noise  .  .  .  .  .  .  .  .  .  .  .  .  .  227


13.2  Binary Hypothesis Testing  .  . .  . . .  . .  . .  .  . .  . .  . . .  . .  . . .  .  229


13.2.1  Deciding  with Minimum  Probability  of  Error:  The MAP  Rule 230


13.2.2  Understanding  Pe :  False  Alarm, Miss  and  Detection  .  .  .  .  .  231


c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 



7 

13.2.3	 The Likelihood Ratio Test  . . . . . . . . . . . . . . . . . . . .  233


13.2.4	 Other Scenarios  . . . . . . . . . . . . . . . . . . . . . . . . . .  233 


13.2.5	 Neyman-Pearson  Detection  and  Receiver  Operating  Charac­

teristics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  234


13.3  Minimum Risk Decisions  .  . .  .  . .  . .  .  . .  . .  . . .  . .  . .  .  . .  . .  238 


13.4  Hypothesis  Testing  in  Coded  Digital  Communication  .  .  .  .  .  .  .  .  .  240


13.4.1	 Optimal  a  priori  Decision  . . . . . . . . . . . . . . . . . . . .  241


13.4.2	 The Transmission Model  . . . . . . . . . . . . . . . . . . . . .  242


13.4.3	 Optimal  a  posteriori  Decision  .  . .  .  . .  . .  .  . .  . .  . .  .  . .  243 


14  Signal  Detection	

247


14.1  Signal Detection as Hypothesis Testing  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  247


14.2  Optimal  Detection  in White  Gaussian  Noise  .  .  .  .  .  .  .  .  .  .  .  .  .  .  247


14.2.1	 Matched Filtering 

. . . . . . . . . . . . . . . . . . . . . . . .  250 


14.2.2	 Signal Classiﬁcation  . . . . . . . . . . . . . . . . . . . . . . .  251


14.3  A General Detector Structure  . . .  . .  . . .  . .  . .  .  . .  . .  . . .  . .  251 


14.3.1	 Pulse Detection in White Noise  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  252


14.3.2	 Maximizing SNR  . . . . . . . . . . . . . . . . . . . . . . . . .  255


14.3.3	 Continuous-Time Matched  Filters 

.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  256


14.3.4	 Pulse Detection in Colored Noise  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  259


°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

8 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

2 

Signals  and  Systems 

This text assumes a basic background in the representation of linear, time-invariant 
systems and the associated continuous-time and discrete-time signals,  through con­
volution,  Fourier  analysis,  Laplace  transforms  and  Z -transforms.  In  this  chapter 
we brieﬂy  summarize  and  review  this  assumed background,  in part  to  establish no­
tation  that we will be using  throughout  the  text, and also as a convenient  reference 
for the topics in the later chapters.  We follow closely the notation, style and presen­
tation  in  Signals  and  Systems,  Oppenheim  and Willsky  with  Nawab,  2nd  Edition, 
Prentice  Hall,  1997. 

2.1  SIGNALS,  SYSTEMS,  MODELS,  PROPERTIES 

Throughout  this  text we  will  be  considering  various  classes  of  signals  and  systems, 
developing  models  for  them  and  studying  their  properties. 

for  us  will  generally  be  real  or  complex  functions  of  some  independent 
Signals 
variables  (almost  always  time  and/or  a  variable  denoting  the  outcome  of  a  proba­
bilistic  experiment,  for  the  situations  we  shall  be  studying).  Signals  can  be: 

• 
1-dimensional  or multi-dimensional 
•  continuous-time  (CT)  or  discrete-time  (DT) 
•  deterministic  or  stochastic  (random,  probabilistic) 
Thus,  a  DT  deterministic  time-signal  may  be  denoted  by  a  function  x[n]  of  the 
integer  time  (or  clock  or  counting)  variable  n. 

Systems  are  collections  of  software  or  hardware  elements,  components,  subsys­
tems.  A  system  can  be  viewed  as mapping  a  set  of  input  signals  to  a  set  of  output 
or  response  signals.  A  more  general  view  is  that  a  system  is  an  entity  imposing 
constraints  on  a  designated  set  of  signals,  where  the  signals  are  not  necessarily  la­
beled  as  inputs  or  outputs.  Any  speciﬁc  set  of  signals  that  satisﬁes  the  constraints 
is  termed  a  behavior  of  the  system. 

Models  are  (usually  approximate)  mathematical  or  software  or  hardware  or  lin­
guistic  or  other  representations  of  the  constraints  imposed  on  a  designated  set  of 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

21

22  Chapter  2 

Signals  and  Systems 

signals  by  a  system.  A  model  is  itself  a  system,  because  it  imposes  constraints  on 
the  set of  signals  represented  in  the model,  so we often use  the words “system” and 
“model”  interchangeably,  although  it  can  sometimes  be  important  to  preserve  the 
distinction  between  something  truly  physical  and  our  representations  of  it  mathe­
matically or in a computer simulation.  We can thus talk of the behavior of a model. 

A mapping model of a system comprises the following:  a set of input signals {xi (t)}, 
each  of  which  can  vary  within  some  speciﬁed  range  of  possibilities;  similarly,  a  set 
of  output  signals {yj (t)},  each  of which  can vary;  and  a description  of  the mapping 
that  uniquely  deﬁnes  the  output  signals  as  a  function  of  the  input  signals.  As  an 
example,  consider  the  following  single-input,  single-output  system: 

x(t) 

�

T { · } 

� 

y(t) = x(t − t0 )

FIGURE  2.1  Name-Mapping Model 

Given  the  input  x(t)  and  the mapping  T { · },  the  output  y(t)  is  unique,  and  in  this 
example  equals  the  input  delayed  by  t0 . 
A behavioral model for a set of signals {wi (t)} comprises a  listing of the constraints 
that  the  wi (t)  must  satisfy.  The  constraints  on  the  voltages  across  and  currents 
through the components in an electrical circuit,  for example, are speciﬁed by Kirch­
hoﬀ ’s  laws,  and  the  deﬁning  equations  of  the  components.  There  can  be  inﬁnitely 
many  combinations  of  voltages  and  currents  that  will  satisfy  these  constraints. 

2.1.1  System/Model  Properties 

For  a  system  or  model  speciﬁed  as  a  mapping,  we  have  the  following  deﬁnitions 
of  various  properties,  all  of  which  we  assume  are  familiar.  They  are  stated  here 
for  the  DT  case  but  easily  modiﬁed  for  the  CT  case.  (We  also  assume  a  single 
input  signal  and  a  single  output  signal  in  our  mathematical  representation  of  the 
deﬁnitions  below,  for  notational  convenience.) 

• 

• 

Memoryless  or  Algebraic  or Non-Dynamic:  The  outputs  at  any  instant 
do  not  depend  on  values  of  the  inputs  at  any  other  instant:  y [n0 ] = T {x[n0 ]}
for  all  n0 . 

Linear:  The response to an arbitrary linear combination (or “superposition”) 
of  inputs  signals  is  always  the  same  linear  combination  of  the  individual  re­
sponses  to  these  signals:  T {axA [n] + bxB [n]} =  aT {xA [n]} + bT {xB [n]},  for 
all  xA ,  xB ,  a  and  b. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.1 

Signals,  Systems,  Models,  Properties  23 

x(t) 

+ 
− 

�y(t) 

FIGURE  2.2  RLC  Circuit 

•	 Time-Invariant:  The  response  to  an  arbitrarily  translated  set  of  inputs  is 
always  the  response  to  the  original  set,  but  translated  by  the  same  amount: 
y [n]  then  x[n − n0 ] 
→	
y [n − n0 ]  for  all  x  and  n0 .
→ 
If  x[n] 
•	 Linear  and Time-Invariant  (LTI): The system, model or mapping  is both 
linear  and  time-invariant. 
•	 Causal:  The  output  at  any  instant  does  not  depend  on  future  inputs:  for  all 
n0 ,  y [n0 ]  does  not  depend  on  x[n]  for  n > n0 .  Said  another  way,  if  xb[n], yb[n] 
denotes another  input-output pair of the  system, with xb[n] = x[n]  for n ≤ n0 , 
then  it  must  be  also  true  that  yb[n] =  y [n]  for  n  ≤  n0 .  (Here  n0  is  arbitrary 
but  ﬁxed.) 
•	 BIBO  Stable:  The response to a bounded input is always bounded:  |x[n]| ≤
Mx  < ∞  for  all  n  implies  that  |y [n]| ≤ My  < ∞  for  all  n. 

EXAMPLE  2.1 

System  Properties 

Consider  the  system  with  input  x[n]  and  output  y [n]  deﬁned  by  the  relationship 

y [n] = x[4n + 1] 	

(2.1) 

We  would  like  to  determine  whether  or  not  the  system  has  each  of  the  following 
properties:  memoryless,  linear,  time-invariant,  causal,  and  BIBO  stable. 

memoryless:  a  simple  counter  example  suﬃces.  For  example,  y [0]  =  x[1],  i.e.  the 
output  at  n =  0  depends  on  input  values  at  times  other  than  at  n =  0.  Therefore 
it  is  not memoryless. 

linear:  To  check  for  linearity,  we  consider  two  diﬀerent  inputs,  xA [n]  and  xB [n], 
and  compare  the  output  of  their  linear  combination  to  the  linear  combination  of 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

24  Chapter  2 

Signals  and  Systems 

their  outputs. 

xA [n] 
xB [n] 
xC [n] = (axA [n] + bxB [n]) 

→ 
→ 
→ 
If  yC [n] = ayA [n] + byB [n],  then  the  system  is  linear.  This  clearly  happens  in  this 
case. 

xA [4n + 1] = yA [n]
xB [4n + 1] = yB [n]
(axA [4n + 1] + bxB [4n + 1]) = yC [n]

time-invariant:  To  check  for  time-invariance,  we  need  to  compare  the  output  due 
to  a  time-shifted  version  of  x[n]  to  the  time-shifted  version  of  the  output  due  to 
x[n]. 

x[n] 
xB [n] = x[n + n0 ] 

→ 
→ 
We now need to compare y [n] time-shifted by n0  (i.e.  y [n + n0 ]) to yB [n].  If they’re 
not  equal,  then  the  system  is  not  time-invariant. 

x[4n + 1] = y [n]
x[4n + n0  + 1] = yB [n]

y [n + n0 ] =  x[4n + 4n0  + 1] 
yB [n] =  x[4n + n0  + 1] 

but 

Consequently, the system is not time-invariant.  To illustrate with a speciﬁc counter­
example,  suppose  that  x[n]  is  an  impulse,  δ [n],  at  n =  0.  In  this  case,  the  output, 
yδ [n],  would  be  δ [4n + 1],  which  is  zero  for  all  values  of  n,  and  y [n + n0 ]  would 
likewise  always  be  zero.  However,  if  we  consider  x[n + n0 ] = δ [n + n0 ],  the  output 
will  be  δ [4n + 1 + n0 ],  which  for  n0  = 3  will  be  one  at  n = −4  and  zero  otherwise. 
causal:  Since  the  output  at  n  =  0  is  the  input  value  at  n  =  1,  the  system  is  not 
causal. 

BIBO  stable:  Since  y [n] =  x[4n + 1] and  the maximum value  for all n of x[n] and 
|
|
|
|
x[4n + 1]  is  the  same,  the  system  is  BIBO  stable. 

2.2  LINEAR,  TIME-INVARIANT  SYSTEMS 

2.2.1 

Impulse-Response  Representation  of  LTI  Systems 

Linear,  time-invariant  (LTI)  systems  form  the  basis  for  engineering  design  in many 
situations.  They have the advantage that there is a rich and well-established theory 
for analysis and design of  this class of  systems.  Furthermore,  in many  systems  that 
are  nonlinear,  small  deviations  from  some  nominal  steady  operation  are  approxi­
mately governed by LTI models,  so  the  tools of LTI  system analysis and design  can 
be  applied  incrementally  around  a  nominal  operating  condition. 

A  very  general  way  of  representing  an  LTI  mapping  from  an  input  signal  x  to 
an  output  signal  y  is  through  convolution  of  the  input  with  the  system  impulse 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.2 

Linear,  Time-Invariant  Systems  25 

∞ 

y(t) = 

response.  In  CT  the  relationship  is 
Z 
x(τ )h(t − τ )dτ 
−∞ 
where  h(t)  is  the  unit  impulse  response  of  the  system.  In  DT,  we  have 
y [n] =  X 
∞
x[k ] h[n − k ] 
k=−∞ 
where  h[n]  is  the  unit  sample  (or  unit  “impulse”)  response  of  the  system. 

(2.2) 

(2.3) 

A  common  notation  for  the  convolution  integral  in  (2.2)  or  the  convolution  sum  in 
(2.3)  is  as 

y(t) = x(t) ∗ h(t) 
y [n] = x[n] ∗ h[n] 
While  this  notation  can  be  convenient,  it  can  also  easily  lead  to  misinterpretation 
if  not  well  understood. 

(2.4) 
(2.5) 

The  characterization  of  LTI  systems  through  the  convolution  is  obtained  by  repre­
senting  the  input  signal  as  a  superposition  of  weighted  impulses.  In  the  DT  case, 
suppose  we  are  given  an  LTI  mapping  whose  impulse  response  is  h[n],  i.e.,  when 
its  input  is  the unit  sample or unit “impulse”  function δ [n],  its output  is h[n].  Now 
a  general  input  x[n]  can  be  assembled  as  a  sum  of  scaled  and  shifted  impulses,  as 
follows: 
x[n] =  X 
∞
x[k ] δ [n − k ] 
k=−∞ 
The  response  y [n]  to  this  input,  by  linearity  and  time-invariance,  is  the  sum  of 
the  similarly  scaled  and  shifted  impulse  responses,  and  is  therefore  given  by  (2.3). 
What  linearity  and  time-invariance  have  allowed  us  to  do  is  write  the  response  to 
a  general  input  in  terms  of  the  response  to  a  special  input.  A  similar  derivation 
holds  for  the  CT  case. 

(2.6) 

It  may  seem  that  the  preceding  derivation  shows  all  LTI  mappings  from  an  in­
put  signal  to  an  output  signal  can  be  represented  via  a  convolution  relationship. 
However,  the  use  of  inﬁnite  integrals  or  sums  like  those  in  (2.2),  (2.3)  and  (2.6) 
actually  involves  some  assumptions  about  the  corresponding  mapping.  We  make 
no  attempt  here  to  elaborate  on  these  assumptions.  Nevertheless,  it  is  not  hard 
to  ﬁnd  “pathological”  examples  of  LTI  mappings  —  not  signiﬁcant  for  us  in  this 
course,  or  indeed  in most  engineering models — where  the convolution  relationship 
does  not  hold  because  these  assumptions  are  violated. 

It  follows  from  (2.2)  and  (2.3)  that  a  necessary  and  suﬃcient  condition  for  an  LTI 
system  to  be  BIBO  stable  is  that  the  impulse  response  be  absolutely  integrable 
(CT)  or  absolutely  summable  (DT),  i.e., 
Z 
∞ 
−∞  |h(t)|dt < ∞ 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

BIBO  stable  (CT)  ⇐⇒ 

26  Chapter  2 

Signals  and  Systems 

BIBO  stable  (DT) 

X 
∞
| < ∞ 
|
h[n]
n=−∞ 
It  also  follows  from  (2.2)  and  (2.3)  that  a  necessary  and  suﬃcient  condition  for  an 
LTI  system  to  be  causal  is  that  the  impulse  response  be  zero  for  t < 0  (CT)  or  for 
n < 0  (DT) 

⇐⇒ 

2.2.2  Eigenfunction  and  Transform  Representation  of  LTI  Systems 

Exponentials  are  eigenfunctions  of  LTI  mappings,  i.e.,  when  the  input  is  an  expo­
nential  for all  time, which we  refer  to as an “everlasting” exponential,  the output  is 
simply  a  scaled  version  of  the  input,  so  computing  the  response  to  an  exponential 
reduces  to  just multiplying  by  the  appropriate  scale  factor.  Speciﬁcally,  in  the  CT 
case,  suppose 

x(t) = e s0 t 

(2.7) 

for  some  possibly  complex  value  s0  (termed  the  complex  frequency).  Then  from 
(2.2) 

= 

y(t) = h(t) ∗ x(t) 
Z 
∞ 
h(τ )x(t − τ )dτ 
= 
−∞Z 
∞ 
h(τ )e s0 (t−τ )dτ 
−∞ 
= H (s0 )e s0 t 
Z 
−∞ 
provided  the  above  integral  has  a  ﬁnite  value  for  s = s0  (otherwise  the  response  to 
the exponential is not well deﬁned).  Note that this integral is precisely the bilateral 
Laplace  transform  of  the  impulse  response,  or  the  transfer  function  of  the  system, 
and  the  (interior of  the)  set of values of s  for which  the above  integral  takes a ﬁnite 
value  constitutes  the  region  of  convergence  (ROC)  of  the  transform. 

h(τ )e−sτ dτ 

where 

∞ 

H (s) = 

(2.8) 

(2.9) 

From  the  preceding  discussion,  one  can  recognize  what  special  property  of  the 
everlasting  exponential  causes  it  to  be  an  eigenfunction  of  an  LTI  system:  it  is 
the  fact  that  time-shifting  an  everlasting  exponential  produces  the  same  result  as 
scaling  it  by  a  constant  factor.  In  contrast,  the  one-sided  exponential  es0 tu(t) — 
where  u(t)  denotes  the  unit  step  —  is  in  general  not  an  eigenfunction  of  an  LTI 
mapping:  time-shifting  a  one-sided  exponential  does  not  produce  the  same  result 
as  scaling  this  exponential. 

When x(t) = ejωt , corresponding to having s0  take the purely imaginary value jω  in 
(2.7), the input is bounded for all positive and negative time, and the corresponding 
output  is 

y(t) = H (jω)ejωt 

(2.10) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Linear,  Time-Invariant  Systems  27 

where 

EXAMPLE  2.2 

Section  2.2 
Z 
−∞ 
Eigenfunctions  of  LTI  Systems 

H (jω) = 

∞ 

h(t)e−jωt dt 

(2.11) 

While  as  demonstrated  above,  the  everlasting  complex  exponential,  ejωt ,  is  an 
eigenfunction  of  any  stable  LTI  system,  it  is  important  to  recognize  that  ejωtu(t) 
is  not.  Consider,  as  a  simple  example,  a  time  delay,  i.e. 

y(t) = x(t − t0 ) 
The  output  due  to  the  input  ejωtu(t)  is 

(2.12) 

e−jωt0  +jωtu(t − t0 )
e 
This is not a simple scaling of the input, so ejωtu(t) is not in general an eigenfunction 
of  LTI  systems. 

The  function  H (jω)  in  (2.10)  is  the  system  frequency  response,  and  is  also  the 
continuous-time  Fourier  transform  (CTFT)  of  the  impulse  response.  The  integral 
that  deﬁnes  the  CTFT  has  a  ﬁnite  value  (and  can  be  shown  to  be  a  continuous 
function  of  ω)  if  h(t)  is  absolutely  integrable,  i.e.  provided 
Z  +∞ 
|h(t)| dt < ∞
−∞ 
We have noted that this condition is equivalent to the system being bounded-input, 
bounded-output  (BIBO)  stable.  The CTFT  can also be deﬁned  for  signals  that are 
not  absolutely  integrable,  e.g.,  for  h(t)  =  (sin t)/t  whose  CTFT  is  a  rectangle  in 
the  frequency  domain,  but  we  defer  examination  of  conditions  for  existence  of  the 
CTFT. 

We  can  similarly  examine  the  eigenfunction  property  in  the  DT  case.  A  DT  ever­
lasting  “exponential”  is  a  geometric  sequence  or  signal  of  the  form 

n 
x[n] = z0 

(2.13) 

for  some  possibly  complex  z0  (termed  the  complex  frequency).  With  this  DT  ex­
ponential  input,  the  output  of  a  convolution mapping  is  (by  a  simple  computation 
that  is  analogous  to  what  we  showed  above  for  the  CT  case) 

where 

n 
y [n] = h[n] ∗ x[n] = H (z0 )z0 
H (z ) =  X 
∞
h[k ]z−k 
k=−∞ 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(2.14) 

(2.15) 

28  Chapter  2 

Signals  and  Systems 

provided  the  above  sum  has  a  ﬁnite  value  when  z  =  z0 .  Note  that  this  sum  is 
precisely  the  bilateral  Z -transform  of  the  impulse  response,  and  the  (interior  of 
the)  set  of  values  of  z  for  which  the  sum  takes  a  ﬁnite  value  constitutes  the  ROC 
nu[n]  is  not  in 
of  the  Z -transform.  As  in  the  CT  case,  the  one-sided  exponential  z0 
general  an  eigenfunction. 
Again,  an  important  case  is  when  x[n] = (ejΩ )n  =  ejΩn ,  corresponding  to  z0  in 
(2.13)  having  unit  magnitude  and  taking  the  value  ejΩ ,  where  Ω  —  the  (real) 
“frequency”  —  denotes  the  angular  position  (in  radians)  around  the  unit  circle  in 
the  z -plane.  Such  an  x[n]  is  bounded  for  all  positive  and  negative  time.  Although 
we  use  a  diﬀerent  symbol,  Ω,  for  frequency  in  the  DT  case,  to  distinguish  it  from 
the  frequency ω  in  the CT  case,  it  is  not  unusual  in  the  literature  to  ﬁnd ω  used  in 
both  CT  and  DT  cases  for  notational  convenience.  The  corresponding  output  is 
y [n] = H (ejΩ )ejΩn 
H (ejΩ ) =  X 
∞
n=−∞ 
The  function  H (ejΩ )  in  (2.17)  is  the  frequency  response  of  the  DT  system,  and  is 
also the discrete-time Fourier transform (DTFT) of the  impulse response.  The sum 
that  deﬁnes  the  DTFT  has  a  ﬁnite  value  (and  can  be  shown  to  be  a  continuous 
function  of  Ω)  if  h[n]  is  absolutely  summable,  i.e.,  provided 
∞X 
n=−∞ 
We noted that this condition is equivalent to the system being BIBO stable.  As with 
the CTFT,  the DTFT can be deﬁned  for  signals  that are not absolutely  summable; 
we  will  elaborate  on  this  later. 

| h[n] | < ∞ 

h[n]e−jΩn 

where 

(2.16) 

(2.17) 

(2.18) 

Note  from  (2.17)  that  the  frequency  response  for  DT  systems  is  always  periodic, 
with  period  2π .  The  “high-frequency”  response  is  found  in  the  vicinity  of Ω = ±π , 
which  is  consistent  with  the  fact  that  the  input  signal  e±jπn  = (−1)n  is  the  most 
rapidly  varying  DT  signal  that  one  can  have. 

When  the  input  of  an  LTI  system  can  be  expressed  as  a  linear  combination  of 
bounded  eigenfunctions,  for  instance  (in  the  CT  case), 
x(t) = X 
jωℓ t 
aℓ e
ℓ 
then,  by  linearity,  the  output  is  the  same  linear  combination  of  the  responses  to 
the  individual  exponentials.  By  the  eigenfunction  property  of  exponentials  in  LTI 
systems,  the  response  to  each  exponential  involves  only  scaling  by  the  system’s 
frequency  response.  Thus 
y(t) = X 
jωℓ t 
aℓH (jωℓ )e
ℓ 
Similar  expressions  can  be  written  for  the  DT  case. 

(2.19) 

(2.20) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

2.2.3  Fourier  Transforms 

Section  2.2 

Linear,  Time-Invariant  Systems  29 

∞ 

x(t) = 

X (jω) = 

(synthesis) 

jωtdω 
X (jω) e

A broad class of input signals can be represented as linear combinations of bounded 
exponentials,  through  the  Fourier  transform.  The  synthesis/analysis  formulas  for 
the  CTFT  are 
1  Z 
2π 
−∞
Z 
∞ 
x(t) e−jωtdt 
−∞ 
Note  that  (2.21)  expresses  x(t)  as  a  linear  combination  of  exponentials —  but  this 
weighted  combination  involves  a  continuum  of  exponentials,  rather  than  a  ﬁnite  or 
countable  number.  If  this  signal  x(t)  is  the  input  to  an  LTI  system  with  frequency 
response  H (jω),  then  by  linearity  and  the  eigenfunction  property  of  exponentials 
the output is the same weighted combination of the responses to these exponentials, 
so 
1  Z 
2π 
−∞ 
By  viewing  this  equation  as  a  CTFT  synthesis  equation,  it  follows  that  the  CTFT 
of  y(t)  is 

jωt dω 
H (jω)X (jω) e

(2.21) 

(2.22) 

(analysis) 

y(t) = 

∞ 

(2.23) 

Y (jω) = H (jω)X (jω) 

(2.24) 

Correspondingly,  the  convolution  relationship  (2.2)  in  the  time  domain  becomes 
multiplication in the transform domain.  Thus, to ﬁnd the response Y  at a particular 
frequency  point,  we  only  need  to  know  the  input  X  at  that  single  frequency,  and 
the  frequency  response  of  the  system  at  that  frequency.  This  simple  fact  serves,  in 
large  measure,  to  explain  why  the  frequency  domain  is  virtually  indispensable  in 
the  analysis  of  LTI  systems. 

X (ejΩ ) ejΩn dΩ  (synthesis) 

The  corresponding  DTFT  synthesis/analysis  pair  is  deﬁned  by 
1  Z 
x[n] = 
2π  <2π> 
X (ejΩ ) =  X 
∞
x[n] e−jΩn  (analysis) 
n=−∞ 
where the notation < 2π > on the integral in the synthesis formula denotes integra­
tion over any contiguous interval of length 2π , since the DTFT is always periodic in 
Ω with period  2π ,  a  simple  consequence  of  the  fact  that  ejΩ  is periodic with period 
2π .  Note  that  (2.25)  expresses  x[n]  as  a  weighted  combination  of  a  continuum  of 
exponentials. 

(2.25) 

(2.26) 

As  in  the  CT  case,  it  is  straightforward  to  show  that  if  x[n]  is  the  input  to  an  LTI 
mapping,  then  the  output  y [n]  has  DTFT 

Y (ejΩ ) = H (ejΩ )X (ejΩ ) 

(2.27) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

30  Chapter  2 

Signals  and  Systems 

2.3  DETERMINISTIC  SIGNALS  AND  THEIR  FOURIER  TRANSFORMS 

In  this section we  review  the DTFT of deterministic DT signals  in more detail, and 
highlight  the classes of  signals  that can be guaranteed  to have well-deﬁned DTFTs. 
We  shall  also  devote  some  attention  to  the  energy  density  spectrum  of  signals  that 
have  DTFTs.  The  section  will  bring  out  aspects  of  the  DTFT  that  may  not  have 
been  emphasized  in your  earlier  signals and  systems  course.  A  similar development 
can  be  carried  out  for  CTFTs. 

2.3.1  Signal  Classes  and  their  Fourier  Transforms 

The  DTFT  synthesis  and  analysis  pair  in  (2.25)  and  (2.26)  hold  for  at  least  the 
three  large  classes  of  DT  signals  described  below. 

Finite-Action  Signals.  Finite-action  signals,  which  are  also  called  absolutely 
summable  signals  or  ℓ1  (“ell-one”)  signals,  are  deﬁned  by  the  condition 
∞X  ¯¯¯x[k ]¯¯¯ < ∞ 
k=−∞ 
The  sum  on  the  left  is  called  the  ‘action’  of  the  signal.  For  these  ℓ1  signals,  the 
inﬁnite  sum  that  deﬁnes  the  DTFT  is  well  behaved  and  the  DTFT  can  be  shown 
to  be  a  continuous  function  for  all  Ω  (so,  in  particular,  the  values  at  Ω = +π  and 
Ω =  −π  are  well-deﬁned  and  equal  to  each  other  —  which  is  often  not  the  case 
when  signals  are  not  ℓ1 ). 

(2.28) 

(2.29) 

Finite-Energy Signals.  Finite-energy signals, which are also called square summable 
or  ℓ2  (“ell-two”)  signals,  are  deﬁned  by  the  condition 
∞X  ¯¯¯x[k ]¯¯¯  < ∞ 
2
k=−∞ 
The  sum  on  the  left  is  called  the  ‘energy’  of  the  signal. 
In discrete-time, an absolutely summable (i.e., ℓ1 ) signal is always square summable 
(i.e.,  ℓ2 ).  (In  continuous-time,  the  story  is  more  complicated:  an  absolutely  inte­
grable signal need not be square  integrable,  e.g.,  consider x(t) = 1/√t  for 0 < t ≤ 1 
and  x(t)  =  0  elsewhere;  the  source  of  the  problem  here  is  that  the  signal  is  not 
bounded.)  However,  the  reverse  is  not  true.  For  example,  consider  the  signal 
(sin Ωcn)/πn  for 0 < Ωc  < π , with  the value at n = 0  taken  to be Ωc /π ,  or consider 
the  signal  (1/n)u[n − 1],  both  of  which  are  ℓ2  but  not  ℓ1 .  If  x[n]  is  such  a  signal, 
its  DTFT  X (ejΩ )  can  be  thought  of  as  the  limit  for  N  → ∞  of  the  quantity 
XN (ejΩ ) =  X 
N
x[k ]e−jΩk 
(2.30) 
k=−N 
and  the  resulting  limit  will  typically  have  discontinuities  at  some  values  of  Ω.  For 
instance,  the  transform  of  (sin Ωcn)/πn  has  discontinuities  at  Ω = ±Ωc . 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.3 

Deterministic  Signals  and  their  Fourier  Transforms  31 

Signals  of  Slow  Growth.  Signals  of  ‘slow’  growth  are  signals whose magnitude 
grows  no  faster  than  polynomially  with  the  time  index,  e.g.,  x[n] = n  for  all  n.  In 
this  case  XN (ejΩ )  in  (2.30)  does  not  converge  in  the  usual  sense,  but  the  DTFT 
still  exists  as  a  generalized  (or  singularity)  function;  e.g.,  if  x[n] = 1  for  all  n,  then 
X (ejΩ ) = 2πδ (Ω)  for  |Ω| ≤ π . 
Within  the  class of  signals of  slow growth,  those of most  interest  to us are bounded 
)  signals: 
(or  ℓ
∞
¯¯¯x[k ]¯¯¯ ≤ M < ∞ 
i.e.,  signals  whose  amplitude  has  a  ﬁxed  and  ﬁnite  bound  for  all  time.  Bounded 
everlasting  exponentials  of  the  form  ejΩ0 n ,  for  instance,  play  a  key  role  in  Fourier 
transform  theory.  Such  signals  need  not  have  ﬁnite  energy,  but  will  have  ﬁnite 
average power over any time interval, where average power is deﬁned as total energy 
over  total  time. 

(2.31) 

(2.32) 

Similar  classes  of  signals  are  deﬁned  in  continuous-time.  Speciﬁcally,  ﬁnite-action 
(or  L1 )  signals  comprise  those  that  are  absolutely  integrable,  i.e., 
Z 
∞  ¯¯¯x(t)¯¯¯dt < ∞ 
−∞ 
Finite-energy  (or  L2 )  signals  comprise  those  that  are  square  summable,  i.e., 
Z 
∞  ¯¯¯x(t)¯¯¯  < ∞ 
2
−∞ 
And  signals  of  slow  growth  are  ones  for  which  the magnitude  grows  no  faster  than 
polynomially  with  time.  Bounded  (or  L )  continuous-time  signals  are  those  for 
∞
which  the  magnitude  never  exceeds  a  ﬁnite  bound  M  (so  these  are  slow-growth 
signals as well).  These may again not have ﬁnite energy, but will have ﬁnite average 
power  over  any  time  interval. 

(2.33) 

In both continuous-time and discrete-time there are many  important Fourier trans­
form pairs and Fourier  transform properties developed and  tabulated  in basic  texts 
on signals and systems (see,  for example, Chapters 4 and 5 of Oppenheim and Will-
sky).  For  convenience,  we  include  here  a  brief  table  of  DTFT  pairs.  Other  pairs 
are  easily derived  from  these by applying various DTFT properties.  (Note  that  the 
δ ’s  in  the  left  column denote unit  samples, while  those  in  the  right  column  are unit 
impulses!) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

32  Chapter  2 

Signals  and  Systems 

DT  Signal 

←→ 

DTFT  for  − π < Ω ≤ π

1←→ 
δ [n]
δ [n − n0 ] ←→ e−jΩn0 
1  (for  all  n)
2πδ(Ω) 
←→ 
ejΩ0 n  (−π < Ω0  ≤ π)
2πδ(Ω − Ω0 )
←→ 
1 
a n u[n]  ,  a < 1
| |  ←→ 
1 − ae−jΩ 
1 
+ πδ (Ω) 
←→ 
u[n]
Ω 
½ 1 −
e−j
sin Ωcn 
Ωc  < Ω < Ωc 
−
1,
πn  ←→ 
0,  otherwise 
1,  −M  ≤ n ≤ M  ¾ 
sin[Ω(2M  + 1)/2] 
0,  otherwise 
sin(Ω/2) 

←→ 

In  general  it  is  important  and  useful  to  be  ﬂuent  in  deriving  and  utilizing  the 
main  transform  pairs  and  properties.  In  the  following  subsection  we  discuss  a 
particular  property,  Parseval’s  identity,  which  is  of  particular  signiﬁcance  in  our 
later  discussion. 

There are, of course, other classes of signals that are of interest to us in applications, 
for  instance  growing  one-sided  exponentials.  To  deal  with  such  signals,  we  utilize 
Z -transforms  in  discrete-time  and  Laplace  transforms  in  continuous-time. 

2.3.2  Parseval’s  Identity,  Energy  Spectral  Density,  Deterministic  Autocorrelation 

x[n]y∗ [n] = 

X (ejΩ )Y ∗ (ejΩ ) dΩ 

An  important property of the Fourier transform  is Parseval’s  identity for ℓ2  signals. 
For  discrete  time,  this  identity  takes  the  general  form 
1  Z
X 
∞
2π  <2π> 
n=−∞ 
and  for  continuous  time, 
1  Z 
Z 
2π
−∞ 
−∞ 
where  the  ∗  denotes  the  complex  conjugate.  Specializing  to  the  case  where  y [n] = 
x[n]  or  y(t) = x(t),  we  obtain 
1  Z
X 
∞
2π  <2π>  |X (ejΩ )| 2 dΩ 
n=−∞ 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

2 
|x[n]|  =

x(t)y∗ (t)dt  = 

X (jω)Y ∗ (jω) dω 

(2.35) 

∞ 

∞ 

(2.34) 

(2.36) 

Section  2.3 

Deterministic  Signals  and  their  Fourier  Transforms  33 

x[n] 

�  H (ejΩ ) 

�  y [n]

�Δ� 

H (ejΩ ) 
� 
1 

� Δ �

Ω0

� 
Ω

−Ω0 
FIGURE  2.3  Ideal  bandpass  ﬁlter. 
1  Z 
Z 
2π 
−∞ 
−∞ 
Parseval’s  identity  allows  us  to  evaluate  the  energy  of  a  signal  by  integrating  the 
squared  magnitude  of  its  transform.  What  the  identity  tells  us,  in  eﬀect,  is  that 
the  energy  of  a  signal  equals  the  energy  of  its  transform  (scaled  by  1/2π). 

|X (jω)|2 dω 

|x(t)|2  =

(2.37) 

∞ 

∞ 

The  real,  even,  nonnegative  function  of  Ω  deﬁned  by 
S xx (ejΩ ) =  |X (ejΩ )|2 

or 

S xx (jω) =  |X (jω)| 2 

(2.38) 

(2.39) 

is  referred  to  as  the  energy  spectral  density  (ESD),  because  it  describes  how  the 
energy  of  the  signal  is  distributed  over  frequency.  To  appreciate  this  claim  more 
concretely, for discrete-time, consider applying x[n] to the input of an ideal bandpass 
ﬁlter  of  frequency  response  H (ejΩ )  that  has  narrow  passbands  of  unit  gain  and 
width  Δ  centered  at  ±Ω0  as  indicated  in  Figure  2.3.  The  energy  of  the  output 
signal  must  then  be  the  energy  of  x[n]  that  is  contained  in  the  passbands  of  the 
ﬁlter.  To  calculate  the  energy  of  the  output  signal,  note  that  this  output  y [n]  has 
the  transform 

Y (ejΩ ) = H (ejΩ )X (ejΩ ) 

(2.40) 

Consequently  the  output  energy,  by  Parseval’s  identity,  is  given  by 
π  Z 
X 
∞
1 
<2π>  |Y (e
2
n=−∞ 
1  Z 
2π  passband 
Thus the energy of x[n] in any frequency band is given by integrating S xx (ejΩ ) over 
that  band  (and  scaling  by  1/2π).  In  other  words,  the  energy  density  of  x[n]  as  a 

|2 
y [n] = 
|

|2 dΩ
jΩ )

S xx (ejΩ ) dΩ 

(2.41) 

= 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

34  Chapter  2 

Signals  and  Systems 

function  of  Ω  is  S xx (Ω)/(2π)  per  radian.  An  exactly  analogous  discussion  can  be 
carried  out  for  continuous-time  signals. 

Since  the  ESD  S xx (ejΩ )  is  a  real  function  of  Ω,  an  alternate  notation  for  it  could 
perhaps  be  Exx (Ω),  for  instance.  However,  we  use  the  notation  S xx (ejΩ )  in  order 
to make  explicit  that  it  is  the  squared magnitude  of X (ejΩ )  and  also  the  fact  that 
the  ESD  for  a  DT  signal  is  periodic  with  period  2π . 

Given  the  role  of  the  magnitude  squared  of  the  Fourier  transform  in  Parseval’s 
identity,  it  is  interesting  to  consider what  signal  it  is  the Fourier  transform  of.  The 
answer  for  DT  follows  on  recognizing  that  with  x[n]  real-valued 
|X (ejΩ )|2  = X (ejΩ )X (e−jΩ ) 
(2.42) 
and  that  X (e−jΩ )  is  the  transform  of  the  time-reversed  signal,  x[−k ].  Thus,  since 
multiplication of  transforms  in  the  frequency domain  corresponds  to convolution of 
signals  in  the  time  domain,  we  have 
S xx (ejΩ ) =  |X (ejΩ )|2  ⇐⇒  x[k ] ∗ x[−k ] =  X 
∞
x[n + k ]x[n] = Rxx [k ] 
n=−∞ 
The function Rxx [k ] = x[k ] ∗x[−k ] is referred to as the deterministic autocorrelation 
function  of  the  signal  x[n],  and  we  have  just  established  that  the  transform  of  the 
deterministic  autocorrelation  function  is  the  energy  spectral  density  S xx (ejΩ ).  A 
basic  Fourier  transform  property  tells  us  that  Rxx [0] —  which  is  the  signal  energy 
P∞ 
x2 [n] — is the area under the Fourier transform of Rxx [k ], scaled by 1/(2π), 
n=−∞
namely  the  scaled  area  under S xx (ejΩ ) = |X (ejΩ )|2 ;  this  is  just Parseval’s  identity, 
of  course. 
The deterministic autocorrelation function measures how alike a signal and its time-
shifted version are, in a total-squared-error sense.  More speciﬁcally, in discrete-time 
the  total  squared  error  between  the  signal  and  its  time-shifted  version  is  given  by 
X 
(x[n + k ] − x[n])2  =  X 
∞
∞
2
|x[n + k ]|
n=−∞ 
n=−∞ 
|x[n]| − 2  X 
+  X 
∞
∞
2 
x[n + k ]x[n] 
n=−∞ 
n=−∞ 
= 2(Rxx [0] − Rxx [k ]) 
Since the total squared error  is always nonnegative,  it follows that Rxx [k ] ≤ Rxx [0], 
and that the  larger the deterministic autocorrelation Rxx [k ]  is,  the closer the signal 
x[n]  and  its  time-shifted  version  x[n + k ]  are. 
Corresponding  results  hold  in  continuous  time,  and  in  particular 
Z 
∞ 
S xx (jω) =  |X (jω)| 2  ⇐⇒  x(τ ) ∗ x(−τ ) = 
−∞ 
where  Rxx (t)  is  the  deterministic  autocorrelation  function  of  x(t). 

x(t + τ )x(t)dt = Rxx (τ )  (2.45) 

(2.43) 

(2.44) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  2.4 

The  Bilateral  Laplace  and  Z -Transforms  35 

2.4  THE  BILATERAL  LAPLACE  AND  Z -TRANSFORMS 
The Laplace and Z -transforms can be thought of as extensions of Fourier transforms 
and are useful for a variety of reasons.  They permit a transform treatment of certain 
classes  of  signals  for  which  the  Fourier  transform  does  not  converge.  They  also 
augment  our  understanding  of  Fourier  transforms  by  moving  us  into  the  complex 
plane,  where  the  theory  of  complex  functions  can  be  applied.  We  begin  in  Section 
2.4.1  with  a  detailed  review  of  the  bilateral  Z -transform.  In  Section  2.4.3  we  give 
a  briefer  review  of  the  bilateral  Laplace  transform,  paralleling  the  discussion  in 
Section  2.4.1. 

2.4.1  The  Bilateral  Z -Transform 
The  bilateral  Z -transform  is  deﬁned  as: 
X (z ) = Z {x[n]} =  X 
∞
x[n]z−n 
n=−∞ 
Here  z  is  a  complex  variable,  which  we  can  also  represent  in  polar  form  as 

(2.46) 

z = rejΩ  ,

so 

(2.48) 

(2.47) 

r ≥ 0 ,  −π < Ω ≤ π 
X (z ) =  X 
∞
x[n]r−n e−jΩn 
n=−∞ 
The  DTFT  corresponds  to  ﬁxing  r  =  1,  in  which  case  z  takes  values  on  the  unit 
circle.  However  there  are  many  useful  signals  for  which  the  inﬁnite  sum  does  not 
converge  (even  in  the  sense  of  generalized  functions)  for  z  conﬁned  to  the  unit 
circle.  The  term  z−n  in  the  deﬁnition  of  the  Z -transform  introduces  a  factor  r−n 
into the inﬁnite sum, which permits the sum to converge (provided r is appropriately 
restricted) for interesting classes of signals, many of which do not have discrete-time 
Fourier  transforms. 
More speciﬁcally, note from (2.48) that X (z ) can be viewed as the DTFT of x[n]r−n . 
If  r >  1,  then  r−n  decays  geometrically  for  positive  n  and  grows  geometrically  for 
negative  n.  For  0  < r <  1,  the  opposite  happens.  Consequently,  there  are  many 
sequences  for which x[n]  is not absolutely  summable but x[n]r−n  is,  for  some  range 
of  values  of  r . 

For  example,  consider  x1 [n] =  anu[n].  If  a >  1,  this  sequence  does  not  have  a 
| |
DTFT.  However,  for  any  a,  x[n]r−n  is  absolutely  summable  provided  r >  a .  In 
| |
particular,  for  example, 

X1 (z ) = 1 + az−1  + a 2 z−2  + 
· · · 
1 
z = r >  a
| | 
| | 
1 − az−1 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

= 

,

(2.49) 

(2.50) 

36  Chapter  2 

Signals  and  Systems 

As  a  second  example,  consider  x2 [n] = −anu[−n − 1].  This  signal  does  not  have  a 
DTFT  if  a < 1.  However,  provided  r <  a ,
| | 
| |
X2 (z ) = −a−1 z − a−2 z 2  − · · · 
1 z 
−
−
a
| | 
z = r <  a
= 
| | 
,
1 z 
− 
1 
−
a
1 
z = r <  a
| | 
| | 
1 − az−1 
The  Z -transforms  of  the  two  distinct  signals  x1 [n]  and  x2 [n]  above  get  condensed 
to  the  same  rational  expressions,  but  for  diﬀerent  regions  of  convergence.  Hence 
the  ROC  is  a  critical  part  of  the  speciﬁcation  of  the  transform. 

(2.52) 

(2.53) 

(2.51) 

= 

,

When  x[n]  is  a  sum  of  left-sided  and/or  right-sided  DT  exponentials,  with  each 
term  of  the  form  illustrated  in  the  examples  above,  then X (z ) will  be  rational  in  z 
(or  equivalently,  in  z−1 ): 

X (z ) = 

Q(z )
P (z ) 

(2.54) 

with  Q(z )  and  P (z )  being  polynomials  in  z . 
Rational Z -transforms are typically depicted by a pole-zero plot in the z -plane, with 
the  ROC  appropriately  indicated.  This  information  uniquely  speciﬁes  the  signal, 
apart  from  a  constant  amplitude  scaling.  Note  that  there  can  be  no  poles  in  the 
ROC,  since  the  transform  is  required  to  be  ﬁnite  in  the  ROC.  Z -transforms  are 
often  written  as  ratios  of  polynomials  in  z−1 .  However,  the  pole-zero  plot  in  the 
z -plane  refers  to  the  polynomials  in  z .  Also  note  that  if  poles  or  zeros  at  z  =  ∞
are  counted,  then  any  ratio  of  polynomials  always  has  exactly  the  same  number  of 
poles  as  zeros. 

Region  of Convergence.  To understand  the complex-function properties of the 
Z -transform,  we  split  the  inﬁnite  sum  that  deﬁnes  it  into  non-negative-time  and 
negative-time portions:  The non-negative-time  or  one-sided Z -transform  is deﬁned 
by 
∞X 
x[n]z−n 
n=0 
and  is  a  power  series  in  z−1 .  The  convergence  of  the  ﬁnite  sum  PN
n=0 x[n]z−n  as 
N  → ∞  is  governed  by  the  radius  of  convergence  R1  ≥  0,  of  the  power  series,  i.e. 
the  series  converges  for  each  z  such  that  z > R1 .  The  resulting  function  of  z  is 
| |
an  analytic  function  in  this  region,  i.e.,  has  a  well-deﬁned  derivative  with  respect 
to  the  complex  variable  z  at  each  point  in  this  region,  which  is  what  gives  the 
function  its  nice  properties.  The  inﬁnite  sum  diverges  for  z < R1 .  The  behavior 
| |
of  the  sum  on  the  circle  z = R1  requires  closer  examination,  and  depends  on  the 
| |
particular  series;  the  series  may  converge  (but  may  not  converge  absolutely)  at  all 
points,  some  points,  or  no  points  on  this  circle.  The  region  z > R1  is  referred  to 
| |
as  the  region  of  convergence  (ROC)  of  the  power  series. 

(2.55) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.4 

The  Bilateral  Laplace  and  Z -Transforms  37 

(2.56) 

Next  consider  the  negative-time  part: 
X 
x[n]z−n  =  X 
−1
∞
m
x[−m]z 
n=−∞ 
m=1 
which  is  a  power  series  in  z ,  and  has  a  radius  of  convergence  R2 .  The  series 
converges  (absolutely)  for  z < R2 ,  which  constitutes  its  ROC;  the  series  is  an 
| |
analytic  function  in  this  region.  The  sum  diverges  for  z > R2 ;  the  behavior  for 
| |
the  circle  z = R2  takes  closer  examination,  and  depends  on  the  particular  series; 
| |
the  series  may  converge  (but  may  not  converge  absolutely)  at  all  points,  some 
points,  or  no  points  on  this  circle.  If  R1  < R2  then  the  Z -transform  converges 
(absolutely)  for  R1  < z < R2 ;  this  annular  region  is  its  ROC,  and  is  denoted  by 
| |
RX .  The  transform  is  analytic  in  this  region.  The  sum  that  deﬁnes  the  transform 
diverges  for  |z |  < R1  and  |z |  > R2 .  If  R1  > R2 ,  then  the  Z -transform  does  not 
exist  (e.g.,  for  x[n] = 0.5nu[−n − 1] + 2nu[n]).  If  R1  =  R2 ,  then  the  transform 
may  exist  in  a  technical  sense,  but  is  not  useful  as  a Z -transform  because  it  has  no 
ROC.  However,  if  R1  =  R2  =  1,  then  we  may  still  be  able  to  compute  and  use  a 
DTFT  (e.g.,  for  x[n] = 3,  all  n;  or  for  x[n] = (sin ω0n)/(πn)). 

Relating  the  ROC  to  Signal  Properties.  For  an  absolutely  summable  signal 
(such  as  the  impulse  response  of  a  BIBO-stable  system),  i.e.,  an  ℓ1 -signal,  the  unit 
circle must  lie  in  the ROC  or must  be  a  boundary  of  the ROC.  Conversely,  we  can 
conclude that a signal is ℓ1  if the ROC contains the unit circle because the transform 
converges  absolutely  in  its  ROC.  If  the  unit  circle  constitutes  a  boundary  of  the 
ROC,  then  further  analysis  is  generally  needed  to  determine  if  the  signal  is  ℓ1 . 
Rational transforms always have a pole on the boundary of the ROC, as elaborated 
on below, so if the unit circle is on the boundary of the ROC of a rational transform, 
then  there  is  a  pole  on  the  unit  circle,  and  the  signal  cannot  be  ℓ1 . 
For a right-sided signal it is the case that R2  = ∞, i.e., the ROC extends everywhere 
in  the  complex  plane  outside  the  circle  of  radius R1 ,  up  to  (and  perhaps  including) 
∞.  The  ROC  includes ∞  if  the  signal  is  0  for  negative  time. 
We  can  state  a  converse  result  if,  for  example,  we  know  the  signal  comprises  only 
sums  of  one-sided  exponentials,  of  the  form  obtained  when  inverse  transforming  a 
rational  transform.  In  this  case,  if  R2  = ∞,  then  the  signal  must  be  right-sided;  if 
the  ROC  includes ∞,  then  the  signal  must  be  causal,  i.e.,  zero  for  n < 0. 
For  a  left-sided  signal,  one  has  R1  =  0,  i.e.,  the  ROC  extends  inwards  from  the 
circle  of  radius  R2 ,  up  to  (and  perhaps  including)  0.  The  ROC  includes  0  if  the 
signal  is  0  for  positive  time. 

In  the  case  of  signals  that  are  sums  of  one-sided  exponentials,  we  have  a  converse: 
if R1  = 0,  then  the  signal must be  left-sided;  if  the ROC  includes 0,  then  the  signal 
must  be  anti-causal,  i.e.,  zero  for  n > 0. 
It  is also  important  to note  that  the ROC cannot contain poles of  the Z -transform, 
because  poles  are  values  of  z  where  the  transform  has  inﬁnite  magnitude,  while 
the  ROC  comprises  values  of  z  where  the  transform  converges.  For  signals  with 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

38	

Chapter  2 

Signals  and  Systems 

rational  transforms,  one  can  use  the  fact  that  such  signals  are  sums  of  one-sided 
exponentials  to  show  that  the  possible  boundaries  of  the ROC  are  in  fact  precisely 
determined  by  the  locations  of  the  poles.  Speciﬁcally: 

(a)	 the  outer  bounding  circle  of  the  ROC  in  the  rational  case  contains  a  pole 
and/or  has  radius  ∞.  If  the  outer  bounding  circle  is  at  inﬁnity,  then  (as  we 
have  already  noted)  the  signal  is  right-sided,  and  is  in  fact  causal  if  there  is 
no  pole  at ∞; 
(b)	 the  inner  bounding  circle  of  the  ROC  in  the  rational  case  contains  a  pole 
and/or  has  radius  0.  If  the  inner  bounding  circle  reduces  to  the  point  0,  then 
(as we  have  already  noted)  the  signal  is  left-sided,  and  is  in  fact  anti-causal  if 
there  is  no  pole  at  0. 

2.4.2  The  Inverse  Z -Transform 
One  way  to  invert  a  rational  Z -transform  is  through  the  use  of  a  partial  fraction 
expansion,  then  either  directly  “recognizeing”  the  inverse  transform  of  each  term 
in  the  partial  fraction  representation,  or  expanding  the  term  in  a  power  series  that 
converges  for  z  in  the  speciﬁed  ROC.  For  example,  a  term  of  the  form 

(2.57) 

1 
1 − az−1	
can  be  expanded  in  a  power  series  in  az−1  if  |a|  <  |z |  for  z  in  the  ROC,  and 
expanded  in  a  power  series  in  a−1 z  if  |a| > |z |  for  z  in  the  ROC.  Carrying  out  this 
procedure  for each  term  in a partial  fraction expansion, we ﬁnd  that  the  signal x[n] 
is  a  sum  of  left-sided  and/or  right-sided  exponentials.  For non-rational  transforms, 
where  there  may  not  be  a  partial  fraction  expansion  to  simplify  the  process,  it  is 
still  reasonable  to  attempt  the  inverse  transformation  by  expansion  into  a  power 
series  consistent  with  the  given  ROC. 
Although we will generally use partial fraction or power series methods to invert Z -
transforms,  there  is an explicit  formula  that  is  similar  to  that of  the  inverse DTFT, 
speciﬁcally, 
π  Z 
¯¯¯z=re
1 
2
jω 
π 
−
where  the  constant  r  is  chosen  to  place  z  in  the  ROC,  RX .  This  is  not  the  most 
general  inversion  formula,  but  is  suﬃcient  for  us,  and  shows  that  x[n]  is  expressed 
as  a  weighted  combination  of  discrete-time  exponentials. 
As  is  the  case  for  Fourier  transforms,  there  are many  useful Z -transform  pairs  and 
properties  developed  and  tabulated  in  basic  texts  on  signals  and  systems.  Appro­
priate  use  of  transform  pairs  and  properties  is  often  the  basis  for  obtaining  the 
Z -transform  or  the  inverse  Z -transform  of  many  other  signals. 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

X (z )z n dω

π

x[n] = 

(2.58) 

Section  2.4 

The  Bilateral  Laplace  and  Z -Transforms  39 

2.4.3  The  Bilateral  Laplace  Transform 

X (s) = 

(2.59) 

x(t) e−st dt 

As  with  the  Z -transform,  the  Laplace  transform  is  introduced  in  part  to  handle 
important  classes  of  signals  that  don’t  have CTFT’s,  but  also  enhances  our  under­
standing  of  the  CTFT.  The  deﬁnition  of  the  Laplace  transform  is 
Z 
∞ 
−∞ 
where  s  is  a  complex  variable,  s  =  σ + jω .  The  Laplace  transform  can  thus  be 
thought  of  as  the  CTFT  of  x(t) e−σt .  With  σ  appropriately  chosen,  the  integral 
(2.59)  can  exist  even  for  signals  that  have  no  CTFT. 
The development of the Laplace transform parallels closely that of the Z -transform 
in  the  preceding  section,  but  with  eσ  playing  the  role  that  r  did  in  Section  2.4.1. 
The  (interior  of  the)  set  of  values  of  s  for  which  the  deﬁning  integral  converges, 
as  the  limits  on  the  integral  approach  ±∞,  comprises  the  region  of  convergence 
(ROC)  for  the  transform X (s).  The ROC  is  now  determined  by  the minimum  and 
maximum allowable values of σ , say σ1  and σ2  respectively.  We refer to σ1 , σ2  as the 
abscissa of  convergence.  The corresponding ROC  is a vertical  strip between σ1  and 
σ2  in  the  complex  plane,  σ1  <  Re(s)  < σ2 .  Equation  (2.59)  converges  absolutely 
within  the  ROC;  convergence  at  the  left  and  right  bounding  vertical  lines  of  the 
strip  has  to  be  separately  examined.  Furthermore,  the  transform  is  analytic  (i.e., 
diﬀerentiable  as  a  complex  function)  throughout  the  ROC.  The  strip  may  extend 
to  σ1  = −∞  on  the  left,  and  to  σ2  = +∞  on  the  right.  If  the  strip  collapses  to  a 
line  (so  that  the  ROC  vanishes),  then  the  Laplace  transform  is  not  useful  (except 
if  the  line  happens  to  be  the  jω  axis,  in  which  case  a  CTFT  analysis  may  perhaps 
be  recovered). 

For  example,  consider  x1 (t) =  eatu(t);  the  integral  in  (2.59)  evaluates  to  X1 (s) = 
1/(s − a)  provided  Re{s}  > a.  On  the  other  hand,  for  x2 (t) =  −eatu(−t),  the 
integral  in  (2.59)  evaluates  to  X2 (s) = 1/(s − a)  provided  Re{s} < a.  As  with  the 
Z -transform,  note  that  the  expressions  for  the  transforms  above  are  identical;  they 
are  distinguished  by  their  distinct  regions  of  convergence. 

The  ROC  may  be  related  to  properties  of  the  signal.  For  example,  for  absolutely 
integrable  signals,  also  referred  to  as  L1  signals,  the  integrand  in  the  deﬁnition  of 
the  Laplace  transform  is  absolutely  integrable  on  the  jω  axis,  so  the  jω  axis  is  in 
the  ROC  or  on  its  boundary.  In  the  other  direction,  if  the  jω  axis  is  strictly  in 
the  ROC,  then  the  signal  is  L1 ,  because  the  integral  converges  absolutely  in  the 
ROC. Recall  that  a  system  has  an  L1  impulse  response  if  and  only  if  the  system  is 
BIBO  stable,  so  the  result  here  is  relevant  to  discussions  of  stability:  if  the  jω  axis 
is  strictly  in  the  ROC  of  the  system  function,  then  the  system  is  BIBO  stable. 

For  right-sided  signals,  the  ROC  is  some  right-half-plane  (i.e.  all  s  such  that 
Re{s}  > σ1 ).  Thus  the  system  function  of  a  causal  system  will  have  an  ROC 
that  is  some  right-half-plane.  For  left-sided  signals,  the  ROC  is  some  left-half­
plane.  For  signals  with  rational  transforms,  the  ROC  contains  no  poles,  and  the 
boundaries of  the ROC will have poles.  Since  the  location of  the ROC of a  transfer 
function relative to the imaginary axis relates to BIBO stability, and since the poles 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

40  Chapter  2 

Signals  and  Systems 

identify  the  boundaries  of  the  ROC,  the  poles  relate  to  stability.  In  particular,  a 
system  with  a  right-sided  impulse  response  (e.g.,  a  causal  system)  will  be  stable 
if  and  only  if  all  its  poles  are  in  the  left-half-plane,  because  this  is  precisely  the 
condition  that  allows  the  ROC  to  contain  the  imaginary  axis.  Also  note  that  a 
signal  with  a  rational  transform  is  causal  if  and  only  if  it  is  right-sided. 

A  further  property  worth  recalling  is  connected  to  the  fact  that  exponentials  are 
eigenfunctions  of  LTI  systems.  If  we  denote  the  Laplace  transform  of  the  impulse 
response  h(t)  of  an  LTI  system  by  H (s),  referred  to  as  the  system  function  or 
transfer  function,  then  es0 t  at  the  input  of  the  system  yields  H (s0 ) es0 t  at  the 
output,  provided  s0  is  in  the  ROC  of  the  transfer  function. 

2.5  DISCRETE-TIME  PROCESSING  OF  CONTINUOUS-TIME  SIGNALS 

Many modern systems for applications such as communication, entertainment, nav­
igation  and  control  are  a  combination  of  continuous-time  and discrete-time  subsys­
tems,  exploiting  the  inherent  properties  and  advantages  of  each.  In  particular,  the 
discrete-time processing of continuous-time  signals  is common  in  such applications, 
and we describe the essential  ideas behind such processing here.  As with the earlier 
sections,  we  assume  that  this  discussion  is  primarily  a  review  of  familiar  material, 
included here  to establish notation and  for convenient  reference  from  later chapters 
in  this  text.  In  this  section,  and  throughout  this  text, we will  often  be  relating  the 
CTFT of a continuous-time signal and the DTFT of a discrete-time signal obtained 
from  samples  of  the  continuous-time  signal.  We  will  use  the  subscripts  c  and  d 
when  necessary  to  help  keep  clear  which  signals  are  CT  and  which  are  DT. 

2.5.1  Basic  Structure  for  DT  Processing  of  CT  Signals 

The  basic  structure  is  shown  in  Figure  2.4.  As  indicated,  the  processing  involves 
continuous-to-discrete or C/D conversion to obtain a sequence of samples of the CT 
signal, then DT ﬁltering to produce a sequence of samples of the desired CT output, 
then discrete-to-continuous or D/C conversion to reconstruct this desired CT signal 
from  the  sequence  of  samples.  We  will  often  restrict  ourselves  to  conditions  such 
that the overall system in Figure 2.4 is equivalent to an LTI continuous-time system. 
The  necessary  conditions  for  this  typically  include  restricting  the  DT  ﬁltering  to 
be LTI processing by a system with  frequency response Hd (ejΩ ), and also requiring 
that the input xc (t) be appropriately bandlimited.  To satisfy the latter requirement, 
it  is  typical  to  precede  the  structure  in  the  ﬁgure  by  a  ﬁlter  whose  purpose  is  to 
ensure  that  xc (t)  is  essentially  bandlimited.  While  this  ﬁlter  is  often  referred  to  as 
an anti-aliasing ﬁlter, we can often allow  some aliasing  in  the C/D conversion  if the 
discrete-time  system  removes  the  aliased  components;  the  overall  system  can  then 
still  be  a  CT  LTI  system. 

The  ideal  C/D  converter  in  Figure  2.4  has  as  its  output  a  sequence  of  samples  of 
xc (t) with a speciﬁed sampling interval T1 , so that the DT signal is xd [n] = xc (nT1 ). 
Conceptually,  therefore,  the  ideal  C/D  converter  is  straightforward.  A  practical 
analog-to-digital  (or  A/D)  converter  also  quantizes  the  signal  to  one  of  a  ﬁnite  set 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.5 

Discrete-Time  Processing  of  Continuous-Time  Signals  41 

of  output  levels.  However,  in  this  text  we  do  not  consider  the  additional  eﬀects  of 
quantization. 

Hc (jω) 

�x[n] 

Hd (ejΩ ) 

�y [n] 

�yc (t) 

D/C 

� 
T2 

xc (t)�  C/D 
� 
T1 

FIGURE  2.4  DT  processing  of  CT  signals. 
In  the  frequency  domain,  the CTFT  of xc (t)  and  the DTFT  of xd [n]  are  related  by 
¯¯¯¯¯Ω=ωT1 
2π ¶ 
Xc µ 
1  X 
Xd ¡ejΩ ¢ 
. 
jω − j k 
T1 
T1 
k 
When  xc (t)  is  suﬃciently  bandlimited  so  that 
Xc (jω) = 0  ,

(2.60) 

(2.61) 

=

ω|

| ≥ 

π 
T1 

= 

or  equivalently 

then  (2.60)  can  be  rewritten  as 
Xd ¡ejΩ ¢ ¯¯¯¯¯Ω=ωT1 
1 
Xc (jω) 
T1 
Xc µ 
1 ¶ 
Xd ¡ejΩ ¢ 
Ω 
j
T
1 
Note  that  Xd (ejΩ )  is  extended  periodically  outside  the  interval  |Ω| < π .  The  fact 
that  the  above  equalities  hold  under  the  condition  (2.61)  is  the  content  of  the 
sampling  theorem. 

|ω | < π/T1 

|Ω| < π . 

(2.62b) 

(2.62a) 

= 

1 
T

The  ideal D/C  converter  in Figure  2.4  is  deﬁned  through  the  interpolation  relation 
yc (t) = X 
sin (π (t − nT2 ) /T2 ) 
yd [n]
π(t − nT2 )/T2 
n 
which shows that yc (nT2 ) = yd [n].  Since each term in the above sum is bandlimited 
to  ω < π/T2 , the CT signal yc (t) is also bandlimited to this frequency range, so this 
|
|D/C converter is more completely referred to as the ideal bandlimited interpolating 
converter.  (The  C/D  converter  in  Figure  2.4,  under  the  assumption  (2.61),  is 
similarly characterized by  the  fact  that  the CT  signal xc (t)  is  the  ideal bandlimited 
interpolation  of  the  DT  sequence  xd [n].) 

(2.63) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

42  Chapter  2 

Signals  and  Systems 

= 

=

(2.64a) 

or  equivalently 

|ω | < π/T2 

Because yc (t) is bandlimited and yc (nT2 ) = yd [n], analogous relations to (2.62) hold 
between  the  DTFT  of  yd [n]  and  the  CTFT  of  yc (t): 
¯¯¯¯¯Ω=ωT2 
Yd ¡ejΩ ¢ 
1 
Yc (jω) 
T
2 
Ω ¶ 
1  µ 
Yd ¡ejΩ ¢ 
Yc  j
T2 
T2 
One  conceptual  representation  of  the  ideal  D/C  converter  is  given  in  Figure  2.5. 
This ﬁgure interprets (2.63) to be the result of evenly spacing a sequence of impulses 
at  intervals  of  T2  —  the  reconstruction  interval — with  impulse  strengths  given  by 
the  yd [n],  then  ﬁltering  the  result  by  an  ideal  low-pass  ﬁlter L(jω)  of  amplitude  T2 
in  the  passband  ω < π/T2 .  This  operation  produces  the  bandlimited  continuous­
|
|
time signal yc (t) that interpolates the speciﬁed sequence values yd [n] at the instants 
t = nT2 ,  i.e.,  yc (nT2 ) = yd [n]. 

|Ω| < π 

(2.64b) 

D/C 

�yd [n] 

δ [n − k ] → 
δ(t − kT2 ) 

�yp (t) 

L(jω)  �yc (t) 

FIGURE 2.5  Conceptual representation of processes that yield ideal D/C conversion, 
interpolating  a  DT  sequence  into  a  bandlimited  CT  signal  using  reconstruction 
interval  T2 . 

2.5.2  DT  Filtering,  and  Overall  CT  Response 

Suppose  from  now  on,  unless  stated  otherwise,  that  T1  = T2  = T .  If  in  Figure  2.4 
the  bandlimiting  constraint  of  (2.61)  is  satisﬁed,  and  if  we  set  yd [n] =  xd [n],  then 
yc (t) =  xc (t).  More  generally,  when  the  DT  system  in  Figure  2.4  is  an  LTI  DT 
ﬁlter  with  frequency  response Hd ¡ejΩ ¢,  so 
Yd (ejΩ ) = Hd (ejΩ )Xd (ejΩ ) 
and  provided  any  aliased  components  of  xc (t)  are  eliminated  by  Hd (ejΩ ),  then 
assembling  (2.62),  (2.64)  and  (2.65)  yields: 
¯¯¯¯¯Ω=ωT 
Yc (jω) = Hd ¡ejΩ ¢
Xc (jω) 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

|ω | < π/T 

(2.66) 

(2.65) 

Section  2.5 

Discrete-Time  Processing  of  Continuous-Time  Signals  43 

|ω | < π/T . 

The  action  of  the  overall  system  is  thus  equivalent  to  that  of  a  CT  ﬁlter  whose 
frequency  response  is 
¯¯¯¯¯Ω=ωT 
Hc (jω) = Hd ¡ejΩ ¢ 
In  other  words,  under  the  bandlimiting  and  sampling  rate  constraints  mentioned 
above, the overall system behaves as an LTI CT ﬁlter, and the response of this ﬁlter 
is  related  to  that  of  the  embedded  DT  ﬁlter  through  a  simple  frequency  scaling. 
The  sampling  rate  can  be  lower  than  the Nyquist  rate,  provided  that  the DT  ﬁlter 
eliminates  any  aliased  components. 
If  we  wish  to  use  the  system  in  Figure  2.4  to  implement  a  CT  LTI  ﬁlter  with 
frequency  response  Hc (jω),  we  choose  Hd ¡ejΩ ¢ 
according  to  (2.67),  provided  that 
xc (t)  is  appropriately  bandlimited. 
If  Hc (jω) = 0  for  |ω | ≥ π/T ,  then  (2.67)  also  corresponds  to  the  following  relation 
between  the  DT  and  CT  impulse  responses: 

(2.67) 

hd [n] = T hc (nT ) 

(2.68) 

The  DT  ﬁlter  is  therefore  termed  an  impulse-invariant  version  of  the  CT  ﬁlter. 
When  xc (t)  and  Hd (ejΩ )  are  not  suﬃciently  bandlimited  to  avoid  aliased  compo­
nents  in  yd [n],  then  the  overall  system  in  Figure  2.4  is  no  longer  time  invariant.  It 
is,  however,  still  linear  since  it  is  a  cascade  of  linear  subsystems. 

The  following  two  important  examples  illustrate  the  use  of  (2.67)  as well  as  Figure 
2.4, both for DT processing of CT signals and for interpretation of an important DT 
system,  whether  or  not  this  system  is  explicitly  used  in  the  context  of  processing 
CT  signals. 

Digital  Diﬀerentiator 
EXAMPLE  2.3 
In  this  example  we  wish  to  implement  a  CT  diﬀerentiator  using  a  DT  system  in 
the conﬁguration of Figure 2.4  .  We need  to choose Hd ¡ejΩ ¢ 
dxc (t)
so  that yc (t) = 
, 
dt 
assuming  that  xc (t)  is  bandlimited  to  π/T .  The  desired  overall  CT  frequency 
response  is  therefore 
Yc (jω)
= jω 
Hc (jω) = 
Xc (jω) 
Consequently,  using  (2.67)  we  choose  Hd (ejΩ )  such  that 
Hd ¡ejΩ ¢ ¯¯¯¯¯Ω=ωT 
Hd ¡ejΩ ¢ 
|Ω| < π 
A discrete-time system with the frequency response in (2.70b) is commonly referred 
to  as  a  digital  diﬀerentiator.  To  understand  the  relation  between  the  input  xd [n] 

or  equivalently 

= jΩ/T 

|ω | < 

π 
T

= jω 

(2.69) 

(2.70a) 

(2.70b) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

44  Chapter  2 

Signals  and  Systems 

and  output  yd [n]  of  the  digital  diﬀerentiator,  note  that  yc (t)  —  which  is  the  ban­
dlimited  interpolation  of  yd [n] —  is  the  derivative  of  xc (t),  and  xc (t)  in  turn  is  the 
bandlimited  interpolation  of  xd [n].  It  follows  that  yd [n]  can,  in  eﬀect,  be  thought 
of as  the  result of  sampling  the derivative of  the bandlimited  interpolation of xd [n]. 

EXAMPLE  2.4 

Half-Sample  Delay 

It  often  arises  in  designing  discrete-time  systems  that  a  phase  factor  of  the  form 
e−jαΩ ,  |Ω| < π ,  is  included  or  required.  When  α  is  an  integer,  this  has  a  straight­
forward  interpretation,  since  it  corresponds  simply  to  an  integer  shift  by  α  of  the 
time  sequence. 

When  α  is  not  an  integer,  the  interpretation  is  not  as  straightforward,  since  a 
DT  sequence  can  only  be  directly  shifted  by  integer  amounts.  In  this  example  we 
consider  the  case  of  α  = 1/2,  referred  to  as  a  half-sample  delay.  To  provide  an 
interpretation,  we  consider  the  implications  of  choosing  the  DT  system  in  Figure 
2.4  to  have  frequency  response 

Hd (ejΩ ) = e−jΩ/2 

|Ω| < π 
Whether or not xd [n] explicitly arose by sampling a CT signal, we can associate with 
xd [n] its bandlimited interpolation xc (t) for any speciﬁed sampling or reconstruction 
interval T .  Similarly, we can associate with yd [n] its bandlimited interpolation yc (t) 
using  the  reconstruction  interval  T .  With Hd ¡ejΩ ¢ 
given  by  (2.71),  the  equivalent 
CT  frequency  response  relating  yc (t)  to  xc (t)  is 
Hc (jω) = e−jωT /2 

(2.71) 

(2.72) 

representing  a  time  delay  of  T /2,  which  is  half  the  sample  spacing;  consequently, 
yc (t) =  xc (t − T /2).  We  therefore  conclude  that  for  a  DT  system  with  frequency 
response  given  by  (2.71),  the  DT  output  yd [n]  corresponds  to  samples  of  the  half-
sample  delay  of  the  bandlimited  interpolation  of  the  input  sequence  xd [n].  Note 
that  in  this  interpretation  the  choice  for  the  value  of  T  is  immaterial.  (Even  if 
xd [n] had been  the  result of  regular  sampling of a CT  signal,  that  speciﬁc  sampling 
period  is  not  required  in  the  interpretation  above.) 

The preceding interpretation allows us to ﬁnd the unit-sample (or impulse) response 
of  the  half-sample  delay  system  through  a  simple  argument.  If  xd [n] =  δ [n],  then 
xc (t)  must  be  the  bandlimited  interpolation  of  this  (with  some  T  that  we  could 
have  speciﬁed  to  take  any  particular  value),  so 

and  therefore 

sin(πt/T ) 
xc (t) = 
πt/T 
sin³π(t − (T /2))/T ´ 
π(t − (T /2))/T 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

yc (t) = 

(2.73) 

(2.74) 

Section  2.5 

Discrete-Time  Processing  of  Continuous-Time  Signals  45 

which  shows  that  the  desired  unit-sample  response  is 
sin³π(n − (1/2))´ 
π(n − (1/2)) 
This  discussion  of  a  half-sample  delay  also  generalizes  in  a  straightforward  way  to 
any  integer  or  non-integer  choice  for  the  value  of  α. 

yd [n] = hd [n] = 

(2.75) 

2.5.3  Non-Ideal  D/C  converters 

In  Section  2.5.1  we  deﬁned  the  ideal  D/C  converter  through  the  bandlimited  in­
terpolation  formula  (2.63);  see  also  Figure  2.5,  which  corresponds  to  processing  a 
train of  impulses with strengths equal to the sequence values yd [n] through an  ideal 
low-pass  ﬁlter.  A  more  general  class  of  D/C  converters,  which  includes  the  ideal 
converter  as  a  particular  case,  creates  a  CT  signal  yc (t)  from  a  DT  signal  yd [n] 
according  to  the  following: 
yc (t) =  X 
∞
yd [n] p(t − nT ) 
n=−∞ 
where p(t)  is some selected basic pulse shape and T  is the reconstruction  interval or 
pulse repetition interval.  This too can be seen as the result of processing an impulse 
train  of  sequence  values  through  a  ﬁlter,  but  a  ﬁlter  that  has  impulse  response  p(t) 
rather than that of the ideal low-pass ﬁlter.  The CT signal yc (t) is thus constructed 
by adding together shifted and scaled versions of the basic pulse shape;  the number 
yd [n]  scales  p(t − nT ),  which  is  the  basic  pulse  delayed  by  nT .  Note  that  the  ideal 
bandlimited  interpolating  converter  of  (2.63)  is  obtained  by  choosing 

(2.76) 

p(t) = 

sin(πt/T ) 
(πt/T ) 

(2.77) 

We  shall  be  talking  in more  detail  in Chapter  12  about  the  interpretation  of  (2.76) 
as  pulse  amplitude  modulation  (PAM)  for  communicating  DT  information  over  a 
CT  channel. 

The relationship (2.76) can also be described quite simply  in the frequency domain. 
Taking the CTFT of both sides, denoting the CTFT of p(t) by P (jω), and using the 
fact  that  delaying  a  signal  by  t0  in  the  time  domain  corresponds  to  multiplication 
by  e−jωt0  in  the  frequency  domain,  we  get 
yd [n] e−jnωT ´ 
Yc (jω) =  ³ X 
∞
P (jω) 
n=−∞ 
¯¯¯¯¯Ω=ωT 
=  Yd (ejΩ ) 
P (jω) 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(2.78) 

46  Chapter  2 

Signals  and  Systems 

FIGURE  2.6  A  centered  zero-order  hold  (ZOH) 

In  the  particular  case  where  p(t)  is  the  sinc  pulse  in  (2.77),  with  transform  P (jω) 
corresponding to an ideal low-pass ﬁlter of amplitude T  for  ω < π/T  and 0 outside 
|
|
this  band,  we  recover  the  relation  (2.64). 

In  practice  an  ideal  low-pass  ﬁlter  can  only  be  approximated,  with  the  accuracy 
of  the  approximation  closely  related  to  cost  of  implementation.  A  commonly  used 
simple  approximation  is  the  (centered)  zero-order  hold  (ZOH),  speciﬁed  by  the 
choice 
p(t) = ½ 
This  D/C  converter  holds  the  value  of  the  DT  signal  at  time  n,  namely  the  value 
yd [n],  for  an  interval  of  length  T  centered  at  nT  in  the  CT  domain,  as  illustrated 
in  Figure  2.6.  Such  ZOH  converters  are  very  commonly  used.  Another  common 
choice  is  a  centered  ﬁrst-order  hold  (FOH),  for which  p(t)  is  triangular  as  shown  in 
Figure  2.7.  Use  of  the  FOH  represents  linear  interpolation  between  the  sequence 
values. 

for  |t| < (T /2) 
1 
0  elsewhere 

(2.79) 

FIGURE  2.7  A  centered  ﬁrst  order  hold  (FOH) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

3 

Transform  Representation  of  Signals 
and  LTI  Systems 

As  you  have  seen  in  your  prior  studies  of  signals  and  systems,  and  as  emphasized 
in  the  review  in  Chapter  2,  transforms  play  a  central  role  in  characterizing  and 
representing  signals  and  LTI  systems  in  both  continuous  and  discrete  time.  In 
this  chapter we  discuss  some  speciﬁc  aspects  of  transform  representations  that will 
play  an  important  role  in  later  chapters.  These  aspects  include  the  interpreta­
tion  of  Fourier  transform  phase  through  the  concept  of  group  delay,  and  methods 
—  referred  to  as  spectral  factorization  —  for  obtaining  a  Fourier  representation 
(magnitude  and  phase)  when  only  the  Fourier  transform  magnitude  is  known. 

3.1  FOURIER  TRANSFORM  MAGNITUDE  AND  PHASE 

The  Fourier  transform  of  a  signal  or  the  frequency  response  of  an  LTI  system  is  in 
general  a  complex-valued  function.  A magnitude-phase  representation  of  a  Fourier 
transform  X (jω)  takes  the  form 
X (jω) = |X (jω)|ej∠X (jω)  . 
In  eq.  (3.1),  X (jω) denotes  the  (non-negative)  magnitude  and  ∠X (jω)  denotes 
|
|
the  (real-valued)  phase.  For  example,  if X (jω)  is  the  sinc  function,  sin(ω)/ω ,  then 
|X (jω)| is the absolute value of this function, while ∠X (jω) is 0 in frequency ranges 
where  the  sinc  is positive,  and π  in  frequency  ranges where  the  sinc  is negative.  An 
alternative  representation  is  an  amplitude-phase  representation 

(3.1) 

A(ω)ej∠AX (jω) 

(3.2) 

in  which  A(ω) =  ±|X (jω)|  is  real  but  can  be  positive  for  some  frequencies  and 
negative for others.  Correspondingly, ∠AX (jω) = ∠X (jω) when A(ω) = + X (jω) , 
|
|
and ∠AX (jω) = ∠X (jω) ± π  when A(ω) = −|X (jω)|. 
This  representation  is  often 
preferred  when  its  use  can  eliminate  discontinuities  of  π  radians  in  the  phase  as 
A(ω)  changes  sign.  In  the  case  of  the  sinc  function  above,  for  instance, we  can pick 
A(ω) = sin(ω)/ω  and ∠A  = 0.  It  is  generally  convenient  in  the  following discussion 
for  us  to  assume  that  the  transform  under  discussion  has  no  zeros  on  the  jω -axis, 
so  that  we  can  take  A(ω) =  |X (jω)|  for  all  ω  (or,  if  we  wish,  A(ω) = −|X (jω)|  for 
all  ω).  A  similar  discussion  applies  also,  of  course,  in  discrete-time. 

In  either  a  magnitude-phase  representation  or  an  amplitude-phase  representation, 
the phase is ambiguous, as any integer multiple of 2π can be added at any frequency 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

47

48  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

without  changing  X (jω)  in  (3.1)  or  (3.2).  A  typical  phase  computation  resolves 
this ambiguity by generating the phase modulo 2π ,  i.e., as the phase passes through 
+π  it  “wraps  around”  to  −π  (or  from  −π  wraps  around  to  +π).  In  Section  3.2 
we  will  ﬁnd  it  convenient  to  resolve  this  ambiguity  by  choosing  the  phase  to  be 
a  continuous  function  of  frequency.  This  is  referred  to  as  the  unwrapped  phase, 
since  the  discontinuities  at ±π  are  unwrapped  to  obtain  a  continuous  phase  curve. 
The  unwrapped  phase  is  obtained  from ∠X (jω)  by  adding  steps  of  height  equal  to 
±π  or  ±2π  wherever  needed,  in  order  to  produce  a  continuous  function  of  ω .  The 
steps  of  height  ±π  are  added  at  points  where  X (jω)  passes  through  0,  to  absorb 
sign  changes  as  needed;  the  steps  of  height ±2π  are  added wherever  else  is  needed, 
invoking  the  fact  that  such  steps  make  no  diﬀerence  to  X (jω),  as  is  evident  from 
(3.1).  We shall proceed as though ∠X (jω)  is indeed continuous (and diﬀerentiable) 
at  the  points  of  interest,  understanding  that  continuity  can  indeed  be  obtained  in 
all  cases  of  interest  to  us  by  adding  in  the  appropriate  steps  of  height  ±π  or  ±2π . 
Typically, our intuition for the time-domain eﬀects of frequency response magnitude 
or  amplitude  on  a  signal  is  rather  well-developed.  For  example,  if  the  Fourier 
transform magnitude is signiﬁcantly attenuated at high frequencies, then we expect 
the  signal  to  vary  slowly  and  without  sharp  discontinuities.  On  the  other  hand,  a 
signal  in  which  the  low  frequencies  are  attenuated  will  tend  to  vary  rapidly  and 
without  slowly  varying  trends. 

In  contrast,  visualizing  the  eﬀect on a  signal of  the phase of  the  frequency  response 
of  a  system  is more  subtle,  but  equally  important.  We  begin  the  discussion  by ﬁrst 
considering several speciﬁc examples which are helpful in then considering the more 
general  case.  Throughout  this  discussion  we  will  consider  the  system  to  be  an  all-
pass system with unity gain, i.e.  the amplitude of the frequency response A(jω) = 1 
(continuous time) or A(ejΩ ) = 1 (discrete time) so that we can focus entirely on the 
eﬀect  of  the  phase.  The  unwrapped  phase  associated  with  the  frequency  response 
will  be  denoted  as  ∠AH (jω)  (continuous  time)  and  ∠AH (ejΩ )  (discrete  time). 

EXAMPLE  3.1 

Linear  Phase 

Consider  an  all-pass  system  with  frequency  response 
H (jω) = e−jαω 
(3.3) 
i.e.  in  an  amplitude/phase  representation  A(jω)  =  1  and  ∠AH (jω) =  −αω .  The 
unwrapped  phase  for  this  example  is  linear  with  respect  to  ω ,  with  slope  of  −α. 
For  input  x(t)  with  Fourier  transform  X (jω),  the  Fourier  transform  of  the  output 
is  Y (jω) = X (jω)e−jαω  and  correspondingly  the  output  y(t)  is  x(t − α).  In words, 
linear phase with a slope of −α corresponds to a time delay of α (or a time advance 
if  α  is  negative). 

For  a  discrete  time  system  with 
H (ejΩ ) = e−jαΩ 
|Ω| < π 
(3.4) 
the  phase  is  again  linear  with  slope  −α.  When  α  is  an  integer,  the  time  domain 
interpretation of the eﬀect on an input sequence x[n] is again straightforward and is 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  3.1 

Fourier  Transform  Magnitude  and  Phase  49 

a simple delay (α positive) or advance (α negative) of  α .  When α is not an integer, 
|
|
the  eﬀect  is  still  commonly  referred  to  as  “a  delay  of  α”,  but  the  interpretation  is 
more  subtle.  If  we  think  of  x[n]  as  being  the  result  of  sampling  a  band-limited, 
continuous-time  signal  x(t)  with  sampling  period  T ,  the  output  y [n]  will  be  the 
result  of  sampling  the  signal  y(t) = x(t − αT )  with  sampling  period  T .  In  fact  we 
saw  this  result  in  Example  2.4  of  chapter  2  for  the  speciﬁc  case  of  a  half-sample 
1 . 
delay,  i.e.  α =  2

EXAMPLE  3.2 

Constant  Phase  Shift 

As  a  second  example,  we  again  consider  an  all-pass  system  with  A(jω)  =  1  and 
unwrapped  phase 
½ 

for  ω > 0
for  ω < 0 

as  indicated  in  Figure  3.1 

∠AH (jω) = 

−φ0
+φ0 

+φ  0 

-φ  0 

ω 

FIGURE  3.1  Phase  plot  of  all-pass  system  with  constant  phase  shift,  φ0 . 

Note  that  the  phase  is  required  to  be  an  odd  function  of  ω  if  we  assume  that  the 
system  impulse  response  is  real  valued.  In  this  example,  we  consider  x(t)  to  be  of 
the  form 

x(t) = s(t) cos(ω0 t + θ) 
(3.5) 
i.e.  an  amplitude-modulated  signal  at  a  carrier  frequency  of  ω0 .  Consequently, 
X (jω)  can  be  expressed  as 

1 
1 
S (jω + jω0 )e−j θ 
S (jω − jω0 )ej θ  +
2 
2
where  S (jω)  denotes  the  Fourier  transform  of  s(t). 

X (jω) = 

(3.6) 

For  this  example,  we  also  assume  that  S (jω)  is  bandlimited  to  ω <  Δ,  with  Δ 
|
|
suﬃciently  small  so  that  the  term  S (jω − jω0 )ej θ  is  zero  for  ω <  0  and  the  term 
S (jω + jω0 )e−j θ  is  zero  for ω > 0,  i.e.  that  (ω0 − Δ) > 0.  The associated  spectrum 
of  x(t)  is  depicted  in  Figure  3.2. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

50  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

X(jω) 

½S(jω+jω )e-jθ 
0

½S(jω-jω0)e+jθ 

-ω 0 

0 

ω0

ω 

ω -Δ 
0

ω +Δ
0

FIGURE  3.2  Spectrum  of  x(t)  with  s(t)  narrowband 

With  these  assumptions  on  x(t),  it  is  relatively  straightforward  to  determine  the 
output  y(t).  Speciﬁcally,  the  system  frequency  response H (jω)  is 
½ 
Since  the  term  S (jω − jω0 )ej θ  in  eq.  (3.6)  is  non-zero  only  for  ω >  0,  it  is  simply 
multiplied  by  e−jφ ,  and  similarly  the  term  S (jω + jω0 )e−j θ  is  multiplied  only  by 
e+jφ .  Consequently,  the  output  frequency  response,  Y (jω),  is  given  by 

ω > 0 
ω < 0 

e−jφ0
+jφ0 
e

H (jω) = 

(3.7) 

= 

Y (jω) =  X (jω)H (jω) 
1 
S (jω − jω0 )e +j θ e−jφ0  +
2
which  we  recognize  as  a  simple  phase  shift  by  φ0  of  the  carrier  in  eq.  (3.5),  i.e. 
replacing  θ  in  eq.  (3.6)  by  θ − φ0 .  Consequently, 
y(t) = s(t) cos(ω0 t + θ − φ0 ) 

1 
S (jω + jω0 )e−j θ e +jφ0 
2 

(3.9) 

(3.8) 

This  change  in  phase  of  the  carrier  can  also  be  expressed  in  terms  of  a  time  delay 
for  the  carrier  by  rewriting  eq.  (3.9)  as 
¸ 
· µ 
φ0 ¶
y(t) = s(t) cos  ω0 
t − 
+ θ 
ω0 

(3.10) 

3.2  GROUP  DELAY  AND  THE  EFFECT  OF  NONLINEAR  PHASE 

In  Example  3.1,  we  saw  that  a  phase  characteristic  that  is  linear  with  frequency 
corresponds  in  the  time  domain  to  a  time  shift.  In  this  section  we  consider  the 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  3.2 

Group  Delay  and  The  Eﬀect  of  Nonlinear  Phase  51 

eﬀect  of  a  nonlinear  phase  characteristic.  We  again  assume  the  system  is  an  all-
pass  system  with  frequency  response 

H (jω) = A(jω)ej∠A [H (jω)] 

(3.11) 

with A(jω) = 1.  A general nonlinear unwrapped phase  characteristic  is depicted  in 
Figure  3.3 

∠ A 

+φ  1 

+ω 0 

ω 

-ω 0 

-φ  1 

FIGURE  3.3  Nonlinear  Unwrapped  Phase  Characteristic 

As we  did  in Example  3.2, we  again  assume  that  x(t)  is  narrowband  of  the  form  of 
equation  (3.5)  and  as  depicted  in Figure  3.2.  We  next  assume  that Δ  in Figure  3.2 
is  suﬃciently  small  so  that  in  the  vicinity  of  ±ω0 ,  ∠AH (jω)  can  be  approximated 
suﬃciently  well  by  the  zeroth  and  ﬁrst  order  terms  of  a  Taylor’s  series  expansion, 
i.e. 
¸ 
· 
d 
∠AH (jω) ≈ ∠AH (jω0 ) + (ω − ω0 ) 
∠AH (jω) 
dω 
ω=ω0 

(3.12) 

Deﬁning  τg (ω)  as 

d 
τg (ω) = −  ∠AH (jω) 
dω 
our  approximation  to  ∠AH (jω)  in  a  small  region  around  ω = ω0  is  expressed  as 

(3.13) 

∠AH (jω) ≈ ∠AH (jω0 ) − (ω − ω0 )τg (ω0 ) 
Similarly  in  a  small  region  around  ω = −ω0 ,  we make  the  approximation 
∠AH (jω) ≈ ∠AH (jω0 ) − (ω + ω0 )τg (−ω0 ) 
As  we  will  see  shortly,  the  quantity  τg (ω)  plays  a  key  role  in  our  interpretation  of 
the  eﬀect  on  a  signal  of  a  nonlinear  phase  characteristic. 

(3.14) 

(3.15) 

With  the  Taylor’s  series  approximation  of  eqs.  (3.14)  and  (3.15)  and  for  input 
signals with  frequency  content  for which  the approximation  is valid, we  can  replace 
Figure  3.3  with  Figure  3.4. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

52  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

slope = -τ g(ω 0)


-ω  0 

+φ

1 

+φ  0 

-φ  0 

-φ  1 

+ω 

0

ω 

slope = -τ g(ω 0) 

FIGURE  3.4  Taylor’s  series  approximation  of  nonlinear  phase  in  the  vicinity  of ±ω0 

where 

and 

−φ1  = ∠AH (jω0 ) 

−φ0  = ∠AH (jω0 ) + ω0 τg (ω0 ) 
Since for LTI systems  in cascade,  the frequency responses multiply and correspond­
ingly  the  phases  add,  we  can  represent  the  all-pass  frequency  response  H (jω)  as 
the  cascade  of  two  all-pass  systems,  HI (jω)  and  HI I (jω),  with  unwrapped  phase 
as  depicted  in  Figure  3.5. 

x(t) 

H I(jω) 

x I(t) 

H (jω) 
II

x II(t) 

∠ A H I(jω) 

+φ 0 

-φ 0 

∠ A H II(jω) 

slope = -τg(ω0) 

ω 

ω 

FIGURE  3.5  An  all-pass  system  frequency  response, H (jω),  represented  as  the  cas­
cade  of  two  all-pass  systems,  HI (jω)  and HI I (jω). 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c



Section  3.2 

Group  Delay  and  The  Eﬀect  of  Nonlinear  Phase  53 

We  recognize  HI (jω)  as  corresponding  to  Example  3.2.  Consequently,  with  x(t) 
narrowband,  we  have 

x(t) =  s(t) cos(ω0 t + θ) 
· µ 
¸ 
φ0 ¶
t − 
xI (t) =  s(t) cos  ω0 
+ θ 
ω0 
Next  we  recognize  HI I (jω)  as  corresponding  to  Example  3.1  with  α  =  τg (ω0 ). 
Consequently, 

(3.16) 

or  equivalently 

xI I (t) = xI  (t − τg (ω0 )) 
· µ 
φ0  + ω0 τg (ω0 ) ¶
t − 
xI I (t) = s(t − τg (ω0 )) cos  ω0 
ω0 
Since,  from  Figure  3.4,  we  see  that 

¸ 
+ θ 

(3.17) 

(3.18) 

equation  (3.18)  can  be  rewritten  as 

φ1  = φ0  + ω0 τg (ω0 ) 

or 

· µ 
¸ 
φ1 ¶
t − 
+ θ 
xI I (t) = s(t − τg (ω0 )) cos  ω0 
ω0 
xI I (t) = s(t − τg (ω0 )) cos [ω0  (t − τp (ω0 )) + θ ] 

(3.19a) 

(3.19b) 

φ1
where  τp ,  referred  to  as  the  phase  delay,  is  deﬁned  as  τp  =  ω
0 
In  summary,  according  to  eqs.  (3.18)  and  (3.19a),  the  time-domain  eﬀect  of  the 
nonlinear phase for the narrowband group of frequencies around the frequency ω0  is 
to delay  the narrowband  signal by  the group delay,  τg (ω0 ), and apply an additional 
φ1
phase  shift  of  ω
to  the  carrier.  An  equivalent,  alternate  interpretation  is  that  the 
0 
time-domain envelope of the  frequency group  is delayed by the group delay and the 
carrier  is  delayed  by  the  phase  delay. 

. 

The discussion has been carried out  thus  far  for narrowband  signals.  To extend  the 
discussion  to broadband  signals, we need  only  recognize  that  any broadband  signal 
can  be  viewed  as  a  superposition  of  narrowband  signals.  This  representation  can 
in  fact  be  developed  formally  by  recognizing  that  the  system  in  Figure  3.6  is  an 
identity  system,  i.e.  r(t) = x(t)  as  long  as 
∞X 
Hi (jω) = 1 
i=0 
By  choosing  the  ﬁlters  Hi (jω)  to  satisfy  eq.  (3.20)  and  to  be  narrowband  around 
center  frequencies  ωi ,  each  of  the  output  signals,  yi (t),  is  a  narrowband  signal. 
Consequently  the  time-domain  eﬀect  of  the  phase  of  G(jω)  is  to  apply  the  group 

(3.20) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

54  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

x(t) 

G(jω) 

r(t) 

H 0(jω ) 

g0(t) 

r 0(t) 

G(jω ) 

x(t) 

H i(jω ) 

gi(t) 

r i(t) 

G(jω ) 

r(t) 

FIGURE  3.6  Continuous-time  all-pass  system  with  frequency  response  amplitude, 
phase  and  group  delay  as  shown  in  Figure  3.7 

FIGURE  3.7  Magnitude,  (nonlinear)  phase,  and  group  delay  of  an  all-pass  ﬁlter. 

delay and phase delay to each of the narrowband components (i.e.  frequency groups) 
yi (t).  If  the  group  delay  is  diﬀerent  at  the  diﬀerent  center  (i.e.  carrier)  frequencies 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  3.2 

Group  Delay  and  The  Eﬀect  of  Nonlinear  Phase  55 

FIGURE  3.8  Impulse  response  for  all-pass  ﬁlter  shown  in  Figure  3.7 

ωi ,  then  the  time  domain  eﬀect  is  for  diﬀerent  frequency  groups  to  arrive  at  the 
output  at  diﬀerent  times. 

As  an  illustration  of  this  eﬀect,  consider  G(jω)  in  Figure  3.6  to  be  the  continuous 
time  all-pass  system  with  frequency  response  amplitude,  phase  and  group  delay  as 
shown  in  Figure  3.7.  The  corresponding  impulse  response  is  shown  in  Figure  3.8. 

If the phase of G(jω) were linear with frequency, the impulse response would simply 
be  a  delayed  impulse,  i.e.  all  the  narrowband  components would  be  delayed  by  the 
same amount and correspondingly would add up to a delayed  impulse.  However, as 
we see in Figure 3.7, the group delay is not constant since the phase is nonlinear.  In 
particular,  frequencies  around  1200  Hz  are  delayed  signiﬁcantly  more  than  around 
other  frequencies.  Correspondingly,  in  Figure  3.8  we  see  that  frequency  group 
appearing  late  in  the  impulse  response. 

A  second  example  is  shown  in  Figure  3.9,  in  which  G(jω)  is  again  an  all-pass 
system with nonlinear phase and consequently non-constant group delay.  With this 
example,  we  would  expect  to  see  diﬀerent  delays  in  the  frequency  groups  around 
ω  = 2π  50,  ω  = 2π  100,  and  ω  = 2π  300  with  the  group  at  ω  = 2π  50  having 
· 
· 
·
·
the  maximum  delay  and  therefore  appearing  last  in  the  impulse  response. 

In both of these examples, the input is highly concentrated in time (i.e.  an impulse) 
and  the  response  is  dispersed  in  time  because  of  the  non-constant  group  delay,  i.e. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

56  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

)
d
a
r
(
 
e
s
a
h
P

4

2

0

-2

-4

)
d
a
r
(
 
e
s
a
h
P

0
-5

-10

-15
-20

0

50

100

150
250
200
Frequency (Hz)
(a)

300

350

400

0

50

100

150
250
200
Frequency (Hz)
(b)

300

350

400

0.10

0.08

0.06

0.04

0.02
0

)
c
e
s
(
 
y
a
l
e
d
 
p
u
o
r
G

0

50

100

150
250
200
Frequency (Hz)
(c)

300

350

400

600
400
200
0
-200
-400
-600

0

0.02

0.04

0.06

0.08

0.1

0.12

0.14

0.16

0.18

0.2

Time (sec)
(d)

Image by MIT OpenCourseWare, adapted from Signals and Systems, Alan Oppenheim
and Alan Willsky. Prentice Hall, 1996.

FIGURE  3.9  Phase,  group  delay,  and  impulse  response  for  an  all-pass  system:  (a) 
principal phase; (b) unwrapped phase; (c) group delay; (d) impulse response.  (From 
Oppenheim  and Willsky,  Signals  and  Systems,  Prentice  Hall,  1997,  Figure  6.5.) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  3.3 

All-Pass  and  Minimum-Phase  Systems  57 

the nonlinear phase.  In general, the eﬀect of nonlinear phase is referred to as disper­
sion.  In  communication  systems  and  many  other  application  contexts  even  when 
a  channel  has  a  relatively  constant  frequency  response  magnitude  characteristic, 
nonlinear phase can result  in signiﬁcant distortion and other negative consequences 
because  of  the  resulting  time  dispersion.  For  this  reason,  it  is  often  essential  to 
incorporate  phase  equalization  to  compensate  for  non-constant  group-delay. 

As  a  third  example,  we  consider  an  all-pass  system  with  phase  and  group  delay  as 
shown  in  Figure  3.101 .  The  input  for  this  example  is  the  touch-tone  digit  “ﬁve” 
which  consists  of  two  very  narrowband  tones  at  center  frequencies  770  and  1336 
Hz.  The  time-domain  signal  and  its  two  narrowband  component  signals  are  shown 
in  Figure  3.11. 

FIGURE 3.10  Phase and group delay for all-pass ﬁlter for touch-tone signal example. 

The touch-tone signal is processed with multiple passes through the all-pass system 
of Figure  3.10.  From  the  group delay plot, we  expect  that,  in  a  single pass  through 
the  all-pass  ﬁlter,  the  tone  at  1336  Hz  would  be  delayed  by  about  2.5  milliseconds 
relative to the tone at 770 Hz.  After 200 passes, this would accumulate to a relative 
delay  of  about  0.5  seconds. 

In  Figure  3.12,  we  show  the  result  of  multiple  passes  through  ﬁlters  and  the  accu­
mulation  of  the  delays. 

3.3  ALL-PASS  AND  MINIMUM-PHASE  SYSTEMS 

Two  particularly  interesting  classes  of  stable  LTI  systems  are  all-pass  systems  and 
minimum-phase  systems.  We  deﬁne  and  discuss  them  in  this  section. 

1This  example  was  developed  by  Prof.  Bernard  Lesieutre  of  the  University  of  Wisconsin, 
Madison,  when  he  taught  the  course  with  us  at  MIT 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

58  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

FIGURE  3.11  Touch-tone  signal  with  its  two  narrowband  component  signals. 

3.3.1  All-Pass  Systems 

An  all-pass  system  is  a  stable  system  for  which  the  magnitude  of  the  frequency 
response  is  a  constant,  independent  of  frequency.  The  frequency  response  in  the 
case  of  a  continuous-time  all-pass  system  is  thus  of  the  form 

Hap (jω) = Aej∠Hap (jω)  , 

(3.21) 

where  A  is  a  constant,  not  varying  with  ω .  Assuming  the  associated  transfer  func­
tion H (s)  is  rational  in  s,  it  will  correspondingly  have  the  form 
Y 
M s + a∗ 
k
Hap (s) = A 
s − ak
k=1 
Note  that  for  each  pole  at  s = +ak  this  has  a  zero  at  the  mirror  image  across  the 
;  and  if  ak  is  complex  and  the  system  impulse 
imaginary  axis,  namely  at  s 
=  −a
∗
k
response  is  real-valued,  every  complex  pole  and  zero will  occur  in  a  conjugate  pair, 
so  there  will  also  be  a  pole  at  s  +a= 
∗ and  a  zero  at  s  =  −ak .  An  example  of  a 
k 
pole-zero  diagram  (in  the  s-plane)  for  a  continuous-time  all-pass  system  is  shown 
in Figure  (3.13).  It  is  straightforward  to  verify  that  each  of  the M  factors  in  (3.22) 
has  unit magnitude  for  s = jω . 

(3.22) 

. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  3.3 

All-Pass  and  Minimum-Phase  Systems  59 

200 
passes 

200 
passes 

200 
passes 

200 
passes 

200 
passes 

FIGURE 3.12  Eﬀect of passing touchtone signal (Figure 3.11) through multiple passes 
of  an  all-pass  ﬁlter  and  the  accumulation  of  delays 
. 

For  a  discrete-time  all-pass  system,  the  frequency  response  is  of  the  form 

Hap (ejΩ ) = Aej∠Hap (ejΩ )  .	

(3.23) 

If  the  associated  transfer  function H (z )  is  rational  in  z ,  it  will  have  the  form 
Hap (z ) = A Y	 z−1  − b∗ 
M
k  . 
1 − bk z−1 
k=1 
The  poles  and  zeros  in  this  case  occur  at  conjugate  reciprocal  locations:  for  each 
pole at z = bk  there is a zero at z = 1/b∗k .  A zero at z = 0 (and associated pole at ∞) 
is obtained by setting bk  = ∞  in the corresponding factor above, after ﬁrst dividing 
both the numerator and denominator by bk ;  this results  in the corresponding factor 
in  (3.24)  being  just  z .  Again,  if  the  impulse  response  is  real-valued  then  every 
complex  pole  and  zeros  will  occur  in  a  conjugate  pair,  so  there  will  be  a  pole  at 
z  =  b∗ 
k  and  a  zero  at  z  = 1/bk .  An  example  of  a  pole-zero  diagram  (in  the  z 
plane)  for  a discrete-time  all-pass  system  is  shown  in Figure  (3.14).  It  is  once more 

(3.24) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

60  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

Im 

1 

−2 

−1 

1 

2 

Re

−1 

FIGURE  3.13  Typical  pole-zero  plot  for  a  continuous-time  all-pass  system. 

straightforward  to  verify  that  each  of  the  M  factors  in  (3.24)  has  unit  magnitude 
for  z = ejΩ . 
The  phase  of  a  continuous-time  all-pass  system  will  be  the  sum  of  the  phases  as­
sociated  with  each  of  the  M  factors  in  (3.22).  Assuming  the  system  is  causal  (in 
addition  to  being  stable),  then  for  each  of  these  factors  Re{ak }  <  0.  With  some 
∗ 
s+a
k  now  has  positive  group 
algebra  it  can  be  shown  that  each  factor  of  the  form 
s−ak 
delay at all frequencies, a property that we will make reference to shortly.  Similarly, 
assuming  causality  (in  addition  to  stability)  for  the  discrete-time  all-pass  system 
z −1 −b ∗ 
in  (3.24),  each  factor  of  the  form 
k  with  bk <  1  contributes  positive  group 
|
|
1−bk z−1 
delay  at  all  frequencies  (or  zero  group  delay  in  the  special  case  of  bk  =  0).  Thus, 
in  both  continuous- and  discrete-time,  the  frequency  response  of  a  causal  all-pass 
system  has  constant  magnitude  and  positive  group  delay  at  all  frequencies. 

3.3.2  Minimum-Phase  Systems 

In discrete-time, a stable system with a rational transfer function is called minimum-
phase  if  its  poles  and  zeros  are  all  inside  the  unit  circle,  i.e.,  have  magnitude  less 
than  unity.  This  is  equivalent  in  the  DT  case  to  the  statement  that  the  system  is 
stable  and  causal,  and  has  a  stable  and  causal  inverse. 

A  similar  deﬁnition  applies  in  the  case  of  a  stable  continuous-time  system  with  a 
rational  transfer  function.  Such  a  system  is  called  minimum-phase  if  its  poles  and 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  3.3 

All-Pass  and  Minimum-Phase  Systems  61 

Unit circle 

Im 

0.8 

−4/3 

−3/4

Re 

FIGURE  3.14  Typical  pole-zero  plot  for  a  discrete-time  all-pass  system. 

ﬁnite  zeros  are  in  the  left-half-plane,  i.e.,  have  real  parts  that  are  negative.  The 
system  is  therefore  necessarily  causal.  If  there  are  as many  ﬁnite  zeros  as  there  are 
poles,  then  a  CT  minimum-phase  system  can  equivalently  be  characterized  by  the 
statement  that  both  the  system  and  its  inverse  are  stable  and  causal,  just  as  we 
had  in  the  DT  case.  However,  it  is  quite  possible  —  and  indeed  common  —  for 
a  CT  minimum-phase  system  to  have  fewer  ﬁnite  zeros  than  poles.  (Note  that  a 
stable  CT  system  must  have  all  its  poles  at  ﬁnite  locations  in  the  s-plane,  since 
poles  at  inﬁnity  would  imply  that  the  output  of  the  system  involves  derivatives  of 
the  input, which  is  incompatible with stability.  Also, whereas  in the DT case a zero 
at  inﬁnity  is  clearly  outside  the  unit  circle,  in  the  CT  case  there  is  no  way  to  tell 
if  a  zero  at  inﬁnity  is  in  the  left  half  plane  or  not,  so  it  should  be  no  surprise  that 
the  CT  deﬁnition  involves  only  the  ﬁnite  zeros.) 

The use of the term ‘minimum phase’ is historical, and the property should perhaps 
more appropriately be termed ‘minimum group delay’, for reasons that we will bring 
out next.  To do this, we need a  fact that we shall shortly establish:  that any causal 
and  stable CT  system with  a  rational  transfer  function Hcs (s)  and  no  zeros  on  the 
imaginary  axis  can  be  represented  as  the  cascade  of  a  minimum-phase  system  and 
an  all-pass  system, 

Hcs (s) = Hmin (s)Hap (s)  . 

(3.25) 

Similarly,  in  the  DT  case,  provided  the  transfer  function  Hcs (z )  has  no  zeros  on 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

62  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

the  unit  circle,  it  can  be  written  as 

Hcs (z ) = Hmin (z )Hap (z )  . 

(3.26) 

The  frequency  response  magnitude  of  the  all-pass  factor  is  constant,  independent 
of frequency, and for convenience let us set this constant to unity.  Then from (3.25) 

|Hcs (jω)| =|Hmin (jω)|  ,  and 
grpdelay[Hcs (jω)] =grpdelay[Hmin (jω)] + grpdelay[Hap (jω)] 

(3.27a) 
(3.27b) 

and  similar  equations  hold  in  the  DT  case. 

We  will  see  in  the  next  section  that  the  minimum-phase  term  in  (3.25)  or  (3.26) 
can be uniquely determined  from  the magnitude of Hcs (jω),  respectively Hcs (ejΩ ). 
Consequently  all  causal,  stable  systems  with  the  same  frequency  response  magni­
tude  diﬀer  only  in  the  choice  of  the  all-pass  factor  in  (3.25)  or  (3.26).  However,  we 
have  shown  previously  that  all-pass  factors  must  contribute  positive  group  delay. 
Therefore we  conclude  from  (3.27b)  that  among  all  causal,  stable  systems with  the 
same  CT  frequency  response  magnitude,  the  one  with  no  all-pass  factors  in  (3.25) 
will  have  the minimum  group  delay.  The  same  result  holds  in  the  DT  case. 

(3.28) 

(3.29) 

We  shall  now  demonstrate  the  validity  of  (3.25);  the  corresponding  result  in  (3.26) 
for discrete time follows in a very similar manner.  Consider a causal, stable transfer 
function Hcs (s)  expressed  in  the  form 
QM1  (s − lk ) QM2  (s − ri )
Hcs (s) = A  k=1
i=1
QN 
n=1 (s − dn
)
where  the  dn ’s  are  the  poles  of  the  system,  the  lk ’s  are  the  zeros  in  the  left-half 
plane  and  the  ri ’s  are  the  zeros  in  the  right-half  plane.  Since  Hcs (s)  is  stable  and 
causal,  all  of  the  poles  are  in  the  left-half  plane  and  would  be  associated  with  the 
factor  Hmin (s)  in  (3.25),  as  would  be  all  of  the  zeros  lk .  We  next  represent  the 
right-half-plane  zeros  as 
Y  (s − ri )
Y 
M2
M2
M2
Y
(s − ri ) = 
(s + ri )
(s + ri ) 
i=1 
i=1 
i=1 
Since  Re{ri }  is  positive,  the  ﬁrst  factor  in  (3.29)  represents  left-half-plane  zeros. 
The second factor corresponds to all-pass terms with  left-half-plane poles, and with 
zeros  at  mirror  image  locations  to  the  poles.  Thus,  combining  (3.28)  and  (3.29), 
Hcs (s)  has  been  decomposed  according  to  (3.25)  where 
QM1  (s − lk ) QM2  (s + ri )
Hmin (s) = A  k=1
i=1
QN  (s − dn )
n=1
Hap (s) = Y  (s − ri ) 
M2
(s + ri )
i=1 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(3.30b) 

(3.30a) 

Section  3.4 

Spectral  Factorization  63 

EXAMPLE  3.3 

Causal,  stable  system  as  cascade  of  minimum-phase  and  all-pass 

Consider  a  causal,  stable  system  with  transfer  function 
(s − 1) 
(s + 2)(s + 3) 

Hcs  =

The  corresponding minimum-phase  and  all-pass  factors  are 

Hmin (s) = 

(s + 1) 
(s + 2)(s + 3) 
s − 1 
s + 1 

Hap (s) = 

(3.31) 

(3.32) 

(3.33) 

3.4  SPECTRAL  FACTORIZATION 

The  minimum-phase/all-pass  decomposition  developed  above  is  useful  in  a  variety 
of contexts.  One  that  is of particular  interest  to us  in  later chapters arises when we 
we  are  given  or  have measured  the magnitude  of  the  frequency  response  of  a  stable 
system  with  a  rational  transfer  function  H (s)  (and  real-valued  impulse  response), 
and  our  ob jective  is  to  recover  H (s)  from  this  information.  A  similar  task  may  be 
posed  in  the  DT  case,  but  we  focus  on  the  CT  version  here.  We  are  thus  given 
|H (jω)|2  = H (jω)H ∗ (jω) 
or,  since H ∗ (jω) = H (−jω), 
|H (jω)|2  = H (jω)H (−jω)  . 
Now  H (jω)  is H (s)  for  s = jω ,  and  therefore 
¯¯¯s=jω 
For  any  numerator  or  denominator  factor  (s − a)  in  H (s),  there  will  be  a  corre­
sponding  factor  (−s − a)  in  H (s)H (−s).  Thus  H (s)H (−s)  will  consist  of  factors 
in  the  numerator  or  denominator  of  the  form  (s − a)(−s − a) = −s2  + a2 ,  and  will 
therefore  be  a  rational  function  of  s2 .  Consequently  H (jω) 2  will  be  a  rational 
|
|
function  of ω2 .  Thus,  if we  are  given  or  can  express  H (jω) 2  as  a  rational  function 
|
|
of ω2 , we can obtain the product H (s)H (−s) by making the substitution ω2  = −s . 
2
The product H (s)H (−s) will always have  its zeros in pairs that are mirrored across 
the imaginary axis of the s-plane, and similarly for its poles.  For any pole or zero of 
H (s)H (−s) at the real value a,  there will be another at the mirror  image −a, while 
for  any pole  or  zero  at  the  complex value  q ,  there will be  others  at  q∗ , −q  and −q∗ , 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

H (jω) 2  = H (s)H (−s)
|

(3.35) 

|

(3.34) 

(3.36) 

64  Chapter  3 

Transform  Representation  of  Signals  and  LTI  Systems 

forming  a  complex  conjugate  pair  (q , q∗ )  and  its  mirror  image  (−q∗ , −q).  We  then 
need  to  assign  one  of  each  mirrored  real  pole  and  zero  and  one  of  each  mirrored 
conjugate  pair  of  poles  and  zeros  to H (s),  and  the  mirror  image  to H (−s). 
If  we  assume  (or  know)  that  H (s)  is  causal,  in  addition  to  being  stable,  then 
we  would  assign  the  left-half  plane  poles  of  each  pair  to  H (s).  With  no  further 
knowledge or assumption we have no guidance on the assignment of the zeros other 
than  the  requirement  of  assigning  one  of  each  mirror  image  pair  to  H (s)  and  the 
other  to H (−s).  If  we  further  know  or  assume  that  the  system  is minimum-phase, 
then the  left-half-plane zeros  from each mirrored pair are assigned to H (s), and the 
right-half-plane  zeros  to  H (−s).  This  process  of  factoring  H (s)H (−s)  to  obtain 
H (s)  is  referred  to  as  spectral  factorization. 

EXAMPLE  3.4 

Spectral  factorization 

Consider a  frequency response magnitude that has been measured or approximated 
as 

(3.37) 

(3.38) 

ω2  + 1 
|H (jω)|2  = 
ω4  + 13ω2  + 36 
Making  the  substitution  ω2  = −s2 ,  we  obtain 
−s2  + 1 
H (s)H (−s) = 
(−s2  + 4)(−s2  + 9) 
which  we  further  factor  as 

= 

ω2  + 1 
(ω2  + 4)(ω2  + 9) 

(s + 1)(−s + 1) 
H (s)H (−s) = 
(s + 2)(−s + 2)(s + 3)(−s + 3) 
It  now  remains  to  associate  appropriate  factors  with  H (s)  and  H (−s).  Assuming 
the  system  is  causal  in  addition  to  being  stable,  the  two  left-half  plane  poles  at 
s = −2  and  s = −3  must  be  associated  with  H (s).  With  no  further  assumptions, 
either one of  the numerator  factors can be associated with H (s) and  the other with 
H (−s).  However,  if  we  know  or  assume  that  H (s)  is  minimum  phase,  then  we 
would  assign  the  left-half  plane  zero  to H (s),  resulting  in  the  choice 

(3.39) 

H (s) = 

(s + 1) 
(s + 2)(s + 3) 

(3.40) 

In the discrete-time case, a similar development leads to an expression for H (z )H (1/z ) 
from knowledge of  |H (ejΩ )|2 .  The  zeros of H (z )H (1/z ) occur  in  conjugate  recipro­
cal  pairs,  and  similarly  for  the  poles.  We  again  have  to  split  such  conjugate  recip­
rocal  pairs,  assigning  one  of  each  to H (z ),  the  other  to H (1/z ),  based  on whatever 
additional  knowledge  we  have.  For  instance,  if  H (z )  is  known  to  be  causal  in  ad­
dition  to  being  stable,  then  all  the  poles  of  H (z )H (1/z )  that  are  in  the  unit  circle 
are  assigned  to  H (z );  and  if  H (z )  is  known  to  be  minimum  phase  as  well,  then  all 
the  zeros  of  H (z )H (1/z )  that  are  in  the  unit  circle  are  assigned  to H (z ). 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

4 

State-Space Models 

4.1  INTRODUCTION 

In  our  discussion  of  system  descriptions  up  to  this  point,  we  have  emphasized 
and  utilized  system  models  that  represent  the  transformation  of  input  signals  into 
output  signals.  In  the  case  of  linear  and  time-invariant  (LTI)  models,  our  focus 
has  been  on  the  impulse  response,  frequency  response  and  transfer  function.  Such 
input-output  models  do  not  directly  consider  the  internal  behavior  of  the  systems 
they  model. 

In  this  chapter  we  begin  a  discussion  of  system  models  that  considers  the  internal 
dynamical behavior of the system as well as the input-output characteristics.  Inter­
nal  behavior  can  be  important  for  a  variety  of  reasons.  For  example,  in  examining 
issues  of  stability,  a  system  can  be  stable  from  an  input-output  perspective  but 
hidden  internal  variables  may  be  unstable,  yielding  what  we  would  want  to  think 
of  as  unstable  system  behavior. 

We introduce in this chapter an important model description that highlights internal 
behavior of the system and is specially suited to representing causal systems for real-
time  applications  such  as  control.  Speciﬁcally,  we  introduce  state-space models  for 
ﬁnite-memory (or lumped) causal systems.  These models exist for both continuous-
time (CT) and discrete-time (DT) systems, and for nonlinear, time-varying systems 
—  although  our  focus  will  be  on  the  LTI  case. 

Having  a  state-space  model  for  a  causal  DT  system  (similar  considerations  apply 
in  the CT  case)  allows  us  to  answer  a  question  that  gets  asked  about  such  systems 
in  many  settings:  Given  the  input  value  x[n]  at  some  arbitrary  time  n,  how  much 
information  do  we  really  need  about  past  inputs,  i.e.,  about  x[k ]  for  k < n,  in 
order  to determine  the present output y [n] ?  As  the  system  is  causal, we know  that 
having  all  past  x[k ]  (in  addition  to  x[n])  will  suﬃce,  but  do  we  actually  need  this 
much  information?  This question addresses the  issue of memory  in the system, and 
is  a  worthwhile  question  for  a  variety  of  reasons. 

For example,  the answer gives us an  idea of the complexity, or number of degrees of 
freedom,  associated  with  the  dynamic  behavior  of  the  system.  The  more  informa­
tion we need about past  inputs  in order  to determine  the present output,  the  richer 
the  variety  of  possible  output  behaviors,  i.e.,  the more ways we  can  be  surprised  in 
the  absence  of  information  about  the  past. 

Furthermore,  in  a  control  application,  the  answer  to  the  above  question  suggests 
the  required  degree  of  complexity  of  the  controller,  because  the  controller  has  to 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

65

66  Chapter  4 

State-Space  Models 

L 

vL 

+ 

iL 
� 

− 

� 
iR1 

+ 

+ 
− 

v 

vR1 

R1 

− 
+ 

vC 
− 

C 

iC 
� 

FIGURE  4.1  RLC  circuit. 

� 
iR2 
+ 

R2 

vR2 

− 

remember enough about the past to determine the eﬀects of present control actions 
on  the  response  of  the  system.  In  addition,  for  a  computer  algorithm  that  acts 
causally  on  a  data  stream,  the  answer  to  the  above  question  suggests  how  much 
memory  will  be  needed  to  run  the  algorithm. 

With  a  state-space  description,  everything  about  the  past  that  is  relevant  to  the 
present  and  future  is  summarized  in  the  present  state,  i.e.,  in  the  present  values  of 
a  set  of  state  variables.  The  number  of  state  variables,  which  we  refer  to  as  the 
order  of  the  model,  thus  indicates  the  amount  of  memory  or  degree  of  complexity 
associated  with  the  system  or model. 

4.2  INPUT-OUTPUT  AND  INTERNAL  DESCRIPTIONS 

As  a  prelude  to  developing  the  general  form  of  a  state-space  model  for  an  LTI 
system,  we  present  two  examples,  one  in  CT  and  the  other  in  DT. 

4.2.1  An  RLC  circuit 

Consider  the  RLC  circuit  shown  in  Figure  4.1.  We  have  labeled  all  the  component 
voltages  and  currents  in  the  ﬁgure. 

The  deﬁning  equations  for  the  components  are: 

= vL (t)

diL (t)
L 
dt

dvC (t)

C 
dt 
vR1 (t) = R1 iR1 (t) 
vR2 (t) = R2 iR2 (t)  , 

= iC (t)

(4.1) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  4.2 

Input-output  and  internal  descriptions  67 

while the voltage source is deﬁned by the condition that its voltage is v(t) regardless 
of  its  current  i(t).  Kirchhoﬀ ’s  voltage  and  current  laws  yield 

v(t) = vL (t) + vR2 (t) 
vR2 (t) = vR1 (t) + vC (t) 
i(t) = iL (t) 
iL (t) = iR1 (t) + iR2 (t) 
iR1 (t) = iC (t)  . 

(4.2) 

All  these equations  together constitute a detailed and explicit  representation of  the 
circuit. 

H (s) = 

Y (s) 
X (s)

= 

s2  + α

Let  us  take  the  voltage  source  v(t)  as  the  input  to  the  circuit;  we  shall  also  denote 
this  by  x(t),  our  standard  symbol  for  inputs.  Choose  any  of  the  circuit  voltages 
or  currents  as  the  output —  let  us  choose  vR2 (t)  for  this  example,  and  also  denote 
it  by  y(t),  our  standard  symbol  for  outputs.  We  can  then  combine  (4.1)  and  (4.2) 
using,  for  example,  Laplace  transforms,  in  order  to  obtain  a  transfer  function  or 
a  linear  constant-coeﬃcient  diﬀerential  equation  relating  the  input  and  output. 
The  coeﬃcients  in  the  transfer  function  or  diﬀerential  equation  will,  of  course  be 
functions  of  the  values  of  the  components  in  the  circuit.  The  resulting  transfer 
function H (s)  from  input  to  output  is 
1  ´ 
³ 
R1 
α L  s +  LC 
³ 
R1 ´
1 
+ 
s + α
L 
R2C
where  α  denotes  the  ratio  R2/(R1  + R2 ).  The  corresponding  input-output  diﬀer­
ential  equation  is 
³  1 
³  1  ´
³ R1 ´ dx(t) 
³  1  ´
R1 ´ dy(t) 
+ 
+ α
x(t)  .  (4.4) 
+ α
dt 
LC 
dt 
LC 
R2C
L
L
An  important  characteristic  of  a  circuit  such  as  in  Figure  4.1  is  that  the  behavior 
for  a  time  interval  beginning  at  some  t  is  completely  determined  by  the  input 
tra jectory  in  that  interval  as  well  as  the  inductor  currents  and  capacitor  voltages 
at  time  t.  Thus,  for  the  speciﬁc  circuit  in  Figure  4.1,  in  determining  the  response 
for  times  ≥  t,  the  relevant  past  history  of  the  system  is  summarized  in  iL (t)  and 
vC (t).  The  inductor  currents  and  capacitor  voltages  in  such  a  circuit  at  any  time 
t  are  commonly  referred  to  as  state  variables,  and  the  particular  set  of  values  they 
take  constitutes  the  state  of  the  system  at  time  t.  This  state,  together  with  the 
input  from  t  onwards,  are  suﬃcient  to  completely  determine  the  response  at  and 
beyond  t. 

d2 y(t) 
+ α
dt2 

y(t) = α

1 
LC 

(4.3) 

The  concept  of  state  for  dynamical  systems  is  an  extremely  powerful  one.  For  the 
RLC circuit of Figure 4.1 it motivates us to reduce the full set of equations (4.1) and 
(4.2)  into  a  set  of  equations  involving  just  the  input,  output,  and  internal  variables 
iL (t)  and  vC (t).  Speciﬁcally,  a  description  of  the  desired  form  can  be  found  by 
appropriately  eliminating  the  other  variables  from  (4.1)  and  (4.2),  although  some 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

68  Chapter  4 

State-Space  Models 

attention  is  required  in  order  to  carry  out  the  elimination  eﬃciently.  With  this, 
we  arrive  at  a  condensed  description,  written  here  using  matrix  notation,  and  in  a 
format  that  we  shall  encounter  frequently  in  this  chapter  and  the  next  two: 
µ	
1/L  ¶ 
iL (t)  ¶ µ 
diL (t)/dt  ¶ µ 
¶ µ 
−αR1 /L 
−α/L 
+ 
v(t)  . 
dvC (t)/dt  = 
0 
−1/(R1  + R2 )C
α/C 
vC (t)
The use of matrix notation  is a convenience; we could of course have simply written 
the  above  description  as  two  separate  but  coupled  ﬁrst-order  diﬀerential  equations 
with  constant  coeﬃcients. 

(4.5) 

We  shall  come  to  appreciate  the  properties  and  advantages  of  a  description  in  the 
form  of  (4.5),  referred  to  as  a CT  (and,  in  this  case,  LTI)  state-space  form.  Its  key 
feature  is  that  it  expresses  the  rates  of  change  of  the  state  variables  at  any  time  t 
as  functions  (in  this  case,  LTI  functions)  of  their  values  and  those  of  the  input  at 
that  same  time  t. 

As  we  shall  see  later,  the  state-space  description  can  be  used  to  solve  for  the  state 
variables iL (t) and vC (t), given the input v(t) and appropriate auxiliary information 
(speciﬁcally,  initial  conditions  on  the  state  variables).  Furthermore,  knowledge  of 
iL (t),  vC (t)  and  v(t)  suﬃces  to  reconstruct  all  the  other  voltages  and  currents  in 
the  circuit  at  time  t.  In  particular,  any  output  variable  can  be  written  in  terms  of 
the  retained  variables.  For  instance,  if  the  output  of  interest  for  this  circuit  is  the 
voltage  vR2 (t)  across  R2 ,  we  can  write  (again  in  matrix  notation) 
αR1  α  ¢ µ 
iL (t)  ¶ 
vR2 (t) = ¡ 
+ ( 0 ) v(t) . 
vC (t) 
For  this  particular  example,  the  output  does  not  involve  the  input  v(t)  directly — 
hence  the  term  ( 0 )  v(t)  in  the  above  output  equation  —  but  in  the  general  case 
the  output  equation will  involve  present  values  of  any  inputs  in  addition  to  present 
values  of  the  state  variables. 

(4.6) 

4.2.2  A  delay-adder-gain  system 

For  DT  systems,  the  role  of  state  variables  is  similar  to  the  role  discussed  in  the 
preceding  subsection  for  CT  systems.  We  illustrate  this  with  the  system  described 
by  the  delay-adder-gain  block  diagram  shown  in  Figure  4.2.2.  The  corresponding 
detailed  equations  relating  the  indicated  signals  are 

q1 [n + 1] = q2 [n] 
q2 [n + 1] = p[n] 
p[n] = x[n] − (1/2)q1 [n] + (3/2)q2 [n] 
y [n] = q2 [n] + p[n]  . 

(4.7) 

The  equations  in  (4.7)  can  be  combined  together  using,  for  example,  z-transform 
methods,  to  obtain  the  transfer  function  or  linear  constant-coeﬃcient  diﬀerence 
equation  relating  input  and  output: 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  4.2 

Input-output  and  internal  descriptions  69 

x[n] 

�

+ 
� 
� 

�1 

p[n] 

� 

�y [n] 

1 �  + 
� 

� 
D 
q2 [n] 
� 

� 
D 
q1 [n] 

1 

� 
3/2 

� 
−1/2 

FIGURE  4.2  Delay-adder-gain  block  diagram. 

and 

H (z ) = 

Y (z ) 
X (z )

= 

1 + z−1 
2 z−1  +  1
1 −  3
2 z−2 

y [n] − 

3
2

1 
y [n − 1] +  y [n − 2] = x[n] + x[n − 1]  . 
2 

(4.8) 

(4.9) 

The  response  of  the  system  in  an  interval  of  time ≥ n  is  completely  determined  by 
the input for times ≥ n and the values q1 [n] and q2 [n] that are stored at the outputs 
of  the  delay  elements  at  time  n.  Thus,  as  with  the  energy  storage  elements  in  the 
circuit of Figure 4.1,  the delay elements  in  the delay-adder-gain  system capture  the 
state  of  the  system  at  any  time,  i.e.,  summarize  all  the  past  history  with  respect 
to  how  it  aﬀects  the  present  and  future  response  of  the  system.  Consequently,  we 
condense  (4.7)  in  terms  of  only  the  input,  output  and  state  variables  to  obtain  the 
following  matrix  equations: 
0  ¶ 
q1 [n + 1]  ¶ µ 
q1 [n]  ¶ µ 
1  ¶ µ 
µ 
q2 [n + 1]  = 
x[n] 
+
3/2 
1 
q2 [n]
µ 
q1 [n]  ¶ 
q2 [n]  + (1)x[n]  . 
5/2 ) 
In  this  case  it  is  quite  easy  to  see  that,  if we  are  given  the  values  q1 [n]  and  q2 [n]  of 
the  state  variables  at  some  time  n,  and  also  the  input  tra jectory  from  n  onwards, 
i.e.,  x[n]  for  times  ≥  n,  then  we  can  compute  the  values  of  the  state  variables  for 
all  times  > n,  and  the  output  for  all  times  ≥ n.  All  that  is  needed  is  to  iteratively 
apply  (4.10)  to  ﬁnd  q1 [n + 1]  and  q2 [n + 1],  then  q1 [n + 2]  and  q2 [n + 2],  and  so  on 
for  increasing  time  arguments,  and  to  use  (4.11)  at  each  time  to  ﬁnd  the  output. 

y [n] = (  −1/2

0
−1/2

(4.10) 

(4.11) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

70  Chapter  4 

State-Space  Models 

4.3  STATE-SPACE  MODELS 

As  illustrated  in  Sections  4.2.1  and  4.2.2,  it  is  often  natural  and  convenient,  when 
studying  or  modeling  physical  systems,  to  focus  not  just  on  the  input  and  output 
signals but rather to describe the interaction and time-evolution of several key vari­
ables  or  signals  that  are  associated  with  the  various  component  processes  internal 
to the system.  Assembling the descriptions of these components and their intercon­
nections  leads  to  a  description  that  is  richer  than  an  input–output  description.  In 
particular,  in  Sections  4.2.1  and  4.2.2  the  description  is  in  terms  of  the  time  evolu­
tion  of  variables  referred  to  as  the  state  variables, which  completely  capture  at  any 
time  the  past  history  of  the  system  as  it  aﬀects  the  present  and  future  response. 
We  turn  now  to  a  more  formal  deﬁnition  of  state-space  models  in  the  DT  and  CT 
cases,  followed  by  a  discussion  of  two  deﬁning  characteristics  of  such models. 

4.3.1  DT  State-Space Models 

A  state-space  model  is  built  around  a  set  of  state  variables;  the  number  of  state 
variables  in  a  model  or  system  is  referred  to  as  its  order.  Although  we  shall  later 
cite examples of distributed or  inﬁnite-order  systems, we  shall only deal with  state-
space  models  of  ﬁnite  order,  which  are  also  referred  to  as  lumped  systems.  For  an 
Lth-order  model  in  the  DT  case,  we  shall  generically  denote  the  values  of  the  L 
· · · 
state  variables  at  time  n  by  q1 [n], q2 [n], 
, qL [n].  It  is  convenient  to  gather  these 
variables  into  a  state  vector:

q1 [n]  

 



[n] 
q[n] =  q2
 . 
 .  
.
.   
 
qL [n] 
The  value  of  this  vector  constitutes  the  state  of  the model  or  system  at  time  n. 
A  DT  LTI  state-space  model  with  single  (i.e.,  scalar)  input  x[n]  and  single  output 
y [n]  takes  the  following  form,  written  in  compact  matrix  notation: 

(4.12) 

q[n + 1] = Aq[n] + bx[n]  , 
(4.13) 
y [n] = c T q[n] + dx[n] . 
(4.14) 
In  (4.13),  A  is  an  L × L  matrix,  b  is  an  L × 1  matrix  or  column-vector,  and  cT  is 
a 1 × L matrix  or  row-vector,  with  the  superscript  T  denoting  transposition  of  the 
column  vector  c  into  the  desired  row  vector.  The  quantity  d  is  a  1 × 1 matrix,  i.e., 
a  scalar.  The  entries  of  all  these matrices  in  the  case  of  an  LTI model  are  numbers 
or  constants  or  parameters,  so  they  do  not  vary  with  n.  Note  that  the  model  we 
arrived  at  in  (4.10)  and  (4.11)  of  Section  4.2.2  has  precisely  the  above  form.  We 
refer to (4.13) as the state evolution equation, and to (4.14) as the output equation. 
These  equations  respectively  express  the  next  state  and  the  current  output  at  any 
time  as  an  LTI  combination  of  the  current  state  variables  and  current  input. 

Generalizations  of  the  DT  LTI  State-Space Model.  There  are  various  nat­

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  4.3 

State-Space  Models  71 

ural  generalizations  of  the  above  DT  LTI  single-input,  single-output  state-space 
model.  A  multi-input  DT  LTI  state-space  model  replaces  the  single  term  bx[n]  in 
(4.13)  by  a  sum  of  terms,  b1x1 [n] +  + bM xM [n],  where  M  is  the  number  of 
· · · 
inputs.  This  corresponds  to  replacing  the  scalar  input  x[n]  by  an  M -component 
vector x[n] of  inputs, with a  corresponding  change of b  to a matrix B of dimension 
L × M .  Similarly,  for  a multi-output  DT  LTI  state-space model,  the  single  output 
equation  (4.14)  is  replaced by  a  collection  of  such  output  equations,  one  for  each  of 
the  P  outputs.  Equivalently,  the  scalar  output  y [n]  is  replaced  by  a  P -component 
vector  y[n]  of  outputs,  with  a  corresponding  change  of  cT  and  d  to  matrices  CT 
and D  of  dimension  P  × L  and  P  × M  respectively. 
A  linear  but  time-varying  DT  state-space  model  takes  the  same  form  as  in  (4.13) 
and  (4.14)  above,  except  that  some  or  all  of  the matrix  entries  are  time-varying.  A 
linear  but  periodically  varying  model  is  a  special  case  of  this,  with  matrix  entries 
that all vary periodically with a common period.  A nonlinear, time-invariant model 
expresses  q[n + 1]  and  y[n]  as  nonlinear  but  time-invariant  functions  of  q[n]  and 
x[n],  rather  than  as  the  LTI  functions  embodied  by  the  matrix  expressions  on  the 
right-hand-sides  of  (4.13)  and  (4.14).  A  nonlinear,  time-varying  model  expresses 
q[n + 1] and y[n] as nonlinear,  time-varying  functions of q[n] and x[n], and one can 
also  deﬁne  nonlinear,  periodically  varying models  as  a  particular  case  in  which  the 
time-variations  are  periodic  with  a  common  period. 

4.3.2  CT  State-Space Models 

Continuous-time  state-space  descriptions  take  a  very  similar  form  to  the  DT  case. 
We  denote  the  state  variables  as  qi (t),  i = 1, 2, ..., L,  and  the  state  vector  as 
q1 (t)   
 


(t) 
q(t) =  q2
 . 
 .  
.
.   
 
qL (t) 
Whereas  in  the  DT  case  the  state  evolution  equation  expresses  the  state  vector  at 
the  next  time  step  in  terms  of  the  current  state  vector  and  input  values,  in  CT 
the  state  evolution  equation  expresses  the  rates  of  change  (i.e.,  derivatives)  of  each 
of  the  state  variables  as  functions  of  the  present  state  and  inputs.  The  general 
Lth-order  CT  LTI  state-space  representation  thus  takes  the  form 

(4.15) 

dq(t) 
dt 

= q˙ (t) = Aq(t) + bx(t)  , 

y(t) = c T q(t) + dx(t)  , 

(4.16) 

(4.17) 

where dq(t)/dt = q˙ (t) denotes the vector whose entries are the derivatives, dqi (t)/dt, 
of  the  corresponding  entries,  qi (t),  of  q(t).  Note  that  the  model  in  (4.5)  and  (4.6) 
of  Section  4.2.1  is  precisely  of  the  above  form. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

72  Chapter  4 

State-Space  Models 

Generalizations to multi-input and multi-output models, and to linear and nonlinear 
time-varying or periodic models, can be described just as in the case of DT systems, 
by  appropriately  relaxing  the  restrictions  on  the  form  of  the  right-hand  sides  of 
(4.16),  (4.17).  We  shall  see  an  example  of  a  nonlinear  time-invariant  state-space 
model  in  Section  1. 

4.3.3  Characteristics  of  State-Space Models 

The  designations  of  “state”  for  q[n]  or  q(t),  and  of  “state-space  description”  for 
(4.13),  (4.14)  and  (4.16),  (4.17) —  or  for  the  various  generalizations  of  these  equa­
tions —  follow  from  the  following  two  key  properties  of  such models. 

State  Evolution  Property:  The  state  at  any  initial  time,  along  with  the  inputs 
over any interval from that initial time onwards, determine the state over that 
entire  interval.  Everything  about  the  past  that  is  relevant  to  the  future  state 
is  embodied  in  the  present  state. 

Instantaneous  Output  Property:  The  outputs  at  any  instant  can be written  in 
terms  of  the  state  and  inputs  at  that  same  instant. 

The  state  evolution  property  is  what  makes  state-space  models  particularly  well 
suited  to  describing  causal  systems.  In  the  DT  case,  the  validity  of  this  state 
evolution property  is evident  from the state evolution equation (4.13), which allows 
us  to update q[n]  iteratively,  going  from  time n  to  time n + 1 using only knowledge 
of  the  present  state  and  input.  The  same  argument  can  also  be  applied  to  the 
generalizations  of  DT  LTI models  that  we  outlined  earlier. 

The  state  evolution  property  should  seem  intuitively  reasonable  in  the  CT  case  as 
well.  Speciﬁcally, knowledge of both the state and the rate of change of the state at 
any  instant  allows  us  to  compute  the  state  after  a  small  increment  in  time.  Taking 
this  small  step  forward,  we  can  re-evaluate  the  rate  of  change  of  the  state,  and 
step  forward  again.  A  more  detailed  proof  of  this  property  in  the  general  nonlin­
ear  and/or  time-varying  CT  case  essentially  proceeds  this  way,  and  is  treated  in 
texts  that  deal  with  the  existence  and  uniqueness  of  solutions  of  diﬀerential  equa­
tions.  These  more  careful  treatments  also  make  clear  what  additional  conditions 
are  needed  for  the  state  evolution  property  to  hold  in  the  general  case.  However, 
the  CT  LTI  case  is  much  simpler,  and  we  shall  demonstrate  the  state  evolution 
property  for  this  class  of  state-space  models  in  the  next  chapter,  when  we  show 
how  to  explicitly  solve  for  the  behavior  of  such  systems. 

The  instantaneous  output  property  is  immediately  evident  from  the  output  equa­
tions (4.14), (4.17).  It also holds for the various generalizations of basic single-input, 
single-output  LTI models  that  we  listed  earlier. 

The  two properties  above may be  considered  the deﬁning  characteristics  of  a  state-
space model.  In eﬀect, what we do  in setting up a state-space model  is to  introduce 
the  additional  vector  of  state  variables  q[n]  or  q(t),  to  supplement  the  input  vari­
ables  x[n]  or  x(t)  and  output  variables  y [n]  or  y(t).  This  supplementation  is  done 
precisely  in  order  to  obtain  a  description  that  satisﬁes  the  two  properties  above. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  4.4 

Equilibria  and  Linearization  of  Nonlinear  State-Space  Models  73 

Often there are natural choices of state variables suggested directly by the particular 
context or application.  In both DT and CT  cases,  state variables are  related  to  the 
“memory”  of  the  system.  In  many  physical  situations  involving  CT  models,  the 
state  variables  are  associated  with  energy  storage,  because  this  is  what  is  carried 
over  from  the  past  to  the  future.  Natural  state  variables  for  electrical  circuits  are 
thus  the  inductor  currents  and  capacitor  voltages,  as  turned  out  to  be  the  case  in 
Section 4.2.1.  For mechanical systems, natural state variables are the positions and 
velocities  of  all  the  masses  in  the  system  (corresponding  respectively  to  potential 
energy and kinetic energy variables), as we will see  in  later examples.  In the case of 
a CT integrator-adder-gain block diagram, the natural state variables are associated 
with the outputs of the integrators, just as in the DT case the natural state variables 
of  a  delay-adder-gain model  are  the  outputs  of  the  delay  elements,  as  was  the  case 
in  the  example  of  Section  4.2.2. 

In  any  of  the  above  contexts,  one  can  choose  any  alternative  set  of  state  variables 
that  together  contain  exactly  the  same  information.  There  are  also  situations  in 
which  there  is  no  particularly  natural  or  compelling  choice  of  state  variables,  but 
in  which  it  is  still  possible  to  deﬁne  supplementary  variables  that  enable  a  valid 
state-space  description  to  be  obtained. 

Our  discussion  of  the  two  key  properties  above  —  and  particularly  of  the  role  of 
the  state  vector  in  separating  past  and  future —  suggests  that  state-space  models 
are particularly  suited  to describing causal  systems.  In  fact,  state-space models are 
almost  never  used  to  describe  non-causal  systems.  We  shall  always  assume  here, 
when  dealing  with  state-space  models,  that  they  represent  causal  systems.  Al­
though causality  is not a central  issue  in analyzing many aspects of communication 
or  signal  processing  systems,  particularly  in  non-real-time  contexts,  it  is  generally 
central  to  simulation  and  control  design  for  dynamic  systems.  It  is  accordingly  in 
such dynamics  and  control  settings  that  state-space descriptions ﬁnd  their  greatest 
value  and  use. 

4.4	 EQUILIBRIA  AND  LINEARIZATION  OF 
NONLINEAR  STATE-SPACE  MODELS 

An  LTI  state-space  model most  commonly  arises  as  an  approximate  description  of 
the  local (or “small-signal”) behavior of a nonlinear time-invariant model,  for small 
deviations of its state variables and inputs from a set of constant equilibrium values. 
In  this  section  we  present  the  conditions  that  deﬁne  equilibrium,  and  describe  the 
role  of  linearization  in  obtaining  the  small-signal  model  at  this  equilibrium. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

74  Chapter  4 

State-Space  Models 

4.4.1  Equilibrium 

, 

. 

(4.18) 

(4.19) 

To  make  things  concrete,  consider  a  DT  3rd-order  nonlinear  time-invariant  state-
space  system,  of  the  form 
´ 
³
q1 [n + 1] = f1  q1 [n], q2 [n], q3 [n], x[n]
´ 
³
q2 [n + 1] = f2  q1 [n], q2 [n], q3 [n], x[n]
´ 
³
q3 [n + 1] = f3  q1 [n], q2 [n], q3 [n], x[n]
with  the  output  y [n]  deﬁned  by  the  equation 
´ 
³
y [n] = g q1 [n], q2 [n], q3 [n], x[n]
The  state  evolution  functions  fi (  ),  for  i  = 1, 2, 3,  and  the  output  function  g( )
· 
·
are  all  time-invariant  nonlinear  functions  of  the  three  state  variables  qi [n]  and  the 
input x[n].  (Time-invariance of the functions simply means that they combine their 
arguments  in  the  same  way,  regardless  of  the  time  index  n.)  The  generalization  to 
an  Lth-order  description  should  be  clear.  In  vector  notation,  we  can  simply  write 
´ 
´ 
³
³
q[n + 1] = f q[n], x[n]
y [n] = g q[n], x[n]
where  for  our  3rd-order  case 
f1 ( )   
 
· 
f (  ) =   f2 ( )    . 
· 
·
f3 ( )· 
Suppose  now  that  the  input  x[n]  is  constant  at  the  value  x  for  all  n.  The  corre­
sponding  state  equilibrium  is  a  state  value  q  with  the  property  that  if  q[n] =  q 
with  x[n] = x,  then  q[n + 1] = q.  Equivalently,  the  point  q  in  the  state  space  is  an 
equilibrium  (or  equilibrium  point)  if,  with  x[n]  ≡  x  for  all  n  and  with  the  system 
initialized  at  q,  the  system  subsequently  remains  ﬁxed  at  q.  From  (4.20),  this  is 
equivalent  to  requiring 

, 

(4.20) 

,

(4.21) 

The  corresponding  equilibrium  output  is 

q = f (q, x)  . 

y = g(q, x)  . 

(4.22) 

(4.23) 

In  deﬁning  an  equilibrium,  no  consideration  is  given  to  what  the  system  behavior 
is  in  the  vicinity  of  the  equilibrium  point,  i.e.,  of  how  the  system  will  behave  if 
initialized  close  to  —  rather  than  exactly  at  —  the  point  q.  That  issue  is  picked 
up  when  one  discusses  local  behavior,  and  in  particular  local  stability,  around  the 
equilibrium. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  4.4 

Equilibria  and  Linearization  of  Nonlinear  State-Space  Models  75 

In  the  3rd-order  case  above,  and  given  x,  we would  ﬁnd  the  equilibrium  by  solving 
the  following  system  of  three  simultaneous  nonlinear  equations  in  three  unknowns: 

q1  = f1 (q1 , q2 , q3 , x) 
q2  = f2 (q1 , q2 , q3 , x) 
q3  = f3 (q1 , q2 , q3 , x)  . 

(4.24) 

There is no guarantee in general that an equilibrium exists for the speciﬁed constant 
input x, and there is no guarantee of a unique equilibrium when an equilibrium does 
exist. 

We  can  apply  the  same  idea  to  CT  nonlinear  time-invariant  state-space  systems. 
Again  consider  the  concrete  case  of  a  3rd-order  system: 
´ 
³
q˙1 (t) = f1  q1 (t), q2 (t), q3 (t), x(t)
´ 
³
q˙2 (t) = f1  q1 (t), q2 (t), q3 (t), x(t)
´ 
³
q˙3 (t) = f1  q1 (t), q2 (t), q3 (t), x(t)
´ 
³
, 
y(t) = g q1 (t), q2 (t), q3 (t), x(t)
´ 
´ 
³
³
y(t) = g q(t), x(t)
q˙ (t) = f q(t), x(t)
Deﬁne  the equilibrium q again as a state value that  the system does not move  from 
when  initialized  there,  and  when  the  input  is  ﬁxed  at  x(t) =  x.  In  the  CT  case, 
what  this  requires  is  that  the  rate  of  change  of  the  state,  namely  q˙ (t),  is  zero  at 
the  equilibrium,  which  yields  the  condition 

or  in  vector  notation, 

(4.26) 

. 

(4.27) 

, 

(4.25) 

with 

,

For  the  3rd-order  case,  this  condition  takes  the  form 

0 = f (q, x)  . 

(4.28) 

0 = f1 (q1 , q2 , q3 , x) 
0 = f2 (q1 , q2 , q3 , x) 
0 = f3 (q1 , q2 , q3 , x)  , 

(4.29) 

which  is  again  a  set  of  three  simultaneous  nonlinear  equations  in  three  unknowns, 
with  possibly  no  solution  for  a  speciﬁed  x,  or  one  solution,  or many. 

4.4.2  Linearization 

We  now  examine  system  behavior  in  the  vicinity  of  an  equilibrium.  Consider  once 
more the 3rd-order DT nonlinear system (4.18), and suppose that  instead of x[n] ≡ 
x,  we  have  x[n]  perturbed  or  deviating  from  this  by  a  value  xe[n],  so 
xe[n] = x[n] − x . 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(4.30) 

76  Chapter  4 

State-Space  Models 

(4.31) 

The  state  variables  will  correspondingly  be  perturbed  from  their  respective  equi­
librium  values  by  amounts  denoted  by 
qei [n] = qi [n] − q i 
for  i = 1, 2, 3  (or more generally  i = 1, 
· · · 
, L),  and  the output will be perturbed by 
ye[n] = y [n] − y . 
Our  ob jective  is  to  ﬁnd  a  model  that  describes  the  behavior  of  these  various  per­
turbations  from  equilibrium. 
The  key  to  ﬁnding  a  tractable  description  of  the  perturbations  or  deviations  from 
equilibrium  is  to  assume  they  are  small,  thereby  permitting  the  use  of  truncated 
Taylor  series  to  provide  good  approximations  to  the  various  nonlinear  functions. 
Truncating  the  Taylor  series  to  ﬁrst  order,  i.e.,  to  terms  that  are  linear  in  the 
deviations,  is  referred  to  as  linearization,  and  produces  LTI  state-space  models  in 
our  setting. 

(4.32) 

To  linearize  the  original  DT  3rd-order  nonlinear model  (4.18),  we  rewrite  the  vari­
ables  appearing  in  that  model  in  terms  of  the  perturbations,  using  the  quantities 
deﬁned  in  (4.30),  (4.31),  and  then  expand  in Taylor  series  to  ﬁrst  order  around  the 
equilibrium  values: 
´ 
³
q i  + qei [n + 1] = fi  q1  + qe1 [n], q2  + qe2 [n], q3  + qe3 [n], x + xe[n]
for  i = 1, 2, 4 
∂ fi 
∂ fi 
∂ fi 
∂ fi 
xe[n]  . 
qe3 [n] + 
qe1 [n] + 
qe2 [n] + 
≈ fi (q1 , q2 , q3 , x) + 
∂x 
∂ q3 
∂ q2 
∂ q1 
(4.33) 
All  the  partial  derivatives  above  are  evaluated  at  the  equilibrium  values,  and  are 
therefore constants, not dependent on the time  index n.  (Also note that the partial 
derivatives  above  are  with  respect  to  the  continuously  variable  state  and  input 
arguments; there are no “derivatives” taken with respect to n, the discretely varying 
time  index!)  The  deﬁnition  of  the  equilibrium  values  in  (4.24)  shows  that  the  term 
q i  on  the  left of  the above  set of  expressions  exactly  equals  the  term fi (q1 , q2 , q3 , x) 
on  the  right,  so  what  remains  is  the  approximate  relation 
∂ fi 
∂ fi 
∂ fi 
∂ fi 
xe[n] 
qe1 [n] + 
qe2 [n] + 
qe3 [n] + 
qei [n + 1] ≈ 
∂x 
∂ q2 
∂ q3 
∂ q1 
for i = 1, 2, 3.  Replacing the approximate equality sign (≈) by the equality sign (=) 
in  this  set  of  expressions produces what  is  termed  the  linearized model  at  the  equi­
librium  point.  This  linearized  model  approximately  describes  small  perturbations 
away  from  the  equilibrium  point. 
We may  write  the  linearized  model  in matrix  form: 
q1 [n + 1]    
  
 
   ∂ f1  
∂ f1  ∂ f1  ∂ f1

q1 [n] 
e
qe2 [n] + 
∂ q1  ∂ q2  ∂ q3 
∂x 

  ∂ q1  ∂ q2  ∂ q3    
 
∂x  

  
∂ f2  ∂ f2  ∂ f2 
∂ f2
q2 [n + 1]  =
 
e
e
∂ f3  ∂ f3  ∂ f3  
qe3 [n] 

q3 [n + 1] 
∂ f3 
e
∂x 
q[n{z 
| 
| 
{z 
{z  }
∂ q1  ∂ q2  ∂ q3 
}
}
|
{z 
| 
}
e
eq[n] 
+1] 
b
A 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

xe[n]  . 

(4.35) 

(4.34) 

Section  4.4 

Equilibria  and  Linearization  of  Nonlinear  State-Space  Models  77 

(4.36) 

We  have  therefore  arrived  at  a  standard  DT  LTI  state-space  description  of  the 
state  evolution  of  our  linearized  model,  with  state  and  input  variables  that  are 
the  respective  deviations  from  equilibrium  of  the  underlying  nonlinear model.  The 
corresponding  output  equation  is  derived  similarly,  and  takes  the  form 
∂ g  ∂ g  ∂ g  i 
h 
∂ g 
xe[n]  . 
q[n] + 
y [n] = 
e
e
∂x 
∂ q1  ∂ q2  ∂ q3 
| 
{z 
} 
|{z}
d 
cT 
The  matrix  of  partial  derivatives  denoted  by  A  in  (4.35)  is  also  called  a  Jacobian 
matrix,  and  denoted  in matrix-vector  notation  by 
h ∂ f  i
∂q  q,x 
The  entry  in  its  ith  row  and  j th  column  is  the  partial  derivative  ∂ fi ( )/∂ qj ,  eval­
· 
uated  at  the  equilibrium  values  of  the  state  and  input  variables.  Similarly, 
h ∂ g i
h ∂ f i 
h ∂ g i
∂q  q,x 
∂x  q,x 
∂x  q,x 
The  derivation  of  linearized  state-space  models  in  CT  follows  exactly  the  same 
route,  except  that  the CT equilibrium condition  is  speciﬁed by  the condition  (4.28) 
rather  than  (4.22). 

T 
,  c  = 

,  d = 

. 

(4.38) 

A = 

.	

(4.37) 

b = 

EXAMPLE  4.1 

A  Hoop-and-Beam  System 

As  an  example  to  illustrate  the  determination  of  equilibria  and  linearizations,  we 
consider  in  this  section  a  nonlinear  state-space  model  for  a  particular  hoop-and­
beam  system. 

The  system  in  Figure  4.3  comprises  a  beam  pivoted  at  its  midpoint,  with  a  hoop 
that  is  constrained  to  maintain  contact  with  the  beam  but  free  to  roll  along  it, 
without  slipping.  A  torque  can  be  applied  to  the  beam,  and  acts  as  the  control 
input.  Our  eventual  ob jective  might  be  to  vary  the  torque  in  order  to  bring  the 
hoop  to —  and  maintain  it  at —  a  desired  position  on  the  beam.  We  assume  that 
the  only  measured  output  that  is  available  for  feedback  to  the  controller  is  the 
position  of  the  hoop  along  the  beam. 

Natural  state  variables  for  such  a  mechanical  system  are  the  position  and  velocity 
variables  associated  with  each  of  its  degrees  of  freedom,  namely: 

•	 the  position  q1 (t)  of  the  point  of  contact  of  the  hoop  relative  to  the  center  of 
the  beam; 
•	 the  angular  position  q2 (t)  of  the  beam  relative  to  horizontal; 
•	 the  translational  velocity  q3 (t) = q˙1 (t)  of  the  hoop  along  the  beam; 
•	 the  angular  velocity  q4 (t) = q˙2 (t)  of  the  beam. 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

78  Chapter  4 

State-Space  Models 

FIGURE  4.3  A  hoop  rolling  on  a  beam  that  is  free  to  pivot  on  its  support.  The 
variable q1 (t) is the position of the point of contact of the hoop relative to the center 
of  the  beam.  The  variable  q2 (t)  is  the  angle  of  the  beam  relative  to  horizontal. 

The measured  output  is 

y(t) = q1 (t)  . 

(4.39) 

To  specify  a  state-space  model  for  the  system,  we  express  the  rate  of  change  of 
each  of  these  state  variables  at  time  t  as  a  function  of  these  variables  at  t,  and  as 
a  function  of  the  torque  input  x(t).  We  arbitrarily  choose  the  direction  of  positive 
torque  to  be  that  which  would  tend  to  increase  the  angle  q2 (t).  The  required 
expressions, which we do not derive here, are most easily obtained using Lagrange’s 
equations of motion, but can also be found by applying the standard and rotational 
forms  of  Newton’s  second  law  to  the  system,  taking  account  of  the  constraint  that 
the  hoop  rolls  without  slipping.  The  resulting  nonlinear  time-invariant  state-space 
model  for  the  system,  with  the  time  argument  dropped  from  the  state  variables  qi 
and  input  x  to  avoid  notational  clutter,  are: 

dq1 
dt

dq2

dt

dq3 
dt 
dq4 
dt 

= q3

= 

= q4
¡q1 q4  − g sin(q2 )¢ 
1 
2

2 
mgr sin(q2 ) − mgq1 cos(q
2 ) − 2mq1 q3 q4  + x
J + mq1 
2

= 

. 

(4.40) 

Here  g  represents  the  acceleration  due  to  gravity,  m  is  the  mass  of  the  hoop,  r  is 
its  radius,  and  J  is  the moment  of  inertia  of  the  beam. 

Equilibrium values of  the model.  An equilibrium state of a system is one that 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  4.4 

Equilibria  and  Linearization  of  Nonlinear  State-Space  Models  79 

can  (ideally)  be  maintained  indeﬁnitely  without  the  action  of  a  control  input,  or 
more  generally  with  only  constant  control  action.  Our  control  ob jective  might  be 
to design a feedback control system that regulates the hoop-and-beam system to its 
equilibrium  state,  with  the  beam  horizontal  and  the  hoop  at  the  center,  i.e.,  with 
q1 (t) ≡ 0 and q2 (t) ≡ 0.  The possible zero-control equilibrium positions  for any CT 
system described  in  state-space  form  can be  found by  setting  the  control  input and 
the  state  derivatives  to  0,  and  then  solving  for  the  state  variable  values. 

For  the  model  above,  we  see  that  the  only  zero-control  equilibrium  position  (with 
the  realistic  constraint  that  − π
π
< q2  < 
)  corresponds  to  a  horizontal  beam  with 
2 
2
the  hoop  at  the  center,  i.e.,  q1  =  q2  =  q3  =  q4  =  0.  If  we  allow  a  constant  but 
nonzero  control  input,  it  is  straightforward  to  see  from  (4.40)  that  it  is  possible  to 
have  an  equilibrium  state  (i.e.,  unchanging  state  variables)  with  a  nonzero  q1 ,  but 
still  with  q2 ,  q3  and  q4  equal  to  0. 

Linearization  for  small  perturbations. 
It  is  generally  quite  diﬃcult  to  elu­
cidate  in  any  detail  the  global  or  large-signal  behavior  of  a  nonlinear  model  such 
as  (4.40).  However,  small  deviations  of  the  system  around  an  equilibrium,  such  as 
might occur in response to small perturbations of the control input from 0, are quite 
well  modeled  by  a  linearized  version  of  the  nonlinear  model  above.  As  already  de­
scribed  in the previous subsection, a  linearized model  is obtained by approximating 
all  nonlinear  terms  using  ﬁrst-order  Taylor  series  expansions  around  the  equilib­
rium.  Linearization  of  a  time-invariant  model  around  an  equilibrium  point  always 
yields a model that  is time  invariant, as well as being  linear.  Thus, even though the 
original nonlinear model may be diﬃcult to work with,  the  linearized model around 
an equilibrium point can be analyzed in great detail, using all the methods available 
to  us  for  LTI  systems.  Note  also  that  if  the  original  model  is  in  state-space  form, 
the  linearization will  be  in  state-space  form  too,  except  that  its  state  variables will 
be  the  deviations  from  equilibrium  of  the  original  state  variables. 

Since  the  equilibrium  of  interest  to  us  in  the  hoop-and-beam  example  corresponds 
to  all  state  variables  being  0,  small  deviations  from  this  equilibrium  correspond  to 
all  state  variables  being  small.  The  linearization  is  thus  easy  to  obtain  without 
formal  expansion  into  Taylor  series.  Speciﬁcally,  as  we  discard  from  the  nonlinear 
model  (4.40)  all  terms  of  higher  order  than  ﬁrst  in  any  nonlinear  combinations  of 
2 
terms,  sin(q2 )  gets  replaced  by  q2 ,  cos(q2 )  gets  replaced  by  1,  and  the  terms  q1 q4
2  are  eliminated.  The  result  is  the  following  linearized  model  in 
and  q1 q3 q4  and  q1
state-space  form: 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

80  Chapter  4 

State-Space  Models 

dq1 
dt 
dq2 
dt 
dq3 
dt 
dq4 
dt 

= q3

= q4

g 
= −
q2 
2 
mg(rq2  − q1 ) + x 
= 
J 

(4.41) 

This model, along with the deﬁning equation (4.39) for the output (which is already 
linear  and  therefore  needs  no  linearization),  can  be  written  in  the  standard matrix 
form  (4.16)  and  (4.17)  for  LTI  state-space  descriptions,  with 
0   
 
 
0  
0 
1
0
0   , 
b =  0  
A = 
1 
0 
0 
0
0
 
 


−g/2 
0 
0
0 
−mg/J  mgr/J  0
1/J 
0  ¤ 
T c  = £ 
1
0
0
The  LTI  model  is  much  more  tractable  than  the  original  nonlinear  time-invariant 
model,  and  consequently  controllers  can  be  designed more  systematically  and  con­
ﬁdently.  If  the  resulting  controllers, when  applied  to  the  system, manage  to  ensure 
that deviations  from equilibrium remain small,  then our use of the  linearized model 
for  design  will  have  been  justiﬁed. 

(4.42) 

4.5  STATE-SPACE  MODELS  FROM  INPUT–OUTPUT  MODELS 

State-space representations can be very naturally and directly generated during the 
modeling process in a variety of settings, as the examples in Sections 4.2.1 and 4.2.2 
suggest.  Other  —  and  perhaps  more  familiar  —  descriptions  can  then  be  derived 
from  them;  again,  these  previous  examples  showed  how  input–output  descriptions 
could  be  obtained  from  state-space  descriptions. 

It  is  also  possible  to  proceed  in  the  reverse  direction,  constructing  state-space  de­
scriptions  from  impulse  responses  or  transfer  functions  or  input–output  diﬀerence 
equations,  for instance.  This is often worthwhile as a prelude to simulation, or ﬁlter 
implementation,  or  in  control  design,  or  simply  in  order  to  understand  the  initial 
description  from  another  point  of  view.  The  following  two  examples  illustrate  this 
reverse process, of synthesizing state-space descriptions  from  input–output descrip­
tions. 

4.5.1  Determining  a  state-space  model  from  an  impulse  response  or  transfer  function 

Consider  the  impulse  response  h[n]  of  a  causal  DT  LTI  system.  Causality  requires 
of  course  that  h[n]  = 0 for  n <  0.  The  output  y [n]  can  be  related  to  past  and 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  4.5 

State-Space  Models  from  Input–Output  Models  81 

(4.43) 

(4.44) 

´ 
h[n − k ] x[k ] +  h[0]x[n]  . 

present  inputs  x[k ],  k ≤ n,  through  the  convolution  sum 
y [n] =  X 
n
h[n − k ] x[k ] 
k=−∞ 
³  X 
n−1
= 
k=−∞ 
The  ﬁrst  term  above,  namely 
q [n] =  X 
n−1
k=−∞ 
represents the eﬀect of the past on the present, at time n, and would therefore seem 
to  have  some  relation  to  the  notion  of  a  state  variable.  Updating  q [n]  to  the  next 
time  step,  we  obtain 
q [n + 1] =  X 
n
k=−∞ 
In general,  if  the  impulse  response has no  special  form,  the  successive values of  q [n] 
have  to  be  recomputed  from  (4.46)  for  each  n.  When  we  move  from  n  to  n + 1, 
none of the past  inputs x[k ]  for k ≤ n,  can be discarded, because all of the past will 
again  be  needed  to  compute  q [n + 1].  In  other  words,  the memory  of  the  system  is 
inﬁnite. 

h[n + 1 − k ] x[k ]  . 

h[n − k ] x[k ]  , 

(4.46) 

(4.45) 

+ d 

(4.47) 

(4.48) 

However, consider the class of systems for which h[n] has the essentially exponential 
form 

H (z ) = 

h[n] = β λn−1 u[n − 1] + d δ [n]  , 
where  β ,  λ  and  d  are  constants.  The  corresponding  transfer  function  is 
β 
z − λ 
(with  ROC  z > λ ).  What  is  important  about  this  impulse  response  is  that  a 
| | 
|
|
time-shifted  version  of  it  is  simply  related  to  a  scaled  version  of  it,  because  of  its 
DT-exponential  form.  For  this  case, 
q [n] = β  X 
n−1
k=−∞ 
q [n + 1] = β  X 
n
λn−k x[k ] 
k=−∞ 
= λ³ 
λn−1−k x[k ] ´ 
β  X 
n−1
k=−∞ 
= λq [n] + βx[n]  . 

λn−1−k x[k ] 

+  βx[n] 

(4.49) 

(4.50) 

(4.51) 

and 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

82  Chapter  4 

State-Space  Models 

x[n] 
� 

� 

� 

� 

d 

β1 
. . . 
z − λ1 
βL 
z − λL 

� 

� 

� 

y [n] 
�

� 

� 
� 

FIGURE  4.4  Decomposition  of  rational  transfer  function  with  distinct  poles. 

Gathering  (4.44)  and  (4.49) with  (4.51)  results  in  a  pair  of  equations  that  together 
constitute  a  state-space  description  for  this  system: 

q [n + 1] = λq [n] + βx[n] 
y [n] = q [n] + dx[n]  . 

(4.52) 
(4.53) 

(4.54) 

Let  us  consider  next  a  similar  but  higher  order  system  with  impulse  response: 
+ βLλn−1  )u[n − 1] + d δ [n] 
h[n] = ( β1λn−1  + β2λn−1  +
· · · 
2 
1
L
with  the  βi  and  d  being  constants.  The  corresponding  transfer  function  is 
³  L
´ 
H (z ) =  X
βi
+ d  . 
z − λi
i=1 
By  using  a  partial  fraction  expansion,  the  transfer  function  H (z )  of  any  causal 
LTI  DT  system  with  a  rational  transfer  function  can  be  written  in  this  form,  with 
appropriate  choices  of  the  βi ,  λi ,  d  and  L,  provided H (z )  has  non-repeated —  i.e., 
distinct — poles.  Note that although we only treat rational transfer functions H (z ) 
whose  numerator  and  denominator  polynomials  have  real  coeﬃcients,  the  poles  of 
H (z )  may  include  some  complex  λi  (and  associated  βi ),  but  in  each  such  case  its 
complex conjugate λ∗i  will also be a pole  (with associated weighting  factor βi∗ ), and 
the  sum 

(4.55) 

βi (λi )n  + βi ∗ (λ∗ 
i )n 

(4.56) 

will  be  real. 

The  block  diagram  in  Figure  4.5.1  shows  that  this  system  can  be  considered  as 
being  obtained  through  the  parallel  interconnection  of  subsystems  corresponding 
to  the  simpler  case  of  (4.47).  Motivated  by  this  structure  and  the  treatment  of  the 
ﬁrst-order  example,  we  deﬁne  a  state  variable  for  each  of  the  L  subsystems: 
qi [n] = βi X 
n−1
−∞ 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

n−1−k x[k ]  ,
λi

i = 1, 2, . . . , L  . 

(4.57) 

Section  4.5 

State-Space  Models  from  Input–Output  Models  83 

With  this,  we  obtain  the  following  state-evolution  equations  for  the  subsystems: 

qi [n + 1] = λi qi [n] + βix[n]  ,

i = 1, 2, . . . , L  . 

(4.58) 

Also,  combining  (4.45),  (4.53)  and  (4.54)  with  the  deﬁnitions  in  (4.57),  we  obtain 
the  output  equation 

(4.59) 

(4.60) 

y [n] = q1 [n] + q2 [n] +  + qL [n] + d x[n]  . 
· · · 
Equations (4.58) and (4.59) together comprise an Lth-order state-space description 
of  the  given  system.  We  can  write  this  state-space  description  in  our  standard 
matrix  form  (4.13)  and  (4.14),  with 
 
 
β1   
0  
0 
· · · 
λ1 
0
0
 β2  
0  
 0  λ2  0 
· · · 
0
.   ,  b =  .  
A =  . 
. 
 . 
.  
 .  
.
.
.
.  
. 
.  
.
.
.
.
 
 
. 
.
.
.
0 
· · · 
0  λL 
0
0
βL
T c  = ¡ 
1  ¢ 
1 1 
· · · 
· · · 
· · · 
. 
The diagonal  form of A  in (4.60) reﬂects the  fact that the state evolution equations 
in this example are decoupled, with each state variable being updated independently 
according  to  (4.58).  We  shall  see  later how a general description of  the  form  (4.13), 
(4.14),  with  a  distinct-eigenvalue  condition  that  we  shall  impose,  can  actually  be 
transformed  to  a  completely  equivalent  description  in  which  the  new  A  matrix  is 
diagonal,  as  in  (4.60).  (Note,  however,  that  when  there  are  complex  eigenvalues, 
this  diagonal  state-space  representation  will  have  complex  entries.) 

(4.61) 

4.5.2  Determining  a  state-space  model  from  an  input–output  diﬀerence  equation 

Let  us  examine  some  ways  of  representing  the  following  input-output  diﬀerence 
equation  in  state-space  form: 

y [n] + a1 y [n − 1] + a2 y [n − 2] = b1x[n − 1] + b2x[n − 2] . 
One  approach,  building  on  the  development  in  the  preceding  subsection,  is  to  per­
form  a  partial  fraction  expansion  of  the  2-pole  transfer  function  associated  with 
this  system,  and  thereby  obtain  a  2nd-order  realization  in  diagonal  form.  (If  the 
real  coeﬃcients  a1  and  a2  are  such  that  the  roots  of  z 2  + a1 z + a2  are  not  real  but 
form  a  complex  conjugate  pair,  then  this  diagonal  2nd-order  realization  will  have 
complex  entries.) 

(4.62) 

For  a  more  direct  attempt  (and  to  guarantee  a  real-valued  rather  than  complex-
valued  state-space  model),  consider  using  as  state  vector  the  quantity 
y [n − 1]   
 
q[n] =  y [n − 2]   . 
 x[n − 1]  
 

x[n − 2] 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(4.63) 

84  Chapter  4 

State-Space  Models 

= 

b1 

b2

b1 
0
0
1

b2 
0 
0 
0 

q[n + 1] = 

−a1  −a2 

−a1  −a2 
0 
1
0 
0
0
0

The  corresponding  4th-order  state-space  model  would  take  the  form 
 
 
 
 
 
 
 
 
y [n − 1] 
0 
y [n] 








y [n − 1] 
y [n − 2] 
0
+
x[n]

  



1 
x[n − 1] 
x[n]
x[n − 1] 
x[n − 2] 
0 
 
 
y [n − 1] 
y [n]  =  ¡ 
¢ 


y [n − 2] 
(4.64) 
 
x[n − 1] 
x[n − 2] 
If  we  are  somewhat  more  careful  about  our  choice  of  state  variables,  it  is  possible 
to  get  more  economical  models.  For  a  3rd-order  model,  suppose  we  pick  as  state 
vector 
x[n − 1]   . 
q[n] =  
y [n] 
y [n − 1] 
The  corresponding  3rd-order  state-space  model  takes  the  form 
q[n + 1] =  
0    
y [n]   =  
y [n] 
y [n + 1] 
−a1  −a2 
b2 
y [n − 1] 
0 
1
x[n − 1] 
x[n] 
0 
0
0

0  ¢  
y [n] 
y [n]  =  ¡ 
y [n − 1] 
x[n − 1] 
A  still more  subtle choice of  state variables yields a 2nd-order  state-space model by 
picking 
¶ 
µ
y [n]
−a2 y [n − 1] + b2x[n − 1] 
The  corresponding  2nd-order  state-space  model  takes  the  form 
µ 
¶ 
−a1  1  ¶ µ 
µ
y [n] 
y [n + 1] 
= 
−a2 y [n − 1] + b2x[n − 1] 
0 
−a2 y [n] + b2x[n] 
−a2 
0  ¢ µ 
¶ 
y [n] =  ¡ 
y [n] 
1
−a2 y [n − 1] + b2x[n − 1] 
It turns out to be impossible in general to get a state-space description of order lower 
than  2  in  this  case.  This  should  not  be  surprising,  in  view  of  the  fact  that  (4.63) 
is  a  2nd-order  diﬀerence  equation, which we  know  requires  two  initial  conditions  in 
order  to  solve  forwards  in  time.  Notice  how,  in  each  of  the  above  cases,  we  have 
incorporated  the  information  contained  in  the  original  diﬀerence  equation  (4.63) 
that  we  started  with. 

 +    x[n] 
b1 
0 
1 
(4.66) 

¶ 
+

µ 

q[n] = 

. 

(4.67) 

1

0

(4.65) 

b1
b2

¶ 
x[n]
(4.68) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

5 

Properties  of  LTI  State-Space 
Models 

5.1  INTRODUCTION 

In  Chapter  4  we  introduced  state-space  models  for  dynamical  systems.  In  this 
chapter we study the structure and solutions of LTI state-space models.  Throughout 
the discussion we  restrict  ourselves  to  the  single-input,  single-output Lth-order CT 
LTI  state-space  model 

q˙ (t) = Aq(t) + bx(t) 
y(t) = c T q(t) + dx(t)  , 

or  the  DT  LTI  state-space  model 

q[n + 1] = Aq[n] + bx[n] 
y [n] = c T q[n] + dx[n]  . 

(5.1) 
(5.2) 

(5.3) 
(5.4) 

Equation (5.1) constitutes a representation of CT LTI system dynamics  in the form 
of  a  set  of  coupled,  ﬁrst-order,  linear,  constant-coeﬃcient  diﬀerential  equations  for 
the  L  variables  in  q(t),  driven  by  the  input  x(t).  Equation  (5.3)  gives  a  similar 
diﬀerence-equation  representation  of  DT  LTI  system  dynamics. 

The  basic  approach  to  analyzing  LTI  state-space models  parallels what  you  should 
already  be  familiar  with  from  solving  linear  constant-coeﬃcient  diﬀerential  or  dif­
ference  equations  (of  any  order)  in  one  variable.  Speciﬁcally,  we  ﬁrst  consider  the 
zero-input  response  to  nonzero  initial  conditions  at  some  starting  time,  and  then 
augment  that  with  the  response  due  to  the  nonzero  input  when  the  initial  condi­
tions  are  zero.  Understanding  the  full  solution  from  the  starting  time  onwards will 
give  us  insight  into  system  stability,  and  into  how  the  internal  behavior  relates  to 
the  input-output  characteristics  of  the  system. 

5.2  THE  ZERO-INPUT  RESPONSE  AND  MODAL  REPRESENTATION 

We  take  our  starting  time  to  be  0,  without  loss  of  generality  (since  we  are  dealing 
with  time-invariant  models).  Consider  the  response  of  the  undriven  system  corre­
sponding  to  (5.1),  i.e.,  the  response with  x(t) ≡ 0  for  t ≥ 0,  but with  some  nonzero 
initial  condition  q(0).  This  is  the  zero-input-response  (ZIR)  of  the  system  (5.1), 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

85

86  Chapter  5 

Properties  of  LTI  State-Space  Models 

and  is  a  solution  of  the  undriven  (or  unforced  or  homogeneous)  system 

q˙ (t) = Aq(t)  . 

(5.5) 

It  is  natural  when  analyzing  an  undriven  LTI  system  to  look  for  a  solution  in 
exponential  form  (essentially  because  exponentials  have  the  unique  property  that 
shifting  them  is  equivalent  to  scaling  them,  and  undriven  LTI  systems  are  charac­
terized  by  invariance  to  shifting  and  scaling  of  solutions).  We  accordingly  look  for 
a  nonzero  solution  of  the  form 

q(t) = ve λt  ,  v = 0  , 

(5.6) 

where  each  state  variable  is  a  scalar  multiple  of  the  same  exponential  eλt ,  with 
these  scalar  multiples  assembled  into  the  vector  v.  (The  boldface  0  at  the  end  of 
the  preceding  equation  denotes  an  L-component  column  vector  whose  entries  are 
all  0 —  we  shall  use  0  for  any  vectors  or matrices  whose  entries  are  all  0,  with  the 
correct  dimensions  being  apparent  from  the  context.  Writing  v  =  0  signiﬁes  that 
at  least  one  component  of  v  is  nonzero.) 

Substituting  (5.6)  into  (5.5)  results  in  the  equation 

λve λt  = Ave λt  , 

(5.7) 

from  which  we  can  conclude  that  the  vector  v  and  scalar  λ must  satisfy 

λv = Av  or  equivalently  (λI − A)v = 0  ,  v =6 0  , 
where  I  denotes  the  identity  matrix,  in  this  case  of  dimension  L × L.  The  above 
equation  has  a  nonzero  solution  v  if  and  only  if  the  coeﬃcient  matrix  (λI − A)  is 
not  invertible,  i.e.,  if  and  only  if  its  determinant  is  0: 

(5.8) 

det(λI − A) = 0 . 
For  an  Lth-order  system,  it  turns  out  that  the  above  determinant  is  a monic  poly­
nomial  of  degree  L,  called  the  characteristic  polynomial  of  the  system  or  of  the 
matrix A: 

det(λI − A) = a(λ) = λL  + aL−1λL−1  +
· · · 
+ a0 
(The  word  “monic”  simply  means  that  the  coeﬃcient  of  the  highest-degree  term 
is  1.)  It  follows  that  (5.6)  is  a  nonzero  solution  of  (5.5)  if  and  only  if  λ  is  one  of 
the L  roots  {λi }L  of  the  characteristic  polynomial.  These  roots  are  referred  to  as 
i=1 
characteristic  roots  of  the  system,  and  as  eigenvalues  of  the matrix A. 

(5.9) 

(5.10) 

The  vector  v  in  (5.6)  is  correspondingly  a  nonzero  solution  vi  of  the  system  of 
equations 

(λi I − A)vi  = 0  ,  vi  6= 0  , 
and is termed the characteristic vector or eigenvector associated with λi .  Note from 
(5.11)  that  multiplying  any  eigenvector  by  a  nonzero  scalar  again  yields  an  eigen­
vector,  so  eigenvectors  are  only  deﬁned  up  to  a  nonzero  scaling.  Any  convenient 
scaling  or  normalization  can  be  used. 

(5.11) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
6
Section  5.2 

The  Zero-Input  Response  and  Modal  Representation  87 

In  summary,  the  undriven  system  has  a  solution  of  the  assumed  exponential  form 
in  (5.6)  if and only  if λ equals  some characteristic value or eigenvalue of A, and  the 
nonzero  vector  v  is  an  associated  characteristic  vector  or  eigenvector. 

We  shall  only  be  dealing  with  state-space  models  for  which  all  the  signals  and  the 
coeﬃcient  matrices  A,  b,  cT  and  d  are  real-valued  (though  we  may  subsequently 
transform  these models  into  the diagonal  forms  seen  in  the previous chapter, which 
may  then  have  complex  entries,  but  occurring  in  very  structured  ways).  The  coef­
ﬁcients  ai  deﬁning  the  characteristic  polynomial  a(λ)  in  (5.10)  are  therefore  real, 
and  thus  the  complex  roots  of  this  polynomial  occur  in  conjugate  pairs.  Also,  it 
is  straightforward  to  show  that  if  vi  is  an  eigenvector  associated  with  a  complex 
eigenvalue λi , then vi∗ —i.e., the vector whose entries are the complex conjugates of 
the corresponding entries of vi  —  is an eigenvector associated with λ∗i ,  the complex 
conjugate  of  λi . 
We  refer  to  a  nonzero  solution  of  the  form  (5.6)  for  λ  =  λi  and  v  =  vi  as  the 
ith  mode  of  the  system  (5.1)  or  (5.5);  the  associated  λi  is  termed  the  ith  modal 
frequency  or  characteristic  frequency  or  natural  frequency  of  the  system,  and  vi  is 
termed  the  ith  mode  shape.  Note  that  if 

q(t) = vi e λi t 

(5.12) 

then the corresponding initial condition must have been q(0) = vi .  It can be shown 
(though we don’t do so here) that the system (5.5) — and similarly the system (5.1) 
—  can  only  have  one  solution  for  a  given  initial  condition,  so  it  follows  that  for  the 
initial  condition  q(0) = vi ,  only  the  ith  mode  will  be  excited. 
It  can  also  be  shown  that  eigenvectors  associated  with  distinct  eigenvalues  are 
linearly  independent,  i.e.,  none  of  them  can  be  written  as  a  weighted  linear  combi­
nation  of  the  remaining  ones.  For  simplicity, we  shall  restrict  ourselves  throughout 
to  the  case  where  all  L  eigenvalues  of  A  are  distinct,  which  will  guarantee  that 
v1 , v2 , . . . , vL  form  an  independent  set.  (In  some  cases  in  which  A  has  repeated 
eigenvalues,  it  is  possible  to  ﬁnd  a  full  set  of  L  independent  eigenvectors,  but  this 
is  not  generally  true.)  We  shall  repeatedly  use  the  fact  that  any  vector  in  an  L-
dimensional space,  such as our state vector q(t) at any speciﬁed time  t = t0 ,  can be 
written  as  a  unique  linear  combination  of  any L  independent  vectors  in  that  space, 
such  as  our  L  eigenvectors. 

5.2.1  Modal  representation  of  the  ZIR 

Because  (5.5)  is  linear,  a  weighted  linear  combination  of  modal  solutions  of  the 
form  (5.12),  one  for  each  eigenvalue,  will  also  satisfy  (5.5).  Consequently  a  more 
general  solution  for  the  zero-input  response  with  distinct  eigenvalues  is 

q(t) = X 
L
λi t 
αivi e 
i=1 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(5.13) 

88  Chapter  5 

Properties  of  LTI  State-Space  Models 

The  expression  in  (5.13)  can  easily be veriﬁed  to be a  solution of  (5.5)  for arbitrary 
weights  αi ,  with  initial  condition 
q(0) = X 
L
αivi  . 
i=1 
Since  the  L  eigenvectors  vi  are  independent  under  our  assumption  of  L  distinct 
eigenvalues,  the  right  side  of  (5.14)  can  be  made  equal  to  any  desired  q(0)  by 
proper  choice  of  the  coeﬃcients  αi ,  and  these  coeﬃcients  are  unique.  Hence  spec­
ifying  the  initial  condition  of  the  undriven  system  (5.5)  speciﬁes  the  αi  via  (5.14), 
and  thus  speciﬁes  the  full  response  of  (5.5)  via  (5.13).  In  other words,  (5.13)  is  ac­
tually  a  general  expression  for  the ZIR  of  (5.1) — under  our  assumption  of distinct 
eigenvalues.  We  refer  to  the  expression  on  the  right  side  of  (5.13)  as  the  modal 
decomposition  of  the  ZIR. 

(5.14) 

The  contribution  to  the modal  decomposition  from  a  conjugate  pair  of  eigenvalues 
λi  =  σi  + jωi  and  λ∗ 
σi  − jωi ,  with  associated  complex  conjugate  eigenvectors 
= 
i 
= ui  − jwi  respectively,  will  be  a  real  term  of  the  form 
vi  = ui  + jwi  and  vi 
λ ∗ 
λi t 
∗ 
∗+ αi v
t
. 
(5.15) 
i e 
αivi e 
i

With  a  little  algebra,  the  real  expression  in  (5.15)  can  be  reduced  to  the  form 

∗+ αi v

(5.16) 

αivi e λi t 

i e λ ∗ 
∗ 
t  = Ki e σi t [ui cos(ωi t + θi ) − wi  sin(ωi t + θi )] 
i
for  some  constants  Ki  and  θi  that  are  determined  by  the  initial  conditions  in  the 
process  of  matching  the  two  sides  of  (5.14).  The  above  component  of  the  modal 
solution  therefore  lies  in  the plane spanned by  the real and  imaginary parts, ui  and 
wi  respectively,  of  the  eigenvector  vi .  The  associated  motion  of  the  component 
of  state  tra jectory  in  this  plane  involves  an  exponential  spiral,  with  growth  or 
negative 
Re{λi }  is  positive 
or 
decay  of  the  spiral  determined  by  whether  σi 
= 
∗ 
respectively  (corresponding  to  the  eigenvalue λi  — and  its  conjugate λ
i  —  lying  in 
the  open  right- or  left-half-plane  respectively).  If  σi  = 0,  i.e.,  if  the  conjugate  pair 
of  eigenvalues  lies  on  the  imaginary  axis,  then  the  spiral  degenerates  to  a  closed 
loop.  The  rate  of  rotation  of  the  spiral  is  determined  by  ωi  = Im{λi}. 
A  similar  development  can  be  carried  out  in  the  DT  case  for  the  ZIR  of  (5.3).  In 
that  case  (5.6)  is  replaced  by  a  solution  of  the  form 

q[n] = vλn 

(5.17) 

and  we  ﬁnd  that  when  A  has  L  distinct  eigenvalues,  the  modal  decomposition  of 
the  general  ZIR  solution  takes  the  form 
q[n] = X 
L
αiviλn
i  . 
i=1 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(5.18) 

5.2.2  Asymptotic  stability 

Section  5.3 

Coordinate  Transformations  89 

The  stability of an LTI  system  is directly  related  to  the behavior of  the modes, and 
more  speciﬁcally  to  the  values  of  the  λi ,  the  roots  of  the  characteristic  polynomial. 
An LTI state-space system  is termed asymptotically stable or  internally stable  if  its 
ZIR  decays  to  zero  for  all  initial  conditions.  We  see  from  (5.13)  that  the  condition 
Re{λi } <  0  for  all  1 ≤  i ≤ L  is  necessary  and  suﬃcient  for  asymptotic  stability  in 
the  CT  case.  Thus,  all  eigenvalues  of  A  in  (5.1)  —  or  natural  frequencies  of  (5.1) 
— must  be  in  the  open  left-half-plane. 

In the DT case, (5.18) shows that a necessary and suﬃcient condition for asymptotic 
stability  is  |λi | < 1  for  all  1 ≤ i ≤ L,  i.e.,  all  eigenvalues  of A  in  (5.3) —  or  natural 
frequencies  of  (5.3) — must  be  strictly  within  the  unit  circle. 

We  used  the modal  decompositions  (5.13)  and  (5.18)  to make  these  claims  regard­
ing  stability  conditions,  but  these  modal  decompositions  were  obtained  under  the 
assumption  of distinct  eigenvalues.  Nevertheless,  it  can be  shown  that  the  stability 
conditions  in  the  general  case  are  identical  to  those  above. 

5.3  COORDINATE  TRANSFORMATIONS 

We  have  so  far  only  described  the  zero-input  response  of  LTI  state-space  systems. 
Before  presenting  the  general  response,  including  the  eﬀects  of  inputs,  it  will  be 
helpful  to  understand  how  a  given  state-space  representation  can  be  transformed 
to an equivalent representation that might be simpler to analyze.  Our development 
is  carried  out  for  the CT  case,  but  an  entirely  similar  development  can  be  done  for 
DT. 

It  is  often  useful  to  examine  the  behavior  of  a  state-space  system  by  rewriting 
the  original  description  in  terms  of  a  transformed  set  of  variables.  A  particularly 
important  case  involves  the  transformation  of  the  state  vector  q(t)  to  a  new  state 
vector  r(t)  that  decomposes  the  behavior  of  the  system  into  its  components  along 
each  of  the  eigenvectors  vi : 
q(t) = X 
L
vi ri (t) = Vr(t)  , 
i=1 
where  the  ith  column  of  the  L × L matrix V  is  the  ith  eigenvector,  vi : 
vL  ¢ 
V = ¡ 
· · · 
. 
v1  v2 
We  refer  to V  as  the modal matrix.  Under  our  assumption  of  distinct  eigenvalues, 
the  eigenvectors  are  independent,  which  guarantees  that V  is  invertible,  so 

(5.20) 

(5.19) 

r(t) = V−1 q(t)  . 

(5.21) 

The transformation  from the original system description  involving q(t) to one writ­
ten  in  terms  of  r(t)  is  called  a  modal  transformation,  and  the  new  state  variables 
ri (t)  deﬁned  through  (5.19)  are  termed modal  variables  or modal  coordinates. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

90  Chapter  5 

Properties  of  LTI  State-Space  Models 

More  generally,  a  coordinate  transformation  corresponds  to  choosing  a  new  state 
vector  z(t)  related  to  the  original  state  vector  q(t)  through  the  relationship 

q(t) = Mz(t) 

(5.22) 

where  the  constant  matrix M  is  chosen  to  be  invertible.  (The  ith  column  of M  is 
the  representation  of  the  ith  unit  vector  of  the  new  z  coordinates  in  terms  of  the 
old  q  coordinates.)  Substituting  (5.22)  in  (5.1)  and  (5.2),  and  solving  for  z˙ (t),  we 
obtain 

z˙ (t) = (M−1AM)z(t) + (M−1b)x(t) 
y(t) = (c T M)z(t) + dx(t)  . 

(5.23) 
(5.24) 

Equations  (5.23) and  (5.24) are  still  in  state-space  form, but with  state vector z(t), 
and  with  modiﬁed  coeﬃcient  matrices.  This  model  is  entirely  equivalent  to  the 
original one, since (5.22) permits q(t) to be obtained from z(t), and the invertibility 
of  M  permits  z(t)  to  be  obtained  from  q(t).  It  is  straightforward  to  verify  that 
the  eigenvalues  of A  are  identical  to  those  of M−1AM,  and  consequently  that  the 
natural  frequencies  of  the  transformed  system  are  the  same  as  those  of  the  original 
system;  only  the  eigenvectors  change,  with  vi  transforming  to M−1vi . 
We  refer  to  the  transformation  (5.22)  as  a  similarity  transformation,  and  say  that 
the model  (5.23),  (5.24)  is  similar  to  the  model  (5.1),  (5.2). 

Note that the input x(t) and output y(t) are unaﬀected by this state transformation. 
For a given input, and assuming an initial state z(0) in the transformed system that 
is related to q(0) via (5.22), we obtain the same output as we would have from (5.1), 
(5.2).  In  particular,  the  transfer  function  from  input  to  output  is  unaﬀected  by  a 
similarity  transformation. 

Similarity  transformations  can  be  deﬁned  in  exactly  the  same way  for  the DT  case 
in  (5.3),  (5.4). 

5.3.1  Transformation  to Modal  Coordinates 

What  makes  the  modal  similarity  transformation  (5.19)  interesting  and  useful  is 
the  fact  that  the  state  evolution  matrix A  transforms  to  a  diagonal  matrix  Λ: 
0   
 
· · · 
. . .   
V−1AV = diagonal  {λ1 , · · ·  , λL } =  
0 
· · · 
. . . 
· · ·  λL 
The  easiest  way  to  verify  this  is  to  establish  the  equivalent  fact  that  AV  =  VΛ, 
which  in  turn  is  simply  the  equation  (5.11),  written  for  i  = 1, 
, L  and  stacked 
· · · 
up  in matrix  form. 

0 
λ2 
. . . 
0 

λ1 
0 
. . . 
0 

= Λ  . 

(5.25) 

The  diagonal  form  of  Λ  causes  the  corresponding  state  equations  in  the  new  co­
ordinate  system  to  be  decoupled.  Under  this  modal  transformation,  the  undriven 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  5.4 

The  Complete  Response  91 

system  (5.5)  is  transformed  into  L  decoupled,  scalar  equations: 

r˙i (t) = λi ri (t) 

for  i = 1, 2, . . . , L  . 

Each  of  these  is  easy  to  solve: 

ri (t) = e λi t ri (0)  . 

Combining  this  with  (5.19)  yields  (5.13)  again,  with  αi  = ri (0). 

(5.26) 

(5.27) 

5.4  THE  COMPLETE  RESPONSE 

Applying  the modal  transformation  (5.19)  to  the  full driven  system  (5.1),  (5.2), we 
see  that  the  transformed  system  (5.23),  (5.24)  takes  the  following  form,  which  is 
decoupled  into  L  parallel  scalar  subsystems: 

i = 1, 2, . . . , L 
r˙i (t) = λi ri (t) + βix(t)  ,
y(t) = ξ1 r1 (t) +  + ξL rL (t) + dx(t)  , 
· · · 

(5.28) 
(5.29) 

where  the  βi  and  ξi  are  deﬁned  via 
 
β1   
V−1b =  β
2   = β ,  c T V = £ 
.. 
 
.
βL 
The  second  equation  in  (5.30)  shows  that 
ξi  = c T vi  . 

ξ1  ξ2 

· · · 

ξL  ¤ 

= ξ . 

(5.30) 

(5.31) 

To  ﬁnd  an  interpretation  of  the  βi ,  note  that  the  ﬁrst  equation  in  (5.30)  can  be 
rewritten  as  b = Vβ .  Writing  out  the  product Vβ  in  detail,  we  ﬁnd 

b = v1β1  + v2β2  +

+ vLβL  . 
· · · 
In  other  words,  the  coeﬃcients  βi  are  the  coeﬃcients  needed  to  express  the  input 
vector  b  as  a  linear  combination  of  the  eigenvectors  vi . 
Each  of  the  scalar  equations  in  (5.28)  is  a  ﬁrst-order  LTI  diﬀerential  equation,  and 
can  be  solved  explicitly  for  t ≥ 0,  obtaining 
Z 
t 
ri (t) = e λi t ri (0) + 
e λi (t−τ )βix(τ ) dτ  ,  t ≥ 0  ,  1 ≤ i ≤ L . 
{z  }
|
0
{z 
| 
}
ZIR 
ZSR 
Expressed in this form, we easily recognize the separate contributions to the solution 
made  by:  (i)  the  response  due  to  the  initial  state  (the  zero-input  response  or ZIR); 
and  (ii)  the  response  due  to  the  system  input  (the  zero-state  response  or  ZSR). 
From  the  preceding  expression  and  (5.29),  one  can  obtain  an  expression  for  y(t). 

(5.32) 

(5.33) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

92	

Chapter  5 

Properties  of  LTI  State-Space  Models 

λ1 t
e

0
... 
0

0
λ2 t	
e
... 
0 

Introducing  the  natural  “matrix  exponential”  notation 
 
0   
· · · 
...   
e Λt  = diagonal  {e λ1 t , · · ·  , e λL t} =  
· · · 
0
. . . 
eλL t 
· · · 
allows  us  to  combine  the  L  equations  in  (5.33)  into  the  following  single  matrix 
equation: 
Z 
t 
r(t) = e Λt r(0) + 
e Λ(t−τ )βx(τ ) dτ ,  t ≥ 0 
0 
(where the integral of a vector is interpreted as the component-wise integral).  Com­
bining  this  equation  with  the  expression  (5.19)  that  relates  r(t)  to  q(t),  we  ﬁnally 
obtain 
q(t) = ³Ve ΛtV−1´q(0) + Z ³Ve Λ(t−τ )V−1´bx(τ ) dτ 
t 
0 
Z 
t 
e A(t−τ )bx(τ ) dτ ,  t ≥ 0  ,	
= e At q(0) + 
0 
where,  by  analogy  with  (5.25),  we  have  deﬁned  the matrix  exponential 
e At  = Ve ΛtV−1  .	

(5.37) 

(5.38) 

(5.34) 

(5.35) 

(5.36) 

Equation  (5.37)  gives  us,  in  compact  matrix  notation,  the  general  solution  of  the 
CT  LTI  system  (5.1). 

An  entirely  parallel  development  can  be  carried  out  for  the  DT  LTI  case.  The 
corresponding  expression  for  the  solution  of  (5.3)  is 
q[n] = ³VΛnV−1´q[0] + X³VΛn−k−1V−1´bx[k ] 
n−1
k=0 
= An q[0] + X 
n−1
An−k−1bx[k ]  , n ≥ 0 .	
k=0 
Equation  (5.40)  is  exactly  the  expression  one  would  get  by  simply  iterating  (5.3) 
forward one step at a time, to get q[n] from q[0].  However, we get additional insight 
from  writing  the  expression  in  the  modally  decomposed  form  (5.39),  because  it 
brings  out  the  role  of  the  eigenvalues  of  A,  i.e.,  the  natural  frequencies  of  the  DT 
system,  in  determining  the  behavior  of  the  system,  and  in  particular  its  stability 
properties. 

(5.40) 

(5.39) 

5.5	 TRANSFER  FUNCTION,  HIDDEN  MODES, 
REACHABILITY,  OBSERVABILITY 

The  transfer  function  H (s)  of  the  transformed  model  (5.28),  (5.29)  describes  the 
zero-state input-output relationship in the Laplace transform domain, and is straight­
forward  to  ﬁnd  because  the  equations  are  totally  decoupled.  Taking  the  Laplace 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  5.5 

Transfer  Function,  Hidden  Modes,  Reachability,  Observability  93 

transforms  of  those  equations,  with  zero  initial  conditions  in  (5.28),  results  in 

(5.41) 

(5.42) 

(5.43) 

´ 
+ d 

βi
X (s) 
Ri (s) = 
s − λi 
³  L
ξiRi (s)´ 
Y (s) =  X 
+ dX (s)  . 
1 
Since  Y (s) = H (s)X (s),  we  obtain 
³  L
H (s) =  X
ξiβi
s − λi
1 
which  can  be  rewritten  in matrix  notation  as 
H (s) = ξT (sI − Λ)−1β + d  . 
This  is  also  the  transfer  function  of  the  original  model  in  (5.1),  (5.2),  as  similarity 
transformations do not change transfer  functions.  An alternative expression  for the 
transfer function of (5.1), (5.2) follows from examination of the Laplace transformed 
version  of  (5.1),  (5.2).  We  omit  the  details,  but  the  resulting  expression  is 
H (s) = c T (sI − A)−1b + d 
We  see  from  (5.43)  that  H (s)  will  have  L  poles  in  general.  However,  if  βj  =  0  for 
some  j  —  i.e.,  if  b  can  be  expressed  as  a  linear  combination  of  the  eigenvectors 
other than vj , see (5.32) — then λj  fails to appear as a pole of the transfer function, 
even  though  it  is  still  a  natural  frequency  of  the  system  and  appears  in  the  ZIR 
for  almost  all  initial  conditions.  The  underlying  cause  for  this  hidden  mode  —  an 
internal mode  that  is  hidden  from  the  input/output  transfer  function —  is  evident 
from  (5.28)  or  (5.41):  with  βj  =  0,  the  input  fails  to  excite  the  j th  mode.  We  say 
that  the mode  associated with  λj  is  an  unreachable mode  in  this  case.  In  contrast, 
if  βk  =  0,  we  refer  to  the  kth  mode  as  reachable.  (The  term  controllable  is  also 
used  for  reachable  —  although  strictly  speaking  there  is  a  slight  diﬀerence  in  the 
deﬁnitions  of  the  two  concepts  in  the  DT  case.) 

(5.44) 

(5.45) 

If  all  L  modes  of  the  system  are  reachable,  then  the  system  itself  is  termed  reach­
able,  otherwise  it  is  called  unreachable.  In  a  reachable  system,  the  input  can  fully 
excite  the  state  (and  in  fact  can  transfer  the  state  vector  from  any  speciﬁed  initial 
condition  to any desired  target  state  in ﬁnite  time).  In an unreachable  system,  this 
is  not  possible.  The  notion  of  reachability  arises  in  several  places  in  systems  and 
control  theory. 
The  dual  situation  happens  when  ξj  = 0  for  some  j  —  i.e.,  if  cT vj  = 0,  see  (5.31). 
In  this  case  again,  (5.43)  shows  that  λj  fails  to  appear  as  a  pole  of  the  transfer 
function,  even  though  it  is  still  a  natural  frequency  of  the  system.  Once  again, 
we  have  a  hidden  mode.  This  time,  the  cause  is  evident  in  (5.29)  or  (5.42):  with 
ξj  =  0,  the  j th  mode  fails  to  appear  at  the  output,  even  when  it  is  present  in  the 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
94  Chapter  5 

Properties  of  LTI  State-Space  Models 

state  response.  We  say  that  the  mode  associated  with  λj  is  unobservable  in  this 
case.  In  contrast,  if  ξk  = 0,  then  we  call  the  kth mode  observable. 
If  all  L modes  of  the  system  are  observable,  the  system  itself  is  termed  observable, 
otherwise  it  is  called  unobservable.  In  an  observable  system,  the  behavior  of  the 
state  vector  can  be  unambiguously  inferred  from  measurements  of  the  input  and 
output  over  some  interval  of  time,  whereas  this  is  not  possible  for  an  unobservable 
system.  The  concept  of  observability  also  arises  repeatedly  in  systems  and  control 
theory. 

Hidden modes can cause diﬃculty, especially if they are unstable.  However, if all we 
are  concerned  about  is  representing  a  transfer  function,  or  equivalently  the  input– 
output relation of an LTI system, then hidden modes may be of no signiﬁcance.  We 
can  obtain  a  reduced-order  state-space  model  that  has  the  same  transfer  function 
by  simply  discarding  all  the  equations  in  (5.28)  that  correspond  to  unreachable  or 
unobservable modes,  and  discarding  the  corresponding  terms  in  (5.29). 

The  converse  also  turns  out  to  be  true:  if  a  state-space model  is  reachable  and  ob­
servable,  then  there  is no  lower order  state-space  system  that has  the  same  transfer 
function;  in  other  words,  a  state-space  model  that  is  reachable  and  observable  is 
minimal. 

Again,  an  entirely  parallel  development  can  be  carried  out  for  the  DT  case,  as  the 
next  example  illustrates. 

EXAMPLE  5.1 

A  discrete-time  non-minimal  system 

In  this  example  we  consider  the  DT  system  represented  by  the  state  equations 
0 1    
 
q1 [n + 1]    
q1 [n]   µ 
0  ¶ 
 =  
5    
 +

x[n] 
1 
q2 [n + 1] 
q2 [n] 
−1 
| {z  } 
2 
| 
{z 
} 
b
A 
q1 [n]   
 
³ 
1 ´ 
 + x[n] 

y [n] =  − 1 
2

| 
{z 
} 
q2 [n] 

Tc
A delay-adder-gain block diagram representing (5.46) and (5.47)  is shown  in Figure 
5.1  below. 
The  modes  of  the  system  correspond  to  the  roots  of  the  characteristic  polynomial 
given  by 

(5.47) 

(5.46) 

These  roots  are  therefore 

det  (λI − A) = λ2  − 

5
λ + 1  . 
2 

λ1  = 2  ,

λ2  = 

1 
2 

. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(5.48) 

(5.49) 

6
Section  5.5 

Transfer  Function,  Hidden  Modes,  Reachability,  Observability  95 

� 

z−1 

q1 [n] 

x[n] 
� 

� 

� 
− 
+ 
+ 
� 

� 

z−1 

q2 [n] 

1 
2 

5
2 

− 
+ 

� 
y [n]
�  � 
+ 
�

FIGURE  5.1  Delay-adder-gain  block  diagram  for  the  system  in  Example  5.1,  equa­
tions  (5.46)  and  (5.47). 

λ 
1 

v = 0 

1
2

v1  = 

, 

v2  = 

. 

(5.51) 

(5.50) 

(λI − A)v = 

Since  it  is  not  the  case  here  that  both  eigenvalues  have  magnitude  strictly  less 
than  1,  the  system  is  not  asymptotically  stable.  The  corresponding  eigenvectors 
are  found  by  solving 
µ 
¶
−1 
5
λ −
2 
with  λ = λ1  = 2,  and  then  again  with  λ = λ2  =
. 
This  yields 
2  ¶ 
µ 
µ 
1  ¶
1 
2
The  input-output  transfer  function  of  the  system  is  given  by 
H (z ) = c T (z I − A)−1b + d 
 
z − 5
1 
2
 
(z I − A)−1 
5
z 2  − z + 1 
−1 
2
#  
 
" 
z − 5
1 
1 
2
 
− 1 
z + 1  
5
2
−1 
2
z − 2 
1 
1 
1
+ 1 = 
2 
2  z 2  −
5
z + 1 
z −
2
1 
1 − 1
2 z−1 

1  
 
z
0  ¸

· 

1


H (z ) = 

z 2 

−

= 

= 

+ 1 

1
2

(5.52) 

(5.53) 

(5.54) 

= 

1

z

+ 1 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

96  Chapter  5 

Properties  of  LTI  State-Space  Models 

Since  the  transfer  function  has  only  one  pole  and  this  pole  is  inside  the  unit  circle, 
the  system  is  input-output  stable.  However,  the  system  has  two  modes,  so  one  of 
them  is  a  hidden mode,  i.e.,  does  not  appear  in  the  input-output  transfer  function. 
Hidden modes are either unreachable from the  input or unobservable in the output, 
or  both.  To  explicitly  check which  is  the  case  in  this  example,  we  change  to modal 
coordinates,  so  the  original  description 

q[n + 1] = Aq[n] + bx[n] 

y [n] = c T q[n] + dx[n] 

q[n] = Vr[n] 

(5.55) 

(5.56) 

(5.57) 

gets  transformed  via 

to  the  form 

(5.60) 

(5.58) 

(5.59) 

1
2 

. 

where 

r[n + 1] =  V−1AV  r[n] +  V−1b x[n] 
|  {z  } 
| {z  } 
b
b
b=β 
A=Λ
y [n] = c T V r[n] +  dx[n] 
| {z } 
bc=ξ 
 
|   · 
2  ¸ 
|
V =   v1 
v2   =
1 
| 
|
The  new  state  evolution  matrix  bA  will  then  be  diagonal: 
0   
 
2
 
Ab = Λ = 
1 
0 
2 
and  the  modiﬁed  b  and  c matrices  will  be 
 
2  
3 
  , 
bb = β  = 
1 
3− 
3 i
h0
T 
bc  = ξ = 
− 
2 
from  which  it  is  clear  that  the  system  is  reachable  (because  β  has  no  entries  that 
are  0),  but  that  its  eigenvalue  λ1  =  2  is  unobservable  (because  ξ  has  a  0  in  the 
ﬁrst  position).  Note  that  if  we  had  mistakenly  applied  this  test  in  the  original 
coordinates  rather  than modal  coordinates, we would have  erroneously  decided  the 
ﬁrst mode  is  not  reachable  because  the  ﬁrst  entry  of  b  is  0,  and  that  the  system  is 
observable  because  cT  has  no  nonzero  entries. 

d = 1  , 

(5.61) 

(5.62) 

(5.63) 

, 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  5.5 

Transfer  Function,  Hidden  Modes,  Reachability,  Observability  97 

= 

2

0 

r2 [n + 1] 

r1 [n + 1] 

In  the  new  coordinates  the  state  equations  are 
0 
 

 



1
2 
 
Ã 
!
3 
y [n] =  0  − 
2 
r1 [n + 1] = 2r1 [n] + 

or  equivalently 

2 
3 

  
+
1 
− 
3 
 + x[n] 
2 
x[n] 
3 

r1 [n] 

r2 [n] 

r1 [n]

r2 [n] 

r2 [n + 1] = 

1 
r2 [n] − 
2 

1 
x[n] 
3 

3 
y [n] = − 
r2 [n] + x[n] 
2 

x[n] 

(5.64) 



(5.65) 

(5.66) 

(5.67) 

(5.68) 

The  delay-adder-gain  block  diagram  represented  by  (5.64)  and  (5.65)  is  shown  in 
Figure  5.2. 

x[n] 

2 
3 

� 

+ 
� 

− 1 
3 
� 
+ 
� 

0 

r1 [n] 

− 3 
2 

r2 [n] 

� 

z−1 

2 

� 

z−1 

1

2


y [n] 
� 

�� 
+ 
� 

FIGURE  5.2  Delay-adder-gain  block  diagram  for  Example  5.1  after  a  coordinate 
transformation  to  display  the modes. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

98  Chapter  5 

Properties  of  LTI  State-Space  Models 

In  the  block  diagram  of  Figure  5.2  representing  the  state  equations  in  modal  co­
ordinates,  the  modes  are  individually  recognizable.  This  corresponds  to  the  fact 
that  the  original  A  matrix  has  been  diagonalized  by  the  coordinate  change.  From 
this  block  diagram  we  can  readily  see  by  inspection  that  the  unstable  mode  is  not 
observable in the output, since the gain connecting that mode to the output is zero. 
However,  it  is  reachable  from  the  input. 

Note  that  the  block  diagram  in  Figure  5.3  has  the  same  modes  and  input-output 
transfer  function  as  that  in  Figure  5.2.  However,  in  this  case  the  unstable  mode  is 
observable  but  not  reachable. 

0 

� 

+ 
� 

x[n] 

� 

z−1 

2 

− 3 
� 
2 

+ 
� 

� 

z−1

2 
3 

r1 [n] 

1 
3 

r2 [n] 

y [n] 
� 

�� 
+ 
� 

1 
2 
FIGURE  5.3  Delay-adder-gain  block  diagram  for  Example  5.1  realizing  the  same 
transfer  function.  In  this  case  the  unstable mode  is  observable  but  not  reachable. 

EXAMPLE  5.2 
tem 

Evaluating  asymptotic  stability  of  a  linear,  periodically  varying  sys­

The  stability  of  linear  periodically  varying  systems  can  be  analyzed  by  methods 
that  are  close  to  those  used  for  LTI  systems.  Suppose,  for  instance,  that 

q[n + 1] = A[n]q[n]  ,  A[n] = A0  for  even  n, A[n] = A1  for  odd  n. 

Then 

q[n + 2] = A1A0q[n] 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  5.5 

Transfer  Function,  Hidden  Modes,  Reachability,  Observability  99 

for  even  n,  so  the  dynamics  of  the  even  samples  is  governed  by  an  LTI model,  and 
the  stability  of  the  even  samples  is  accordingly  determined  by  the  eigenvalues  of 
the  constant  matrix  Aeven  = A1A0 .  The  stability  of  the  odd  samples  is  similarly 
governed  by  the  eigenvalues  of  the  matrix  Aodd  =  A0A1 ;  it  turns  out  that  the 
nonzero eigenvalues of  this matrix are  the  same as  those of Aeven ,  so either one can 
be  used  for  a  stability  check. 

A0  = 

,  A1  = 

As  an  example,  suppose 
µ 
1  ¶ 
µ 
0 1  ¶
0
4.25  −1.25 
3 
0
whose  respective  eigenvalues  are  (0 ,  3)  and  (1.53 ,  −2.78),  so  both  matrices  have 
eigenvalues  of  magnitude  greater  than  1.  Now 
3  ¶ 
µ 
0.5 
and  its  eigenvalues  are  (0 ,  0.5),  which  corresponds  to  a  stable  system! 

Aeven  = A1A0  = 

, 

(5.69) 

0
0

, 

(5.70) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

100  Chapter  5 

Properties  of  LTI  State-Space  Models 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010

c

C H A P T E R 

6 

State Observers  and  State  Feedback 

Our study of  the modal solutions of LTI state-space models made clear  in complete 
analytical  detail  that  the  state  at  any  given  time  summarizes  everything  about  the 
past  that  is  relevant  to  future  behavior  of  the  model.  More  speciﬁcally,  given  the 
value of the state vector at some initial instant, and given the entire input tra jectory 
over  some  interval  of  time  extending  from  the  initial  instant  into  the  future,  one 
can  determine  the  entire  future  state  and  output  tra jectories  of  the  model  over 
that  interval.  The  same  general  conclusion  holds  for  nonlinear  and  time-varying 
state-space models,  although  they  are  generally  far  less  tractable  analytically.  Our 
focus  will  be  on  LTI models. 

It  is  typically  the  case  that  we  do  not  have  any  direct  measurement  of  the  ini­
tial  state  of  a  system,  and  will  have  to  make  some  guess  or  estimate  of  it.  This 
uncertainty about the  initial state generates uncertainty about the  future state tra­
jectory,  even  if  our  model  for  the  system  is  perfect,  and  even  if  we  have  accurate 
knowledge  of  the  inputs  to  the  system. 

The  ﬁrst  part  of  this  chapter  is  devoted  to  addressing  the  issue  of  state  tra jectory 
estimation, given uncertainty about the initial state of the system.  We shall see that 
the  state  can  actually  be  asymptotically  determined  under  appropriate  conditions, 
by  means  of  a  so-called  state  observer.  The  observer  uses  a  model  of  the  system 
along  with  past  measurements  of  both  the  input  and  output  tra jectories  of  the 
system. 

The  second  part  of  the  chapter  examines  how  the  input  to  the  system  should  be 
controlled  in  order  to  yield  desirable  system  behavior.  We  shall  see  that  having 
knowledge of the present state of the system provides a powerful basis for designing 
feedback  control  to  stabilize  or  otherwise  improve  the  behavior  of  the  resulting 
closed-loop  system.  When  direct  measurements  of  the  state  are  not  available,  the 
asymptotic  state  estimate  provided  by  an  observer  turns  out  to  suﬃce. 

6.1  PLANT  AND  MODEL 

It  is  important now to make a distinction between the actual, physical (and causal) 
system we are interested in studying or working with or controlling — what is often 
termed  the  plant  (as  in  “physical  plant”) —  and  our  idealized model  for  the  plant. 
The plant  is usually a  complex,  highly nonlinear  and  time-varying  ob ject,  typically 
requiring  an  inﬁnite  number  (or  a  continuum)  of  state  variables  and  parameters  to 
represent  it  with  ultimate  ﬁdelity.  Our  model,  on  the  other  hand,  is  an  idealized 
and  simpliﬁed  (and  often  LTI)  representation,  of  relatively  low  order,  that  aims  to 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

101

102  Chapter  6 

State  Observers  and  State  Feedback 

capture  the  behavior  of  the  plant  in  some  limited  regime  of  its  operation,  while 
remaining  tractable  for  analysis,  computation,  simulation  and  design. 

The  inputs  to  the model  represent  the  inputs  acting  on  or driving  the  actual plant, 
and  the  outputs  of  the  model  represent  signals  in  the  plant  that  are  accessible  for 
measurement.  In  practice  we  will  typically  not  know  all  the  driving  inputs  to  the 
plant  exactly.  Apart  from  those  driving  inputs  that  we  have  access  to,  there  will 
also generally be additional unmeasured disturbance inputs acting on the plant that 
we are only able  to  characterize  in  some general way,  perhaps as  random processes. 
Similarly,  the measured outputs of  the plant will diﬀer  from what we might predict 
on  the  basis  of  our  limited  model,  partly  because  of measurement  noise. 

6.2  STATE  ESTIMATION  BY  REAL-TIME  SIMULATION 

Suppose the plant of interest to us is correctly described by the following equations, 
which  constitute  an  Lth-order  LTI  state-space  representation  of  the  plant: 

q[n + 1] = Aq[n] + bx[n] + w[n]  , 
y [n] = c T q[n] + dx[n] + ζ [n]  . 

(6.1) 
(6.2) 

Here  x[n]  denotes  the  known  (scalar)  control  input,  and  w[n]  denotes  the  vector 
of  unknown  disturbances  that  drive  the  plant,  not  necessarily  through  the  same 
channels  as  the  input x[n].  For  example, we might have w[n] = f v [n], where  v [n]  is 
a  scalar  disturbance  signal  and  f  is  a  vector  describing  how  this  scalar  disturbance 
drives  the  system  (just  as  b  describes  how  x[n]  drives  the  system).  The  quantity 
y [n] denotes the known or measured (scalar) output, and ζ [n] denotes the unknown 
noise  in  this  measured  output.  We  refer  to  w[n]  as  plant  disturbance  or  plant 
noise, and to ζ [n] as measurement noise.  We  focus mainly on the DT case now, but 
essentially  everything  carries  over  in  a  natural  way  to  the  CT  case. 

With  the  above  equations  representing  the  true  plant,  what  sort  of  model  might 
we  use  to  study  or  simulate  the behavior  of  the plant,  given  that we  know x[n]  and 
y [n]?  If  nothing  further  was  known  about  the  disturbance  variables  in  w[n]  and 
the  measurement  noise  ζ [n],  or  if  we  only  knew  that  they  could  be  represented  as 
zero-mean  random  processes,  for  instance,  then  one  strategy  would  be  to  simply 
ignore  these  variables  when  studying  or  simulating  the  plant.  If  everything  else 
about  the  plant  was  known,  our  representation  of  the  plant’s  behavior  would  be 
embodied  in  an  LTI  state-space  model  of  the  form 
qb[n + 1] = Aqb[n] + bx[n]  , 
yb[n] = c T qb[n] + dx[n] . 
The x[n]  that drives our model  is  the  same known x[n]  that  is an  input  (along with 
possibly  other  inputs)  to  the  plant.  However,  the  state  qb[n]  and  output  yb[n]  of  the 
model will generally diﬀer  from  the corresponding  state q[n] and output y [n] of  the 
plant,  because  in  our  formulation  the  plant  state  and  output  are  additionally  per­
turbed by w[n] and ζ [n] respectively.  The assumption that our model has correctly 
captured  the  dynamics  of  the  plant  and  the  relationships  among  the  variables  is 

(6.3) 
(6.4) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  6.3 

The  State  Observer  103 

what  allows  us  to  use  the  same A,  b,  cT  and  d  in  our model  as  occur  in  the  “true” 
plant. 

It  bears  repeating  that  in  reality  there  are  several  sources  of  uncertainty  we  are 
ignoring here.  At  the very  least,  there will be discrepancies between  the actual and 
assumed  parameter  values —  i.e.,  between  the  actual  entries  of  A,  b,  cT  and  d  in 
(6.1),  (6.2)  and  the  assumed  entries  of  these  matrices  in  (6.3),  (6.4)  respectively. 
Even  more  troublesome  is  the  fact  that  the  actual  system  is  probably  more  accu­
rately  represented  by  a  nonlinear,  time-varying  model  of  much  higher  order  than 
that  of  our  assumed  LTI  model,  and  with  various  other  disturbance  signals  acting 
on it.  We shall not examine the eﬀects of all these additional sources of uncertainty. 

With a model  in hand,  it  is natural to consider obtaining an estimate of the current 
plant  state  by  running  the model  forward  in  real  time,  as  a  simulator.  For  this, we 
initialize  the  model  (6.3)  at  some  initial  time  (which  we  take  to  be  n =  0  without 
loss  of  generality),  picking  its  initial  state  qb[0]  to  be  some  guess  or  estimate  of  the 
initial  state  of  the  plant.  We  then  drive  the model with  the  known  input x[n]  from 
time  n = 0  onwards,  generating  an  estimated  or  predicted  state  tra jectory  qb[n]  for 
n > 0.  We could then also generate the predicted output yb[n] using the prescription 
in  (6.4). 
In order to examine how well this real-time simulator performs as a state estimator, 
we  examine  the  error  vector 

qe[n] = q[n] − qb[n]  . 
(6.5) 
Note  that  qe[n]  is  the  diﬀerence  between  the  actual  and  estimated  (or  predicted) 
state  tra jectories.  By  subtracting  (6.3)  from  (6.1),  we  see  that  this  diﬀerence,  the 
estimation  error  or  prediction  error  qe[n],  is  itself  governed  by  an  LTI  state-space 
equation: 
qe[n + 1] = Aqe[n] + w[n] 
(6.6) 
with  initial  condition 
(6.7) 
qe[0] = q[0] − qb[0]  . 
This  initial  condition  is  our  uncertainty  about  the  initial  state  of  the  plant. 
What  (6.6)  shows  is  that,  if  the  original  system  (6.1)  is  unstable  (i.e.,  if  A  has 
eigenvalues  of  magnitude  greater  than  1),  or  has  otherwise  undesirable  dynamics, 
and  if  either  qe[0]  or  w[n]  is  nonzero,  then  the  error  qe[n]  between  the  actual  and 
estimated  state  tra jectories will  grow  exponentially,  or will have  otherwise undesir­
able  behavior,  see  Figure  6.1.  Even  if  the  plant  is  not  unstable,  we  see  from  (6.6) 
that the error dynamics are driven by the disturbance process w[n], and we have no 
means to shape the eﬀect of this disturbance on the estimation error.  The real-time 
simulator  is  thus  generally  an  inadequate  way  of  reconstructing  the  state. 

6.3  THE  STATE  OBSERVER 

To do better than the real-time simulator (6.3), we must use not only the input x[n] 
but  also  the measured  output  y [n].  The  key  idea  is  to  use  the  discrepancy  between 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

104  Chapter  6 

State  Observers  and  State  Feedback 

q 

q ^ 

0 

t 

FIGURE  6.1  Schematic  representation  of  the  eﬀect  of  an  erroneous  initial  condition 
on  the  state  estimate  produced  by  the  real-time  simulator  for  an  unstable  plant. 
actual  and  predicted  outputs,  y [n]  in  (6.2)  and  yb[n]  in  (6.4)  respectively —  i.e.,  to 
use  the  output  prediction  error —  as  a  correction  term  for  the  real-time  simulator. 
The  resulting  system  is  termed  a  state  observer  (or  state  estimator)  for  the  plant, 
and  in  our  setting  takes  the  form 
qb[n + 1] = Aqb[n] + bx[n] 
´ 
³ 
− ℓ y [n] − yb[n]
The  observer  equation  above  has  been  written  in  a  way  that  displays  its  two  con­
stituent  parts:  a  part  that  simulates  as  closely  as  possible  the  plant  whose  states 
we are  trying  to  estimate,  and a part  that  feeds  the  correction  term y [n] − yb[n]  into 
this  simulation.  This  correction  term  is  applied  through  the  L-component  vector 
ℓ,  termed  the  observer  gain  vector,  with  ith  component  ℓi .  (The  negative  sign  in 
front of ℓ in (6.8) is used only to simplify the appearance of some later expressions). 
Figure  6.2  is  a  block-diagram  representation  of  the  resulting  structure. 

(6.8) 

. 

Now subtracting (6.8) from (6.1), we ﬁnd that the state estimation error or observer 
error  satisﬁes 
´
³
T 
qe[n + 1] = Aqe[n] + w[n] + ℓ y [n] − c qb[n] − dx[n]
= (A + ℓc T )qe[n] + w[n] + ℓζ [n]  . 
If  the  observer  gain  ℓ  is  0,  then  the  error  dynamics  are  evidently  just  the  dynamics 
of  the  real-time  simulator  (6.6).  More  generally,  the  dynamics  are  governed  by  the 
system’s  natural  frequencies,  namely  the  eigenvalues  of A + ℓcT  or  the  roots  of  the 
characteristic  polynomial 
κ(λ) = det³λI − (A + ℓc T )´ 
= λL  + κL−1λL−1  +
+ κ0  . 
· · · 
(This  polynomial,  like  all  the  characteristic  polynomials  we  deal  with,  has  real 
coeﬃcients  and  is  monic,  i.e.,  its  highest-degree  term  is  scaled  by  1  rather  than 
some  non-unit  scalar.) 

(6.11) 

(6.10) 

(6.9) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  6.3 

The  State  Observer  105 

x[n] 

b 

]1

[  +nq 
+ 
+ + 

observer 
+ ˆq [ n  +  1 ] 
+ 
b 
+ 

­

D

A 

D 

A 

y[n] 

q [ n ] 

cT

ˆq [ n ] 

cT 

ˆy [ n ] 

+ 
+ 

­

l 

FIGURE  6.2  An  observer  for  the  plant  in  the  upper  part  of  the  diagram  comprises 
a  real-time  simulation  of  the  plant,  driven  by  the  same  input,  and  corrected  by  a 
signal  derived  from  the  output  prediction  error. 

Two  questions  immediately  arise: 

(i)	 How  much  freedom  do  we  have  in  placing  the  observer  eigenvalues,  i.e.,  the 
eigenvalues  of  A +  ℓcT  or  the  roots  of  κ(λ),  by  appropriate  choice  of  the 
observer  gain  ℓ ? 
(ii)	 How  does  the  choice  of  ℓ  shape  the  eﬀects  of  the  disturbance  and  noise  terms 
w[n]  and  ζ [n]  on  the  observer  error? 

Brief  answers  to  these  questions  are  respectively  as  follows: 

(i)	 At  ℓ  =  0  the  observer  eigenvalues,  namely  the  eigenvalues  of  A + ℓcT ,  are 
those  of  the  real-time  simulator,  which  are  also  those  of  the  given  system  or 
plant.  By  varying  the  entries  of  ℓ  away  from  0,  it  turns  out  we  can  move  all 
the  eigenvalues  that  correspond  to  observable  eigenvalues  of  the  plant  (which 
may number as many as L eigenvalues), and those are the only eigenvalues we 
can  move.  Moreover,  appropriate  choice  of  ℓ  allows  us,  in  principle,  to  move 
these  observable  eigenvalues  to  any  arbitrary  set  of  self-conjugate  points  in 
the  complex  plane.  (A  self-conjugate  set  is  one  that  remains  unchanged  by 
taking  the  complex  conjugate  of  the  set.  This  is  equivalent  to  requiring  that 
if  a  complex  point  is  in  such  a  set,  then  its  complex  conjugate  is  as  well.) 
The  self-conjugacy  restriction  is  necessary  because  we  are  working  with  real 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

106  Chapter  6 

State  Observers  and  State  Feedback 

parameters  and  gains. 
The unobservable  eigenvalues  of  the plant  remain  eigenvalues  of  the observer, 
and  cannot  be  moved.  (This  claim  can  be  explicitly  demonstrated  by  trans­
formation  to modal coordinates, but we omit  the details.)  The  reason  for  this 
is  that  information  about  these  unobservable  modes  does  not  make  its  way 
into  the  output  prediction  error  that  is  used  in  the  observer  to  correct  the 
real-time  simulator. 
It follows from the preceding statements that a stable observer can be designed 
if and only if all unobservable modes of the plant are stable (a property that is 
termed detectability).  Also, the observer can be designed to have an arbitrary 
characteristic  polynomial  κ(λ)  if  and  only  if  the  plant  is  observable. 
We  shall  not  prove  the  various  claims  above.  Instead,  we  limit  ourselves  to 
proving,  later  in  this  chapter,  a  closely  analogous  set  of  results  for  the  case  of 
state  feedback  control. 
In  designing  observers  analytically  for  low-order  systems,  one way  to  proceed 
is by  specifying a desired  set of observer eigenvalues  ǫ1 ,
ǫL ,  thus  specifying 
· · · 
the  observer  characteristic  polynomial  κ(λ)  as 
L
κ(λ) = Y(λ − ǫi )  .	
i=1 
Expanding  this  out  and  equating  it  to  det³λI −  (A + ℓc T )´ 
,  as  in  (6.10), 
yields L simultaneous linear equations in the unknown gains ℓ1 , 
· · · 
, ℓL .  These 
equations  will  be  consistent  and  solvable  for  the  observer  gains  if  and  only  if 
all  the unobservable eigenvalues of  the plant are  included among  the  speciﬁed 
observer  eigenvalues  {ǫi }. 
The  preceding  results  also  suggest  an  alternative  way  to  determine  the  un-
observable  eigenvalues  of  the  plant:  the  roots  of  det³λI − (A + ℓc  )´ 
T
that 
cannot  be  moved,  no  matter  how  ℓ  is  chosen,  are  precisely  the  unobservable 
eigenvalues  of  the  plant.  This  approach  to  exposing  unobservable  modes  can 
be  easier  in  some  problems  than  the  approach  used  in  the  previous  chapter, 
which  required  ﬁrst  computing  the  eigenvectors  {vi }  of  the  system,  and  then 
checking  for  which  i  we  had  cT vi  = 0. 

(6.12) 

(ii)	 We  now  address  how  the  choice  of  ℓ  shapes  the  eﬀects  of  the  disturbance  and 
noise  terms  w[n]  and  ζ [n]  on  the  observer  error.  The  ﬁrst  point  to  note  is 
that  if  the  error  system  (6.9)  is  made  asymptotically  stable  by  appropriate 
choice  of  observer  gain  ℓ,  then  bounded  plant  disturbance w[n]  and  bounded 
measurement  noise  ζ [n]  will  result  in  the  observer  error  being  bounded.  This 
is most  easily  proved  by  transforming  to modal  coordinates,  but  we  omit  the 
details. 
The  observer  error  equation  (6.9)  shows  that  the  observer  gain  ℓ  enters  in 
two  places,  ﬁrst  in  causing  the  error  dynamics  to  be  governed  by  the  state 
evolution  matrix  A + ℓcT  rather  than  A,  and  again  as  the  input  vector  for 
the  measurement  noise  ζ [n].  This  highlights  a  basic  tradeoﬀ  between  error 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  6.3 

The  State  Observer  107 

decay and noise  immunity.  The observer gain can be used  to obtain  fast error 
decay,  as  might  be  needed  in  the  presence  of  plant  disturbances  w[n]  that 
continually  perturb  the  system  state  away  from  where  we  think  it  is  —  but 
large entries in ℓ may be required to accomplish this (certainly in the CT case, 
but  also  in DT  if  the model  is  a  sampled-data  version  of  some  underlying CT 
system,  as  in  the  following  example),  and  these  large  entries  in  ℓ  will  have 
the  undesired  result  of  accentuating  the  eﬀect  of  the  measurement  noise.  A 
large  observer  gain may  also  increase  the  susceptibility  of  the  observer  design 
to mod!  eling  errors  and  other  discrepancies.  In  practice,  such  considerations 
would lead us design somewhat conservatively, not attempting to obtain overly 
fast  error-decay  dynamics. 
Some  aspects  of  the  tradeoﬀs  above  can  be  captured  in  a  tractable  optimiza­
tion problem.  Modeling w[n]  and  ζ [n]  as  stationary  random processes  (which 
are  introduced  in  a  later  chapter),  we  can  formulate  the  problem  of  picking 
ℓ  to  minimize  some  measure  of  the  steady-state  variances  in  the  components 
of  the  state  estimation  error  qe[n].  The  solution  to  this  and  a  range  of  related 
problems  is provided by  the  so-called Kalman ﬁltering  framework.  We will be 
in  a  position  to  work  through  some  elementary  versions  of  this  once  we  have 
developed  the  machinery  for  dealing  with  stationary  random  processes. 

EXAMPLE  6.1 

Ship  Steering 

= 

(6.13) 

q[n + 1] = 

Consider  the  following  simpliﬁed  sampled-data  model  for  the  steering  dynamics 
of  a  ship  traveling  at  constant  speed,  with  a  rudder  angle  that  is  controlled  in  a 
piecewise-constant  fashion  by  a  computer-based  controller: 
1  σ  ¸ · 
ǫ  ¸ 
· 
· 
· 
q1 [n + 1]  ¸
q1 [n]  ¸
+ 
x[n]
q2 [n + 1] 
0  α
q2 [n] 
σ 
= Aq[n] + bx[n]  . 
The  state  vector  q[n]  comprises  the  sampled  heading  error  q1 [n]  (which  is  the 
direction  the  ship  points  in,  relative  to  the  desired  direction  of  motion)  and  the 
sampled  rate  of  turn  q2 [n]  of  the  ship,  both  sampled  at  time  t  =  nT ;  x[n]  is  the 
constant  value  of  the  rudder  angle  (relative  to  the  direction  in  which  the  ship 
points)  in  the  interval  nT  ≤  t < nT  + T  (we  pick  positive  rudder  angle  to  be  that 
which  would  tend  to  increase  the  heading  error).  The  positive  parameters  α,  σ 
and  ǫ  are  determined  by  the  type  of  ship,  its  speed,  and  the  sampling  interval  T . 
In  particular,  α  is  generally  smaller  than  1,  but  can  be  larger  than  1  for  a  large 
tanker;  in  any  case,  the  system  (6.13)  is  not  asymptotically  stable.  The  constant  σ 
is  approximately  equal  to  the  sampling  interval  T . 
Suppose  we  had  (noisy)  measurements  of  the  rate  of  turn,  so 
T c  = ¡ 
1  ¢ 
. 
0
µ 
1  σ + ℓ1  ¶ 
A + ℓc T  = 
0  α + ℓ2 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Then 

(6.14) 

(6.15) 

. 

108  Chapter  6 

State  Observers  and  State  Feedback 

Evidently  one natural  frequency  of  the  error  equation  is ﬁxed  at  1,  no matter what 
ℓ  is.  This  natural  frequency  corresponds  to  a  mode  of  the  original  system  that  is 
unobservable from rate-of-turn measurements.  Moreover, it is not an asymptotically 
stable  mode,  so  the  corresponding  observer  error  will  not  decay.  Physically,  the 
problem  is  that  the  rate  of  turn  contains  no  input  from  or  information  about  the 
heading  error  itself. 

In  this  case 

If,  instead,  we  have  (noisy)  measurements  of  the  heading  error,  so 
T c  = ¡ 
0  ¢ 
. 
1
µ 
1 + ℓ1  σ  ¶ 
A + ℓc T  = 
α 
ℓ2 
The  characteristic  polynomial  of  this  matrix  is 
κ(λ) = λ2  − λ(1 + ℓ1  + α) + α(1 + ℓ1 ) − ℓ2σ . 
This  can  be  made  into  an  arbitrary  monic  polynomial  of  degree  2  by  choice  of  the 
gains  ℓ1  and  ℓ2 ,  which  also  establishes  the  observability  of  our  plant  model. 
One  interesting choice of observer gains  in  this case  is ℓ1  = −1 − α and ℓ2  = −α2 /σ 
(which,  for  typical  parameter  values,  results  in  ℓ2  being  large).  With  this  choice, 
σ  ¶ 
µ 
−α2
α
/σ  α 
−
The characteristic polynomial of this matrix is κ(λ) = λ2 , so the natural frequencies 
of  the  observer  error  equation  are  both  at  0. 

A + ℓc T  = 

(6.19) 

(6.16) 

(6.17) 

(6.18) 

. 

. 

A DT LTI system with all natural frequencies at 0 is referred to as deadbeat, because 
its  zero-input  response  settles  exactly  to  the  origin  in  ﬁnite  time.  (This  ﬁnite-time 
settling  is  possible  for  the  zero-input  response  of  an  LTI  DT  system,  but  not  for 
an  LTI  CT  system,  though  of  course  it  is  possible  for  an  LTI  CT  system  to  have 
an arbitrarily  small  zero-input  response after any  speciﬁed positive  time.)  We have 
not discussed how  to analyze LTI  state-space models with non-distinct eigenvalues, 
but to verify the above claim of ﬁnite settling  for our observer,  it suﬃces to conﬁrm 
from  (6.19)  that  (A + ℓcT )2  =  0  when  the  gains  ℓi  are  chosen  to  yield  κ(λ) =  λ2 . 
This  implies  that  in  the  absence  of  plant  disturbance  and  measurement  noise,  the 
observer  error  goes  to  0  in  at most  two  steps. 

In the presence of measurement noise, one may want to choose a slower error decay, 
so  as  to  keep  the  observer  gain  ℓ  —  and  ℓ2  in  particular  —  smaller  than  in  the 
deadbeat  case,  and  thereby  not  accentuate  the  eﬀects  of measurement  noise  on  the 
estimation  error. 

6.4  STATE  FEEDBACK  CONTROL 

For  a  causal  system  or  plant  with  inputs  that  we  are  able  to  manipulate,  it  is 
natural  to  ask  how  the  inputs  should  be  chosen  in  order  to  cause  the  system  to 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  6.4 

State  Feedback  Control  109 

behave  in  some  desirable  fashion.  Feedback  control  of  such  a  system  is  based  on 
sensing  its  present  or  past  behavior,  and  using  the  measurements  of  the  sensed 
variables to generate control signals to apply to  it.  Feedback control  is also referred 
to  as  closed-loop  control. 

Open-loop control, by contrast,  is not based on continuous monitoring of the plant, 
but  rather  on  using  only  information  available  at  the  time  that  one  starts  inter­
acting  with  the  system.  The  trouble  with  open-loop  control  is  that  errors,  even  if 
recognized,  are  not  corrected  or  compensated  for.  If  the  plant  is  poorly  behaved  or 
unstable,  then  uncorrected  errors  can  lead  to  bad  or  catastrophic  consequences. 

Feedforward  control  refers  to  schemes  incorporating  measurements  of  signals  that 
currently  or  in  the  future  will  aﬀect  the  plant,  but  that  are  not  themselves  af­
fected  by  the  control.  For  example,  in  generating  electrical  control  signals  for  the 
positioning  motor  of  a  steerable  radar  antenna,  the  use  of  measurements  of  wind 
velocity would correspond to feedforward control, whereas the use of measurements 
of  antenna  position  would  correspond  to  feedback  control.  Controls  can  have  both 
feedback  and  feedforward  components. 

Our  focus  in  this  section  is  on  feedback  control.  To  keep  our  development  stream­
lined,  we  assume  the  plant  is  well  modeled  by  the  following  Lth-order  LTI  state-
space  description: 

q[n + 1] = Aq[n] + bx[n] 
y [n] = c T q[n] 

(6.20) 
(6.21) 

rather  than  the  more  elaborate  description  (6.1),  (6.2).  As  always,  x[n]  denotes 
the  control  input  and  y [n]  denotes  the  measured  output,  both  taken  to  be  scalar 
functions  of  time.  We  shall  also  refer  to  this  as  the  open-loop  system.  Again,  we 
treat  the  DT  case,  but  essentially  everything  carries  over  naturally  to  CT.  Also, 
for  notational  simplicity,  we  omit  from  (6.21)  the  direct  feedthrough  term  dx[n] 
that  has  appeared  in  our  system  descriptions  until  now,  because  this  term  can 
complicate  the  appearance  of  some  of  the  expressions  we  derive,  without  being  of 
much  signiﬁcance  in  itself;  it  is  easily  accounted  for  if  necessary. 

Denote  the  characteristic  polynomial  of  the  matrix A  in  (6.20)  by 
L
a(λ) = det(λI − A) = Y(λ − λi )  . 
i=1 
The  transfer  function H (z )  of  the  system  (6.20),  (6.21)  is  given  by 
H (z ) = c T (z I − A)−1b 
η(z ) 
= 
. 
a(z ) 

(6.22) 

(6.23) 

(6.24) 

(The  absence  of  the  direct  feedthrough  term  in  (6.21)  causes  the  degree  of  the 
polynomial η(z ) to be strictly  less than L.  If the  feedthrough term was present,  the 
transfer  function  would  simply  have  d  added  to  the  H (z )  above.)  Note  that  there 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

110  Chapter  6 

State  Observers  and  State  Feedback 

may  be  pole-zero  cancelations  involving  common  roots  of  a(z )  and  η(z )  in  (6.24), 
corresponding  to  the  presence  of  unreachable  and/or  unobservable  modes  of  the 
system.  Only  the  uncanceled  roots  of  a(z )  survive  as  poles  of  H (z ),  and  similarly 
only  the  uncanceled  roots  of  η(z )  survive  as  zeros  of  the  transfer  function. 

We  reiterate  that  the  model  undoubtedly  diﬀers  from  the  plant  in  many  ways, 
but  we  shall  not  examine  the  eﬀects  of  various  possible  sources  of  discrepancy 
and  uncertainty.  A  proper  treatment  of  such  issues  constitutes  the  ﬁeld  of  robust 
control,  which  continues  to  be  an  active  area  of  research. 

Since  the  state  of  a  system  completely  summarizes  the  relevant  past  of  the  system, 
we  should  expect  that  knowledge  of  the  state  at  every  instant  gives  us  a  powerful 
basis  for  designing  feedback  control  signals.  In  this  section  we  consider  the  use  of 
state feedback for the system (6.20), assuming that we have access to the entire state 
vector  at  each  time.  Though  this  assumption  is  unrealistic  in  general,  it  will  allow 
us  to  develop  some  preliminary  results  as  a  benchmark.  We  shall  later  consider 
what  happens  when  we  treat  the  more  realistic  situation,  where  the  state  cannot 
be measured  but  has  to  be  estimated  instead.  It will  turn  out  in  the  LTI  case  that 
the  state  estimate provided by  an observer will  actually  suﬃce  to accomplish much 
of  what  can  be  achieved  when  the  actual  state  is  used  for  feedback. 

The  particular  case  of LTI  state  feedback  is  represented  in Figure  6.3,  in which  the 
feedback part of the  input x[n]  is a constant  linear function of the state q[n] at that 
instant: 

x[n] = p[n] + g T q[n] 

(6.25) 

where  the  L-component  row  vector  gT  is  the  state  feedback  gain  vector  (with  ith 
component  gi ),  and  p[n]  is  some  external  input  signal  that  can  be  used  to  augment 
the  feedback  signal.  Thus  x[n]  is  p[n]  plus  a  weighted  linear  combination  of  the 
state  variables  qi [n],  with  constant  weights  gi . 

p 

�

+ 
� 

x 

�

Linear  Dynamical 
System 

q 

> 

g T 
q 

<gT

FIGURE  6.3  Linear  dynamical  system  with  LTI  state  feedback.  The  single  lines 
denote  scalar  signals  and  the  double  lines  denote  vector  signals. 

With  this  choice  for  x[n],  the  system  (6.20)  becomes 
´
³
T 
q[n + 1] = Aq[n] + b p[n] + g q[n]
= ³A + bgT ´q[n] + bp[n]  . 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(6.26) 

Section  6.4 

State  Feedback  Control  111 

The  behavior  of  this  closed-loop  system,  and  in  particular  its  stability,  is  governed 
by  its  natural  frequencies,  namely  by  the  L  eigenvalues  of  the  matrix  A + bgT  or 
the  roots  of  the  characteristic  polynomial 
ν (λ) = det³λI − (A + bgT )´	
= λL  + νL−1λL−1  +
+ ν0  .	
· · · 
Some  questions  immediately  arise: 

(6.27) 

(6.28) 

(i)	 How much  freedom do we have  in placing  the closed-loop eigenvalues,  i.e.,  the 
eigenvalues of A + bgT  or the roots of ν (λ), by appropriate choice of the state 
feedback  gain  gT  ? 
(ii)	 How  does  state  feedback  aﬀect  reachability,  observability  and  the  transfer

function  of  the  system? 

(iii)	 How does the choice of gT  aﬀect the state behavior and the control eﬀort that 
is  required? 

Brief  answers  to  these  (inter-related)  questions  are  respectively  as  follows: 

(i)	 By  varying  the  entries  of  gT  away  from  0,  we  can  move  all  the  reachable 
eigenvalues  of  the  system  (which may  number  as many  as  L),  and  only  those 
eigenvalues.  Moreover,  appropriate  choice  of  gT  allows  us,  in  principle,  to 
move  the reachable eigenvalues  to any arbitrary  set of self-conjugate points  in 
the  complex  plane. 
The  unreachable  eigenvalues  of  the  open-loop  system  remain  eigenvalues  of 
the closed-loop  system,  and  cannot be moved.  (This  can be  explicitly demon­
strated  by  transformation  to  modal  coordinates,  but  we  omit  the  details.) 
The  reason  for  this  is  that  the  control  input  cannot  access  these  unreachable 
modes. 
It  follows  from  the  preceding  claims  that  a  stable  closed-loop  system  can  be 
designed  if  and  only  if  all  unreachable  modes  of  the  open-loop  system  are 
stable  (a  property  that  is  termed  stabilizability).  Also,  state  feedback  can 
yield an arbitrary closed-loop characteristic polynomial ν (λ)  if and only  if the 
open-loop  system  (6.20)  is  reachable. 
The  proof  for  the  above  claims  is  presented  in  Section  6.4.1.

In  designing  state  feedback  control  analytically  for  low-order  examples,  one

way to proceed is by specifying a desired set of closed-loop eigenvalues µ1 ,
· · · 
µL ,

thus  specifying  ν (λ)  as 
L
ν (λ) = Y(λ − νi )  .	
(6.29) 
i=1 
Expanding  this  out  and  equating  it  to  det³λI − (A + bgT )´,  as  in  (6.27), 
yields L simultaneous linear equations in the unknown gains g1 , 
, gL .  These 
· · · 
equations  will  be  consistent  and  solvable  for  the  state  feedback  gains  if  and 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

112  Chapter  6 

State  Observers  and  State  Feedback 

only  if  all  the  unreachable  eigenvalues  of  the  plant  are  included  among  the 
speciﬁed  closed-loop  eigenvalues  {µi }. 
The  preceding  results  also  suggest  an  alternative  way  to  determine  the  un­
reachable eigenvalues of the given plant:  the roots of det³λI− (A+bgT )´ 
that 
cannot  be  moved,  no  matter  how  gT  is  chosen,  are  precisely  the  unreachable 
eigenvalues  of  the  plant.  This  approach  to  exposing  unreachable  modes  can 
be  easier  in  some  problems  than  the  approach  used  in  the  previous  chapter, 
which  required  ﬁrst  computing  the  eigenvectors  {vi }  of  the  plant,  and  then 
checking  which  of  these  eigenvectors  were  not  needed  in  writing  b  as  a  linear 
combination  of  the  eigenvectors. 
[The above discussion has closely paralleled our discussion of observers, except 
that  observability  statements  have  been  replaced  by  reachability  statements 
throughout.  The  underlying  reason  for  this  “duality”  is  that  the  eigenvalues 
of  A + bgT  are  the  same  as  those  of  its  transpose,  namely  AT  + gbT .  The 
latter  matrix  has  exactly  the  structure  of  the  matrix  A + ℓcT  that  was  the 
focus  of  our  discussion  of  observers,  except  that  A  is  now  replaced  by  AT , 
and cT  is replaced by bT .  It is not hard to see that the structure of observable 
and  unobservable  modes  determined  by  the  pair  AT  and  bT  is  the  same  as 
the  structure  of  reachable  and  unreachable  modes  determined  by  the  pair  A 
and  b.] 

(ii) 	 The  results  in  part  (i)  above  already  suggest  the  following  fact:  that whether 
or  not  an  eigenvalue  is  reachable  from  the  external  input  —  i.e.,  from  x[n] 
for  the  open-loop  system  and  p[n]  for  the  closed-loop  system —  is  unaﬀected 
by  state  feedback.  An unreachable eigenvalue of  the open-loop  system cannot 
be  excited  from  the  input  x[n],  no  matter  how  the  input  is  generated,  and 
therefore  cannot  be  excited  even  in  closed  loop  (which  also  explains  why  it 
cannot  be  moved  by  state  feedback).  Similarly,  a  reachable  eigenvalue  of  the 
open-loop  system  can  also  be  excited  in  the  closed-loop  system,  because  any 
x[n]  that  excites  it  in  the  open-loop  system  may  be  generated  in  the  closed-
loop  system  by  choosing  p[n] = x[n] − gT q[n]. 
The  proof  in  Section  6.4.1  of  the  claims  in  (i)  will  also  establish  that  the 
transfer  function  of  the  closed-loop  system,  from  p[n]  to  y [n],  is  now 
Hcl (z ) = c T ³ 
z I − (A + bgT )´−1 
b 
η(z ) 
. 
= 
ν (z ) 
Thus  the  zeros  of  the  closed-loop  transfer  function  are  still  drawn  from  the 
roots of  the same numerator polynomial η(z )  in  (6.24)  that contains  the zeros 
of  the  open-loop  system;  state  feedback  does  not  change  η(z ).  However,  the 
actual  zeros  of  the  closed-loop  system  are  those  roots  of  η(z )  that  are  not 
canceled  by  roots  of  the  new  closed-loop  characteristic  polynomial  ν (z ),  and 
may  therefore  diﬀer  from  the  zeros  of  the  open-loop  system. 
We  know  from  the  previous  chapter  that  hidden modes  in  a  transfer  function 
are  the  result  of  the  modes  being  unreachable  and/or  unobservable.  Because 

(6.30) 

(6.31) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  6.4 

State  Feedback  Control  113 

state feedback cannot alter reachability properties,  it follows that any changes 
in cancelations of roots of η(z ),  in going from the original open-loop system to 
the  closed-loop  one,  must  be  the  result  of  state  feedback  altering  the  observ­
ability  properties  of  the  original  modes.  If  an  unobservable  (but  reachable) 
eigenvalue  of  the  open-loop  system  is  moved  by  state  feedback  and  becomes 
observable,  then  a  previously  canceled  root  of  η(z )  is  no  longer  canceled  and 
now  appears  as  a  zero  of  the  closed-loop  system.  Similarly,  if  an  observable 
(and reachable) eigenvalue of the open-loop system is moved by state feedback 
to  a  location where  it  now  cancels  a  root  of  η(z ),  then  this  root  is  no  longer  a 
zero  of  the  closed-loop  system,  and  this  hidden  mode  corresponds  to  a  mode 
that  has  been made  unobservable  by  state  feed!  back. 
(iii)	 We turn now to the question of how the choice of gT  aﬀects the state behavior 
and  the  control  eﬀort  that  is  required.  Note  ﬁrst  that  if  gT  is  chosen  such 
that  the  closed-loop  system  is asymptotically  stable,  then a bounded external 
signal  p[n]  in  (6.26) will  lead  to  a  bounded  state  tra jectory  in  the  closed-loop 
system.  This  is  easily  seen  by  considering  the  transformation  of  (6.26)  to 
modal  coordinates,  but  we  omit  the  details. 
The  state  feedback  gain  gT  aﬀects  the  closed-loop  system  in  two  key  ways, 
ﬁrst  by  causing  the  dynamics  to  be  governed  by  the  eigenvalues  of  A + bgT 
rather  than  those  of A,  and  second  by  determining  the  scaling  of  the  control 
input  x[n]  via  the  relationship  in  (6.25).  This  highlights  a  basic  tradeoﬀ 
between  the  response  rate  and  the  control  eﬀort.  The  state  feedback  gain 
can  be  used  to  obtain  a  fast  response,  to  bring  the  system  state  from  its 
initially  disturbed  value  rapidly  back  to  the  origin —  but  large  entries  in  gT 
may  be  needed  to  do  this  (certainly  in  the  CT  case,  but  also  in  DT  if  the 
model  is  a  sampled-data  version  of  some  underlying  CT  system),  and  these 
large entries  in gT  result  in  large control eﬀort being expended.  Furthermore, 
the  eﬀects  of  any  errors  in  measuring  or  estimating  the  state  vector,  or  of 
modeling  errors  and  other  discrepancies,  are  likely  to  be  accentuated  with 
large  feedback  gains.  In  practice,  these  considerations  would  lead  us  design 
somewhat  conservatively,  not  attempting  to  obtain  overly  fast  closed-loop 
dynamics.  Again,  some  aspects  of  the  tradeoﬀs  involved  can  be  captured  in 
tractable  optimization problems,  but  these  are  left  to more advanced  courses. 

We  work  through  a  CT  example  ﬁrst,  partly  to  make  clear  that  our  development 
carries  over  directly  from  the  DT  to  the  CT  case. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

114  Chapter  6 

State  Observers  and  State  Feedback 

EXAMPLE  6.2 

Inverted  Pendulum  with  Torque  Control 

m 

θ 

R 

FIGURE  6.4  Inverted  pendulum. 

Consider  the  inverted  pendulum  shown  in  Figure  6.4,  comprising  a  mass  m  at  the 
end  of  a  light,  hinged  rod  of  length  R.  For  small  deviations  θ(t)  from  the  vertical, 

(6.33) 

q˙ (t) = 

= K θ(t) + σx(t) , 

d2 θ(t) 
dt2 
where  K  =  g/R  (g  being  the  acceleration  due  to  gravity),  σ  = 1/(mR2 ),  and 
a  torque  input  x(t)  is  applied  at  the  point  of  support  of  the  pendulum.  Deﬁne 
q1 (t) = θ(t),  q2 (t) = θ˙(t);  then 
· 
0  ¸ 
· 
1  ¸
0
x(t)  . 
q(t) + 
σ 
K  0 
We could now determine the system eigenvalues and eigenvectors to decide whether 
the  system  is  reachable.  However,  this  step  is  actually  not  necessary  in  order  to 
assess  reachability  and  compute  a  state  feedback.  Instead,  considering  directly  the 
eﬀect  of  the  state  feedback,  we  ﬁnd 
x(t) = g T q(t) 
· 
· 
0  ¸ 
1  ¸
0
[  g1  g2  ]q(t) 
q(t) + 
σ 
K  0 
· 
1  ¸ 
0
q(t)  . 
K + σg1  σg2 
The  corresponding  characteristic  polynomial  is 
ν (λ) = λ2  − λσg2  − (K + σg1 )  . 
Inspection  of  this  expression  shows  that  by  appropriate  choice  of  the  real  gains  g1 
and  g2  we  can make  this  polynomial  into  any  desired monic  second-degree  polyno­
mial.  In other words, we can obtain any self-conjugate set of closed-loop eigenvalues. 
This  also  establishes  that  the  original  system  is  reachable. 

q˙ (t) = 

= 

(6.32) 

(6.34) 

(6.35) 

(6.36) 

(6.37) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  6.4 

State  Feedback  Control  115 

Suppose  we  want  the  closed-loop  eigenvalues  at  particular  numbers  µ1 ,  µ2 ,  which 
is  equivalent  to  specifying  the  closed-loop  characteristic  polynomial  to  be 
ν (λ) = (λ − µ1 )(λ − µ2 ) = λ2  − λ(µ1  + µ2 ) + µ1µ2  . 
Equating  this  to  the  polynomial  in  (6.37)  shows  that 
µ1  + µ2 
µ1µ2  + K
g1  = − 
σ 
σ
Both  gains  are  negative  when  µ1  and  µ2  form  a  self-conjugate  set  in  the  open 
left-half  plane. 

(6.38) 

(6.39) 

g2  = 

and 

. 

We  return  now  to  the  ship  steering  example  introduced  earlier. 

EXAMPLE  6.3 

Ship  Steering  (continued) 

= 

(6.40) 

q[n + 1] = 

Consider  again  the DT  state-space model  in Example  6.1,  repeated  here  for  conve­
nience: 
1  σ  ¸ · 
ǫ  ¸ 
· 
· 
· 
q1 [n + 1]  ¸
q1 [n]  ¸
+ 
x[n]
q2 [n + 1] 
0  α
q2 [n] 
σ 
= Aq[n] + bx[n]  . 
(A model of this  form  is also obtained  for other systems of  interest,  for  instance the 
motion  of  a DC motor whose  input  is  a  voltage  that  is  held  constant  over  intervals 
of  length  T  by  a  computer-based  controller.  In  that  case,  for  x[n]  in  appropriate 
units,  we  have  α = 1,  σ = T ,  and  ǫ = T 2 /2.) 
For  the  purposes  of  this  example,  take 
· 
· 
1  ¸
1  ¸
32 
4 
1 
1 
4 
x[n] = g1 q1 [n] + g2 q2 [n] 
to  get  the  closed-loop  matrix 
· 
g2  ¸
1 
1 +  g1 
+ 
4 
32 
32 
1 +  g2 
g1 
4 
4
The fastest possible closed-loop response in this DT model is the deadbeat behavior 
described  earlier  in  Example  6.1,  obtained  by  placing  both  closed-loop  natural 
frequencies at 0, i.e., choosing the closed-loop characteristic polynomial to be ν (λ) = 
λ2 .  A little bit of algebra shows that g1  and g2  need to satisfy the following equations 
for  this  to  be  achieved: 

A + bgT  = 

and  set 

,  b = 

(6.42) 

A = 

1 
0

(6.41) 

. 

(6.43) 

g1 
32 
g1 
− 
32 

g2 
+  = −2 
4 
g2 
= −1  . 
+
4 

(6.44) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

116  Chapter  6 

State  Observers  and  State  Feedback 

Solving  these  simultaneously,  we  get  g1  =  −16  and  g2  =  −6.  We  have  not  shown 
how  to  analyze  system  behavior  when  there  are  repeated  eigenvalues,  but  in  the 
particular  instance  of  repeated  eigenvalues  at  0,  it  is  easy  to  show  that  the  state 
will  die  to  0  in  a  ﬁnite  number  of  steps —  at most  two  steps,  for  this  second-order 
system.  To  establish  this,  note  that  with  the  above  choice  of  g  we  get 
1  ¸ 
· 
1
2 
16 
1 
−4  − 2 
³A + bgT ´2 
= 0  , 
which shows that any nonzero initial condition will vanish in two steps.  In practice, 
such  deadbeat  behavior  may  not  be  attainable,  as  unduly  large  control  eﬀort  — 
rudder  angles,  in  the  case  of  the  ship  —  would  be  needed.  One  is  likely  therefore 
to  aim  for  slower  decay  of  the  error. 

A + bgT  = 

(6.46) 

(6.45) 

so 

, 

Typically,  we  do  not  have  direct  measurements  of  the  state  variables,  only  knowl­
edge  of  the  control  input,  along  with  noisy  measurements  of  the  system  output. 
The  state  may  then  be  reconstructed  using  an  observer  that  produces  asymptot­
ically  convergent  estimates  of  the  state  variables,  under  the  assumption  that  the 
system (6.20),  (6.21)  is observable.  We shall see  in more detail shortly that one can 
do  quite well  using  the  state  estimates  produced  by  the  observer,  in  place  of  direct 
state measurements,  in  a  feedback  control  scheme. 

6.4.1  Proof  of  Eigenvalue  Placement  Results 

This  subsection  presents  the  proof  of  the main  result  claimed  earlier  for  state  feed­
back, namely that it can yield any (monic, real-coeﬃcient) closed-loop characteristic 
polynomial ν (λ) that includes among its roots all the unreachable eigenvalues of the 
original  system.  We  shall  also  demonstrate  that  the  closed-loop  transfer  function 
is  given  by  the  expression  in  (6.31). 

First  transform  the  open-loop  system  (6.20),  (6.21)  to  modal  coordinates;  this 
changes  nothing  essential  in  the  system,  but  simpliﬁes  the  derivation.  Using  the 
same  notation  for  modal  coordinates  as  in  the  previous  chapter,  the  closed-loop 
system  is  now  deﬁned  by  the  equations 

where 

ri [n + 1] = λi ri [n] + βix[n]  ,
i = 1, 2, . . . , L 
x[n] = γ1 r1 [n] +  + γL rL [n] + p[n]  , 
· · · 
¡ 
γL  ¢ 
· · · 
and  V  is  the  modal  matrix,  whose  columns  are  the  eigenvectors  of  the  open-loop 
system.  The  γi  are  therefore  just  the  state-feedback  gains  in  modal  coordinates. 

(6.47) 
(6.48) 

= g T V  , 

(6.49) 

γ1 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  6.5 

Observer-Based  Feedback  Control  117 

X (z )
P (z ) 

Now  using  (6.47)  and  (6.48)  to  evaluate  the  transfer  function  from  p[n]  to  x[n],  we 
get 
= ³1 − X  γiβi  ´−1 
L
z − λi 
1 
To  obtain  the  second  equality  in  the  above  equation,  we  have  used  the  following 
facts:  (ii)  the  open-loop  characteristic  polynomial  a(z )  is  given  by  (6.22),  and  this 
is  what  appears  in  the  numerator  of  (6.50;  (ii)  the  poles  of  this  transfer  function 
must be the closed-loop poles of the system, and its denominator degree must equal 
its numerator degree, so the denominator of this expression must be the closed-loop 
characteristic  polynomial  ν (z ).  Then  using  (6.24), we  ﬁnd  that  the  overall  transfer 
function  from  the  input  p[n]  of  the  closed-loop  system  to  the  output  y [n]  is 

a(z ) 
ν (z )

(6.50) 

= 

. 

Y (z ) X (z ) 
Y (z ) 
= 
P (z )  X (z ) P (z ) 
η(z )  a(z ) 
a(z )  ν (z ) 
η(z ) 
ν (z ) 

= 

= 

. 

(6.51) 

(6.52) 

(6.53) 

Inverting  (6.50),  we  ﬁnd 

The  conclusion  from  all  this  is  that  state  feedback  has  changed  the  denominator  of 
the input-output transfer function expression from a(z ) in the open-loop case to ν (z ) 
in  the  closed-loop  case,  and  has  accordingly modiﬁed  the  characteristic  polynomial 
and  poles.  State  feedback  has  left  unchanged  the  numerator  polynomial  η(z )  from 
which  the  zeros are  selected;  all  roots of  η(z )  that  are not  canceled by  roots of  ν (z ) 
will  appear  as  zeros  of  the  closed-loop  transfer  function. 
X  γiβi 
L
= 1 − 
z − λi 
1 
Hence, given  the desired closed-loop characteristic polynomial ν (λ), we can expand 
ν (z )/a(z )  in  a  partial  fraction  expansion,  and  determine  the  state  feedback  gain  γi 
(in  modal  coordinates)  for  each  i  by  dividing  the  coeﬃcient  of  1/(z − λi )  by  −βi , 
assuming  this  is  nonzero,  i.e.,  assuming  the  ith mode  is  reachable.  If  the  j th mode 
is  unreachable,  so  βj  =  0,  then  λj  does  not  appear  as  a  pole  on  the  right  side  of 
(6.54),  which  must  mean  that  ν (z )  has  to  contain  z − λj  as  a  factor  (in  order  for 
this  factor  to  cancel  out  on  the  left  side  of  the  equation),  i.e.,  every  unreachable 
natural  frequency  of  the  open-loop  system  has  to  remain  as  a  natural  frequency  of 
the  closed-loop  system. 

ν (z ) 
a(z ) 

(6.54) 

. 

6.5  OBSERVER-BASED  FEEDBACK  CONTROL 

The  obstacle  to  state  feedback  is  the  general  unavailability  of  direct measurements 
of  the  state.  All  we  typically  have  are  knowledge  of  what  control  signal  x[n]  we 
are  applying,  along  with  (possibly  noise-corrupted)  measurements  of  the  output 
y [n],  and  a  nominal  model  of  the  system.  We  have  already  seen  how  to  use  this 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

118  Chapter  6 

State  Observers  and  State  Feedback 

(6.55) 

information  to  estimate  the  state  variables,  using  an  observer  or  state  estimator. 
Let  us  therefore  consider  what  happens  when  we  use  the  state  estimate  provided 
by  the  observer,  rather  than  the  (unavailable)  actual  state,  in  the  feedback  control 
law  (6.25).  With  this  substitution,  (6.25)  is modiﬁed  to 
x[n] = p[n] + g T qb[n] 
= p[n] + g T (q[n] − qe[n])  . 
The  overall  closed-loop  system  is  then  as  shown  in  Figure  6.5,  and  is  governed  by 
the  following  state-space  model,  obtained  by  combining  the  representations  of  the 
subsystems  that make up  the overall  system, namely  the plant  (6.1),  observer error 
dynamics  (6.9),  and  feedback  control  law  (6.55): 
· 
0  ¸ 
· 
· 
q[n]  ¸ · 
A + bgT  −bgT  ¸ · 
· 
I  ¸
b  ¸
q[n + 1]  ¸
ζ [n]  . 
w[n]+ 
p[n]+ 
q[n + 1]  = 
+
A + ℓcT 
0 
0 
ℓ
I
q[n]
e
e
(6.56) 
Note  that  we  have  reverted  here  to  the  more  elaborate  plant  representation  in 
(6.1),  (6.2)  rather  than  the  streamlined  one  in  (6.20),  (6.21),  in  order  to  display 
the  eﬀect  of  plant  disturbance  and  measurement  error  on  the  overall  closed-loop 
system.  (Instead  of  choosing  the  state  vector  of  the  overall  system  to  comprise 
the  state  vector  q[n]  of  the  plant  and  the  state  vector  qe[n]  of  the  error  equation, 
we  could  equivalently  have  picked  q[n]  and  qb[n].  The  former  choice  leads  to  more 
transparent  expressions.) 
The  (block)  triangular  structure  of  the  state matrix  in  (6.56)  allows  us  to  conclude 
that  the natural  frequencies of  the overall  system are  simply  the eigenvalues of A + 
bgT  along with those of A + ℓcT .  (This  is not hard to demonstrate, either based on 
the  deﬁnition  of  eigenvalues  and  eigenvectors,  or  using  properties  of  determinants, 
but  we  omit  the  details.)  In  other  words,  our  observer-based  feedback  control  law 
results  in  a  nicely  behaved  closed-loop  system,  with  natural  frequencies  that  are 
the  union  of  those  obtained  with  perfect  state  feedback  and  those  obtained  for  the 
observer error equation.  Both sets of natural frequencies can be arbitrarily selected, 
provided  the  open-loop  system  is  reachable  and  observable.  One  would  normally 
pick  the modes  that  govern  observer  error  decay  to  be  faster  than  those  associated 
with  state  feedback,  in order  to have  reasonably accurate estimates available  to  the 
feedback  control  law  before  the  plant  state  can  wander  too  far  away  from  what  is 
desired. 

The  other  interesting  fact  is  that  the  transfer  function  from  p[n]  to  y [n]  in  the  new 
closed-loop  system  is  exactly  what  would  be  obtained  with  perfect  state  feedback, 
namely the transfer function in (6.46).  The reason is that the condition under which 
the  transfer  function  is  computed  —  as  the  input-output  response  when  starting 
from  the  zero  state  —  ensures  that  the  observer  starts  up  from  the  same  initial 
condition  as  the  plant.  This  in  turn  ensures  that  there  is  no  estimation  error,  so 
the  estimated  state  is  as  good  as  the  true  state.  Another  way  to  see  this  is  to  note 
that  the  observer  error  modes  are  unobservable  from  the  available  measurements. 

The  preceding  observer-based  compensator  is  the  starting  point  for  a  very  general 
and  powerful  approach  to  control  design,  one  that  carries  over  to  the  multi-input, 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  6.5 

Observer-Based  Feedback  Control  119 

p


� +
� 

x


� 

Plant 
q 

y


�  Observer 
bq 

� 

by = cT bq 

� 
� 
+ 
�− 

�ℓ

� 

g T 

bq 

FIGURE  6.5  Observer-based  compensator,  feeding  back  an  LTI  combination  of  the 
estimated  state  variables. 

multi-output  case.  With  the  appropriate  embellishments  around  this  basic  struc­
ture, one can obtain every possible stabilizing LTI feedback controller for the system 
(6.20),  (6.21).  Within  this  class  of  controllers,  we  can  search  for  those  that  have 
good  robustness  properties,  in  the  sense  that  they  are  relatively  immune  to  the 
uncertainties  in  our  models.  Further  exploration  of  all  this  has  to  be  left  to  more 
advanced  courses. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

120  Chapter  6 

State  Observers  and  State  Feedback 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010

c

C H A P T E R 

7 

Probabilistic Models 

INTRODUCTION 

In  the  preceding  chapters  our  emphasis  has  been  on  deterministic  signals.  In  the 
remainder of this text we expand the class of signals considered to include those that 
are  based  on  probabilistic  models,  referred  to  as  random  or  stochastic  processes. 
In  introducing  this  important  class  of  signals,  we  begin  in  this  chapter  with  a 
review of  the basics of probability and  random variables.  We assume  that you have 
encountered  this  foundational  material  in  a  previous  course,  but  include  a  review 
here  for  convenient  reference  and  to  establish  notation.  In  the  following  chapter 
and  beyond,  we  apply  these  concepts  to  deﬁne  and  discuss  the  class  of  random 
signals. 

7.1  THE  BASIC  PROBABILITY  MODEL 

Associated  with  a  basic  probability  model  are  the  following  three  components,  as 
indicated  in  Figure  7.1: 

1.	 Sample  Space  The  sample  space  Ψ  is  the  set  of  all  possible  outcomes  ψ  of 
the  probabilistic  experiment  that  the  model  represents.  We  require  that  one 
and  only  one  outcome  be  produced  in  each  experiment  with  the model. 
2. 	 Event  Algebra  An  event  algebra  is  a  collection  of  subsets  of  the  sample 
space —  referred  to  as  events  in  the  sample  space —  chosen  such  that  unions 
of  events  and  complements  of  events  are  themselves  events  (i.e.,  are  in  the 
collection  of  subsets).  We  say  that  a  particular  event  has  occurred  if  the 
outcome  of  the  experiment  lies  in  this  event  subset;  thus  Ψ  is  the  “certain 
event” because it always occurs, and the empty set ∅ is the “impossible event” 
because  it  never  occurs.  Note  that  intersections  of  events  are  also  events, 
because  intersections  can  be  expressed  in  terms  of  unions  and  complements. 
3. 	 Probability  Measure  A  probability  measure  associates  with  each  event  A 
a  number  P (A),  termed  the  probability  of  A,  in  such  a  way  that: 

(a)  P (A) ≥ 0 ; 
(b)  P (Ψ) = 1 ; 
(c)  If  A ∩ B  = ∅,  i.e.,  if  events  A  and  B  are mutually  exclusive,  then 
P (A ∪ B ) = P (A) + P (B ) . 

c	
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

121

122  Chapter  7 

Probabilistic  Models 

Sample  Space  Ψ 

Outcome  ψ 

Collection  of  outcomes 
(Event) 

� 

� 

FIGURE  7.1  Sample  space  and  events. 

Note that for any particular case we often have a range of options in specifying what 
constitutes an outcome,  in deﬁning an event algebra, and  in assigning a probability 
measure.  It  is generally convenient  to have as  few elements or outcomes as possible 
in a sample space, but we need enough of them to enable speciﬁcation of  the events 
of  interest  to  us.  It  is  typically  convenient  to  pick  the  smallest  event  algebra  that 
contains  the  events  of  interest.  We  also  require  that  there  be  an  assignment  of 
probabilities to events that is consistent with the above conditions.  This assignment 
may  be  made  on  the  basis  of  symmetry  arguments  or  in  some  other  way  that  is 
suggested  by  the  particular  application. 

7.2	 CONDITIONAL  PROBABILITY,  BAYES’  RULE,  AND  INDEPEN­
DENCE 

The probability of event A, given that event B  has occurred,  is denoted by P (A B ). 
|
Knowing  that  B  has  occurred  in  eﬀect  reduces  the  sample  space  to  the  outcomes 
in  B ,  so  a  natural  deﬁnition  of  the  conditional  probability  is 

Δ  P (A ∩ B )
P (A|B ) = 
P (B ) 
It  is  straightforward  to verify  that  this deﬁnition of  conditional probability yields a 
valid  probability measure  on  the  sample  space B .  The  preceding  equation  can  also 
be  rearranged  to  the  form 

if  P (B ) > 0  .	

(7.1) 

P (A ∩ B ) = P (A|B )P (B ) . 	
We often write P (AB ) or P (A, B )  for  the  joint probability P (A ∩ B ).  If P (B ) = 0, 
then  the  conditional  probability  in  (7.1)  is  undeﬁned. 

(7.2) 

By  symmetry,  we  can  also  write 

P (A ∩ B ) = P (B |A)P (A)	
Combining  the  preceding  two  equations,  we  obtain  one  form  of  Bayes’  rule  (or 
theorem),  which  is  at  the  heart  of  much  of  what  we’ll  do  with  signal  detection, 

(7.3) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  7.2 

Conditional  Probability,  Bayes’  Rule,  and  Independence  123 

classiﬁcation,  and  estimation: 

)P 
P (A
(B ) 
|B
(A
P
)

P (B |A) = 
A more detailed form of Bayes’ rule can be written for the conditional probability of 
one  of  a  set  of  events  {Bj }  that  are mutually  exclusive  and  collectively  exhaustive, 
i.e.  Bℓ  ∩ Bm  = ∅  if  ℓ =6 m,  and S Bj  = Ψ.  In  this  case, 
j 
P (A ∩ Bj ) = X 
P (A) = X 
P (A|Bj )P (Bj ) 
j 
j
P (A|Bℓ )P (Bℓ ) 
P (Bℓ A) = 
Pj  P (A|Bj )P (Bj ) 
|
Events  A  and  B  are  said  to  be  independent  if 
P (A B ) = P (A) 
|
or  equivalently  if  the  joint  probability  factors  as 

so  that 

(7.5) 

(7.4) 

(7.6) 

(7.7) 

P (A ∩ B ) = P (A)P (B )  . 
More  generally,  a  collection  of  events  is  said  to  be  mutually  independent  if  the 
probability  of  the  intersection  of  events  from  this  collection,  taken  any  number  at 
a  time,  is  always  the  product  of  the  individual  probabilities.  Note  that  pairwise 
independence  is  not  enough.  Also,  two  sets  of  events  A  and  B  are  said  to  be 
independent  of  each  other  if  the  probability  of  an  intersection  of  events  taken  from 
these two sets always factors into the product of the joint probability of those events 
that  are  in  A  and  the  joint  probability  of  those  events  that  are  in  B . 

(7.8) 

EXAMPLE  7.1 

Transmission  errors  in  a  communication  system 

A  communication  system  transmits  symbols  labeled  A,  B ,  and  C .  Because  of 
errors  (noise)  introduced  by  the  channel,  there  is  a  nonzero  probability  that  for 
each  transmitted  symbol,  the  received  symbol  diﬀers  from  the  transmitted  one. 
Table  7.1  describes  the  joint  probability  for  each  possible  pair  of  transmitted  and 
received  symbols  under  a  certain  set  of  system  conditions. 

Symbol  sent  A 
0.05 
A 
0.13 
B 
0.12 
C 

Symbol  received 
B 
0.10 
0.08 
0.07 

C 
0.09 
0.21 
0.15 

TABLE  7.1  Joint  probability  for  each  possible  pair  of  transmitted  and  received 
symbols 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

124  Chapter  7 

Probabilistic  Models 

For  notational  convenience  let’s  use  As ,  Bs ,  Cs  to  denote  the  events  that  A,  B  or 
C  respectively  is  sent,  and  Ar ,  Br ,  Cr  to  denote  A,  B  or  C  respectively  being  re­
ceived.  So,  for  example, P (Ar , Bs ) = 0.13  and P (Cr , Cs ) = 0.15.  To determine  the 
marginal probability P (Ar ), we  sum  the probabilities  for all  the mutually  exclusive 
ways  that  A  is  received.  So,  for  example, 

P (Ar ) =  P (Ar , As ) + P (Ar , Bs ) + P (Ar , Cs ) 
.05 + .13 + .12 = 0.3  . 
= 

(7.9) 

Similarly  we  can  determine  the marginal  probability  P (As )  as 

P (As ) = P (Ar , As ) + P (Br , As ) + P (Cr , As ) = 0.24 

(7.10) 

In a communication context, it may be important to know the probability, for exam­
ple,  that  C  was  sent,  given  that  B  was  received,  i.e.,  P (Cs Br ).  That  information 
|
is  not  entered  directly  in  the  table  but  can  be  calculated  from  it  using  Bayes’  rule. 
Speciﬁcally,  the  desired  conditional  probability  can  be  expressed  as 

P (Cs , Br )
P (Cs |Br ) = 
P (Br ) 
The  numerator  in  (7.11)  is  given  directly  in  the  table  as  .07.  The  denominator  is 
calculated  as  P (Br ) = P (Br , As ) + P (Br , Bs ) + P (Br , Cs ) = 0.25.  The  result  then 
is  that  P (Cs Br ) = 0.28. 
|
In  communication  systems  it  is  also  often  of  interest  to  measure  or  calculate  the 
probability of a  transmission  error.  Denoting  this by Pt  it would correspond  to any 
of  the  following  mutually  exclusive  events  happening: 

(7.11) 

(As  ∩ Br ), (As  ∩ Cr ), (Bs  ∩ Ar ), (Bs  ∩ Cr ), (Cs  ∩ Ar ), (Cs  ∩ Br ) 
Pt  is  therefore  the  sum  of  the  probabilities  of  these  six  mutually  exclusive  events, 
and  all  these  probabilities  can  be  read  directly  from  the  table  in  the  oﬀ-diagonal 
locations,  yielding  Pt  = 0.72. 

(7.12) 

7.3  RANDOM  VARIABLES 

A  real-valued  random  variable  X (  )  is  a  function  that  maps  each  outcome  ψ  of  a 
· 
probabilistic  experiment  to  a  real  number X (ψ),  which  is  termed  the  realization  of 
(or value taken by) the random variable in that experiment.  An additional technical 
requirement  imposed  on  this  function  is  that  the  set  of  outcomes  {ψ}  that maps  to 
the interval X  ≤ x must be an event in Ψ,  for all real numbers x.  We shall typically 
· 
just  write  the  random  variable  as X  instead  of  X (  ) or  X (ψ). 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section 7.4 

Cumulative Distribution, Probability Density, and Probability Mass Function For Random Variables  125 

Ψ 

�Real  line 

� 

X (ψ) 

ψ 

FIGURE  7.2  A  random  variable. 

It  is  often  also  convenient  to  consider  random  variables  taking  values  that  are 
not  speciﬁed  as  real  numbers  but  rather  a  ﬁnite  or  countable  set  of  labels,  say 
L0 , L1 , L2 , . . ..  For  instance,  the  random  status  of  a machine may  be  tracked  using 
the  labels  Idle,  Busy,  and  Failed.  Similarly,  the  random  presence  of  a  target  in  a 
radar  scan  can  be  tracked  using  the  labels  Absent  and  Present.  We  can  think  of 
these  labels  as  comprising  a  set  of  mutually  exclusive  and  collectively  exhaustive 
events,  where  each  such  event  comprises  all  the  outcomes  that  carry  that  label. 
We  refer  to  such  random  variables  as  random  events,  mapping  each  outcome  ψ 
of  a  probabilistic  experiment  to  the  label  L(ψ),  chosen  from  the  possible  values 
L0 , L1 , L2 , . . ..  We  shall  typically  just  write  L  instead  of  L(ψ). 

7.4	 CUMULATIVE  DISTRIBUTION,  PROBABILITY  DENSITY,  AND 
PROBABILITY  MASS  FUNCTION  FOR  RANDOM  VARIABLES 

Cumulative  Distribution  Functions  For  a  (real-valued)  random  variable  X , 
the probability of  the event comprising all ψ  for which X (ψ) ≤ x  is described using 
the  cumulative  distribution  function  (CDF)  FX (x): 

We  can  therefore  write 

FX (x) = P (X  ≤ x)  .	

(7.13) 

P (a < X  ≤ b) = FX (b) − FX (a)  . 	
In  particular,  if  there  is  a  nonzero  probability  that X  takes  a  speciﬁc  value  x1 ,  i.e. 
if  P (X  =  x1 )  >  0,  then  FX (x)  will  have  a  jump  at  x1  of  height  P (X  =  x1 ),  and 
FX (x1 ) − FX (x1−) = P (X  = x1 ).  The CDF  is  nondecreasing  as  a  function  of  x;  it 
starts  from  FX (−∞) = 0  and  rises  to  FX (∞) = 1. 
A  related  function  is  the  conditional  CDF  FX |L (x|Li ),  used  to  describe  the  distri­
bution  of X  conditioned  on  some  random  event L  taking  the  speciﬁc  value Li ,  and 
assuming  P (L = Li ) > 0: 

(7.14) 

FX |L (x|Li ) = P (X  ≤ x|L = Li ) = 

P (X  ≤ x, L = Li )
P (L = Li ) 

. 

(7.15) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

126  Chapter  7 

Probabilistic  Models 

�FX (x) 

1 

x1 

� 
x 

FIGURE  7.3  Example  of  a  CDF. 

Probability Density Functions  The probability density function (PDF) fX (x) 
of  the  random  variable X  is  the  derivative  of  FX (x): 

fX (x) = 

. 

(7.16) 

dFX (x)
dx 
It  is  of  course  always  non-negative  because  FX (x)  is  nondecreasing.  At  points  of 
discontinuity  in FX (x),  corresponding  to values of x  that have non-zero probability 
of  occurring,  there  will  be  (Dirac)  impulses  in  fX (x),  of  strength  or  area  equal  to 
the  height  of  the  discontinuity.  We  can  write 
Z  b 
P (a < X  ≤ b) = 
a 
(Any  impulse  of  fX (x)  at  b  would  be  included  in  the  integral,  while  any  impulse 
at  a  would  be  left  out  —  i.e.  the  integral  actually  goes  from  a+  to  b+.)  We  can 
heuristically  think  of  fX (x) dx  as  giving  the  probability  that  X  lies  in  the  interval 
(x − dx, x]: 

P (x − dx < X  ≤ x) ≈ fX (x) dx  . 
(7.18) 
Note  that  at  values  of  x  where  fX (x)  does  not  have  an  impulse,  the  probability  of 
X  having  the  value  x  is  zero,  i.e.,  P (X  = x) = 0. 
A  related  function  is  the  conditional  PDF  fX |L (x|Li ),  deﬁned  as  the  derivative  of 
FX |L (x|Li )  with  respect  to  x. 

fX (x) dx  . 

(7.17) 

Probability  Mass  Function  A  real-valued  discrete  random  variable  X  is  one 
that  takes  only  a  ﬁnite  or  countable  set  of  real  values,  {x1 , x2 , · · · }.  (Hence  this  is 
actually  a  random  event  —  as  deﬁned  earlier  —  but  speciﬁed  numerically  rather 
than  via  labels.)  The  CDF  in  this  case  would  be  a  “staircase”  function,  while  the 
PDF  would  be  zero  everywhere,  except  for  impulses  at  the  xj ,  with  strengths  cor­
responding  to  the  respective  probabilities  of  the  xj .  These  strengths/probabilities 
are  conveniently  described  by  the  probability  mass  function  (PMF)  pX (x),  which 
gives  the  probability  of  the  event X  = xj : 

P (X  = xj ) = pX (xj )  . 

(7.19) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  7.5 

Jointly  Distributed  Random  Variables  127 

7.5  JOINTLY  DISTRIBUTED  RANDOM  VARIABLES 

We  almost  always  use models  involving multiple  (or  compound)  random  variables. 
Such  situations  are  described  by  joint  probabilities.  For  example,  the  joint CDF  of 
two  random  variables  X  and  Y  is 

FX,Y  (x, y) = P (X  ≤ x, Y  ≤ y)  . 
The  corresponding  joint  PDF  is 

fX,Y  (x, y) = 

∂ 2FX,Y  (x, y)
∂x ∂ y 

and  has  the  heuristic  interpretation  that 

(7.20) 

(7.21) 

(7.22) 

P (x − dx < X  ≤ x  , y − dy < Y  ≤ y) ≈ fX,Y  (x, y) dx dy  . 
The marginal PDF fX (x) is deﬁned as the PDF of the random variable X  considered 
on  its  own,  and  is  related  to  the  joint  density  fX,Y  (x, y)  by 
Z  +∞ 
−∞ 
A  similar  expression  holds  for  the marginal  PDF  fY  (y). 
We  have  already  noted  that  when  the  model  involves  a  random  variable  X  and  a 
random  event  L,  we  may  work  with  the  conditional  CDF 
P (X  ≤ x, L = Li ) 
P (L = Li ) 

FX |L (x Li ) = P (X  ≤ x L = Li ) = 
|
|

fX,Y  (x, y) dy  . 

fX (x) = 

(7.23) 

, 

(7.24) 

provided  P (L  =  Li )  >  0.  The  derivative  of  this  function  with  respect  to  x  gives 
the  conditional PDF fX |L (x|Li ).  When  the model  involves  two  continuous  random 
variables  X  and  Y ,  the  corresponding  function  of  interest  is  the  conditional  PDF 
fX |Y  (x|y)  that  describes  the  distribution  of  X ,  given  that  Y  =  y .  However,  for 
a  continuous  random  variable  Y ,  P (Y  =  y)  =  0,  so  even  though  the  following 
deﬁnition  may  seem  natural,  its  justiﬁcation  is more  subtle: 

fX,Y  (x, y)
fY  (y) 
To  see  the  plausibility  of  this  deﬁnition,  note  that  the  conditional  PDF  fX |Y  (x|y) 
must  have  the  property  that 

fX |Y  (x|y) = 

(7.25) 

. 

fX |Y  (x|y) dx ≈ P (x − dx < X  ≤ x | y − dy < Y  ≤ y) 
but by Bayes’  rule  the quantity on  the  right  in  the above equation can be  rewritten 
as 

(7.26) 

P (x − dx < X  ≤ x | y − dy < Y  ≤ y) ≈ 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

fX,Y  (x, y) dx dy 
fY  (y)dy 

. 

(7.27) 

128  Chapter  7 

Probabilistic  Models 

Combining  the  latter  two  expressions  yields  the  deﬁnition  of  fX |Y  (x|y)  given  in 
(7.25). 

Using  similar  reasoning,  we  can  obtain  relationships  such  as  the  following: 
fX |L (x|Li )P (L = Li ) 
fX (x) 

P (L = Li X  = x) = 
|

. 

(7.28) 

Two random variables X  and Y  are said to be independent or statistically  indepen­
dent  if  their  joint  PDF  (or  equivalently  their  joint  CDF)  factors  into  the  product 
of  the  individual  ones: 

fX,Y  (x, y) =  fX (x)fY  (y)  ,  or 
FX,Y  (x, y) =  FX (x)FY  (y) . 

(7.29) 

This  condition  turns out  to be  equivalent  to having any  collection of  events deﬁned 
in  terms  of X  be  independent  of  any  collection  of  events  deﬁned  in  terms  of  Y . 

For a set of more than two random variables to be  independent, we require that the 
joint  PDF  (or  CDF)  of  random  variables  from  this  set  factors  into  the  product  of 
the  individual  PDFs  (respectively,  CDFs).  One  can  similarly  deﬁne  independence 
of  random  variables  and  random  events. 

EXAMPLE  7.2 

Independence  of  events 

To  illustrate  some  of  the  above  deﬁnitions  and  concepts  in  the  context  of  random 
variables  and  random  events,  consider  two  independent  random  variables X  and Y 
for  which  the  marginal  PDFs  are  uniform  between  zero  and  one: 
½ 
fX (x) = 
fY  (y) = ½ 
Because  X  and  Y  are  independent,  the  joint  PDF  fX,Y  (x, y)  is  given  by 

0 ≤ x ≤ 1 
1
0  otherwise 

0 ≤ y ≤ 1 
1
0  otherwise 

fX,Y  (x, y) = fX (x)fY  (y) 

We  deﬁne  the  events  A,  B ,  C  and  D  as  follows: 
1 o 
1 o 
1 o
n
n
, C  = nx < 
A =  y > 
, B  =  y < 
,
2 
2
2
1 o n
1 o
n
1
1
D =  x < 
and  y > 
2  ∪  x > 
. 
and  y < 
2 
2 
2 
These  events  are  illustrated  pictorially  in  Figure  7.4 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  7.6 

Expectations,  Moments  and  Variance  129 

y 
� 
1 

1 
2 

D 

D 

y 
� 
1 

1 
2 

A 

y 
� 
1 

1 
2 

B 

y 
� 
1 

1 
2 C

� 
x 

� 
x

1 

1 
1 
1 
1 
2
2
2
2
FIGURE  7.4  Illustration  of  events  A,  B ,  C ,  and D ,  for  Example  7.2 

1 

1 

� 
x 

� 
x 

1 

Questions that we might ask include whether these events are pairwise independent, 
e.g.  whether  A  and  C  are  independent.  To  answer  such  questions,  we  consider 
whether the joint probability factors into the product of the individual probabilities. 
So,  for  example, 

µ 
P (A ∩ C ) = P  y > 
P (A) = P (C ) = 

1
, x < 
2 

1 ¶ 
2

= 

1 
4 

1
2

= 0 

, y < 

1 
2 
Since  P (A ∩ C ) = P (A)P (C ),  events  A  and  C  are  independent.  However, 
1 ¶ 
µ 
P (A ∩ B ) = P  y > 
2 
P (A) = P (B ) = 

1 
2 
Since  P (A ∩ B ) =6 P (A)P (B ),  events  A  and  B  are  not  independent. 
Note  that  P (A ∩ C ∩ D) =  0  since  there  is  no  region  where  all  three  sets  overlap. 
1
However,  P (A) =  P (C ) =  P (D)  = 
,  so  P (A ∩ C  ∩ D) =6 P (A)P (C )P (D)  and 
2
the  events A, C ,  and D  are  not mutually  independent,  even  though  they  are  easily 
seen  to  be  pairwise  independent.  For  a  collection  of  events  to  be  independent,  we 
require  the  probability  of  the  intersection  of  any  of  the  events  to  equal  the  product 
of  the  probabilities  of  each  individual  event.  So  for  the  3–event  case,  pairwise 
independence  is  a  necessary  but  not  suﬃcient  condition  for  independence. 

7.6  EXPECTATIONS,  MOMENTS  AND  VARIANCE 

For many purposes it suﬃces to have a more aggregated or approximate description 
than  the  PDF  provides.  The  expectation  —  also  termed  the  expected  or  mean 
or  average  value,  or  the  ﬁrst-moment  —  of  the  real-valued  random  variable  X  is 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

130  Chapter  7 

Probabilistic  Models 

denoted  by  E [X ]  or  X  or  µX ,  and  deﬁned  as 
Z 
∞ 
−∞ 
In terms of the probability “mass” on the real line, the expectation gives the location 
of  the  center  of  mass.  Note  that  the  expected  value  of  a  sum  of  random  variables 
is  just  the  sum  of  the  individual  expected  values: 

E [X ] = X  = µX  = 

xfX (x) dx  . 

(7.30) 

E [X + Y ] = E [X ] + E [Y ]  . 

(7.31) 

Other  simple measures  of  where  the  PDF  is  centered  or  concentrated  are  provided 
by  the  median,  which  is  the  value  of  x  for  which  FX (x) = 0.5,  and  by  the  mode, 
which  is  the  value  of  x  for  which  fX (x)  is  maximum  (in  degenerate  cases  one  or 
both  of  these may  not  be  unique). 

The  variance  or  centered  second-moment  of  the  random  variable  X  is  denoted  by 
σ2  and  deﬁned  as 
X 
σ2  =  E [(X − µX )2 ] = expected  squared  deviation  from  the mean 
Z 
X 
∞ 
(x − µX )2 fX (x)dx 
=
−∞ 
=  E [X 2 ] − µX  , 
2
where  the  last  equation  follows  on  writing  (X  − µX )2  =  X 2  − 2µX X  + µ2  and 
X 
taking  the  expectation  term  by  term.  We  refer  to  E [X 2 ]  as  the  second-moment 
of  X .  The  square  root  of  the  variance,  termed  the  standard  deviation,  is  a  widely 
used  measure  of  the  spread  of  the  PDF. 

(7.32) 

The  focus  of  many  engineering  models  that  involve  random  variables  is  primarily 
on  the means  and  variances  of  the  random  variables.  In  some  cases  this  is  because 
the detailed PDFs  are hard  to determine  or  represent or work with.  In  other  cases, 
the  reason  for  this  focus  is  that  the means  and  variances  completely  determine  the 
PDFs,  as  with  the  Gaussian  (or  normal)  and  uniform  PDFs. 

EXAMPLE  7.3 

Gaussian  and  uniform  random  variables 

Two  common  PDF’s  that  we  will  work  with  are  the  Gaussian  (or  normal)  density 
and  the  uniform  density: 

Gaussian:  fX (x) = 

1 
e− 1 ( x−m )2 
√2πσ 
2 
σ
½ 
1 
b−a 
0 
The  two parameters m and σ  that deﬁne  the Gaussian PDF  can be  shown  to be  its 
mean  and  standard  deviation  respectively.  Similarly,  though  the  uniform  density 
can  be  simply  parametrized  by  its  lower  and  upper  limits  a  and  b  as  above,  an 

a < x < b 
otherwise 

fX (x) = 

Uniform: 

(7.33) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  7.6 

Expectations,  Moments  and  Variance  131 

equivalent  parametrization  is  via  its  mean  m  = (a + b)/2  and  standard  deviation 
σ = p(b − a)2 /12. 
There are useful  statements  that can be made  for general PDFs on  the basis of  just 
the  mean  and  variance.  The  most  familiar  of  these  is  the  Chebyshev  inequality: 
µX | ≥ k´ 
P ³ 
1 
− 
|X
k2  . 
≤ 
σ
X 
This  inequality  implies  that,  for  any  random  variable,  the  probability  it  lies  at 
or  more  than  3  standard  deviations  away  from  the  mean  (on  either  side  of  the 
mean)  is  not  greater  than  (1/32 ) = 0.11.  Of  course,  for  particular  PDFs,  much 
more precise  statements can be made,  and conclusions derived  from  the Chebyshev 
inequality  can  be  very  conservative.  For  instance,  in  the  case  of  a  Gaussian  PDF, 
the  probability  of  being  more  than  3  standard  deviations  away  from  the  mean  is 
only  0.0026,  while  for  a  uniform  PDF  the  probability  of  being  more  than  even  2 
standard  deviations  away  from  the  mean  is  precisely  0. 

(7.34) 

For  much  of  our  discussion  we  shall  make  do  with  evaluating  the  means  and  vari­
ances of  the  random variables  involved  in our models.  Also, we will be highlighting 
problems  whose  solution  only  requires  knowledge  of  means  and  variances. 

The  conditional  expectation  of  the  random  variable  X ,  given  that  the  random 
variable  Y  takes  the  value  y ,  is  the  real  number 
Z  +∞ 
E [X Y  = y ] = 
xfX |Y  (x y)dx = g(y)  , 
|
|
−∞ 
i.e.,  this  conditional  expectation  takes  some  value  g(y)  when  Y  =  y .  We  may  also 
consider  the  random  variable  g(Y ),  namely  the  function  of  the  random  variable  Y 
that,  for  each  Y  =  y ,  evaluates  to  the  conditional  expectation  E [X Y  =  y ].  We 
|
refer to this random variable g(Y ) as the conditional expectation of X  “given Y ” (as 
opposed to “given Y  = y”), and denote g(Y ) by E [X Y ].  Note that the expectation 
|
E [g(Y )]  of  the  random  variable  g(Y ),  i.e.  the  iterated  expectation  E [E [X Y ]],  is 
|
well deﬁned.  What we  show  in  the next paragraph  is  that  this  iterated  expectation 
works  out  to  something  simple,  namely  E [X ].  This  result  will  be  of  particular  use 
in  the  next  chapter. 

(7.35) 

∞ 

∞ 

Consider  ﬁrst  how  to  compute  E [X ]  when  we  have  the  joint  PDF  fX,Y  (x, y).  One 
way  is  to  evaluate  the marginal  density  fX (x)  of X ,  and  then  use  the  deﬁnition  of 
expectation  in  (7.30): 
x³Z 
E [X ] = Z 
fX,Y  (x, y) dy´ 
dx  . 
−∞ 
−∞ 
However,  it  is  often  simpler  to  compute  the  conditional  expectation  of  X ,  given 
Y  =  y ,  then  average  this  conditional  expectation  over  the  possible  values  of  Y , 
using  the marginal  density  of  Y .  To  derive  this more  precisely,  recall  that 
fX,Y  (x, y) = fX |Y  (x|y)fY  (y) 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(7.37) 

(7.36) 

132  Chapter  7 

Probabilistic  Models 

∞ 

and  use  this  in  (7.36)  to  deduce  that 
fY  (y)³Z 
E [X ] = Z 
xfX |Y  (x|y) dx´ 
dy = EY  [EX |Y  [X |Y ]]  . 
−∞ 
−∞ 
We  have  used  subscripts  on  the  preceding  expectations  in  order  to  make  explicit 
which  densities  are  involved  in  computing  each  of  them.  More  simply,  one  writes 

(7.38) 

∞ 

∞ 

(7.39) 

E [X ] = E [E [X Y ]] .	
|
The preceding result has an important implication for the computation of the expec­
tation of a function of a random variable.  Suppose X  = h(Y ), then E [X Y ] = h(Y ), 
|
so 
Z 
E [X ] = E [E [X Y ]] = 
|
−∞ 
This  shows  that  we  only  need  fY  (y)  to  calculate  the  expectation  of  a  function  of 
Y ;  to  compute  the  expectation  of  X  = h(Y ),  we  do  not  need  to  determine  fX (x). 
Similarly,  if X  is  a  function  of  two  random  variables,  X  = h(Y , Z ),  then 
∞	 Z 
Z 
−∞  −∞ 
It  is  easy  to  show  from  this  that  if  Y  and  Z  are  independent,  and  if  h(y , z ) = 
g(y)ℓ(z ),  then 

h(y , z )fY ,Z (y , z )dy dz  . 

h(y)fY  (y)dy  . 

E [X ] = 

(7.41) 

(7.40) 

∞ 

E [g(Y )ℓ(Z )] = E [g(Y )]E [ℓ(Z )]  . 

(7.42) 

7.7	 CORRELATION  AND  COVARIANCE  FOR  BIVARIATE  RANDOM 
VARIABLES 

Consider  a  pair  of  jointly  distributed  random  variables  X  and  Y .  Their  marginal 
PDFs  are  simply  obtained  by  pro jecting  the  probability mass  along  the  y -axis  and 
x-axis  directions  respectively: 
Z 
Z 
−∞ 
−∞	
In  other  words,  the  PDF  of  X  is  obtained  by  integrating  the  joint  PDF  over  all 
possible  values  of  the  other  random  variable  Y  —  and  similarly  for  the  PDF  of  Y . 

fX,Y  (x, y) dx  . 

fX,Y  (x, y) dy , 

fX (x) = 

fY  (y) = 

(7.43) 

∞ 

∞	

It  is of  interest,  just as  in the single-variable case,  to be able to capture the location 
and  spread  of  the  bivariate  PDF  in  some  aggregate  or  approximate  way,  without 
having to describe the full PDF. And again we turn to notions of mean and variance. 
The mean value of  the bivariate PDF  is  speciﬁed by giving  the mean values of  each 
of  its  two  component  random  variables:  the  mean  value  has  an  x  component  that 
is E [X ],  and  a  y  component  that  is E [Y ],  and  these  two  numbers  can  be  evaluated 
from  the  respective marginal  densities.  The  center  of mass  of  the  bivariate  PDF  is 
thus  located  at 

(x, y) = (E [X ], E [Y ])  .	

(7.44) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  7.7 

Correlation  and  Covariance  for  Bivariate  Random  Variables  133 

A  measure  of  the  spread  of  the  bivariate  PDF  in  the  x  direction  may  be  obtained 
from  the  standard  deviation  σX  of  X ,  computed  from  fX (x);  and  a  measure  of 
the  spread  in  the  y  direction  may  be  obtained  from  σY  ,  computed  similarly  from 
fY  (y).  However,  these  two  numbers  clearly  only  oﬀer  a  partial  view.  We  would 
really  like  to  know  what  the  spread  is  in  a  general  direction  rather  than  just  along 
the  two  coordinate  axes.  We  can  consider,  for  instance,  the  standard deviation  (or, 
equivalently,  the  variance)  of  the  random  variable  Z  deﬁned  as 

Z  = αX + βY 

(7.45) 

for  arbitrary  constants  α  and  β .  Note  that  by  choosing  α  and  β  appropriately, 
we  get  Z  =  X  or  Z  =  Y ,  and  therefore  recover  the  special  coordinate  directions 
that  we  have  already  considered;  but  being  able  to  analyze  the  behavior  of  Z  for 
arbitary  α  and  β  allows  us  to  specify  the  behavior  in  all  directions. 

To visualize how Z  behaves, note that Z  = 0 when αx+β y = 0.  This is the equation 
of  a  straight  line  through  the  origin  in  the  (x, y)  plane,  a  line  that  indicates  the 
precise  combinations  of  values  x  and  y  that  contribute  to  determining  fZ (0),  by 
pro jection  of  fX,Y  (x, y)  along  the  line.  Let  us  call  this  the  reference  line.  If Z  now 
takes  a  nonzero  value  z ,  the  corresponding  set  of  (x, y)  values  lies  on  a  line  oﬀset 
from  but  parallel  to  the  reference  line.  We  pro ject  fX,Y  (x, y)  along  this  new  oﬀset 
line  to  determine  fZ (z ). 
Before  seeing  what  computations  are  involved  in  determining  the  variance  of  Z , 
note  that  the  mean  of  Z  is  easily  found  in  terms  of  quantities  we  have  already 
computed,  namely  E [X ]  and  E [Y ]: 

E [Z ] = αE [X ] + βE [Y ]  . 

(7.46) 

As  for  the  variance  of  Z ,  it  is  easy  to  establish  from  (7.45)  and  (7.46)  that 
σ2  = E [Z 2 ] − (E [Z ])2 
Z
where  σ2  and  σ2  are  the  variances  already  computed  along  the  coordinate  direc-
Y 
X
tions  x  and  y ,  and  σX,Y  is  the  covariance  of  X  and  Y ,  also  denoted  by  cov(X, Y ) 
or  CX,Y  ,  and  deﬁned  as 

X  + β 2σ2  + 2αβ σX,Y 
= α2σ2
Y 

(7.47) 

σX,Y  = cov(X, Y ) = CX,Y  = E [(X − E [X ])(Y  − E [Y ])] 
or  equivalently 

(7.48) 

σX,Y  = E [X Y ] − E [X ]E [Y ]  . 
where  (7.49)  follows  from  multiplying  out  the  terms  in  parentheses  in  (7.48)  and 
then  taking  term-by-term  expectations.  Note  that  when  Y  =  X  we  recover  the 
familiar  expressions  for  the  variance  of  X .  The  quantity  E [X Y ]  that  appears  in 
(7.49),  i.e.,  the  expectation  of  the  product  of  the  random  variables,  is  referred  to 
as  the  correlation  or  second  cross-moment  of  X  and  Y  (to  distinguish  it  from  the 
second  self-moments  E [X 2 ]  and  E [Y 2 ]),  and  will  be  denoted  by  RX,Y  : 

(7.49) 

RX,Y  = E [X Y ]  . 

(7.50) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

134  Chapter  7 

Probabilistic  Models 

It is reassuring to note from (7.47) that the covariance σX,Y  is the only new quantity 
needed when  going  from mean  and  spread  computations  along  the  coordinate  axes 
to  such  computations  along  any  axis;  we  do  not  need  a  new  quantity  for  each  new 
direction.  In  summary,  we  can  express  the  location  of  fX,Y  (x, y)  in  an  aggregate 
or  approximate way  in  terms  of  the  1st-moments,  E [X ]  , E [Y ];  and we  can  express 
the  spread around  this  location  in an aggregate or approximate way  in  terms of  the 
(central)  2nd-moments,  σ2  , σ2  , σX,Y  .
Y 
X
It  is  common  to  work  with  a  normalized  form  of  the  covariance,  namely  the  corre­
lation  coeﬃcient  ρX,Y  : 

σX,Y 
σX σY 
This normalization ensures that the correlation coeﬃcient is unchanged if X  and/or 
Y  is  multiplied  by  any  nonzero  constant  or  has  any  constant  added  to  it.  For 
instance,  the  centered  and  normalized  random  variables 
Y  − µY 
X − µX 
σY 
σX 

ρX,Y  = 

(7.52) 

(7.51) 

. 

V  = 

,

W  = 

, 

each  of  which  has  mean  0  and  variance  1,  have  the  same  correlation  coeﬃcient  as 
X  and  Y .  The  correlation  coeﬃcient  might  have  been  better  called  the  covariance 
coeﬃcient,  since  it  is  deﬁned  in  terms  of  the  covariance  and  not  the  correlation  of 
the  two  random  variables,  but  this  more  helpful  name  is  not  generally  utilized. 
Invoking  the  fact  that  σ2  in  (7.47)  must  be  non-negative,  and  further  noting  from 
Z 
this equation  that σ2 /β 2  is quadratic  in α,  it can be proved by elementary analysis 
Z 
of  the  quadratic  expression  that 

|ρX,Y  | ≤ 1  . 
From  the  various  preceding  deﬁnitions,  a  positive  correlation  RX,Y  >  0  suggests 
that X  and Y  tend to take the same sign, on average, whereas a positive covariance 
σX,Y  > 0 —  or  equivalently  a  positive  correlation  coeﬃcient  ρX,Y  > 0 —  suggests 
that  the  deviations  of X  and  Y  from  their  respective means  tend  to  take  the  same 
sign,  on  average.  Conversely,  a  negative  correlation  suggests  that X  and Y  tend  to 
take opposite signs, on average, while a negative covariance or correlation coeﬃcient 
suggests  that  the  deviations  of  X  and  Y  from  their  means  tend  to  take  opposite 
signs,  on  average. 

(7.53) 

Since  the  correlation  coeﬃcient  of  X  and  Y  captures  some  features  of  the  rela­
tion  between  their  deviations  from  their  respective  means,  we  might  expect  that 
the  correlation  coeﬃcient  can  play  a  role  in  constructing  an  estimate  of  Y  from 
measurements  of  X ,  or  vice  versa.  We  shall  see  in  the  next  chapter,  where  linear 
minimum  mean-square  error  (LMMSE)  estimation  is  studied,  that  this  is  indeed 
the  case. 

The random variables X  and Y  are said to be uncorrelated (or linearly independent, 
a  less  common  and  potentially  misleading  term)  if 

E [X Y ] = E [X ]E [Y ]  , 

(7.54) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  7.7 

Correlation  and  Covariance  for  Bivariate  Random  Variables  135 

or  equivalently  if 

σX,Y  = 0  or  ρX,Y  = 0  . 
Thus  uncorrelated  does  not  mean  zero  correlation  (unless  one  of  the  random  vari­
ables  has  an  expected  value  of  zero).  Rather,  uncorrelated  means  zero  covariance. 
Again, a better term  for uncorrelated might have been non-covariant, but this term 
is  not  widely  used. 

(7.55) 

Note  also  that  independent  random  variables X  and  Y ,  i.e.,  those  for  which 

fX,Y  (x, y) = fX (x)fY  (y)  , 

(7.56) 

are always uncorrelated, but the converse is not generally true:  uncorrelated random 
variables  may  not  be  independent.  If  X  and  Y  are  independent,  then  E [X Y ] = 
E [X ]E [Y ]  so  X  and  Y  are  uncorrelated.  The  converse  does  not  hold  in  general. 
For  instance,  consider  the  case where  the  combination  (X, Y )  takes  only  the  values 
(1, 0),  (−1, 0).  (0, 1)  and  (0, −1),  each  with  equal  probability  1 .  Then  X  and  Y
4 
are  easily  seen  to  be  uncorrelated  but  dependent,  i.e.,  not  independent. 

A ﬁnal bit of terminology that we will shortly motivate and ﬁnd useful occurs in the 
following deﬁnition:  Two random variables X  and Y  are orthogonal if E [X Y ] = 0. 

EXAMPLE  7.4 

Perfect  correlation,  zero  correlation 

Consider  the degenerate  case where Y  is  given by  a deterministic  linear  function  of 
a  random  variable  X  (so  Y  is  also  a  random  variable,  of  course): 

Y  = ξX + ζ , 

(7.57) 

where  ξ  and  ζ  are  constants.  Then  it  is  easy  to  show  that  ρX,Y  =  1  if  ξ >  0  and 
ρ = −1 if ξ < 0.  Note that in this case the probability mass is entirely concentrated 
on  the  line  deﬁned  by  the  above  equation,  so  the  bivariate  PDF  —  if  we  insist  on 
talking  about  it!  —  is  a  two-dimensional  impulse  (but  this  fact  is  not  important  in 
evaluating  ρX,Y  ). 
You  should  also  have  no  diﬃculty  establishing  that  ρX,Y  = 0  if 

Y  = ξX 2  + ζ 

(7.58) 

and  X  has  a  PDF  fX (x)  that  is  even  about  0,  i.e.,  fX (−x) = fX (x). 

EXAMPLE  7.5 

Bivariate  Gaussian  density 

The random variables X  and Y  are said to be bivariate Gaussian or bivariate normal 
if  their  joint  PDF  is  given  by 
µY  ´o 
fX,Y  (x, y) = c  expn−q³ x − 
y − 
µX 
σY 
σX 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(7.59) 

,

136  Chapter  7 

Probabilistic  Models 

where  c  is  a  normalizing  constant  (so  that  the  PDF  integrates  to  1)  and  q(v , w) 
is  a  quadratic  function  of  its  two  arguments  v  and  w,  expressed  in  terms  of  the 
correlation  coeﬃcient  ρ  of  X  and  Y : 
1 
2πσX σY p1 − ρ2 
1 
(v 2  − 2ρvw + w 2 )	
2(1 − 
ρ2 )
This density is the natural bivariate generalization of the familiar Gaussian density, 
and  has  several  nice  properties: 

q(v , w) = 

(7.60) 

(7.61) 

c =	

•	 The  marginal  densities  of  X  and  Y  are  Gaussian. 
•	 The  conditional  density  of  Y ,  given  X  =  x,  is  Gaussian  with  mean  ρx  and 
variance σ2  (1 − ρ2 )  (which  evidently does not depend on  the value of x);  and 
Y 
similary  for  the  conditional  density  of X ,  given  Y  = y . 
•	 If  X  and  Y  are  uncorrelated,  i.e.,  if  ρ  =  0,  then  X  and  Y  are  actually 
independent,  a  fact  that  is  not  generally  true  for  other  bivariate  random 
variables,  as  noted  above. 
•	 Any  two aﬃne  (i.e.,  linear plus constant) combinations of X  and Y  are  them­
selves  bivariate  Gaussian  (e.g.,  Q  =  X  + 3Y  + 2  and  R  = 7X  + Y  − 3  are 
bivariate  Gaussian). 

The  bivariate  Gaussian  PDF  and  indeed  the  associated  notion  of  correlation  were 
essentially  discovered  by  the  statistician  Francis  Galton  (a  ﬁrst-cousin  of  Charles 
Darwin)  in 1886, with help from the mathematician Hamilton Dickson.  Galton was 
actually  studying  the  joint  distribution  of  the  heights  of  parents  and  children,  and 
found  that  the marginals  and  conditionals were well  represented  as Gaussians.  His 
question to Dickson was:  what joint PDF has Gaussian marginals and conditionals? 
The  answer:  the  bivariate  Gaussian!  It  turns  out  that  there  is  a  2-dimensional 
version  of  the  central  limit  theorem,  with  the  bivariate  Gaussian  as  the  limiting 
density,  so  this  is  a  reasonable  model  for  two  jointly  distributed  random  variables 
in many  settings.  There  are  also  natural  generalization  to many  variables. 

fX1 ,X2 ,

Some  of  the  generalizations  of  the  preceding  discussion  from  two  random  variables 
to many random variables are fairly evident.  In particular, the mean of a joint PDF 
,Xℓ (x1 , x2 , 
· · · 
··· 
in the ℓ-dimensional space of possible values has coordinates that are the respective 
· · · 
individual  means,  E [X1 ], 
, E [Xℓ ].  The  spreads  in  the  coordinate  directions  are 
deduced  from  the  individual  (marginal)  spreads,  σX1 , 
, σXℓ .  To  be  able  to  com­
· · · 
pute the spreads in arbitrary directions, we need all the additional ℓ(ℓ − 1)/2 central 
2nd  moments,  namely  σXi ,Xj  for  all  1 ≤  i < j  ≤  ℓ  (note  that  σXj ,Xi  = σXi ,Xj ) — 
but  nothing  more. 

(7.62) 

, xℓ )	

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  7.8 

A  Vector-Space  Picture  for  Correlation  Properties  of  Random  Variables  137 

7.8	 A VECTOR-SPACE PICTURE FOR CORRELATION PROPERTIES OF 
RANDOM  VARIABLES 

A  vector-space  picture  is  often  useful  as  an  aid  to  recalling  the  second-moment 
relationships  between  two  random  variables  X  and  Y .  This  picture  is  not  just  a 
mnemonic:  there  is  a  very  precise  sense  in  which  random  variables  can  be  thought 
of  (or  are)  vectors  in  a  vector  space  (of  inﬁnite  dimensions),  as  long  as we  are  only 
interested  in  their  second-moment  properties.  Although  we  shall  not  develop  this 
correspondence  in  any  depth,  it  can  be  very  helpful  in  conjecturing  or  checking 
answers  in  the  linear  minimum  mean-square-error  (LMMSE)  estimation  problems 
that  we  shall  treat. 

To  develop  this  picture,  we  represent  the  random  variables  X  and  Y  as  vectors  X 
and  Y  in  some  abstract  vector  space.  For  the  squared  lengths  of  these  vectors, 
we  take  the  second-moments  of  the  associated  random  variables,  E [X 2 ]  and E [Y 2 ] 
respectively.  Recall  that  in Euclidean vector  space  the  squared  length of a vector  is 
the inner product of the vector with itself.  This suggests that perhaps in our vector-
space interpretation the inner product < X, Y > between two general vectors X and 
Y  should  be  deﬁned  as  the  correlation  (or  second  cross-moment)  of  the  associate 
random  variables: 

< X, Y >= E [X Y ] = RX,Y  .	
(7.63) 
This  indeed  turns  out  to  be  the  deﬁnition  that’s  needed.  With  this  deﬁnition,  the 
standard  properties  required  of  an  inner  product  in  a  vector  space  are  satisﬁed, 
namely: 

Symmetry:  < X, Y >=< Y , X > . 

Linearity:  < X, a1Y1  + a2Y2  >= a1  < X, Y1  > +a2  < X, Y2  > 

Positivity:  < X, X >  is  positive  for X = 0,  and  0  otherwise. 

This  deﬁnition  of  inner  product  is  also  consistent  with  the  fact  that  we  often  refer 
to  two  random  variables  as  orthogonal  when  E [X Y ] = 0. 
The  centered  random  variables X − µX  and Y  − µY  can  similary  be  represented  as 
vectors  Xe and  Ye in  this  abstract  vector  space,  with  squared  lengths  that  are  now 
the  variances  of  the  random  variables X  and  Y : 
σ2  = E [(X − µX )2 ]  ,
σ2  = E [(Y  − µY  )2 ] 
(7.64) 
X	
Y 
respectively.  The  lengths  are  therefore  the  standard  deviations  of  the  associated 
random variables, σX  and σY  respectively.  The  inner product of  the vectors Xe and 
Ye becomes 
< Xe , Ye >= E [(X − µX )(Y  − µY  )] = σX,Y  , 
(7.65) 
namely  the  covariance  of  the  random  variables. 
In  Euclidean  space  the  inner  product  of  two  vectors  is  given  by  the  product  of  the 
lengths  of  the  individual  vectors  and  the  cosine  of  the  angle  between  them: 
< Xe , Ye >= σX,Y  = σX σY  cos(θ)  , 	
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(7.66) 

6
138  Chapter  7 

Probabilistic  Models 

�  Y  − µY 

σY 

θ = cos−1 ρ 
σX 

�X − µX 

FIGURE  7.5  Random  Variables  as  Vectors. 

so  the  quantity 

θ = cos−1³  σX,Y  ´ 
σX σY 
can  be  thought  of  as  the  angle  between  the  vectors.  Here  ρ  is  the  correlation 
coeﬃcient  of  the  two  random  variables,  so  evidently 

= cos−1 ρ 

(7.67) 

ρ = cos(θ)  . 

(7.68) 

Thus,  the  correlation  coeﬃcient  is  the  cosine  of  the  angle  between  the  vectors.  It 
is  therefore  not  surprising  at  all  that 

− 1 ≤ ρ ≤ 1  . 
When  ρ  is  near  1,  the  vectors  are  nearly  aligned  in  the  same  direction,  whereas 
when  ρ  is  near  −1  they  are  close  to  being  oppositely  aligned.  The  correlation 
coeﬃcient is zero when these vectors Xe and Ye (which represent the centered random 
variables) are orthogonal, or equivalently,  the corresponding random variables have 
zero  covariance, 
σX,Y  = 0  . 
(7.70) 

(7.69) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

8 

Estimation with Minimum Mean 
Square  Error 

INTRODUCTION 

A  recurring  theme  in  this  text  and  in  much  of  communication,  control  and  signal 
processing  is  that  of  making  systematic  estimates,  predictions  or  decisions  about 
some  set  of  quantities,  based  on  information  obtained  from measurements  of  other 
quantities.  This  process  is  commonly  referred  to  as  inference.  Typically,  inferring 
the desired  information  from  the measurements  involves  incorporating models  that 
represent  our  prior  knowledge  or  beliefs  about  how  the measurements  relate  to  the 
quantities  of  interest. 

Inference  about  continuous  random  variables  and  ultimately  about  random  pro­
cesses  is  the  topic  of  this  chapter  and  several  that  follow.  One  key  step  is  the 
introduction  of  an  error  criterion  that  measures,  in  a  probabilistic  sense,  the  error 
between  the  desired  quantity  and  our  estimate  of  it.  Throughout  our  discussion 
in  this  and  the  related  subsequent  chapters,  we  focus  primarily  on  choosing  our 
estimate  to  minimize  the  expected  or  mean  value  of  the  square  of  the  error,  re­
ferred  to  as  a  minimum  mean-square-error  (MMSE)  criterion.  In  Section  8.1  we 
consider  the  MMSE  estimate  without  imposing  any  constraint  on  the  form  that 
the  estimator  takes.  In  Section  8.3 we  restrict  the  estimate  to  be  a  linear  combina­
tion  of  the measurements,  a  form  of  estimation  that we  refer  to  as  linear minimum 
mean-square-error  (LMMSE)  estimation. 

Later  in  the  text we  turn  from  inference  problems  for  continuous  random  variables 
to  inference  problems  for  discrete  random  quantities,  which  may  be  numerically 
speciﬁed or may be non-numerical.  In the latter case especially, the various possible 
outcomes  associated  with  the  random  quantity  are  often  termed  hypotheses,  and 
the  inference  task  in  this  setting  is  then  referred  to  as  hypothesis  testing,  i.e.,  the 
task of deciding which hypothesis applies, given measurements or observations.  The 
MMSE criterion may not be meaningful in such hypothesis testing problems, but we 
can  for  instance aim to minimize  the probability of an  incorrect  inference regarding 
which  hypothesis  actually  applies. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

139

140  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

8.1  ESTIMATION  OF  A  CONTINUOUS  RANDOM  VARIABLE 

from  which 

To  begin  the  discussion,  let  us  assume  that  we  are  interested  in  a  random  variable 
Y  and  we  would  like  to  estimate  its  value,  knowing  only  its  probability  density 
function.  We  will  then  broaden  the  discussion  to  estimation  when  we  have  a  mea­
surement  or  observation  of  another  random  variable  X ,  together  with  the  joint 
probability  density  function  of X  and  Y . 
Based  only  on  knowledge  of  the  PDF  of  Y ,  we  wish  to  obtain  an  estimate  of  Y 
—  which  we  denote  as  yb —  so  as  to  minimize  the  mean  square  error  between  the 
actual  outcome  of  the  experiment  and  our  estimate  yb.  Speciﬁcally,  we  choose  yb to 
minimize 
Z 
(y − yb)2 fY  (y) dy  . 
E [(Y  − yb)2 ] = 
(8.1) 
Diﬀerentiating  (8.1)  with  respect  to  yb and  equating  the  result  to  zero,  we  obtain 
Z 
(y − yb)fY  (y) dy = 0 
− 2
(8.2) 
or 
Z 
Z 
yfY  (y) dy = 
yfY  (y) dy 
b
y = E [Y ]  . 
b

The  second  derivative  of  E [(Y  − yb)2 ]  with  respect  to  yb is

Z 
2 
fY  (y) dy = 2  , 
(8.5) 
which  is  positive,  so  (8.4)  does  indeed  deﬁne  the  minimizing  value  of  yb.  Hence  the 
MMSE  estimate  of  Y  in  this  case  is  simply  its mean  value,  E [Y ]. 
The  associated  error —  the  actual MMSE —  is  found  by  evaluating  the  expression 
in  (8.1)  with  yb =  E [Y ].  We  conclude  that  the  MMSE  is  just  the  variance  of  Y , 
2  : 
namely  σY 
min E [(Y  − yb)2 ] = E [(Y  − E [Y ])2 ] = σ2  . 
(8.6) 
Y 
In  a  similar  manner,  it  is  possible  to  show  that  the  median  of  Y ,  which  has  half 
the  probability  mass  of  Y  below  it  and  the  other  half  above,  is  the  value  of  yb that 
minimizes  the  mean  absolute  deviation,  E [ |Y  − yb| ].  Also,  the  mode  of  Y ,  which 
is  the  value  of  y  at  which  the  PDF  fY  (y)  is  largest,  turns  out  to  minimize  the 
expected  value  of  an  all-or-none  cost  function,  i.e.,  a  cost  that  is  unity  when  the 
error  is  outside  of  a  vanishingly  small  tolerance  band,  and  is  zero  within  the  band. 
We will  not  be  pursuing  these  alternative  error metrics  further,  but  it  is  important 
to  be  aware  that  our  choice  of  mean  square  error,  while  convenient,  is  only  one  of 
many  possible  error metrics. 

(8.3) 

(8.4) 

The  insights  from  the  simple  problem  leading  to  (8.4)  and  (8.6)  carry  over  directly 
to  the  case  in which we have  additional  information  in  the  form  of  the measured  or 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  8.1 

Estimation  of  a  Continuous  Random  Variable  141 

observed  value  x  of  a  random  variable  X  that  is  related  somehow  to  Y .  The  only 
change  from  the  previous  discussion  is  that,  given  the  additional  measurement, 
we  work  with  the  conditional  or  a  posteriori  density  fY |X (y |x),  rather  than  the 
unconditioned  density  fY  (y),  and  now  our  aim  is  to minimize 
Z 
E [{Y  − yb(x)}2 |X  = x] = 
{y − yb(x)}2 fY |X (y |x) dy  . 
(8.7) 
We  have  introduced  the  notation  yb(x)  for  our  estimate  to  show  that  in  general  it 
will  depend  on  the  speciﬁc  value  x.  Exactly  the  same  calculations  as  in  the  case  of 
no  measurements  then  show  that 
y(x) = E [Y X  = x] , 
(8.8) 
|
b
the  conditional  expectation  of  Y ,  given  X  = x.  The  associated MMSE  is  the  vari­
ance  σ2 
of  the  conditional  density  fY |X (y |x),  i.e.,  the  MMSE  is  the  conditional 
Y |X 
variance.  Thus,  the  only  change  from  the  case  of  no  measurements  is  that  we  now 
condition  on  the  obtained  measurement. 

Going  a  further  step,  if  we  have  multiple  measurements,  say  X1  =  x1 , X2  = 
, XL  = xL ,  then  we  work  with  the  a  posteriori  density 
x2 , 
· · · 
fY  | X1 ,X2 ,··· ,XL (y | x1 , x2 , · · ·  , xL )  . 
Apart  from  this  modiﬁcation,  there  is  no  change  in  the  structure  of  the  solutions. 
Thus,  without  further  calculation,  we  can  state  the  following: 

(8.9) 

The MMSE  estimate  of  Y , 
given  X1  = x1 , 
, XL  = xL ,
· · · 
is  the  conditional  expectation  of  Y : 

(8.10) 

, XL  = xL ]

y(x1 , . . . , xL ) = E [Y X1  = x1 , 
| 
· · · 
b
For  notational  convenience,  we  can  arrange  the  measured  random  variables  into  a 
column  vector  X,  and  the  corresponding  measurements  into  the  column  vector  x. 
The dependence of the MMSE estimate on the measurements can now be  indicated 
by  the  notation  yb(x),  with 
Z 
∞ 
yb(x) = 
−∞ 
The minimum mean  square  error  (or MMSE)  for  the  given  value  of X  is  again  the 
2 
|X  of  the  conditional  density  fY |X (y | x). 
conditional  variance,  i.e.,  the  variance  σY 

y fY |X (y | X = x) dy = E [ Y  | X = x ]  . 

(8.11) 

EXAMPLE  8.1 

MMSE  Estimate  for  Discrete  Random  Variables 

A discrete-time discrete-amplitude  sequence  s[n]  is  stored  on  a noisy medium.  The 
retrieved  sequence  is  r [n].  Suppose  at  some particular  time  instant n = n0  we have 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

142  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

s[n0 ]  and  r [n0 ]  modeled  as  random  variables,  which  we  shall  simply  denote  by  S 
and  R  respectively.  From  prior  measurements,  we  have  determined  that  S  and  R 
have  the  joint  probability  mass  function  (PMF)  shown  in  Figure  8.1. 

r 

1 

-1 

-1 

1 

s

FIGURE  8.1  Joint  PMF  of  S  and  R. 
Based  on  receiving  the  value  R  =  1,  we  would  like  to  make  an  MMSE  estimate  sb
of  S .  From  (8.10),  sb = E (S |R = 1),  which  can  be  determined  from  the  conditional 
PMF  PS |R (s|R = 1),  which  in  turn  we  can  obtain  as 
PR,S (R = 1, s)
(8.12) 
. 
PS |R (s|R = 1) = 
PR (R = 1) 

From  Figure  8.1, 

(8.13) 

2 
7 

0 
1/7 
1/7 

and 

Consequently, 

s = −1 
s = 0 
s = +1 

PR (1) = 
PR,S (1, s) =  
 
½ 
1/2 
s = 0 
PS |R (s|R = 1) = 
s = +1 
1/2 
Thus,  the  MMSE  estimate  is  sb =  1 .  Note  that  although  this  estimate  minimizes 
2 
the  mean  square  error,  we  have  not  constrained  it  to  take  account  of  the  fact  that 
S  can  only  have  the  discrete  values  of  +1,  0  or  −1.  In  a  later  chapter  we  will 
return  to  this  example  and  consider  it  from  the  perspective  of  hypothesis  testing, 
i.e.,  determining which  of  the  three  known  possible  values will  result  in minimizing 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.1 

Estimation  of  a  Continuous  Random  Variable  143 

a  suitable  error  criterion. 

EXAMPLE  8.2 

MMSE  Estimate  of  Signal  in  Additive  Noise 

A  discrete-time  sequence  s[n]  is  transmitted  over  a  noisy  channel  and  retrieved. 
The  received  sequence  r [n]  is  modeled  as  r [n] =  s[n] + w[n]  where  w[n]  represents 
the  noise.  At  a  particular  time  instant  n =  n0 ,  suppose  r [n0 ],  s[n0 ]  and  w[n0 ]  are 
random  variables,  which  we  denote  as  R,  S  and  W  respectively.  We  assume  that 
1
1
, 
S  and  W  are  independent,  that  W  is  uniformly  distributed  between  + and  −
2
2
and  S  is  uniformly  distributed  between  −1  and  +1.  The  speciﬁc  received  value  is 
1
R = ,  and  we  want  the MMSE  estimate  sb for  S .  From  (8.10), 
4
1 
s = E (S R = 
) 
|
b
4
1
which  can  be  determined  from  fS |R (s R =|
4 ): 
1
1 
|
fR|S ( s)fS (s)
4
fS |R (s|R = 
) = 
1
4 ) 
4
fR (

(8.15) 

(8.14) 

. 

We  evaluate  separately  the  numerator  and  denominator  terms  in  (8.15).  The PDF 
s)  is  identical  in  shape  to  the PDF  of W ,  but with  the mean  shifted  to  s,  as 
fR|S (r

|
1
Consequently,  fR|S (
4 |s)  is  as  shown  in  Figure  8.3,
indicated  in  Figure  8.2  below.

and  fR|S ( 1
s)fS (s)  is  shown  in  Figure  8.4.
4 |

1 

fR|S (r |s) 

− 1
2 + s 
FIGURE  8.2  Conditional  PDF  of  R  given  S ,  fR|S (r |s). 

+ 1
2 + s 

r 

1
1
)  we  divide  Figure  8.4  by  fR ( ),  which  can  easily  be  ob­
To  obtain  fS |R (s R|
=
4
4
tained  by  evaluating  the  convolution  of  the  PDF’s  of  S  and  W 
at  the  argument 
1
1
)  must  have  total  area  of  unity  and  it  is  the 
More  simply,  since  fS |R (s R|
. 
=
4
4
1
4 ), we  can  easily obtain  it by  just normalizing 
same  as Figure  8.4 but  scaled by fR (
Figure  8.4  to  have  an  area  of  1.  The  resulting  value  for  sb is  the  mean  associated 
1
),  which  will  be 
with  the  PDF  fS |R (s R =|
4
1 
. 
s = 
(8.16) 
b
4 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

144  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

1 

3
4 

Plot  of  fR|S (

1
4 |s). 

0 

− 1
4
FIGURE  8.3 

1 
2 

− 1
4
FIGURE  8.4 

0 

3
4

1
Plot  of  fR|S ( s)fS (s). 
4 |

s 

s 

The  associated MMSE  is  the  variance  of  this  PDF,  namely

1 
12 .

EXAMPLE  8.3 

MMSE  Estimate  for  Bivariate  Gaussian  Random  Variables 

Two  random  variables X  and  Y  are  said  to  have  a  bivariate Gaussian  joint PDF  if 
the joint density of the centered (i.e.  zero-mean) and normalized (i.e.  unit-variance) 
random  variables 

V  = 

is  given  by 

X − µX 
σX 

,  W  = 

Y  − µY 
σY 

(8.17) 

fV ,W (v , w) = 

½ 
2 ) ¾ 
(v2 − 2ρvw + w
1 
exp  − 
2πp1 − ρ2 
2(1 − ρ2 ) 
Here µX  and µY  are the means of X  and Y  respectively, and σX , σY  are the respec­
tive  standard  deviations  of  X  and  Y .  The  number  ρ  is  the  correlation  coeﬃcient 
of  X  and  Y ,  and  is  deﬁned  by 

. 

(8.18) 

ρ = 

σX Y 
σX σY 

,  with  σX Y  = E [X Y ] − µX µY 

(8.19) 

where  σX Y  is  the  covariance  of  X  and  Y . 
Now,  consider  yb(x),  the  MMSE  estimate  of  Y  given  X  =  x,  when  X  and  Y  are 
bivariate  Gaussian  random  variables.  From  (8.10), 
y(x) = E [Y X  = x] 
(8.20) 
| 
b
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.2 

From  Estimates  to  an  Estimator  145 

(8.21) 

(8.22) 

or,  in  terms  of  the  zero-mean  normalized  random  variables  V  and W , 
x − µX ¸ 
· 
y(x) = E  (σY W  + µY  )  V  =
| 
b
σX 
µX ¸ 
= σY E · 
x − 
+ µY  . 
W  | V  = 
σX 
| 
It  is  straightforward  to  show  with  some  computation  that  fW |V  (w v)  is  Gaussian 
with  mean  ρv ,  and  variance  1 − ρ2 ,  from  which  it  follows  that 
· 
x − µX ¸ 
· 
x − µX ¸
E W V  =
. 
= ρ
| 
σX 
σX 
Combining  (8.21)  and  (8.22), 
y(x) = E [ Y  X = x ]
| 
b
σY 
= µY  + ρ 
(x − µX ) 
σX 
The  MMSE  estimate  in  the  case  of  bivariate  Gaussian  variables  has  a  nice  linear 
(or  more  correctly,  aﬃne,  i.e.,  linear  plus  a  constant)  form. 
The minimum mean square error is the variance of the conditional PDF fY |X (y |X = 
x): 
E [ (Y  − yb(x))2  | X = x ] = σY 
2  (1 − ρ2 )  . 
(8.24) 
2  is  the mean  square  error  in  Y  in  the  absence  of  any  additional  infor­
Note  that  σY 
mation.  Equation (8.24) shows what the residual mean square error is after we have 
a  measurement  of  X .  It  is  evident  and  intuitively  reasonable  that  the  larger  the 
magnitude  of  the  correlation  coeﬃcient  between X  and  Y ,  the  smaller  the  residual 
mean  square  error. 

(8.23) 

8.2  FROM  ESTIMATES  TO  AN  ESTIMATOR 

The  MMSE  estimate  in  (8.8)  is  based  on  knowing  the  speciﬁc  value  x  that  the 
random variable X  takes.  While X  is a random variable,  the speciﬁc value x  is not, 
and  consequently  yb(x)  is  also  not  a  random  variable. 
As we move forward  in the discussion,  it is important to draw a distinction between 
the estimate of a random variable and the procedure by which we form the estimate. 
This  is  completely  analogous  to  the  distinction  between  the  value  of  a  function  at 
a  point  and  the  function  itself.  We  will  refer  to  the  procedure  or  function  that 
produces  the  estimate  as  the  estimator. 

For instance, in Example 8.1 we determined the MMSE estimate of S  for the speciﬁc 
value  of  R  =  1.  We  could  more  generally  determine  an  estimate  of  S  for  each  of 
the  possible  values  of  R,  i.e.,  −1, 0, and + 1.  We  could  then  have  a  tabulation  of 
these  results  available  in  advance,  so  that  when  we  retrieve  a  speciﬁc  value  of  R 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

146  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

we  can  look  up  the  MMSE  estimate.  Such  a  table  or  more  generally  a  function 
of  R  would  correspond  to  what  we  term  the  MMSE  estimator.  The  input  to  the 
table  or  estimator  would  be  the  speciﬁc  retrieved  value  and  the  output  would  be 
the  estimate  associated  with  that  retrieved  value. 
We  have  already  introduced  the  notation  yb(x)  to  denote  the  estimate  of  Y  given 
X  =  x.  The  function  yb(  )  determines  the  corresponding  estimator,  which  we 
· 
will  denote  by  yb(X ),  or  more  simply  by  just  Yb ,  if  it  is  understood  what  random 
variable  the  estimator  is  operating  on.  Note  that  the  estimator  Yb =  yb(X )  is a 
random  variable.  We  have  already  seen  that  the  MMSE  estimate  yb(x)  is  given  by 
the conditional mean, E [Y X  = x], which suggests yet another natural notation  for 
|
the MMSE  estimator: 
Yb = yb(X ) = E [Y |X ]  . 
(8.25) 
Note  that  E [Y X ]  denotes  a  random  variable,  not  a  number. 
|
The preceding discussion applies essentially unchanged to the case where we observe 
several  random  variables,  assembled  in  the  vector X.  The MMSE  estimator  in  this 
case  is  denoted  by 
Yb = yb(X) = E [Y |X]  . 
Perhaps  not  surprisingly,  the MMSE  estimator  for  Y  given X minimizes  the mean 
square  error,  averaged  over  all  Y  and  X.  This  is  because  the  MMSE  estimator 
minimizes  the mean  square  error  for  each  particular  value  x  of X.  More  formally, 
[Y  − yb(X)]2 ´ 
= EX ³ 
EY |X ³ 
EY ,X ³ 
[Y  − yb(X)]2  | X ´´ 
= Z 
∞ ³ 
EY |X ³ 
[Y  − yb(x)]2  | X = x ´ 
fX (x) dx  . 
−∞ 
(The  subscripts  on  the  expectation  operators  are  used  to  indicate  explicitly  which 
densities  are  involved  in  computing  the  associated  expectations;  the  densities  and 
integration  are  multivariate  when  X  is  not  a  scalar.)  Because  the  estimate  yb(x) 
is  chosen  to  minimize  the  inner  expectation  EY |X  for  each  value  x  of  X,  it  also 
minimizes  the  outer  expectation  EX ,  since  fX (X)  is  nonnegative. 

(8.27) 

(8.26) 

EXAMPLE  8.4 

MMSE  Estimator  for  Bivariate  Gaussian  Random  Variables 

We  have  already,  in  Example  8.3,  constructed  the MMSE  estimate  of  one  member 
of a pair of bivariate Gaussian random variables, given a measurement of the other. 
Using the same notation as  in that example,  it  is evident that the MMSE estimator 
is  simply  obtained  on  replacing  x  by X  in  (8.23): 
σY
Yb = yb(X ) = µY  + ρ
(X − µX )  . 
σX 
The conditional MMSE given X  = x was  found  in the earlier example to be σ2  (1 −Y 
ρ2 ), which did not depend on the value of x, so the MMSE of the estimator, averaged 

(8.28) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.2 

From  Estimates  to  an  Estimator  147 

over  all  X ,  ends  up  still  being  σ2  (1 − ρ2 ). 
Y 

EXAMPLE  8.5 

MMSE  Estimator  for  Signal  in  Additive  Noise 

Suppose the random variable X  is a noisy measurement of the angular position Y  of 
an antenna,  so X  = Y  + W , where W  denotes  the additive noise.  Assume  the noise 
is  independent  of  the  angular  position,  i.e.,  Y  and  W  are  independent  random 
variables,  with  Y  uniformly  distributed  in  the  interval  [−1, 1]  and  W  uniformly 
distributed in the interval [−2, 2].  (Note that the setup in this example is essentially 
the  same  as  in  Example  8.2,  though  the  context,  notation  and  parameters  are 
diﬀerent.) 
Given  that  X  =  x,  we  would  like  to  determine  the  MMSE  estimate  yb(x),  the 
resulting  mean  square  error,  and  the  overall  mean  square  error  averaged  over  all 
possible values x that the random variable X  can take.  Since yb(x) is the conditional 
expectation  of  Y  given  X  =  x,  we  need  to  determine  fY |X (y |x).  For  this,  we  ﬁrst 
determine  the  joint  density  of  Y  and  W ,  and  from  this  the  required  conditional 
density. 
From  the  independence  of  Y  and W : 

fY ,W (y , w) = fY  (y)fW (w) = 

−2

− 2 ≤ w ≤ 2, −1 ≤ y ≤ 1 
otherwise


2 

� 
w 

 1 
8 

 
0 
�y 
1 

0 

−1 

FIGURE  8.5  Joint  PDF  of  Y  and W  for  Example  8.5. 

Conditioned  on  Y  =  y ,  X  is  the  same  as  y + W ,  uniformly  distributed  over  the 
interval  [y − 2, y + 2].  Now 
1
fX,Y  (x, y) = fX |Y  (x|y)fY  (y) = ( 
4

1 
)( 
) = 
2

1 
8 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

148  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

for  −1 ≤ y ≤ 1,  y − 2 ≤ x ≤ y + 2,  and  zero  otherwise.  The  joint  PDF  is  therefore 
uniform  over  the  parallelogram  shown  in  the  Figure  8.6. 

�y 
1 


� 
x


�

−3 

−2 

−1

0 

1

2

3


−1 

FIGURE  8.6  Joint  PDF  of X  and  Y  and  plot  of  the MMSE  estimator  of  Y  from X

for  Example  8.5.


�y 

�y 

�y 

�y 

�y 

�y 

�y 

1 


0 

−1 

1


� 

1


1
2


1
2


1
2


fY |X (y  | −3) 

fY |X (y  | −1) 

fY |X (y  |  1) 

fY |X (y  |  3) 

fY |X (y  | −2) 

fY |X (y  |  0) 

fY |X (y  |  2) 

FIGURE  8.7  Conditional  PDF  fY |X  for  various  realizations  of X  for  Example  8.5. 
Given  X  =  x,  the  conditional  PDF  fY |X  is  uniform  on  the  corresponding  vertical 
section  of  the  parallelogram: 
 
 
1

3 − x 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

c

− 3 ≤ x ≤ −1 , −1 ≤ y ≤ x + 2 

− 1 ≤ x ≤ 1 , −1 ≤ y ≤ 1 
1 ≤ x ≤ 3 , x − 2 ≤ y ≤ 1


(8.29)

1

3 + x

1

2


fY |X (y , x) = 

(8.30)

X  = x]

(8.31) 

0 

1

x

2 

+

X  = x] = 

| 

1
2

1

+  x 
2


(3 + x)2 
12 


1

3

(3 − x)2

12 


− 3 ≤ x < −1 
− 1 ≤ x < 1 
1 ≤ x ≤ 3


Section  8.2 
From  Estimates  to  an  Estimator  149 
The  MMSE  estimate  yb(x)  is  the  conditional  mean  of  Y  given  X  =  x,  and  the 
conditional mean  is  the midpoint of  the  corresponding vertical  section of  the paral­
lelogram.  The conditional mean  is displayed as  the heavy  line on  the parallelogram 
in  the  second  plot.  In  analytical  form, 
 
− 3 ≤ x < −1 
− 1 ≤ x < 1

y(x) = E [Y 
b
 
1
1 ≤ x ≤ 3

− 2
The  minimum  mean  square  error  associated  with  this  estimate  is  the  variance  of 
the  uniform  distribution  in  eq.  (8.29),  speciﬁcally: 
 
E [{Y  − yb(x)}2  | 
 
Equation  (8.31)  speciﬁes  the  mean  square  error  that  results  for  any  speciﬁc  value 
x  of  the measurement  of X .  Since  the measurement  is  a  random  variable,  it  is  also 
of  interest  to  know what  the mean  square  error  is,  averaged  over  all possible  values 
of  the  measurement,  i.e.  over  the  random  variable  X .  To  determine  this,  we  ﬁrst 
determine  the  marginal  PDF  of X : 
 
This  could  also  be  found  by  convolution,  fX  =  fY  ∗  fW ,  since  Y  and  W  are 
statistically  independent.  Then, 
Z∞ 
E [(Y  − yb(x))2  | X  = x]fX (x)dx 
EX [EY |X {(Y  − yb(x)}2  | X  = x]] = 
−∞ 
Z 
Z 
Z 
−1 
3

1
(3 + x)2 
(3 − x)2 
3 + x

3 − x

1

1
( 
= 
)dx + (  )(  )dx + ( 
)( 
)( 
8

12 

12 

8 

3

4

−3 
1 
−1
1

= 
4


− 3 ≤ x < −1 
− 1 ≤ x < 1

1 ≤ x ≤ 3

otherwise


3 + x 

8


1

4

3 − x 
8

0 

fX,Y  (x, y) 
fY |X (y  | x) 

fX (x) = 

= 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010

c

)dx 

150  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

Compare this with the mean square error if we just estimated Y  by its mean, namely 
2  : 
0.  The mean  square  error  would  then  be  the  variance  σY 
[1 − (−1)]2 
12 

1 
3 

= 

σ2 
Y 

=

,

so  the mean  square  error  is  indeed  reduced  by  allowing  ourselves  to  use  knowledge 
of  X  and  of  the  probabilistic  relation  between  Y  and  X . 

8.2.1	 Orthogonality 

A  further  important  property  of  the  MMSE  estimator  is  that  the  residual  error 
Y  − yb(X)  is  orthogonal  to  any  function  h(X)  of  the measured  random  variables: 
EY ,X [{Y  − yb(X)}h(X)] = 0 ,	
(8.32) 
where  the  expectation  is  computed over  the  joint density of Y  and X.  Rearranging 
this,  we  have  the  equivalent  condition 
EY ,X [yb(X)h(X)] = EY ,X [Y h(X)]  , 
i.e.,  the MMSE  estimator  has  the  same  correlation  as  Y  does  with  any  function  of 
X .  In  particular,  choosing  h(X) = 1,  we  ﬁnd  that 
EY ,X [yb(X)] = EY  [Y ]  .	
The  latter  property  results  in  the  estimator  being  referred  to  as  unbiased:  its 
expected  value  equals  the  expected  value  of  the  random  variable  being  estimated. 
We  can  invoked  the  unbiasedness  property  to  interpret  (8.32)  as  stating  that  the 
estimation  error  of  the  MMSE  estimator  is  uncorrelated  with  any  function  of  the 
random  variables  used  to  construct  the  estimator. 

(8.33) 

(8.34) 

The proof of the correlation matching property in (8.33) is in the following sequence 
of  equalities: 

EY ,X [yb(X)h(X)]  = EX [EY |X [Y |X]h(X)] 
= EX [EY |X [Y h(X)|X]] 
= EY ,X [Y h(X)]  . 
Rearranging  the  ﬁnal  result  here, we  obtain  the  orthogonality  condition  in  (8.32). 

(8.35)

(8.36)

(8.37)


8.3	 LINEAR  MINIMUM  MEAN  SQUARE  ERROR  ESTIMATION 

In  general,  the  conditional  expectation  E (Y  X)  required  for  the  MMSE  estimator 
|
developed in the preceding sections is diﬃcult to determine, because the conditional 
density  fY |X (y |x)  is  not  easily  determined.  A  useful  and  widely  used  compromise 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  8.3 

Linear  Minimum  Mean  Square  Error  Estimation  151 

is  to  restrict  the  estimator  to  be  a  ﬁxed  linear  (or  actually  aﬃne,  i.e.,  linear  plus 
a  constant)  function  of  the  measured  random  variables,  and  to  choose  the  linear 
relationship  so  as  to  minimize  the  mean  square  error.  The  resulting  estimator  is 
called  the  linear minimum mean  square  error  (LMMSE)  estimator.  We  begin  with 
the  simplest  case. 

(8.38) 

(8.39) 

Suppose  we  wish  to  construct  an  estimator  for  the  random  variable  Y  in  terms  of 
another  random  variable X ,  restricting  our  estimator  to  be  of  the  form 
Ybℓ  = ybℓ (X ) = aX + b , 
where  a  and  b  are  to  be  determined  so  as  to minimize  the mean  square  error 
EY ,X [(Y  − Ybℓ )2 ] = EY ,X [{Y  − (aX + b)} 2 ]  . 
Note  that  the  expectation  is  taken  over  the  joint  density  of  Y  and  X ;  the  linear 
estimator  is  picked  to  be  optimum when  averaged  over  all  possible  combinations  of 
Y  and X  that may  occur.  We  have  accordingly  used  subscripts  on  the  expectation 
operations  in  (8.39)  to  make  explicit  for  now  the  variables  whose  joint  density  the 
expectation  is  being  computed  over;  we  shall  eventually  drop  the  subscripts. 
Once  the  optimum  a  and  b  have  been  chosen  in  this  manner,  the  estimate  of  Y , 
given  a  particular  x,  is  just  ybℓ (x) =  ax + b,  computed  with  the  already  designed 
values  of  a  and  b.  Thus,  in  the  LMMSE  case  we  construct  an  optimal  linear 
estimator,  and  for  any  particular  x  this  estimator  generates  an  estimate  that  is 
not  claimed  to  have  any  individual  optimality  property.  This  is  in  contrast  to  the 
MMSE  case  considered  in  the  previous  sections,  where  we  obtained  an  optimal 
MMSE  estimate  for  each  x,  namely  E [Y X  = x],  that  minimized  the  mean  square 
|
error  conditioned  on  X  =  x.  The  distinction  can  be  summarized  as  follows:  in 
the unrestricted MMSE  case,  the optimal  estimator  is  obtained by  joining  together 
all  the  individual  optimal  estimates,  whereas  in  the  LMMSE  case  the  (generally 
non-optimal)  individual  estimates  are  obtained  by  simply  evaluating  the  optimal 
linear  estimator. 

We  turn  now  to  minimizing  the  expression  in  (8.39),  by  diﬀerentiating  it  with 
respect  to  the  parameters  a  and  b,  and  setting  each  of  the  derivatives  to  0.  (Con­
sideration  of  the  second  derivatives  will  show  that  we  do  indeed  ﬁnd  minimizing 
values  in  this  fashion,  but  we  omit  the  demonstration.)  First  diﬀerentiating  (8.39) 
with  respect  to  b,  taking  the  derivative  inside  the  integral  that  corresponds  to  the 
expectation  operation,  and  then  setting  the  result  to  0,  we  conclude  that 

or  equivalently 

EY ,X [Y  − (aX + b)] = 0 , 
E [Y ] = E [aX + b] = E [Ybℓ ]  , 
from  which  we  deduce  that 
b = µY  − aµX  , 
where  µY  =  E [Y ] =  EY ,X [Y ]  and  µX  =  E [X ] =  EY ,X [X ].  The  optimum  value  of 
b  speciﬁed  in  (8.42)  in  eﬀect  serves  to make  the  linear  estimator  unbiased,  i.e.,  the 

(8.40) 

(8.41) 

(8.42) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

152  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

expected value of  the estimator becomes equal  to  the expected value of  the  random 
variable  we  are  trying  to  estimate,  as  (8.41)  shows. 

Using  (8.42)  to  substitute  for  b  in  (8.38),  it  follows  that 
Ybℓ  = µY  + a(X − µX )  . 
In  other  words,  to  the  expected  value  µY  of  the  random  variable  Y  that  we  are 
estimating,  the  optimal  linear  estimator  adds  a  suitable  multiple  of  the  diﬀerence 
X  − µX  between  the  measured  random  variable  and  its  expected  value.  We  turn 
now  to  ﬁnding  the  optimum  value  of  this  multiple,  a. 

(8.43) 

(8.44) 

where 

First  rewrite  the  error  criterion  (8.39)  as 
E [{(Y  − µY  ) − (Ybℓ  − µY  )}2 ] = E [( Ye − aXe )2 ]  , 
and  Xe = X − µX  , 
Ye = Y  − µY 
(8.45) 
and  where  we  have  invoked  (8.43)  to  obtain  the  second  equality  in  (8.44).  Now 
taking  the  derivative  of  the  error  criterion  in  (8.44)  with  respect  to  a,  and  setting 
the  result  to  0,  we  ﬁnd 
E [( Ye − aXe )Xe ] = 0 . 
(8.46) 
Rearranging  this,  and  recalling  that  E [Ye Xe ] =  σY X ,  i.e.,  the  covariance  of  Y  and 
X ,  and  that  E [Xe 2 ] = σ2  ,  we  obtain 
X 
σY X 
σY 
a =
= ρY X 
, 
(8.47) 
σ2 
σX 
X 
where  ρY X  —  which  we  shall  simply  write  as  ρ  when  it  is  clear  from  context  what 
variables  are  involved —  denotes  the  correlation  coeﬃcient  between  Y  and X . 

It  is  also  enlightening  to  understand  the  above  expression  for  a  in  terms  of  the 
vector-space  picture  for  random  variables  developed  in  the  previous  chapter. 

eY  − a eX  = Y  −  bYℓ 

eY

aXe
FIGURE  8.8  Expression  for  a  from  Eq.  (8.47)  illustrated  in  vector  space. 

eX 

The  expression  (8.44)  for  the  error  criterion  shows  that we  are  looking  for  a  vector 
aXe , which  lies  along  the  vector Xe ,  such  that  the  squared  length  of  the  error  vector 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.3 
Linear  Minimum  Mean  Square  Error  Estimation  153 
Ye − aXe is minimum.  It follows from familiar geometric reasoning that the optimum 
choice of aXe must be the orthogonal pro jection of Ye on Xe , and that this pro jection 
is 
Y ,  e
<  e X > 
a e
e X >  e
(8.48) 
X .	
X  = 
< X ,  e
Here,  as  in  the  previous  chapter,  <  U, V  >  denotes  the  inner  product  of  the  vec­
tors  U  and  V ,  and  in  the  case  where  the  “vectors”  are  random  variables,  denotes 
E [U V ].  Our  expression  for  a  in  (8.47)  follows  immediately.  Figure  8.8  shows  the 
construction  associated  with  the  requisite  calculations.  Recall  from  the  previous 
chapter  that  the  correlation  coeﬃcient  ρ  denotes  the  cosine  of  the  angle  between 
the  vectors  Ye and Xe . 
The  preceding  pro jection  operation  implies  that  the  error  Ye − aXe ,  which  can  also 
be  written  as  Y  − Ybℓ ,  must  be  orthogonal  to  Xe = X − µX .  This  is  precisely  what 
(8.46)  says.  In  addition,  invoking  the  unbiasedness  of  Ybℓ  shows  that  Y  − Ybℓ  must 
be  orthogonal  to  µX  (or  any  other  constant),  so  Y  − Ybℓ  is  therefore  orthogonal  to 
X	 itself: 
E [(Y  − Ybℓ )X ] = 0 . 
(8.49) 
In  other  words,  the  optimal  LMMSE  estimator  is  unbiased  and  such  that  the  esti­
mation  error  is  orthogonal  to  the  random  variable  on which  the  estimator  is based. 
(Note that the statement in the case of the MMSE estimator in the previous section 
was  considerably  stronger,  namely  that  the  error  was  orthogonal  to  any  function 
h(X )  of  the measured  random  variable,  not  just  to  the  random  variable  itself.) 

The  preceding  development  shows  that  the  properties  of  (i)  unbiasedness  of  the 
estimator,  and  (ii)  orthogonality  of  the  error  to  the  measured  random  variable, 
completely  characterize  the  LMMSE  estimator.  Invoking  these  properties  yields 
the  LMMSE  estimator. 

Going  a  step  further  with  the  geometric  reasoning,  we  ﬁnd  from  Pythagoras’s  the­
orem  applied  to  the  triangle  in  Figure  8.8  that  the  minimum  mean  square  error 
(MMSE)  obtained  through  use  of  the  LMMSE  estimator  is 
2  (1 − ρ2 )  . 
MMSE = E [( Ye − aXe )2 ] = E [Ye 2 ](1 − ρ2 ) = σY 
This  result  could  also  be  obtained  purely  analytically,  of  course,  without  recourse 
2 
to  the  geometric  interpretation.  The  result  shows  that  the  mean  square  error  σY 
that we  had  prior  to  estimation  in  terms  of X  is  reduced  by  the  factor  1 − ρ2  when 
we use X  in an LMMSE estimator.  The closer that ρ is to +1 or −1 (corresponding 
to  strong  positive  or  negative  correlation  respectively),  the  more  our  uncertainty 
about  Y  is  reduced  by  using  an  LMMSE  estimator  to  extract  information  that  X 
carries  about  Y . 

(8.50) 

Our  results  on  the  LMMSE  estimator  can  now  be  summarized  in  the  following 
expressions  for  the  estimator,  with  the  associated  minimum  mean  square  error 
being  given  by  (8.50): 
Ybℓ  = ybℓ (X ) = µY  + 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

σY X	
σ2  (X − µX ) = µY  + ρ
X 

(8.51) 

σY
σX 

(X − µX )  , 

154  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

or  the  equivalent  but  perhaps more  suggestive  form 
Ybℓ  − µY 
σY 
The  latter expression states that the normalized deviation of the estimator  from  its 
mean is ρ times the normalized deviation of the observed variable from its mean; the 
more highly correlated Y  and X  are, the more closely we match the two normalized 
deviations. 

X − µX 
σX 

(8.52) 

= ρ

. 

Note  that  our  expressions  for  the  LMMSE  estimator  and  its mean  square  error  are 
the same as those obtained in Example 8.4 for the MMSE estimator in the bivariate 
Gaussian  case.  The  reason  is  that  the MMSE  estimator  in  that  case  turned  out  to 
be  linear  (actually,  aﬃne),  as  already  noted  in  the  example. 

EXAMPLE  8.6 

LMMSE  Estimator  for  Signal  in  Additive  Noise 

We  return  to  Example  8.5,  for  which  we  have  already  computed  the  MMSE  esti­
mator,  and  we  now  design  an  LMMSE  estimator.  Recall  that  the  random  vari­
able  X  denotes  a  noisy  measurement  of  the  angular  position  Y  of  an  antenna,  so 
X  =  Y  + W ,  where  W  denotes  the  additive  noise.  We  assume  the  noise  is  inde­
pendent  of  the  angular  position,  i.e.,  Y  and W  are  independent  random  variables, 
with  Y  uniformly  distributed  in  the  interval  [−1, 1]  and  W  uniformly  distributed 
in  the  interval  [−2, 2]. 
For  the LMMSE estimator of Y  in  terms of X , we need  to determine  the  respective 
means and variances, as well as the covariance, of these random variables.  It is easy 
to  see  that 

µY 

= 0  , µW  = 0  , µX  = 0  ,

σ

2
Y 

= 

1 
3 

,  σ

2
W

= 

4
3 

,

= 

.

1
3 

2 
Y

= 

,  σY X  = σ

X  = σ2 
σ2 
Y  + σ2
W 

1 
,  ρY X  =  √5 

5 
3 
The  LMMSE  estimator  is  accordingly 
b
Yℓ  = 
2 
Y  (1 − ρ2 ) = 
This MMSE  should be compared with  the  (larger) mean  square error of
if we  simply  use µY  = 0  as  our  estimator  for Y ,  and  the  (smaller)  value
using  the MMSE  estimator  in  Example  8.5. 

and  the  associated MMSE  is 

1 
X , 
5 

σ

4 
15 

. 

1 
3
1 
4

obtained 
obtained 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.3 

Linear  Minimum  Mean  Square  Error  Estimation  155 

EXAMPLE  8.7 

Single-Point  LMMSE  Estimator  for  Sinusoidal  Random  Process 

Consider  a  sinusoidal  signal  of  the  form 

X (t) = A cos(ω0 t + Θ) 

(8.53) 

where  ω0  is  assumed  known,  while  A  and  Θ  are  statistically  independent  random 
variables,  with  the  PDF  of  Θ  being  uniform  in  the  interval  [0, 2π ].  Thus  X (t)  is  a 
random  signal,  or  equivalently  a  set  or  “ensemble”  of  signals  corresponding  to  the 
various  possible  outcomes  for  A  and  Θ  in  the  underlying  probabilistic  experiment. 
We  will  discuss  such  signals  in more  detail  in  the  next  chapter,  where  we  will  refer 
to  them  as  random  processes.  The  value  that  X (t)  takes  at  some  particular  time 
t  =  t0  is  simply  a  random  variable,  whose  speciﬁc  value  will  depend  on  which 
outcomes  for  A  and  Θ  are  produced  by  the  underlying  probabilistic  experiment. 

(8.54) 

Suppose  we  are  interested  in  determining  the  LMMSE  estimator  for  X (t1 )  based 
on  a measurement  of X (t0 ), where  t0  and  t1  are  speciﬁed  sampling  times.  In  other 
words,  we  want  to  choose  a  and  b  in 
Xb (t1 ) = aX (t0 ) + b 
so  as  to minimize  the mean  square  error  between  X (t1 )  and Xb (t1 ). 
We  have  established  that  b  must  be  chosen  to  ensure  the  estimator  is  unbiased: 
E [Xb (t1 )] = aE [X (t0 )] + b = E [X (t1 )]  . 
Since  A  and  Θ  are  independent, 
Z  2π  1 
E [X (t0 )] = E {A} 
cos(ω0 t0  + θ) dθ = 0 
2π
0 
and  similarly  E [X (t1 )] = 0,  so  we  choose  b = 0. 
Next  we  use  the  fact  that  the  error  of  the  LMMSE  estimator  is  orthogonal  to  the 
data: 
E [( Xb (t1 ) − X (t1 ))X (t0 )] = 0 
aE [X 2 (t0 )] = E [X (t1 )X (t0 )] 

and  consequently 

or 

. 

(8.55) 

a = 

E [X (t1 )X (t0 )] 
E [X 2 (t0 )] 
The  numerator  and  denominator  in  (8.55)  are  respectively 
Z  2π  1 
E [X (t1 )X (t0 )]  =  E [A2 ] 
2π 
0 
E [A2 ] 
cos{ω0 (t1  − t0 )}
2 

= 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

cos(ω0 t1  + θ) cos(ω0 t0  + θ) dθ 

156  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

and  E [X 2 (t0 )] =  E [A2 ] .  Thus  a = cos{ω0 (t1  − t0 )},  so  the  LMMSE  estimator  is 
2 
b
X (t1 ) = X (t0 ) cos{ω0 (t1  − t0 )}  . 
(8.56) 
It  is  interesting  to  observe  that  the  distribution  of  A  doesn’t  play  a  role  in  this 
equation. 
To evaluate  the mean  square error associated with  the LMMSE estimator, we com­
pute  the  correlation  coeﬃcient  between  the  samples  of  the  random  signal  at  t0  and 
t1 .  It  is  easily  seen  thatρ = a = cos{ω0 (t1  − t0 )},  so  the mean  square  error  is 
E [A2 ] ³1 − cos 2 {ω0 (t1  − t0 )}´ 
E [A2 ] 
sin2 {ω0 (t1  − t0 )}  . 
2 
2

(8.57) 

= 

We now extend the LMMSE estimator to the case where our estimation of a random 
variable  Y  is  based  on  observations  of  multiple  random  variables,  say  X1 , . . . , XL , 
gathered  in  the  vector X.  The  aﬃne  estimator  may  then  be  written  in  the  form 
Ybℓ  = ybℓ (X) = a0  + X 
L
aj Xj  . 
j=1 
As we shall see,  the coeﬃcient ai  of this LMMSE estimator can be  found by solving 
a  linear  system  of  equations  that  is  completely  deﬁned  by  the  ﬁrst  and  second 
moments  (i.e.,  means,  variances  and  covariances)  of  the  random  variables  Y  and 
Xj .  The fact that the model (8.58) is linear in the parameters ai  is what results in a 
linear  system of equations;  the  fact  that  the model  is aﬃne  in  the  random variables 
is what makes  the  solution  only  depend  on  their  ﬁrst  and  second moments.  Linear 
equations  are  easy  to  solve,  and  ﬁrst  and  second  moments  are  generally  easy  to 
determine,  hence  the  popularity  of  LMMSE  estimation. 

(8.58) 

The  development  below  follows  along  the  same  lines  as  that  done  earlier  in  this 
section  for  the  case  where  we  just  had  a  single  observed  random  variable  X ,  but 
we use  the opportunity  to  review  the  logic of  the development and  to provide a  few 
additional  insights. 

We  want  to minimize  the mean  square  error 
aj Xj )´2 i 
E h³Y  − (a0  + X 
L
j=1 
where  the  expectation  is  computed  using  the  joint  density  of Y  and X.  We  use  the 
joint  density  rather  than  the  conditional  because  the  parameters  are  not  going  to 
be picked to be best  for a particular set of measured values x — otherwise we could 
do  as  well  as  the  nonlinear  estimate  in  this  case,  by  setting  a0  = E [Y  X = x]  and 
|
setting all the other ai  to zero.  Instead, we are picking the parameters to be the best 
averaged  over  all  possible  X.  The  linear  estimator  will  in  general  not  be  as  good 

(8.59) 

, 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.3 

Linear  Minimum  Mean  Square  Error  Estimation  157 

as  the  unconstrained  estimator,  except  in  special  cases  (some  of  them  important, 
as  in  the  case  of  bivariate  Gaussian  random  variables)  but  this  estimator  has  the 
advantage  that  it  is  easy  to  solve  for,  as  we  now  show. 

To  minimize  the  expression  in  (8.59),  we  diﬀerentiate  it  with  respect  to  ai  for 
· · · 
i = 0, 1, 
, L,  and  set  each  of  the  derivatives  to  0.  (Again,  calculations  involving 
second  derivatives  establish  that  we  do  indeed  obtain  minimizing  values,  but  we 
omit  these  calculation  here.)  First  diﬀerentiating  with  respect  to  a0  and  setting 
the  result  to  0,  we  conclude  that 
E [Y ] = E [ a0  + X 
L
aj Xj  ] = E [Ybℓ ] 
j=1 
a0  = µY  − X 
L
aj  µXj  , 
j=1 
where  µY  = E [Y ]  and  µXj  = E [Xj ].  This  optimum  value  of  a0  serves  to  make  the 
linear  estimator  unbiased,  in  the  sense  that  (8.60)  holds,  i.e.,  the  expected  value  of 
the estimator is the expected value of the random variable we are trying to estimate. 

(8.61) 

(8.60) 

or 

Using  (8.61)  to  substitute  for  a0  in  (8.58),  it  follows  that 
Ybℓ  = µY  + X 
L
aj (Xj  − µXj )  . 
j=1 
In  other  words,  the  estimator  corrects  the  expected  value  µY  of  the  variable  we 
are  estimating,  by  a  linear  combination  of  the  deviations  Xj  − µXj  between  the 
measured  random  variables  and  their  respective  expected  values. 

(8.62) 

, 

(8.63) 

(8.64) 

where 

Taking  account  of  (8.62),  we  can  rewrite  our mean  square  error  criterion  (8.59)  as 
aj Xej )´2 i 
E [{(Y  − µY  ) − (Ybℓ  − µY  )}2 ] = E h³ 
Ye − X 
L
j=1 
Ye = Y  − µY 
and  Xej  = Xj  − µXj  . 
Diﬀerentiating this with respect to each of the remaining coeﬃcients ai , i = 1, 2, ...L, 
and  setting  the  result  to  zero  produces  the  equations 
E [( Ye − X 
L
aj Xej )Xei ] = 0 
j=1 
or  equivalently,  if  we  again  take  account  of  (8.62), 
E [(Y  − Ybℓ )Xei ] = 0 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

i = 1, 2, ..., L  . 

i = 1, 2, ..., L  . 

(8.65) 

(8.66) 

158  Chapter  8 
Estimation  with  Minimum  Mean  Square  Error 
Yet  another  version  follows  on  noting  from  (8.60)  that  Y  − Ybℓ  is  orthogonal  to  all 
constants,  in  particular  to  µXi ,  so 
E [(Y  − Ybℓ )Xi ] = 0 
i = 1, 2, ..., L  . 
(8.67) 
All  three  of  the  preceding  sets  of  equations  express,  in  slightly  diﬀerent  forms,  the 
orthogonality of the estimation error to the random variables used in the estimator. 
One  moves  between  these  forms  by  invoking  the  unbiasedness  of  the  estimator. 
The  last  of  these,  (8.67),  is  the  usual  statement  of  the  orthogonality  condition  that 
governs  the  LMMSE  estimator.  (Note  once more  that  the  statement  in  the  case  of 
the MMSE estimator in the previous section was considerably stronger, namely that 
the  error  was  orthogonal  to  any  function  h(X)  of  the  measured  random  variables, 
not  just  to  the  random  variables  themselves.)  Rewriting  this  last  equation  as 
E [Y Xi ] = E [YbℓXi ] 
yields  an  equivalent  statement  of  the  orthogonality  condition,  namely  that  the 
LMMSE  estimator  Ybℓ  has  the  same  correlations  as  Y  with  the  measured  variables 
Xi . 
The  orthogonality  and  unbiasedness  conditions  together  determine  the  LMMSE 
estimator  completely.  Also,  the  preceding  developments  shows  that  the  ﬁrst  and 
second  moments  of  Y  and  the  Xi  are  exactly  matched  by  the  corresponding  ﬁrst 
and  second  moments  of  Ybℓ  and  the  Xi .  It  follows  that  Y  and  Ybℓ  cannot  be  told 
apart  on  the  basis  of  only  ﬁrst  and  second  moments  with  the  measured  variables 
Xi . 
We  focus  now  on  (8.65),  because  it  provides  the  best  route  to  a  solution  for  the 
coeﬃcients  aj ,  j  = 1, . . . , L.  This  set  of  equations  can  be  expressed  as 
LX 
j=1 
where  σXiXj  is  the  covariance  of  Xi  and  Xj  (so  σXiXi  is  just  the  variance  σ2  ), Xi 
and σXi Y  is the covariance of Xi  and Y .  Collecting these equations  in matrix  form, 
we  obtain 
σX1 Y   
a1     
· · ·  σX1XL    
 
=  
 
. . .   
  
 
· · · 
σX2 Y 
a2 
σX2XL 
. . . 
. . . 
. . . 
· · ·  σXLXL 
σXL Y 
aL 
This  set  of  equations  is  referred  to  as  the  normal  equations.  We  can  rewrite  the 
normal  equations  in  more  compact  matrix  notation: 

σX1X1  σX1X2 
σX2X2 
σX2X1 
. . . 
. . . 
σXLX1  σXL X2 

σXi Xj aj  = σXi Y  , 

. 

(8.70) 

i = 1, 2, ..., L 

(8.68) 

(8.69) 

(CXX ) a = CXY 

(8.71) 

where the deﬁnitions of CXX , a, and CXY  should be evident on comparing the  last 
two  equations.  The  solution  of  this  set  of  L  equations  in  L  unknowns  yields  the 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  8.3 

Linear  Minimum  Mean  Square  Error  Estimation  159 

· · · 
, L,  and  these  values may  be  substituted  in  (8.62)  to  completely 
{aj }  for  j  = 1, 
specify  the  estimator.  In matrix  notation,  the  solution  is 

a = (CXX )−1CXY  . 

(8.72) 

It  can  be  shown  quite  straightforwardly  (though  we  omit  the  demonstration)  that 
the  minimum  mean  square  error  obtained  with  the  LMMSE  estimator  is 
2  − CY X (CXX )−1CXY  = σY 
2  − CY Xa  , 
σY 
where  CY X  is  the  transpose  of CXY  . 

(8.73) 

EXAMPLE  8.8 

Estimation  from  Two  Noisy Measurements 

Y  → 

|
| 

→

→

R1 
↓L 
L 
↑R2 

→ 

X1

→ 

X2

FIGURE  8.9  Illustration  of  relationship  between  random  variables  from  Eq.  (8.75) 
for  Example  8.8. 

Assume that Y , R1  and R2  are mutually uncorrelated, and that R1  and R2  have zero 
means and equal variances.  We wish to ﬁnd the linear MMSE estimator for Y , given 
measurements of X1  and X2 .  This estimator takes the form Ybℓ  = a0 + a1X1 + a2X2 . 
Our  requirement  that  Ybℓ  be  unbiased  results  in  the  constraint 
a0  = µY  − a1µX1  − a2µX2  = µY  (1 − a1  − a2 ) 
(8.74) 
Next,  we  need  to  write  down  the  normal  equations,  for  which  some  preliminary 
calculations  are  required.  Since 

X1  = Y  + R1

X2  = Y  + R2 

and  Y ,  R1  and  R2  are mutually  uncorrelated,  we  ﬁnd 
2 ] = E [Y 2 ] + E [R2 
i ]  , 
E [Xi 
E [X1X2 ] = E [Y 2 ]  , 
E [XiY ] = E [Y 2 ]  . 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(8.75) 


(8.76) 

160  Chapter  8 

Estimation  with  Minimum  Mean  Square  Error 

σ2  + σ2 
R
Y
2
σ
Y

The  normal  equations  for  this  case  thus  become 
· 
a1  ¸ 
¸ · 
a2 
from  which  we  conclude  that 
· 
a1  ¸ 
a2 

σ2  + σ2 
R 
Y
−σ2 
Y 

σ2 
Y 
+

·	

= 

2
R 

2
Y

σ

σ

= 

· 

σ2 
Y 
2
σ
Y 

¸ 

(8.77) 

2σ− Y 
2σ+ R 
2σY

¸ · 

2σY
Yσ2 

¸ 

. 

(8.78) 

1 
(σ2	 + σ2 
)2
R
Y
·
σ2 
Y 
σ+ 
2
Y

2σ

2
R 

− σ4 
Y 
¸1 
1 

= 

Finally,  therefore, 

1 
2σ+ R

σ

2
Y

+

= 

µY 

+1

2(σR

X2 ) 

2σ2 
Y 

2
σ X
Y

Ybℓ 
and applying (8.73) we get that the associated minimum mean square error (MMSE) 
is 

2
2
σ σRY
2
2
σ+ R
2σ
Y
One  can  easily  check  that  both  the  estimator  and  the  associated  MMSE  take  rea­
sonable values at extreme ranges of the signal-to-noise ratio  σ /σR
. 
2
2
Y

(8.79) 

(8.80) 

.	

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

9 

Random  Processes 

INTRODUCTION 

Much of your background  in  signals and  systems  is assumed  to have  focused on  the 
eﬀect  of  LTI  systems  on  deterministic  signals,  developing  tools  for  analyzing  this 
class  of  signals  and  systems,  and  using  what  you  learned  in  order  to  understand 
applications  in  communication  (e.g.,  AM  and  FM  modulation),  control  (e.g.,  sta­
bility of  feedback systems), and signal processing (e.g., ﬁltering).  It  is  important to 
develop  a  comparable  understanding  and  associated  tools  for  treating  the  eﬀect  of 
LTI  systems  on  signals  modeled  as  the  outcome  of  probabilistic  experiments,  i.e., 
a  class  of  signals  referred  to  as  random  signals  (alternatively  referred  to  as  random 
processes  or  stochastic  processes).  Such  signals  play  a  central  role  in  signal  and 
system  design  and  analysis,  and  throughout  the  remainder  of  this  text.  In  this 
chapter we  deﬁne  random  processes  via  the  associated  ensemble  of  signals,  and  be­
gin  to  explore  their  properties.  In  successive  chapters  we  use  random  processes  as 
models  for  random  or  uncertain  signals  that  arise  in  communication,  control  and 
signal  processing  applications. 

9.1  DEFINITION  AND  EXAMPLES  OF  A  RANDOM  PROCESS 

In Section 7.3 we deﬁned a random variable X  as a function that maps each outcome 
of  a  probabilistic  experiment  to  a  real  number.  In  a  similar  manner,  a  real-valued 
CT  or  DT  random  process,  X (t)  or  X [n]  respectively,  is  a  function  that  maps 
each  outcome  of  a  probabilistic  experiment  to  a  real  CT  or DT  signal  respectively, 
termed  the  realization  of  the  random  process  in  that  experiment.  For  any  ﬁxed 
time  instant  t  =  t0  or  n  =  n0 ,  the  quantities  X (t0 )  and  X [n0 ]  are  just  random 
variables.  The  collection  of  signals  that  can  be  produced  by  the  random  process  is 
referred  to  as  the  ensemble  of  signals  in  the  random  process. 

EXAMPLE  9.1 

Random  Oscillators 

As  an  example  of  a  random  process,  imagine  a  warehouse  containing  N  harmonic 
oscillators,  each  producing  a  sinusoidal  waveform  of  some  speciﬁc  amplitude,  fre­
quency,  and  phase,  all  of  which  may  be  diﬀerent  for  the  diﬀerent  oscillators.  The 
probabilistic  experiment  that  results  in  the  ensemble  of  signals  consists  of  selecting 
an  oscillator  according  to  some  probability  mass  function  (PMF)  that  assigns  a 
probability  to  each  of  the  numbers  from  1  to N ,  so  that  the  ith  oscillator  is  picked 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

161

162  Chapter  9 

Random  Processes 

Ψ 

�Amplitude 

� 

X (t; ψ) 

t0 

�

t 

ψ 

FIGURE  9.1  A  random  process. 

with  probability  pi .  Associated  with  each  outcome  of  this  experiment  is  a  speciﬁc 
sinusoidal  waveform. 

In  Example  9.1,  before  an  oscillator  is  chosen,  there  is  uncertainty  about  what 
the  amplitude,  frequency  and  phase  of  the  outcome  of  the  experiment  will  be. 
Consequently,  for  this  example,  we  might  express  the  random  process  as 

X (t) = A sin(ωt + φ) 

where  the  amplitude  A,  frequency  ω  and  phase  φ  are  all  random  variables.  The 
value  X (t1 )  at  some  speciﬁc  time  t1  is  also  a  random  variable.  In  the  context  of 
this  experiment,  knowing  the  PMF  associated  with  each  of  the  numbers  1  to  N 
involved  in  choosing  an  oscillator,  as  well  as  the  speciﬁc  amplitude,  frequency  and 
phase  of  each  oscillator,  we  could  determine  the  probability  distributions  of  any  of 
the  underlying  random  variables  A,  ω ,  φ  or  X (t1 ) mentioned  above. 
Throughout  this and  later  chapters, we will be  considering many other  examples of 
random  processes.  What  is  important  at  this  point,  however,  is  to  develop  a  good 
mental picture of what a random process is.  A random process is not just one signal 
but  rather  an  ensemble  of  signals,  as  illustrated  schematically  in  Figure  9.2  below, 
for which the outcome of the probabilistic experiment could be any of the four wave­
forms  indicated.  Each  waveform  is  deterministic,  but  the  process  is  probabilistic 
or  random  because  it  is  not  known  a  priori  which  waveform  will  be  generated  by 
the  probabilistic  experiment.  Consequently,  prior  to  obtaining  the  outcome  of  the 
probabilistic  experiment, many  aspects  of  the  signal  are  unpredictable,  since  there 
is uncertainty associated with which signal will be produced.  After the experiment, 
or  a  posteriori,  the  outcome  is  totally  determined. 

If  we  focus  on  the  values  that  a  random  process  X (t)  can  take  at  a  particular 
instant of time,  say t1  —  i.e.,  if we  look down the entire ensemble at a ﬁxed time — 
what  we  have  is  a  random  variable,  namely  X (t1 ).  If  we  focus  on  the  ensemble  of 
values  taken at an arbitrary  collection of  ℓ ﬁxed  time  instants  t1  < t2  <  < tℓ  for 
· · · 
some  arbitrary  integer  ℓ,  we  are  dealing  with  a  set  of  ℓ  jointly  distributed  random 
variables  X (t1 ),  X (t2 ), 
,  X (tℓ ),  all  determined  together  by  the  outcome  of  the 
· · · 
underlying  probabilistic  experiment.  From  this  point  of  view,  a  random  process 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  9.1 

Deﬁnition  and  examples  of  a  random  process  163 

X(t) = x (t) 
a 

X(t) = x (t)b 

X(t) = x (t)c 

X(t) = x (t)d 

t 

t 

t 

t 

t 
1 

t

2 

FIGURE  9.2  Realizations  of  the  random  process  X (t) 

can  be  thought  of  as  a  family  of  jointly  distributed  random  variables  indexed  by 
t  (or  n  in  the  DT  case).  A  full  probabilistic  characterization  of  this  collection  of 
random  variables  would  require  the  joint  PDFs  of  multiple  samples  of  the  signal, 
taken  at  arbitrary  times: 

fX (t1 ),X (t2 ),

,X (tℓ ) (x1 , x2 , 
· · · 
··· 

, xℓ )

for  all  ℓ  and  all  t1 , t2 , 
· · · 
, tℓ .
An important set of questions that arises as we work with random processes in later 
chapters of this book is whether, by observing just part of the outcome of a random 
process,  we  can  determine  the  complete  outcome.  The  answer  will  depend  on  the 
details  of  the  random  process,  but  in  general  the  answer  is  no.  For  some  random 
processes,  having  observed  the  outcome  in  a  given  time  interval  might  provide 
suﬃcient  information  to know  exactly which  ensemble member was determined.  In 
other cases  it would not be suﬃcient.  We will be exploring  some of  these aspects  in 
more  detail  later,  but  we  conclude  this  section  with  two  additional  examples  that 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

164  Chapter  9 

Random  Processes 

further  emphasize  these  points. 

EXAMPLE  9.2 

Ensemble  of  batteries 

Consider a collection of N  batteries, each providing one voltage out of a given ﬁnite 
set  of  voltage  values.  The  histogram  of  voltages  (i.e.,  the  number  of  batteries  with 
a  given  voltage)  is  given  in  Figure  9.3.  The  probabilistic  experiment  is  to  choose 

Number of 
Batteries 

Voltage 

FIGURE  9.3  Histogram  of  battery  distribution  for  Example  9.2. 

1  ,  i.e., 
one  of  the  batteries,  with  the  probability  of  picking  any  speciﬁc  one  being  N 
they  are  all  equally  likely  to  be  picked.  A  little  reﬂection  should  convince  you  that 
1  ,  this  normalized  histogram  will 
if  we  multiply  the  histogram  in  Figure  9.3  by  N 
represent  (or  approximate)  the  PMF  for  the  battery  voltage  at  the  outcome  of  the 
experiment.  Since  the  battery  voltage  is  a  constant  signal,  this  corresponds  to  a 
random  process,  and  in  fact  is  similar  to  the  oscillator  example  discussed  earlier, 
but  with  ω = 0  and  φ = 0,  so  that  only  the  amplitude  is  random. 

For  this  example  observation  of  X (t)  at  any  one  time  is  suﬃcient  information  to 
determine  the  outcome  for  all  time. 

EXAMPLE  9.3 

Ensemble  of  coin  tossers 

Consider N  people,  each  independently having written down a  long  random  string 
of  ones  and  zeros, with  each  entry  chosen  independently  of  any  other  entry  in  their 
string  (similar  to  a  sequence  of  independent  coin  tosses).  The  random  process  now 
comprises  this  ensemble  of  strings.  A  realization  of  the  process  is  obtained  by 
randomly  selecting  a person  (and  therefore  one  of  the N  strings  of  ones  and  zeros), 
following  which  the  speciﬁc  ensemble  member  of  the  random  process  is  totally 
determined.  The  random  process  described  in  this  example  is  often  referred  to  as 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  9.1 

Deﬁnition  and  examples  of  a  random  process  165 

the  Bernoulli  process  because  of  the  way  in  which  the  string  of  ones  and  zeros  is 
generated  (by  independent  coin  ﬂips). 

Now  suppose  that  person  shows  you  only  the  tenth  entry  in  the  string.  Can  you 
determine  (or  predict)  the  eleventh  entry  from  just  that  information?  Because  of 
the  manner  in  which  the  string  was  generated,  the  answer  clearly  is  no.  Similarly 
if  the  entire  past  history  up  to  the  tenth  entry  was  revealed  to  you,  could  you 
determine  the  remaining  sequence  beyond  the  tenth?  For  this  example,  the  answer 
is  again  clearly  no. 

While  the  entire  sequence  has  been  determined  by  the  nature  of  the  experiment, 
partial  observation  of  a  given  ensemble  member  is  in  general  not  suﬃcient  to  fully 
specify  that member. 

Rather  than  looking at  the nth entry of a single ensemble member, we can consider 
the  random  variable  corresponding  to  the  values  from  the  entire  ensemble  at  the 
nth  entry.  Looking down  the  ensemble  at n = 10,  for  example, we would would  see 
ones  and  zeros  with  equal  probability. 

In  the  above  discussion  we  indicated  and  emphasized  that  a  random  process  can 
be  thought  of  as  a  family  of  jointly  distributed  random  variables  indexed  by  t  or 
n.  Obviously  it would  in  general  be  extremely  diﬃcult  or  impossible  to  represent  a 
random process this way.  Fortunately, the most widely used random process models 
have  special  structure  that  permits  computation  of  such  a  statistical  speciﬁcation. 
Also,  particularly when we  are  processing  our  signals with  linear  systems, we  often 
design the processing or analyze the results by considering only the ﬁrst and second 
moments  of  the  process,  namely  the  following  functions: 

µX (ti ) = E [X (ti )], 
Mean: 
Auto-correlation:  RXX (ti , tj ) = E [X (ti )X (tj )],  and 
Auto-covariance:  CXX (ti , tj ) = E [(X (ti ) − µX (ti ))(X (tj ) − µX (tj ))] 
= RXX (ti , tj ) − µX (ti )µX (tj ). 
The  word  “auto”  (which  is  sometime  written  without  the  hyphen,  and  sometimes 
dropped  altogether  to  simplify  the  terminology)  here  refers  to  the  fact  that  both 
samples  in  the  correlation  function  or  the  covariance  function  come  from  the  same 
process; we  shall  shortly encounter an extension of  this  idea, where  the  samples are 
taken  from  two  diﬀerent  processes. 

(9.1) 
(9.2) 

(9.3) 

One  case  in  which  the  ﬁrst  and  second  moments  actually  suﬃce  to  completely 
specify  the  process  is  in  the  case  of  what  is  called  a  Gaussian  process,  deﬁned 
as  a  process  whose  samples  are  always  jointly  Gaussian  (the  generalization  of  the 
bivariate  Gaussian  to many  variables). 

We can also consider multiple random processes, e.g., two processes, X (t) and Y (t). 
For  a  full  stochastic  characterization  of  this, we need  the PDFs  of  all possible  com­
binations  of  samples  from  X (t), Y (t).  We  say  that  X (t)  and  Y (t)  are  independent 
if  every  set  of  samples  from X (t)  is  independent  of  every  set  of  samples  from  Y (t), 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

166  Chapter  9 

Random  Processes 

so  that  the  joint  PDF  factors  as  follows: 

, xk , y1 , 
· · · 
,Y (t ′ ) (x1 , 
· · · 
, yℓ )
fX (t1 ),
,X (tk ),Y (t ′  ),
1 ··· 
··· 
ℓ 
,X (tk ) (x1 , 
,Y (t ′ ) (y1 , 
· · · 
· · · 
, yℓ )  . 
= fX (t1 ),
, xk ).fY (t ′  ),
··· 
··· 
1 
ℓ
If  only  ﬁrst  and  second moments  are  of  interest,  then  in  addition  to  the  individual 
ﬁrst  and  second  moments  of  X (t)  and  Y (t)  respectively,  we  need  to  consider  the 
cross-moment  functions: 

(9.4) 

Cross-correlation: RX Y  (ti , tj ) = E [X (ti )Y (tj )],  and 
Cross-covariance:  CX Y  (ti , tj ) = E [(X (ti ) − µX (ti ))(Y (tj ) − µY  (tj ))] 
= RX Y  (ti , tj ) − µX (ti )µY  (tj ). 
If CX Y  (t1 , t2 ) = 0  for  all  t1 , t2 ,  we  say  that  the  processes X (t)  and  Y (t)  are  uncor­
related.  Note  again  that  the  term  “uncorrelated”  in  its  common  usage means  that 
the  processes  have  zero  covariance  rather  than  zero  correlation. 

(9.6) 

(9.5) 

Note  that  everything  we  have  said  above  can  be  carried  over  to  the  case  of  DT 
random  processes,  except  that  now  the  sampling  instants  are  restricted  to  be  dis­
crete  time  instants.  In  accordance  with  our  convention  of  using  square  brackets 
[  ]  around  the  time  argument  for  DT  signals,  we  will  write  µX [n]  for  the  mean 
· 
· 
of  a  random  process  X [  ]  at  time  n;  similarly,  we  will  write  RXX [ni , nj ]  for  the 
correlation  function  involving  samples  at  times  ni  and  nj ;  and  so  on. 

9.2  STRICT-SENSE  STATIONARITY 

In  general,  we  would  expect  that  the  joint  PDFs  associated  with  the  random  vari­
ables obtained by sampling a random process at an arbitrary number k  of arbitrary 
times  will  be  time-dependent,  i.e.,  the  joint  PDF 

,X (tk ) (x1 , 
· · · 
··· 
will  depend  on  the  speciﬁc  values  of  t1 , 
, tk .  If  all  the  joint  PDFs  stay  the  same 
· · · 
under  arbitrary  time  shifts,  i.e.,  if 

fX (t1 ),

, xk )

fX (t1 ),

,X (tk +τ ) (x1 , 
· · · 
,X (tk ) (x1 , 
· · · 
··· 
··· 
for  arbitrary  τ ,  then  the  random process  is  said  to be  strict-sense  stationary  (SSS). 
Said  another  way,  for  a  strict-sense  stationary  process,  the  statistics  depend  only 
on  the  relative  times  at  which  the  samples  are  taken,  not  on  the  absolute  times. 

, xk ) = fX (t1+τ ),

(9.7) 

, xk ) 

EXAMPLE  9.4 

Representing  an  i.i.d.  process 

Consider a DT random process whose values X [n] may be regarded as independently 
chosen  at  each  time  n  from  a  ﬁxed  PDF  fX (x),  so  the  values  are  independent  and 
identically  distributed,  thereby  yielding  what  is  called  an  i.i.d.  process.  Such  pro­
cesses  are  widely  used  in  modeling  and  simulation.  For  instance,  if  a  particular 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  9.3  Wide-Sense  Stationarity  167 

DT  communication  channel  corrupts  a  transmitted  signal  with  added  noise  that 
takes  independent  values  at  each  time  instant,  but  with  characteristics  that  seem 
unchanging  over  the  time  window  of  interest,  then  the  noise  may  be  well  modeled 
as an  i.i.d.  process.  It  is also easy to generate an  i.i.d.  process  in a simulation envi­
ronment, provided one can arrange a random-number generator to produce samples 
from  a  speciﬁed  PDF  (and  there  are  several  good  ways  to  do  this).  Processes  with 
more complicated dependence across time samples can then be obtained by ﬁltering 
or  other  operations  on  the  i.i.d.  process,  as  we  shall  see  in  the  next  chapter. 

For  such  an  i.i.d.  process,  we  can  write  the  joint  PDF  quite  simply: 

fX [n1 ],X [n2 ],

,X [nℓ ] (x1 , x2 , 
, xℓ ) = fX (x1 )fX (x2 ) 
fX (xℓ ) 
· · · 
· · · 
··· 
for  any  choice  of  ℓ  and  n1 , 
, nℓ .  The  process  is  clearly  SSS. 
· · · 

(9.8) 

9.3  WIDE-SENSE  STATIONARITY 

Of  particular  use  to  us  is  a  less  restricted  type  of  stationarity.  Speciﬁcally,  if  the 
mean  value  µX (ti )  is  independent  of  time  and  the  autocorrelation  RXX (ti , tj )  or 
equivalently the autocovariance CXX (ti , tj ) is dependent only on the time diﬀerence 
(ti  −  tj ),  then  the  process  is  said  to  be  wide-sense  stationary  (WSS).  Clearly  a 
process  that  is  SSS  is  also  WSS.  For  a  WSS  random  process  X (t),  therefore,  we 
have 

µX (t) = µX 
RXX (t1 , t2 ) = RXX (t1  + α, t2  + α)  for  every  α 
= RXX (t1  − t2 , 0)  . 
(Note  that  for  a Gaussian  process  (i.e.,  a  process  whose  samples  are  always  jointly 
Gaussian) WSS  implies  SSS,  because  jointly  Gaussian  variables  are  entirely  deter­
mined  by  the  their  joint  ﬁrst  and  second moments.) 

(9.10) 

(9.9) 

Two  random  processes  X (t)  and  Y (t)  are  jointly  WSS  if  their  ﬁrst  and  second 
moments  (including  the  cross-covariance)  are  stationary.  In  this  case  we  use  the 
notation  RX Y  (τ )  to  denote  E [X (t + τ )Y (t)]. 

EXAMPLE  9.5 

Random  Oscillators  Revisited 

Consider  again  the  harmonic  oscillators  as  introduced  in  Example  9.1,  i.e. 

X (t; A, Θ) = A cos(ω0 t + Θ) 

where  A  and  Θ  are  independent  random  variables,  and  now  ω0  is  ﬁxed  at  some 
known  value. 

If  Θ  is  actually  ﬁxed  at  the  constant  value  θ0 ,  then  every  outcome  is  of  the  form 
x(t) = A cos(ω0 t + θ0 ),  and  it  is  straightforward  to  see  that  this process  is not WSS 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

168  Chapter  9 

Random  Processes 

(and hence not SSS). For  instance,  if A has a nonzero mean value, µA  = 0,  then the 
expected  value  of  the  process,  namely  µA cos(ω0 t + θ0 ),  is  time  varying.  To  argue 
that the process is not WSS even when µA  = 0, we can examine the autocorrelation 
function.  Note  that  x(t)  is  ﬁxed  at  the  value  0  for  all  values  of  t  such  that ω0 t + θ0 
is  an  odd  multiple  of  π/2,  and  takes  the  values  ±A  half-way  between  such  points; 
the correlation between such samples taken π/ω0  apart in time can correspondingly 
be  0  (in  the  former  case)  or  −E [A2 ]  (in  the  latter).  The  process  is  thus  not WSS. 
On  the  other  hand,  if  Θ  is  distributed  uniformly  in  [−π , π ],  then 
Z  π  1 
cos(ω0 t + θ)dθ = 0  , 
µX (t) = µA 
−π  2π 
CXX (t1 , t2 ) = RXX (t1 , t2 ) 
= E [A2 ]E [cos(ω0 t1  + Θ) cos(ω0 t2  + Θ)] 
E [A2 ] 
2 

cos(ω0 (t2  − t1 ))  , 
so  the  process  is  WSS.  It  can  also  be  shown  to  be  SSS,  though  this  is  not  totally 
straightforward  to  show  formally. 

= 

(9.11) 

(9.12) 

To  simplify  notation  for  a  WSS  process,  we  write  the  correlation  function  as 
RXX (t1  − t2 );  the  argument  t1  − t2  is  referred  to  as  the  lag  at  which  the  corre­
lation  is  computed.  For  the  most  part,  the  random  processes  that  we  treat  will 
be  WSS  processes.  When  considering  just  ﬁrst  and  second  moments  and  not  en­
tire  PDFs  or  CDFs,  it  will  be  less  important  to  distinguish  between  the  random 
process  X (t)  and  a  speciﬁc  realization  x(t)  of  it —  so  we  shall  go  one  step  further 
in  simplifying  notation,  by  using  lower  case  letters  to  denote  the  random  process 
itself.  We  shall  thus  talk  of  the  random  process  x(t),  and —  in  the  case  of  a WSS 
process  —  denote  its  mean  by  µx  and  its  correlation  function  E {x(t + τ )x(t)}  by 
Rxx (τ ).  Correspondingly,  for DT we’ll  refer  to  the  random process x[n] and  (in  the 
WSS  case)  denote  its mean  by  µx  and  its  correlation  function  E {x[n + m]x[n]}  by 
Rxx [m]. 

9.3.1  Some  Properties  of WSS  Correlation  and  Covariance  Functions 

It  is  easily  shown  that  for  real-valued WSS  processes  x(t)  and  y(t)  the  correlation 
and  covariance  functions  have  the  following  symmetry  properties: 

Cxx (τ ) = Cxx (−τ ) 
Rxx (τ ) = Rxx (−τ )  ,
Cxy (τ ) = Cyx (−τ )  . 
Rxy (τ ) = Ryx (−τ )  ,
We  see  from  (9.13)  that  the  autocorrelation  and  autocovariance  have  even  symme­
try.  Similar  properties  hold  for  DT WSS  processes. 

(9.13) 
(9.14) 

Another  important  property  of  correlation  and  covariance  functions  follows  from 
noting  that  the  correlation  coeﬃcient  of  two  random  variables  has  magnitude  not 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
Section  9.4 

Summary  of  Deﬁnitions  and  Notation  169 

exceeding  1.  Applying  this  fact  to  the  samples  x(t)  and  x(t + τ )  of  the  random 
process  x(  )  directly  leads  to  the  conclusion  that 
· 

− Cxx (0)  ≤  Cxx (τ )  ≤  Cxx (0)  . 

(9.15) 

In  other  words,  the  autocovariance  function  never  exceeds  in  magnitude  its  value 
2  to  each  term above, we ﬁnd  the  following  inequality holds 
at  the origin.  Adding µx 
for  correlation  functions: 

2  ≤  Rxx (τ )  ≤  Rxx (0)  . 
− Rxx (0) + 2µx 

(9.16) 

In  Chapter  10  we  will  demonstrate  that  correlation  and  covariance  functions  are 
characterized  by  the  property  that  their  Fourier  transforms  are  real  and  non­
negative  at  all  frequencies,  because  these  transforms  describe  the  frequency  dis­
tribution  of  the  expected  power  in  the  random  process.  The  above  symmetry  con­
straints  and  bounds  will  then  follow  as  natural  consequences,  but  they  are  worth 
highlighting  here  already. 

9.4  SUMMARY  OF  DEFINITIONS  AND  NOTATION 

In this section we summarize some of the deﬁnitions and notation we have previously 
introduced.  As  in  Section  9.3,  we  shall  use  lower  case  letters  to  denote  random 
processes,  since we will  only  be  dealing  with  expectations  and  not  densities.  Thus, 
with  x(t)  and  y(t)  denoting  (real)  random  processes,  we  summarize  the  following 
deﬁnitions: 

mean  :

(t) △
µx = E {x(t)} 

autocorrelation  :
cross − correlation  :

Rxx

Rxy

(t1 , t2 ) △
= E {x(t1 )x(t2 )} 
(t1 , t2 ) △
= E {x(t1 )y(t2 )} 

(9.17) 

(9.18) 

(9.19) 

autocovariance  :

(t1 , t2 ) △
(t1 )][x(t2 ) − µx (t2 )]}
= E {[x(t1 ) − µx

Cxx
= Rxx (t1 , t2 ) − µx (t1 )µx (t2 ) 
(9.20) 

(t1 , t2 ) △
(t1 )][y(t2 ) − µy (t2 )]}
= E {[x(t1 ) − µx

Cxy
= Rxy (t1 , t2 ) − µx (t1 )µy (t2 ) 
(9.21)

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

cross − covariance  :

170  Chapter  9 

Random  Processes 

strict-sense  stationary  (SSS):  all  joint  statistics  for  x(t1 ), x(t2 ), . . . , x(tℓ )  for  all  ℓ > 0 
and  all  choices  of  sampling  instants  t1 , · · ·  , tℓ 
depend  only  on  the  relative  locations  of  sampling  instants. 
wide-sense  stationary  (WSS):  µx (t)  is  constant  at  some  value  µx ,  and  Rxx (t1 , t2 )  is  a  function 
of  (t1  − t2 )  only,  denoted  in  this  case  simply  by  Rxx (t1  − t2 ); 
hence  Cxx (t1 , t2 )  is  a  function  of  (t1  − t2 )  only,  and 
written  as  Cxx (t1  − t2 ). 
x(t)  and  y(t)  are  individually WSS  and  Rxy (t1 , t2 )  is 
a  function  of  (t1  − t2 )  only,  denoted  simply  by 
Rxy (t1  − t2 );  hence  Cxy (t1 , t2 )  is  a  function  of  (t1  − t2 )  only, 
and  written  as  Cxy (t1  − t2 ). 

jointly  wide-sense  stationary: 

For WSS  processes  we  have,  in  continuous-time  and  with  simpler  notation, 

Rxx (τ ) = E {x(t + τ )x(t)} = E {x(t)x(t − τ )} 
Rxy (τ ) = E {x(t + τ )y(t)} = E {x(t)y(t − τ )}, 
and  in  discrete-time, 

Rxx [m] = E {x[n + m]x[n]} = E {x[n]x[n − m]} 
Rxy [m] = E {x[n + m]y [n]} = E {x[n]y [n − m]}. 
We  use  corresponding  (centered)  deﬁnitions  and  notation  for  covariances: 

Cxx (τ ), Cxy (τ ), Cxx [m],  and  Cxy [m]  . 

(9.22) 
(9.23) 

(9.24) 
(9.25) 

It  is worth noting  that an alternative  convention used  elsewhere  is  to deﬁne Rxy (τ ) 
(τ ) △
as Rxy
= E {x(t)y(t+ τ )}.
In our notation, this expectation would be denoted by 
Rxy (−τ ).  It’s important to be careful to take account of what notational convention 
is  being  followed  when  you  read  this  material  elsewhere,  and  you  should  also  be 
clear  about  what  notational  convention  we  are  using  in  this  text. 

9.5  FURTHER  EXAMPLES 

EXAMPLE  9.6 

Bernoulli  process 

The  Bernoulli  process,  a  speciﬁc  example  of  which  was  discussed  previously  in 
Example  9.3,  is  an  example  of  an  i.i.d.  DT  process  with 

P(x[n] = 1) = p 
P(x[n] = −1) = (1 − p) 
and  with  the  value  at  each  time  instant  n  independent  of  the  values  at  all  other 

(9.26) 
(9.27) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  9.5 

Further  Examples  171 

time  instants.  A  simple  calculation  results  in 
E {x[n]} = 2p − 1 = µx 
(1 
m = 0 
E {x[n + m]x[n]} = 
(2p − 1)2  m = 0 
Cxx [m] = E {(x[n + m] − µx )(x[n] − µx )} 
= {1 − (2p − 1)2 }δ [m] = 4p(1 − p)δ [m]  . 

(9.28) 

(9.29) 

(9.30) 
(9.31) 

EXAMPLE  9.7 

Random  telegraph  wave 

A  useful  example  of  a  CT  random  process  that  we’ll  make  occasional  reference 
to  is  the  random  telegraph  wave.  A  representative  sample  function  of  a  random 
telegraph  wave  process  is  shown  in  Figure  9.4.  The  random  telegraph  wave  can  be 
deﬁned  through  the  following  two  properties: 

x(t) 

+1 

−1 

�  t 

FIGURE  9.4  One  realization  of  a  random  telegraph  wave. 

1.	 X (0) = ±1  with  probability  0.5. 
2. 	 X (t)  changes  polarity  at Poisson  times,  i.e.,  the  probability  of  k  sign  changes

in  a  time  interval  of  length  T  is


P(k  sign  changes  in  an  interval  of  length  T ) = 

(λT )k e−λT 
k ! 

. 

(9.32) 

Property  2  implies  that  the  probability  of  a  non-negative,  even  number  of  sign 
changes  in  an  interval  of  length  T  is 
= e−λT  X 
P(a  non-negative  even  #  of  sign  changes) =  X 
∞ 1 + (−1)k  (λT )k 
∞ (λT )k
e−λT 
2 
k ! 
k !	
k=0 
k=0 
k  even 
Using  the  identity 

(9.33) 

∞ (λT )k 
λT  Xe  = 
k ! 
k=0 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

6
	
172  Chapter  9 

Random  Processes 

equation  (9.33)  becomes 
P(a  non-negative  even #  of  sign  changes) = e−λT  (eλT  + e−λT ) 
2 
1 
=  (1 + e−2λT )  . 
2 

(9.34) 

= 

= 

1 
2 

. 

Similarly,  the  probability  of  an  odd  number  of  sign  changes  in  an  interval  of  length 
T  is  1 (1 − e−2λT ).  It  follows  that 
2 
P(X (t) = 1) = P(X (t) = 1 X (0) = 1)P(X (0) = 1) 
|
+ P(X (t) = 1|X (0) = −1)P(X (0) = −1) 
1 
=  P(even  #  of  sign  changes  in  [0, t]) 
2 
1 
+  P(odd  #  of  sign  changes  in  [0, t]) 
2 
1 ½ 
1 ½ 
¾ 
¾ 
1 
1 
(1 + e−2λt ) + 
(1 − e−2λt )
2 
2
2
2
Note that because of Property I, the expression  in the  last  line of Eqn.  (9.35)  is not 
needed, since the line before that already allows us to conclude that the answer is  1
2 : 
since  the  number  of  sign  changes  in  any  interval  must  be  either  even  or  odd,  their 
probabilities add up  to 1,  so P (X (t) = 1) =  1
2 .  However,  if Property 1  is  relaxed  to 
1 ,  then  the  above  computation must  be  carried  through 
allow P(X (0) = 1) = p0  =  2
to  the  last  line,  and  yields  the  result 
¾ 
½ 
½ 
¾
1 ©1 + (2p0  − 1)e−2λtª 
1 
1 
(1 − e−2λt )
(1 + e−2λt )  +(1−p0 ) 
2 
2 
2
(9.36) 
Returning  to  the  case  where  Property  1  holds,  so  P(X (t) = 1),  we  get 

P(X (t) = 1) = p0 

(9.35) 

= 

. 

µX (t) = 0,  and 
RXX (t1 , t2 ) = E [X (t1 )X (t2 )] 
= 1 × P (X (t1 ) = X (t2 )) + (−1) × P (X (t1 ) =6 X (t2 )) 
= e−2λ|t2−t1 |  . 

(9.37) 

(9.38) 

In  other  words,  the  process  is  exponentially  correlated  and WSS. 

9.6  ERGODICITY 

The  concept  of  ergodicity  is  sophisticated  and  subtle,  but  the  essential  idea  is  de­
scribed here.  We typically observe the outcome of a random process (e.g., we record 
a  noise waveform)  and want  to  characterize  the  statistics  of  the  random  process  by 
measurements  on  one  ensemble member.  For  instance, we  could  consider  the  time-
average  of  the  waveform  to  represent  the mean  value  of  the  process  (assuming  this 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
Section  9.7 

Linear  Estimation  of  Random  Processes  173 

mean  is  constant  for  all  time).  We  could  also  construct  histograms  that  represent 
the  fraction of  time  (rather  than  the probability-weighted  fraction of  the ensemble) 
that the waveform lies in diﬀerent amplitude bins, and this could be taken to reﬂect 
the  probability  density  across  the  ensemble  of  the  value  obtained  at  a  particular 
sampling time.  If the random process is such that the behavior of almost every par­
ticular  realization  over  time  is  representative  of  the  behavior  down  the  ensemble, 
then  the  process  is  called  ergodic. 

A  simple  example  of  a  process  that  is  not  ergodic  is  Example  9.2,  an  ensemble  of 
batteries.  Clearly,  for  this  example,  the behavior  of  any  realization  is not  represen­
tative  of  the  behavior  down  the  ensemble. 

hxi = 

Narrower  notions  of  ergodicity  may  be  deﬁned.  For  example,  if  the  time  average 
1  Z  T 
lim 
T →∞  2T 
−T 
almost  always  (i.e.  for  almost  every  realization  or  outcome)  equals  the  ensemble 
average  µX ,  then  the  process  is  termed  ergodic  in  the  mean.  It  can  be  shown, 
for  instance,  that  a  WSS  process  with  ﬁnite  variance  at  each  instant  and  with  a 
covariance  function  that  approaches  0  for  large  lags  is  ergodic  in  the  mean.  Note 
that  a  (nonstationary)  process  with  time-varying  mean  cannot  be  ergodic  in  the 
mean. 

x(t) dt 

(9.39) 

In  our  discussion  of  random  processes,  we  will  primarily  be  concerned  with  ﬁrst-
and  second-order  moments  of  random  processes.  While  it  is  extremely  diﬃcult 
to  determine  in  general  whether  a  random  process  is  ergodic,  there  are  criteria 
(speciﬁed  in  terms  of  the  moments  of  the  process)  that  will  establish  ergodicity 
in  the  mean  and  in  the  autocorrelation.  Frequently,  however,  such  ergodicity  is 
simply  assumed  for  convenience,  in  the  absence  of  evidence  that  the  assumption 
is  not  reasonable.  Under  this  assumption,  the  mean  and  autocorrelation  can  be 
obtained  from  time-averaging  on  a  single  ensemble  member,  through  the  following 
equalities: 
1  ZT
E {x(t)} =  lim 
T →∞  2T 
−T 
1  ZT
E {x(t)x(t + τ )} =  lim 
T →∞  2T 
−T 
A  random  process  for  which  (9.40)  and  (9.41)  are  true  is  referred  as  second-order 
ergodic. 

x(t)x(t + τ )dt 

x(t)dt 

(9.40) 

and 

(9.41) 

9.7  LINEAR  ESTIMATION  OF  RANDOM  PROCESSES 

A  common  class  of  problems  in  a  variety  of  aspects  of  communication,  control  and 
signal  processing  involves  the  estimation  of  one  random  process  from  observations 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

174  Chapter  9 

Random  Processes 

of  another,  or  estimating  (predicting)  future  values  from  the  observation  of  past 
values.  For example,  it  is common  in communication  systems that  the signal at the 
receiver  is  a  corrupted  (e.g.,  noisy)  version  of  the  transmitted  signal,  and we would 
like  to  estimate  the  transmitted  signal  from  the  received  signal.  Other  examples 
lie  in  predicting  weather  and  ﬁnancial  data  from  past  observations.  We  will  be 
treating  this  general  topic  in much more  detail  in  later  chapters,  but  a  ﬁrst  look  at 
it  here  can  be  beneﬁcial  in  understanding  random  processes. 

We  shall  ﬁrst  consider  a  simple  example  of  linear  prediction  of  a  random  process, 
then a more elaborate example of linear FIR ﬁltering of a noise-corrupted process to 
estimate  the underlying  random  signal.  We  conclude  the  section with  some  further 
discussion  of  the  basic  problem  of  linear  estimation  of  one  random  variable  from 
measurements  of  another. 

9.7.1  Linear  Prediction 

As  a  simple  illustration  of  linear  prediction,  consider  a  discrete-time  process  x[n]. 
Knowing  the  value  at  time  n0  we  may  wish  to  predict  what  the  value  will  be  m 
samples  into  the  future,  i.e.  at  time  n0  + m.  We  limit  the  prediction  strategy  to  a 
linear  one,  i.e.,  with  ˆx[n0  + m]  denoting  the  predicted  value,  we  restrict  ˆx[n0  + m] 
to  be  of  the  form 

xˆ[n0  + m] = ax[n0 ] + b 

(9.42) 

and  choose  the  prediction  parameters  a  and  b  to  minimize  the  expected  value  of 
the  square  of  the  error,  i.e.,  choose  a  and  b  to minimize 

ǫ = E {(x[n0  + m] − xˆ[n0  + m])2 } 

(9.43) 

or 

(9.44) 

ǫ = E {(x[n0  + m] − ax[n0 ] − b)2 }. 
To  minimize  ǫ  we  set  to  zero  its  partial  derivative  with  respect  to  each  of  the  two 
parameters  and  solve  for  the  parameter  values.  The  resulting  equations  are 
E {(x[n0  + m] − ax[n0 ] − b)x[n0 ]} = E {(x[n0  + m] − xb[n0  + m])x[n0 ]} = 0 
(9.45a) 
E {x[n0  + m] − ax[n0 ] − b} = E {x[n0  + m] − xb[n0  + m]} = 0  . 
(9.45b) 
Equation  (9.45a)  states  that  the  error  x[n0  + m] − xb[n0  + m]  associated  with  the 
optimal  estimate  is  orthogonal  to  the  available  data  x[n0 ].  Equation  (9.45b)  states 
that  the  estimate  is  unbiased. 
Carrying out the multiplications and expectations in the preceding equations results 
in  the  following  equations,  which  can  be  solved  for  the  desired  constants. 

Rxx [n0  + m, n0 ] − aRxx [n0 , n0 ] − bµx [n0 ] = 0 
µx [n0  + m] − aµx [n0 ] − b = 0. 

(9.46a) 
(9.46b) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  9.7 

Linear  Estimation  of  Random  Processes  175 

If we assume that the process is WSS so that Rxx [n0+m, n0 ] = Rxx [m], Rxx [n0 , n0 ] = 
Rxx [0], and also assume that it is zero mean, (µx  = 0), then equations (9.46) reduce 
to 

a = Rxx [m]/Rxx [0] 
b = 0 

(9.47) 
(9.48) 

so  that 

Rxx [m] 
xb[n0  + m] = 
x[n0 ]. 
Rxx [0] 
If  the  process  is  not  zero mean,  then  it  is  easy  to  see  that 
Cxx [m] 
xb[n0  + m] = µx  + 
(x[n0 ] − µx )  . 
Cxx [0] 
An  extension  of  this  problem  would  consider  how  to  do  prediction  when  measure­
ments of several past values are available.  Rather than pursue this case, we illustrate 
next  what  to  do  with  several  measurements  in  a  slightly  diﬀerent  setting. 

(9.49) 

(9.50) 

9.7.2  Linear  FIR  Filtering 

As another example, which we will treat in more generality in chapter 11 on Wiener 
ﬁltering,  consider  a  discrete-time  signal  s[n]  that  has  been  corrupted  by  additive 
noise d[n].  For  example,  s[n] might be a  signal  transmitted  over  a  channel and d[n] 
the  noise  introduced  by  the  channel.  The  received  signal  r [n]  is  then 

r [n] = s[n] + d[n]. 

(9.51) 

Assume  that  both  s[n]  and  d[n]  are  zero-mean  random  processes  and  are  uncor­
related.  At  the  receiver  we  would  like  to  process  r [n]  with  a  causal  FIR  (ﬁnite 
impulse  response)  ﬁlter  to  estimate  the  transmitted  signal  s[n]. 

d[n] 

s[n] 

�� 
� 
⊕ 
r [n] 

�  sb[n]
FIGURE  9.5  Estimating  the  noise  corrupted  signal. 

h[n] 

If  h[n]  is  a  causal  FIR  ﬁlter  of  length  L,  then 
sb[n] = X 
L−1
h[k ]r [n − k ]. 
k=0 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(9.52) 

176  Chapter  9 

Random  Processes 

∂ ǫ 
∂h[m] 

We would  like  to  determine  the  ﬁlter  coeﬃcients  h[k ]  to minimize  the mean  square 
error  between  sb[n]  and  s[n],  i.e.,  minimize  ǫ  given  by 
ǫ = E (s[n] − sb[n])2 
= E (s[n] − X 
L−1
h[k ]r [n − k ])2 . 
k=0 
∂ ǫ 
To  determine  h,  we  set  ∂h[m]  =  0  for  each  of  the  L  values  of  m.  Taking  this 
derivative,  we  get 
= −E {2(s[n] − X 
h[k ]r [n − k ])r [n − m]}
k 
= −E {2(s[n] − sb[n])r [n − m]}
m = 0, 1, 
· · · 
, L − 1 
(9.54) 
= 0 
which  is  the  orthogonality  condition we  should be  expecting:  the  error  (s[n] − sb[n]) 
associated  with  the  optimal  estimate  is  orthogonal  to  the  available  data,  r [n − m]. 
Carrying  out  the  multiplications  in  the  above  equations  and  taking  expectations 
results  in 
L−1X 
h[k ]Rrr [m − k ] = Rsr [m]  , m = 0, 1, 
, L − 1 
· · · 
k=0 
Eqns.  (9.55)  constitute  L  equations  that  can  be  solved  for  the  L  parameters  h[k ]. 
With  r [n] =  s[n] +  d[n],  it  is  straightforward  to  show  that  Rsr [m] =  Rss [m] + 
Rsd [m] and  since we assumed  that s[n] and d[n] are uncorrelated,  then Rsd [m] = 0. 
Similarly,  Rrr [m] = Rss [m] + Rdd [m]. 
These  results  are  also  easily  modiﬁed  for  the  case  where  the  processes  no  longer 
have  zero mean. 

(9.53) 

(9.55) 

9.8  THE  EFFECT  OF  LTI  SYSTEMS  ON  WSS  PROCESSES 

Your  prior  background  in  signals  and  systems,  and  in  the  earlier  chapters  of  these 
notes,  has  characterized how LTI  systems  aﬀect  the  input  for deterministic  signals. 

We  will  see  in  later  chapters  how  the  correlation  properties  of  a  random  process, 
and the eﬀects of LTI systems on these properties, play an  important role  in under­
standing  and  designing  systems  for  such  tasks  as  ﬁltering,  signal  detection,  signal 
estimation  and  system  identiﬁcation.  We  focus  in  this  section  on  understanding 
in  the  time  domain  how  LTI  systems  shape  the  correlation  properties  of  a  random 
process.  In  Chapter  10  we  develop  a  parallel  picture  in  the  frequency  domain,  af­
ter  establishing  that  the  frequency  distribution  of  the  expected  power  in  a  random 
signal  is  described  by  the  Fourier  transform  of  the  autocorrelation  function. 

Consider an LTI system whose input is a sample function of a WSS random process 
x(t),  i.e., a signal chosen by a probabilistic experiment  from the ensemble  that con­
stitutes  the  random process x(t); more  simply, we  say  that  the  input  is  the  random 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  9.8 

The  Eﬀect  of  LTI  Systems  on WSS  Processes  177 

process  x(t).  The  WSS  input  is  characterized  by  its  mean  and  its  autocovariance 
or  (equivalently)  autocorrelation  function. 

Among other considerations, we are  interested  in knowing when  the output process 
y(t) —  i.e.,  the ensemble of signals obtained as responses to the signals  in the  input 
ensemble — will itself be WSS, and want to determine its mean and autocovariance 
or  autocorrelation  functions,  as well  as  its  cross-correlation with  the  input  process. 
For  an  LTI  system  whose  impulse  response  is  h(t),  the  output  y(t)  is  given  by  the 
convolution 
Z  +∞ 
Z  +∞ 
−∞ 
−∞ 
for any speciﬁc input x(t) for which the convolution is well-deﬁned.  The convolution 
is well-deﬁned if, for instance, the input x(t) is bounded and the system is bounded-
input  bounded-output  (BIBO)  stable,  i.e.  h(t)  is  absolutely  integrable.  Figure  9.6 
indicates what the two components of the integrand in the convolution integral may 
look  like. 

h(v)x(t − v)dv = 

y(t) = 

x(v)h(t − v)dv 

(9.56) 

x(v) 

h(t - v) 

v 

v 

t

FIGURE  9.6  Illustration  of  the  two  terms  in  the  integrand  of  Eqn.  (9.56) 

Rather  than  requiring  that  every  sample  function of our  input process be bounded, 
it  will  suﬃce  for  our  convolution  computations  below  to  assume  that  E [x2 (t)]  = 
Rxx (0)  is ﬁnite.  With  this assumption,  and also assuming  that  the  system  is BIBO 
stable,  we  ensure  that  y(t)  is  a  well-deﬁned  random  process,  and  that  the  formal 
manipulations  we  carry  out  below  —  for  instance,  interchanging  expectation  and 
convolution  —  can  all  be  justiﬁed  more  rigorously  by  methods  that  are  beyond 
our  scope  here.  In  fact,  the  results  we  obtain  can  also  be  applied,  when  properly 
interpreted,  to  cases  where  the  input  process  does  not  have  a  bounded  second 
moment,  e.g., when x(t)  is  so-called CT white  noise,  for which Rxx (τ ) = δ(τ ).  The 
results  can  also  be  applied  to  a  system  that  is  not  BIBO  stable,  as  long  as  it  has  a 
well-deﬁned  frequency  response H (jω),  as  in  the  case  of  an  ideal  lowpass  ﬁlter,  for 
example. 

We  can  use  the  convolution  relationship  (9.56)  to  deduce  the  ﬁrst- and  second-
order properties of y(t).  What we shall establish  is that y(t)  is  itself WSS, and that 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

178  Chapter  9 

Random  Processes 

x(t)  and  y(t)  are  in  fact  jointly  WSS.  We  will  also  develop  relationships  for  the 
autocorrelation  of  the  output  and  the  cross-correlation  between  input  and  output. 

First,  consider  the  mean  value  of  the  output.  Taking  the  expected  value  of  both 
sides  of  (9.56),  we  ﬁnd 
¾ 
½Z  +∞ 
E [y(t)] = E
h(v)x(t − v) dv 
−∞ 
Z  +∞
h(v)E [x(t − v)] dv 
−∞Z  +∞ 
h(v)µx dv 
−∞Z  +∞ 
= µx 
−∞ 
= H (j 0) µx  = µy  . 

h(v) dv 

(9.57) 

= 

= 

In  other words,  the mean  of  the  output process  is  constant,  and  equals  the mean  of 
the  input  scaled  by  the  the  DC  gain  of  the  system.  This  is  also  what  the  response 
of  the  system  would  be  if  its  input  were  held  constant  at  the  value  µx . 
The  preceding  result  and  the  linearity  of  the  system  also  allow  us  to  conclude  that 
applying the zero-mean WSS process x(t) − µx  to the input of the stable LTI system 
would  result  in  the  zero-mean  process  y(t) − µy  at  the  output.  This  fact  will  be 
useful  below  in  converting  results  that  are  derived  for  correlation  functions  into 
results  that  hold  for  covariance  functions. 

Next  consider  the  cross-correlation  between  output  and  input: 
½·  Z  +∞ 
¾ 
¸
E {y(t + τ )x(t)} = E
h(v)x(t + τ  − v)dv  x(t) 
−∞ 
Z  +∞ 
h(v)E {x(t + τ  − v)x(t)}dv  . 
−∞ 
Since  x(t)  is WSS,  E {x(t + τ  − v)x(t)} = Rxx (τ  − v),  so 
Z  +∞ 
h(v)Rxx (τ  − v)dv 
E {y(t + τ )x(t)} = 
−∞ 
= h(τ ) ∗ Rxx (τ )

= Ryx (τ )  . 

= 

(9.58) 

(9.59)


Note  that  the  cross-correlation  depends  only  on  the  lag  τ  between  the  sampling 
instants  of  the  output  and  input  processes,  not  on  both  τ  and  the  absolute  time 
location  t.  Also,  this  cross-correlation  between  the  output  and  input  is  determinis­
tically  related  to  the  autocorrelation  of  the  input,  and  can  be  viewed  as  the  signal 
that would result if the system input were the autocorrelation function, as indicated 
in  Figure  9.7. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  9.8 

The  Eﬀect  of  LTI  Systems  on WSS  Processes  179 

Rxx (τ ) 

� 

h(τ ) 

�  Ryx (τ )

FIGURE  9.7  Representation  of  Eqn.  (9.59) 

We  can  also  conclude  that 
Rxy (τ ) = Ryx (−τ ) = Rxx (−τ ) ∗ h(−τ ) = Rxx (τ ) ∗ h(−τ )  , 
where the second equality follows from Eqn.  (9.59) and the fact that time-reversing 
the  two  functions  in  a  convolution  results  in  time-reversal  of  the  result,  while  the 
last equality follows from the symmetry Eqn.  (9.13) of the autocorrelation function. 

(9.60) 

The  above  relations  can  also  be  expressed  in  terms  of  covariance  functions,  rather 
than  in  terms  of  correlation  functions.  For  this,  simply  consider  the  case where  the 
input  to  the  system  is  the  zero-mean  WSS  process  x(t) − µx ,  with  corresponding 
zero-mean output y(t) − µy .  Since  the correlation  function  for x(t) − µx  is  the same 
as  the  covariance  function  for  x(t),  i.e.,  since 

Rx−µx ,x−µx (τ ) = Cxx (τ )  , 
the  results  above  hold  unchanged  when  every  correlation  function  is  replaced  by 
the  corresponding  covariance  function.  We  therefore  have,  for  instance,  that 

(9.61) 

¾ 
¸
h(v)x(t + τ  − v)dv  y(t) 

Cyx (τ ) = h(τ ) ∗ Cxx (τ ) 
Next  we  consider  the  autocorrelation  of  the  output  y(t): 
½·  Z  +∞ 
E {y(t + τ )y(t)} = E
−∞ 
Z  +∞ 
h(v) E {x(t + τ  − v)y(t)} dv 
| 
{z 
}
−∞ 
Rxy (τ −v) 
Z  +∞ 
h(v)Rxy (τ  − v)dv 
−∞ 
= h(τ ) ∗ Rxy (τ )

= Ryy (τ )  . 

= 

= 

(9.62) 

(9.63) 


Note  that  the  autocorrelation  of  the  output  depends  only  on  τ ,  and  not  on  both 
τ  and  t.  Putting  this  together  with  the  earlier  results,  we  conclude  that  x(t)  and 
y(t)  are  jointly WSS,  as  claimed. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

180  Chapter  9 

Random  Processes 

The  corresponding  result  for  covariances  is 

Cyy (τ ) = h(τ ) ∗ Cxy (τ )  . 
Combining  (9.63)  with  (9.60),  we  ﬁnd  that 
Ryy (τ ) = Rxx (τ ) ∗  h(τ ) ∗ h(−τ ) = Rxx (τ ) ∗ Rhh (τ )  . 
| 
{z 
} 
△ 
h(τ )∗h(−τ )=Rhh (τ ) 
The function Rhh (τ ) is typically referred to as the deterministic autocorrelation 
function  of  h(t),  and  is  given  by 
Z  +∞ 
−∞ 
For  the  covariance  function  version  of  (9.65),  we  have 
Cyy (τ ) = Cxx (τ ) ∗  h(τ ) ∗ h(−τ ) = Cxx (τ ) ∗ Rhh (τ )  . 
| 
{z 
} 
△ 
h(τ )∗h(−τ )=Rhh (τ ) 
Note  that  the  deterministic  correlation  function  of  h(t)  is  still  what  we  use,  even 
when relating the covariances of the input and output.  Only the means of the input 
and  output  processes  get  adjusted  in  arriving  at  the  present  result;  the  impulse 
response  is  untouched. 

Rhh (τ ) = h(τ ) ∗ h(−τ ) = 

h(t + τ )h(t)dt  . 

(9.66) 

(9.64) 

(9.65) 

(9.67) 

The  correlation  relations  in  Eqns.  (9.59),  (9.60),  (9.63)  and  (9.65),  as  well  as 
their  covariance  counterparts,  are  very  powerful,  and  we  will  make  considerable 
use  of  them.  Of  equal  importance  are  their  statements  in  the  Fourier  and  Laplace 
transform domains.  Denoting the Fourier and Laplace transforms of the correlation 
function  Rxx (τ )  by  Sxx (jω)  and  Sxx (s)  respectively,  and  similarly  for  the  other 
correlation  functions  of  interest,  we  have: 
Syy (jω) = Sxx (jω)|H (jω)| 2 , 
Syy (s) = Sxx (s)H (s)H (−s)  . 
We can denote the Fourier and Laplace transforms of the covariance function Cxx (τ ) 
by Dxx (jω) and Dxx (s) respectively, and similarly for the other covariance functions 
of  interest,  and  then  write  the  same  sorts  of  relationships  as  above. 

Syx (jω) = Sxx (jω)H (jω),
Syx (s) = Sxx (s)H (s),

(9.68) 

Exactly  parallel  results  hold  in  the  DT  case.  Consider  a  stable  discrete-time  LTI 
system whose  impulse response  is h[n] and whose  input  is the WSS random process 
x[n].  Then, as in the continuous-time case, we can conclude that the output process 
y [n]  is  jointly  WSS  with  the  input  process  x[n],  and 
µy  = µx X 
∞
h[n] 
−∞ 
Ryx [m] = h[m] ∗ Rxx [m] 
Ryy [m] = Rxx [m] ∗ Rhh [m]  , 

(9.70) 
(9.71) 

(9.69) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  9.8 

The  Eﬀect  of  LTI  Systems  on WSS  Processes  181 

where  Rhh [m]  is  the  deterministic  autocorrelation  function  of  h[m],  deﬁned  as 
Rhh [m] =  X 
+∞
h[n + m]h[n]  . 
n=−∞ 
The  corresponding  Fourier  and  Z -transform  statements  of  these  relationships  are: 
µy  = H (ej 0 )µx  , Syx (ejΩ ) = Sxx (ejΩ )H (ejΩ )  , Syy (ejΩ ) = Sxx (ejΩ )|H (ejΩ )| 2 , 
µy  = H (1)µx  ,
Syx (z ) = Sxx (z )H (z )  ,
Syy (z ) = Sxx (z )H (z )H (1/z ). 
(9.73) 

(9.72) 

All  of  these  expressions  can  also  be  rewritten  for  covariances  and  their  transforms. 

The basic  relationships  that we have developed  so  far  in  this  chapter  are  extremely 
powerful.  In  Chapter  10  we  will  use  these  relationships  to  show  that  the  Fourier 
transform  of  the  autocorrelation  function  describes  how  the  expected  power  of  a 
WSS  process  is  distributed  in  frequency.  For  this  reason,  the  Fourier  transform  of 
the autocorrelation  function  is termed the power  spectral  density  (PSD) of the 
process. 

The relationships developed in this chapter are also very important in using random 
processes  to measure  or  identify  the  impulse  response  of  an LTI  system.  For  exam­
ple, from (9.70), if the input x[n] to a DT LTI system is a WSS random process with 
autocorrelation  function  Rxx [m] =  δ [m],  then  by  measuring  the  cross-correlation 
between  the  input  and  output  we  obtain  a  measurement  of  the  system  impulse  re­
sponse.  It  is  easy  to  construct an  input process with autocorrelation  function  δ [m], 
for  example  an  i.i.d.  process  that  is  equally  likely  to  take  the  values +1  and −1  at 
each  time  instant. 

As  another  example,  suppose  the  input  x(t)  to  a  CT  LTI  system  is  a  random 
telegraph  wave,  with  changes  in  sign  at  times  that  correspond  to  the  arrivals  in  a 
Poisson  process  with  rate  λ,  i.e., 

. 

P(k  switches  in  an  interval  of  length  T ) = 

(λT )k e−λT 
k ! 
Then, assuming x(0) takes the values ±1 with equal probabilities, we can determine 
that  the  process  x(t)  has  zero  mean  and  correlation  function  Rxx (τ ) =  e−2λ|τ | ,  so 
it  is WSS  (for  t ≥ 0).  If we  determine  the  cross-correlation Ryx (τ ) with  the  output 
y(t)  and  then  use  the  relation 
Ryx (τ ) = Rxx (τ ) ∗ h(τ )  , 
we can obtain the system impulse response h(τ ).  For example,  if Syx (s), Sxx (s) and 
H (s)  denote  the  associated  Laplace  transforms,  then 

(9.74) 

(9.75) 

Syx (s)
Sxx (s) 
Note  that Sxx (s)  is a  rather well-behaved  function of  the  complex variable s  in  this 
case,  whereas  any  particular  sample  function  of  the  process  x(t)  would  not  have 
such  a  well-behaved  transform.  The  same  comment  applies  to  Syx (s). 

H (s) = 

(9.76) 

. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

182  Chapter  9 

Random  Processes 

As  a  third  example,  suppose  that  we  know  the  autocorrelation  function  Rxx [m] 
of  the  input  x[n]  to  a  DT  LTI  system,  but  do  not  have  access  to  x[n]  and  there­
fore  cannot  determine  the  cross-correlation  Ryx [m]  with  the  output  y [n],  but  can 
determine  the  output  autocorrelation  Ryy [m].  For  example,  if 

(9.77) 

Rxx [m] = δ [m] 
and  we  determine  Ryy [m]  to  be  Ryy [m] = ¡ 
1 ¢|m| ,  then 
2
µ 
1 ¶|m|
= Rhh [m] = h[m] ∗ h[−m]. 
Ryy [m] = 
2 
Equivalently, H (z )H (z−1 ) can be obtained from the Z -transform Syy (z ) of Ryy [m]. 
Additional  assumptions  or  constraints,  for  instance  on  the  stability  and  causality 
of  the  system  and  its  inverse,  may  allow  one  to  recover  H (z )  from  knowledge  of 
H (z )H (z−1 ). 

(9.78) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

10 

Power  Spectral Density 

INTRODUCTION 

Understanding how  the  strength  of  a  signal  is distributed  in  the  frequency domain, 
relative  to  the  strengths  of  other  ambient  signals,  is  central  to  the  design  of  any 
LTI  ﬁlter  intended  to  extract  or  suppress  the  signal.  We  know  this well  in  the  case 
of  deterministic  signals,  and  it  turns  out  to  be  just  as  true  in  the  case  of  random 
signals.  For  instance,  if  a  measured  waveform  is  an  audio  signal  (modeled  as  a 
random  process  since  the  speciﬁc  audio  signal  isn’t  known)  with  additive  distur­
bance  signals,  you  might  want  to  build  a  lowpass  LTI  ﬁlter  to  extract  the  audio 
and  suppress  the  disturbance  signals.  We  would  need  to  decide  where  to  place  the 
cutoﬀ  frequency  of  the  ﬁlter. 

There  are  two  immediate  challenges  we  confront  in  trying  to  ﬁnd  an  appropriate 
frequency-domain  description  for  a WSS  random  process.  First,  individual  sample 
functions  typically  don’t have  transforms  that  are  ordinary, well-behaved  functions 
of  frequency;  rather,  their  transforms  are  only  deﬁned  in  the  sense  of  generalized 
functions.  Second,  since  the  particular  sample  function  is  determined  as  the  out­
come of a probabilistic experiment,  its  features will actually be random,  so we have 
to  search  for  features  of  the  transforms  that  are  representative  of  the  whole  class 
of  sample  functions,  i.e.,  of  the  random  process  as  a  whole. 

It  turns  out  that  the  key  is  to  focus  on  the  expected  power  in  the  signal.  This  is  a 
measure  of  signal  strength  that  meshes  nicely  with  the  second-moment  characteri­
zations  we  have  for WSS  processes,  as  we  show  in  this  chapter.  For  a  process  that 
is  second-order  ergodic,  this  will  also  correspond  to  the  time  average  power  in  any 
realization.  We  introduce  the  discussion  using  the  case  of  CT WSS  processes,  but 
the  DT  case  follows  very  similarly. 

10.1	 EXPECTED  INSTANTANEOUS  POWER  AND  POWER  SPECTRAL 
DENSITY 

Motivated  by  situations  in  which  x(t)  is  the  voltage  across  (or  current  through)  a 
unit  resistor, we  refer  to  x2 (t)  as  the  instantaneous  power  in  the  signal  x(t).  When 
x(t)  is WSS,  the  expected  instantaneous  power  is  given  by 

1  Z 
2π 
−∞ 
c	
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

E [x 2 (t)] = Rxx (0) = 

∞ 

Sxx (jω) dω  , 

(10.1) 

183

184  Chapter  10 

Power  Spectral  Density 

where  Sxx (jω)  is  the  CTFT  of  the  autocorrelation  function  Rxx (τ ).  Furthermore, 
when  x(t)  is  ergodic  in  correlation,  so  that  time  averages  and  ensemble  averages 
are  equal  in  correlation  computations,  then  (10.1)  also  represents  the  time-average 
power  in  any  ensemble  member.  Note  that  since  Rxx (τ ) =  Rxx (−τ ),  we  know 
Sxx (jω)  is  always  real  and  even  in  ω ;  a  simpler  notation  such  as  Pxx (ω)  might 
therefore  have  been more  appropriate  for  it,  but  we  shall  stick  to  Sxx (jω)  to  avoid 
a  proliferation  of  notational  conventions,  and  to  keep  apparent  the  fact  that  this 
quantity  is  the  Fourier  transform  of  Rxx (τ ). 
The  integral  above  suggests  that  we  might  be  able  to  consider  the  expected  (in­
stantaneous)  power  (or,  assuming  the  process  is  ergodic,  the  time-average  power) 
in  a  frequency  band  of  width  dω  to  be  given  by  (1/2π)Sxx (jω) dω .  To  examine 
this  thought  further,  consider  extracting  a  band  of  frequency  components  of  x(t) 
by  passing  x(t)  through  an  ideal  bandpass  ﬁlter,  shown  in  Figure  10.1. 

x(t) 

�  H (jω) 

�  y(t) 

�Δ� 

H (jω) 
� 
1 

� Δ �

−ω0 
FIGURE  10.1  Ideal bandpass ﬁlter  to  extract a band of  frequencies  from  input, x(t). 

ω0 

� 
ω

Because  of  the  way  we  are  obtaining  y(t)  from  x(t),  the  expected  power  in  the 
output  y(t)  can  be  interpreted  as  the  expected  power  that  x(t)  has  in  the  selected 
passband.  Using  the  fact  that 

(10.2) 

E {y 2 (t)} = Ryy (0) = 
Thus 

Syy (jω) = |H (jω)|2Sxx (jω)  , 
we  see  that  this  expected  power  can  be  computed  as 
1  Z 
1  Z  +∞ 
Syy (jω) dω = 
2π 
2π
−∞ 
passband 
1  Z 
Sxx (jω) dω 
2π  passband 
is  indeed  the  expected  power  of  x(t)  in  the  passband.  It  is  therefore  reasonable  to 
call Sxx (jω)  the power  spectral  density  (PSD)  of x(t).  Note  that  the  instanta­
neous power of y(t), and hence the expected instantaneous power E [y2 (t)], is always 
nonnegative,  no  matter  how  narrow  the  passband,  It  follows  that,  in  addition  to 
being  real  and  even  in  ω ,  the  PSD  is  always  nonnegative,  Sxx (jω)  ≥  0  for  all  ω . 
While  the PSD Sxx (jω)  is  the Fourier  transform  of  the  autocorrelation  function,  it 

Sxx (jω) dω  . 

(10.3) 

(10.4) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section 10.2 

Einstein-Wiener-Khinchin Theorem on Expected Time-Averaged Power  185 

is  useful  to  have  a  name  for  the  Laplace  transform  of  the  autocorrelation  function; 
we  shall  refer  to  Sxx (s)  as  the  complex  PSD. 
Exactly  parallel  results  apply  for  the  DT  case,  leading  to  the  conclusion  that 
Sxx (ejΩ )  is  the  power  spectral  density  of  x[n]. 

10.2	 EINSTEIN-WIENER-KHINCHIN  THEOREM  ON  EXPECTED  TIME­
AVERAGED  POWER 

The previous  section deﬁned  the PSD as  the  transform of  the autocorrelation  func­
tion,  and  provided  an  interpretation  of  this  transform.  We  now  develop  an  alter­
native  route  to  the  PSD.  Consider  a  random  realization  x(t)  of  a  WSS  process. 
We  have  already  mentioned  the  diﬃculties  with  trying  to  take  the  CTFT  of  x(t) 
directly,  so  we  proceed  indirectly.  Let  xT (t)  be  the  signal  obtained  by  windowing 
x(t),  so  it  equals  x(t)  in  the  interval  (−T , T )  but  is  0  outside  this  interval.  Thus 
xT (t) = wT (t) x(t)  , 	
(10.5) 

∞	

(10.7) 

2 

. 

(10.8) 

where we deﬁne  the window  function wT (t)  to be 1  for  t < T  and 0 otherwise.  Let 
| |
XT (jω) denote the Fourier transform of xT (t); note that because the signal xT (t) is 
nonzero  only  over  the  ﬁnite  interval  (−T , T ),  its  Fourier  transform  is  typically well 
deﬁned.  We  know  that  the  energy  spectral  density  (ESD)  S xx (jω)  of  xT (t)  is 
given  by 

wT (α)wT (α − τ )x(α)x(α − τ ) dα ⇔ 

S xx (jω) =  |XT (jω)|2	
(10.6) 
and that this ESD is actually the Fourier transform of xT (τ )∗x←T  (τ ), where x←T  (t) = 
xT (−t).  We  thus  have  the  CTFT  pair 
Z 
∞ 
wT (α)wT (α − τ )x(α)x(α − τ ) dα ⇔ |XT (jω)|2  , 
xT (τ ) ∗ x←T  (τ ) = 
−∞ 
or,  dividing  both  sides  by  2T  (which  is  valid,  since  scaling  a  signal  by  a  constant 
scales  its  Fourier  transform  by  the  same  amount), 
1  Z 
2T
−∞ 
The quantity on the right is what we deﬁned (for the DT case) as the periodogram 
of  the  ﬁnite-length  signal  xT (t). 
Because  the  Fourier  transform  operation  is  linear,  the  Fourier  transform  of  the 
expected  value  of  a  signal  is  the  expected  value  of  the  Fourier  transform.  We 
may  therefore  take  expectations  of  both  sides  in  the  preceding  equation.  Since 
E [x(α)x(α − τ )] = Rxx (τ ),  we  conclude  that 
1 
E [|XT (jω)| 2 ]  ,	
Rxx (τ )Λ(τ ) ⇔ 
2T
where  Λ(τ )  is  a  triangular  pulse  of  height  1  at  the  origin  and  decaying  to  0  at 
|τ |  = 2T ,  the  result  of  carrying  out  the  convolution  wT  ∗ wT← (τ )  and  dividing  by 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

1 
2T  |XT (jω)|

(10.9) 

186  Chapter  10 

Power  Spectral  Density 

2T .  Now  taking  the  limit  as  T  goes  to ∞,  we  arrive  at  the  result

1

E [|XT (jω)| 2 ]  . 
(jω) =  lim 
Rxx ⇔ Sxx
(τ )
T →∞  2T
This  is  the  Einstein-Wiener-Khinchin  theorem  (proved  by  Wiener,  and  inde­
pendently  by  Khinchin,  in  the  early  1930’s,  but  —  as  only  recently  recognized  — 
stated  by  Einstein  in  1914). 

(10.10) 

The  result  is  important  to  us  because  it  underlies  a  basic  method  for  estimating 
Sxx (jω):  with  a  given  T ,  compute  the  periodogram  for  several  realizations  of  the 
random  process  (i.e.,  in  several  independent  experiments),  and  average  the  results. 
Increasing  the  number  of  realizations  over  which  the  averaging  is  done  will  reduce 
the  noise  in  the  estimate,  while  repeating  the  entire  procedure  for  larger  T  will 
improve  the  frequency  resolution  of  the  estimate. 

10.2.1  System  Identiﬁcation  Using  Random  Processes  as  Input 

Consider  the  problem  of  determining  or  “identifying”  the  impulse  response  h[n] 
of  a  stable  LTI  system  from  measurements  of  the  input  x[n]  and  output  y [n],  as 
indicated  in  Figure  10.2. 

x[n] 

� 

h[n] 

�  y [n] 

FIGURE  10.2  System  with  impulse  response  h[n]  to  be  determined. 

The  most  straightforward  approach  is  to  choose  the  input  to  be  a  unit  impulse 
x[n] =  δ [n],  and  to  measure  the  corresponding  output  y [n],  which  by  deﬁnition  is 
the  impulse  response.  It  is  often  the  case  in  practice,  however,  that we  do  not wish 
to —  or  are  unable  to —  pick  this  simple  input. 

For instance, to obtain a reliable estimate of the impulse response in the presence of 
measurement errors, we may wish  to use a more “energetic”  input, one  that excites 
the  system  more  strongly.  There  are  generally  limits  to  the  amplitude  we  can  use 
on  the  input  signal,  so  to  get  more  energy  we  have  to  cause  the  input  to  act  over 
a  longer  time.  We  could  then  compute  h[n]  by  evaluating  the  inverse  transform 
of  H (ejΩ ),  which  in  turn  could  be  determined  as  the  ratio  Y (ejΩ )/X (ejΩ ).  Care 
has  to  be  taken,  however,  to  ensure  that  X (ejΩ )  =  0  for  any  Ω;  in  other  words, 
the  input  has  to  be  suﬃciently  “rich”.  In  particular,  the  input  cannot  be  just  a 
ﬁnite  linear combination of sinusoids (unless the LTI system  is such that knowledge 
of  its  frequency  response  at  a  ﬁnite  number  of  frequencies  serves  to  determine  the 
frequency  response  at  all  frequencies  —  which  would  be  the  case  with  a  lumped 
system,  i.e.,  a  ﬁnite-order  system,  except  that  one  would  need  to  know  an  upper 
bound  on  the  order  of  the  system  so  as  to  have  a  suﬃcient  number  of  sinusoids 
combined  in  the  input). 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
Section 10.2 

Einstein-Wiener-Khinchin Theorem on Expected Time-Averaged Power  187 

The  above  constraints  might  suggest  using  a  randomly  generated  input  signal.  For 
instance, suppose we let the input be a Bernoul li process, with x[n] for each n taking 
the  value  +1  or  −1  with  equal  probability,  independently  of  the  values  taken  at 
other  times.  This  process  is  (strict- and)  wide-sense  stationary,  with  mean  value 
0  and  autocorrelation  function  Rxx [m] =  δ [m].  The  corresponding  power  spectral 
density  Sxx (ejΩ )  is  ﬂat  at  the  value  1  over  the  entire  frequency  range  Ω ∈  [−π , π ]; 
evidently  the  expected  power  of  x[n]  is  distributed  evenly  over  all  frequencies.  A 
process  with  ﬂat  power  spectrum  is  referred  to  as  a  white  process  (a  term  that 
is motivated  by  the  rough  notion  that white  light  contains  all  visible  frequencies  in 
equal  amounts);  a  process  that  is  not  white  is  termed  colored. 

Now  consider what  the DTFT X (ejΩ ) might  look  like  for a  typical  sample  function 
of  a  Bernoulli  process.  A  typical  sample  function  is  not  absolutely  summable  or 
square  summable,  and  so  does  not  fall  into  either  of  the  categories  for  which  we 
know  that  there  are  nicely  behaved  DTFTs.  We  might  expect  that  the  DTFT 
exists  in  some  generalized-function  sense  (since  the  sample  functions  are  bounded, 
and  therefore  do  not  grow  faster  than  polynomially  with  n  for  large  n ),  and  this 
|
|
is  indeed  the  case,  but  it  is not  a  simple  generalized  function;  not  even  as  “nice”  as 
the  impulses  or  impulse  trains  or  doublets  that  we  are  familiar  with. 

When  the  input  x[n]  is  a  Bernoulli  process,  the  output  y [n]  will  also  be  a  WSS 
random  process,  and  Y (ejΩ )  will  again  not  be  a  pleasant  transform  to  deal  with. 
However,  recall  that 

Ryx [m] = h[m] ∗ Rxx [m]  , 
so if we can estimate the cross-correlation of the input and output, we can determine 
the  impulse  response  (for  this  case  where  Rxx [m] =  δ [m])  as  h[m] =  Ryx [m].  For 
a  more  general  random  process  at  the  input,  with  a  more  general  Rxx [m],  we  can 
solve  for  H (ejΩ )  by  taking  the  Fourier  transform  of  (10.11),  obtaining 

(10.11) 

H (ejΩ ) = 

Syx (ejΩ ) 
Sxx (ejΩ ) 

. 

(10.12) 

If  the  input  is not accessible,  and only  its autocorrelation  (or  equivalently  its PSD) 
is  known,  then  we  can  still  determine  the  magnitude  of  the  frequency  response,  as 
long  as  we  can  estimate  the  autocorrelation  (or  PSD)  of  the  output.  In  this  case, 
we  have 

Syy (ejΩ ) 
2 
|H (ejΩ )| = 
Sxx (ejΩ ) 
Given  additional  constraints  or  knowledge  about  the  system,  one  can  often  deter­
mine a lot more (or even everything) about H (ejω ) from knowledge of its magnitude. 

. 

(10.13) 

10.2.2 

Invoking  Ergodicity 

How does one estimate Ryx [m] and/or Rxx [m] in an example such as the one above? 
The  usual  procedure  is  to  assume  (or  prove)  that  the  signals  x  and  y  are  ergodic. 
What  ergodicity  permits  —  as  we  have  noted  earlier  —  is  the  replacement  of  an 
expectation  or  ensemble  average  by  a  time  average,  when  computing  the  expected 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

188  Chapter  10 

Power  Spectral  Density 

lim 
N→∞ 

E {x[n]} = 

value of various  functions of  random variables associated with a  stationary  random 
process.  Thus  a WSS  process  x[n]  would  be  called  mean-ergodic  if 
1  X 
N
2N  + 1 
k=−N 
(The  convergence  on  the  right  hand  side  involves  a  sequence  of  random  variables, 
so there are subtleties involved  in deﬁning it precisely, but we bypass these issues in 
6.011.)  Similarly, for a pair of jointly-correlation-ergodic processes, we could replace 
the  cross-correlation  E {y [n + m]x[n]}  by  the  time  average  of  y [n + m]x[n]. 
What ergodicity generally requires is that values taken by a typical sample function 
over  time  be  representative  of  the  values  taken  across  the  ensemble.  Intuitively, 
what  this  requires  is  that  the  correlation  between  samples  taken  at  diﬀerent  times 
falls  oﬀ  fast  enough.  For  instance,  a  suﬃcient  condition  for  a  WSS  process  x[n] 
with  ﬁnite  variance  to  be  mean-ergodic  turns  out  to  be  that  its  autocovariance 
function  Cxx [m]  tends  to  0  as  |m|  tends  to  ∞,  which  is  the  case  with  most  of  the 
examples  we  deal  with  in  these  notes.  A  more  precise  (necessary  and  suﬃcient) 
condition  for  mean-ergodicity  is  that  the  time-averaged  autocovariance  function 
Cxx [m],  weighted  by  a  triangular  window,  be  0: 
1 − |m|  ¶ 
1  X µ 
L
Cxx [m] = 0 . 
lim 
L→∞  2L + 1 
L + 1 
m=−L 
A  similar  statement  holds  in  the  CT  case.  More  stringent  conditions  (involving 
fourth  moments  rather  than  just  second  moments)  are  needed  to  ensure  that  a 
process  is  second-order  ergodic;  however,  these  conditions are  typically  satisﬁed  for 
the  processes  we  consider,  where  the  correlations  decay  exponentially  with  lag. 

x[k ]  . 

(10.14) 

(10.15) 

10.2.3  Modeling  Filters  and Whitening  Filters 

There  are  various  detection  and  estimation  problems  that  are  relatively  easy  to 
formulate,  solve,  and  analyze  when  some  random  process  that  is  involved  in  the 
problem — for instance, the set of measurements — is white,  i.e., has a ﬂat spectral 
density.  When  the  process  is  colored  rather  than  white,  the  easier  results  from  the 
white  case  can  still  often  be  invoked  in  some  appropriate  way  if: 

(a)	 the  colored  process  is  the  result  of  passing  a white  process  through  some  LTI 
modeling  or  shaping  ﬁlter,  which  shapes  the  white  process  at  the  input  into 
one  that  has  the  spectral  characteristics  of  the  given  colored  process  at  the 
output;  or 
(b)	 the colored process is transformable into a white process by passing it through 
an  LTI  whitening  ﬁlter,  which  ﬂattens  out  the  spectral  characteristics  of  the 
colored  process  presented  at  the  input  into  those  of  the  white  noise  obtained 
at  the  output. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section 10.2 

Einstein-Wiener-Khinchin Theorem on Expected Time-Averaged Power  189 

Thus,  a modeling  or  shaping ﬁlter  is one  that  converts  a white process  to  some  col­
ored  process, while  a whitening  ﬁlter  converts  a  colored  process  to  a white  process. 

An  important  result  that  follows  from  thinking  in  terms  of  modeling  ﬁlters  is  the 
following  (stated  and  justiﬁed  rather  informally  here  —  a  more  careful  treatment 
is  beyond  our  scope): 

Key  Fact:  A  real  function Rxx [m]  is  the  autocorrelation  function  of  a  real-valued 
WSS  random  process  if  and  only  if  its  transform  Sxx (ejΩ )  is  real,  even  and  non­
negative.  The  transform  in  this  case  is  the  PSD  of  the  process. 

The necessity of  these  conditions on  the  transform of  the  candidate autocorrelation 
function  follows  from  properties  we  have  already  established  for  autocorrelation 
functions  and  PSDs. 

To argue  that  these conditions are also suﬃcient,  suppose Sxx (ejΩ ) has  these prop­
erties,  and  assume  for  simplicity  that  it  has  no  impulsive  part.  Then  it  has  a 
real  and  even  square  root,  which  we  may  denote  by  pSxx (ejΩ ).  Now  construct  a 
(possibly  noncausal)  modeling  ﬁlter  whose  frequency  response  H (ejΩ )  equals  this 
square  root;  the  unit-sample  reponse  of  this  ﬁlter  is  found  by  inverse-transforming 
H (ejΩ ) =  pSxx (ejΩ ).  If  we  then  apply  to  the  input  of  this  ﬁlter  a  (zero-mean) 
unit-variance white noise process,  e.g.,  a Bernoulli process  that has  equal probabil­
ities  of  taking +1  and −1  at  each DT  instant  independently  of  every  other  instant, 
then  the  output  will  be  a  WSS  process  with  PSD  given  by  |H (ejΩ )|2  =  Sxx (ejΩ ), 
and  hence  with  the  speciﬁed  autocorrelation  function. 

If  the  transform  Sxx (ejΩ )  had  an  impulse  at  the  origin,  we  could  capture  this  by 
adding an appropriate constant (determined by the impulse strength) to the output 
of  a  modeling  ﬁlter,  constructed  as  above  by  using  only  the  non-impulsive  part  of 
the transform.  For a pair of  impulses at  frequencies Ω = ±Ωo  = 0  in the transform, 
we could  similarly add a  term of  the  form A cos(Ωon + Θ), where A  is deterministic 
(and  determined  by  the  impulse  strength)  and  Θ  is  independent  of  all  other  other 
variables,  and  uniform  in  [0, 2π ]. 

Similar  statements  can  be made  in  the  CT  case. 

We illustrate below the logic involved in designing a whitening ﬁlter for a particular 
example;  the  logic  for  a  modeling  ﬁlter  is  similar  (actually,  inverse)  to  this. 

Consider  the  following  discrete-time  system  shown  in  Figure  10.3. 

x[n] 

� 

h[n] 

�  w[n] 

FIGURE  10.3  A  discrete-time  whitening  ﬁlter. 

Suppose  that  x[n]  is  a  process  with  autocorrelation  function  Rxx [m]  and  PSD 
Sxx (ejΩ ),  i.e.,  Sxx (ejΩ ) =  F {Rxx [m]}.  We  would  like  w[n]  to  be  a  white  noise 
output  with  variance  σ2  .w

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
190  Chapter  10 

Power  Spectral  Density 

We  know  that 

or, 

Sww (ejΩ ) = |H (ejΩ )|2 Sxx (ejΩ ) 
σ2 
w 
|H (ejΩ )|2  = 
. 
ejΩ ) 
Sxx (
This  then  tells  us  what  the  squared  magnitude  of  the  frequency  response  of  the 
LTI  system  must  be  to  obtain  a  white  noise  output  with  variance  σ2  .  If  we  have 
w
Sxx (ejΩ ) available as a  rational  function of ejΩ  (or  can model  it  that way),  then we 
can  obtain H (ejΩ )  by  appropriate  factorization  of  |H (ejΩ )|2 . 

(10.16) 

(10.17) 

EXAMPLE  10.1  Whitening  ﬁlter 

Suppose  that 

5
4  − cos(Ω). 
Then,  to  whiten  x(t),  we  require  a  stable  LTI  ﬁlter  for  which 

Sxx (ejΩ ) = 

|H (ejΩ )|2  = 

1 
ejΩ )(1 −

(1 − 

1
2

, 

1 e−jΩ )
2 

(10.18) 

(10.19) 

or  equivalently, 

1 
1 z−1 ) 
(1 −  1
z )(1 −
2 
2
The ﬁlter is constrained to be stable in order to produce a WSS output.  One choice 
of H (z )  that  results  in  a  causal  ﬁlter  is 

H (z )H (1/z ) = 

(10.20) 

. 

H (z ) = 

1 
1 
1 −  2 z−1 
with  region  of  convergence  (ROC)  given  by  |z | >  1 .  This  system  function  could  be 
2 
multiplied by the system function A(z ) of any al lpass system,  i.e., a system function 
satisfying  A(z )A(z−1 )  =  1,  and  still  produce  the  same  whitening  action,  because 
|A(ejΩ )|2  = 1. 

(10.21) 

, 

10.3  SAMPLING  OF  BANDLIMITED  RANDOM  PROCESSES 

A  WSS  random  process  is  termed  band limited  if  its  PSD  is  bandlimited,  i.e.,  is 
zero  for  frequencies  outside  some  ﬁnite  band.  For  deterministic  signals  that  are 
bandlimited,  we  can  sample  at  or  above  the  Nyquist  rate  and  recover  the  signal 
exactly.  We  examine  here  whether  we  can  do  the  same  with  bandlimited  random 
processes. 

In the discussion of sampling and DT processing of CT signals in your prior courses, 
the  derivations  and  discussion  rely  heavily  on  picturing  the  eﬀect  in  the  frequency 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  10.3 

Sampling  of  Bandlimited  Random  Processes  191 

domain,  i.e.,  tracking  the  Fourier  transform  of  the  continuous-time  signal  through 
the  C/D  (sampling)  and  D/C  (reconstruction)  process.  While  the  arguments  can 
alternatively  be  carried  out  directly  in  the  time  domain,  for  deterministic  ﬁnite-
energy  signals  the  frequency  domain  development  seems more  conceptually  clear. 

As  you  might  expect,  results  similar  to  the  deterministic  case  hold  for  the  re­
construction  of  bandlimited  random  processes  from  samples.  However,  since  these 
stochastic signals do not possess Fourier transforms except in the generalized sense, 
we  carry  out  the  development  for  random  processes  directly  in  the  time  domain. 
An  essentially  parallel  argument  could  have  been  used  in  the  time  domain  for  de­
terministic signals (by examining the total energy in the reconstruction error rather 
than  the  expected  instantaneous  power  in  the  reconstruction  error,  which  is  what 
we  focus  on  below). 

The basic sampling and bandlimited reconstruction process should be familiar from 
your  prior  studies  in  signals  and  systems,  and  is  depicted  in  Figure  10.4  below. 
In  this  ﬁgure  we  have  explicitly  used  bold  upper-case  symbols  for  the  signals  to 
underscore  that  they  are  random  processes. 

Xc (t) 

� 

C/D 

� 
T 

�

X[n] = Xc (nT ) 

X[n] 

� 

D/C 

� 
T 

� Yc (t) = P+∞  X[n] sinc( t−T
nT  )
n=−∞ 
where  sinc x =  sinπx 
πx 

FIGURE  10.4  C/D  and  D/C  for  random  processes. 

π , then 
For the deterministic case, we know that if xc (t) is bandlimited to less than  T
with  the  D/C  reconstruction  deﬁned  as 
yc (t) = X 
t − nT 
x[n] sinc( 
T 
n 
it  follows  that  yc (t) = xc (t).  In  the  case  of  random  processes,  what  we  show  below 
is  that,  under  the  condition  that  Sxc xc (jω),  the  power  spectral  density  of Xc (t),  is 
bandlimited  to  less  that  π ,  the  mean  square  value  of  the  error  between  Xc (t)  and 
T 
Yc (t)  is  zero;  i.e.,  if 

(10.22) 

) 

Sxc xc (jω) = 0 

|w| ≥ 

π 
T

, 

(10.23) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

192  Chapter  10 

Power  Spectral  Density 

then 

E  △
= E {[Xc (t) − Yc (t)]2 } = 0  . 
This,  in  eﬀect,  says  that  there  is  “zero  power”  in  the  error.  (An  alternative  proof 
to  the  one  below  is  outlined  in  Problem  13  at  the  end  of  this  chapter.) 

(10.24) 

To develop the above result, we expand the error and use the deﬁnitions of the C/D 
(or  sampling)  and  D/C  (or  ideal  bandlimited  interpolation)  operations  in  Figure 
10.4  to  obtain 

(t)Xc

(10.25) 

(t)}  . 

E  = E {X2 
2 (t)} − 2E {Yc
c (t)} + E {Yc 
We  ﬁrst  consider  the  last  term,  E {Yc (t)Xc (t)}: 
E {Yc (t)Xc (t)} = E {  X 
+∞
t − nT 
Xc (nT ) sinc( 
T 
n=−∞ 
=  X 
+∞
nT  − t 
Rxc xc (nT  − t) sinc( 
) 
T 
n=−∞ 
where,  in  the  last  expression,  we  have  invoked  the  symmetry  of  sinc(.)  to  change 
the  sign  of  its  argument  from  the  expression  that  precedes  it. 

) Xc (t)}

(10.26) 

(10.27) 

Equation  (10.26)  can  be  evaluated  using Parseval’s  relation  in  discrete  time, which 
states  that 
1  Z  π
X 
+∞
v [n]w[n] = 
2π 
−π 
n=∞ 
To  apply  Parseval’s  relation,  note  that  Rxc xc (nT  − t)  can  be  viewed  as  the  result 
of  the  C/D  or  sampling  process  depicted  in  Figure  10.5,  in  which  the  input  is 
considered  to  be  a  function  of  the  variable  τ : 

V (ejΩ )W ∗ (ejΩ )dΩ 

(10.28) 

Rxc xc (τ  − t) 

� 

C/D 

� Rxc xc (nT  − t) 

� 
T 
FIGURE  10.5  C/D  applied  to  Rxc xc (τ  − t). 

The  CTFT  (in  the  variable  τ )  of  Rxc xc (τ  − t)  is  e−jωtSxc xc (jω),  and  since  this  is 
bandlimited  to  ω <  π ,  the  DTFT  of  its  sampled  version  Rxc xc (nT  − t)  is 
| 
|
T
1 
Ω 
−jΩt
e  T  Sxc xc (j  ) 
T 
T

(10.29) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  10.3 

Sampling  of  Bandlimited  Random  Processes  193 

= 

Sxc xc (jω)dω 

. Consequently, 

E {Yc (t)Xc (t)} = 

t − mT 
) sinc( 
T 
t − mT 
) sinc( 
T 

Ωt 
e −j
in  the  interval  |Ω| < π .  Similarly,  the DTFT  of  sinc( nT −t )  is 
T 
T 
π 
under  the  condition  that  Sxc xc (jω)  is  bandlimited  to  ω <  T  ,
| 
|
1  Z  π 
jΩ 
Sxc xc ( 
)dΩ 
2πT 
T
−π 
1  Z  (π/T ) 
2π 
−(π/T ) 
2 (t)} 
= Rxc xc (0) = E {Xc 
Next,  we  expand  the  middle  term  in  equation  (10.25): 
2 (t)} = E {X X 
t − nT 
Xc (nT )Xc (mT ) sinc( 
E {Yc 
T
n m 
= X X 
t − mT 
Rxc xc (nT  − mT ) sinc( 
T
n m 
With  the  substitution  n − m = r ,  we  can  express  10.31  as 
Rxc xc (rT ) X 
2 (t)} = X 
t − mT 
t − mT  − rT 
) sinc( 
sinc( 
E {Yc 
T 
T
m 
r
Using  the  identity 
X 
sinc(n − θ1 )sinc(n − θ2 ) = sinc(θ2  − θ1 )  , 
n 
which  again  comes  from  Parseval’s  theorem  (see  Problem  12  at  the  end  of  this 
chapter),  we  have 
2 (t)} = X 
(rT ) sinc(r)
E {Yc 
Rxc xc 
r 
= Rxc xc (0) = E {X2 
c } 
since  sinc(r)  =  1  if  r  =  0  and  zero  otherwise.  Substituting  10.31  and  10.34  into 
10.25,  we  obtain  the  result  that  E  = 0,  as  desired. 

)  . 

(10.32) 

)}

) . 

(10.31) 

(10.30) 

(10.33) 

(10.34) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

194  Chapter  10 

Power  Spectral  Density 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010

c

C H A P T E R 

11 

Wiener  Filtering 

INTRODUCTION 

In this chapter we will consider the use of LTI systems in order to perform minimum 
mean-square-error  (MMSE)  estimation  of  a WSS  random  process  of  interest,  given 
measurements  of  another  related  process.  The  measurements  are  applied  to  the 
input  of  the  LTI  system,  and  the  system  is  designed  to  produce  as  its  output  the 
MMSE  estimate  of  the  process  of  interest. 

We  ﬁrst  develop  the  results  in  discrete  time,  and  for  convenience  assume  (unless 
otherwise stated) that the processes we deal with are zero-mean.  We will then show 
that  exactly  analogous  results  apply  in  continuous  time,  although  their  derivation 
is  slightly  diﬀerent  in  certain  parts. 

Our  problem  in  the  DT  case may  be  stated  in  terms  of  Figure  11.1. 

Here  x[n]  is  a  WSS  random  process  that  we  have  measurements  of.  We  want 
to  determine  the  unit  sample  response  or  frequency  response  of  the  above  LTI 
system such that the ﬁlter output yb[n]  is the minimum-mean-square-error  (MMSE) 
estimate  of  some  “target”  process  y [n]  that  is  jointly WSS  with  x[n].  Deﬁning  the 
error  e[n]  as 
Δ 
e[n] = yb[n] − y [n] , 
(11.1) 
we  wish  to  carry  out  the  following  minimization: 
min ǫ = E {e 2 [n]}  .	
]· 
h[
The resulting ﬁlter h[n] is called the Wiener ﬁlter for estimation of y [n] from x[n]. 

(11.2) 

In  some  contexts  it  is  appropriate  or  convenient  to  restrict  the  ﬁlter  to  be  an 
FIR  (ﬁnite-duration  impulse  response)  ﬁlter  of  length  N ,  e.g.  h[n]  =  0  except  in 
the  interval  0  ≤  n  ≤  N  − 1.  In  other  contexts  the  ﬁlter  impulse  response  can 
be  of  inﬁnite  duration  and  may  either  be  restricted  to  be  causal  or  allowed  to 
be  noncausal.  In  the  next  section  we  discuss  the  FIR  and  general  noncausal  IIR 

x[n] 

�  LTI  h[n] 

�	 yb[n] =  estimate 
y [n] =  target  process 
FIGURE  11.1  DT  LTI  ﬁlter  for  linear MMSE  estimation. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010	

195 

196  Chapter  11 

Wiener  Filtering 

(inﬁnite-duration  impulse  response)  cases.  A  later  section  deals  with  the  more 
involved  case  where  the  ﬁlter  is  IIR  but  restricted  to  be  causal. 

If x[n] = y [n] + v [n] where y [n] is a signal and v [n] is noise (both random processes), 
then  the  above  estimation  problem  is  called  a  ﬁltering  problem.  If  y [n] = x[n + n0 ] 
with  n0  positive,  and  if  h[n]  is  restricted  to  be  causal,  then  we  have  a  prediction 
problem.  Both  ﬁt  within  the  same  general  framework,  but  the  solution  under  the 
restriction  that  h[n]  be  causal  is  more  subtle. 

11.1  NONCAUSAL  DT  WIENER  FILTER 

(11.3) 

To determine the optimal choice for h[n] in (11.2), we ﬁrst expand the error criterion 
in  (11.2): 
ǫ = E  
h[k ]x[n − k ] − y [n] !2 
Ã
+∞X 
 . 
 
k −∞=
The  impulse  response  values  that  minimize  ǫ  can  then  be  obtained  by  setting 
∂ ǫ 
=  0  for  all  values  of  m  for  which  h[m]  is  not  restricted  to  be  zero  (or 
∂h[m]

otherwise  pre-speciﬁed):

 
= E  
! 
ÃX 
h[k ]x[n − k ] − y [n]  x[n − m] 
2 
 
 
k 
} 
{z
|
e[n] 
The  above  equation  implies  that 
E {e[n]x[n − m]} = 0,  or 
Rex [m] = 0,  for  all m  for  which  h[m]  can  be  freely  chosen. 

∂ ǫ 
∂h[m] 

(11.5) 

= 0  . 

(11.4) 

You  may  recognize  the  above  equation  (or  constraint)  on  the  relation  between  the 
input  and  the  error  as  the  familiar  orthogonality  principle:  for  the  optimal  ﬁlter, 
the  error  is  orthogonal  to  al l  the  data  that  is  used  to  form  the  estimate.  Under  our 
assumption  of  zero-mean  x[n],  orthogonality  is  equivalent  to  uncorrelatedness.  As 
we  will  show  shortly,  the  orthogonality  principle  also  applies  in  continuous  time. 

Note  that 

Rex [m] = E {e[n]x[n − m]} 
= E {(yb[n] − y [n])x[n − m]} 
= R [m] − Ryx [m]  . 
b
yx
Therefore,  an  alternative  way  of  stating  the  orthogonality  principle  (11.5)  is  that 
Ryx [m] = Ryx [m]  for  all  appropriate m . 
b
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(11.6) 

(11.7) 

Section  11.1 

Noncausal  DT Wiener  Filter  197 

or  equivalently, 

h[k ]Rxx [m − k ] = Ryx [m] 

In other words,  for the optimal system,  the cross-correlation between the  input and 
output  of  the  estimator  equals  the  cross-correlation  between  the  input  and  target 
output. 
To  actually  ﬁnd  the  impulse  response  values,  observe  that  since  yb[n]  is  obtained 
by  ﬁltering  x[n]  through  an  LTI  system  with  impulse  response  h[n],  the  following 
relationship  applies: 
Ryx [m] = h[m] ∗ Rxx [m]  . 
(11.8) 
b
Combining  this  with  the  alternative  statement  of  the  orthogonality  condition,  we 
can  write 
h[m] ∗ Rxx [m] = Ryx [m]  , 
X 
k 
Equation  (11.10)  represents  a  set  of  linear  equations  to  be  solved  for  the  impulse 
response  values.  If  the  ﬁlter  is  FIR  of  length N ,  then  there  are N  equations  in  the 
N  unrestricted  values  of  h[n].  For  instance,  suppose  that  h[n]  is  restricted  to  be 
zero  except  for n ∈  [0, N − 1].  The  condition  (11.10)  then yields as many  equations 
as  unknowns,  which  can  be  arranged  in  the  following  matrix  form,  which  you may 
recognize  as  the  appropriate  form  of  the  normal  equations  for  LMMSE  estimation, 
which  we  introduced  in  Chapter  8: 
Ryx [0]   
 
Rxx [1 − N ]    
h[0]    
· · · 
Rxx [0] 
Rxx [−1] 
Ryx [1]   .
· · ·  Rxx [2 − N ]   
h[1]   = 

Rxx [0] 
Rxx [1] 

 
 

. 
. 
. 
. 

 
 

.
.
. 
. 
. 
. 
.
.
  
 
  
 
. 
. 
. 
. 
.
.
Ryx [N  − 1] 
· · · 
h[N  − 1] 
Rxx [N  − 1]  Rxx [N  − 2] 
Rxx [0] 
(11.11) 
These  equations  can  now be  solved  for  the  impulse  response  values.  Because  of  the 
particular  structure  of  these  equations,  there  are  eﬃcient  methods  for  solving  for 
the  unknown  parameters,  but  further  discussion  of  these  methods  is  beyond  the 
scope  of  our  course. 

(11.9) 

(11.10) 

In  the  case  of  an  IIR  ﬁlter,  equation  (11.10)  must  hold  for  an  inﬁnite  number  of 
values  of  m  and,  therefore,  cannot  simply  be  solved  by  the  methods  used  for  a 
ﬁnite  number  of  linear  equations.  However,  if  h[n]  is  not  restricted  to  be  causal  or 
FIR,  the  equation  (11.10)  must  hold  for  all  values  of  m  from  −∞  to  +∞,  so  the 
z-transform  can  be  applied  to  equation  (11.10)  to  obtain 

H (z )Sxx (z ) = Syx (z ) 

(11.12) 

The  optimal  transfer  function,  i.e.  the  transfer  function  of  the  resulting  (Wiener) 
ﬁlter,  is  then 

H (z ) = Syx (z )/Sxx (z ) 

(11.13) 

If  either  of  the  correlation  functions  involved  in  this  calculation  does  not  possess 
a  z-transform  but  if  both  possess  Fourier  transforms,  then  the  calculation  can  be 
carried  out  in  the  Fourier  transform  domain. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

198  Chapter  11 

Wiener  Filtering 

Note  the  similarity  between  the  above  expression  for  the  optimal  ﬁlter  and  the 
expression we  obtained  in Chapters  5  and  7  for  the  gain  σY X /σXX  that multiplies 
a  zero-mean  random  variable X  to  produce  the LMMSE  estimator  for  a  zero-mean 
random  variables  Y .  In  eﬀect,  by  going  to  the  transform  domain  or  frequency 
domain, we  have  decoupled  the  design  into  a  problem  that —  at  each  frequency — 
is  as  simple  as  the  one  we  solved  in  the  earlier  chapters. 

As  we  will  see  shortly,  in  continuous  time  the  results  are  exactly  the  same: 
Ryx (τ ) = Ryx (τ ), 
b
h(τ ) ∗ Rxx (τ ) = Ryx (τ ), 
H (s)Sxx (s) = Syx (s),  and 

(11.14) 

(11.15) 
(11.16) 

H (s) = Syx (s)/Sxx (s) 

(11.17) 

The  mean-square-error  corresponding  to  the  optimum  ﬁlter,  i.e.  the  minimum 
MSE,  can  be  determined  by  straightforward  computation.  We  leave  you  to  show 
that 

(11.18) 

Ree [m] = Ryy [m] − R [m] = Ryy [m] − h[m] ∗ Rxy [m] 
b
yy
where  h[m]  is  the  impulse  response  of  the  optimal  ﬁlter.  The  MMSE  is  then  just 
Ree [0].  It  is  illuminating  to  rewrite  this  in  the  frequency  domain,  but  dropping  the 
argument  ejΩ  on  the power  spectra S (ejΩ )  and  frequency  response H (ejΩ ) below 
∗∗
to  avoid  notational  clutter: 
1  Z  π 
2π 
−π 
1  Z  π 
(Syy  − H Sxy ) dΩ 
2π 
−π 
1  Z  π 
Syy Sxx ´ 
Syy ³1 − 
SyxSxy
dΩ 
2π 
−π 
1  Z  π 
Syy ³1 − ρyxρyx ∗  ´ 
dΩ  . 
2π 
−π 

MMSE = Ree [0] = 

(11.19) 

See dΩ 

= 

= 

= 

The  function  ρyx (ejΩ )  deﬁned  by 

ρyx (ejΩ ) = 

Syx (ejΩ ) 
pSyy (ejΩ )Sxx
(ejΩ )
evidently plays the role of a frequency-domain correlation coeﬃcient (compare with 
our  earlier  deﬁnition  of  the  correlation  coeﬃcient  between  two  random  variables). 
This function is sometimes referred to as the coherence function of the two processes. 
Again, note the similarity of this expression to the expression σY Y  (1− ρ2 
) that we 
Y X 
obtained  in  a  previous  lecture  for  the  (minimum) mean-square-error  after  LMMSE 

(11.20) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  11.1 

Noncausal  DT Wiener  Filter  199 

estimation  of  a  random  variable  Y  using  measurements  of  a  random  variable X . 

EXAMPLE  11.1 

Signal  Estimation  in  Noise  (Filtering) 

Consider  a  situation  in which  x[n],  the  sum  of  a  target  process  y [n]  and  noise  v [n], 
is  observed: 

(11.21) 
x[n] = y [n] + v [n] . 
We  would  like  to  estimate  y [n]  from  our  observations  of  x[n].  Assume  that  the 
signal  and  noise  are  uncorrelated,  i.e.  Rvy [m] = 0.  Then 

H (ejΩ ) = 

(11.22) 
(11.23) 

Rxx [m] = Ryy [m] + Rvv [m], 
Ryx [m] = Ryy [m], 
Syy (ejΩ ) 
Syy (ejΩ ) + Svv (ejΩ ) 
At  values  of  Ω  for  which  the  signal  power  is  much  greater  than  the  noise  power, 
H (ejΩ )  ≈  1.  Where  the  noise  power  is  much  greater  than  the  signal  power, 
H (ejΩ ) ≈ 0.  For  example,  when 
Syy (ejΩ ) = (1 + e−jΩ )(1 + ejΩ ) = 2(1 + cos Ω) 
and  the  noise  is  white,  the  optimal  ﬁlter  will  be  a  low-pass  ﬁlter  with  a  frequency 
response  that  is appropriately  shaped,  shown  in Figure 11.2.  Note  that  the ﬁlter  in 

. 

(11.24) 

(11.25) 

4 

3.5


3


2.5


2


1.5


1


0.5


0


S  (ejΩ
)
yy

− π 

− π/2 

H(ejΩ
) 

0 
Ω 

S  (ejΩ
)
vv

π/2 

π 

FIGURE  11.2  Optimal  ﬁlter  frequency  response,  H (ejΩ ),  input  signal  PSD  signal, 
Syy (ejΩ ),  and  PSD  of  white  noise,  Svv (ejΩ ). 

this  case  must  have  an  impulse  response  that  is  an  even  function  of  time,  since  its 
frequency  response  is  a  real  –  and  hence  even  –  function  of  frequency. 

Figure  11.3  shows  a  simulation  example  of  such  a  ﬁlter  in  action  (though  for  a 
diﬀerent  Syy (ejΩ ).  The  top  plot  is  the  PSD  of  the  signal  of  interest;  the  middle 
plot  shows  both  the  signal  s[n]  and  the measured  signal  x[n];  and  the  bottom  plot 
compares  the  estimate  of  s[n]  with  s[n]  itself. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

200  Chapter  11 

Wiener  Filtering 

 
y
t
i
s
n
e
d
 
l
a
)
B
r
t
c
d
e
(
p
s
 
r
e
w
o
P

30
25
20
15
10
5
0
-5
-10
-0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5
Frequency
Power spectral density of AR(1) process

Syy

10
8
6
4
2
0
-2
-4
-6
-8
-10
0

Data x
Signal y

5

10

15 20 25
30 35
Sample number, n
(a) Signal and Data

40

45 50

10
8
6
4
2
0
-2
-4
-6
-8
-10

0

5

Signal estimate y 
True signal y

45 50

10

15 20 25
30 35
Sample number, n
(b) Signal and Signal Estimate

40

Wiener Filtering Example

Image by MIT OpenCourseWare, adapted from Fundamentals of Statistical
Signal Processing: Estimation Theory, Steven Kay. Prentice Hall, 1993.

FIGURE 11.3  Wiener ﬁltering example.  (From S.M. Kay, Fundamentals of Statistical

Signal Processing:  Estimation Theory, Prentice Hall, 1993.  Figures 11.9 and 11.10.)

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  11.1 

Noncausal  DT Wiener  Filter  201 

EXAMPLE  11.2 

Prediction 

Suppose  we  wish  to  predict  the measured  process  n0  steps  ahead,  so 

y [n] = x[n + n0 ]  . 

Then 

Ryx [m] = Rxx [m + n0 ] 
so  the  optimum  ﬁlter  has  system  function 

H (z ) = z n0  . 

(11.26) 

(11.27) 

(11.28) 

This  is  of  course  not  surprising:  since  we’re  allowing  the  ﬁlter  to  be  noncausal, 
prediction  is  not  a  diﬃcult  problem!  Causal  prediction  is  much  more  challenging 
and  interesting,  and  we  will  examine  it  later  in  this  chapter. 

EXAMPLE  11.3 

Deblurring  (or  Deconvolution) 

x[n] 

�  G(z ) 

v [n] 
�L� �  H (z ) 
�  xb[n] 
r [n] 
ξ [n] 

Known,  stable  system 
Wiener  ﬁlter

FIGURE  11.4  Wiener  ﬁltering  of  a  blurred  and  noisy  signal. 

In  the  Figure  11.4,  r [n]  is  a  ﬁltered  or  “blurred”  version  of  the  signal  of  interest, 
x[n], while v [n]  is additive noise that  is uncorrelated with x[n].  We wish to design a 
ﬁlter that will deblur the noisy measured signal ξ [n] and produce an estimate of the 
input  signal  x[n].  Note  that  in  the  absence  of  the  additive  noise,  the  inverse  ﬁlter 
1/G(z )  will  recover  the  input  exactly.  However,  this  is  not  a  good  solution  when 
noise  is  present,  because  the  inverse  ﬁlter  accentuates  precisely  those  frequencies 
where  the  measurement  power  is  small  relative  to  that  of  the  noise.  We  shall 
therefore  design  a Wiener  ﬁlter  to  produce  an  estimate  of  the  signal  x[n]. 

We  have  shown  that  the  cross-correlation  between  the  measured  signal,  which  is 
the  input  to  the Wiener  ﬁlter,  and  the  estimate  produced  at  its  output  is  equal  to 
the  cross-correlation  between  the  measurement  process  and  the  target  process.  In 
the  transform  domain,  the  statement  of  this  condition  is 
Sxξ (z ) = Sxξ (z ) 
b
Sξξ (z )H (z ) = S (z ) = Sxξ (z )  . 
bxξ 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(11.29) 

or 

(11.30) 

202  Chapter  11 

Wiener  Filtering 

We  also  know  that 

Sξξ (z ) = Svv (z ) + Sxx (z )G(z )G(1/z ) 
Sxξ (z ) = Sxr (z ) 
= Sxx (z )G(1/z ), 

(11.31) 
(11.32) 
(11.33) 

where we have (in the ﬁrst equality above) used the fact that Svr (z ) = G(1/z )Svx (z ) = 
0.  We  can  now  write 

H (z ) = 

Sxx (z )G(1/z )
Svv (z ) + Sxx (z )G(z )G(1/z ) 

. 

(11.34) 

We  leave  you  to  check  that  this  system  function  assumes  reasonable  values  in  the 
limiting cases where the noise power is very small, or very large.  It is also interesting 
to  verify  that  the  same  overall  ﬁlter  is  obtained  if  we  ﬁrst  ﬁnd  an MMSE  estimate 
rb[n]  from  ξ [n]  (as  in  Example  11.1),  and  then  pass  rb[n]  through  the  inverse  ﬁlter 
1/G(z ). 

EXAMPLE  11.4 

“De-Multiplication” 

A message  s[n]  is  transmitted  over  a multiplicative  channel  (e.g.  a  fading  channel) 
so  that  the  received  signal  r [n]  is 

r [n] = s[n]f [n]  . 

(11.35) 

Suppose  s[n]  and  f [n]  are  zero  mean  and  independent.  We  wish  to  estimate  s[n] 
from  r [n]  using  a Wiener  ﬁlter. 

Again,  we  have 

. 

Rsr [m] = Rsr [m] 
b
= h[m] ∗  Rrr [m] 
|  {z  } 
Rss [m]Rf f [m] 
But  we  also  know  that  Rsr [m] = 0.  Therefore  h[m] = 0.  This  example  emphasizes 
that  the  optimality  of  a  ﬁlter  satisfying  certain  constraints  and  minimizing  some 
criterion  does  not  necessarily  make  the  ﬁlter  a  good  one.  The  constraints  on  the 
ﬁlter  and  the  criterion  have  to  be  relevant  and  appropriate  for  the  intended  task. 
For  instance,  if f [n] was known  to be  i.i.d.  and +1 or −1 at  each  time,  then  simply 
squaring  the  received  signal  r [n]  at  any  time would have  at  least  given us  the  value 
of  s2 [n],  which would  seem  to  be more  valuable  information  than what  the Wiener 
ﬁlter  produces  in  this  case. 

(11.36) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

11.2  NONCAUSAL  CT  WIENER  FILTER 

Section  11.2 

Noncausal  CT Wiener  Filter  203 

In the previous discussion we derived and  illustrated the discrete-time Wiener ﬁlter 
for  the FIR  and  noncausal  IIR  cases.  In  this  section we  derive  the  continuous-time 
counterpart  of  the  result  for  the  noncausal  IIR  Wiener  ﬁlter.  The  DT  derivation 
involved  taking  derivatives  with  respect  to  a  (countable)  set  of  parameters  h[m], 
but  in  the CT  case  the  impulse  response  that we  seek  to  compute  is  a CT  function 
h(t),  so  the  DT  derivation  cannot  be  directly  copied.  However,  you  will  see  that 
the results take the same form as  in the DT case;  furthermore,  the derivation below 
has  a  natural  DT  counterpart,  which  provides  an  alternate  route  to  the  results  in 
the  preceding  section. 

Our  problem  is  again  stated  in  terms  of  Figure  11.5. 

Estimator 

x(t) 

�  h(t), H (jω) 

� 	 yb(t) =  estimate 
y(t) =  target  process 
FIGURE  11.5  CT  LTI  ﬁlter  for  linear MMSE  estimation. 

Let  x(t)  be  a  (zero-mean)  WSS  random  process  that  we  have  measurements  of. 
We want to determine the  impulse response or  frequency response of the above LTI 
system such that the ﬁlter output yb(t) is the LMMSE estimate of some (zero-mean) 
“target”  process  y(t)  that  is  jointly WSS  with  x(t).  We  can  again  write 
Δ 
e(t) = y(t) − yb(t) 
min ǫ = E {e 2 (t)}  . 
h(	 )· 
Assuming  the ﬁlter  is  stable  (or at  least has a well-deﬁned  frequency  response),  the 
process  yb(t)  is  jointly WSS  with  x(t).  Furthermore, 
E [yb(t + τ )y(t)] = h(τ ) ∗ Rxy (τ ) = Rbyy (τ )  , 
The  quantity  we  want  to minimize  can  again  be  written  as 
ǫ = E {e 2 (t)} = Ree (0)  ,	

(11.37) 

(11.38) 

(11.39) 

where  the error autocorrelation  function Ree (τ )  is — using  the deﬁnition  in  (11.37) 
—  evidently  given  by 

Ree (τ ) = Ryy (τ ) + R y (τ ) − R  y (τ ) − Ryy (τ )  . 
byb
yb
b
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(11.40) 

204  Chapter  11 

Wiener  Filtering 

Thus 

. 

= 

= 

dω 

ǫ = E {e 2 (t)} = Ree (0) = 

1  Z 
∞ 
See (jω) dω 
2π 
−∞ 
1  Z 
∞  ³Syy (jω) + S y (jω) − S  y (jω) − Syy (jω)´ 
byb
yb
b
2π 
−∞ 
1  Z 
∞ 
(Syy  + HH ∗Sxx  − H ∗Syx  − H Sxy ) dω  ,  (11.41) 
2π 
−∞ 
where  we  have  dropped  the  argument  jω  from  the  PSDs  in  the  last  line  above  for 
notational simplicity, and have used H ∗  to denote the complex conjugate of H (jω), 
namely H (−jω).  The  expression  in  this  last  line  is  obtained  by  using  the  fact  that 
x(t) and yb(t) are the WSS input and output, respectively, of a ﬁlter whose frequency 
response  is  H (jω).  Note  also  that  because  Ryx (τ ) = Rxy (−τ )  we  have 
Syx  = Syx (jω) = Sxy (−jω) = S ∗ 
. 
(11.42) 
xy 
Our  task  is  now  to  choose  H (jω)  to  minimize  the  integral  in  (11.41).  We  can  do 
this  by  minimizing  the  integrand  for  each  ω .  The  ﬁrst  term  in  the  integrand  does 
not  involve  or  depend  on H ,  so  in  eﬀect  we  need  to minimize 
HH ∗Sxx  − H ∗Syx  − H Sxy  = HH ∗Sxx  − H ∗Syx  − H S ∗ 
yx 
If all  the quantities  in  this  equation were  real,  this minimization would be  straight­
forward.  Even  with  a  complex H  and  Syx ,  however,  the  minimization  is  not  hard. 
The  key  to  the  minimization  is  an  elementary  technique  referred  to  as  completing 
the  square.  For  this,  we  write  the  quantity  in  (11.43)  in  terms  of  the  squared 
magnitude  of  a  term  that  is  linear  in  H .  This  leads  to  the  following  rewriting  of 
(11.43): 
Syx ∗ ´ 
³HpSxx  − √Sxx ´³H ∗pSxx  − √Sxx  − 
S ∗
Syx yx 
Syx 
(11.44) 
. 
Sxx 
In writing √Sxx , we have made use of the fact that Sxx (jω) is real and nonnegative. 
We have also  felt  free to divide by pSxx (jω) because  for any ω  where this quantity 
is 0 it can be shown that Syx (jω) = 0 also.  The optimal choice of H (jω) is therefore 
arbitrary  at  such  ω ,  as  evident  from  (11.43).  We  thus  only  need  to  compute  the 
optimal  H  at  frequencies  where pSxx (jω) > 0. 
Notice  that  the  second  term  in  parentheses  in  (11.44)  is  the  complex  conjugate 
of  the  ﬁrst  term,  so  the  product  of  these  two  terms  in  parentheses  is  real  and 
nonnegative.  Also,  the  last  term  does  not  involve  H  at  all.  To  cause  the  terms 
in  parentheses  to  vanish  and  their  product  to  thereby  become  0,  which  is  the  best 
we  can  do,  we  evidently  must  choose  as  follows  (assuming  there  are  no  additional 
constraints  such  as  causality  on  the  estimator): 

(11.43) 

Syx (jω)
Sxx (jω) 
This expression has the same form as in the DT case.  The formula for H (jω) causes 
it  to  inherit  the  symmetry  properties  of  Syx (jω),  so  H (jω)  has  a  real  part  that  is 

H (jω) = 

(11.45) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  11.3 

Causal Wiener  Filtering  205 

even  in  ω ,  and  an  imaginary  part  that  is  odd  in  ω .  Its  inverse  transform  is  thus  a 
real  impulse  response  h(t),  and  the  expression  in  (11.45)  is  the  frequency  response 
of  the  optimum  (Wiener)  ﬁlter. 

See dω 

MMSE = Ree (0) = 

With  the  choice  of  optimum  ﬁlter  frequency  response  in  (11.45),  the mean-square­
error  expression  in  (11.41)  reduces  (just  as  in  the  DT  case)  to: 
1  Z 
∞ 
2π 
−∞ 
1  Z 
∞ 
(Syy  − H Sxy ) dω 
2π 
−∞ 
1  Z 
SyxSxy ´ 
Syy ³1 − 
∞ 
dω 
Syy Sxx
2π
−∞ 
1  Z 
∞ 
Syy (1 − ρρ∗ ) dω 
2π 
−∞ 
where  the  function  ρ(jω)  is  deﬁned  by 
Syx (jω)
pSyy (jω)Sxx (jω) 
and  evidently  plays  the  role  of  a  (complex)  frequency-by-frequency  correlation  co­
eﬃcient, analogous to that played by the correlation coeﬃcient of random variables 
Y  and X . 

ρ(jω) = 

(11.46) 

(11.47) 

= 

= 

= 

11.2.1  Orthogonality  Property 

Rearranging  the  equation  for  the  optimal Wiener  ﬁlter,  we  ﬁnd 

H Sxx  = Syx 

(11.48) 

or 

(11.49) 

or  equivalently 

Syx  = Syx  , 
b
(11.50) 
Ryx (τ ) = Ryx (τ )  for  all  τ . 
b
Again,  for  the  optimal  system,  the  cross-correlation  between  the  input  and  output 
of  the  estimator  equals  the  cross-correlation  between  the  input  and  target  output. 
Yet another way to state the above result is via the following orthogonality property: 
Rex (τ ) = R (τ ) − Ryx (τ ) = 0  for  all  τ . 
b
yx
In  other  words,  for  the  optimal  system,  the  error  is  orthogonal  to  the  data. 
11.3  CAUSAL  WIENER  FILTERING 

(11.51) 

In  the  preceding  discussion  we  developed  the  Wiener  ﬁlter  with  no  restrictions  on 
the  ﬁlter  frequency  response  H (jω).  This  allowed  us  to  minimize  a  frequency-
domain  integral by  choosing H (jω)  at  each ω  to minimize  the  integrand.  However, 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

206  Chapter  11 

Wiener  Filtering 

if we constrain the ﬁlter to be causal,  then the frequency response cannot be chosen 
arbitrarily at each  frequency,  so the previous approach needs to be modiﬁed.  It can 
be  shown  that  for  a  causal  system  the  real  part  of  H (jω)  can  be  determined  from 
the  imaginary  part,  and  vice  versa,  using  what  is  known  as  a  Hilbert  transform. 
This shows that H (jω)  is constrained  in the causal case.  (We shall not need to deal 
explicitly  with  the  particular  constraint  relating  the  real  and  imaginary  parts  of 
H (jω),  so we will not pursue  the Hilbert  transform  connection here.)  The develop­
ment of the Wiener ﬁlter in the causal case is therefore subtler than the unrestricted 
case,  but  you  know  enough  now  to  be  able  to  follow  the  argument. 

Recall  our  problem,  described  in  terms  of  Figure  11.6. 
Estimator 

x(t) 

�  h(t), H (jω) 

�  yb(t) =  estimate 
y(t) =  target  process 
FIGURE  11.6  Representation  of  LMMSE  estimation  using  an  LTI  system. 

The  input  x(t)  is  a  (zero-mean) WSS  random  process  that  we  have  measurements 
of,  and  we  want  to  determine  the  impulse  response  or  frequency  response  of  the 
above  LTI  system  such  that  the  ﬁlter  output  yb(t)  is  the  LMMSE  estimate  of  some 
(zero-mean)  “target”  process  y(t)  that  is  jointly WSS  with  x(t): 
Δ 
e(t) = y(t) − yb(t) 
min ǫ = E {e 2 (t)}  . 
(11.52) 
h( )· 
We  shall  now  require,  however,  that  the  ﬁlter  be  causal.  This  is  essential  in,  for 
example,  the  problem  of  prediction,  where  y(t) = x(t + t0 )  with  t0  > 0. 
We  have  already  seen  that  the  quantity  we  want  to minimize  can  be  written  as 
1  Z 
∞ 
See (jω) dω 
2π 
−∞ 
1  Z 
∞  ³Syy (jω) + S (jω) − S  (jω) − S (jω)´ 
dω 
byb
yb
b
y 
2π 
y
yy
−∞ 
1  Z 
∞ 
(Syy  + HH ∗Sxx  − H ∗Syx  − H Sxy ) dω  (11.53) 
2π 
−∞ 
1  Z 
1  Z 
SyxS ∗ ´ 
¯¯¯  dω +
∞  ¯¯¯HpSxx  − 
∞  ³Syy  − 
Syx  2 
yx 
dω  . 
√Sxx 
2π 
Sxx
2π
−∞ 
−∞ 
(11.54) 
The  last  equality was  the  result  of  “completing  the  square”  on  the  integrand  in  the 
preceding  integral.  In  the case where H  is unrestricted, we can  set  the ﬁrst  integral 
of  the  last  equation  to  0  by  choosing 

ǫ = E {e 2 (t)} = Ree (0) = 

= 

= 

= 

H (jω) = 

Syx (jω)
Sxx (jω) 

(11.55) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  11.3 

Causal Wiener  Filtering  207 

at  each  frequency.  The  second  integral  of  the  last  equation  is  unaﬀected  by  our 
choice  of  H ,  and  determines  the MMSE. 
If  the Wiener  ﬁlter  is  required  to  be  causal,  then  we  have  to  deal  with  the  integral 
π  Z 
∞  ¯¯¯HpSxx  − √Sxx ¯¯¯  dω 
1 
Syx  2 
2
−∞ 
as  a  whole  when  we  minimize  it,  because  causality  imposes  constraints  on  H (jω) 
that  prevent  it  being  chosen  freely  at  each  ω .  (Because  of  the  Hilbert  transform 
relationship mentioned  earlier, we  could  for  instance  choose  the  real  part  of H (jω) 
freely,  but  then  the  imaginary  part  would  be  totally  determined.)  We  therefore 
have  to  proceed more  carefully. 

(11.56) 

or 

(11.57) 

(11.58) 

Sxx  = Mxx

Note ﬁrst that the expression we obtained for the integrand in (11.56) by completing 
the  square  is  actually not quite  as  general  as we might have made  it.  Since we may 
need to use all the ﬂexibility available to us when we tackle the constrained problem, 
we  should  explore  how  generally  we  can  complete  the  square.  Speciﬁcally,  instead 
of  using  the  real  square  root  √Sxx  of  the  PSD  Sxx ,  we  could  choose  a  complex 
square  root Mxx ,  deﬁned  by  the  requirement  that 
M ∗ 
(jω) = Mxx (jω)Mxx (−jω)  , 
Sxx
xx 
and  correspondingly  rewrite  the  criterion  in  (11.56)  as 
1  Z 
∞  ¯¯¯HMxx  − 
Syx  ¯¯¯  dω  , 
2
M ∗
2π
−∞ 
xx 
which  is  easily  veriﬁed  to  be  the  same  criterion,  although  written  diﬀerently.  The 
quantity Mxx (jω)  is termed a spectral  factor of Sxx (jω) or a modeling ﬁlter  for the 
process x.  The reason  for the  latter name  is that passing (zero-mean) unit-variance 
white noise through a ﬁlter with frequency response Mxx (jω) will produce a process 
with  the  PSD  Sxx (jω),  so  we  can  model  the  process  x  as  being  the  result  of  such 
a  ﬁltering  operation.  Note  that  the  real  square  root  √Sxx (jω)  we  used  earlier  is  a 
special  case  of  a  spectral  factor,  but  others  exist.  In  fact, multiplying √Sxx (jω) by 
an  all-pass  frequency  response  A(jω)  will  yield  a  modeling  ﬁlter: 
A(jω) pSxx (jω) = Mxx (jω)  ,
A(jω)A(−jω) = 1 . 
Conversely,  it  is  easy  to  show  that  the  frequency  response  of  any  modeling  ﬁlter 
can  be  written  as  the  product  of  an  all-pass  frequency  response  and √Sxx (jω). 
It  turns  out  that  under  fairly  mild  conditions  (which  we  shall  not  go  into  here)  a 
PSD is guaranteed to have a spectral factor that is the frequency response of a stable 
and  causal  system,  and whose  inverse  is also  the  frequency  response of a  stable  and 
causal system.  (To simplify how we talk about such factors, we shall adopt an abuse 
of  terminology  that  is  common when  talking  about Fourier  transforms,  referring  to 
the  factor  itself  —  rather  than  the  system  whose  frequency  response  is  this  factor 
—  as  being  stable  and  causal,  with  a  stable  and  causal  inverse.)  For  instance,  if 

(11.59) 

Sxx (jω) = 

ω2  + 9 
ω2  + 4 

, 

(11.60) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

208  Chapter  11 

Wiener  Filtering 

then  the  required  factor  is 

. 

Mxx (jω) = 

jω + 3 
jω + 2 
We shall limit ourselves entirely to Sxx  that have such a spectral factor, and assume 
for  the  rest  of  the  derivation  that  the  Mxx  introduced  in  the  criterion  (11.58)  is 
such  a  factor.  (Keep  in  mind  that  wherever  we  ask  for  a  stable  system  here,  we 
can  actually make  do with  a  system with  a well-deﬁned  frequency  response,  even  if 
it’s not BIBO  stable,  except  that our  results may  then need  to be  interpreted more 
carefully.) 

(11.61) 

With  these  understandings,  it  is  evident  that  the  term  HMxx  in  the  integrand  in 
(11.58) is causal, as it is the cascade of two causal terms.  The other term, Syx/M ∗ ,xx
is  generally  not  causal,  but  we  may  separate  its  causal  part  out,  denoting  the 
transform of its causal part by [Syx/M ∗ ]+ , and the transform of its anti-causal part 
xx
by  [Syx /M ∗ ]
(In  the DT  case,  the  latter would actually denote  the  transform  of 
xx − . 
the  strictly  anti-causal part,  i.e.,  at  times −1  and  earlier;  the  value  at  time  0 would 
be  retained  with  the  causal  part.) 

Now  consider  rewriting  (11.58)  in  the  time  domain,  using  Parseval’s  theorem.  If 
we denote  the  inverse  transform operation by I { · },  then  the  result  is  the  following 
rewriting  of  our  criterion: 
Z 
∞  ¯¯¯I {HMxx } − I {[Syx/M ∗  ]+  − I {[Syx/M ∗  ]− } ¯¯¯  dt 
2
xx
xx
−∞ 
Since  the  term  I {HMxx}  is  causal  (i.e.,  zero  for  negative  time),  the  best  we  can 
do  with  it,  as  far  as  minimizing  this  integral  is  concerned,  is  to  cancel  out  all  of 
In  other  words,  our  best  choice  is 
xx ]+ }. 
/M ∗
I {[Syx

(11.62) 

or 

HMxx 

= [Syx /M ∗  ]+  , 
xx
h  Syx (jω)  i
1 
Mxx (jω)  Mxx (−jω)  + 
Note  that  the  stability  and  causality  of  the  inverse  of Mxx  guarantee  that  this  last 
step  preserves  stability  and  causality,  respectively,  of  the  solution. 

H (jω) = 

(11.63) 

(11.64) 

. 

The  expression  in  (11.64)  is  the  solution  of  the Wiener  ﬁltering  problem  under  the 
causality  constraint.  It  is  also  evident  now  that  the  MMSE  is  larger  than  in  the 
unconstrained  (noncausal)  case  by  the  amount 
1  Z 
∞  ¯¯¯h Syx  i  ¯¯¯  dω  . 
2 
M ∗xx
2π
− 
−∞ 

ΔMMSE = 

(11.65) 

EXAMPLE  11.5 

DT  Prediction 

Although  the  preceding  results  were  developed  for  the  CT  case,  exactly  analogous 
expressions  with  obvious  modiﬁcations  (namely,  using  the  DTFT  instead  of  the 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  11.3 

Causal Wiener  Filtering  209 

CTFT,  with  integrals  from  −π  to  π  rather  than  −∞  to ∞,  etc.)  apply  to  the  DT 
case. 

Consider a process x[n]  that  is  the  result of passing  (zero-mean) white noise of unit 
variance  through  a  (modeling)  ﬁlter  with  frequency  response 
Mxx (ejΩ ) = α0  + α1 e−jΩ  , 

(11.66) 

where  both  α0  and  α1  are  assumed  nonzero.  This  ﬁlter  is  stable  and  causal,  and 
if  α1 < α0 then  the  inverse  is  stable  and  causal  too.  We  assume  this  condition 
| 
|
|
|
holds.  (If  it  doesn’t,  we  can  always  ﬁnd  another  modeling  ﬁlter  for  which  it  does, 
by  multiplying  the  present  ﬁlter  by  an  appropriate  allpass  ﬁlter.) 

Thus 

Suppose we want to do causal one-step prediction for this process, so y [n] = x[n+ 1]. 
Then  Ryx [m] = Rxx [m + 1],  so 
Syx  = ejΩSxx  = ejΩMxxM ∗  . 
xx 
h Syx  i 
M ∗ +xx 
and  so  the  optimum  ﬁlter,  according  to  (11.64),  has  frequency  response 
α1 
H (ejΩ ) = 
α0  + α1 e−jΩ 
The  associated  MMSE  is  evaluated  by  the  expression  in  (11.65),  and  turns  out  to 
2  that  would  have 
be  simply  α2
0  (which  can  be  compared  with  the  value  of  α2
0  + α1
been  obtained  if  we  estimated  x[n + 1]  by  just  its  mean  value,  namely  zero). 

= [ejΩMxx ]+  = α1  , 

(11.69) 

(11.67) 

(11.68) 

. 

11.3.1  Dealing  with  Nonzero Means 

We  have  so  far  considered  the  case  where  both  x  and  y  have  zero  means  (and  the 
practical  consequence  has  been  that  we  haven’t  had  to  worry  about  their  PSDs 
having  impulses  at  the  origin).  If  their means  are nonzero,  then we  can do  a better 
job  of  estimating  y(t)  if we  allow  ourselves  to  adjust  the  estimates produced by  the 
LTI  system,  by  adding  appropriate  constants  (to  make  an  aﬃne  estimator).  For 
this, we  can ﬁrst  consider  the problem  of  estimating  y − µy  from x − µx ,  illustrated 
in  Figure  11.7 

Estimator 

x(t) − µx 

�  h(t), H (jω) 

�  yb(t) − µy  =  estimate 
y(t) − µy  =  target  process 
FIGURE  11.7  Wiener  ﬁltering  with  non-zero  means. 

Denoting  the  transforms  of  the  covariances  Cxx (τ )  and  Cyx (τ )  by  Dxx (jω)  and 
Dyx (jω)  respectively  (these  transforms  are  sometimes  referred  to  as  covariance 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

210  Chapter  11 

Wiener  Filtering 

PSDs),  the  optimal  unconstrained  Wiener  ﬁlter  for  our  task  will  evidently  have  a 
frequency  response  given  by 

H (jω) = 

Dyx (jω)
Dxx (jω) 

. 

(11.70) 

We can  then add µy  to  the output of  this ﬁlter  to get our LMMSE estimate of y(t). 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

12 

Pulse Amplitude Modulation  (PAM), 
Quadrature  Amplitude Modulation 
(QAM) 

12.1  PULSE  AMPLITUDE  MODULATION 

In Chapter  2, we  discussed  the  discrete-time  processing  of  continuous-time  signals, 
and  in  that  context  reviewed  and  discussed  D/C  conversion  for  reconstructing  a 
continuous-time  signal  from  a  discrete-time  sequence.  Another  common  context 
in  which  it  is  useful  and  important  to  generate  a  continuous-time  signal  from  a 
sequence is in communication systems, in which discrete data — for example, digital 
or quantized data — is to be transmitted over a channel in the form of a continuous-
time  signal.  In  this  case,  unlike  in  the  case  of  DT  processing  of  CT  signals,  the 
resulting  continuous-time  signal  will  be  converted  back  to  a  discrete-time  signal  at 
the  receiving  end.  Despite  this  diﬀerence  in  the  two  contexts,  we  will  see  that  the 
same  basic  analysis  applies  to  both. 

As  examples  of  the  communication  of  DT  information  over  CT  channels,  consider 
transmitting  a  binary  sequence  of  1’s  and  0’s  from  one  computer  to  another  over  a 
telephone  line  or  cable,  or  from  a  digital  cell  phone  to  a  base  station  over  a  high-
frequency  electromagnetic  channel.  These  instances  correspond  to  having  analog 
channels that require the transmitted signal to be continuous in time, and to also be 
compatible with  the bandwidth and other constraints of  the channel.  Such  require­
ments  impact  the  choice  of  continuous-time waveform  that  the  discrete  sequence  is 
modulated  onto. 

The translation of a DT signal to a CT signal appropriate  for transmission, and the 
translation  back  to  a  DT  signal  at  the  receiver,  are  both  accomplished  by  devices 
referred  to  as  modems  (modulators/demodulators).  Pulse  Amplitude  Modulation 
(PAM)  underlies  the  operation  of  a  wide  variety  of  modems. 

12.1.1  The  Transmitted  Signal 

The  basic  idea  in  PAM  for  communication  over  a  CT  channel  is  to  transmit  a  se­
quence  of  CT  pulses  of  some  pre-speciﬁed  shape  p(t),  with  the  sequence  of  pulse 
amplitudes  carrying  the  information.  The  associated  baseband  signal  at  the  trans­
mitter (which is then usually modulated onto some carrier to form a bandpass signal 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

211

212  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

before  actual  transmission —  but  we  shall  ignore  this  aspect  for  now)  is  given  by 
x(t) = X 
a[n] p(t − nT ) 
n 

(12.1) 

p(t) 
� 

A 

−T 

− Δ 
2

Δ 
2

T

x(t)  when  a[n]  are  samples  of  bandlimited  signal 
� 

2T 

0 

T 

3T 

� 

t

x(t)  for  a[n]  from  on/oﬀ  signaling 
� 

A 

2T 

0 

T 

3T 

� 

t 

� 

t 

x(t)  for  a[n]  from  antipodal  signaling 
� 

2T 

0 

T 

3T 

� 

t 

x(t)  for  a[n]  from  bipolar  signaling 
� 

2T 

0 

T 

3T 

� 

t 

+A 

−A 

+A 

−A 

FIGURE  12.1  Baseband  signal  at  the  transmitter  in  Pulse  Amplitude  Modulation 
(PAM). 

where  the  numbers  a[n]  are  the  pulse  amplitudes,  and  T  is  the  pulse  repetition 
interval  or  the  inter-symbol  spacing,  so  1/T  is  the  symbol  rate  (or  “baud”  rate). 
An  individual  pulse may  be  conﬁned  to  an  interval  of  length T ,  as  shown  in Figure 
12.1,  or  it  may  extend  over  several  intervals,  as  we  will  see  in  several  examples 
shortly.  The DT signal a[n] may comprise samples of a bandlimited analog message 
(taken  at  the  Nyquist  rate  or  higher,  and  generally  quantized  to  a  speciﬁed  set  of 
levels,  for  instance 32  levels);  or 1 and 0  for on/oﬀ or “unipolar” signaling;  or 1 and 
−1  for  antipodal  or  “polar”  signaling;  or  1,  0  and  −1  for  “bipolar”  signaling;  each 
of  these  possibilities  is  illustrated  in  Figure  12.1. 

The particular pulse shape in Figure 12.1 is historically referred to as an RZ (return­
to-zero)  pulse  when  Δ  < T  and  an  NRZ  (non-return-to-zero)  pulse  when  Δ  =  T . 
These  pulses  would  require  substantial  channel  bandwidth  (of  the  order  of  1/Δ) 
in  order  to  be  transmitted  without  signiﬁcant  distortion,  so  we  may  wish  to  ﬁnd 
alternative  choices  that  use  less  bandwidth,  to  accommodate  the  constraints  of  the 
channel.  Such  considerations  are  important  in  designing  appropriate  pulse  shapes, 
and  we  shall  elaborate  on  them  shortly. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  12.1 

Pulse  Amplitude  Modulation  213 

If  p(t)  is  chosen  such  that  p(0)  =  1  and  p(nT )  =  0  for  n  =  0,  then  we  could 
recover  the  amplitudes  a[n]  from  the  PAM  waveform  x(t)  by  just  sampling  x(t)  at 
times nT , since x(nT ) = a[n] in this case.  However, our interest is in recovering the 
amplitudes from the signal at the receiver, rather than directly from the transmitted 
signal,  so  we  need  to  consider  how  the  communication  channel  aﬀects  x(t).  Our 
ob jective  will  be  to  recover  the  DT  signal  in  as  simple  a  fashion  as  possible,  while 
compensating  for  distortion  and  noise  in  the  channel. 

12.1.2  The  Received  Signal 

When  we  transmit  a  PAM  signal  through  a  channel,  the  characteristics  of  the 
channel  will  aﬀect  our  ability  to  accurately  recover  the  pulse  amplitudes  a[n]  from 
the  received  signal  r(t).  We might  model  r(t)  as 
r(t) = h(t) ∗ x(t) + η(t) 
corresponding to the channel being modeled as LTI with impulse response h(t), and 
channel  noise  being  represented  through  the  additive  noise  signal  η(t).  We  would 
still  typically  try  to  recover  the  pulse  amplitudes  a[n]  from  samples  of  r(t)  —  or 
from  samples  of  an  appropriately  ﬁltered  version  of  r(t) — with  the  samples  taken 
at  intervals  of  T . 

(12.2) 

The  overall  model  is  shown  in  Figure  12.2,  with  f (t)  representing  the  impulse 
response  of  an  LTI  ﬁlter  at  the  receiver.  This  receiver  ﬁlter  will  play  a  key  role  in 
ﬁltering  out  the  part  of  the  noise  that  lies  outside  the  frequency  bands  in  which 
the  signal  information  is  concentrated.  Here,  we  ﬁrst  focus  on  the  noise-free  case 
(for  which  one  would  normally  set  f (t) = δ(t),  corresponding  to  no  ﬁltering  before 
sampling  at  the  receiver  end),  but  for  generality we  shall  take  account  of  the  eﬀect 
of  the  ﬁlter  f (t)  as  well. 

x(t) =  � 
P 
a[n]p(t − nT ) 

h(t)

Noise  η(t) 
�  � 
� + 
r(t) 

f (t) 

� 
b(t) 

Filtering 

Sample  every  T 

� 

Samples  b(nT ) 

FIGURE  12.2  Transmitter,  channel  and  receiver  model  for  a  PAM  system. 

12.1.3  Frequency-Domain  Characterizations 

Denote the CTFT of the pulse p(t) by P (jω), and similarly for the other CT signals 
in  Figure  12.2.  If  the  frequency  response  H (jω)  of  the  channel  is  unity  over  the 
frequency  range  where  P (jω)  is  signiﬁcant,  then  a  single  pulse  p(t)  is  transmitted 
essentially  without  distortion.  In  this  case,  we might  invoke  the  linearity  and  time 
invariance  of  our  channel  model  to  conclude  that  x(t)  in  (12.1)  is  itself  transmit­
ted  essentially  without  distortion,  in  which  case  r(t)  ≈  x(t)  in  the  noise-free  case 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
214  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

X (jω) = 

that  we  are  considering.  However,  this  conclusion  leaves  the  possiblity  that  dis­
tortions  which  are  insigniﬁcant  when  a  single  pulse  is  transmitted  accumulate  in  a 
non-negligible way when  a  succession  of pulses  is  transmitted.  We  should  therefore 
directly  examine  x(t),  r(t),  and  their  corresponding  Fourier  transforms.  The  un­
derstanding  we  obtain  from  this  is  a  prerequisite  for  designing  P (jω)  and  picking 
the  inter-symbol  time  T  for  a  given  channel,  and  also  allows  us  to  determine  the 
inﬂuence  of  the  DT  signal  a[n]  on  the  CT  signals  x(t)  and  r(t). 
To  compute  X (jω),  we  take  the  transform  of  both  sides  of  (12.1): 
a[n] e−jωnT ´ 
³X 
P (jω)
n 
=  A(ejΩ )|Ω=ωT  P (jω) 
where  A(ejΩ )  denotes  the  DTFT  of  the  sequence  a[n].  The  quantity  A(ejΩ )|Ω=ωT 
that appears  in the above expression  is simply a uniform re-scaling of the frequency 
axis  of  the  DTFT;  in  particular,  the  point  Ω  =  π  in  the  DTFT  is  mapped  to  the 
point  ω = π/T  in  the  expression  A(ejΩ )|Ω=ωT . 
The  expression  in  (12.3)  therefore  describes  X (jω)  for  us,  assuming  the  DTFT  of 
the  sequence  a[n]  is  well  deﬁned.  For  example,  if  a[n] = 1  for  all  n,  corresponding 
to  periodic  repetition  of  the  basic  pulse  waveform  p(t),  then  A(ejΩ ) = 2πδ (Ω)  for 
|Ω| ≤ π ,  and  repeats  with  period  2π  outside  this  range.  Hence  X (jω)  comprises  a 
train of  impulses spaced apart by 2π/T ;  the strength of each  impulse  is 2π/T  times 
the  value  of P (jω)  at  the  location  of  the  impulse  (note  that  the  scaling property  of 
impulses  yields  δ(Ω) = δ(ωT ) = (1/T )δ(ω)  for  positive  T ). 

(12.3) 

In the absence of noise,  the received signal r(t) and the signal b(t) that results  from 
ﬁltering  at  the  receiver  are  both  easily  characterized  in  the  frequency  domain: 

R(jω) = H (jω)X (jω)  ,

B (jω) = F (jω)H (jω)X (jω)  . 

(12.4) 

Some  important  constraints  emerge  from  (12.3)  and  (12.4).  Note  ﬁrst  that  for  a 
general  DT  signal  a[n],  necessary  information  about  the  signal  will  be  distributed 
in  its  DTFT  A(ejΩ )  at  frequencies  Ω  throughout  the  interval  |Ω| ≤  π ;  knowing 
A(ejΩ )  only  in  a  smaller  range  |Ω| ≤  Ωa  < π  will  in  general  be  insuﬃcient  to 
allow  reconstruction  of  the  DT  signal.  Now,  setting  Ω = ωT  as  speciﬁed  in  (12.3), 
we  see  that  A(ejωT )  will  contain  necessary  information  about  the  DT  signal  at 
frequencies  ω  that  extend  throughout  the  interval  |ω | ≤  π/T .  Thus,  if  P (jω) =6
0 
for  |ω | ≤  π/T  then  X (jω)  preserves  the  information  in  the  DT  signal;  and  if 
H (jω)P (jω)  6=  0  for  |ω | ≤  π/T  then  R(jω)  preserves  the  information  in  the  DT 
signal;  and  if  F (jω)H (jω)P (jω) =6
0  for  |ω | ≤  π/T  then  B (jω)  preserves  the 
information  in  the  DT  signal. 

The  above  constraints  have  some  design  implications.  A  pulse  for  which  P (jω) 
was  nonzero  only  in  a  strictly  smaller  interval  |ω | ≤ ωp  < π/T  would  cause  loss  of 
information  in  going  from  the DT  signal  to  the PAM  signal x(t),  and would  not  be 
a  suitable  pulse  for  the  chosen  symbol  rate  1/T  (but  could  become  a  suitable  pulse 
if  the  symbol  rate  was  reduced  appropriately,  to  ωp /π  or  less). 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  12.1 

Pulse  Amplitude  Modulation  215 

Similarly,  even  if  the  pulse  was  appropriately  designed  so  that  x(t)  preserved  the 
information  in  the  DT  signal,  if  we  had  a  lowpass  channel  for  which  H (jω)  was 
nonzero  only  in  a  strictly  smaller  interval  |ω | ≤  ωc  <  π/T  (so  ωc  is  the  cutoﬀ 
frequency  of  the  channel),  then  we  would  lose  information  about  the  DT  signal  in 
going  from x(t) to r(t);  the chosen symbol rate 1/T  would be  inappropriate  for this 
channel, and would need to be reduced to ωc/π  in order to preserve the information 
in  the  DT  signal. 

12.1.4 

Inter-Symbol  Interference  at  the  Receiver 

In  the absence of any channel  impairments,  the  signal values can be  recovered  from 
the transmitted pulse trains shown in Figure 12.1 by re-sampling at the times which 
are  integer multiples  of  T .  However,  these  pulses,  while  nicely  time  localized,  have 
inﬁnite  bandwidth.  Since  any  realistic  channel  will  have  a  limited  bandwidth,  one 
eﬀect of a communication channel on a PAM waveform is to “de-localize” or disperse 
the  energy  of  each  pulse  through  low-pass  ﬁltering.  As  a  consequence,  pulses  that 
may not have overlapped (or that overlapped only benignly) at the transmitter may 
overlap  at  the  receiver  in  a  way  that  impedes  the  recovery  of  the  pulse  amplitudes 
from  samples  of  r(t),  i.e.  in  a  way  that  leads  to  inter-symbol  interference  (ISI). 
We  now  make  explicit  what  condition  is  required  in  order  for  ISI  to  be  eliminated 

M-ary  signal 

T 

2T 
2π  = ωs
T 

x(t) 

�  H (jω) 

r(t)
�

3T 

t 

Channel 

Intersymbol Interference 

0 

1 

2 

3 

4 

FIGURE  12.3  Illustration  of  Inter-symbol  Interference  (ISI). 

from  the  ﬁltered  signal  b(t)  at  the  receiver.  When  this  no-ISI  condition  is  met,  we 
will  again  be  able  to  recover  the  DT  signal  by  simply  sampling  b(t).  Based  on  this 
condition,  we  can  identify  the  additional  constraints  that  must  be  satisﬁed  by  the 
pulse shape p(t) and the impulse response f (t) of the ﬁlter (or channel compensator 
or  equalizer)  at  the  receiver  so  as  to  eliminate  or minimize  ISI. 
With x(t) as given in (12.1), and noting that b(t) = f (t) ∗ h(t) ∗ x(t) in the noise-free 
case,  we  can  write 
b(t) = X 
(12.5) 
a[n] g(t − nT ) 
n 
g(t) = f (t) ∗ h(t) ∗ p(t) 
We assume that g(t)  is continuous (i.e., has no discontinuity) at the sampling times 

where 

(12.6) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

216  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

nT .  Our  requirement  for  no  ISI  is  then  that 

g(0) = c ,  and  g(nT ) = 0  for  nonzero  integers  n, 

(12.7) 

where  c  is  some  nonzero  constant.  If  this  condition  is  satisﬁed,  then  if  follows  from 
(12.5)  that  b(nT ) = c.a[n],  and  consequently  the DT  signal  is  exactly  recovered  (to 
within  the  known  scale  factor  c). 

As  an  example,  suppose  that  g(t)  in  (12.6)  is 

g(t) = 

sin ωc t 
ωc t 

, 

with  corresponding  G(jω)  given  by 

G(jω) = 

π 
|ω | < ωc 
ωc 
=  0  otherwise  . 

for 

(12.8) 

(12.9) 

π 
Then  choosing  the  inter-symbol  spacing  to  be  T  = 
,  we  can  avoid  ISI  in  the 
ωc 
received  samples,  since  g(t)  =  1  at  t  =  0  and  is  zero  at  other  integer  multiples  of 
T ,  as  illustrated  in  Figure  12.4. 

a[0] 

a[1] 

π/ω c 

t 

FIGURE 12.4  Illustration of the no-ISI property for PAM when g(0) = 1 and g(t) = 0 
at  other  integer  multiples  of  the  inter-symbol  time  T . 

We  are  thereby  able  to  transmit  at  a  symbol  rate  that  is  twice  the  cutoﬀ  frequency 
of  the  channel.  From  what  was  said  earlier,  in  the  discussion  following  (12.3)  on 
constraints  involving  the  symbol  rate  and  the  channel  cutoﬀ  frequency,  we  cannot 
expect  to  do  better  in  general. 

More  generally,  in  the  next  section  we  translate  the  no-ISI  time-domain  condition 
in  (12.7)  to  one  that  is  useful  in  designing  p(t)  and  f (t)  for  a  given  channel.  The 
approach  is  based  on  the  frequency-domain  translation  of  the  no-ISI  condition, 
leading  to  a  result  that  was  ﬁrst  articulated  by  Nyquist. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

12.2  NYQUIST  PULSES 

Section  12.2 

Nyquist  Pulses  217 

The  frequency domain  interpretation of  the no-ISI  condition of  (12.7) was  explored 
by  Nyquist  in  1924  (and  extended  by  him  in  1928  to  a  statement  of  the  sampling 
theorem —  this  theorem  then waited  almost  20  years  to  be  brought  to  prominence 
by  Gabor  and  Shannon). 

Consider  sampling  g(t)  with  a  periodic  impulse  train: 
g(t) = g(t)  X 
+∞
δ(t − nT )  . 
(12.10) 
b
n=−∞ 
Then  our  requirements  on  g(t)  in  (12.7)  imply  that  gb(t) =  c δ(t),  an  impulse  of 
strength  c,  whose  transform  is  Gb(jω) =  c.  Taking  transforms  of  both  sides  of 
(12.10),  and  utilizing  the  fact  that  multiplication  in  the  time  domain  corresponds 
to  convolution  in  the  frequency  domain,  we  obtain 
T  X 
1  +∞
2π 
Gb(jω) = c = 
(12.11) 
G(jω − jm 
)  . 
T 
m=−∞ 
The  expression  on  the  right  hand  side  of  (12.11)  represents  a  replication  of  G(jω) 
(scaled  by  1/T )  at  every  integer  multiple  of  2π/T  along  the  frequency  axis.  The 
Nyquist requirement is thus that G(jω) and its replications, spaced 2πm/T  apart for 
all  integer m,  add up  to a  constant.  Some  examples of G(jω) = F (jω)H (jω)P (jω) 
that  satisfy  this  condition  are  given  below. 

The  particular  case  of  the  sinc  function  of  (12.8)  and  (12.9)  certainly  satisﬁes  the 
Nyquist  condition  of  (12.11). 

If  we  had  an  ideal  lowpass  channel  H (jω)  with  bandwidth  ωc  or  greater,  then 
choosing p(t) to be the sinc pulse of (12.8) and not doing any ﬁltering at the receiver 
— so F (jω) = 1 — would result in no ISI. However, there are two problems with the 
sinc  characteristic.  First,  the  signal  extends  indeﬁnitely  in  time  in  both  directions. 
Second,  the  sinc  has  a  very  slow  roll-oﬀ  in  time  (as  1/t).  This  slow  roll-oﬀ  in  time 
is coupled to the sharp cut-oﬀ of the transform of the sinc  in the  frequency domain. 
This  is  a  familiar  manifestation  of  time-frequency  duality:  quick  transition  in  one 
domain  means  slow  transition  in  the  other. 

It  is  highly  desirable  in  practice  to  have  pulses  that  taper  oﬀ more  quickly  in  time 
than a  sinc.  One  reason  is  that,  given  the  inevitable  inaccuracies  in  sampling  times 
due  to  timing  jitter,  there will be  some unavoidable  ISI, and  this  ISI will propagate 
for  unacceptably  long  times  if  the  underlying  pulse  shape  decays  too  slowly.  Also, 
a  faster  roll-oﬀ  allows  better  approximation  of  a  two-sided  signal  by  a  one-sided 
signal,  as  would  be  required  for  a  causal  implementation.  The  penalty  for  more 
rapid  pulse  roll-oﬀ  in  time  is  that  the  transition  in  the  frequency  domain  has  to 
be  more  gradual,  necessitating  a  larger  bandwidth  for  a  given  symbol  rate  (or  a 
reduced  symbol  rate  for  a  given  bandwidth). 

The  two  examples  in Figure 12.5 have  smoother  transitions  than  the previous  case, 
and  correspond  to  pulses  that  fall  oﬀ  as  1/t2 .  It  is  evident  that  both  can  be  made 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

218  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

to  satisfy  the  Nyquist  condition  by  appropriate  choice  of  T . 

P(jω)H(jω) 

P(jω)H(jω) 

π/T 

ω 

π/T 

ω

FIGURE  12.5  Two  possible  choices  for  the Fourier  transform  of  pulses  that  decay  in 
time  as  1/t2  and  satisfy  the Nyquist  zero-ISI  condition  for  appropriate  choice  of T . 

Still  smoother  transitions  can be  obtained with  a  family  of  frequency-domain  char­
acteristics  in which there  is a cosine transition  from 1 to 0 over the  frequency range 
π
π
ω 
(1 + β ),  where  β  is  termed  the  roll-oﬀ  parameter.  The 
(1 − β )  to  ω 
= 
= 
T
T
corresponding  formula  for  the  received  and  ﬁltered  pulse  is 

f (t) ∗ h(t) ∗ p(t) 

= 

π
cos  β π
T t 
sin
T t
π
T t  1 − (2β t/T )2 

which  falls  oﬀ  as  1/t3  for  large  t. 

X(t) 

X(ω) 

T 

0 

β=1 

β=0.5 

β=0 

T 

0 

(12.12) 

β = 0
β = 0.5 
β = 1 

−4T 

−3T 

−2T 

−T 

0 
time, t 

T 

2T 

3T 

4T 

−2 π/T 

− π/T 

0 
frequency, ω 

π/T 

2π/T

FIGURE  12.6  Time  and  frequency  characteristics  of  the  family  of  pulses  in  Eq. 
(12.12) 

Once  G(jω)  is  speciﬁed,  knowledge  of  the  channel  characteristic  H (jω)  allows  us 
to  determine  the  corresponding  pulse  transform  P (jω),  if we  ﬁx  F (jω) = 1.  In the 
presence  of  channel  noise  that  corrupts  the  received  signal  r(t),  it  turns  out  that  it 
is  best  to  only  do  part  of  the  pulse  shaping  at  the  transmitter,  with  the  rest  done 
at  the  receiver  prior  to  sampling.  For  instance,  if  the  channel  has  no  distortion 
in  the  passband  (i.e.,  if  H (jω)  =  1  in  the  passband)  and  if  the  noise  intensity  is 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  12.3 

Carrier  Transmission  219 

TABLE 5.4: Selected CCITT International Telephone Line Modem Standards 

Bit Rate 

Symbol Rate 

330 
1,200 
2,400 
1,200 
2,400 
4,800 
9,600 
4,800 
9,600 
14,400 
28,800 

300 
600 
600 
1,200 
1,200 
1,600 
2,400 
2,400 
2,400 
2,400 
3,429 

Modulation 
2FSK 
QPSK 
16QAM 
2FSK 
QPSK 
8PSK 
Fig. 3.15(a) 
QPSK 
16QAM 
128QAM,TCM 
1024QAM,TCM 

CCITT Standard 
V.21 
V.22 
V.22bis 
V.23 
V.26 
V.27 
V.29 
V.32 
V.32ALT 
V.32bis 
V.fast(V.34) 

Copyright © 1999 IEEE. Used with permission.
FIGURE 12.7  From Digital Transmission Engineering  by J.B.Anderson,  IEEE Press 
1999.  The  reference  to  Fig.  3.15  a  is  a  particular  QAM  constellation. 
uniform  in  this  passband,  then  the  optimal  choice  of  pulse  is  P (jω) =  pG(jω), 
assuming  that  G(jω)  is  purely  real,  and  this  is  also  the  optimal  choice  of  receiver 
ﬁlter  F (jω).  We  shall  say  a  little  more  about  this  sort  of  issue  when  we  deal  with 
matched  ﬁltering  in  a  later  chapter. 

12.3  CARRIER  TRANSMISSION 

The  previous  discussion  centered  around  the  design  of  baseband  pulses.  For  trans­
mission  over  phone  lines,  wireless  links,  satellites,  etc.  the  baseband  signal  needs 
to  be  modulated  onto  a  carrier,  i.e.  converted  to  a  passband  signal.  This  also 
opens  opportunities  for  augmentation  of  PAM.  The  table  in  Figure  12.7  shows  the 
evolution of telephone  line digital modem standards.  FSK refers to  frequency-shift­
keying, PSK to phase-shift-keying, and QAM to quadrature amplitude modulation, 
each  of  which  we  describe  in  more  detail  below.  The  indicated  increase  in  symbol 
rate  (or  baud  rate)  and  bit  rates  over  the  years  corresponds  to  improvements  in 
signal  processing,  to  better  modulation  schemes,  to  the  use  of  better  conditioned 
channels,  and  to  more  elaborate  coding  (and  correspondingly  complex  decoding, 
but  now  well  within  real-time  computational  capabilities  of  digital  receivers). 

For  baseband  PAM,  the  transmitted  signal  is  of  the  form  of  equation  (12.1)  i.e. 
x(t) = X 
a[n] p(t − nT ) 
n 
where  p(t)  is  a  lowpass  pulse.  When  this  is  amplitude-modulated  onto  a  carrier, 
the  transmitted  signal  takes  the  form 
s(t) = X 
n 
where  ωc  and  θc  are  the  carrier  frequency  and  phase. 

a[n] p(t − nT ) cos(ωc t + θc ) 

(12.13) 

(12.14) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

220  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

In  the  simplest  form of  equation  (12.14),  speciﬁcally with ωc  and  θc  ﬁxed,  equation 
(12.14)  corresponds  to  using  amplitude  modulation  to  shift  the  frequency  content 
from  baseband  to  a  band  centered  at  the  carrier  frequency  ωc .  However,  since  two 
additional  parameters  have  been  introduced  (i.e.  ωc  and  θc )  this  opens  additional 
possibilities  for  embedding  data  in  s(t).  Speciﬁcally,  in  addition  to  changing  the 
amplitude  in  each  symbol  interval,  we  can  consider  changing  the  carrier  frequency 
and/or  the  phase  in  each  symbol  interval.  These  alternatives  lead  to  frequency-
shift-keying  (FSK)  and  phase-shift-keying  (PSK). 

12.3.1  FSK 

With  frequency  shift  keying  (12.14)  takes  the  form 
s(t) = X 
a[n] p(t − nT ) cos((ω0  + Δn )t + θc ) 
n 
where ω0  is the nominal carrier frequency and Δn  is the shift in the carrier frequency 
in  symbol  interval  n.  In  principle  in  FSK  both  a[n]  and  Δn  can  incorporate  data 
although  it  is  typically  the  case  that  in  FSK  the  amplitude  does  not  change. 

(12.15) 

12.3.2  PSK 

In  phase  shift  keying  (12.14)  takes  the  form 
s(t) = X 
a[n] p(t − nT ) cos(ωc t + θn ) 
n 
In  each  symbol  interval,  information  can  then  be  incorporated  in  both  the  pulse 
amplitude  a[n]  and  the  carrier  phase  θn .  In  what  is  typically  referred  to  as  PSK, 
information  is  only  incorporated  in  the  phase,  i.e.  a[n] = a = constant. 

(12.16) 

For  example,  with 

θn  =

2πbn
M 

;  bn  a  non-negative  integer 

(12.17) 

one of M  symbols can be encoded  in the phase  in each symbol  interval.  For M  = 2, 
θn  = 0  or  π ,  commonly  referred  to  as  binary  PSK  (BPSK). With M  = 4,  θn  takes 
π . 
on  one  of  the  four  values  0,  π 
2 ,  π ,  or  3
2 
To  interpret  PSK  somewhat  diﬀerently  and  as  a  prelude  to  expanding  the  discus­
sion  to  a  further  generalization  (quadrature  amplitude  modulation  or  QAM)  it  is 
convenient  to  express  equation  (12.16)  in  some  alternate  forms.  For  example, 
s(t) = X 
j θn 
p(t − nT )e
Re{ae
n 
s(t) = I (t) cos(ωc t) − Q(t) sin(ωc t) 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

and  equivalently 

(12.18) 

jωc t

} 

(12.19) 

with 

and 

Section  12.3 

Carrier  Transmission  221 

I (t) = X 
ai [n] p(t − nT ) 
n 
Q(t) = X 
aq [n] p(t − nT ) 
n 

ai [n] = a cos(θn ) 
aq [n] = a sin(θn ) 

(12.20) 

(12.21) 

(12.22) 
(12.23) 

Equation  12.19  is  referred  to  as  the  quadrature  form  of  equation  12.16  and  I (t) 
and  Q(t)  are  referred  to  as  the  in-phase  and  quadrature  components.  For  BPSK, 
ai [n] = ±a  and  aq [n] = 0. 
For  PSK  with  θn  in  the  form  of  equation  12.17  and M  = 4,  θn  can  take  on  any  of 
π .  In  the  form  of  equations  12.22  and  12.23  ai [n]  will 
the  four  values  0,  π 
2 ,  π ,  or  3
2 
then  be  either  +a, −a,  or  zero  and  aq [n]  will  be  either  +a, −a,  or  zero.  However, 
clearly  QPSK  can  only  encode  four  symbols  in  the  phase  not  nine,  i.e.  the  various 
possibilities  for  ai [n]  and  aq [n]  are  not  independent.  For  example,  for  M  =  4,  if 
ai [n] = +a  then  aq [n]  must  be  zero  since  ai [n] = +a  implies  that  θn  =  0.  A  con­
venient way  of  looking  at  this  is  through what’s  referred  to  as  an  I -Q  constellation 
as  shown  in  Figure  12.8. 

aq 

+a 

−a 

−a 

+a 

ai 

FIGURE  12.8  I -Q  Constellation  for  QPSK. 

Each  point  in  the  constellation  represents  a  diﬀerent  symbol  that  can  be  encoded, 
and clearly with the constellation of Figure 12.8 one of four symbols can be encoded 
in  each  symbol  interval  (recall  that  for  now,  the  amplitude  a[n]  is  constant.  This 
will  change  when  we  expand  the  discussion  shortly  to  QAM). 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

222  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

aq 

a
+ 
√
2 

a√
− 
2 

a
2√− 

a√
+ 
2 

ai 

FIGURE  12.9  I -Q  Constellation  for  quadrature  phase-shift-keying  (QPSK). 

An  alternative  form  with  four-phase  PSK  is  to  choose 

θn  =

+ 

in which case ai [n] = ±
12.9. 

;  bn  a  non-negative  integer 

π 
2πbn 
4 
4
a√2  and aq [n] = ±  a√2  resulting  in the constellation  in Figure 

(12.24) 

In this case, the amplitude modulation of I (t) and Q(t) (equations 12.20 and 12.21) 
can be done independently.  Modulation with this constellation is commonly referred 
to  as  QPSK  (quadrature  phase-shift  keying). 

In PSK as described above,  a[n] was assumed  constant.  By  incorporating  encoding 
in  both  the  amplitude  a[n]  and  phase  θn  in  equation  12.16  we  are  led  to  a  richer 
form of modulation referred to as quadrature amplitude modulation (QAM). In the 
form  of  equations  (12.19  - 12.21)  we  now  allow  ai [n]  and  aq [n]  to  be  chosen  from  a 
richer  constellation. 

12.3.3  QAM 

The  QAM  constellation  diagram  is  shown  in  Figure  12.10  for  the  case  where  each 
set  of  amplitudes  can  take  the  values  ±a  and  ±3a.  The  16  diﬀerent  combinations 
that  are  available  in  this  case  can  be  used  to  code  4  bits,  as  shown  in  the  ﬁgure. 
This particular constellation  is what  is used  in  the V.32ALT  standard shown  in  the 
table  of  Figure  12.7.  In  this  standard,  the  carrier  frequency  is  1,800  Hz,  and  the 
symbol  frequency  or  baud  rate  (1/T )  is  2,400  Hz.  With  4  bits  per  symbol,  this 
works  out  to  the  indicated  9,600  bits/second.  One  baseband  pulse  shape  p(t)  that 
may  be used  is  the  square  root  of  the  cosine-transition  pulse mentioned  earlier,  say 
with  β  = 0.3.  This  pulse  contains  frequencies  as  high  as  1.3 × 1, 200  =  1, 560  Hz. 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  12.3 

Carrier  Transmission  223 

After modulation of  the 1,800 Hz  carrier,  the  signal occupies  the band  from 240 Hz 
to  3,360  Hz,  which  is  right  in  the  passband  of  the  voice  telephone  channel. 

The two faster modems shown in the table use more elaborate QAM-based schemes. 
The V.32bis  standard  involves  128QAM, which  could  in principle  convey 7 bits per 
symbol,  but  at  the  price  of  greater  sensitivity  to  noise  (because  the  constellation 
points  are  more  tightly  clustered  for  a  given  signal  power).  However,  the  QAM 
in  this  case  is  actually  combined  with  so-called  trel lis-coded  modulation  (TCM), 
which  in  eﬀect  codes  in  some  redundancy  (by  introducing  dependencies  among  the 
modulating  amplitudes),  leading  to  greater  noise  immunity  and  an  eﬀective  rate  of 
6 bits per  symbol  (think of  the TCM as  in  eﬀect  reserving a bit  for  error  checking). 
The  symbol  rate here  is  still  2,400 Hz,  so  the  transmission  is  at  6 × 2, 400 = 14, 400 
bits/second.  Similarly,  the  V.34  standard  involves  1024QAM,  which  could  convey 
10  bits  per  symbol,  although  with  more  noise  sensitivity.  The  combination  with 
TCM  introduces  redundancy  for  error  control,  and  the  resulting  bit  rate  is  28,800 
bits/second  (9  eﬀective  bits  times  a  symbol  frequency  of  3,200  Hz). 

Demodulation  of  Quadrature  Modulated  PAM  signals: 
The  carrier  modulated  signals  in  the  form  of  equations  (12.19  - 12.23)  can  carry 
encoded data in both the I  and Q components I (t) and Q(t).  Therefore in demodu­
lation we must be able to extract these seperately.  This is done through quadrature 
demodulation  as  shown  in  Figure  12.11 

In  both  the  modulation  and  demodulation,  it  is  assumed  that  the  bandwidth  of 
p(t)  is  low  compared  with  the  carrier  frequency  wc  so  that  the  bandwidth  of  I (t) 
and  Q(t)  are  less  than  ωc .  The  input  signal  ri (t)  is 
ri (t) = I (t)cos 2 (ωc t) − Q(t)sin(ωc t)cos(ωc t) 
1 
1 
1
I (t) −
I (t)cos(2ωc t) −  Q(t)sin(2ωc t) 
= 
2 
2 
2

(12.26) 

(12.25) 

Similarly 

rq (t) = I (t)cos(ωc t)sin(ωc t) − Q(t)sin2 (ωc t) 
1 
1 
1
=  I (t)sin(2ωc t) + 
Q(t) −
Q(t)cos(2ωc t) 
2 
2 
2

(12.27) 

(12.28) 

Choosing the cutoﬀ frequency of the lowpass ﬁlters to be greater than the bandwidth 
of  p(t)  (and  therefore  also  greater  than  the  bandwidth  of  I (t)  and  Q(t))  but  low 
enough  to  eliminate  the  components  in  ri (t) and  rq (t) around 2ωc ,  the outputs will 
be  the  quadrature  signals  I (t)  and  Q(t). 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

224  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

aq 
a 

+3 

+1 

1011 

1001 

1010 

1000 

0001 

0000 

1110 

1111 

1100 

1101 

+1 

0100 

ai 
a 

+3 

0110 

0011 

0010 

0101 

0111 

FIGURE  12.10  16 QAM  constellation.  (From 
J.B.  Anderson,  IEEE  Press,  1999,  p.96) 

Digital  Transmission  Engineering  by 

Copyright © 1999 IEEE. Used with permission.

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  12.3 

Carrier  Transmission  225 

cos(ωc t) 

� 

� 

ri (t) 

LPF 

�  I (t)

s(t)
� 

� 

�


sin(ωc t) 

�


� 

rq (t) 

LPF 

�  Q(t)

FIGURE  12.11  Demodulation  scheme  for  a  Quadrature Modulated  PAM  Signal. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

226  Chapter 12 

Pulse Amplitude Modulation (PAM), Quadrature Amplitude Modulation (QAM) 

1.5

1

0.5

0

-0.5

-1

-1.5
-5

1.5

1

0.5

0

-0.5

-1

-1.5
-5

5

10

0

   t
(a)

5

10

0

   t
(b)

Image by MIT OpenCourseWare, adapted from Digital Transmission
Engineering, John Anderson. IEEE Press, 1999.

FIGURE  12.12  (a) PAM  signal with  sinc  pulse.  (b) PAM  signal with  ‘raised  cosine’ 
pulse.  Note much  larger  tails  and  excursions  in narrow band pulse of  (a);  tails may 
not  be  truncated  without  widening  the  bandwidth.  (From  J.B.  Anderson,  Digital 
Transmission  Engineering,  IEEE  Press,  1999.) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

C H A P T E R 

13 

Hypothesis Testing 

INTRODUCTION 

The  topic  of  hypothesis  testing  arises  in  many  contexts  in  signal  processing  and 
communications,  as  well  as  in  medicine,  statistics  and  other  settings  in  which  a 
choice  among  multiple  options  or  hypotheses  is  made  on  the  basis  of  limited  and 
noisy  data.  For  example,  from  tests  on  such  data,  we  may  need  to  determine: 
whether  a  person  does  or  doesn’t  have  a  particular  disease;  whether  or  not  a  par­
ticular  radar  return  indicates  the  presence  of  an  aircraft;  which  of  four  values  was 
transmitted  at  a  given  time  in  a  PAM  system;  and  so  on. 

Hypothesis  testing provides a  framework  for  selecting among M  possible  choices or 
hypotheses  in  some  principled  or  optimal  way.  In  our  discussion  we  will  initially 
focus  on  M  =  2,  i.e.,  on  binary  hypothesis  testing,  to  illustrate  the  key  concepts. 
Though  Section  13.1  introduces  the  discussion  in  the  context  of  binary  pulse  am­
plitude  modulation  in  noise,  the  presentation  and  results  in  Section  13.2  apply  to 
the  general  problem  of  binary  hypothesis  testing.  In  Sections  13.3  and  13.4  we 
explicitly  treat  the  case  of more  than  two  hypotheses. 

13.1  BINARY  PULSE  AMPLITUDE  MODULATION  IN  NOISE 

In  Chapter  12  we  introduced  the  basic  principles  of  pulse  amplitude  modulation, 
and  considered  the  eﬀects  of  pulse  rate,  pulse  shape,  and  channel  and  receiver 
ﬁltering  in  PAM  systems.  We  also  developed  and  discussed  the  condition  for  no 
inter-symbol  interference  (the  no-ISI  condition).  Under  the  assumption  of  no  ISI, 
we  want  to  now  examine  the  eﬀect  of  noise  in  the  channel.  Toward  this  end,  we 
again  consider  the  overall  PAM  model  in  Figure  13.1,  with  the  channel  noise  v(t) 
represented  as  an  additive  term. 

For  now  we  will  assume  no  post-ﬁltering  at  the  receiver,  i.e.,  assume  f (t) =  δ(t). 
In  Chapter  14  we  will  see  how  performance  is  improved  with  the  use  of  ﬁltering  in 
the  receiver.  The basic pulse  p(t)  going  through  the  channel with  impulse  response 
h(t) produces a  signal at  the channel output  that we  represent by s(t) = p(t) ∗ h(t). 
Figure  13.1  thus  reduces  to  the  overall  system  shown  in  Figure  13.2. 

Since we are assuming no ISI, we can carry out our discussion  for just a single pulse 
index  n,  which  we  will  choose  as  n = 0  for  convenience.  We  therefore  focus,  in  the 
system  of  Figure  13.2,  on 

b[0] = r(0) = a[0]s(0) + v(0) . 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(13.1) 

227

228  Chapter  13 

Hypothesis  Testing 

x(t) =  � 
P 
a[n]p(t − nT ) 

h(t)

Channel 

Noise  v(t) 
�
� + 

� 

r(t) 

f (t) 

� 
b(t) 

Filtering 

Sample  every  T 

Samples  b(nT )
�

FIGURE  13.1  Overall  model  of  a  PAM  system. 

P 
a[n]s(t − nT ) 

� 

v(t) 

�  �r(t) 
�⊕ 

�  b[n] = r(nT ) 

Sample  every  T 

FIGURE  13.2  Simpliﬁed  representation  of  a  PAM  system. 

Writing  r(0),  a[0]  and  v(0)  simply  as  r ,  a  and  v  respectively,  and  setting  s(0) =  1 
without  loss  of  generality,  the  relation  of  interest  to  us  is 

r = a + v . 

(13.2) 

Our  broad  ob jective  is  to  determine  the  value  of  a  as  well  as  possible,  given  the 
measured  value  r .  There  are  several  variations  of  this  problem,  depending  on  the 
nature  of  the  transmitted  sequence  a[n]  and  the  characteristics  of  the  noise.  The 
amplitude  a[n]  may  span  a  continuous  range  or  it  may  be  discrete  (e.g.,  binary). 
The  amplitude  may  correspondingly  be  modeled  as  a  random  variable  A  with  a 
known  PDF  or  PMF;  then  a  is  the  speciﬁc  value  that  A  takes  in  a  particular 
outcome  or  instance  of  the  probabilistic  model.  The  contribution  of  the  noise  also 
is  typically  represented  as  a  random  variable  V ,  usually  continuous,  with  v  being 
the  speciﬁc  value  that  it  takes.  We  may  thus  model  the  quantity  r  at  the  receiver 
as  the  observation  of  a  random  variable  R,  with 

R = A + V , 

(13.3) 

and  we  want  to  estimate  the  value  that  the  random  variable  A  takes,  given  that 
R =  r .  Consequently,  we  need  to  add  a  further  processing  step  to  our  receiver,  in 
which  an  estimate  of  A  is  obtained. 

In  the  case  where  the  pulse  amplitude  can  be  only  one  of  two  values,  i.e.,  in  the 
case  of  binary  signaling,  ﬁnding  an  estimate  of  A  reduces  to  deciding,  on  the  basis 
of the observed value r  of R, which of the two possible amplitudes was transmitted. 
Two  common  forms  of  binary  signaling  in  PAM  systems  are  on/oﬀ  signaling  and 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  13.2 

Binary  Hypothesis  Testing  229 

antipodal  signaling.  Letting  a1  and  a0  denote  the  two  possible  amplitudes  (repre­
senting  for  example  a  binary  “one”  or  “zero”),  in  on/oﬀ  signaling  we  have  a0  = 0, 
= −a1  6
= 0. 
= 0,  whereas  in  antipodal  signaling  a0 
a1  6
Thus,  in  binary  signaling,  the  required  post-processing  corresponds  to  deciding  be­
tween  two  alternatives  or  hypotheses,  where  the  available  information may  include 
some prior information along with a measurement r of the single continuous random 
variable R.  (The  extension  to multiple  hypotheses  and multiple measurements will 
be  straightforward  once  the  two-hypothesis  case  is  understood.)  The  hypotheses 
are  listed  below: 

Hypothesis  H0 :  the  transmitted  amplitude  A  takes  the  value  a0 ,  so  R = a0  + V . 
Hypothesis  H1 :  the  transmitted  amplitude  A  takes  the  value  a1 ,  so  R = a1  + V . 
Our  task  now  is  to  decide,  given  the  measurement  R  =  r ,  whether  H0  or  H1  is 
responsible  for  the  measurement.  The  next  section  develops  a  framework  for  this 
sort  of  hypothesis  testing  task. 

13.2  BINARY  HYPOTHESIS  TESTING 

Our  general  binary  hypothesis  testing  task  is  to  decide,  on  the  basis  of  a  mea­
surement  r  of  a  random  variable  R,  which  of  two  hypotheses  —  H0  or  H1  —  is 
responsible for the measurement.  We shall indicate these decisions by ‘H0 ’ and ‘H1 ’ 
respectively (where the quotation marks are  intended to suggest the announcement 
of  a  decision).  An  alternative  notation  is Hb = H0  and Hb = H1  respectively,  where 
Hb denotes  our  estimate  of,  or  decision  on,  the  hypothesis H . 
Suppose H  is modeled as a random quantity, and assume we know the a priori (i.e., 
prior)  probabilities 
P (H0  is  true) = P (H  = H0 ) = P (H0 ) = p0 

(13.4) 

and 

(13.5) 
P (H1  is  true) = P (H  = H1 ) = P (H1 ) = p1 
(where  the  last  two  equalities  in  each  case  simply  deﬁne  streamlined  notation  that 
we  will  be  using).  We  shall  also  require  the  conditional  densities  fR|H (r |H0 )  and 
fR|H (r |H1 )  that  tell  us  how  the  measured  variable  is  distributed  under  the  two 
respective  hypotheses.  These  conditional  densities  in  eﬀect  constitute  the  relevant 
speciﬁcations of how the measured data relates to the two hypotheses.  For example, 
in  the  PAM  setting,  with  R  deﬁned  as  in  (13.3)  and  assuming  V  is  independent  of 
A  under  each  hypothesis,  these  conditional  densities  are  simply 
fR|H (r |H0 ) = fV  (r − a0 )  and  fR|H (r |H1 ) = fV  (r − a1 )  . 
It  is  natural  in many  settings,  as  in  the  case  of  digital  communication  by  PAM,  to 
want  to  minimize  the  probability  of  picking  the  wrong  hypothesis,  i.e.,  to  choose 
with minimum probability of error between the hypotheses, given the measurement 
R  =  r .  We  will,  for  most  of  our  discussion  of  hypothesis  testing,  focus  on  this 
criterion  of  minimum  probability  of  error. 

(13.6) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

230  Chapter  13 

Hypothesis  Testing 

13.2.1  Deciding  with Minimum  Probability  of  Error:  The MAP  Rule 

Consider ﬁrst how one would choose between H0  and H1  with minimum probability 
of  error  in  the  absence  of  any measurement  of  R.  If  we make  the  choice  ‘H0 ’,  then 
we  make  an  error  precisely  when  H0  does  not  hold,  so  the  probability  of  error 
with  this  choice  is  1 −  P (H0 ) = 1 −  p0 .  Similarly,  if  we  chose  ‘H1 ’,  then  the 
probability  of  error  is  1 − P (H1 ) = 1 − p1  = p0 .  Thus,  for minimum  probability  of 
error,  we  should  decide  in  favor  of  whichever  hypothesis  has maximum  probability 
—  an  intuitively  reasonable  conclusion.  (The  preceding  reasoning  extends  in  the 
same  way  to  choosing  one  from  among  many  hypotheses,  and  leads  to  the  same 
conclusion.) 

What changes when we aim to choose between H0  and H1  with minimum probabil­
ity  of  error,  knowing  that  R =  r?  The  same  reasoning  applies  as  in  the  preceding 
paragraph,  except  that  all  probabilities  now  need  to  be  conditioned  on  the  mea­
surement  R  =  r .  We  conclude  that  to  minimize  the  conditional  probability  of 
error,  P (error R  =  r),  we  need  to  decide  in  favor  of  whichever  hypothesis  has 
|
maximum  conditional  probability,  conditioned  on  the  measurement  R  =  r .  (If 
there  were  several  random  variables  for  which  we  had  measurements,  rather  than 
just  the  single  random  variable  R,  we  would  simply  condition  on  all  the  available 
measurements.)  Thus,  if  P (H1 R  =  r)  > P (H0 R  =  r),  we  decide  ‘H1 ’,  and  if 
|
|
P (H1 R = r) < P (H0 R = r),  we  decide  ‘H0 ’.  This  may  be  compactly  written  as 
|
|

P (H1 R = r) 
|

‘H1 ’ 
> 
< 
‘H0 ’ 

P (H0 R = r)  . 
|

(13.7) 

(If the two conditional probabilities happen to be equal, we get the same conditional 
probability of error whether we choose ‘H0 ’ or ‘H1 ’.)  The corresponding conditional 
probability  of  error  is 

P (error|R = r) = min{1 − P (H0 |R = r), 1 − P (H1 |R = r)}  . 

(13.8) 

The  overall  probability  of  error,  Pe ,  associated  with  the  use  of  the  above  decision 
rule  (but  before  knowing  what  speciﬁc  value  of  R  is  measured)  is  obtained  by 
averaging  the  conditional  probability  of  error  in  (13.8)  over  all  possible  values  of  r 
that  might  be  measured,  using  the  PDF  fR (r)  as  a  weighting  function.  We  shall 
study  Pe  in  more  detail  shortly. 
The  conditional  probabilities  P (H0 R  =  r)  and  P (H1 R  =  r)  that  appear  in  the 
|
|
expression  (13.7)  are  referred  to  as  the  a  posteriori  or  posterior  probabilities  of  the 
hypotheses,  to distinguish  them  from  the a  priori or prior probabilities, P (H0 ) and 
P (H1 ).  The  decision  rule  in  (13.7)  is  accordingly  referred  to  as  the  maximum  a 
posteriori  probability  rule,  usually  abbreviated  as  the  “MAP”  rule. 

To  actually  evaluate  the  posterior  probabilities  in  (13.7),  we  use  Bayes’  rule  to 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.2 

Binary  Hypothesis  Testing  231 

rewrite  them  in  terms  of  known  quantities,  so  the  decision  rule  becomes 

‘H1 ’ 
p1 fR|H (r H1 )  > p0 fR|H (r H0 )
|
|
< 
fR (r) 
fR (r) 
‘H0 ’ 

, 

(13.9) 

under the reasonable assumption that fR (r) > 0,  i.e.,  that the PDF of R  is positive 
at the value r  that was actually measured.  (In any case, we only need to specify our 
decision  rule  at  values  of  r  for  which  fR (r) > 0,  because  the  choices made  at  other 
values of r  do not aﬀect the overall probability of error, Pe .)  Since the denominator 
is  the  same  and  positive  on  both  sides  of  the  above  expression,  we  may  further 
simplify  it  to 

(13.10) 

p1 fR|H (r |H1 ) 

p0 fR|H (r |H0 )  . 

‘H1 ’ 
> 
<
‘H0 ’ 
This  now  provides  us  with  an  easily  visualized  and  implemented  decision  rule.  We 
ﬁrst  use  the  prior  probabilities  pi  =  P (Hi )  to  scale  the  PDFs  fR|H (r |Hi )  that 
describe how  the measured  quantity R  is distributed  under  each  of  the hypotheses. 
We  then  decide  in  favor  of  the  hypothesis  associated with whichever  scaled PDF  is 
largest at the measured value r .  (The preceding description also applies to choosing 
with minimum probability of error among multiple hypotheses, rather than just two, 
and  given  measurements  of  several  associated  random  variables,  rather  than  just 
one —  the  reasoning  is  identical.) 

13.2.2  Understanding  Pe :  False  Alarm, Miss  and  Detection 

The  sample  space  that  is  relevant  to  evaluating  a  decision  rule  consists  of  the 
following  four  mutually  exclusive  and  collectively  exhaustive  possibilities:  Hi  is 
true  and  we  declare  ‘Hj ’,  i, j  = 1, 2.  Of  the  four  possible  outcomes,  the  two  that 
represent  errors  are  (H0 , ‘H1 ’)  and  (H1 , ‘H0 ’).  Therefore,  the  probability  of  error 
Pe  — averaged over all possible values of  the measured  random variable —  is given 
by 

Pe  = P (H0 , ‘H1 ’) + P (H1 , ‘H0 ’) 
= p0P (‘H1 ’|H0 ) + p1P (‘H0 ’|H1 )  . 
The conditional probability P (‘H1 ’ H0 )  is referred to as  the conditional probability 
|
of  a  false  alarm,  and  denoted  by  PF A .  The  conditional  probability  P (‘H0 ’ H1 )
|
is  referred  to  as  the  conditional  probability  of  a  miss,  and  denoted  by  PM .  The 
word  “conditional”  is  usually  omitted  from  these  terms  in  normal  use,  but  it  is 
important  to keep  in mind  that  the probability  of  a  false  alarm  and  the probability 
of  a  miss  are  deﬁned  as  conditional  probabilities,  and  are  furthermore  conditioned 
on  diﬀerent  events. 

(13.11) 

The  preceding  terminology  is  historically motivated  by  the  radar  context,  in which 
H1  represents  the  presence  of  a  target  and  H0  the  absence  of  a  target.  A  false 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

232  Chapter  13 

Hypothesis  Testing 

alarm  then  occurs  if  you  declare  that  a  target  is  present when  it  actually  isn’t,  and 
a  miss  occurs  if  you  declare  that  a  target  is  absent  when  it  actually  isn’t.  We  will 
also  make  reference  to  the  conditional  probability  of  detection, 

PD  = P (‘H1 ’|H1 )  . 
In  the  radar  context,  this  is  the  probability  of  declaring  a  target  is  present when  it 
is actually present.  As with PF A  and PM , the word “conditional” is usually omitted 
in normal use,  but  it  is  important  to keep  in mind  that  the probability  of detection 
is  a  conditional  probability. 

(13.12) 

Expressing  the  probability  of  error  in  terms  of  PF A  and  PM ,  (13.11)  becomes 

Also  note  that 

or 

Pe  = p0PF A  + p1PM  . 

P (‘H0 ’ H1 ) + P (‘H1 ’ H1 ) = 1 
|
|

(13.13) 

(13.14) 

(13.15) 

PM  = 1 − PD  . 
To  explicitly  relate  PF A  and  PM  to  whatever  the  corresponding  decision  rule  is,  it 
is  helpful  to  introduce  the  notion  of  a  decision  region  in  measurement  space.  In 
the  case  of  a  decision  rule  based  on  measurement  of  a  single  random  variable  R, 
specifying  the  decision  rule  corresponds  to  choosing  a  range  of  values  D1  on  the 
real line such that, when the measured value r of R falls in D1 , we declare ‘H1 ’, and 
when  r  falls  outside D1  —  a  region  that  we  shall  denote  by D0  —  then  we  declare 
‘H0 ’.  This  is  illustrated  in  Figure  13.3,  for  some  arbitrary  choice  of  D1 .  (There  is 
a  direct  generalization  of  this  notion  to  the  case  where  multiple  random  variables 
are measured.) 

f(r|H 
1) 

f(r|H 
0  ) 

D 
1 

r 

FIGURE  13.3  Decision  regions.  The  choice  of  D1  marked  here  is  arbitrary,  not  the 
optimal  choice  for minimum  probability  of  error. 

With  the  preceding  deﬁnitions,  we  can  write 
Z 
D1 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

PF A  = 

fR|H (r |H0 )dr 

(13.16) 

Section  13.2 

Binary  Hypothesis  Testing  233 

and 

PM  = Z 
D0 

fR|H (r |H1 )dr  . 

13.2.3  The  Likelihood  Ratio  Test 

Rewriting  (13.10),  we  can  state  the  minimum-Pe  decision  rule  in  the  form 

or


Λ(r) = 

fR|H (r |H1 ) 
fR|H (r |H0 ) 

‘H1 ’ 
> 
< 
‘H0 ’ 

p0 
p1 

Λ(r) 

‘H1 ’

>

< 
‘H0 ’ 

η , 	

(13.17) 

(13.18) 

(13.19) 

where  Λ(r)  is  referred  to  as  the  likelihood  ratio,  and  η  is  referred  to  as  the  thresh­
old.  This  particular  way  of  writing  our  decision  rule  is  of  interest  because  other 
formulations  of  the  binary  hypothesis  testing  problem  —  with  criteria  other  than 
minimization  of  Pe  —  also  often  lead  to  a  decision  rule  that  involves  comparing 
the  likelihood  ratio  with  a  threshold.  The  only  diﬀerence  is  that  the  threshold  is 
picked  diﬀerently  in  these  other  formulations.  We  describe  two  of  these  alternate 
formulations  —  the  Neyman-Pearson  approach,  and  minimum  risk  decisions —  in 
later  sections  of  this  chapter. 

13.2.4  Other  Scenarios 

While  the  above  discussion  of  binary  hypothesis  testing was  introduced  in  the  con­
text of binary PAM, it applies in many other scenarios.  For example,  in the medical 
literature,  clinical  tests  are  described  using  a  hypothesis  testing  framework  simi­
lar  to  that  used  here  for  communication  and  signal  detection  problems,  with  H0 
generally  denoting  the  absence  of  a  medical  condition  and  H1  its  presence.  The 
terminology  in  the  medical  context  is  slightly  diﬀerent,  but  still  suggestive  of  the 
intent,  as  the  following  examples  show: 

•	 PD  is  the  sensitivity  of  the  clinical  test. 
•	 P (‘H1 ’|H0 )  is the probability of a  false positive (rather than of a  false alarm). 
•	 1 − PF A  is  the  speciﬁcity  of  the  test. 
•	 P (H1 )  is  the  prevalence  of  the  condition  that  the  test  is  aimed  at. 
•	 P (H1  |‘H1 ’)  is the positive predictive value of the test, and P (H0  | ‘H0 ’)  is the 
negative  predictive  value. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

234  Chapter  13 

Hypothesis  Testing 

Some easy exploration using Bayes’ rule and the above terminology will  lead you to 
recognize  how  small  the  positive  predictive  value  of  a  test  can  be  if  the  prevalence 
of  the  targeted  medical  condition  is  low,  even  if  the  test  is  highly  sensitive  and 
speciﬁc. 

Another important context for binary hypothesis testing is in target detection, such 
as  aircraft  detection  and  tracking,  in  which  a  radar  pulse  is  transmitted  and  the 
decision on the presence or absence of an aircraft is based on the presence or absence 
of  reﬂected  energy. 

13.2.5  Neyman-Pearson  Detection  and  Receiver  Operating  Characteristics 

A  diﬃculty  with  using  the  minimization  of  Pe  as  the  decision  criterion  in  many  of 
these  other  contexts  is  that  it  relies  heavily  on  knowing  the  a  priori  probabilities 
p0  and  p1 ,  and  in  many  situations  there  is  little  basis  for  coming  up  with  these 
numbers.  One  alternative  that  often  makes  sense  is  to  maximize  the  probability 
of  detection  PD ,  while  keeping  PF A  below  some  speciﬁed  tolerable  level.  These 
conditional  probabilities  are  determined  by  the  measurement  models  under  the 
diﬀerent hypotheses, and by the decision rule, but not by the probabilities governing 
the  selection  of  hypotheses.  Such  a  formulation  of  the  hypothesis  testing  problem 
again  leads  to  a  decision  rule  that  involves  comparing  the  likelihood  ratio  with  a 
threshold;  the  only  diﬀerence  now  is  that  the  threshold  is  picked  diﬀerently  in  this 
formulation.  This  approach  is  referred  to  as  Neyman-Pearson  detection,  and  is 
elaborated  on  below. 

fR|H (r |H1 )dr  , 

Consider  a  context  in  which  we  want  to maximize  the  probability  of  detection, 
Z 
PD  = P (‘H1 ’|H1 ) = 
D1 
while  keeping  the  probability  of  false  alarm, 
Z 
PF A  = P (‘H1 ’|H0 ) = 
fR|H (r |H0 )dr  , 
D1 
below  a  pre-speciﬁed  level.  (Both  integrals  are  over  the  decision  region  D1 ,  and 
augmenting D1  by  adding more  of  the  real  axis  to  it  will  not  decrease  either  prob­
ability.)  As  we  show  shortly,  we  can  achieve  our  ob jective  by  picking  the  decision 
region D1  to  comprise  those  values  of  r  for which  the  likelihood  ratio  Λ(r)  exceeds 
a  certain  threshold  η ,  so 

(13.20) 

(13.21) 

Λ(r) = 

‘H1 ’ 
fR|H (r |H1 )  > 
< 
fR|H (r |H0 )
0 ’ 
‘H

η . 

(13.22) 

The  threshold  η  is  picked  to  provide  the  largest  possible  PD  while  ensuring  that 
PF A  is  not  larger  than  the  pre-speciﬁed  level.  The  smaller  the  η ,  the  larger  the 
decision  region  D1  and  the  value  of  PD  become,  but  the  larger  PF A  grows  as  well, 
so  one  would  pick  the  smallest  η  that  is  consistent  with  the  given  bound  on  PF A . 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.2 

Binary  Hypothesis  Testing  235 

To  understand  why  the  decision  rule  in  this  setting  takes  the  form  of  (13.22),  note 
that our ob jective is to include in D1  values of r  that contribute as much as possible 
to  the  integral  that  deﬁnes PD ,  and  as  little  as  possible  to  the  integral  that  deﬁnes 
PF A .  If  we  start  with  a  high  value  of  the  threshold  η ,  we  will  be  including  in 
D1  those  r  for  which  Λ(r)  is  large,  and  therefore  where  the  contribution  to  PD  is 
relatively  large  compared  to  the  contribution  to  PF A .  Moving  η  lower,  we  increase 
both PD  and PF A , but the rate of increase of PD  drops, while the rate of increase of 
PF A  rises.  These increases in PD  and PF A  may not be continuous in η .  (Reducing η 
from  inﬁnitesimally  above  some  value  η  to  inﬁnitesimally  below  this  value will  give 
rise  to  a  ﬁnite  upward  jump  in  both  PD  and  PF A  if  fR|H (r |H1 ) =  η fR|H (r |H0 ) 
throughout  some  interval  of  r  where  both  these  PDFs  are  positive.)  Typically, 
though,  the variation of PD  and PF A  with η  is  indeed continuous,  so as η  is  lowered 
we  reach  a  point  where  the  speciﬁed  bound  on  PF A  is  attained,  or  PD  =  1 is 
reached.  This  is  the  value  of  η  used  in  the  Neyman-Pearson  test.  (In  the  rare 
situation  where  PF A  jumps  discontinuously  from  a  value  below  its  tolerable  level 
to  one  above  its  tolerable  level  as  η  is  lowered  through  some  value  η ,  it  turns  out 
that  a  randomized  decision  rule  allows  one  to  come  right  up  to  the  tolerable  PF A 
level,  and  !  thereby  maximize  PD .  A  case  like  this  is  explored  in  a  problem  at  the 
end  of  this  chapter.) 

The  following  argument  shows  in  a  little  more  detail,  though  still  informally,  why 
the Neyman-Pearson  criterion  is  equivalent  to  a  likeliood  ratio  test.  If  the  decision 
region D1  is optimal  for the Neyman-Pearson criterion,  then any change  in D1  that 
keeps  PF A  the  same  cannot  lead  to  an  improvement  in  PD .  So  suppose  we  take  a 
inﬁnitesimal  segment of width dr  at a point r  in  the optimal D1  region and convert 
it  to  be  part  of  D0 .  In  order  to  keep  PF A  unchanged,  we  must  correspondingly 
take  an  inﬁnitesimal  segment  of  width  dr ′  at  an  arbitrary  point  r ′  in  the  optimal 
D0  region,  and  convert  it  to  be  a  part  of D1 . 

f(r|H 
1) 

f(r|H 
0  ) 

dr 

dr’ 

r 

D 
1 

FIGURE  13.4  Illustrating  the  construction  used  in  deriving  the  likelihood  ratio  test 
for  the  Neyman-Pearson  criterion. 

The  requirement  that  PF A  be  unchanged  then  imposes  the  condition 

fR|H (r ′ |H0 ) dr ′  = fR|H (r |H0 ) dr  , 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(13.23) 

236  Chapter  13 

Hypothesis  Testing 

while  the  requirement  that  the  new  PD  not  be  larger  than  the  old  implies  that 
fR|H (r ′ |H1 ) dr ′  ≤ fR|H (r |H1 ) dr  . 
Combining  (13.23)  and  (13.24),  we  ﬁnd 
Λ(r ′ ) ≤ Λ(r)  . 
What (13.25) shows is that the likelihood ratio cannot be less inside D1  than it is in 
D0 .  We  can  therefore  conclude  that  the  optimum  solution  to  the Neyman-Pearson 
formulation  is  in  fact  based  on  a  threshold  test  on  the  likelihood  ratio: 

(13.25) 

(13.24) 

Λ(r) = 

fR|H (r |H1 ) 
fR|H (r |H0 ) 

‘H1 ’ 
> 
< 
‘H0 ’ 

η  , 

(13.26) 

where  the  threshold  η  is  picked  to  obtain  the  largest  possible  PD  while  ensuring 
that  PF A  is  not  larger  than  the  pre-speciﬁed  bound. 
The above derivation has made various implicit assumptions.  However, our purpose 
is  only  to  convey  the  essence  of  how  one  arrives  at  a  likelihood  ratio  test  in  this 
case. 

Receiver  Operating  Characteristic. 
In  considering  which  value  of  PF A  to 
choose  as  a  bound  in  the Neyman-Pearson  test,  it  is  often  useful  to  look  at  a  curve 
of  PD  versus  PF A  as  the  parameter  η  is  varied.  This  is  referred  to  as  the  Receiver 
Operating  Characteristic  (ROC).  More  generally,  such  an  ROC  can  be  deﬁned 
for  any  decision  rule  that  causes  PD  to  be  uniquely  ﬁxed,  once  PF A  is  speciﬁed. 
The  ROC  can  be  used  to  identify  whether,  for  instance,  modifying  the  variable 
parameters  in  a  given  test  to  permit  a  slightly  higher PF A  results  in  a  signiﬁcantly 
higher  PD .  The  ROC  can  also  be  used  to  compare  diﬀerent  tests. 

EXAMPLE  13.1 

Detection  and  ROC  for  Signal  in  Gaussian  Noise 

Consider  a  scenario  in  which  a  radar  pulse  is  emitted  from  a  ground  station.  If 
an  aircraft  is  located  in  the  propagation  path,  a  reﬂected  pulse  will  travel  back 
towards  the  radar  station.  We  assume  that  the  received  signal  will  then  consist  of 
noise  alone  if  no  aircraft  is  present,  and  noise  plus  the  reﬂected  pulse  if  an  aircraft 
is present.  The processing  of  the  received  signal  results  in  a number  that we model 
as the realization of a random variable R.  If an aircraft is not present, then R = W , 
where  W  is  a  random  variable  denoting  the  result  of  processing  just  the  noise.  If 
an  aircraft  is  present,  then  R  =  s + W ,  where  the  constant  s  is  due  to  processing 
of  the  reﬂected  pulse,  and  is  assumed  here  to  be  a  known  value.  We  thus  have  the 
following  two  hypotheses: 

H0  :  R = W 
H1  :  R = s + W . 

(13.27) 
(13.28) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  13.2 

Binary  Hypothesis  Testing  237 

Assume  that  the  additive  noise  term W  is Gaussian  with  zero mean  and  unit  vari­
ance,  i.e., 

1
fW (w) =  √
2π

2
e−w /2 . 

(13.29) 

Consequently, 

+

(13.30) 

(13.31) 

e−r 2 /2 

r2 i
2 

e−(r−s)2 /2  . 

1 
fR|H (r |H0 ) =  √2π
1
fR|H (r |H1 ) =  √
2π
The  likelihood  ratio  as  deﬁned  in  (13.18)  is  then 
h (r − s)2 
− 
Λ(r) = exp
2
h
s2 i
= exp sr − 
. 
2 
For  detection  with  minimum  probability  of  error,  the  decision  rule  corresponds  to 
evaluating  this  likelihood  ratio  at  the  received  value  r ,  and  comparing  the  result 
against  the  threshold  p0 /p1 ,  as  stated  in  (13.18): 
s2 i 
exp sr −h
2 
It  is  interesting  and  important  to  note  that,  for  this  case,  the  threshold  test  on 
the  likelihood  ratio  can  be  rewritten  as  a  threshold  test  on  the  received  value  r . 
Speciﬁcally,  (13.33)  can  equivalently  be  expressed  as 
s2 i
2 

‘H1 ’ 
> 
<
‘H0 ’ 

[sr − 

η = 

p0 
p1 

‘H1 ’ 
>
< 
‘H0 ’ 

ln η , 

(13.34) 

(13.32) 

(13.33) 

or,  if  s > 0, 

r 

‘H1 ’ 
>  1 h s2 
i 
+ ln η = γ , 
< s  2 
‘H0 ’ 
where  γ  denotes  the  threshold  on  r .  (If  s <  0,  the  inequalities  in  (13.35)  are 
simply  reversed.)  For  example,  if  both  hypotheses  are  equally  likely  a  priori,  so 
that  p0  = p1 ,  then  ln η  = 0  and  the  decision  rule  for  minimum  probability  of  error 
when  s > 0  is  simply 

(13.35) 

r 

‘H1 ’ 
> s 
<  2 
‘H0 ’ 

= γ . 

(13.36) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

238  Chapter  13 

Hypothesis  Testing 

f(r|H 
0  ) 

f(r|H
1) 

γ 

s

r 

FIGURE  13.5  Threshold  γ  on  measured  value  r . 

The  situation  is  represented  in  Figure  13.5.


The  receiver  operating  characteristic  displays  PD  versus  PF A  as  η  is  varied,  and  is

sketched  in  Figure  13.6.


PD 

1.0 

.5 

0.0 

0.0 

.5 

1.0  PFA 

FIGURE  13.6  Receiver  operating  characteristic. 

In  a  more  general  setting  than  the  Gaussian  case  in  Example  13.1,  a  threshold 
test  on  the  likelihood  ratio  would  not  simply  translate  to  a  threshold  test  on  the 
measurement  r .  Nevertheless,  we  could  still  decide  to  use  a  simple  threshold  test 
on  r  as  our  decision  rule,  and  then  generate  and  evaluate  the  associated  receiver 
operating  characteristic. 

13.3  MINIMUM  RISK  DECISIONS 

This section brieﬂy describes a decision criterion, called minimum risk, that includes 
minimum  probability  of  error  as  a  special  case,  and  that  in  the  binary  case  again 
leads to a likelihood ratio test.  We describe it for the general case of M  hypotheses. 

Let  the  available  measurement  be  the  value  r  of  the  random  variable  R  (the  same 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.3 

Minimum  Risk  Decisions  239 

development  holds  if we  have measurements  of  several  random  variables).  Suppose 
we  associate  a  cost  cij  with  each  combination  of  model  Hj  and  decision  ‘Hi ’  for 
0 ≤ i, j  ≤ M  − 1,  reﬂecting  the  costs  of  actions  and  consequences  that  follow  from 
this  combination  of  model  and  decision.  Our  ob jective  now  is  to  pick  whichever 
decision  has minimum  expected  cost,  or minimum  “risk”,  given  the measurement. 

The  expected  cost  of  deciding  ‘Hi ’,  conditioned  on  R = r ,  is  given  by 
E [Cost R = r, ‘Hi ’] =  X 
cij P (Hj  R = r, ‘Hi ’) =  X 
M −1
M −1
|
|
j=0 
j=0 
where  the  last  equality  is  a  consequence  of  the  fact  that,  given  the  received  mea­
surement  R = r ,  the  output  of  the  decision  rule  conveys  no  additional  information 
about  which  hypothesis  actually  holds.  The  next  step  is  to  compare  these  condi­
tional  expected  costs  for  all  i,  and  decide  in  favor  of  the  hypothesis with minimum 
conditional  expected  cost.  Specifying  our  decision  for  each  possible  r ,  we  obtain 
the  decision  rule  that minimizes  the  overall  expected  cost  or  risk. 

cij P (Hj  R = r)  ,  (13.37) 
|

[It is in this setting that hypothesis testing comes closest to the estimation problems 
for  continuous  random  variables  that  we  considered  in  our  chapter  on  minimum 
mean-square-error  estimation.  We  noted  there  that  a  variety  of  such  estimation 
problems  can  be  formulated  in  terms  of  minimizing  an  expected  cost  function. 
Establishing an estimate for a random variable is like carrying out a hypothesis test 
for  a  continuum  of  numerically  speciﬁed  hypotheses  (rather  than  just  M  general 
hypotheses),  with  a  cost  function  that  penalizes  some  measure  of  the  numerical 
distance  between  the  actual  hypothesis  and  the  one  we  decide  on.] 

Note that  if cii  = 0  for all i and  if cij  = 1  for j  = i,  so we penalize all errors equally, 
then  the  conditional  expected  cost  in  (13.37)  becomes 
E [Cost R = r, ‘Hi ’] = X 
P (Hj  r) = 1 − P (Hi r)  . 
|
|
|
j=i 
This  conditional  expected  cost  is  thus  precisely  the  conditional  probability  of  error 
associated with deciding  ‘Hi ’,  conditioned on R = r .  The  right  side of  the equation 
then  shows  that  to minimize  this  conditional  probability  of  error  we  should  decide 
in  favor  of  the  hypothesis  with  largest  conditional  probability.  In  other  words, 
with  this  choice  of  costs,  the  risk  (when  the  expectation  is  taken  over  all  possible 
values  of  r)  is  exactly  the  probability  of  error  Pe ,  and  the  optimum  decision  rule 
for  minimizing  this  criterion  is  again  seen  to  be  the MAP  rule. 

(13.38) 

Using Bayes’ rule in (13.37) and noting that fR (r) — assumed positive — is common 
to all the quantities  involved  in our comparison, we see that an equivalent but more 
directly  implementable  procedure  is  to  pick  the  hypothesis  for  which 
M −1X 
j=0 
is  minimum.  In  the  case  of  two  hypotheses,  and  assuming  c01  > c11 ,  it  is  easy  to 

cij f (r |Hj )P (Hj ) 

(13.39) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

6
6
240  Chapter  13 

Hypothesis  Testing 

see  that  the  decision  rule  based  on  (13.39)  can  be  rewritten  as 

Λ(r) = 

‘H1 ’ 
f (r |H1 )  > P (H0 )(c10  − c00 )
< 
P (H1 )(c01  − c11 ) 
f (r |H0 )
0 ’ 
‘H

= η , 

(13.40) 

where  Λ(r)  denotes  the  likelihood  ratio,  and  η  is  the  threshold.  We  have  therefore 
again  arrived  at  a  decision  rule  that  involves  comparing  a  likelihood  ratio  with  a 
threshold.  If  cii  =  0  for  i  = 0, 1  and  if  cij  =  1  for  j  =  i,  then  we  obtain  the 
threshold  associated  with  the MAP  decision  rule  for minimum  Pe ,  as  expected. 
The  trouble  with  the  above  minimum  risk  approach  to  classiﬁcation,  and  with  the 
minimum error probability  formulation that we have examined a  few times already, 
is  the  requirement  that  the  prior  probabilities  P (Hi )  be  known. 
It  is  often  unrealistic  to  assume  that  prior  probabilities  are  known,  so  we  are  led 
to  consider  alternative  criteria.  Most  important  among  these  alternatives  is  the 
Neyman-Pearson  approach  treated  earlier,  where  the  decision  is  based  on  the  con­
ditional probabilities PD  and PF A ,  thereby avoiding the need for prior probabilities 
on  the  hypotheses. 

13.4  HYPOTHESIS  TESTING  IN  CODED  DIGITAL  COMMUNICATION 

In  our  discussion  of  PAM  earlier  in  this  chapter,  we  considered  binary  hypothesis 
testing  on  a  single  received  pulse.  In modern  communication  systems,  an  alphabet 
of  symbols  may  be  transmitted,  with  each  symbol  encoded  into  a  binary  sequence 
of  “ones”  and  “zeroes”.  Consequently,  in  addition  to  making  a  binary  decision  on 
each received pulse, we may need to further decode a string of bits to make our best 
judgement of  the  transmitted  symbol,  and perhaps yet  further processing  to decide 
on the sequence of symbols that constitutes the entire message.  It would in principle 
be better  to  take all  the  raw measurements and  then make optimal decisions about 
the  entire  sequence  of  symbols  that  was  transmitted,  but  this  would  be  a  hugely 
more  complex  task.  In  practice,  therefore,  the  task  is  commonly  broken  down  into 
three  stages,  as  here,  with  locally  optimal  decisions  made  at  the  single-pulse  level 
to  decode  sequences  of  “ones”  and  “zeros”,  then  further  decisions  made  to  decode 
at  the  symbol  level,  and  still  further  decisions  made  at  the  symbol  sequence  level. 
In  this  section  we  illustrate  the  second  of  these  decoding  stages. 

For  concreteness,  we  center  our  discussion  on  the  system  in  Figure  13.7.  Suppose 
the  transmitter  randomly  selects  for  transmission  one  of  four  possible  symbols, 
which  we  label  A,  B ,  C  and  D .  The  probabilities  with  which  these  are  selected 
will  be  denoted  by  P (A),  P (B ),  P (C )  and  P (D)  respectively.  Whatever  symbol 
the  transmitter  selects  is  now  coded  appropriately  for  transmission  over  the  binary 
channel.  The  coding  adds  some  redundancy  to  provide  a  basis  for  error  correction 
at  the  receiver,  in  order  to  combat  errors  introduced  by  channel  noise  that  may 
corrupt  the  individual  bits.  The  resulting  signal  is  then  sent  to  the  receiver.  After 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
Section  13.4 

Hypothesis  Testing  in  Coded  Digital  Communication  241 

A 
B 
C 
D 

�  Symbol 
Selector 

�A 

Encoder  �000  Binary 
Channel 
� 

�010  Decoder 
(Decision 
Rule) 

�  B 

Noise


FIGURE  13.7  Communication  over  a  binary  channel.


the  receiver  decodes  the  received  pulses,  attempting  to  correct  for  channel  noise  in 
the  process,  it  has  to  arrive  at  a  decision  as  to  which  symbol  was  transmitted. 

A  natural  criterion  for  measuring  the  performance  of  the  receiver,  with  whatever 
decision  process  or  decision  rule  it  applies,  is  again  the  probability  of  error,  Pe .  It 
is natural,  in a communications  setting,  to want minimum probability of  error, and 
this  is  the  criterion  we  adopt. 

In  the  development  below,  rather  than  simply  invoking  the  MAP  rule  we  derived 
earlier,  we  repeat  in  this  higher-level  setting  the  line  of  reasoning  that  led  to  the 
MAP  rule.  We  do  this  partly  because  there  are  some  diﬀerences  from  what  we 
considered earlier:  we now have multiple hypotheses (four in our example), not just 
a pair of hypotheses; and the measured quantity  is a discrete random symbol (more 
exactly,  the  received  and  possibly  noise  corrupted  binary  code  for  a  transmitted 
symbol),  rather  than  a  continuous  random  variable.  However,  it  will  be  clear  that 
the  problem  here  is  not  fundamentally  diﬀerent  or  harder. 

13.4.1  Optimal  a  priori  Decision 

Consider, ﬁrst of all, what the minimum-probability-of-error decision rule would be 
for  the  receiver  if  the  channel  was  down,  i.e.,  if  the  receiver  had  to  decide  on  the 
transmitted  signal without  the beneﬁt of any received signal, using only on a  priori 
information.  If the receiver guesses that the transmitter selected the symbol A, then 
the  receiver  is  correct  if A was  indeed  the  transmitted  symbol,  and  the  receiver has 
made an error if A was not the transmitted symbol.  Hence the receiver’s probability 
of error with this choice is 1−P (A).  Similar reasoning applies for the other symbols. 
So  the  minimum-probability-of-error  decision  rule  for  the  receiver  is  to  decide  in 
favor  of  whichever  symbol  has maximum  probability.  This  seems  quite  obvious  for 
this  simple  case,  and  the  general  case  (i.e.,  with  the  channel  functioning)  is  not 
really  any  harder.  We  turn  now  to  this  general  case,  where  the  receiver  actually 
receives  the  result  of  sending  the  transmitted  signal  through  the  noisy  channel. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

242  Chapter  13 

Hypothesis  Testing 

13.4.2  The  Transmission Model 

Let  us  model  the  channel  as  a  binary  channel,  which  accepts  1’s  and  0’s  from  the 
transmitter,  and  delivers  1’s  and  0’s  to  the  receiver.  Suppose  that  because  of  the 
noise  in  the  channel  there  is  a  probability  p > 0  that  a  transmitted  1  is  received  as 
a 0, and that a transmitted 0  is received as a 1.  Because the probability  is the same 
for  both  types  of  errors,  this  binary  channel  is  called  symmetric  (we  could  treat 
the  non-symmetric  case  as  easily,  apart  from  some  increased  notational  burden). 
Implicit  in  our  deﬁnition  of  this  channel  is  the  assumption  that  it  is  memoryless, 
i.e.,  its  characteristics  during  any  particular  transmission  slot  are  independent  of 
what  has  been  transmitted  in  other  time  slots.  The  channel  is  also  assumed  time-
invariant,  i.e.,  its  characteristics  do  not  vary  with  time. 

Given such a channel, the transmitter needs to code the selected symbol into binary 
form.  Suppose  the  transmitter  uses  3  bits  to  code  each  symbol,  as  follows: 

A  : 000 , B  : 011  , C  : 101  , D  : 110  . 

(13.41) 

Because of the ﬁnite probability of bit-errors introduced by the channel, the received 
sequence  for  any  of  these  transmissions  could  be  any  3-bit  binary  number: 

R0  = 000  , R1  = 001  , R2  = 010  , R3  = 011  , 

R4  = 100  , R5  = 101  , R6  = 110  , R7  = 111  . 
The  redundancy  introduced  by  using  3  bits  —  rather  than  the  2  bits  that  would 
suﬃce  to  communicate  our  set  of  four  symbols  —  is  intended  to  provide  some 
protection  against  channel  noise.  Notice  that  with  our  particular  3-bits/symbol 
code,  a  single  bit-error  would  be  recognized  at  the  receiver  as  an  error,  because  it 
would  result  in  an  invalid  codeword.  It  takes  two  bit-errors  (which  are  rarer  than 
single bit-errors)  to convert any valid codeword  into another valid one, and  thereby 
elude  recognition  of  the  error  by  the  receiver. 

(13.42) 

There  are  now  various  probabilities  that  it might  potentially  be  of  interest  to  eval­
uate,  such  as: 

•	 P (R1  | D),  the  probability  that  R1  is  received,  given  that  D  was  sent; 
•	 P (D  |  R1 ),  the  probability  that  D  was  sent,  given  that  R1  was  received  — 
this  is  the  a  posteriori  probability  of  D ,  in  contrast  to  P (D),  which  is  the  a 
priori  probability  of D ; 
•	 P (D , R1 ),  the  probability  that D  is  sent  and  R1  is  received; 
• 	 P (R1 ),  the  probability  that  R1  is  received. 
The  sample  space  of  our  probabilistic  experiment  can  be  described  by  Table  13.1, 
which  contains  an  entry  corresponding  to  every  possible  combination  of  transmit­
ted  symbol  and  received  sequence.  In  the  j th  row  of  column  A,  we  enter  the 
probability  P (A, Rj )  that  A  was  transmitted  and  Rj  received,  and  similarly  for 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.4 

Hypothesis  Testing  in  Coded  Digital  Communication  243 

columns  B ,  C ,  and  D .  The  simplest  way  to  actually  compute  this  probability  is 
by  recognizing  that  P (A, Rj ) =  P (Rj  A)P (A);  the  characterization  of  the  chan­
|
nel  permits  computation  of P (Rj  A), while  the  characterization  of  the  information 
|
source  at  the  transmitter  yields  the  prior  probability  P (A).  Note  that  we  can  also 
write  P (A, Rj ) =  P (A Rj )P (Rj ).  Examples  of  these  three  ways  of  writing  the 
|
probabilities  of  the  outcomes  of  our  experiment  are  shown  in  the  table. 

13.4.3  Optimal  a  posteriori  Decision 

We  now  want  to  design  the  decision  rule  for  the  receiver,  i.e.,  the  rule  by  which 
it  decides  or  hypothesizes  what  symbol  was  transmitted,  after  the  reception  of  a 
particular  sequence.  We would  like  to  do  this  in  such  a way  that  the  probability  of 
error,  Pe ,  is  minimized. 
Since  a  decision  rule  in  our  example  selects  one  of  the  four  possible  symbols  (or 
hypotheses),  namely  A,  B ,  C ,  or  D ,  for  each  possible  Rj ,  it  can  be  represented 
in  Table  13.1  by  selecting  one  (and  only  one)  entry  in  each  row;  we  shall  mark 
the  selected  entry  by  a  box.  For  instance,  a  particular  decision  rule  may  declare 
D  to  be  the  transmitted  signal  whenever  it  receives  R4 ;  this  is  indicated  on  the 
table  by  putting  a  box  around  the  entry  in  row  R4 ,  column  D ,  as  shown.  Each 
possible  decision  rule  is  therefore  associated  with  a  table  of  the  preceding  form, 
with  precisely  one  entry  boxed  in  each  row. 

Now,  for  a  given  decision  rule,  the  probability  of  being  correct  is  the  sum  of  the 
probabilities  in  all  the  boxed  entries,  because  this  sum  gives  the  total  probability 
that  the  decision  rule  declares  in  favor  of  the  same  symbol  that  was  transmitted. 
The  probability  of  error,  Pe ,  is  therefore  1 minus  the  probability  of  being  correct. 
It  follows  that  to  specify  the  decision  rule  for  minimum  probability  of  error  or 
maximum  probability  of  being  correct,  we  must  pick  in  each  row  the  box  that  has 
the  maximum  entry.  (If  more  than  one  entry  has  the  maximum  value,  we  are  free 
to pick one of  these arbitrarily — Pe  is not aﬀected by which of  these we pick.)  For 
row Rj  in  Table  13.1,  we  should  pick  for  the  optimum  decision  rule  the  symbol  for 
which  we  maximize 

| 
P (symbol, Rj ) = P (Rj  symbol)P (symbol) 
= P (symbol  Rj )P (Rj )  . 
|
Table  13.2  displays  some  examples  of  the  required  computation  in  a  particular  nu­
merical  case.  The  computation  in  this  example  is  carried  out  according  to  the 
prescription  on  the  right  side  in  the  ﬁrst  of  the  above  pair  of  equations.  As  noted 
earlier,  this  is  generally  the  form  that  yields  the  most  direct  computation  in  prac­
tice, because the characterization of the channel usually permits direct computation 
of P (Rj  symbol), while the characterization of the  information source at the trans­
|
mitter  yields  the  prior  probabilities  P (symbol). 

(13.43) 

The  right  side  of  the  second  equation  in  (13.43)  permits  a  nice,  intuitive  interpre­
tation  of what  the optimum decision  rule does.  Since our  comparison  is being done 
across  the  row,  for  a  given  Rj  the  term  P (Rj )  in  the  second  equation  stays  the 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

244  Chapter  13 

Hypothesis  Testing 

A  : 000 

B  : 011 

C  : 101 

D  : 110 

P (A, R0 ) 

P (B , R0 ) 
P (C, R0 ) 
= P (R0 |B )P (B )  = P (C |R0 )P (R0 ) 
= p2 (1 − p)P (B ) 

P (D , R0 ) 

R0  = 000 

R1  = 001 

R2  = 010 

R3  = 011 

R4  = 100  P (A, R4 ) 

P (B , R4 ) 

P (C, R4 ) 

P (D , R4 ) 

R5  = 101 

R6  = 110 

R7  = 111 

TABLE  13.1  Each  entry  corresponds  to  a  transmitted  symbol  and  a  received 
sequence. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  13.4 

Hypothesis  Testing  in  Coded  Digital  Communication  245 

same,  so  actually  all  that  we  need  to  compare  are  the  a  posteriori  probabilities, 
P (symbol  Rj ),  i.e.  the  probabilities  of  the  various  symbols,  given  the  data.  The 
|
optimum  decision  rule  therefore  picks  the  symbol  with  the  maximum  a  posteriori 
probability.  This  is  again  the MAP  decision  rule  that  we  derived  previously  in  the 
binary hypothesis case.  To summarize the important result we have arrived at here, 
and which we  shall encounter again  in more elaborate hypothesis  testing contexts: 

For minimum error probability Pe , decide in favor of the choice that has maximum a 
posteriori probability, i.e., the choice whose probability, conditioned on the available 
data,  is maximum. 

Note that the only diﬀerence from the minimum-Pe  a priori decision rule we arrived 
at  earlier,  for  the  case  where  the  channel  was  down,  is  the  computation  now  has 
to  involve  conditional  or  a  posteriori  probabilities  —  conditioned  on  the  received 
information  —  rather  than  the  a  priori  probabilities.  The  receiver  still  decides  in 
favor of  the most probable  choice, but now  incorporating  (i.e.,  conditioning on)  the 
received  information. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

246  Chapter  13 

Hypothesis  Testing 

000 
A 

011 
B 

101 
C 

110 
D 

Decision 

R0 
000 

R1 
001 
010  µ 
4 ¶2 
3 
R2 
R3 
011 

R4 
100 

R5 
101 
110  µ 
4 ¶2 
1 
R6 
R7 
111 

2  µ 
4 ¶2 
1 
1 
3 
4 

4  µ 
4 ¶3 
1 
1 
1 
4 

8  µ 
4 ¶2 
1 
3 

1 
1 
4 
8 

‘A’ 

2  µ 
4 ¶2 
3 
1 
1 
4 

4  µ 
4 ¶2 
3 
1 
1 
4 

8  µ 
4 ¶3 
3 
1 
3 
4 

1 
8 

‘D ’ 

1 ,  P (B ) =  4
1 , 
TABLE  13.2  Designing  the  optimal  decision  rule,  with  P (A) =  2
1 
1 ,  p  =  4
1 
,  P (D) = 
.  The  MAP  rule  chooses  the  symbol  that  maximizes 
P (C ) =  8
8
the  a  posteriori  probability,  P (symbol  data). 
| 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

C H A P T E R 

14 

Signal Detection 

14.1  SIGNAL  DETECTION  AS  HYPOTHESIS  TESTING 

In Chapter 13 we  considered hypothesis  testing  in  the  context  of  random variables. 
The detector resulting in the minimum probability of error corresponds to the MAP 
test as developed in section 13.2.1 or equivalently the likelihood ratio test in section 
13.2.3. 

In  this  chapter  we  extend  those  results  to  a  class  of  detection  problems  that  are 
central in radar, sonar and communications,  involving measurements of signals over 
time.  The  generic  signal detection  problem  that we  consider  corresponds  to  receiv­
ing  a  signal  r(t)  over  a  noisy  channel.  r(t)  either  contains  a  known  deterministic 
pulse  s(t)  or  it  does  not  contain  the  pulse.  Thus  our  two  hypotheses  are 

H1  : r(t) = s(t) + w(t)

H0  : r(t) = w(t), 

(14.1) 


where  w(t)  is  a  wide-sense  stationary  random  process.  One  example  of  a  scenario 
in  which  this  problem  arises  is  in  binary  communication  using  pulse  amplitude 
modulation.  In  that  context  the  presence  or  absence  of  the  pulse  s(t)  represents 
the  transmission  of  a  “one”  or  a  “zero”.  As  another  example,  radar  and  sonar 
systems  are based on  transmitting  a pulse and detecting  the presence or absence of 
an  echo. 

In  our  treatment  in  this  chapter  we  ﬁrst  consider  the  case  in  which  the  noise  is 
white  and  carry  out  the  formulation  and  analysis  in  discrete-time  which  avoids 
some  of  the  subtler  issues  associated  with  continuous-time  white  noise.  We  also 
initially  treat  the  case  in  which  the  noise  is  Gaussian.  In  Section  14.3.4  we  extend 
the discussion  to discrete-time Gaussian  colored noise.  In Section  14.3.2 we discuss 
the  implications  when  the  noise  is  not  Gaussian  and  in  Section  14.3.3  we  discuss 
how  the  results  generalize  to  the  continuous-time  case. 

14.2  OPTIMAL  DETECTION  IN  WHITE  GAUSSIAN  NOISE 

In  the  signal  detection  task  outlined  above,  our  hypothesis  test  is  no  longer  based 
on  the  measurement  of  a  single  (scalar)  random  variable  R,  but  instead  involves  a 
collection  of  L  (scalar)  random  variables  R1 , R2 , . . . , RL . 
Speciﬁcally,  we  receive  the  (ﬁnite-length)  DT  signal  r [n],  n = 1, 2, 
, L,  regarded 
· · · 
as  the  realization  of  a  random  process.  More  simply,  the  signal  r [n]  is  modeled  as 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

247

248  Chapter  14 

Signal  Detection 

the  values  taken  by  a  set  of  random  variables  R[n].  Let  H0  denote  the  hypothesis 
that  the  random  waveform  is  only  white  Gaussian  noise,  i.e. 

H0  :  R[n] = W [n] 
· · · 
where  the  W [n]  for  n = 1, 2, 
, L  are  independent,  zero-mean,  Gaussian  random 
variables,  with  variance  σ2 .  Similarly,  let H1  denote  the  hypothesis  that  the  wave­
form  R[n]  is  the  sum  of  white  Gaussian  noise  W [n]  and  a  known,  deterministic 
signal  s[n],  i.e. 

(14.2) 

H1  :  R[n] = s[n] + W [n] 
(14.3) 
where  the  W [n]  are  again  distributed  as  above.  Our  task  is  to  decide  in  favor  of 
H0  or H1  on  the  basis  of  the  measurements  r [n]. 
The  nature  and  derivation  of  the  solutions  to  such  decision  problems  are  similar 
to  those  in  Chapter  13,  except  that  we  now  use  posterior  probabilities  conditioned 
, r[L])  rather  than 
on  the  entire  collection  of  measurements,  i.e.  P (Hi r [1], r[2], 
· · · 
|
P (Hi r).  Similarly, we use compound (or joint) PDF’s, such as f (r [1], r[2], 
· · · 
|
|
, r[L] Hi )
instead  of  f (r Hi ).  The  associated  decision  regions  Di  are  now  regions  in  an  L­
|
dimensional  space,  rather  than  segments  of  the  real  line. 

For  detection  with  minimum  probability  of  error,  we  again  use  the  MAP  rule  or 
equivalently  compare  the  values  of 

f (r [1], r[2], . . . , r[L]  Hi ) P (Hi ) 
| 
for  i = 0, 1,  and  decide  in  favor  of  whichever  hypothesis  yields  the maximum  value 
of  this  expression,  i.e.  the  form  of  equation  (13.7)  for  the  case  of multiple measure­
ments  is 

(14.4) 

f (r [1], r[2], . . . , r[L]  H1 ) P (H1 ) 
| 

‘H1 ’ 
> 
< 
‘H0 ’ 

f (r [1], r[2], . . . , r[L]  H0 ) P (H0 ) 
| 

(14.5) 

which  also  can  easily be put  into  the  form  of  equation  (13.18)  corresponding  to  the 
likelihood  ratio  test. 

With  W [n]  white  and  Gaussian,  the  conditional  densities  in  (14.5)  are  easy  to 
evaluate,  and  take  the  form 

f (r [1], r[2], . . . , r[L] | H0 ) = 

½ 
(r [n])2 ¾ 
(2πσ2 )(L/2)  Y 
L
1 
exp − 
2σ2 
n=1 
exp − (X  (r [n])2 ) 
L
1 
2σ2 
(2πσ2 )(L/2) 
n=1 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

= 

(14.6) 

Section  14.2 

Optimal  Detection  in White  Gaussian  Noise  249 

and 

f (r [1], r[2], . . . , r[L]  H1 ) = 
| 

¾ 
½ 
(2πσ2 )(L/2)  Y 
L
(r [n] − s[n])2 
1 
exp − 
2σ2 
=1 
n
) 
(X 
L
(r [n] − s[n])2 
1 
(2πσ2 )(L/2)  exp − 
2σ2 
n=1 
The  inequality  in  equation  (14.5)  (or  any  inequality  in  general)  will,  of  course  still 
hold  if  a  nonlinear,  strictly  increasing  function  is  applied  to  both  sides.  Because 
of  the  form  of  equations  (14.6)  and  (14.7)  it  is  particularly  convenient  to  replace 
equation  (14.5)  by  applying  the  natural  logarithm  to  both  sides  of  the  inequality. 
The  resulting  inequality,  in  the  case  of  (14.6)  and  (14.7),  is: 

(14.7) 

= 

“H1 ” 
> 
<
“H ” 0 

g = 

¶ 
µ 
X 
LX 
L
P (H0 ) 
σ2  ln 
s 2 [n] 
+ 
r [n]s[n] 
P (H1 )
n=1 
=1 
n
The  sum  on  the  left-hand  side  of  Eq.  (14.8)  is  referred  to  as  the  deterministic 
correlation  between  r [n]  and  s[n],  which  we  denote  as  g .  The  second  sum  on  the 
right-hand  side  is  the  energy  in  the  deterministic  signal  s[n] which we  denote by  E . 
For  convenience  we  denote  the  threshold  represented  by  the  entire  right  hand  side 
of  (14.8)  as  γ ,  i.e.,  equation  (14.8)  becomes 

(14.8) 

1 
2 

g

“H1 ” 
> 
< 
“H0 ” 
) +  E 
P (H0 )
where  γ  = σ2  ln( 
2 
P (H1 )

γ 

(14.9a) 

(14.9b) 

If  the  Neyman-Pearson  formulation  is  used,  then  the  optimal  decision  rule  is  still 
of  the  form  of  equation  (14.8),  except  that  the  right  hand  side  of  the  inequality  is 
determined  by  the  speciﬁed  bound  on  PF A . 
If  hypothesis  H0  is  true,  i.e.  if  the  signal  s[n]  is  absent,  then  r [n]  on  the  left  hand 
side  of  equation  (14.8)  will  be Gaussian  white  noise  only,  i.e.  g  will  be  the  random 
variable 
X 
L
G =  W [n]s[n] 
n=1 
Since  W [n]  at  each  value  of  n  is  Gaussian,  with  zero  mean  and  variance  σ2 ,  and 
since a weighted,  linear combination of Gaussian random variables is also Gaussian, 
X 
L
2 [n] = σ2
s 
n=1 

the random variable G is Gaussian with mean zero and variance σ2 

(14.10) 

E . 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

250  Chapter  14 

Signal  Detection 

When  the  signal  is  actually  present,  i.e.,  when  H1  holds,  the  random  variable  is 
the  realisation  of  a  Gaussian  random  variable  with  mean  E  and  still  with  variance 
E σ2  or  standard  deviation  σ√E .  The  optimal  test  in  (14.8)  is  therefore  described 
by  Figure  14.1  which  is  of  course  similar  to  that  in  Figure  13.5  : 

f(r|H 
0  ) 

f(r|H
1) 

σ  ε 

γ 

ε 

r  = Σ r[n]s[n] 

FIGURE  14.1  Optimal  test  for  two  hypotheses  with  equal  variances  and  diﬀerent 
means. 

Using  the  facts  summarized  in  this ﬁgure,  and  given  a detection  threshold γ  on  the 
correlation  (e.g.  with  γ  picked  equal  to  the  right  side  of  (14.8),  or  in  some  other 
way),  we  can  compute  PF A ,  PD ,  Pe ,  and  other  probabilities  of  interest. 
Figure  14.1 makes  evident  that  the  performance  of  the  detection  strategy  is  deter­
mined  entirely  by  the  ratio  E /(σ√E ),  or  equivalently  by  the  signal-to-noise  ratio 
E /σ2 ,  i.e.  the  ratio  of  the  signal  energy  E  to  the  noise  variance  σ2 . 

14.2.1  Matched  Filtering 

Since  the  correlation  sum  in  (14.8)  constitutes  a  linear  operation  on  the  measured 
signal, we  can  consider  computing  the  sum  through  the use of an LTI ﬁlter and  the 
output  sampled  at  an  appropriate  time  to  form  the  correlation  sum  g .  Speciﬁcally, 
with  h[n]  as  the  impulse  response  and  r [n]  as  the  input,  the  output  will  be  the 
convolution  sum 
∞X 
r [k ]h[n − k ] 
k=−∞ 
For r [n] = 0 except for 1 ≤ n ≤ L and with h[n] chosen as s[−n], the ﬁlter output at 
n = 0  is PL
k=1 r [k ]s[k ] = g  as  required.  In other words, we choose  the ﬁlter  impulse 
response  to  be  a  time-reversed  version  of  the  target  signal  for  n = 1, 2, . . . , L,  with 
h[n] = 0  elsewhere.  This  ﬁlter  is  said  to  be  the matched  ﬁlter  for  the  target  signal. 
The  structure  of  the  optimum  detector  for  a  ﬁnite-length  signal  in  white  Gaussian 
noise  is  therefore  as  shown  below: 

(14.11) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Matched Filter 

x[k] 

h[k] 
= s[-k] 

Section  14.3 

A  General  Detector  Structure  251 

r = Σ x[k]s[k] 

>  γ 
< 

’H1  ’ 
’H0  ’ 

Sample at 
time zero 

FIGURE  14.2  Optimum  detector 

14.2.2  Signal  Classiﬁcation 

We  can  easily  extend  the  previous  two-hypothesis  problem  to  the multiple  hypoth­
esis case, where Hi ,  i = 0, 1, 
, M − 1 denotes the hypothesis that the signal R[n], 
· · · 
n  = 1, 2, 
· · · 
, L,  is  a  noise-corrupted  version  of  the  ith  deterministic  signal  si [n], 
selected  from  a  possible  set  of M  deterministic  signals: 

Hi  :  R[n] = si [n] + W [n] 

(14.12) 

with  the  W [n]  denoting  independent,  zero-mean,  Gaussian  random  variables  with 
variance σ2 .  This scenario arises, for example, in radar signature analysis.  Diﬀerent 
aircraft  reﬂect  a  radar pulse diﬀerently,  typically with  a distinct  signature  that  can 
be used  to  identify not only  its presence, but  the  type of aircraft.  In  this  case,  each 
of  the  signals  si [n]  and  correspondingly  each  hypothesis  Hi  would  correspond  to 
the  presence  of  a  particular  type  of  aircraft.  Thus,  our  task  is  to  decide  in  favor 
of  one  of  the  hypotheses,  given  a  set  of  measurements  r [n]  of  R[n].  For  minimum 
error  probability,  the  required  test  involves  comparison  of  the  quantities 
Ã 
! 
LX 
r [n]si [n]  − Ei 
2 
n=1 
where  Ei  denotes  the  energy  of  the  ith  signal.  The  largest  of  the  expressions  in 
, M  − 1,  determines  which  hypothesis  is  selected.  If  the 
(14.13),  for  i  = 0, 1, 
· · · 
signals have equal energies and equal prior probabilities, then the above comparison 
reduces  to  deciding  in  favor  of  the  signal with  the  highest  deterministic  correlation 
LX 
r [n]si [n]  . 
n=1 

+ σ2  ln P (Hi ) 

(14.13) 

(14.14) 

14.3  A  GENERAL  DETECTOR  STRUCTURE 

The matched  ﬁlter  developed  in  Section  14.2  extends  to  the  case where we  have  an 
inﬁnite number of measurements rather than just L measurements.  As we will see in 
Section  14.3.4,  it  also  extends  to  the  case  of  colored  noise.  We  shall,  for  simplicity, 
treat  these  extensions  by  assuming  the  general  detector  structure,  shown  in Figure 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

252  Chapter  14 

Signal  Detection 

�  Processor 

r [n] 
↑ 
random 
process 

�  Threshold 

g [n]  � n = 0 
↑ 
↑
random 
random 
process 
variable 

‘H1 ’ 
>�  <
‘H0 ’ 
↑ 
decision 

FIGURE  14.3  A  general  detector  structure. 

11.7,  and  determine  an  optimum  choice  of  processor  and  of  detection  threshold  for 
each  scenario. 

We  are  assuming  that  the  transmitter  and  receiver  are  synchronized,  so  that  we 
test  g [n]  at  a  known  (ﬁxed)  time,  which  we  choose  here  as  n  =  0.  The  choice 
of  0  as  the  sampling  instant  is  for  convenience;  any  other  instant  may  be  picked, 
with  a  corresponding  time-shift  in  the  operation  of  the  processor.  Although  the 
processor  could  in  general  be  nonlinear,  we  shall  assume  the  processing  will  be 
done with  an  LTI  ﬁlter.  Thus  the  system  to  be  considered  is  shown  in Figure  14.4; 
a  corresponding  system  can  be  considered  for  continuous  time. 

r [n] 

�  LTI,  h[n] 

g [n]  � n = 0 

�  Threshold 
G 

‘H1 ’ 
>�  <
‘H0 ’

FIGURE 14.4  Detector structure of Figure 14.3 with the processor as an LTI system. 

It  can  be  shown  formally,  but  is  also  intuitively  reasonable,  that  scaling  h[n]  by  a 
constant gain will not aﬀect the overall performance of the detector  if the threshold 
is  correspondingly adjusted  since a  constant overall gain  scales  the  signal and noise 
identically. 

For  convenience,  we  normalize  the  gain  of  the  LTI  system  so  as  to  have 
+∞X 
h2 [n] = 1 . 
n=−∞ 
If r [n] is a Gaussian random process, then so is g [n], because it is obtained by linear 
processing  of  r [n],  and  therefore  G  is  a  Gaussian  random  variable  in  this  case. 

(14.15) 

14.3.1  Pulse  Detection  in White  Noise 

To  suggest  the  approach we  consider  a very  simple  choice  of LTI processor,  namely 
with  h[n] = δ [n],  so 

H1  : G = g [0] = s[0] + w[0] 
H0  : G = g [0] = w[0]  . 

(14.16) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  14.3 

A  General  Detector  Structure  253 

Thus,  under  each  hypothesis,  g [0]  is  Gaussian: 

Also  for  convenience  we  assume  that  s[0]  is  positive. 
exp " 
(g − s[0]) # 
2 
1 
H1  : fG|H (g |H1 ) = N (s[0], σ2 ) =  √2
− 
2σ2 
πσ 
g ¸ 
· 
1 
2
. 
exp  − 
H0  : fG|H (g |H0 ) =  √2πσ 
2σ2 
fG|H (g |H0 ) 

fG|H (g |H1 ) 

(14.17) 

� 

� 

0 

s[0] 

g 

FIGURE  14.5  PDF’s  for  the  two  hypotheses  in  Eq.  (14.16). 

This is just the binary hypothesis testing problem on the random variable G treated 
in  Section  13.2  and  correspondingly  the  MAP  rule  for  detection  with  minimum 
probability  of  error  is  given  by 

‘H1 ’ 
>
| 
P (H1  G = g)  < P (H0  G = g) , 
| 
‘H0 ’ 

or,  equivalently,  the  likelihood  ratio  test: 

fG|H (g  | H1 ) 
fG|H (g  | H0 )

‘H1 ’ 
P (H0 )
>
<
‘H0 ’  P (H1 ) 

= η . 

(14.18) 

and  equivalently 

Evaluating  equation  (14.18)  using  equation  (14.17)  leads  to  the  relationship 
g ¸¾  ‘H1 ’ 
· 
½· 
(g − s[0])2 ¸
P (H0 )
2
> 
exp 
− 
< P (H1 ) 
2σ2 
2σ2 
‘H0 ’ 
s2 [0] ¸  ‘H1 ’ 
· 
gs[0] 
P (H0 ) 
> 
exp 
< 
σ2 
2σ2 
0 ’  P (H1 ) 
‘H
or,  taking  the  natural  logarithm  of  both  sides  of  the  likelihood  ratio  test  as  we  did 
in  Section  14.2,  equation  (14.20)  is  replaced  by 
> 1 ’ 
‘H
g < 
‘H0 ’ 

σ2 
P (H0 ) 
ln 
s[0]  P (H1 )

s[0] 
2 

+ 

(14.19) 

(14.20) 

+

− 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(14.21) 

254  Chapter  14 

Signal  Detection 

We may not know  the a  priori probabilities P(H0 ) and P(H1 ) or,  for other reasons, 
may want  to modify  the  threshold, but  still using a  threshold  test on  the  likelihood 
ratio,  or  a  threshold  test  of  the  form 

‘H1 ’ 
> 
g  <  λ . 
‘H0 ’ 

(14.22) 

Sweeping  the  threshholds  over  all  possible  values  leads  to  the  receiver  operating 
characteristics  as  discussed  in  Section  13.2.5. 

We  next  consider  the  more  general  case  in  which  h[n]  is  not  the  identity  system. 
Then,  under  the  two  hypothesis  we  have: 

H1  :  g [n] =  s[n] ∗ h[n] + w[n] ∗ h[n] 
H0  :  g [n] =  w[n] ∗ h[n] , 

(14.23) 

The  term  w[n] ∗ h[n]  still  represents  noise  but  is  no  longer  white,  i.e.  its  spectral 
shape  is changed by the ﬁlter h[n].  Denoting w[n] ∗ h[n] as v [n],  the autocorrelation 
function  of  v [n]  is 
Rvv [m] = Rww [m] ∗ Rhh [m] 
(14.24) 
and  in  particular  the  mean  v [n]  is  zero  and  its  variance  is 
var{v [n]} = σ2  X 
∞
h2 [n]. 
n=−∞ 
Because  of  the  normalization  in  equation  (14.15)  the  variance  of  v [n]  is  the  same 
as  that of  the white noise,  i.e.  var{v [n]} = σ2 .  Furthermore,  since w[n]  is Gaussian 
so  is  v [n].  Consequently  the  value  g [0]  is  again  a  Gaussian  random  variable  with 
variance  σ2 .  The mean  of  g [0]  under  the  two  hypotheses  is  now: 
H1  :  E {g [n]}  =  X 
∞
n=−∞
H0  :  E {g [n]}  = 0, 
Therefore  equation  (14.17)  is  replaced  by 

h[n]s[−n] , µ 

(14.25) 

(14.26) 

H1  : fG|H (g |H1 ) = N (µ, σ2 )

H0  : fG|H (g |H0 ) = N (0, σ2 ). 

(14.27)


The  probability  density  functions  representing  the  two  hypothesis  are  shown  in 
Figure 14.6 below.  On this ﬁgure we have also indicated the threshold γ  of equation 
(14.27)  above  which  we  would  declare  H1  to  be  true  and  below  which  we  would 
declare  H0  to  be  true.  Also  indicated  by  the  shaded  areas  are  the  areas  under  the 
PDF’s  that  would  correspond  to  PF A  and  PD . 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  14.3 

A  General  Detector  Structure  255 

fG|H (g [0] H0 )  fG|H (g [0] H1 ) 
|
|
�
� 

PF A 
� 

PD 
� 

0 

λ

M 

g [0] 

FIGURE  14.6  Indication  of  the  areas  representing  PF A  and  PD . 

∞ 

PD  = 

(14.28) 

fG (g [0] H1 )dg 
|

The  value  of  PF A  is  ﬁxed  by  the  shape  of  fG|H (g [0]|H0 )  and  the  value  of  the 
threshold  γ .  Since  fG|H (g [0]|H0 )  is  not  dependent  on  h[n],  the  choice  of  h[n]  will 
not  aﬀect  PF A .  The  variance  of  fG (g [0] H1 )  is  also  not  inﬂuenced  by  the  choice  of 
|
h[n]  but  its  mean  µ  is.  In  particular,  as  we  see  from  Figure  14.6,  the  value  of  PD 
is  given  by 
Z 
γ 
which increases as µ increases.  Consequently, to minimize P (error), or alternatively 
to maximize PD  for a given PF A , we want to maximize the value of µ.  To determine 
the  choice  of  h[n]  to maximize  µ  we  use  the  Schwarz  inequality: 
h[n]s[−n]¯¯¯  ≤ X 
¯¯¯X 
h2 [n] X 
2
s 2 [−n] 
with  equality  if  and  only  if h[n] = cs[−n]  for  some  constant  c.  Since we normalized 
the  energy  in  h[n],  the  optimum  ﬁlter  is  h[n] = ( √1
E )s[−n],  which  is  again  the 
matched ﬁlter.  (This  is as expected,  since the optimum detector  for a known ﬁnite-
length  pulse  in  white  Gaussian  noise  has  already  been  shown  in  Section  14.2.1  to 
have  the  form  we  assumed  here,  with  the  impulse  response  of  the  LTI  ﬁlter  being 
matched to the signal.)  The ﬁlter output g [n] due to the pulse is then  √1
E Rss [n] and 
the  output  due  to  the  noise  is  the  colored  noise  v [n]  with  variance  σ2 .  Since  g [0] 
E  P∞n=−∞ s2 [n]  and  variance  σ2 ,  only  the  energy 
is  a  random  variable with mean  √1
in  the  pulse  and  not  its  speciﬁc  shape,  aﬀects  the  performance  of  the  detector. 

(14.29) 

14.3.2  Maximizing  SNR 

If  w[n]  is  white  but  not  Gaussian,  then  g [0]  is  not  Gaussian.  However,  g [0]  is  still 
distributed  the  same  under  each  hypothesis,  except  that  its  mean  under  H0  is  0 
while  the  mean  under  H1  is  µ  as  given  in  equation  (14.26).  The  matched  ﬁlter 
in  this  case  still  maximizes  the  output  signal-to-noise  ratio  (SNR)  in  the  speciﬁed 
structure  (namely, LTI ﬁltering  followed by  sampling), where  the SNR  is deﬁned as 
E {g [0]|H1 }2 /σ2 .  The square root of the SNR  is the relative separation between the 
means  of  the  two  distributions, measured  in  standard  deviations.  In  some  intuitive 
sense,  therefore, maximizing the SNR tries to separate the two distributions as well 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

256  Chapter  14 

Signal  Detection 

as possible.  However,  this does not  in general necessarily correspond  to minimizing 
the  probability  of  error. 

14.3.3  Continuous-Time Matched  Filters 

All  of  the matched ﬁlter  results developed  in  this  section  carry  over  in  a direct way 
to  continuous-time.  In  Figure  14.7  we  show  the  continuous-time  counterpart  to 
Figure  14.4  As  before,  we  normalize  the  gain  of  h(t)  so  that 

r(t) 

�  LTI  h(t) 

g(t)  � t = 0 
G 

�  Threshold  λ 

‘H1 ’ 
>�  <
‘H0 ’ 

FIGURE  14.7  Continuous-time  matched  ﬁltering. 
Z 
−∞ 
with  r(t)  a  Gaussian  random  process,  g(t)  is  also  Gaussian  and  G  is  a  Gaussian 
random  variable.  Under  the  two  hypotheses  the  PDF  of  G  is  then  given  by 

h2 (t)dt = 1 

(14.30) 

∞ 

where 

and 

(14.31) 

h2 (t)dt = N0 

H1  : fG|H (g H1 ) = N (µ, σ2
G ) 
|
H0  : fG|H (g H0 ) = N (0, σ2 
G )  , 
|
Z 
σ2  = N0 
G 
−∞ 
Z 
∞ 
−∞ 
Consequently,  as  in  the  discrete-time  case,  the  probability  of  error  is  minimized 
by  choosing  h(t)  to  separate  the  two  PDF’s  in  equation  (14.31)  as  much  as  possi­
ble.  With  the  continuous-time version of  the Cauchy-Schwarz  inequality applied  to 
equation  (14.33) we  then  conclude  that  the optimum  choice  for h(t)  is proportional 
to  s(−t),  i.e.  again  the  matched  ﬁlter 

h(t)s(−t)dt 

(14.32) 

∞ 

µ = 

(14.33) 

EXAMPLE  14.1 

PAM  with Matched  Filter 

Figure  14.8(a)  shows  an  example  of  a  typical  noise-free  binary  PAM  signal  as  rep­
resented by Eq.  (13.1).  The pulse p(t)  is a  rectangular pulse of  length 50  sec.  The 
binary  sequence a[n] over  the  time  interval  shown  is  indicated  above  the waveform. 
In  the  absence  of  noise,  the  optimal  threshold  detector  of  the  form  of  Figure  14.4 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

l
a
n
g
i
s
 
d
e
t
t
i
m
s
n
a
r
T

2

1 

0 

−1 

10 

0 

−10 

l
a
n
g
i
s
 
d
e
v
i
e
c
e
R

2

0 

−2 

t
u
p
t
u
o
 
r
e
t
l
i
f
 
d
e
h
c
t
a
M

Section  14.3 

A  General  Detector  Structure  257 

1

0 

1 

0

0

1

1

0

1

1 

0

0 

1 

0 

200 

400 

0 

200 

400 

600 
Time (s) 
(a) 

600 
Time(s) 
(b) 

800 

1000 

1200 

800 

1000 

1200 

0 

200 

400 

800 

1000 

1200 

600 
Time (s) 
(c) 

FIGURE  14.8  Binary  detection  with  on/oﬀ  signaling 

would  simply  test  at  integer  multiples  of  T  whether  the  received  signal  is  positive 
or  zero.  Clearly  the  probability  of  error  in  this  noise-free  case  would  be  zero. 

In Figure 14.8(b) we  show  the  same PAM  signal but with wideband Gaussian noise 
added.  If  h(t)  is  the  identity  system  and  the  threshold  of  the  detector  is  chosen 
according  to  Eq.  (14.18)  with  P (H0 ) =  P (H1 )  i.e.  using  the  likelihood  ratio 
test  but without  the matched  ﬁlter,  the  decoded binary  sequence  is  0100111111011 
which  has  6  bit  errors.  Figure  14.8(c)  shows  the  output  of  the  matched  ﬁlter,  i.e. 
with  h(t) =  s(−t).  The  detector  threshold  is  again  chosen  based  on  the  likelihood 
ratio  test.  The  resulting  decoded  binary  sequence  is  1010011111000  which  has  2 
bit  errors 

In  Figure  14.9  we  show  the  corresponding  results  when  antipodal  rather  than  on-
oﬀ  signaling  is  used.  Figure  14.9(a)  depicts  the  transmitted  waveform  with  the 
same  binary  sequence  as  was  used  in  Figure  14.8,  and  Figure  14.9(b)  the  received 
signal  including  additive  noise.  If  h(t) = δ(t)  and  P (H0 ) = P (H1 ),  then  the  choice 
of  threshold  for  the  likelihood  ratio  test  is  zero.  The  decoded  binary  sequence  is 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

258  Chapter  14 

Signal  Detection 

l
a
n
g
i
S
 
d
e
t
t
i
m
s
n
a
r
T

2


0


−2 

0 

200 

400 

10 

 
l
a
n
g
i
S
 
d
e
v
i
e
−10 
c
e
R

0 

0 

200 

400 

 
t
u
p
t
u
o
 
r
e
t
l
i
f
 
d
e
h
c
t
a
M

2 

0 

−2 

0 

200 

400 

800 

1000 

1200 

800 

1000 

1200 

800 

1000 

1200 

600 
Time (s) 
(a) 

600 
Time(s) 
(b) 

600 
Time (s) 
(c) 

FIGURE  14.9  Binary  Detection  with  antipodal  signaling 

0001001011001,  resulting  in 4 bit errors.  With h(t) chosen as the matched ﬁlter the 
signal  before  the  threshold  detector  is  that  shown  in  Figure  14.9(c).  The  resulting 
decoded  binary  sequence  is  1010011011001  with  no  bit  errors.  In  Table  14.1  we 
summarize  the results  for  this speciﬁc example based on a simulation with a binary 
sequence  of  length  104 . 

On/Oﬀ  Signaling

Antipodal  Signaling


No matched  ﬁlter  W/ matched  Filter

0.3752

0.4808 
0.4620 
0.2457 

TABLE  14.1  Bit  error  rate  for  a  PAM  signal  illustrating  eﬀect  of  matched  ﬁlter  for 
two  diﬀerent  signaling  schemes. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  14.3 

A  General  Detector  Structure  259 

14.3.4  Pulse  Detection  in  Colored  Noise 

In Sections 14.2 and 14.3 the optimal detector was developed under the assumption 
that  the  noise  is white.  When  the  noise  is  colored  ,  i.e.  when  its  spectral  density  is 
not  ﬂat,  the  results  are  easily modiﬁed.  We  again  assume  a  detector  of  the  form  of 
Figure  14.4.  The  two  hypotheses  are  now: 

H1  : r [n] = s[n] + v [n], 

H0  : r [n] = v [n] , 

(14.34)


where  v [n]  is  again  a  zero-mean  Gaussian  process  but  in  general,  not  white.  The 
autocorrelation function of v [n] is denoted by Rvv [m] and the power spectral density 
by  Svv (ejΩ ).  The  basic  approach  is  to  transform  the  problem  to  that  dealt with  in 
the previous  section by ﬁrst processing r [n] with a whitening ﬁlter as was discussed 
in  Section  10.2.3  ,  which  is  always  possible  as  long  as  Svv (ejΩ )  is  strictly  positive, 
i.e.  it  is not zero at any value of Ω.  This ﬁrst  stage of ﬁltering  is depicted  in Figure 
14.10. 

Whitening  Filter 
r [n] 
rw [n]�

�  hw [n] 

FIGURE  14.10  First  stage  of  ﬁltering 

The  impulse  response  hw [n]  is  chosen  so  that  its  output  due  to  the  input  noise 
v [n]  is  white,  with  variance  σ2  and,  of  course,  will  also  be  Gaussian.  With  this 
pre-processing  the  signal  rw [n]  now  has  the  form  assumed  in  Section  14.3.4  with 
the  white  noise  w[n]  corresponding  to  v [n] ∗ hw [n]  and  the  pulse  s[n]  replaced  by 
p[n] =  s[n] ∗ hw [n].  The  detector  structure  now  takes  the  form  shown  in  Figure 
14.11  where  h[n]  is  again  the  matched  ﬁlter,  but  in  this  case  matched  to  the  pulse 
p[n],  i.e.  hm [n]  is  proportional  to  p[−n]. 

�r [n] 

LTI  hw [n] 

rw [n] 

�

LTI  h[n] 

g [n] 

� n = 0  � 
g [0] 

Threshold  λ 

‘H1 ’ 
>�  <
‘H0 ’ 

FIGURE  14.11  Detector  structure  with  colored  noise. 

Assuming  that  hw [n]  is  invertible  (i.e.  its  Z -transform  has  no  zeros  on  the  unit 
circle)  there  is no  loss of generality  in having ﬁrst applied a whitening ﬁlter.  To  see 
this concretely denote the combined LTI ﬁlter from r [n] to g [n] as hc [n] and assume 
that  if whitening  had  not  ﬁrst  been  applied,  the  optimum  choice  for  the  ﬁlter  from 
r [n]  to  g [n]  is  hopt [n].  Since 

hc [n] = hw [n] ∗ hm [n] 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(14.35) 

260  Chapter  14 

Signal  Detection 

where  hm [n]  denotes  the  matched  ﬁlter  after  whitening.  If  the  performance  with 
hopt [n]  is  better  than  with  hc [n],  this  would  imply  that  choosing  hm [n]  as  hopt [n] ∗ 
hinv [n] would  lead  to  better  performance  on  the whitened  signal.  However,  as  seen 
w 
in  Section  14.3,  hm [n] =  p[−n]  is  the  optimum  choice  after  the  whitening  and 
consequently  we  conclude  that 
hm [n] = p[−n] = hopt [n] ∗ hinv 
w  [n] 

(14.36) 

or  equivalently 

hopt [n] = hw [n] ∗ p[−n] 
In  the  following  example  we  illustrate  the  determination  of  the  optimum  detector 
in  the  case  of  colored  noise. 

(14.37) 

EXAMPLE  14.2 

Pulse  Detection  in  Colored  Noise 

Consider  a  pulse  s[n]  in  colored  noise  v [n],  with 

and 

s[n] = δ [n]  . 

(14.38) 

1 
Rvv [m] = (  )|m| ,  so  σ2  = 1 
v 
2 
3/4 
1 
z−1 )(1 −  z )
2 

(1 −  1
2

then  Svv (z ) = 

. 

(14.39) 

The  noise  component  w[n]  of  desired  output  of  the  whitening  ﬁlter  has  autocorre­
lation  function  Rww [m] = σ2 δ [m]  and  consequently  we  require  that 

Svv (z )Hw (z )Hw (1/z ) = σ2 
σ2 
4
= σ2 
Svv (z ) 
3

Thus Hw (z )Hw (1/z ) = 

(1 − 

1 
1 
z−1 )(1 −  z )  . 
2 
2

(14.40) 

We  can  of  course  choose  σ  arbitrarily  (since  it  will  only  impact  the  overall  gain). 
Choosing  σ2  = 1,  either 

1 
Hw (z ) = (1 −  z−1 ),  or 
2 
1 
Hw (z ) = (1 −  z ) 
2 
Note  that  the  second  of  these  choices  is  non-causal.  There  are  also  other  possi­
bile  choices  since  we  can  cascade  either  choice  with  an  all-pass  Hap (z )  such  that 
Hap (z )Hap (1/z ) = 1. 

(14.41) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  14.3 

A  General  Detector  Structure  261 

With  the  ﬁrst  choice  for Hw (z )  from  above,  we  have 

1 
z−1 ),
Hw (z ) = (1 − 
2 
1 
hw [n] = δ [n] −  δ [n − 1],
2

σ2  = 3/4,


1

p[n] = s[n] −  s[n − 1],  and 
2 
h[n] = Ap[−n]  for  any  convenient  choice  of  A. 

(14.42) 

In  our  discussion  in  Section  14.3  of  the  detection  of  a  pulse  in  white  noise,  we 
observed  that  the  energy  in  the  pulse  aﬀects  performance  of  the  detector  but  not 
the  speciﬁc pulse  shape.  This was a consequence of  the  fact  that  the ﬁlter  is chosen 
to maximize  the  quantity  √1
E Rss [0]  where  s[n]  is  the  pulse  to  be  detected.  For  the 
case  of  a  pulse  in  colored  noise,  we  correspondingly  want  to  maximize  the  energy 
Ep  in  p[n]  where 

(14.43) 

p[n] = hw [n] ∗ s[n] 
Expressed  in  the  frequency  domain, 

P (ejΩ ) = Hw (ejΩ )S (ejΩ ) 

(14.44) 

and  from  Parseval’s  relation 

Ep  = 

= 

(14.45a) 

π  Z  π 
1 
|Hw (ejΩ )|2 |S (ejΩ )|2dΩ 
2
π 
1  Z−
2 
π
|S (ejΩ )| dΩ 
−π  Svv (ejΩ ) 
2π 
Based only on Eq.  (14.45b), Ep  can be maximized by placing all of the energy of the 
transmitted  signal  s[n]  at  the  frequency  at  which  Svv (ejΩ )  is  minimum.  However, 
in  many  situations  the  transmitted  signal  is  constrained  in  other  ways,  such  as 
peak  amplitude  and/or  time duration.  The  task  then  is  to  choose  s[n]  to maximize 
the  integral  in  Eq.  (14.45b)  under  these  constraints.  There  is  generally  no  closed-
form  solution  to  this  optimization  problem,  but  roughly  speaking  a  good  solution 
will  distribute  the  signal  energy  so  that  it  is  more  concentrated  where  the  power 
Svv (ejΩ )  of  the  colored  noise  is  less. 

(14.45b) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

MIT OpenCourseWare
http://ocw.mit.edu 

6.011 Introduction to Communication, Control, and Signal Processing 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

