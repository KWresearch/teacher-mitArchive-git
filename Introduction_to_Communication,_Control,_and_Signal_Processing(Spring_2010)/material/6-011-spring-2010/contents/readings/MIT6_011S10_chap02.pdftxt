C H A P T E R 

2 

Signals  and  Systems 

This text assumes a basic background in the representation of linear, time-invariant 
systems and the associated continuous-time and discrete-time signals,  through con­
volution,  Fourier  analysis,  Laplace  transforms  and  Z -transforms.  In  this  chapter 
we brieﬂy  summarize  and  review  this  assumed background,  in part  to  establish no­
tation  that we will be using  throughout  the  text, and also as a convenient  reference 
for the topics in the later chapters.  We follow closely the notation, style and presen­
tation  in  Signals  and  Systems,  Oppenheim  and Willsky  with  Nawab,  2nd  Edition, 
Prentice  Hall,  1997. 

2.1  SIGNALS,  SYSTEMS,  MODELS,  PROPERTIES 

Throughout  this  text  we  will  be  considering  various  classes  of  signals  and  systems, 
developing  models  for  them  and  studying  their  properties. 

Signals 
for  us  will  generally  be  real  or  complex  functions  of  some  independent 
variables  (almost  always  time  and/or  a  variable  denoting  the  outcome  of  a  proba­
bilistic  experiment,  for  the  situations  we  shall  be  studying).  Signals  can  be: 

• 
1-dimensional  or  multi-dimensional 
•  continuous-time  (CT)  or  discrete-time  (DT) 
•  deterministic  or  stochastic  (random,  probabilistic) 
Thus,  a  DT  deterministic  time-signal  may  be  denoted  by  a  function  x[n]  of  the 
integer  time  (or  clock  or  counting)  variable  n. 

Systems  are  collections  of  software  or  hardware  elements,  components,  subsys­
tems.  A  system  can  be  viewed  as mapping  a  set  of  input  signals  to  a  set  of  output 
or  response  signals.  A  more  general  view  is  that  a  system  is  an  entity  imposing 
constraints  on  a  designated  set  of  signals,  where  the  signals  are  not  necessarily  la­
beled  as  inputs  or  outputs.  Any  speciﬁc  set  of  signals  that  satisﬁes  the  constraints 
is  termed  a  behavior  of  the  system. 

Models  are  (usually  approximate)  mathematical  or  software  or  hardware  or  lin­
guistic  or  other  representations  of  the  constraints  imposed  on  a  designated  set  of 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

21

22  Chapter  2 

Signals  and  Systems 

signals  by  a  system.  A  model  is  itself  a  system,  because  it  imposes  constraints  on 
the  set of  signals  represented  in  the model,  so we often use  the words “system” and 
“model”  interchangeably,  although  it  can  sometimes  be  important  to  preserve  the 
distinction  between  something  truly  physical  and  our  representations  of  it  mathe­
matically or in a computer simulation.  We can thus talk of the behavior of a model. 

A mapping model of a system comprises the following:  a set of input signals {xi (t)}, 
each  of  which  can  vary  within  some  speciﬁed  range  of  possibilities;  similarly,  a  set 
of  output  signals {yj (t)},  each  of which  can vary;  and  a description  of  the mapping 
that  uniquely  deﬁnes  the  output  signals  as  a  function  of  the  input  signals.  As  an 
example,  consider  the  following  single-input,  single-output  system: 

x(t) 

�

T { · } 

� 

y(t) = x(t − t0 )

FIGURE  2.1  Name-Mapping Model 

Given  the  input  x(t)  and  the mapping  T { · },  the  output  y(t)  is  unique,  and  in  this 
example  equals  the  input  delayed  by  t0 . 
A behavioral model for a set of signals {wi (t)} comprises a  listing of the constraints 
that  the  wi (t)  must  satisfy.  The  constraints  on  the  voltages  across  and  currents 
through the components in an electrical circuit,  for example, are speciﬁed by Kirch­
hoﬀ ’s  laws,  and  the  deﬁning  equations  of  the  components.  There  can  be  inﬁnitely 
many  combinations  of  voltages  and  currents  that  will  satisfy  these  constraints. 

2.1.1  System/Model  Properties 

For  a  system  or  model  speciﬁed  as  a  mapping,  we  have  the  following  deﬁnitions 
of  various  properties,  all  of  which  we  assume  are  familiar.  They  are  stated  here 
for  the  DT  case  but  easily  modiﬁed  for  the  CT  case.  (We  also  assume  a  single 
input  signal  and  a  single  output  signal  in  our  mathematical  representation  of  the 
deﬁnitions  below,  for  notational  convenience.) 

• 

• 

Memoryless  or Algebraic  or Non-Dynamic:  The  outputs  at  any  instant 
do  not  depend  on  values  of  the  inputs  at  any  other  instant:  y [n0 ] = T {x[n0 ]}
for  all  n0 . 

Linear:  The response to an arbitrary linear combination (or “superposition”) 
of  inputs  signals  is  always  the  same  linear  combination  of  the  individual  re­
sponses  to  these  signals:  T {axA [n] + bxB [n]} =  aT {xA [n]} + bT {xB [n]},  for 
all  xA ,  xB ,  a  and  b. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.1 

Signals,  Systems,  Models,  Properties  23 

x(t) 

+ 
− 

�y(t) 

FIGURE  2.2  RLC  Circuit 

•	 Time-Invariant:  The  response  to  an  arbitrarily  translated  set  of  inputs  is 
always  the  response  to  the  original  set,  but  translated  by  the  same  amount: 
If  x[n] 
y [n]  then  x[n − n0 ] 
→	
y [n − n0 ]  for  all  x  and  n0 .
→ 
•	 Linear  and Time-Invariant  (LTI): The system, model or mapping  is both 
linear  and  time-invariant. 
•	 Causal:  The  output  at  any  instant  does  not  depend  on  future  inputs:  for  all 
n0 ,  y [n0 ]  does  not  depend  on  x[n]  for  n > n0 .  Said  another  way,  if  xb[n], yb[n] 
denotes another  input-output pair of the  system, with xb[n] = x[n]  for n ≤ n0 , 
then  it  must  be  also  true  that  yb[n] =  y [n]  for  n  ≤  n0 .  (Here  n0  is  arbitrary 
but  ﬁxed.) 
•	 BIBO  Stable:  The response to a bounded input is always bounded:  |x[n]| ≤
Mx  < ∞  for  all  n  implies  that  |y [n]| ≤ My  < ∞  for  all  n. 

EXAMPLE  2.1 

System  Properties 

Consider  the  system  with  input  x[n]  and  output  y [n]  deﬁned  by  the  relationship 

y [n] = x[4n + 1]	

(2.1) 

We  would  like  to  determine  whether  or  not  the  system  has  each  of  the  following 
properties:  memoryless,  linear,  time-invariant,  causal,  and  BIBO  stable. 

memoryless:  a  simple  counter  example  suﬃces.  For  example,  y [0]  =  x[1],  i.e.  the 
output  at  n =  0  depends  on  input  values  at  times  other  than  at  n =  0.  Therefore 
it  is  not  memoryless. 

linear:  To  check  for  linearity,  we  consider  two  diﬀerent  inputs,  xA [n]  and  xB [n], 
and  compare  the  output  of  their  linear  combination  to  the  linear  combination  of 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

24  Chapter  2 

Signals  and  Systems 

their  outputs. 

xA [n] 
xB [n] 
xC [n] = (axA [n] + bxB [n]) 

→ 
→ 
→ 
If  yC [n] = ayA [n] + byB [n],  then  the  system  is  linear.  This  clearly  happens  in  this 
case. 

xA [4n + 1] = yA [n]
xB [4n + 1] = yB [n]
(axA [4n + 1] + bxB [4n + 1]) = yC [n]

time-invariant:  To  check  for  time-invariance,  we  need  to  compare  the  output  due 
to  a  time-shifted  version  of  x[n]  to  the  time-shifted  version  of  the  output  due  to 
x[n]. 

x[n] 
xB [n] = x[n + n0 ] 

→ 
→ 
We now need to compare y [n] time-shifted by n0  (i.e.  y [n + n0 ]) to yB [n].  If they’re 
not  equal,  then  the  system  is  not  time-invariant. 

x[4n + 1] = y [n]
x[4n + n0  + 1] = yB [n]

y [n + n0 ] =  x[4n + 4n0  + 1] 
yB [n] =  x[4n + n0  + 1] 

but 

Consequently, the system is not time-invariant.  To illustrate with a speciﬁc counter­
example,  suppose  that  x[n]  is  an  impulse,  δ [n],  at  n =  0.  In  this  case,  the  output, 
yδ [n],  would  be  δ [4n + 1],  which  is  zero  for  all  values  of  n,  and  y [n + n0 ]  would 
likewise  always  be  zero.  However,  if  we  consider  x[n + n0 ] = δ [n + n0 ],  the  output 
will  be  δ [4n + 1 + n0 ],  which  for  n0  = 3  will  be  one  at  n = −4  and  zero  otherwise. 
causal:  Since  the  output  at  n  =  0  is  the  input  value  at  n  =  1,  the  system  is  not 
causal. 

BIBO  stable:  Since  y [n] =  x[4n + 1] and  the maximum value  for all n of x[n] and 
|
|
|
|
x[4n + 1]  is  the  same,  the  system  is  BIBO  stable. 

2.2  LINEAR,  TIME-INVARIANT  SYSTEMS 

2.2.1 

Impulse-Response  Representation  of  LTI  Systems 

Linear,  time-invariant  (LTI)  systems  form  the  basis  for  engineering  design  in many 
situations.  They have the advantage that there is a rich and well-established theory 
for analysis and design of  this  class of  systems.  Furthermore,  in many  systems  that 
are  nonlinear,  small  deviations  from  some  nominal  steady  operation  are  approxi­
mately governed by LTI models,  so  the  tools of LTI  system analysis and design  can 
be  applied  incrementally  around  a  nominal  operating  condition. 

A  very  general  way  of  representing  an  LTI  mapping  from  an  input  signal  x  to 
an  output  signal  y  is  through  convolution  of  the  input  with  the  system  impulse 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.2 

Linear,  Time-Invariant  Systems  25 

∞ 

y(t) = 

response.  In  CT  the  relationship  is 
Z 
x(τ )h(t − τ )dτ 
−∞ 
where  h(t)  is  the  unit  impulse  response  of  the  system.  In  DT,  we  have 
y [n] =  X 
∞
x[k ] h[n − k ] 
k=−∞ 
where  h[n]  is  the  unit  sample  (or  unit  “impulse”)  response  of  the  system. 

(2.2) 

(2.3) 

A  common  notation  for  the  convolution  integral  in  (2.2)  or  the  convolution  sum  in 
(2.3)  is  as 

y(t) = x(t) ∗ h(t) 
y [n] = x[n] ∗ h[n] 
While  this  notation  can  be  convenient,  it  can  also  easily  lead  to  misinterpretation 
if  not  well  understood. 

(2.4) 
(2.5) 

The  characterization  of  LTI  systems  through  the  convolution  is  obtained  by  repre­
senting  the  input  signal  as  a  superposition  of  weighted  impulses.  In  the  DT  case, 
suppose  we  are  given  an  LTI  mapping  whose  impulse  response  is  h[n],  i.e.,  when 
its  input  is  the unit  sample or unit “impulse”  function δ [n],  its output  is h[n].  Now 
a  general  input  x[n]  can  be  assembled  as  a  sum  of  scaled  and  shifted  impulses,  as 
follows: 
x[n] =  X 
∞
x[k ] δ [n − k ] 
k=−∞ 
The  response  y [n]  to  this  input,  by  linearity  and  time-invariance,  is  the  sum  of 
the  similarly  scaled  and  shifted  impulse  responses,  and  is  therefore  given  by  (2.3). 
What  linearity  and  time-invariance  have  allowed  us  to  do  is  write  the  response  to 
a  general  input  in  terms  of  the  response  to  a  special  input.  A  similar  derivation 
holds  for  the  CT  case. 

(2.6) 

It  may  seem  that  the  preceding  derivation  shows  all  LTI  mappings  from  an  in­
put  signal  to  an  output  signal  can  be  represented  via  a  convolution  relationship. 
However,  the  use  of  inﬁnite  integrals  or  sums  like  those  in  (2.2),  (2.3)  and  (2.6) 
actually  involves  some  assumptions  about  the  corresponding  mapping.  We  make 
no  attempt  here  to  elaborate  on  these  assumptions.  Nevertheless,  it  is  not  hard 
to  ﬁnd  “pathological”  examples  of  LTI  mappings  —  not  signiﬁcant  for  us  in  this 
course,  or  indeed  in most  engineering models — where  the convolution  relationship 
does  not  hold  because  these  assumptions  are  violated. 

It  follows  from  (2.2)  and  (2.3)  that  a  necessary  and  suﬃcient  condition  for  an  LTI 
system  to  be  BIBO  stable  is  that  the  impulse  response  be  absolutely  integrable 
(CT)  or  absolutely  summable  (DT),  i.e., 
Z 
∞ 
−∞  |h(t)|dt < ∞ 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

BIBO  stable  (CT)  ⇐⇒ 

26  Chapter  2 

Signals  and  Systems 

BIBO  stable  (DT) 

X 
∞
| < ∞ 
|
h[n]
n=−∞ 
It  also  follows  from  (2.2)  and  (2.3)  that  a  necessary  and  suﬃcient  condition  for  an 
LTI  system  to  be  causal  is  that  the  impulse  response  be  zero  for  t < 0  (CT)  or  for 
n < 0  (DT) 

⇐⇒ 

2.2.2  Eigenfunction  and  Transform  Representation  of  LTI  Systems 

Exponentials  are  eigenfunctions  of  LTI  mappings,  i.e.,  when  the  input  is  an  expo­
nential  for all  time, which we  refer  to as an “everlasting” exponential,  the output  is 
simply  a  scaled  version  of  the  input,  so  computing  the  response  to  an  exponential 
reduces  to  just multiplying  by  the  appropriate  scale  factor.  Speciﬁcally,  in  the  CT 
case,  suppose 

x(t) = e s0 t 

(2.7) 

for  some  possibly  complex  value  s0  (termed  the  complex  frequency).  Then  from 
(2.2) 

= 

y(t) = h(t) ∗ x(t) 
Z 
∞ 
h(τ )x(t − τ )dτ 
= 
−∞Z 
∞ 
h(τ )e s0 (t−τ )dτ 
−∞ 
= H (s0 )e s0 t 
Z 
−∞ 
provided  the  above  integral  has  a  ﬁnite  value  for  s = s0  (otherwise  the  response  to 
the exponential is not well deﬁned).  Note that this integral is precisely the bilateral 
Laplace  transform  of  the  impulse  response,  or  the  transfer  function  of  the  system, 
and  the  (interior of  the)  set of values of s  for which  the above  integral  takes a ﬁnite 
value  constitutes  the  region  of  convergence  (ROC)  of  the  transform. 

h(τ )e−sτ dτ 

where 

∞ 

H (s) = 

(2.8) 

(2.9) 

From  the  preceding  discussion,  one  can  recognize  what  special  property  of  the 
everlasting  exponential  causes  it  to  be  an  eigenfunction  of  an  LTI  system:  it  is 
the  fact  that  time-shifting  an  everlasting  exponential  produces  the  same  result  as 
scaling  it  by  a  constant  factor.  In  contrast,  the  one-sided  exponential  es0 tu(t) — 
where  u(t)  denotes  the  unit  step  —  is  in  general  not  an  eigenfunction  of  an  LTI 
mapping:  time-shifting  a  one-sided  exponential  does  not  produce  the  same  result 
as  scaling  this  exponential. 

When x(t) = ejωt , corresponding to having s0  take the purely imaginary value jω  in 
(2.7), the input is bounded for all positive and negative time, and the corresponding 
output  is 

y(t) = H (jω)ejωt 

(2.10) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Linear,  Time-Invariant  Systems  27 

where 

EXAMPLE  2.2 

Section  2.2 
Z 
−∞ 
Eigenfunctions  of  LTI  Systems 

H (jω) = 

∞ 

h(t)e−jωt dt 

(2.11) 

While  as  demonstrated  above,  the  everlasting  complex  exponential,  ejωt ,  is  an 
eigenfunction  of  any  stable  LTI  system,  it  is  important  to  recognize  that  ejωtu(t) 
is  not.  Consider,  as  a  simple  example,  a  time  delay,  i.e. 

y(t) = x(t − t0 ) 
The  output  due  to  the  input  ejωtu(t)  is 

(2.12) 

e−jωt0  +jωtu(t − t0 )
e 
This is not a simple scaling of the input, so ejωtu(t) is not in general an eigenfunction 
of  LTI  systems. 

The  function  H (jω)  in  (2.10)  is  the  system  frequency  response,  and  is  also  the 
continuous-time  Fourier  transform  (CTFT)  of  the  impulse  response.  The  integral 
that  deﬁnes  the  CTFT  has  a  ﬁnite  value  (and  can  be  shown  to  be  a  continuous 
function  of  ω)  if  h(t)  is  absolutely  integrable,  i.e.  provided 
Z  +∞ 
|h(t)| dt < ∞
−∞ 
We have noted that this condition is equivalent to the system being bounded-input, 
bounded-output  (BIBO)  stable.  The CTFT  can also be deﬁned  for  signals  that are 
not  absolutely  integrable,  e.g.,  for  h(t)  =  (sin t)/t  whose  CTFT  is  a  rectangle  in 
the  frequency  domain,  but  we  defer  examination  of  conditions  for  existence  of  the 
CTFT. 

We  can  similarly  examine  the  eigenfunction  property  in  the  DT  case.  A  DT  ever­
lasting  “exponential”  is  a  geometric  sequence  or  signal  of  the  form 

n 
x[n] = z0 

(2.13) 

for  some  possibly  complex  z0  (termed  the  complex  frequency).  With  this  DT  ex­
ponential  input,  the  output  of  a  convolution  mapping  is  (by  a  simple  computation 
that  is  analogous  to  what  we  showed  above  for  the  CT  case) 

where 

n 
y [n] = h[n] ∗ x[n] = H (z0 )z0 
H (z ) =  X 
∞
h[k ]z−k 
k=−∞ 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(2.14) 

(2.15) 

28  Chapter  2 

Signals  and  Systems 

provided  the  above  sum  has  a  ﬁnite  value  when  z  =  z0 .  Note  that  this  sum  is 
precisely  the  bilateral  Z -transform  of  the  impulse  response,  and  the  (interior  of 
the)  set  of  values  of  z  for  which  the  sum  takes  a  ﬁnite  value  constitutes  the  ROC 
of  the  Z -transform.  As  in  the  CT  case,  the  one-sided  exponential  z0 
nu[n]  is  not  in 
general  an  eigenfunction. 
Again,  an  important  case  is  when  x[n] = (ejΩ )n  =  ejΩn ,  corresponding  to  z0  in 
(2.13)  having  unit  magnitude  and  taking  the  value  ejΩ ,  where  Ω  —  the  (real) 
“frequency”  —  denotes  the  angular  position  (in  radians)  around  the  unit  circle  in 
the  z -plane.  Such  an  x[n]  is  bounded  for  all  positive  and  negative  time.  Although 
we  use  a  diﬀerent  symbol,  Ω,  for  frequency  in  the  DT  case,  to  distinguish  it  from 
the  frequency ω  in  the CT  case,  it  is  not  unusual  in  the  literature  to  ﬁnd ω  used  in 
both  CT  and  DT  cases  for  notational  convenience.  The  corresponding  output  is 
y [n] = H (ejΩ )ejΩn 
H (ejΩ ) =  X 
∞
n=−∞ 
The  function  H (ejΩ )  in  (2.17)  is  the  frequency  response  of  the  DT  system,  and  is 
also the discrete-time Fourier transform (DTFT) of the  impulse response.  The sum 
that  deﬁnes  the  DTFT  has  a  ﬁnite  value  (and  can  be  shown  to  be  a  continuous 
function  of  Ω)  if  h[n]  is  absolutely  summable,  i.e.,  provided 
∞X 
n=−∞ 
We noted that this condition is equivalent to the system being BIBO stable.  As with 
the CTFT,  the DTFT can be deﬁned  for  signals  that are not absolutely  summable; 
we  will  elaborate  on  this  later. 

| h[n] | < ∞ 

h[n]e−jΩn 

where 

(2.16) 

(2.17) 

(2.18) 

Note  from  (2.17)  that  the  frequency  response  for  DT  systems  is  always  periodic, 
with  period  2π .  The  “high-frequency”  response  is  found  in  the  vicinity  of Ω = ±π , 
which  is  consistent  with  the  fact  that  the  input  signal  e±jπn  = (−1)n  is  the  most 
rapidly  varying  DT  signal  that  one  can  have. 

When  the  input  of  an  LTI  system  can  be  expressed  as  a  linear  combination  of 
bounded  eigenfunctions,  for  instance  (in  the  CT  case), 
x(t) = X 
jωℓ t 
aℓ e
ℓ 
then,  by  linearity,  the  output  is  the  same  linear  combination  of  the  responses  to 
the  individual  exponentials.  By  the  eigenfunction  property  of  exponentials  in  LTI 
systems,  the  response  to  each  exponential  involves  only  scaling  by  the  system’s 
frequency  response.  Thus 
y(t) = X 
jωℓ t 
aℓH (jωℓ )e
ℓ 
Similar  expressions  can  be  written  for  the  DT  case. 

(2.19) 

(2.20) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

2.2.3  Fourier  Transforms 

Section  2.2 

Linear,  Time-Invariant  Systems  29 

∞ 

x(t) = 

X (jω) = 

(synthesis) 

jωtdω 
X (jω) e

A broad class of input signals can be represented as linear combinations of bounded 
exponentials,  through  the  Fourier  transform.  The  synthesis/analysis  formulas  for 
the  CTFT  are 
1  Z 
2π 
−∞
Z 
∞ 
x(t) e−jωtdt 
−∞ 
Note  that  (2.21)  expresses  x(t)  as  a  linear  combination  of  exponentials —  but  this 
weighted  combination  involves  a  continuum  of  exponentials,  rather  than  a  ﬁnite  or 
countable  number.  If  this  signal  x(t)  is  the  input  to  an  LTI  system  with  frequency 
response  H (jω),  then  by  linearity  and  the  eigenfunction  property  of  exponentials 
the output is the same weighted combination of the responses to these exponentials, 
so 
1  Z 
2π 
−∞ 
By  viewing  this  equation  as  a  CTFT  synthesis  equation,  it  follows  that  the  CTFT 
of  y(t)  is 

jωt dω 
H (jω)X (jω) e

(2.21) 

(2.22) 

(analysis) 

y(t) = 

∞ 

(2.23) 

Y (jω) = H (jω)X (jω) 

(2.24) 

Correspondingly,  the  convolution  relationship  (2.2)  in  the  time  domain  becomes 
multiplication in the transform domain.  Thus, to ﬁnd the response Y  at a particular 
frequency  point,  we  only  need  to  know  the  input  X  at  that  single  frequency,  and 
the  frequency  response  of  the  system  at  that  frequency.  This  simple  fact  serves,  in 
large  measure,  to  explain  why  the  frequency  domain  is  virtually  indispensable  in 
the  analysis  of  LTI  systems. 

X (ejΩ ) ejΩndΩ  (synthesis) 

The  corresponding  DTFT  synthesis/analysis  pair  is  deﬁned  by 
1  Z 
x[n] = 
2π  <2π> 
X (ejΩ ) =  X 
∞
x[n] e−jΩn  (analysis) 
n=−∞ 
where the notation < 2π > on the integral in the synthesis formula denotes integra­
tion over any contiguous interval of length 2π , since the DTFT is always periodic in 
Ω with period  2π ,  a  simple  consequence  of  the  fact  that  ejΩ  is periodic with period 
2π .  Note  that  (2.25)  expresses  x[n]  as  a  weighted  combination  of  a  continuum  of 
exponentials. 

(2.25) 

(2.26) 

As  in  the  CT  case,  it  is  straightforward  to  show  that  if  x[n]  is  the  input  to  an  LTI 
mapping,  then  the  output  y [n]  has  DTFT 

Y (ejΩ ) = H (ejΩ )X (ejΩ ) 

(2.27) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

30  Chapter  2 

Signals  and  Systems 

2.3  DETERMINISTIC  SIGNALS  AND  THEIR  FOURIER  TRANSFORMS 

In  this  section we  review  the DTFT of deterministic DT signals  in more detail, and 
highlight  the classes of  signals  that can be guaranteed  to have well-deﬁned DTFTs. 
We  shall  also  devote  some  attention  to  the  energy  density  spectrum  of  signals  that 
have  DTFTs.  The  section  will  bring  out  aspects  of  the  DTFT  that  may  not  have 
been  emphasized  in your  earlier  signals and  systems  course.  A  similar development 
can  be  carried  out  for  CTFTs. 

2.3.1  Signal  Classes  and  their  Fourier  Transforms 

The  DTFT  synthesis  and  analysis  pair  in  (2.25)  and  (2.26)  hold  for  at  least  the 
three  large  classes  of  DT  signals  described  below. 

Finite-Action  Signals.  Finite-action  signals,  which  are  also  called  absolutely 
summable  signals  or  ℓ1  (“ell-one”)  signals,  are  deﬁned  by  the  condition 
∞X  ¯¯¯x[k ]¯¯¯ < ∞ 
k=−∞ 
The  sum  on  the  left  is  called  the  ‘action’  of  the  signal.  For  these  ℓ1  signals,  the 
inﬁnite  sum  that  deﬁnes  the  DTFT  is  well  behaved  and  the  DTFT  can  be  shown 
to  be  a  continuous  function  for  all  Ω  (so,  in  particular,  the  values  at  Ω = +π  and 
Ω =  −π  are  well-deﬁned  and  equal  to  each  other  —  which  is  often  not  the  case 
when  signals  are  not  ℓ1 ). 

(2.28) 

(2.29) 

Finite-Energy Signals.  Finite-energy signals, which are also called square summable 
or  ℓ2  (“ell-two”)  signals,  are  deﬁned  by  the  condition 
∞X  ¯¯¯x[k ]¯¯¯  < ∞ 
2
k=−∞ 
The  sum  on  the  left  is  called  the  ‘energy’  of  the  signal. 
In discrete-time, an absolutely summable (i.e., ℓ1 ) signal is always square summable 
(i.e.,  ℓ2 ).  (In  continuous-time,  the  story  is  more  complicated:  an  absolutely  inte­
grable signal need not be square  integrable,  e.g.,  consider x(t) = 1/√t  for 0 < t ≤ 1 
and  x(t)  =  0  elsewhere;  the  source  of  the  problem  here  is  that  the  signal  is  not 
bounded.)  However,  the  reverse  is  not  true.  For  example,  consider  the  signal 
(sin Ωcn)/πn  for 0 < Ωc  < π , with  the value at n = 0  taken  to be Ωc /π ,  or consider 
the  signal  (1/n)u[n − 1],  both  of  which  are  ℓ2  but  not  ℓ1 .  If  x[n]  is  such  a  signal, 
its  DTFT  X (ejΩ )  can  be  thought  of  as  the  limit  for  N  → ∞  of  the  quantity 
XN (ejΩ ) =  X 
N
x[k ]e−jΩk 
(2.30) 
k=−N 
and  the  resulting  limit  will  typically  have  discontinuities  at  some  values  of  Ω.  For 
instance,  the  transform  of  (sin Ωcn)/πn  has  discontinuities  at  Ω = ±Ωc . 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.3 

Deterministic  Signals  and  their  Fourier  Transforms  31 

Signals  of  Slow  Growth.  Signals  of  ‘slow’  growth  are  signals whose magnitude 
grows  no  faster  than  polynomially  with  the  time  index,  e.g.,  x[n] = n  for  all  n.  In 
this  case  XN (ejΩ )  in  (2.30)  does  not  converge  in  the  usual  sense,  but  the  DTFT 
still  exists  as  a  generalized  (or  singularity)  function;  e.g.,  if  x[n] = 1  for  all  n,  then 
X (ejΩ ) = 2πδ(Ω)  for  |Ω| ≤ π . 
Within  the  class of  signals of  slow growth,  those of most  interest  to us are bounded 
(or  ℓ
)  signals: 
∞
¯¯¯x[k ]¯¯¯ ≤ M < ∞ 
i.e.,  signals  whose  amplitude  has  a  ﬁxed  and  ﬁnite  bound  for  all  time.  Bounded 
everlasting  exponentials  of  the  form  ejΩ0 n ,  for  instance,  play  a  key  role  in  Fourier 
transform  theory.  Such  signals  need  not  have  ﬁnite  energy,  but  will  have  ﬁnite 
average power over any time interval, where average power is deﬁned as total energy 
over  total  time. 

(2.31) 

(2.32) 

Similar  classes  of  signals  are  deﬁned  in  continuous-time.  Speciﬁcally,  ﬁnite-action 
(or  L1 )  signals  comprise  those  that  are  absolutely  integrable,  i.e., 
Z 
∞  ¯¯¯x(t)¯¯¯dt < ∞ 
−∞ 
Finite-energy  (or  L2 )  signals  comprise  those  that  are  square  summable,  i.e., 
Z 
∞  ¯¯¯x(t)¯¯¯  < ∞ 
2
−∞ 
And  signals  of  slow  growth  are  ones  for  which  the magnitude  grows  no  faster  than 
polynomially  with  time.  Bounded  (or  L )  continuous-time  signals  are  those  for 
∞
which  the  magnitude  never  exceeds  a  ﬁnite  bound  M  (so  these  are  slow-growth 
signals as well).  These may again not have ﬁnite energy, but will have ﬁnite average 
power  over  any  time  interval. 

(2.33) 

In both continuous-time and discrete-time there are many  important Fourier trans­
form pairs and Fourier  transform properties developed and  tabulated  in basic  texts 
on signals and systems (see,  for example, Chapters 4 and 5 of Oppenheim and Will-
sky).  For  convenience,  we  include  here  a  brief  table  of  DTFT  pairs.  Other  pairs 
are  easily derived  from  these by applying various DTFT properties.  (Note  that  the 
δ ’s  in  the  left  column denote unit  samples, while  those  in  the  right  column  are unit 
impulses!) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

32  Chapter  2 

Signals  and  Systems 

DT  Signal 

←→ 

DTFT  for  − π < Ω ≤ π

1←→ 
δ [n]
δ [n − n0 ] ←→ e−jΩn0 
1  (for  all  n)
2πδ(Ω) 
←→ 
ejΩ0 n  (−π < Ω0  ≤ π)
2πδ(Ω − Ω0 )
←→ 
1 
a n u[n]  ,  a < 1
| |  ←→ 
1 − ae−jΩ 
1 
+ πδ(Ω) 
←→ 
u[n]
Ω 
½ 1 −
e−j
sin Ωcn 
Ωc  < Ω < Ωc 
−
1,
πn  ←→ 
0,  otherwise 
1,  −M  ≤ n ≤ M  ¾ 
sin[Ω(2M  + 1)/2] 
0,  otherwise 
sin(Ω/2) 

←→ 

In  general  it  is  important  and  useful  to  be  ﬂuent  in  deriving  and  utilizing  the 
main  transform  pairs  and  properties.  In  the  following  subsection  we  discuss  a 
particular  property,  Parseval’s  identity,  which  is  of  particular  signiﬁcance  in  our 
later  discussion. 

There are, of course, other classes of signals that are of interest to us in applications, 
for  instance  growing  one-sided  exponentials.  To  deal  with  such  signals,  we  utilize 
Z -transforms  in  discrete-time  and  Laplace  transforms  in  continuous-time. 

2.3.2  Parseval’s  Identity,  Energy  Spectral  Density,  Deterministic  Autocorrelation 

x[n]y∗ [n] = 

X (ejΩ )Y ∗ (ejΩ ) dΩ 

An  important property of the Fourier transform  is Parseval’s  identity for ℓ2  signals. 
For  discrete  time,  this  identity  takes  the  general  form 
1  Z
X 
∞
2π  <2π> 
n=−∞ 
and  for  continuous  time, 
1  Z 
Z 
2π
−∞ 
−∞ 
where  the  ∗  denotes  the  complex  conjugate.  Specializing  to  the  case  where  y [n] = 
x[n]  or  y(t) = x(t),  we  obtain 
1  Z
X 
∞
2π  <2π>  |X (ejΩ )| 2 dΩ 
n=−∞ 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

2 
|x[n]|  =

x(t)y∗ (t)dt  = 

X (jω)Y ∗ (jω) dω 

(2.35) 

∞ 

∞ 

(2.34) 

(2.36) 

Section  2.3 

Deterministic  Signals  and  their  Fourier  Transforms  33 

x[n] 

�  H (ejΩ ) 

�  y [n]

�Δ� 

H (ejΩ ) 
� 
1 

� Δ �

Ω0

� 
Ω

−Ω0 
FIGURE  2.3  Ideal  bandpass  ﬁlter. 
1  Z 
Z 
2π 
−∞ 
−∞ 
Parseval’s  identity  allows  us  to  evaluate  the  energy  of  a  signal  by  integrating  the 
squared  magnitude  of  its  transform.  What  the  identity  tells  us,  in  eﬀect,  is  that 
the  energy  of  a  signal  equals  the  energy  of  its  transform  (scaled  by  1/2π). 

|X (jω)|2 dω 

|x(t)|2  =

(2.37) 

∞ 

∞ 

The  real,  even,  nonnegative  function  of  Ω  deﬁned  by 
S xx (ejΩ ) = |X (ejΩ )|2 

or 

S xx (jω) = |X (jω)| 2 

(2.38) 

(2.39) 

is  referred  to  as  the  energy  spectral  density  (ESD),  because  it  describes  how  the 
energy  of  the  signal  is  distributed  over  frequency.  To  appreciate  this  claim  more 
concretely, for discrete-time, consider applying x[n] to the input of an ideal bandpass 
ﬁlter  of  frequency  response  H (ejΩ )  that  has  narrow  passbands  of  unit  gain  and 
width  Δ  centered  at  ±Ω0  as  indicated  in  Figure  2.3.  The  energy  of  the  output 
signal  must  then  be  the  energy  of  x[n]  that  is  contained  in  the  passbands  of  the 
ﬁlter.  To  calculate  the  energy  of  the  output  signal,  note  that  this  output  y [n]  has 
the  transform 

Y (ejΩ ) = H (ejΩ )X (ejΩ ) 

(2.40) 

Consequently  the  output  energy,  by  Parseval’s  identity,  is  given  by 
π  Z 
X 
∞
1 
|2 dΩ
jΩ )
<2π>  |Y (e
2
n=−∞ 
1  Z 
2π  passband 
Thus the energy of x[n] in any frequency band is given by integrating S xx (ejΩ ) over 
that  band  (and  scaling  by  1/2π).  In  other  words,  the  energy  density  of  x[n]  as  a 

|2 
y [n] = 
|

S xx (ejΩ ) dΩ 

(2.41) 

= 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

34 

 
Chapter 2

 

Signals  and  Systems 

function  of  Ω  is  S xx (Ω)/(2π)  per  radian.  An  exactly  analogous  discussion  can  be 
carried  out  for  continuous-time  signals. 

Since  the  ESD  S xx (ejΩ )  is  a  real  function  of  Ω,  an  alternate  notation  for  it  could 
perhaps  be  Exx (Ω),  for  instance.  However,  we  use  the  notation  S xx (ejΩ )  in  order 
to  make  explicit  that  it  is  the  squared  magnitude  of X (ejΩ )  and  also  the  fact  that 
the  ESD  for  a  DT  signal  is  periodic  with  period  2π . 

Given  the  role  of  the  magnitude  squared  of  the  Fourier  transform  in  Parseval’s 
identity,  it  is  interesting  to  consider what  signal  it  is  the Fourier  transform  of.  The 
answer  for  DT  follows  on  recognizing  that  with  x[n]  real-valued 
|X (ejΩ )|2  = X (ejΩ )X (e−jΩ ) 
(2.42) 
and  that  X (e−jΩ )  is  the  transform  of  the  time-reversed  signal,  x[−k ].  Thus,  since 
multiplication of  transforms  in  the  frequency domain  corresponds  to convolution of 
signals  in  the  time  domain,  we  have 
S xx (ejΩ ) =  |X (ejΩ )|2  ⇐⇒  x[k ] ∗ x[−k ] =  X 
∞
x[n + k ]x[n] = Rxx [k ] 
n=−∞ 
The function Rxx [k ] = x[k ] ∗x[−k ] is referred to as the deterministic autocorrelation 
function  of  the  signal  x[n],  and  we  have  just  established  that  the  transform  of  the 
deterministic  autocorrelation  function  is  the  energy  spectral  density  S xx (ejΩ ).  A 
basic  Fourier  transform  property  tells  us  that  Rxx [0] —  which  is  the  signal  energy 
P∞ 
x2 [n] — is the area under the Fourier transform of Rxx [k ], scaled by 1/(2π), 
n=−∞
namely  the  scaled  area  under S xx (ejΩ ) = |X (ejΩ )|2 ;  this  is  just Parseval’s  identity, 
of  course. 
The deterministic autocorrelation function measures how alike a signal and its time-
shifted version are, in a total-squared-error sense.  More speciﬁcally, in discrete-time 
the  total  squared  error  between  the  signal  and  its  time-shifted  version  is  given  by 
(x[n + k ] − x[n])2  =  X 
X 
∞
∞
2
|x[n + k ]|
n=−∞ 
n=−∞ 
+  X 
|x[n]| − 2  X 
∞
∞
2 
x[n + k ]x[n] 
n=−∞ 
n=−∞ 
= 2(Rxx [0] − Rxx [k ]) 
Since the total squared error is always nonnegative,  it follows that Rxx [k ] ≤ Rxx [0], 
and that the  larger the deterministic autocorrelation Rxx [k ]  is,  the closer the signal 
x[n]  and  its  time-shifted  version  x[n + k ]  are. 
Corresponding  results  hold  in  continuous  time,  and  in  particular 
Z 
∞ 
S xx (jω) = |X (jω)| 2  ⇐⇒  x(τ ) ∗ x(−τ ) = 
−∞ 
where  Rxx (t)  is  the  deterministic  autocorrelation  function  of  x(t). 

x(t + τ )x(t)dt = Rxx (τ )  (2.45) 

(2.43) 

(2.44) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  2.4 

The  Bilateral  Laplace  and  Z -Transforms  35 

2.4  THE  BILATERAL  LAPLACE  AND  Z -TRANSFORMS 
The Laplace and Z -transforms can be thought of as extensions of Fourier transforms 
and are useful for a variety of reasons.  They permit a transform treatment of certain 
classes  of  signals  for  which  the  Fourier  transform  does  not  converge.  They  also 
augment  our  understanding  of  Fourier  transforms  by  moving  us  into  the  complex 
plane,  where  the  theory  of  complex  functions  can  be  applied.  We  begin  in  Section 
2.4.1  with  a  detailed  review  of  the  bilateral  Z -transform.  In  Section  2.4.3  we  give 
a  briefer  review  of  the  bilateral  Laplace  transform,  paralleling  the  discussion  in 
Section  2.4.1. 

2.4.1  The  Bilateral  Z -Transform 
The  bilateral  Z -transform  is  deﬁned  as: 
X (z ) = Z {x[n]} =  X 
∞
x[n]z−n 
n=−∞ 
Here  z  is  a  complex  variable,  which  we  can  also  represent  in  polar  form  as 

(2.46) 

z = rejΩ  ,

so 

(2.47) 

(2.48) 

r ≥ 0 ,  −π < Ω ≤ π 
X (z ) =  X 
∞
x[n]r−n e−jΩn 
n=−∞ 
The  DTFT  corresponds  to  ﬁxing  r  =  1,  in  which  case  z  takes  values  on  the  unit 
circle.  However  there  are  many  useful  signals  for  which  the  inﬁnite  sum  does  not 
converge  (even  in  the  sense  of  generalized  functions)  for  z  conﬁned  to  the  unit 
circle.  The  term  z−n  in  the  deﬁnition  of  the  Z -transform  introduces  a  factor  r−n 
into the inﬁnite sum, which permits the sum to converge (provided r is appropriately 
restricted) for interesting classes of signals, many of which do not have discrete-time 
Fourier  transforms. 
More speciﬁcally, note from (2.48) that X (z ) can be viewed as the DTFT of x[n]r−n . 
If  r >  1,  then  r−n  decays  geometrically  for  positive  n  and  grows  geometrically  for 
negative  n.  For  0  < r <  1,  the  opposite  happens.  Consequently,  there  are  many 
sequences  for which x[n]  is not absolutely  summable but x[n]r−n  is,  for  some  range 
of  values  of  r . 

For  example,  consider  x1 [n] =  anu[n].  If  a >  1,  this  sequence  does  not  have  a 
| |
DTFT.  However,  for  any  a,  x[n]r−n  is  absolutely  summable  provided  r >  a .  In 
| |
particular,  for  example, 

X1 (z ) = 1 + az−1  + a 2 z−2  + 
· · · 
1 
z = r >  a
| | 
| | 
1 − az−1 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

= 

,

(2.49) 

(2.50) 

36  Chapter  2 

Signals  and  Systems 

As  a  second  example,  consider  x2 [n] = −anu[−n − 1].  This  signal  does  not  have  a 
DTFT  if  a < 1.  However,  provided  r <  a ,
| | 
| |
X2 (z ) = −a−1 z − a−2 z 2  − · · · 
1 z 
−
−
a
| | 
| | 
z = r <  a
= 
,
− 
1 
1 z 
−
a
1 
z = r <  a
| | 
| | 
1 − az−1 
The  Z -transforms  of  the  two  distinct  signals  x1 [n]  and  x2 [n]  above  get  condensed 
to  the  same  rational  expressions,  but  for  diﬀerent  regions  of  convergence.  Hence 
the  ROC  is  a  critical  part  of  the  speciﬁcation  of  the  transform. 

(2.52) 

(2.53) 

(2.51) 

= 

,

When  x[n]  is  a  sum  of  left-sided  and/or  right-sided  DT  exponentials,  with  each 
term  of  the  form  illustrated  in  the  examples  above,  then X (z ) will  be  rational  in  z 
(or  equivalently,  in  z−1 ): 

X (z ) = 

Q(z )
P (z ) 

(2.54) 

with  Q(z )  and  P (z )  being  polynomials  in  z . 
Rational Z -transforms are typically depicted by a pole-zero plot in the z -plane, with 
the  ROC  appropriately  indicated.  This  information  uniquely  speciﬁes  the  signal, 
apart  from  a  constant  amplitude  scaling.  Note  that  there  can  be  no  poles  in  the 
ROC,  since  the  transform  is  required  to  be  ﬁnite  in  the  ROC.  Z -transforms  are 
often  written  as  ratios  of  polynomials  in  z−1 .  However,  the  pole-zero  plot  in  the 
z -plane  refers  to  the  polynomials  in  z .  Also  note  that  if  poles  or  zeros  at  z  =  ∞
are  counted,  then  any  ratio  of  polynomials  always  has  exactly  the  same  number  of 
poles  as  zeros. 

Region  of Convergence.  To understand the complex-function properties of the 
Z -transform,  we  split  the  inﬁnite  sum  that  deﬁnes  it  into  non-negative-time  and 
negative-time  portions:  The non-negative-time  or  one-sided Z -transform  is deﬁned 
by 
∞X 
x[n]z−n 
n=0 
and  is  a  power  series  in  z−1 .  The  convergence  of  the  ﬁnite  sum  PN
n=0 x[n]z−n  as 
N  → ∞  is  governed  by  the  radius  of  convergence  R1  ≥  0,  of  the  power  series,  i.e. 
the  series  converges  for  each  z  such  that  z > R1 .  The  resulting  function  of  z  is 
| |
an  analytic  function  in  this  region,  i.e.,  has  a  well-deﬁned  derivative  with  respect 
to  the  complex  variable  z  at  each  point  in  this  region,  which  is  what  gives  the 
function  its  nice  properties.  The  inﬁnite  sum  diverges  for  z < R1 .  The  behavior 
| |
of  the  sum  on  the  circle  z = R1  requires  closer  examination,  and  depends  on  the 
| |
particular  series;  the  series  may  converge  (but  may  not  converge  absolutely)  at  all 
points,  some  points,  or  no  points  on  this  circle.  The  region  z > R1  is  referred  to 
| |
as  the  region  of  convergence  (ROC)  of  the  power  series. 

(2.55) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.4 

The  Bilateral  Laplace  and  Z -Transforms  37 

(2.56) 

Next  consider  the  negative-time  part: 
x[n]z−n  =  X 
X 
−1
∞
m
x[−m]z 
n=−∞ 
m=1 
which  is  a  power  series  in  z ,  and  has  a  radius  of  convergence  R2 .  The  series 
converges  (absolutely)  for  z < R2 ,  which  constitutes  its  ROC;  the  series  is  an 
| |
analytic  function  in  this  region.  The  sum  diverges  for  z > R2 ;  the  behavior  for 
| |
the  circle  z = R2  takes  closer  examination,  and  depends  on  the  particular  series; 
| |
the  series  may  converge  (but  may  not  converge  absolutely)  at  all  points,  some 
points,  or  no  points  on  this  circle.  If  R1  < R2  then  the  Z -transform  converges 
(absolutely)  for  R1  < z < R2 ;  this  annular  region  is  its  ROC,  and  is  denoted  by 
| |
RX .  The  transform  is  analytic  in  this  region.  The  sum  that  deﬁnes  the  transform 
diverges  for  |z |  < R1  and  |z |  > R2 .  If  R1  > R2 ,  then  the  Z -transform  does  not 
exist  (e.g.,  for  x[n] = 0.5nu[−n − 1] + 2nu[n]).  If  R1  =  R2 ,  then  the  transform 
may  exist  in  a  technical  sense,  but  is  not  useful  as  a Z -transform  because  it  has  no 
ROC.  However,  if  R1  =  R2  =  1,  then  we  may  still  be  able  to  compute  and  use  a 
DTFT  (e.g.,  for  x[n] = 3,  all  n;  or  for  x[n] = (sin ω0n)/(πn)). 

Relating  the  ROC  to  Signal  Properties.  For  an  absolutely  summable  signal 
(such  as  the  impulse  response  of  a  BIBO-stable  system),  i.e.,  an  ℓ1 -signal,  the  unit 
circle must  lie  in  the ROC  or must  be  a  boundary  of  the ROC.  Conversely,  we  can 
conclude that a signal is ℓ1  if the ROC contains the unit circle because the transform 
converges  absolutely  in  its  ROC.  If  the  unit  circle  constitutes  a  boundary  of  the 
ROC,  then  further  analysis  is  generally  needed  to  determine  if  the  signal  is  ℓ1 . 
Rational transforms always have a pole on the boundary of the ROC, as elaborated 
on below, so if the unit circle is on the boundary of the ROC of a rational transform, 
then  there  is  a  pole  on  the  unit  circle,  and  the  signal  cannot  be  ℓ1 . 
For a right-sided signal it is the case that R2  = ∞, i.e., the ROC extends everywhere 
in  the  complex  plane  outside  the  circle  of  radius R1 ,  up  to  (and  perhaps  including) 
∞.  The  ROC  includes ∞  if  the  signal  is  0  for  negative  time. 
We  can  state  a  converse  result  if,  for  example,  we  know  the  signal  comprises  only 
sums  of  one-sided  exponentials,  of  the  form  obtained  when  inverse  transforming  a 
rational  transform.  In  this  case,  if  R2  = ∞,  then  the  signal  must  be  right-sided;  if 
the  ROC  includes ∞,  then  the  signal  must  be  causal,  i.e.,  zero  for  n < 0. 
For  a  left-sided  signal,  one  has  R1  =  0,  i.e.,  the  ROC  extends  inwards  from  the 
circle  of  radius  R2 ,  up  to  (and  perhaps  including)  0.  The  ROC  includes  0  if  the 
signal  is  0  for  positive  time. 

In  the  case  of  signals  that  are  sums  of  one-sided  exponentials,  we  have  a  converse: 
if R1  = 0,  then  the  signal must be  left-sided;  if  the ROC  includes  0,  then  the  signal 
must  be  anti-causal,  i.e.,  zero  for  n > 0. 
It  is also  important  to note  that  the ROC cannot contain poles of  the Z -transform, 
because  poles  are  values  of  z  where  the  transform  has  inﬁnite  magnitude,  while 
the  ROC  comprises  values  of  z  where  the  transform  converges.  For  signals  with 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

38	

Chapter  2 

Signals  and  Systems 

rational  transforms,  one  can  use  the  fact  that  such  signals  are  sums  of  one-sided 
exponentials  to  show  that  the  possible  boundaries  of  the ROC  are  in  fact  precisely 
determined  by  the  locations  of  the  poles.  Speciﬁcally: 

(a)	 the  outer  bounding  circle  of  the  ROC  in  the  rational  case  contains  a  pole 
and/or  has  radius  ∞.  If  the  outer  bounding  circle  is  at  inﬁnity,  then  (as  we 
have  already  noted)  the  signal  is  right-sided,  and  is  in  fact  causal  if  there  is 
no  pole  at ∞; 
(b)	 the  inner  bounding  circle  of  the  ROC  in  the  rational  case  contains  a  pole 
and/or  has  radius  0.  If  the  inner  bounding  circle  reduces  to  the  point  0,  then 
(as we  have  already  noted)  the  signal  is  left-sided,  and  is  in  fact  anti-causal  if 
there  is  no  pole  at  0. 

2.4.2  The  Inverse  Z -Transform 
One  way  to  invert  a  rational  Z -transform  is  through  the  use  of  a  partial  fraction 
expansion,  then  either  directly  “recognizeing”  the  inverse  transform  of  each  term 
in  the  partial  fraction  representation,  or  expanding  the  term  in  a  power  series  that 
converges  for  z  in  the  speciﬁed  ROC.  For  example,  a  term  of  the  form 

(2.57) 

1 
1 − az−1	
can  be  expanded  in  a  power  series  in  az−1  if  |a|  <  |z |  for  z  in  the  ROC,  and 
expanded  in  a  power  series  in  a−1 z  if  |a| > |z |  for  z  in  the  ROC.  Carrying  out  this 
procedure  for each  term  in a partial  fraction expansion, we ﬁnd  that  the  signal x[n] 
is  a  sum  of  left-sided  and/or  right-sided  exponentials.  For non-rational  transforms, 
where  there  may  not  be  a  partial  fraction  expansion  to  simplify  the  process,  it  is 
still  reasonable  to  attempt  the  inverse  transformation  by  expansion  into  a  power 
series  consistent  with  the  given  ROC. 
Although we will generally use partial fraction or power series methods to invert Z -
transforms,  there  is an explicit  formula  that  is  similar  to  that of  the  inverse DTFT, 
speciﬁcally, 
π  Z 
¯¯¯z=re
1 
2
π 
−
where  the  constant  r  is  chosen  to  place  z  in  the  ROC,  RX .  This  is  not  the  most 
general  inversion  formula,  but  is  suﬃcient  for  us,  and  shows  that  x[n]  is  expressed 
as  a  weighted  combination  of  discrete-time  exponentials. 
As  is  the  case  for  Fourier  transforms,  there  are many  useful Z -transform  pairs  and 
properties  developed  and  tabulated  in  basic  texts  on  signals  and  systems.  Appro­
priate  use  of  transform  pairs  and  properties  is  often  the  basis  for  obtaining  the 
Z -transform  or  the  inverse  Z -transform  of  many  other  signals. 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

X (z )z n dω

(2.58) 

π

x[n] = 

jω 

Section  2.4 

The  Bilateral  Laplace  and  Z -Transforms  39 

2.4.3  The  Bilateral  Laplace  Transform 

X (s) = 

(2.59) 

x(t) e−st dt 

As  with  the  Z -transform,  the  Laplace  transform  is  introduced  in  part  to  handle 
important  classes  of  signals  that  don’t  have CTFT’s,  but  also  enhances  our  under­
standing  of  the  CTFT.  The  deﬁnition  of  the  Laplace  transform  is 
Z 
∞ 
−∞ 
where  s  is  a  complex  variable,  s  =  σ + jω .  The  Laplace  transform  can  thus  be 
thought  of  as  the  CTFT  of  x(t) e−σt .  With  σ  appropriately  chosen,  the  integral 
(2.59)  can  exist  even  for  signals  that  have  no  CTFT. 
The development of the Laplace transform parallels closely that of the Z -transform 
in  the  preceding  section,  but  with  eσ  playing  the  role  that  r  did  in  Section  2.4.1. 
The  (interior  of  the)  set  of  values  of  s  for  which  the  deﬁning  integral  converges, 
as  the  limits  on  the  integral  approach  ±∞,  comprises  the  region  of  convergence 
(ROC)  for  the  transform X (s).  The ROC  is  now  determined  by  the minimum  and 
maximum allowable values of σ , say σ1  and σ2  respectively.  We refer to σ1 , σ2  as the 
abscissa of  convergence.  The corresponding ROC  is a vertical  strip between σ1  and 
σ2  in  the  complex  plane,  σ1  <  Re(s)  < σ2 .  Equation  (2.59)  converges  absolutely 
within  the  ROC;  convergence  at  the  left  and  right  bounding  vertical  lines  of  the 
strip  has  to  be  separately  examined.  Furthermore,  the  transform  is  analytic  (i.e., 
diﬀerentiable  as  a  complex  function)  throughout  the  ROC.  The  strip  may  extend 
to  σ1  = −∞  on  the  left,  and  to  σ2  = +∞  on  the  right.  If  the  strip  collapses  to  a 
line  (so  that  the  ROC  vanishes),  then  the  Laplace  transform  is  not  useful  (except 
if  the  line  happens  to  be  the  jω  axis,  in  which  case  a  CTFT  analysis  may  perhaps 
be  recovered). 

For  example,  consider  x1 (t) =  eatu(t);  the  integral  in  (2.59)  evaluates  to  X1 (s) = 
1/(s − a)  provided  Re{s}  > a.  On  the  other  hand,  for  x2 (t) =  −eatu(−t),  the 
integral  in  (2.59)  evaluates  to  X2 (s) = 1/(s − a)  provided  Re{s} < a.  As  with  the 
Z -transform,  note  that  the  expressions  for  the  transforms  above  are  identical;  they 
are  distinguished  by  their  distinct  regions  of  convergence. 

The  ROC  may  be  related  to  properties  of  the  signal.  For  example,  for  absolutely 
integrable  signals,  also  referred  to  as  L1  signals,  the  integrand  in  the  deﬁnition  of 
the  Laplace  transform  is  absolutely  integrable  on  the  jω  axis,  so  the  jω  axis  is  in 
the  ROC  or  on  its  boundary.  In  the  other  direction,  if  the  jω  axis  is  strictly  in 
the  ROC,  then  the  signal  is  L1 ,  because  the  integral  converges  absolutely  in  the 
ROC. Recall  that  a  system  has  an  L1  impulse  response  if  and  only  if  the  system  is 
BIBO  stable,  so  the  result  here  is  relevant  to  discussions  of  stability:  if  the  jω  axis 
is  strictly  in  the  ROC  of  the  system  function,  then  the  system  is  BIBO  stable. 

For  right-sided  signals,  the  ROC  is  some  right-half-plane  (i.e.  all  s  such  that 
Re{s}  > σ1 ).  Thus  the  system  function  of  a  causal  system  will  have  an  ROC 
that  is  some  right-half-plane.  For  left-sided  signals,  the  ROC  is  some  left-half­
plane.  For  signals  with  rational  transforms,  the  ROC  contains  no  poles,  and  the 
boundaries of  the ROC will have poles.  Since  the  location  of  the ROC of a  transfer 
function relative to the imaginary axis relates to BIBO stability, and since the poles 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

40  Chapter  2 

Signals  and  Systems 

identify  the  boundaries  of  the  ROC,  the  poles  relate  to  stability.  In  particular,  a 
system  with  a  right-sided  impulse  response  (e.g.,  a  causal  system)  will  be  stable 
if  and  only  if  all  its  poles  are  in  the  left-half-plane,  because  this  is  precisely  the 
condition  that  allows  the  ROC  to  contain  the  imaginary  axis.  Also  note  that  a 
signal  with  a  rational  transform  is  causal  if  and  only  if  it  is  right-sided. 

A  further  property  worth  recalling  is  connected  to  the  fact  that  exponentials  are 
eigenfunctions  of  LTI  systems.  If  we  denote  the  Laplace  transform  of  the  impulse 
response  h(t)  of  an  LTI  system  by  H (s),  referred  to  as  the  system  function  or 
transfer  function,  then  es0 t  at  the  input  of  the  system  yields  H (s0 ) es0 t  at  the 
output,  provided  s0  is  in  the  ROC  of  the  transfer  function. 

2.5  DISCRETE-TIME  PROCESSING  OF  CONTINUOUS-TIME  SIGNALS 

Many modern systems for applications such as communication, entertainment, nav­
igation  and  control  are  a  combination  of  continuous-time  and discrete-time  subsys­
tems,  exploiting  the  inherent  properties  and  advantages  of  each.  In  particular,  the 
discrete-time processing of continuous-time  signals  is common  in  such applications, 
and we describe the essential  ideas behind such processing here.  As with the earlier 
sections,  we  assume  that  this  discussion  is  primarily  a  review  of  familiar  material, 
included here  to establish notation and  for convenient  reference  from  later chapters 
in  this  text.  In  this  section,  and  throughout  this  text,  we will  often  be  relating  the 
CTFT of a continuous-time signal and the DTFT of a discrete-time signal obtained 
from  samples  of  the  continuous-time  signal.  We  will  use  the  subscripts  c  and  d 
when  necessary  to  help  keep  clear  which  signals  are  CT  and  which  are  DT. 

2.5.1  Basic  Structure  for  DT  Processing  of  CT  Signals 

The  basic  structure  is  shown  in  Figure  2.4.  As  indicated,  the  processing  involves 
continuous-to-discrete or C/D conversion to obtain a sequence of samples of the CT 
signal, then DT ﬁltering to produce a sequence of samples of the desired CT output, 
then discrete-to-continuous or D/C conversion to reconstruct this desired CT signal 
from  the  sequence  of  samples.  We  will  often  restrict  ourselves  to  conditions  such 
that the overall system in Figure 2.4 is equivalent to an LTI continuous-time system. 
The  necessary  conditions  for  this  typically  include  restricting  the  DT  ﬁltering  to 
be LTI processing by a system with  frequency response Hd (ejΩ ), and also requiring 
that the input xc (t) be appropriately bandlimited.  To satisfy the latter requirement, 
it  is  typical  to  precede  the  structure  in  the  ﬁgure  by  a  ﬁlter  whose  purpose  is  to 
ensure  that  xc (t)  is  essentially  bandlimited.  While  this  ﬁlter  is  often  referred  to  as 
an anti-aliasing ﬁlter, we can often allow  some aliasing  in the C/D conversion  if the 
discrete-time  system  removes  the  aliased  components;  the  overall  system  can  then 
still  be  a  CT  LTI  system. 

The  ideal  C/D  converter  in  Figure  2.4  has  as  its  output  a  sequence  of  samples  of 
xc (t) with a speciﬁed sampling interval T1 , so that the DT signal is xd [n] = xc (nT1 ). 
Conceptually,  therefore,  the  ideal  C/D  converter  is  straightforward.  A  practical 
analog-to-digital  (or  A/D)  converter  also  quantizes  the  signal  to  one  of  a  ﬁnite  set 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  2.5 

Discrete-Time  Processing  of  Continuous-Time  Signals  41 

of  output  levels.  However,  in  this  text  we  do  not  consider  the  additional  eﬀects  of 
quantization. 

Hc (jω) 

�x[n] 

Hd (ejΩ ) 

�y [n] 

�yc (t) 

D/C 

� 
T2 

xc (t)�  C/D 
� 
T1 

FIGURE  2.4  DT  processing  of  CT  signals. 
In  the  frequency  domain,  the CTFT  of xc (t)  and  the DTFT  of xd [n]  are  related  by 
¯¯¯¯¯Ω=ωT1 
2π ¶ 
Xc µ 
1  X 
Xd ¡ejΩ ¢ 
jω − j k 
. 
T1 
T1 
k 
When  xc (t)  is  suﬃciently  bandlimited  so  that 
Xc (jω) = 0  ,

(2.60) 

(2.61) 

=

ω|

| ≥ 

π 
T1 

= 

or  equivalently 

then  (2.60)  can  be  rewritten  as 
Xd ¡ejΩ ¢ ¯¯¯¯¯Ω=ωT1 
1 
Xc (jω) 
T1 
Xc µ 
1 ¶ 
Xd ¡ejΩ ¢ 
Ω 
j
T
1 
Note  that  Xd (ejΩ )  is  extended  periodically  outside  the  interval  |Ω| < π .  The  fact 
that  the  above  equalities  hold  under  the  condition  (2.61)  is  the  content  of  the 
sampling  theorem. 

|ω | < π/T1 

|Ω| < π . 

(2.62b) 

(2.62a) 

= 

1 
T

The  ideal D/C  converter  in Figure  2.4  is  deﬁned  through  the  interpolation  relation 
yc (t) = X 
sin (π (t − nT2 ) /T2 ) 
yd [n]
π(t − nT2 )/T2 
n 
which shows that yc (nT2 ) = yd [n].  Since each term in the above sum is bandlimited 
to  ω < π/T2 , the CT signal yc (t) is also bandlimited to this frequency range, so this 
|
|D/C converter is more completely referred to as the ideal bandlimited interpolating 
converter.  (The  C/D  converter  in  Figure  2.4,  under  the  assumption  (2.61),  is 
similarly characterized by  the  fact  that  the CT  signal xc (t)  is  the  ideal bandlimited 
interpolation  of  the  DT  sequence  xd [n].) 

(2.63) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

42  Chapter  2 

Signals  and  Systems 

= 

=

(2.64a) 

or  equivalently 

|ω | < π/T2 

Because yc (t) is bandlimited and yc (nT2 ) = yd [n], analogous relations to (2.62) hold 
between  the  DTFT  of  yd [n]  and  the  CTFT  of  yc (t): 
¯¯¯¯¯Ω=ωT2 
Yd ¡ejΩ ¢ 
1 
Yc (jω) 
T
2 
Ω ¶ 
1  µ 
Yd ¡ejΩ ¢ 
Yc  j
T2 
T2 
One  conceptual  representation  of  the  ideal  D/C  converter  is  given  in  Figure  2.5. 
This ﬁgure interprets (2.63) to be the result of evenly spacing a sequence of impulses 
at  intervals  of  T2  —  the  reconstruction  interval — with  impulse  strengths  given  by 
the  yd [n],  then  ﬁltering  the  result  by  an  ideal  low-pass  ﬁlter L(jω)  of  amplitude  T2 
in  the  passband  ω < π/T2 .  This  operation  produces  the  bandlimited  continuous­
|
|
time signal yc (t) that interpolates the speciﬁed sequence values yd [n] at the instants 
t = nT2 ,  i.e.,  yc (nT2 ) = yd [n]. 

|Ω| < π 

(2.64b) 

D/C 

�yd [n] 

δ [n − k ] → 
δ(t − kT2 ) 

�yp (t) 

L(jω)  �yc (t) 

FIGURE 2.5  Conceptual representation of processes that yield ideal D/C conversion, 
interpolating  a  DT  sequence  into  a  bandlimited  CT  signal  using  reconstruction 
interval  T2 . 

2.5.2  DT  Filtering,  and  Overall  CT  Response 

Suppose  from  now  on,  unless  stated  otherwise,  that  T1  = T2  = T .  If  in  Figure  2.4 
the  bandlimiting  constraint  of  (2.61)  is  satisﬁed,  and  if  we  set  yd [n] =  xd [n],  then 
yc (t) =  xc (t).  More  generally,  when  the  DT  system  in  Figure  2.4  is  an  LTI  DT 
ﬁlter  with  frequency  response Hd ¡ejΩ ¢,  so 
Yd (ejΩ ) = Hd (ejΩ )Xd (ejΩ ) 
and  provided  any  aliased  components  of  xc (t)  are  eliminated  by  Hd (ejΩ ),  then 
assembling  (2.62),  (2.64)  and  (2.65)  yields: 
¯¯¯¯¯Ω=ωT 
Yc (jω) = Hd ¡ejΩ ¢
Xc (jω) 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

|ω | < π/T 

(2.66) 

(2.65) 

Section  2.5 

Discrete-Time  Processing  of  Continuous-Time  Signals  43 

|ω | < π/T . 

The  action  of  the  overall  system  is  thus  equivalent  to  that  of  a  CT  ﬁlter  whose 
frequency  response  is 
¯¯¯¯¯Ω=ωT 
Hc (jω) = Hd ¡ejΩ ¢ 
In  other  words,  under  the  bandlimiting  and  sampling  rate  constraints  mentioned 
above, the overall system behaves as an LTI CT ﬁlter, and the response of this ﬁlter 
is  related  to  that  of  the  embedded  DT  ﬁlter  through  a  simple  frequency  scaling. 
The  sampling  rate  can  be  lower  than  the Nyquist  rate,  provided  that  the DT  ﬁlter 
eliminates  any  aliased  components. 
If  we  wish  to  use  the  system  in  Figure  2.4  to  implement  a  CT  LTI  ﬁlter  with 
frequency  response  Hc (jω),  we  choose  Hd ¡ejΩ ¢ 
according  to  (2.67),  provided  that 
xc (t)  is  appropriately  bandlimited. 
If  Hc (jω) = 0  for  |ω | ≥ π/T ,  then  (2.67)  also  corresponds  to  the  following  relation 
between  the  DT  and  CT  impulse  responses: 

(2.67) 

hd [n] = T hc (nT ) 

(2.68) 

The  DT  ﬁlter  is  therefore  termed  an  impulse-invariant  version  of  the  CT  ﬁlter. 
When  xc (t)  and  Hd (ejΩ )  are  not  suﬃciently  bandlimited  to  avoid  aliased  compo­
nents  in  yd [n],  then  the  overall  system  in  Figure  2.4  is  no  longer  time  invariant.  It 
is,  however,  still  linear  since  it  is  a  cascade  of  linear  subsystems. 

The  following  two  important  examples  illustrate  the  use  of  (2.67)  as well  as  Figure 
2.4, both for DT processing of CT signals and for interpretation of an important DT 
system,  whether  or  not  this  system  is  explicitly  used  in  the  context  of  processing 
CT  signals. 

EXAMPLE  2.3 
Digital  Diﬀerentiator 
In  this  example  we  wish  to  implement  a  CT  diﬀerentiator  using  a  DT  system  in 
the conﬁguration of Figure 2.4  .  We need  to choose Hd ¡ejΩ ¢ 
dxc (t)
so  that yc (t) = 
, 
dt 
assuming  that  xc (t)  is  bandlimited  to  π/T .  The  desired  overall  CT  frequency 
response  is  therefore 
Yc (jω)
= jω 
Hc (jω) = 
Xc (jω) 
Consequently,  using  (2.67)  we  choose  Hd (ejΩ )  such  that 
Hd ¡ejΩ ¢ ¯¯¯¯¯Ω=ωT 
Hd ¡ejΩ ¢ 
|Ω| < π 
A discrete-time system with the frequency response in (2.70b) is commonly referred 
to  as  a  digital  diﬀerentiator.  To  understand  the  relation  between  the  input  xd [n] 

or  equivalently 

= jΩ/T 

|ω | < 

π 
T

= jω 

(2.69) 

(2.70a) 

(2.70b) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

44  Chapter  2 

Signals  and  Systems 

and  output  yd [n]  of  the  digital  diﬀerentiator,  note  that  yc (t)  —  which  is  the  ban­
dlimited  interpolation  of  yd [n] —  is  the  derivative  of  xc (t),  and  xc (t)  in  turn  is  the 
bandlimited  interpolation  of  xd [n].  It  follows  that  yd [n]  can,  in  eﬀect,  be  thought 
of as  the  result of  sampling  the derivative of  the bandlimited  interpolation of xd [n]. 

EXAMPLE  2.4 

Half-Sample  Delay 

It  often  arises  in  designing  discrete-time  systems  that  a  phase  factor  of  the  form 
e−jαΩ ,  |Ω| < π ,  is  included  or  required.  When  α  is  an  integer,  this  has  a  straight­
forward  interpretation,  since  it  corresponds  simply  to  an  integer  shift  by  α  of  the 
time  sequence. 

When  α  is  not  an  integer,  the  interpretation  is  not  as  straightforward,  since  a 
DT  sequence  can  only  be  directly  shifted  by  integer  amounts.  In  this  example  we 
consider  the  case  of  α  = 1/2,  referred  to  as  a  half-sample  delay.  To  provide  an 
interpretation,  we  consider  the  implications  of  choosing  the  DT  system  in  Figure 
2.4  to  have  frequency  response 

Hd (ejΩ ) = e−jΩ/2 

|Ω| < π 
Whether or not xd [n] explicitly arose by sampling a CT signal, we can associate with 
xd [n] its bandlimited interpolation xc (t) for any speciﬁed sampling or reconstruction 
interval T .  Similarly, we can associate with yd [n] its bandlimited interpolation yc (t) 
using  the  reconstruction  interval  T .  With Hd ¡ejΩ ¢ 
given  by  (2.71),  the  equivalent 
CT  frequency  response  relating  yc (t)  to  xc (t)  is 
Hc (jω) = e−jωT /2 

(2.71) 

(2.72) 

representing  a  time  delay  of  T /2,  which  is  half  the  sample  spacing;  consequently, 
yc (t) =  xc (t − T /2).  We  therefore  conclude  that  for  a  DT  system  with  frequency 
response  given  by  (2.71),  the  DT  output  yd [n]  corresponds  to  samples  of  the  half-
sample  delay  of  the  bandlimited  interpolation  of  the  input  sequence  xd [n].  Note 
that  in  this  interpretation  the  choice  for  the  value  of  T  is  immaterial.  (Even  if 
xd [n] had been  the  result of  regular  sampling of a CT  signal,  that  speciﬁc  sampling 
period  is  not  required  in  the  interpretation  above.) 

The preceding interpretation allows us to ﬁnd the unit-sample (or impulse) response 
of  the  half-sample  delay  system  through  a  simple  argument.  If  xd [n] =  δ [n],  then 
xc (t)  must  be  the  bandlimited  interpolation  of  this  (with  some  T  that  we  could 
have  speciﬁed  to  take  any  particular  value),  so 

and  therefore 

sin(π t/T ) 
xc (t) = 
π t/T 
sin³π(t − (T /2))/T ´ 
π(t − (T /2))/T 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

yc (t) = 

(2.73) 

(2.74) 

Section  2.5 

Discrete-Time  Processing  of  Continuous-Time  Signals  45 

which  shows  that  the  desired  unit-sample  response  is 
sin³π(n − (1/2))´ 
π(n − (1/2)) 
This  discussion  of  a  half-sample  delay  also  generalizes  in  a  straightforward  way  to 
any  integer  or  non-integer  choice  for  the  value  of  α. 

yd [n] = hd [n] = 

(2.75) 

2.5.3  Non-Ideal  D/C  converters 

In  Section  2.5.1  we  deﬁned  the  ideal  D/C  converter  through  the  bandlimited  in­
terpolation  formula  (2.63);  see  also  Figure  2.5,  which  corresponds  to  processing  a 
train of  impulses with strengths equal to the sequence values yd [n] through an  ideal 
low-pass  ﬁlter.  A  more  general  class  of  D/C  converters,  which  includes  the  ideal 
converter  as  a  particular  case,  creates  a  CT  signal  yc (t)  from  a  DT  signal  yd [n] 
according  to  the  following: 
yc (t) =  X 
∞
yd [n] p(t − nT ) 
n=−∞ 
where p(t)  is some selected basic pulse shape and T  is the reconstruction interval or 
pulse repetition interval.  This too can be seen as the result of processing an impulse 
train  of  sequence  values  through  a  ﬁlter,  but  a  ﬁlter  that  has  impulse  response  p(t) 
rather than that of the ideal low-pass ﬁlter.  The CT signal yc (t) is thus constructed 
by adding together shifted and scaled versions of the basic pulse shape;  the number 
yd [n]  scales  p(t − nT ),  which  is  the  basic  pulse  delayed  by  nT .  Note  that  the  ideal 
bandlimited  interpolating  converter  of  (2.63)  is  obtained  by  choosing 

(2.76) 

p(t) = 

sin(π t/T ) 
(π t/T ) 

(2.77) 

We  shall  be  talking  in more  detail  in Chapter  12  about  the  interpretation  of  (2.76) 
as  pulse  amplitude  modulation  (PAM)  for  communicating  DT  information  over  a 
CT  channel. 

The relationship (2.76) can also be described quite simply  in the frequency domain. 
Taking the CTFT of both sides, denoting the CTFT of p(t) by P (jω), and using the 
fact  that  delaying  a  signal  by  t0  in  the  time  domain  corresponds  to  multiplication 
by  e−jωt0  in  the  frequency  domain,  we  get 
yd [n] e−jnωT ´ 
Yc (jω) =  ³ X 
∞
P (jω) 
n=−∞ 
¯¯¯¯¯Ω=ωT 
=  Yd (ejΩ ) 
P (jω) 
c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

(2.78) 

46  Chapter  2 

Signals  and  Systems 

FIGURE  2.6  A  centered  zero-order  hold  (ZOH) 

In  the  particular  case  where  p(t)  is  the  sinc  pulse  in  (2.77),  with  transform  P (jω) 
corresponding to an ideal low-pass ﬁlter of amplitude T  for  ω < π/T  and 0 outside 
|
|
this  band,  we  recover  the  relation  (2.64). 

In  practice  an  ideal  low-pass  ﬁlter  can  only  be  approximated,  with  the  accuracy 
of  the  approximation  closely  related  to  cost  of  implementation.  A  commonly  used 
simple  approximation  is  the  (centered)  zero-order  hold  (ZOH),  speciﬁed  by  the 
choice 
p(t) = ½ 
This  D/C  converter  holds  the  value  of  the  DT  signal  at  time  n,  namely  the  value 
yd [n],  for  an  interval  of  length  T  centered  at  nT  in  the  CT  domain,  as  illustrated 
in  Figure  2.6.  Such  ZOH  converters  are  very  commonly  used.  Another  common 
choice  is  a  centered  ﬁrst-order  hold  (FOH),  for which  p(t)  is  triangular  as  shown  in 
Figure  2.7.  Use  of  the  FOH  represents  linear  interpolation  between  the  sequence 
values. 

1 
for  |t| < (T /2) 
0  elsewhere 

(2.79) 

FIGURE  2.7  A  centered  ﬁrst  order  hold  (FOH) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

MIT OpenCourseWare
http://ocw.mit.edu 

6.011 Introduction to Communication, Control, and Signal Processing 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

