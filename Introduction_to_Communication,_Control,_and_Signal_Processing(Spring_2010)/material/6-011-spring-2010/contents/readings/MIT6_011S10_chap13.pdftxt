C H A P T E R 

13 

Hypothesis Testing 

INTRODUCTION 

The  topic  of  hypothesis  testing  arises  in  many  contexts  in  signal  processing  and 
communications,  as  well  as  in  medicine,  statistics  and  other  settings  in  which  a 
choice  among  multiple  options  or  hypotheses  is  made  on  the  basis  of  limited  and 
noisy  data.  For  example,  from  tests  on  such  data,  we  may  need  to  determine: 
whether  a  person  does  or  doesn’t  have  a  particular  disease;  whether  or  not  a  par­
ticular  radar  return  indicates  the  presence  of  an  aircraft;  which  of  four  values  was 
transmitted  at  a  given  time  in  a  PAM  system;  and  so  on. 

Hypothesis  testing provides a  framework  for  selecting among M  possible  choices or 
hypotheses  in  some  principled  or  optimal  way.  In  our  discussion  we  will  initially 
focus  on  M  =  2,  i.e.,  on  binary  hypothesis  testing,  to  illustrate  the  key  concepts. 
Though  Section  13.1  introduces  the  discussion  in  the  context  of  binary  pulse  am­
plitude  modulation  in  noise,  the  presentation  and  results  in  Section  13.2  apply  to 
the  general  problem  of  binary  hypothesis  testing.  In  Sections  13.3  and  13.4  we 
explicitly  treat  the  case  of more  than  two  hypotheses. 

13.1  BINARY  PULSE  AMPLITUDE  MODULATION  IN  NOISE 

In  Chapter  12  we  introduced  the  basic  principles  of  pulse  amplitude  modulation, 
and  considered  the  eﬀects  of  pulse  rate,  pulse  shape,  and  channel  and  receiver 
ﬁltering  in  PAM  systems.  We  also  developed  and  discussed  the  condition  for  no 
inter-symbol  interference  (the  no-ISI  condition).  Under  the  assumption  of  no  ISI, 
we  want  to  now  examine  the  eﬀect  of  noise  in  the  channel.  Toward  this  end,  we 
again  consider  the  overall  PAM  model  in  Figure  13.1,  with  the  channel  noise  v(t) 
represented  as  an  additive  term. 

For  now  we  will  assume  no  post-ﬁltering  at  the  receiver,  i.e.,  assume  f (t) =  δ(t). 
In  Chapter  14  we  will  see  how  performance  is  improved  with  the  use  of  ﬁltering  in 
the  receiver.  The basic pulse  p(t)  going  through  the  channel with  impulse  response 
h(t) produces a  signal at  the channel output  that we  represent by s(t) = p(t) ∗ h(t). 
Figure  13.1  thus  reduces  to  the  overall  system  shown  in  Figure  13.2. 

Since we are assuming no ISI, we can carry out our discussion for just a single pulse 
index  n,  which  we  will  choose  as  n = 0  for  convenience.  We  therefore  focus,  in  the 
system  of  Figure  13.2,  on 

b[0] = r(0) = a[0]s(0) + v(0) . 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(13.1) 

227

228  Chapter  13 

Hypothesis  Testing 

x(t) =  � 
P 
a[n]p(t − nT ) 

h(t)

Channel 

Noise  v(t) 
�
� + 

� 

r(t) 

f (t) 

� 
b(t) 

Filtering 

Sample  every  T 

Samples  b(nT )
�

FIGURE  13.1  Overall  model  of  a  PAM  system. 

P 
a[n]s(t − nT ) 

� 

v(t) 

�  �r(t) 
�⊕ 

�  b[n] = r(nT ) 

Sample  every  T 

FIGURE  13.2  Simpliﬁed  representation  of  a  PAM  system. 

Writing  r(0),  a[0]  and  v(0)  simply  as  r ,  a  and  v  respectively,  and  setting  s(0) =  1 
without  loss  of  generality,  the  relation  of  interest  to  us  is 

r = a + v . 

(13.2) 

Our  broad  ob jective  is  to  determine  the  value  of  a  as  well  as  possible,  given  the 
measured  value  r .  There  are  several  variations  of  this  problem,  depending  on  the 
nature  of  the  transmitted  sequence  a[n]  and  the  characteristics  of  the  noise.  The 
amplitude  a[n]  may  span  a  continuous  range  or  it  may  be  discrete  (e.g.,  binary). 
The  amplitude  may  correspondingly  be  modeled  as  a  random  variable  A  with  a 
known  PDF  or  PMF;  then  a  is  the  speciﬁc  value  that  A  takes  in  a  particular 
outcome  or  instance  of  the  probabilistic  model.  The  contribution  of  the  noise  also 
is  typically  represented  as  a  random  variable  V ,  usually  continuous,  with  v  being 
the  speciﬁc  value  that  it  takes.  We  may  thus  model  the  quantity  r  at  the  receiver 
as  the  observation  of  a  random  variable  R,  with 

R = A + V , 

(13.3) 

and  we  want  to  estimate  the  value  that  the  random  variable  A  takes,  given  that 
R =  r .  Consequently,  we  need  to  add  a  further  processing  step  to  our  receiver,  in 
which  an  estimate  of  A  is  obtained. 

In  the  case  where  the  pulse  amplitude  can  be  only  one  of  two  values,  i.e.,  in  the 
case  of  binary  signaling,  ﬁnding  an  estimate  of  A  reduces  to  deciding,  on  the  basis 
of the observed value r  of R, which of the two possible amplitudes was transmitted. 
Two  common  forms  of  binary  signaling  in  PAM  systems  are  on/oﬀ  signaling  and 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  13.2 

Binary  Hypothesis  Testing  229 

antipodal  signaling.  Letting  a1  and  a0  denote  the  two  possible  amplitudes  (repre­
senting  for  example  a  binary  “one”  or  “zero”),  in  on/oﬀ  signaling  we  have  a0  = 0, 
= 0,  whereas  in  antipodal  signaling  a0 
= −a1  6
= 0. 
a1  6
Thus,  in  binary  signaling,  the  required  post-processing  corresponds  to  deciding  be­
tween  two  alternatives  or  hypotheses,  where  the  available  information may  include 
some prior information along with a measurement r of the single continuous random 
variable R.  (The  extension  to multiple  hypotheses  and multiple measurements will 
be  straightforward  once  the  two-hypothesis  case  is  understood.)  The  hypotheses 
are  listed  below: 

Hypothesis  H0 :  the  transmitted  amplitude  A  takes  the  value  a0 ,  so  R = a0  + V . 
Hypothesis  H1 :  the  transmitted  amplitude  A  takes  the  value  a1 ,  so  R = a1  + V . 
Our  task  now  is  to  decide,  given  the  measurement  R  =  r ,  whether  H0  or  H1  is 
responsible  for  the  measurement.  The  next  section  develops  a  framework  for  this 
sort  of  hypothesis  testing  task. 

13.2  BINARY  HYPOTHESIS  TESTING 

Our  general  binary  hypothesis  testing  task  is  to  decide,  on  the  basis  of  a  mea­
surement  r  of  a  random  variable  R,  which  of  two  hypotheses  —  H0  or  H1  —  is 
responsible for the measurement.  We shall indicate these decisions by ‘H0 ’ and ‘H1 ’ 
respectively (where the quotation marks are  intended to suggest the announcement 
of  a  decision).  An  alternative  notation  is Hb = H0  and Hb = H1  respectively,  where 
Hb denotes  our  estimate  of,  or  decision  on,  the  hypothesis H . 
Suppose H  is modeled as a random quantity, and assume we know the a priori (i.e., 
prior)  probabilities 
P (H0  is  true) = P (H  = H0 ) = P (H0 ) = p0 

(13.4) 

and 

(13.5) 
P (H1  is  true) = P (H  = H1 ) = P (H1 ) = p1 
(where  the  last  two  equalities  in  each  case  simply  deﬁne  streamlined  notation  that 
we  will  be  using).  We  shall  also  require  the  conditional  densities  fR|H (r|H0 )  and 
fR|H (r|H1 )  that  tell  us  how  the  measured  variable  is  distributed  under  the  two 
respective  hypotheses.  These  conditional  densities  in  eﬀect  constitute  the  relevant 
speciﬁcations of how the measured data relates to the two hypotheses.  For example, 
in  the  PAM  setting,  with  R  deﬁned  as  in  (13.3)  and  assuming  V  is  independent  of 
A  under  each  hypothesis,  these  conditional  densities  are  simply 
fR|H (r|H0 ) = fV  (r − a0 )  and  fR|H (r|H1 ) = fV  (r − a1 )  . 
It  is  natural  in many  settings,  as  in  the  case  of  digital  communication  by  PAM,  to 
want  to  minimize  the  probability  of  picking  the  wrong  hypothesis,  i.e.,  to  choose 
with minimum probability of error between the hypotheses, given the measurement 
R  =  r .  We  will,  for  most  of  our  discussion  of  hypothesis  testing,  focus  on  this 
criterion  of  minimum  probability  of  error. 

(13.6) 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

230  Chapter  13 

Hypothesis  Testing 

13.2.1  Deciding  with Minimum  Probability  of  Error:  The MAP  Rule 

Consider ﬁrst how one would choose between H0  and H1  with minimum probability 
of  error  in  the  absence  of  any measurement  of  R.  If  we make  the  choice  ‘H0 ’,  then 
we  make  an  error  precisely  when  H0  does  not  hold,  so  the  probability  of  error 
with  this  choice  is  1 −  P (H0 ) = 1 −  p0 .  Similarly,  if  we  chose  ‘H1 ’,  then  the 
probability  of  error  is  1 − P (H1 ) = 1 − p1  = p0 .  Thus,  for minimum  probability  of 
error,  we  should  decide  in  favor  of  whichever  hypothesis  has maximum  probability 
—  an  intuitively  reasonable  conclusion.  (The  preceding  reasoning  extends  in  the 
same  way  to  choosing  one  from  among  many  hypotheses,  and  leads  to  the  same 
conclusion.) 

What changes when we aim to choose between H0  and H1  with minimum probabil­
ity  of  error,  knowing  that  R =  r?  The  same  reasoning  applies  as  in  the  preceding 
paragraph,  except  that  all  probabilities  now  need  to  be  conditioned  on  the  mea­
surement  R  =  r .  We  conclude  that  to  minimize  the  conditional  probability  of 
error,  P (error R  =  r),  we  need  to  decide  in  favor  of  whichever  hypothesis  has 
|
maximum  conditional  probability,  conditioned  on  the  measurement  R  =  r .  (If 
there  were  several  random  variables  for  which  we  had  measurements,  rather  than 
just  the  single  random  variable  R,  we  would  simply  condition  on  all  the  available 
measurements.)  Thus,  if  P (H1 R  =  r)  > P (H0 R  =  r),  we  decide  ‘H1 ’,  and  if 
|
|
P (H1 R = r) < P (H0 R = r),  we  decide  ‘H0 ’.  This  may  be  compactly  written  as 
|
|

P (H1 R = r) 
|

‘H1 ’ 
> 
< 
‘H0 ’ 

P (H0 R = r)  . 
|

(13.7) 

(If the two conditional probabilities happen to be equal, we get the same conditional 
probability of error whether we choose ‘H0 ’ or ‘H1 ’.)  The corresponding conditional 
probability  of  error  is 

P (error|R = r) = min{1 − P (H0 |R = r), 1 − P (H1 |R = r)}  . 

(13.8) 

The  overall  probability  of  error,  Pe ,  associated  with  the  use  of  the  above  decision 
rule  (but  before  knowing  what  speciﬁc  value  of  R  is  measured)  is  obtained  by 
averaging  the  conditional  probability  of  error  in  (13.8)  over  all  possible  values  of  r 
that  might  be  measured,  using  the  PDF  fR (r)  as  a  weighting  function.  We  shall 
study  Pe  in  more  detail  shortly. 
The  conditional  probabilities  P (H0 R  =  r)  and  P (H1 R  =  r)  that  appear  in  the 
|
|
expression  (13.7)  are  referred  to  as  the  a  posteriori  or  posterior  probabilities  of  the 
hypotheses,  to distinguish  them  from  the a  priori or prior probabilities, P (H0 ) and 
P (H1 ).  The  decision  rule  in  (13.7)  is  accordingly  referred  to  as  the  maximum  a 
posteriori  probability  rule,  usually  abbreviated  as  the  “MAP”  rule. 

To  actually  evaluate  the  posterior  probabilities  in  (13.7),  we  use  Bayes’  rule  to 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.2 

Binary  Hypothesis  Testing  231 

rewrite  them  in  terms  of  known  quantities,  so  the  decision  rule  becomes 

‘H1 ’ 
p1 fR|H (r H1 )  > p0 fR|H (r H0 )
|
|
< 
fR (r) 
fR (r) 
‘H0 ’ 

, 

(13.9) 

under the reasonable assumption that fR (r) > 0,  i.e.,  that the PDF of R  is positive 
at the value r  that was actually measured.  (In any case, we only need to specify our 
decision  rule  at  values  of  r  for  which  fR (r) > 0,  because  the  choices made  at  other 
values of r  do not aﬀect the overall probability of error, Pe .)  Since the denominator 
is  the  same  and  positive  on  both  sides  of  the  above  expression,  we  may  further 
simplify  it  to 

(13.10) 

p1 fR|H (r|H1 ) 

p0 fR|H (r|H0 )  . 

‘H1 ’ 
> 
<
‘H0 ’ 
This  now  provides  us  with  an  easily  visualized  and  implemented  decision  rule.  We 
ﬁrst  use  the  prior  probabilities  pi  =  P (Hi )  to  scale  the  PDFs  fR|H (r|Hi )  that 
describe how  the measured  quantity R  is distributed  under  each  of  the hypotheses. 
We  then  decide  in  favor  of  the  hypothesis  associated with whichever  scaled PDF  is 
largest at the measured value r .  (The preceding description also applies to choosing 
with minimum probability of error among multiple hypotheses, rather than just two, 
and  given  measurements  of  several  associated  random  variables,  rather  than  just 
one —  the  reasoning  is  identical.) 

13.2.2  Understanding  Pe :  False  Alarm, Miss  and  Detection 

The  sample  space  that  is  relevant  to  evaluating  a  decision  rule  consists  of  the 
following  four  mutually  exclusive  and  collectively  exhaustive  possibilities:  Hi  is 
true  and  we  declare  ‘Hj ’,  i, j  = 1, 2.  Of  the  four  possible  outcomes,  the  two  that 
represent  errors  are  (H0 , ‘H1 ’)  and  (H1 , ‘H0 ’).  Therefore,  the  probability  of  error 
Pe  — averaged over all possible values of  the measured  random variable —  is given 
by 

Pe  = P (H0 , ‘H1 ’) + P (H1 , ‘H0 ’) 
= p0P (‘H1 ’|H0 ) + p1P (‘H0 ’|H1 )  . 
The conditional probability P (‘H1 ’ H0 )  is referred to as  the conditional probability 
|
of  a  false  alarm,  and  denoted  by  PF A .  The  conditional  probability  P (‘H0 ’ H1 )
|
is  referred  to  as  the  conditional  probability  of  a  miss,  and  denoted  by  PM .  The 
word  “conditional”  is  usually  omitted  from  these  terms  in  normal  use,  but  it  is 
important  to keep  in mind  that  the probability  of  a  false  alarm  and  the probability 
of  a  miss  are  deﬁned  as  conditional  probabilities,  and  are  furthermore  conditioned 
on  diﬀerent  events. 

(13.11) 

The  preceding  terminology  is  historically motivated  by  the  radar  context,  in which 
H1  represents  the  presence  of  a  target  and  H0  the  absence  of  a  target.  A  false 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

232  Chapter  13 

Hypothesis  Testing 

alarm  then  occurs  if  you  declare  that  a  target  is  present when  it  actually  isn’t,  and 
a  miss  occurs  if  you  declare  that  a  target  is  absent  when  it  actually  isn’t.  We  will 
also  make  reference  to  the  conditional  probability  of  detection, 

PD  = P (‘H1 ’|H1 )  . 
In  the  radar  context,  this  is  the  probability  of  declaring  a  target  is  present when  it 
is actually present.  As with PF A  and PM , the word “conditional” is usually omitted 
in normal use,  but  it  is  important  to keep  in mind  that  the probability  of detection 
is  a  conditional  probability. 

(13.12) 

Expressing  the  probability  of  error  in  terms  of  PF A  and  PM ,  (13.11)  becomes 

Also  note  that 

or 

Pe  = p0PF A  + p1PM  . 

P (‘H0 ’ H1 ) + P (‘H1 ’ H1 ) = 1 
|
|

(13.13) 

(13.14) 

(13.15) 

PM  = 1 − PD  . 
To  explicitly  relate  PF A  and  PM  to  whatever  the  corresponding  decision  rule  is,  it 
is  helpful  to  introduce  the  notion  of  a  decision  region  in  measurement  space.  In 
the  case  of  a  decision  rule  based  on  measurement  of  a  single  random  variable  R, 
specifying  the  decision  rule  corresponds  to  choosing  a  range  of  values  D1  on  the 
real line such that, when the measured value r of R falls in D1 , we declare ‘H1 ’, and 
when  r  falls  outside D1  —  a  region  that  we  shall  denote  by D0  —  then  we  declare 
‘H0 ’.  This  is  illustrated  in  Figure  13.3,  for  some  arbitrary  choice  of  D1 .  (There  is 
a  direct  generalization  of  this  notion  to  the  case  where  multiple  random  variables 
are  measured.) 

f(r|H 
1) 

f(r|H 
0  ) 

D 
1 

r 

FIGURE  13.3  Decision  regions.  The  choice  of  D1  marked  here  is  arbitrary,  not  the 
optimal  choice  for  minimum  probability  of  error. 

With  the  preceding  deﬁnitions,  we  can  write 
Z 
D1 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

PF A  = 

fR|H (r|H0 )dr 

(13.16) 

Section  13.2 

Binary  Hypothesis  Testing  233 

and 

PM  = Z 
D0 

fR|H (r|H1 )dr  . 

13.2.3  The  Likelihood  Ratio  Test 

Rewriting  (13.10),  we  can  state  the  minimum-Pe  decision  rule  in  the  form 

or


Λ(r) = 

fR|H (r|H1 ) 
fR|H (r|H0 ) 

‘H1 ’ 
> 
< 
‘H0 ’ 

p0 
p1 

Λ(r) 

‘H1 ’

>

< 
‘H0 ’ 

η ,	

(13.17) 

(13.18) 

(13.19) 

where  Λ(r)  is  referred  to  as  the  likelihood  ratio,  and  η  is  referred  to  as  the  thresh­
old.  This  particular  way  of  writing  our  decision  rule  is  of  interest  because  other 
formulations  of  the  binary  hypothesis  testing  problem  —  with  criteria  other  than 
minimization  of  Pe  —  also  often  lead  to  a  decision  rule  that  involves  comparing 
the  likelihood  ratio  with  a  threshold.  The  only  diﬀerence  is  that  the  threshold  is 
picked  diﬀerently  in  these  other  formulations.  We  describe  two  of  these  alternate 
formulations  —  the  Neyman-Pearson  approach,  and  minimum  risk  decisions —  in 
later  sections  of  this  chapter. 

13.2.4  Other  Scenarios 

While  the  above  discussion  of  binary  hypothesis  testing was  introduced  in  the  con­
text of binary PAM, it applies in many other scenarios.  For example,  in the medical 
literature,  clinical  tests  are  described  using  a  hypothesis  testing  framework  simi­
lar  to  that  used  here  for  communication  and  signal  detection  problems,  with  H0 
generally  denoting  the  absence  of  a  medical  condition  and  H1  its  presence.  The 
terminology  in  the  medical  context  is  slightly  diﬀerent,  but  still  suggestive  of  the 
intent,  as  the  following  examples  show: 

•	 PD  is  the  sensitivity  of  the  clinical  test. 
•	 P (‘H1 ’|H0 )  is the probability of a  false positive (rather than of a  false alarm). 
•	 1 − PF A  is  the  speciﬁcity  of  the  test. 
•	 P (H1 )  is  the  prevalence  of  the  condition  that  the  test  is  aimed  at. 
•	 P (H1  |‘H1 ’)  is the positive predictive value of the test, and P (H0  | ‘H0 ’)  is the 
negative  predictive  value. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

234  Chapter  13 

Hypothesis  Testing 

Some easy exploration using Bayes’ rule and the above terminology will  lead you to 
recognize  how  small  the  positive  predictive  value  of  a  test  can  be  if  the  prevalence 
of  the  targeted  medical  condition  is  low,  even  if  the  test  is  highly  sensitive  and 
speciﬁc. 

Another important context for binary hypothesis testing is in target detection, such 
as  aircraft  detection  and  tracking,  in  which  a  radar  pulse  is  transmitted  and  the 
decision on the presence or absence of an aircraft is based on the presence or absence 
of  reﬂected  energy. 

13.2.5  Neyman-Pearson  Detection  and  Receiver  Operating  Characteristics 

A  diﬃculty  with  using  the  minimization  of  Pe  as  the  decision  criterion  in  many  of 
these  other  contexts  is  that  it  relies  heavily  on  knowing  the  a  priori  probabilities 
p0  and  p1 ,  and  in  many  situations  there  is  little  basis  for  coming  up  with  these 
numbers.  One  alternative  that  often  makes  sense  is  to  maximize  the  probability 
of  detection  PD ,  while  keeping  PF A  below  some  speciﬁed  tolerable  level.  These 
conditional  probabilities  are  determined  by  the  measurement  models  under  the 
diﬀerent hypotheses, and by the decision rule, but not by the probabilities governing 
the  selection  of  hypotheses.  Such  a  formulation  of  the  hypothesis  testing  problem 
again  leads  to  a  decision  rule  that  involves  comparing  the  likelihood  ratio  with  a 
threshold;  the  only  diﬀerence  now  is  that  the  threshold  is  picked  diﬀerently  in  this 
formulation.  This  approach  is  referred  to  as  Neyman-Pearson  detection,  and  is 
elaborated  on  below. 

fR|H (r|H1 )dr  , 

Consider  a  context  in  which  we  want  to  maximize  the  probability  of  detection, 
Z 
PD  = P (‘H1 ’|H1 ) = 
D1 
while  keeping  the  probability  of  false  alarm, 
Z 
PF A  = P (‘H1 ’|H0 ) = 
fR|H (r|H0 )dr  , 
D1 
below  a  pre-speciﬁed  level.  (Both  integrals  are  over  the  decision  region  D1 ,  and 
augmenting D1  by  adding more  of  the  real  axis  to  it  will  not  decrease  either  prob­
ability.)  As  we  show  shortly,  we  can  achieve  our  ob jective  by  picking  the  decision 
region D1  to  comprise  those  values  of  r  for  which  the  likelihood  ratio  Λ(r)  exceeds 
a  certain  threshold  η ,  so 

(13.20) 

(13.21) 

Λ(r) = 

‘H1 ’ 
fR|H (r|H1 )  > 
< 
fR|H (r|H0 )
0 ’ 
‘H

η . 

(13.22) 

The  threshold  η  is  picked  to  provide  the  largest  possible  PD  while  ensuring  that 
PF A  is  not  larger  than  the  pre-speciﬁed  level.  The  smaller  the  η ,  the  larger  the 
decision  region  D1  and  the  value  of  PD  become,  but  the  larger  PF A  grows  as  well, 
so  one  would  pick  the  smallest  η  that  is  consistent  with  the  given  bound  on  PF A . 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.2 

Binary  Hypothesis  Testing  235 

To  understand  why  the  decision  rule  in  this  setting  takes  the  form  of  (13.22),  note 
that our ob jective is to include in D1  values of r  that contribute as much as possible 
to  the  integral  that  deﬁnes  PD ,  and  as  little  as  possible  to  the  integral  that  deﬁnes 
PF A .  If  we  start  with  a  high  value  of  the  threshold  η ,  we  will  be  including  in 
D1  those  r  for  which  Λ(r)  is  large,  and  therefore  where  the  contribution  to  PD  is 
relatively  large  compared  to  the  contribution  to  PF A .  Moving  η  lower,  we  increase 
both PD  and PF A , but the rate of increase of PD  drops, while the rate of increase of 
PF A  rises.  These increases in PD  and PF A  may not be continuous in η .  (Reducing η 
from  inﬁnitesimally  above  some  value  η  to  inﬁnitesimally  below  this  value will  give 
rise  to  a  ﬁnite  upward  jump  in  both  PD  and  PF A  if  fR|H (r|H1 ) =  η fR|H (r|H0 ) 
throughout  some  interval  of  r  where  both  these  PDFs  are  positive.)  Typically, 
though,  the variation of PD  and PF A  with η  is  indeed continuous,  so as η  is  lowered 
we  reach  a  point  where  the  speciﬁed  bound  on  PF A  is  attained,  or  PD  =  1 is 
reached.  This  is  the  value  of  η  used  in  the  Neyman-Pearson  test.  (In  the  rare 
situation  where  PF A  jumps  discontinuously  from  a  value  below  its  tolerable  level 
to  one  above  its  tolerable  level  as  η  is  lowered  through  some  value  η ,  it  turns  out 
that  a  randomized  decision  rule  allows  one  to  come  right  up  to  the  tolerable  PF A 
level,  and  !  thereby  maximize  PD .  A  case  like  this  is  explored  in  a  problem  at  the 
end  of  this  chapter.) 

The  following  argument  shows  in  a  little  more  detail,  though  still  informally,  why 
the Neyman-Pearson  criterion  is  equivalent  to  a  likeliood  ratio  test.  If  the  decision 
region D1  is optimal  for the Neyman-Pearson criterion,  then any change  in D1  that 
keeps  PF A  the  same  cannot  lead  to  an  improvement  in  PD .  So  suppose  we  take  a 
inﬁnitesimal  segment of width dr  at a point r  in  the optimal D1  region and convert 
it  to  be  part  of  D0 .  In  order  to  keep  PF A  unchanged,  we  must  correspondingly 
take  an  inﬁnitesimal  segment  of  width  dr ′  at  an  arbitrary  point  r ′  in  the  optimal 
D0  region,  and  convert  it  to  be  a  part  of D1 . 

f(r|H 
1) 

f(r|H 
0  ) 

dr 

dr’ 

r 

D 
1 

FIGURE  13.4  Illustrating  the  construction  used  in  deriving  the  likelihood  ratio  test 
for  the  Neyman-Pearson  criterion. 

The  requirement  that  PF A  be  unchanged  then  imposes  the  condition 

fR|H (r ′ |H0 ) dr ′  = fR|H (r|H0 ) dr  , 
°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

(13.23) 

236  Chapter  13 

Hypothesis  Testing 

while  the  requirement  that  the  new  PD  not  be  larger  than  the  old  implies  that 
fR|H (r ′ |H1 ) dr ′  ≤ fR|H (r|H1 ) dr  . 
Combining  (13.23)  and  (13.24),  we  ﬁnd 
Λ(r ′ ) ≤ Λ(r)  . 
What (13.25) shows is that the likelihood ratio cannot be less inside D1  than it is in 
D0 .  We  can  therefore  conclude  that  the  optimum  solution  to  the Neyman-Pearson 
formulation  is  in  fact  based  on  a  threshold  test  on  the  likelihood  ratio: 

(13.25) 

(13.24) 

Λ(r) = 

fR|H (r|H1 ) 
fR|H (r|H0 ) 

‘H1 ’ 
> 
< 
‘H0 ’ 

η  , 

(13.26) 

where  the  threshold  η  is  picked  to  obtain  the  largest  possible  PD  while  ensuring 
that  PF A  is  not  larger  than  the  pre-speciﬁed  bound. 
The above derivation has made various implicit assumptions.  However, our purpose 
is  only  to  convey  the  essence  of  how  one  arrives  at  a  likelihood  ratio  test  in  this 
case. 

Receiver  Operating  Characteristic. 
In  considering  which  value  of  PF A  to 
choose  as  a  bound  in  the Neyman-Pearson  test,  it  is  often  useful  to  look  at  a  curve 
of  PD  versus  PF A  as  the  parameter  η  is  varied.  This  is  referred  to  as  the  Receiver 
Operating  Characteristic  (ROC).  More  generally,  such  an  ROC  can  be  deﬁned 
for  any  decision  rule  that  causes  PD  to  be  uniquely  ﬁxed,  once  PF A  is  speciﬁed. 
The  ROC  can  be  used  to  identify  whether,  for  instance,  modifying  the  variable 
parameters  in  a  given  test  to  permit  a  slightly  higher PF A  results  in  a  signiﬁcantly 
higher  PD .  The  ROC  can  also  be  used  to  compare  diﬀerent  tests. 

EXAMPLE  13.1 

Detection  and  ROC  for  Signal  in  Gaussian  Noise 

Consider  a  scenario  in  which  a  radar  pulse  is  emitted  from  a  ground  station.  If 
an  aircraft  is  located  in  the  propagation  path,  a  reﬂected  pulse  will  travel  back 
towards  the  radar  station.  We  assume  that  the  received  signal  will  then  consist  of 
noise  alone  if  no  aircraft  is  present,  and  noise  plus  the  reﬂected  pulse  if  an  aircraft 
is present.  The processing  of  the  received  signal  results  in  a number  that we model 
as the realization of a random variable R.  If an aircraft is not present, then R = W , 
where  W  is  a  random  variable  denoting  the  result  of  processing  just  the  noise.  If 
an  aircraft  is  present,  then  R  =  s + W ,  where  the  constant  s  is  due  to  processing 
of  the  reﬂected  pulse,  and  is  assumed  here  to  be  a  known  value.  We  thus  have  the 
following  two  hypotheses: 

H0  :  R = W 
H1  :  R = s + W . 

(13.27) 
(13.28) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  13.2 

Binary  Hypothesis  Testing  237 

Assume  that  the  additive  noise  term W  is Gaussian  with  zero mean  and  unit  vari­
ance,  i.e., 

1
fW (w) =  √
2π

2
e−w /2 . 

(13.29) 

Consequently, 

e−r 2 /2 

+

(13.30) 

(13.31) 

Λ(r) = exp

r2 i
2 

e−(r−s)2 /2  . 

1 
fR|H (r|H0 ) =  √2π
1
fR|H (r|H1 ) =  √
2π
The  likelihood  ratio  as  deﬁned  in  (13.18)  is  then 
h (r − s)2 
− 
2
h
s2 i
= exp sr − 
. 
2 
For  detection  with  minimum  probability  of  error,  the  decision  rule  corresponds  to 
evaluating  this  likelihood  ratio  at  the  received  value  r ,  and  comparing  the  result 
against  the  threshold  p0 /p1 ,  as  stated  in  (13.18): 
s2 i 
exp sr −h
2 
It  is  interesting  and  important  to  note  that,  for  this  case,  the  threshold  test  on 
the  likelihood  ratio  can  be  rewritten  as  a  threshold  test  on  the  received  value  r . 
Speciﬁcally,  (13.33)  can  equivalently  be  expressed  as 
s2 i
2 

‘H1 ’ 
> 
<
‘H0 ’ 

η = 

p0 
p1 

[sr − 

‘H1 ’ 
>
< 
‘H0 ’ 

ln η , 

(13.32) 

(13.33) 

(13.34) 

or,  if  s > 0, 

r 

‘H1 ’ 
>  1 h s2 
i 
+ ln η = γ , 
< s  2 
‘H0 ’ 
where  γ  denotes  the  threshold  on  r .  (If  s <  0,  the  inequalities  in  (13.35)  are 
simply  reversed.)  For  example,  if  both  hypotheses  are  equally  likely  a  priori,  so 
that  p0  = p1 ,  then  ln η  = 0  and  the  decision  rule  for  minimum  probability  of  error 
when  s > 0  is  simply 

(13.35) 

r 

‘H1 ’ 
> s 
<  2 
‘H0 ’ 

= γ . 

(13.36) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

238  Chapter  13 

Hypothesis  Testing 

f(r|H 
0  ) 

f(r|H
1) 

γ 

s

r 

FIGURE  13.5  Threshold  γ  on  measured  value  r . 

The  situation  is  represented  in  Figure  13.5.


The  receiver  operating  characteristic  displays  PD  versus  PF A  as  η  is  varied,  and  is

sketched  in  Figure  13.6.


PD 

1.0 

.5 

0.0 

0.0 

.5 

1.0  PFA 

FIGURE  13.6  Receiver  operating  characteristic. 

In  a  more  general  setting  than  the  Gaussian  case  in  Example  13.1,  a  threshold 
test  on  the  likelihood  ratio  would  not  simply  translate  to  a  threshold  test  on  the 
measurement  r .  Nevertheless,  we  could  still  decide  to  use  a  simple  threshold  test 
on  r  as  our  decision  rule,  and  then  generate  and  evaluate  the  associated  receiver 
operating  characteristic. 

13.3  MINIMUM  RISK  DECISIONS 

This section brieﬂy describes a decision criterion, called minimum risk, that includes 
minimum  probability  of  error  as  a  special  case,  and  that  in  the  binary  case  again 
leads to a likelihood ratio test.  We describe it for the general case of M  hypotheses. 

Let  the  available  measurement  be  the  value  r  of  the  random  variable  R  (the  same 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.3 

Minimum  Risk  Decisions  239 

development  holds  if we  have measurements  of  several  random  variables).  Suppose 
we  associate  a  cost  cij  with  each  combination  of  model  Hj  and  decision  ‘Hi ’  for 
0 ≤ i, j  ≤ M  − 1,  reﬂecting  the  costs  of  actions  and  consequences  that  follow  from 
this  combination  of  model  and  decision.  Our  ob jective  now  is  to  pick  whichever 
decision  has minimum  expected  cost,  or  minimum  “risk”,  given  the measurement. 

The  expected  cost  of  deciding  ‘Hi ’,  conditioned  on  R = r ,  is  given  by 
E [Cost R = r, ‘Hi ’] =  X 
cij P (Hj  R = r, ‘Hi ’) =  X 
M −1
M −1
|
|
j=0 
j=0 
where  the  last  equality  is  a  consequence  of  the  fact  that,  given  the  received  mea­
surement  R = r ,  the  output  of  the  decision  rule  conveys  no  additional  information 
about  which  hypothesis  actually  holds.  The  next  step  is  to  compare  these  condi­
tional  expected  costs  for  all  i,  and  decide  in  favor  of  the  hypothesis with minimum 
conditional  expected  cost.  Specifying  our  decision  for  each  possible  r ,  we  obtain 
the  decision  rule  that  minimizes  the  overall  expected  cost  or  risk. 

cij P (Hj  R = r)  ,  (13.37) 
|

[It is in this setting that hypothesis testing comes closest to the estimation problems 
for  continuous  random  variables  that  we  considered  in  our  chapter  on  minimum 
mean-square-error  estimation.  We  noted  there  that  a  variety  of  such  estimation 
problems  can  be  formulated  in  terms  of  minimizing  an  expected  cost  function. 
Establishing an estimate for a random variable is like carrying out a hypothesis test 
for  a  continuum  of  numerically  speciﬁed  hypotheses  (rather  than  just  M  general 
hypotheses),  with  a  cost  function  that  penalizes  some  measure  of  the  numerical 
distance  between  the  actual  hypothesis  and  the  one  we  decide  on.] 

Note that  if cii  = 0  for all i and  if cij  = 1  for j  = i,  so we penalize all errors equally, 
then  the  conditional  expected  cost  in  (13.37)  becomes 
E [Cost R = r, ‘Hi ’] = X 
P (Hj  r) = 1 − P (Hi r)  . 
|
|
|
j=i 
This  conditional  expected  cost  is  thus  precisely  the  conditional  probability  of  error 
associated with deciding  ‘Hi ’,  conditioned on R = r .  The  right  side of  the equation 
then  shows  that  to  minimize  this  conditional  probability  of  error  we  should  decide 
in  favor  of  the  hypothesis  with  largest  conditional  probability.  In  other  words, 
with  this  choice  of  costs,  the  risk  (when  the  expectation  is  taken  over  all  possible 
values  of  r)  is  exactly  the  probability  of  error  Pe ,  and  the  optimum  decision  rule 
for  minimizing  this  criterion  is  again  seen  to  be  the MAP  rule. 

(13.38) 

Using Bayes’ rule in (13.37) and noting that fR (r) — assumed positive — is common 
to all the quantities  involved  in our comparison, we see that an equivalent but more 
directly  implementable  procedure  is  to  pick  the  hypothesis  for  which 
M −1X 
j=0 
is  minimum.  In  the  case  of  two  hypotheses,  and  assuming  c01  > c11 ,  it  is  easy  to 

cij f (r|Hj )P (Hj ) 

(13.39) 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

6
6
240  Chapter  13 

Hypothesis  Testing 

see  that  the  decision  rule  based  on  (13.39)  can  be  rewritten  as 

Λ(r) = 

‘H1 ’ 
f (r|H1 )  > P (H0 )(c10  − c00 )
< 
P (H1 )(c01  − c11 ) 
f (r|H0 )
0 ’ 
‘H

= η , 

(13.40) 

where  Λ(r)  denotes  the  likelihood  ratio,  and  η  is  the  threshold.  We  have  therefore 
again  arrived  at  a  decision  rule  that  involves  comparing  a  likelihood  ratio  with  a 
threshold.  If  cii  =  0  for  i  = 0, 1  and  if  cij  =  1  for  j  =  i,  then  we  obtain  the 
threshold  associated  with  the MAP  decision  rule  for  minimum  Pe ,  as  expected. 
The  trouble  with  the  above  minimum  risk  approach  to  classiﬁcation,  and  with  the 
minimum error probability  formulation that we have examined a  few times already, 
is  the  requirement  that  the  prior  probabilities  P (Hi )  be  known. 
It  is  often  unrealistic  to  assume  that  prior  probabilities  are  known,  so  we  are  led 
to  consider  alternative  criteria.  Most  important  among  these  alternatives  is  the 
Neyman-Pearson  approach  treated  earlier,  where  the  decision  is  based  on  the  con­
ditional probabilities PD  and PF A ,  thereby avoiding the need for prior probabilities 
on  the  hypotheses. 

13.4  HYPOTHESIS  TESTING  IN  CODED  DIGITAL  COMMUNICATION 

In  our  discussion  of  PAM  earlier  in  this  chapter,  we  considered  binary  hypothesis 
testing  on  a  single  received  pulse.  In modern  communication  systems,  an  alphabet 
of  symbols  may  be  transmitted,  with  each  symbol  encoded  into  a  binary  sequence 
of  “ones”  and  “zeroes”.  Consequently,  in  addition  to  making  a  binary  decision  on 
each received pulse, we may need to further decode a string of bits to make our best 
judgement of  the  transmitted  symbol,  and perhaps yet  further processing  to decide 
on the sequence of symbols that constitutes the entire message.  It would in principle 
be better  to  take all  the  raw measurements and  then make optimal decisions about 
the  entire  sequence  of  symbols  that  was  transmitted,  but  this  would  be  a  hugely 
more  complex  task.  In  practice,  therefore,  the  task  is  commonly  broken  down  into 
three  stages,  as  here,  with  locally  optimal  decisions  made  at  the  single-pulse  level 
to  decode  sequences  of  “ones”  and  “zeros”,  then  further  decisions  made  to  decode 
at  the  symbol  level,  and  still  further  decisions  made  at  the  symbol  sequence  level. 
In  this  section  we  illustrate  the  second  of  these  decoding  stages. 

For  concreteness,  we  center  our  discussion  on  the  system  in  Figure  13.7.  Suppose 
the  transmitter  randomly  selects  for  transmission  one  of  four  possible  symbols, 
which  we  label  A,  B ,  C  and  D .  The  probabilities  with  which  these  are  selected 
will  be  denoted  by  P (A),  P (B ),  P (C )  and  P (D)  respectively.  Whatever  symbol 
the  transmitter  selects  is  now  coded  appropriately  for  transmission  over  the  binary 
channel.  The  coding  adds  some  redundancy  to  provide  a  basis  for  error  correction 
at  the  receiver,  in  order  to  combat  errors  introduced  by  channel  noise  that  may 
corrupt  the  individual  bits.  The  resulting  signal  is  then  sent  to  the  receiver.  After 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

6
Section  13.4 

Hypothesis  Testing  in  Coded  Digital  Communication  241 

A 
B 
C 
D 

�  Symbol 
Selector 

�A 

Encoder  �000  Binary 
Channel 
� 

�010  Decoder 
(Decision 
Rule) 

�  B 

Noise


FIGURE  13.7  Communication  over  a  binary  channel.


the  receiver  decodes  the  received  pulses,  attempting  to  correct  for  channel  noise  in 
the  process,  it  has  to  arrive  at  a  decision  as  to  which  symbol  was  transmitted. 

A  natural  criterion  for  measuring  the  performance  of  the  receiver,  with  whatever 
decision  process  or  decision  rule  it  applies,  is  again  the  probability  of  error,  Pe .  It 
is natural,  in a communications  setting,  to want minimum probability of  error,  and 
this  is  the  criterion  we  adopt. 

In  the  development  below,  rather  than  simply  invoking  the  MAP  rule  we  derived 
earlier,  we  repeat  in  this  higher-level  setting  the  line  of  reasoning  that  led  to  the 
MAP  rule.  We  do  this  partly  because  there  are  some  diﬀerences  from  what  we 
considered earlier:  we now have multiple hypotheses (four in our example), not just 
a pair of hypotheses; and the measured quantity  is a discrete random symbol (more 
exactly,  the  received  and  possibly  noise  corrupted  binary  code  for  a  transmitted 
symbol),  rather  than  a  continuous  random  variable.  However,  it  will  be  clear  that 
the  problem  here  is  not  fundamentally  diﬀerent  or  harder. 

13.4.1  Optimal  a  priori  Decision 

Consider, ﬁrst of all, what the minimum-probability-of-error decision rule would be 
for  the  receiver  if  the  channel  was  down,  i.e.,  if  the  receiver  had  to  decide  on  the 
transmitted  signal without  the beneﬁt of any received signal, using only on a  priori 
information.  If the receiver guesses that the transmitter selected the symbol A, then 
the  receiver  is  correct  if A was  indeed  the  transmitted  symbol,  and  the  receiver has 
made an error if A was not the transmitted symbol.  Hence the receiver’s probability 
of error with this choice is 1−P (A).  Similar reasoning applies for the other symbols. 
So  the  minimum-probability-of-error  decision  rule  for  the  receiver  is  to  decide  in 
favor  of  whichever  symbol  has maximum  probability.  This  seems  quite  obvious  for 
this  simple  case,  and  the  general  case  (i.e.,  with  the  channel  functioning)  is  not 
really  any  harder.  We  turn  now  to  this  general  case,  where  the  receiver  actually 
receives  the  result  of  sending  the  transmitted  signal  through  the  noisy  channel. 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

242  Chapter  13 

Hypothesis  Testing 

13.4.2  The  Transmission Model 

Let  us  model  the  channel  as  a  binary  channel,  which  accepts  1’s  and  0’s  from  the 
transmitter,  and  delivers  1’s  and  0’s  to  the  receiver.  Suppose  that  because  of  the 
noise  in  the  channel  there  is  a  probability  p > 0  that  a  transmitted  1  is  received  as 
a 0, and that a transmitted 0  is received as a 1.  Because the probability  is the same 
for  both  types  of  errors,  this  binary  channel  is  called  symmetric  (we  could  treat 
the  non-symmetric  case  as  easily,  apart  from  some  increased  notational  burden). 
Implicit  in  our  deﬁnition  of  this  channel  is  the  assumption  that  it  is  memoryless, 
i.e.,  its  characteristics  during  any  particular  transmission  slot  are  independent  of 
what  has  been  transmitted  in  other  time  slots.  The  channel  is  also  assumed  time-
invariant,  i.e.,  its  characteristics  do  not  vary  with  time. 

Given such a channel, the transmitter needs to code the selected symbol into binary 
form.  Suppose  the  transmitter  uses  3  bits  to  code  each  symbol,  as  follows: 

A  : 000 , B  : 011  , C  : 101  , D  : 110  . 

(13.41) 

Because of the ﬁnite probability of bit-errors introduced by the channel, the received 
sequence  for  any  of  these  transmissions  could  be  any  3-bit  binary  number: 

R0  = 000  , R1  = 001  , R2  = 010  , R3  = 011  , 

R4  = 100  , R5  = 101  , R6  = 110  , R7  = 111  . 
The  redundancy  introduced  by  using  3  bits  —  rather  than  the  2  bits  that  would 
suﬃce  to  communicate  our  set  of  four  symbols  —  is  intended  to  provide  some 
protection  against  channel  noise.  Notice  that  with  our  particular  3-bits/symbol 
code,  a  single  bit-error  would  be  recognized  at  the  receiver  as  an  error,  because  it 
would  result  in  an  invalid  codeword.  It  takes  two  bit-errors  (which  are  rarer  than 
single bit-errors)  to convert any valid codeword  into another valid one, and thereby 
elude  recognition  of  the  error  by  the  receiver. 

(13.42) 

There  are  now  various  probabilities  that  it might  potentially  be  of  interest  to  eval­
uate,  such  as: 

•	 P (R1  | D),  the  probability  that  R1  is  received,  given  that  D  was  sent; 
•	 P (D  |  R1 ),  the  probability  that  D  was  sent,  given  that  R1  was  received  — 
this  is  the  a  posteriori  probability  of  D ,  in  contrast  to  P (D),  which  is  the  a 
priori  probability  of D ; 
•	 P (D, R1 ),  the  probability  that D  is  sent  and  R1  is  received; 
•	 P (R1 ),  the  probability  that  R1  is  received. 
The  sample  space  of  our  probabilistic  experiment  can  be  described  by  Table  13.1, 
which  contains  an  entry  corresponding  to  every  possible  combination  of  transmit­
ted  symbol  and  received  sequence.  In  the  j th  row  of  column  A,  we  enter  the 
probability  P (A, Rj )  that  A  was  transmitted  and  Rj  received,  and  similarly  for 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

Section  13.4 

Hypothesis  Testing  in  Coded  Digital  Communication  243 

columns  B ,  C ,  and  D .  The  simplest  way  to  actually  compute  this  probability  is 
by  recognizing  that  P (A, Rj ) =  P (Rj  A)P (A);  the  characterization  of  the  chan­
|
nel  permits  computation  of P (Rj  A), while  the  characterization  of  the  information 
|
source  at  the  transmitter  yields  the  prior  probability  P (A).  Note  that  we  can  also 
write  P (A, Rj ) =  P (A Rj )P (Rj ).  Examples  of  these  three  ways  of  writing  the 
|
probabilities  of  the  outcomes  of  our  experiment  are  shown  in  the  table. 

13.4.3  Optimal  a  posteriori  Decision 

We  now  want  to  design  the  decision  rule  for  the  receiver,  i.e.,  the  rule  by  which 
it  decides  or  hypothesizes  what  symbol  was  transmitted,  after  the  reception  of  a 
particular  sequence.  We would  like  to  do  this  in  such  a way  that  the  probability  of 
error,  Pe ,  is  minimized. 
Since  a  decision  rule  in  our  example  selects  one  of  the  four  possible  symbols  (or 
hypotheses),  namely  A,  B ,  C ,  or  D ,  for  each  possible  Rj ,  it  can  be  represented 
in  Table  13.1  by  selecting  one  (and  only  one)  entry  in  each  row;  we  shall  mark 
the  selected  entry  by  a  box.  For  instance,  a  particular  decision  rule  may  declare 
D  to  be  the  transmitted  signal  whenever  it  receives  R4 ;  this  is  indicated  on  the 
table  by  putting  a  box  around  the  entry  in  row  R4 ,  column  D ,  as  shown.  Each 
possible  decision  rule  is  therefore  associated  with  a  table  of  the  preceding  form, 
with  precisely  one  entry  boxed  in  each  row. 

Now,  for  a  given  decision  rule,  the  probability  of  being  correct  is  the  sum  of  the 
probabilities  in  all  the  boxed  entries,  because  this  sum  gives  the  total  probability 
that  the  decision  rule  declares  in  favor  of  the  same  symbol  that  was  transmitted. 
The  probability  of  error,  Pe ,  is  therefore  1 minus  the  probability  of  being  correct. 
It  follows  that  to  specify  the  decision  rule  for  minimum  probability  of  error  or 
maximum  probability  of  being  correct,  we  must  pick  in  each  row  the  box  that  has 
the  maximum  entry.  (If  more  than  one  entry  has  the  maximum  value,  we  are  free 
to pick one of  these arbitrarily — Pe  is not aﬀected by which of  these we pick.)  For 
row Rj  in  Table  13.1,  we  should  pick  for  the  optimum  decision  rule  the  symbol  for 
which  we  maximize 

| 
P (symbol, Rj ) = P (Rj  symbol)P (symbol) 
= P (symbol  Rj )P (Rj )  . 
|
Table  13.2  displays  some  examples  of  the  required  computation  in  a  particular  nu­
merical  case.  The  computation  in  this  example  is  carried  out  according  to  the 
prescription  on  the  right  side  in  the  ﬁrst  of  the  above  pair  of  equations.  As  noted 
earlier,  this  is  generally  the  form  that  yields  the  most  direct  computation  in  prac­
tice, because the characterization of the channel usually permits direct computation 
of P (Rj  symbol), while the characterization of the  information source at the trans­
|
mitter  yields  the  prior  probabilities  P (symbol). 

(13.43) 

The  right  side  of  the  second  equation  in  (13.43)  permits  a  nice,  intuitive  interpre­
tation  of what  the optimum decision  rule does.  Since our  comparison  is being done 
across  the  row,  for  a  given  Rj  the  term  P (Rj )  in  the  second  equation  stays  the 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

244  Chapter  13 

Hypothesis  Testing 

A  : 000 

B  : 011 

C  : 101 

D  : 110 

P (A, R0 ) 

P (B , R0 ) 
P (C, R0 ) 
= P (R0 |B )P (B )  = P (C |R0 )P (R0 ) 
= p2 (1 − p)P (B ) 

P (D , R0 ) 

R0  = 000 

R1  = 001 

R2  = 010 

R3  = 011 

R4  = 100  P (A, R4 ) 

P (B , R4 ) 

P (C, R4 ) 

P (D , R4 ) 

R5  = 101 

R6  = 110 

R7  = 111 

TABLE  13.1  Each  entry  corresponds  to  a  transmitted  symbol  and  a  received 
sequence. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

Section  13.4 

Hypothesis  Testing  in  Coded  Digital  Communication  245 

same,  so  actually  all  that  we  need  to  compare  are  the  a  posteriori  probabilities, 
P (symbol  Rj ),  i.e.  the  probabilities  of  the  various  symbols,  given  the  data.  The 
|
optimum  decision  rule  therefore  picks  the  symbol  with  the  maximum  a  posteriori 
probability.  This  is  again  the MAP  decision  rule  that  we  derived  previously  in  the 
binary hypothesis case.  To summarize the important result we have arrived at here, 
and which we  shall encounter again  in more elaborate hypothesis  testing  contexts: 

For minimum error probability Pe , decide in favor of the choice that has maximum a 
posteriori probability, i.e., the choice whose probability, conditioned on the available 
data,  is maximum. 

Note that the only diﬀerence from the minimum-Pe  a priori decision rule we arrived 
at  earlier,  for  the  case  where  the  channel  was  down,  is  the  computation  now  has 
to  involve  conditional  or  a  posteriori  probabilities  —  conditioned  on  the  received 
information  —  rather  than  the  a  priori  probabilities.  The  receiver  still  decides  in 
favor of  the most probable choice, but now  incorporating  (i.e.,  conditioning on)  the 
received  information. 

°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 
c

246  Chapter  13 

Hypothesis  Testing 

000 
A 

011 
B 

101 
C 

110 
D 

Decision 

R0 
000 

R1 
001 
010  µ 
4 ¶2 
3 
R2 
R3 
011 

R4 
100 

R5 
101 
110  µ 
4 ¶2 
1 
R6 
R7 
111 

2  µ 
4 ¶2 
1 
1 
3 
4 

4  µ 
4 ¶3 
1 
1 
1 
4 

8  µ 
4 ¶2 
1 
3 

1 
1 
4 
8 

‘A’ 

2  µ 
4 ¶2 
3 
1 
1 
4 

4  µ 
4 ¶2 
3 
1 
1 
4 

8  µ 
4 ¶3 
3 
1 
3 
4 

1 
8 

‘D ’ 

1 , 
1 ,  P (B ) =  4
TABLE  13.2  Designing  the  optimal  decision  rule,  with  P (A) =  2
1 
1 ,  p  =  4
1 
P (C ) =  8
,  P (D) = 
.  The  MAP  rule  chooses  the  symbol  that  maximizes 
8
the  a  posteriori  probability,  P (symbol  data). 
| 

c°Alan  V.  Oppenheim  and  George  C.  Verghese,  2010 

MIT OpenCourseWare
http://ocw.mit.edu 

6.011 Introduction to Communication, Control, and Signal Processing 
Spring 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

