Spatially Distributed 
Queues II 

M/G/1 
2 Servers 
N servers: Hypercube Queueing Model 
Approximations 

Setup:  Hypercube  

Queueing Model 

aRegion comprised of geographical atoms 
or nodes 
aEach node j is an independent Poisson 
generator, with rate λj 
aTravel times: τil  = travel time from node i 
to node j 
aN servers 
aServer locations are random:  lnj 

Setup:  Hypercube  

Queueing Model - con't. 

aServer assignment:  one assigned

aState dependent dispatching 
aService times:  mean = 1/µn ; negative 
exponential density 
aService time dependence on travel time

aWe allow a queue (FCFS, infinite 
capacity) 

Fixed Preference Dispatch 
Policies for the Model 

aIdea:  for each atom, say Atom 12, there 
exists a vector of length N that is the 
preference-ordered list of servers to 
assign to a customer from that atom 
aExample:  {3,1,7,5,6,4,2}, for N=7. 

aDispatcher always will assign the most 
preferred available server to the customer 
aUsually order this list in terms of some 
travel time criterion. 

New York City 
EMS  Hypercube 

New York City 

EMS  Hypercube 

Illustration of Desktop Hypercube with ARCVIEW
Illustration of Desktop Hypercube with ARCVIEW


Illustration of Desktop Hypercube with ARCVIEW
Illustration of Desktop Hypercube with ARCVIEW


Example Dispatch Policies

aSCM:  Strict Center of Mass 
`Place server at its center of mass

`Place customer at its center of mass 
`Estimate travel times:  center of mass to 
center of mass 
aMCM:  Modified Center of Mass

`Place server at its center of mass 
`Keep customer at centroid of atom 
`Estimate travel times:  center of mass to 
centroid of atom 

Example Dispatch Policies


aEMCM:  Expected Modified Center of 
Mass 
`Do the conditional expected travel time 
calculation correctly, conditioned on the 
centroid of the atom containing the customer 

Are fixed preference  

policies optimal? 

aAVL:  Automatic Vehicle Location: 
dispatch the real time nearest server 
`This can be incorporated into the Hypercube 
framework, but very carefully! 
`Consider two servers:


Customer 
X 

RA1 

RA2 

X 

Customer in square 
marked X.  Place an 
asterisk in each square 
that could have the 
closest server. 
Assume each server is available 
and is located 'somewhere' in 
his/her square "police beat." 

* 
* 
* 

*
*
X*  * 
*
*

* 
* 
* 

* 
* 
* 
* 
* 

* 
* 
*
*
X*  * 
*
*
*
*

* 
* 
* 

What to know about the 
Hypercube Queueing Model 

aKnow the 2-server setup 
aBe able to work with a 3-server model 

`Read in the text the formulas to apply

aForget the cases for N>3 servers. 
aKnow Hypercube Approximation 
Procedure (still to come -- fasten your seat 
belts!) 

1,0 

1,1 

0,0 

0,1 

1,0 

1,1 

0,0 

0,1 

1,1,0 

1,1,1 

0,1,0 

0,1,1 

1,0,0 

1,0,1 

0,0,0 

0,0,1 

Hypercube Approximation 
Hypercube Approximation

Procedure:  A General Technique
Procedure:  A General Technique

aWant to reduce dramatically the number 
of simultaneous equations to solve 
aThe procedure reduces the number of 
equations from 2N  simultaneous linear 
equations to N simultaneous nonlinear 
equations. 
aWe look at only those performance 
measures we need, not at micro-structure 
of the binary state space 

Hypercube Approximation Procedure
Hypercube Approximation Procedure

A General Technique
A General Technique

Theory:  Sampling Servers Without  

Replacement from M/M/N Queue


From  M / M / N / ∞ we know the aggregate 

state probabilities:

k  = 0,1, 2, ..., N − 1 
P{Sk} ≡ Pk  =  N k ρk P0 / k! 
P{SN} ≡ PN  =  N N ρN P0  /(N![1 − ρ]) 
N −1 
P{S0} ≡ P0  = [∑ N iρ / i! + N N ρN  /( N!{1 − ρ})]−1 
i
i= 0 

The Hypercube Model, 
when the state space is 
compressed from its cube 
in N  dimensions to a 'line' 
birth and death process, 
always reduces to an 
M/M/N  queue (assuming 
service times are not 
server-specific) 

P{B1, B2
Bj , Fj +1} 
, ..., 
Key expression: 
For our applications, we do not need to know the fine grained 
binary state probabilities. 
Rather we need dispatch probabilities and 
server workloads. 
What about 'B-' probability reasoning?

"Flips coins" until first Heads is obtained:

(1 − ρ) 
jρ⎧
P{B1, B2 , ..., Bj , Fj +1} ≈ 
⎨
Nρ
⎩

Incompatible with known state probability PN 
Doesn't include biases. 

j  = 0,1, 2,..., N − 1
⎫
⎬
j =  N 
⎭


Let's "Divide and conquer": 
k = N 
∑
P{B1, B2 , ..., Bj , Fj +1} = 
P{B1 , B2 ,..., Bj , Fj +1 | Sk}Pk
k = 0 

 (*) 

Working carefully and slowly to find the state-conditioned 
dispatch probabilities: 
P{B1, B2 , ..., Bj , Fj +1 | Sk } =  P{Fj +1 | B1 , B2 , ..., Bj , Sk }...P{B2 | B1Sk}P{B1 | Sk} 
N − k ... 
k − 1 
k
P{B1, B2 , ..., Bj , Fj +1 | Sk } =	
(**)
... 
...... 
N − 1 
N −  j
N

Can plug (**) back into (*) and obtain an exact expression. 
Manipulate it to obtain a convenient form as "B-" probability 
reasoning with an 'A+" correction term: 
Bj , Fj +1} = Q ( N ,ρ, 
j )ρ(1 − ρ) 
j
P{B1, B2
, ..., 

(* * *)


"Correction factor" 

Explore properties of Correction Factor 

The desired dispatch probabilities can be written as a telescoped expression:

P{B1, B2 , ..., Bj , Fj +1} = P{Fj +1 | B1B2 ... Bj}P{Bj  | B1B2 ... Bj −1}...P{B1}


Use above in Eq.(***) to obtain: 

P{Fj +1 | B1 ...B j}  P{Bj  | B1 ...B j −1}
Q( N, r , j ) = [ 
][
1 − ρ 
ρ

]...[

P{B1}
ρ 

]

≤ 1 

≥ 1 

= 1


k  ≡ set of geographical atoms for which unit n is 
Gn 
the k th  preferred dispatch alternative 
nlj  ≡ 
j th  preferred unit for atom l 
id #  of the 
Set µ = 1 

∑ 
∑ 
∑ 
+  λj P{Bn j 1 Bn j 2  Fn} 
} +  λj P{Bn j 1 Fn} 
ρn  =  λj P{Fn 
+ ... + λPN  / N 
j∈Gn 
j ∈G n 
j∈Gn 
3 
2 
1 
ρn  =  λj (1 − ρn 
) +  λj Q( N ,ρ,1)ρn j 1 
2 ∑ 
1 ∑ 
j∈Gn 
j∈Gn 
(1 − ρn ) 
ρn j  2 
λjQ( N, ρ, 2 )ρn j 1 
+ ... + λPN  / N 
3 ∑ 
j ∈Gn 

(1 − ρn ) 
+ 

The last equation gives N nonlinear simultaneous equations in 
the unknown workloads, ρn, subject to the constraint that 
N 
∑  = λ
ρn 
     " normalization" 
n =1 

Typically converges in 3 to 5 iterations, within 1 to 2% of 
'exact Hypercube' results 

Response patterns: 
λk 
λQ( N ,ρ, j −
f nkj k  = 

j −1 ∏ 
ρn kl 
1){ 
l=1 

− ρn kj  )
}(1 

id # of jth  preferred 
unit for atom k 

j-1 more 
preferred 
units


jth  preferred 
unit 

Square Root Laws (approximations) 

In Chapter 3 we found 
E[ D] = C 

Area of service region 

A 
N 0 

Number of mobile servers 

depended on distance metric 
and location strategy 

Assumes all N0  servers are available or free (not busy) 

Now consider N  to be a R.V.


Might we expect the following to be true? 

A
k 

E[ D | N  = k ] = C 

k  = 1, 2,..., N0

What if the locations of servers were determined by a homogenous 
spatial Poisson process, with busy servers selected by "random erasers"? 

Getting to Expected Travel Distance 


N 0 
E[ D] =  P0 D0  + ∑ Pk C 
k =1 

A

k
From M/M/N0 
queueing model 
where Pk  = Probability of k servers available (M/M/N0) 

Moving to E[D]

Since P0≅0, we can write 
E[ D] ≅ C AE states of 
M  / M  / N 0 

[1 /  N ] 

We now apply "B-" probability reasoning, to get 
A
E[ D] ≅ C 
E[ N ] 

(Jensen's Inequality shows that this Eq. is a lower bound to true E[D].)


Finishing

E[ N ] ≈  N0  − N 0ρ =  N0 (1 − ρ) 
A 
E[ D] ≈ C 
N0 (1 − ρ) 
A 
N0 (1 − ρ) 

E[T ] ≈ C 
v 

+  v 
a 

Great results in practice 


Acceleration term 

Jensen's Inequality 


If g(X) is a convex function over the region of non-zero probability, 
then  E[g( X )] ≥ g( E[ X ]) 

(Problem 5.5 explores this further.) 

Jensen's Inequality

1.2 

1 /


N 

1 

0.8 

0.6 

0.4 

0.2 

0 

Series1 

N 
 

1 

2 

3 

4 

5 

6 

7 

8 

9 

10

]=0.5*(1) + 0.5*(10)
E[ 
= 0.5*(1 + 0.316) = 0.658 
1 /   N 
-0.5 
1/E[N]-0.5  = 1/(1*0.5 + 10*0.5)-0.5  =1/(5.5)-0.5  = 1/2.345 = 0.426 

1 /


N 

1.2 

1 

0.8 

0.6 

0.4 

0.2 

0 

True mean (0.658) 

Series1 

1 
2 
Suppose 50% of 
probability 
mass here 

3 

4 

5 

6 

7 

8 

9 

10

 

"B-" mean (0.426)

And suppose 50% 
of probability 
mass here


