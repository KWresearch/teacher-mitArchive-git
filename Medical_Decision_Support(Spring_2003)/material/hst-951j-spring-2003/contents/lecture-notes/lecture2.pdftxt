Simple Probabilistic  

Reasoning

6.873/HST951 

 

 

Harvard-MIT Division of Health Sciences and Technology
HST.951J: Medical Decision Support

Change over 30 years


•  1970’s: human knowledge, not much data 
•	 2000’s: vast amounts of data, traditional human 
knowledge (somewhat) in doubt 

•	 Could we “re-discover” all of medicine from 
data?  I think not! 
•	 Should we focus on methods for reasoning with
uncertain data?  Absolutely! 
•  But: Feinstein, A. R. (1977). “Clinical Biostatistics 
XXXIX. The Haze of Bayes, the Aerial Palaces of
Decision Analysis, and the Computerized Ouija Board.”
Clinical Pharmacology and Therapeutics 21: 482-496. 

Simplest Example 

•	 Relationship 
between a 
diagnostic 
conclusion 
and a 
diagnostic test 

Disease 
Present 

Disease 
Absent 

Test 
Positive 

True 
Positive 

False 
Positive 

TP+FP 

Test 
Negative 

False 
Negative 

True 
Negative 

FN+TN 

TP+FN 

FP+TN 

Disease 
Present 

Disease 
Absent 

Test 
Positive 

True 
Positive 

False 
Positive 

TP+FP 

Test 
Negative 

False 
Negative 

True 
Negative 

FN+TN 

TP+FN 

FP+TN 

Definitions 

Sensitivity (true positive rate): TP/(TP+FN) 
False negative rate: 1-Sensitivity = FN/(TP+FN) 
Specificity (true negative rate): TN/(FP+TN) 
False positive rate: 1-Specificity = FP/(FP+TN) 
Positive Predictive Value: TP/(TP+FP) 
Negative Predictive Value: TN/(FN+TN) 

Test Thresholds


-

+ 

FN 

FP

T


Wonderful Test 


-

+ 

FN 

FP

T


Test Thresholds Change Trade-off  

between Sensitivity and Specificity 


-

FN 

+ 

FP

T


Receiver Operator Characteristic 

(ROC) Curve


TPR (sensitivity) 
1 

T 

0 

0 

FPR (1-specificity)


1


What makes a better test? 


TPR (sensitivity) 
1 

superb 

OK 

worthless 

0 

0 

FPR (1-specificity)


1


How certain are we after a test?

T+ 

TP=p(T+|D+) 

D+ 

p(D+) 

FN=p(T-|D+) 

D? 

T­

T+ 

p(D-)=1-p(D+) 

D-

FP=p(T+|D-) 

Bayes’ Rule: 

P i (D j )P (S | D j ) 
TN=p(T-|D-) 
P i+1( D j)  =	 n
� P i (D k )P (S | D k)
k=1 

T-

Rationality


•	 Behavior is a continued sequence of 
choices, interspersed by the world’s 
responses 
•	 Best action is to make the choice with the 
greatest expected value 
•  … decision analysis 

Example: Acute Renal Failure 

•  Based on Gorry, et al., AJM 55, 473-484, 1973. 
•	 Choice of a handful (8) of therapies (antibiotics, 
steroids, surgery, etc.) 
•	 Choice of a handful (3) of invasive tests 
(biopsies, IVP, etc.) 
•	 Choice of 27 diagnostic “questions” (patient 
characteristics, history, lab values, etc.) 
•  Underlying cause is one of 14 diseases 
–  We assume one and only one disease 

Decision Tree for ARF 

•  Choose: 
– Surgery for obstruction 
– Treat with antibiotics 
– Perform pyelogram 
– Perform arteriography 
– Measure patient’s temperature 
– Determine if there is proteinuria 
– … 

Decision Tree for ARF


Value = ???


Surgery for obstruction

Treat with antibiotics

Perform pyelogram 

Perform arteriography

Measure patient’s  

temperature

Determine if there is  

proteinuria 


What happens when we act?


•  Treatment: leads to few possible outcomes 
–  different outcomes have different probabilities 
•  probabilities depend on distribution of disease probabilities 
–  value of outcome can be directly determined 
•  value may depend on how we got there (see below) 
•	 therefore, value of a treatment can be determined by 
expectation 
•	 Test: lead to few results, revise probability 
distribution of diseases, and impose disutility 
•	 Questions: lead to few results, revise probability 
distribution 

Treatment Outcome

(not as in ARF) 


p1 

p2 

p3 

p4 

Surgery for Obstruction 


V 

�
= 
i 

piV (O

i ) 

Dead 

0 

Remained obstructed 

600


Cleared but complications 

900


Perfect outcome


1000


Full decision tree


P´ 

A1 

A2 

A3 

A4 

P


A1 

A2 

A3 

A4 

P´´ 

A1 

A2 

A3 

A4 

Initial probability distribution 


0.250 
ATN 
Acute tubular necrosis 
0.400 
FARF  Functional acute renal failure 
0.100 
OBSTR  Urinary tract obstruction 
0.100 
AGN  Acute glomerulonephritis 
0.020 
CN 
Renal cortical necrosis 
0.005 
Hepatorenal syndrome 
HS 
0.010 
PYE 
Pyelonephritis 
0.003 
Atheromatous Emboli 
AE 
0.002 
RI 
Renal infarction (bilateral) 
0.002 
RVT 
Renal vein thrombosis 
0.050 
VASC  Renal vasculitis 
SCL 
0.002 
Scleroderma 
CGAE  Chronic glomerulonephritis, acute exacerbation  0.030 
0.030 
Malignant hypertension & nephrosclerosis 
MH 

ARF’s Database: P(obs|D)


Conditional probabilities for 
Proteinuria 
Diseases 

Probabilities 
Trace 
to 2+ 

0 

ATN

FARF

OBSTR

AGN

CN

HS 

PYE

AE

RI 

RVT

VASC 

SCL

CGAE

MH


0.1 
0.8 
0.7 
0.01 
0.01 
0.8 
0.4 
0.1 
0.1 
0.001 
0.01 
0.1 
0.001 
0.001 

0.8 
0.2 
0.3 
0.2 
0.8 
0.2 
0.6 
0.8 
0.7 
0.1 
0.2 
0.4 
0.2 
0.4 

3+ to 
4+ 

0.1 
0.001 
0.001 
0.8 
0.2 
0.001 
0.001 
0.1 
0.2 
0.9 
0.8 
0.5 
0.8 
0.6 

Questions 


•  Blood pressure at onset 
•  proteinuria 
• 
casts in urine sediment 
•  hematuria 
•  history of prolonged hypotension 
•  urine specific gravity 
• 
large fluid loss preceding onset 
• 
kidney size 
•  urine sodium 
• 
strep  infection within three weeks 
•  urine volume 
• 
recent surgery or trauma 
•  age 
•  papilledema 
flank pain 
• 
• 
skin, intestinal or lung lesions 

•  history of proteinuria 
• 
symptoms of bladder obstruction 
•  exposure to nephrotoxic  drugs 
•  disturbance in clotting mechanism 
•  pyuria 
•  bacteriuria 
sex 
• 
• 
transfusion within one day 
jaundice or ascites 
• 
•	
ischemia of extremities or aortic 
aneurism 
•  atrial fibrillation or recent MI 

Invasive tests and treatments 


•  Tests 
–  biopsy 
–  retrograde 
pyelography 
–  transfemoral 
arteriography 

•  Treatments 
– 
steroids 
conservative therapy 
– 
iv-fluids 
– 
surgery for urinary tract 
– 
obstruction 
antibiotics 
surgery for clot in renal 
vessels 
antihypertensive drugs

heparin 

–

–


–

–


Updating probability distribution


Pi(D j)P(S|D j) 
Pi+1(D j) =	 n
� Pi(Dk)P(S|Dk)
k=1 

Bayes’ rule


Value of treatment 

•	 Three results: improved, unchanged, 
worsened 
– each has an innate value, modified by “tolls” 
paid on the way 
•	 Probabilities depend on underlying 
disease probability distribution 
V(I)

I 
Ip 
Up 

Tx


U 

V(U)


W 

V(W)


Modeling treatment 

Utilities: 
improved: 
unchanged: 
worse: 

5000

-2500

-5000


Steroids 
improved   unchanged   worse 
0 .20  
0 .20  
0 .60  
0 .60  
0 .35  
0 .05  
0 .05  
0 .60  
0 .35  
0 .20  
0 .40  
0 .40  
0 .05  
0 .75  
0 .20  
0 .90  
0 .05  
0 .05  
0 .90  
0 .05  
0 .05  
0 .05  
0 .70  
0 .25  
0 .85  
0 .14  
0 .01  
0 .10  
0 .30  
0 .60  
0 .60  
0 .25  
0 .15  
0 .90  
0 .05  
0 .05  
0 .40  
0 .35  
0 .25  
0 .90  
0 .05  
0 .05  

atn 
farf 
obstr 
agn  
cn  
hs  
pye  
ae  
ri 
rv t 
vasc  
s c l  
cgae  
mh 

Modeling test:  

transfemoral arteriography


p(clot) 
cos t  
0 .01   500  
0 .01   800  
0 .01   500  
0 .01   500  
0 .01   500  
0 .01   800  
0 .01   500  
0 .03   800  
0 .85   500  
0 .50   500  
0 .01   500  
0 .01   500  
0 .01   500  
0 .01   500  

a tn  
farf 
obstr 
agn 
cn  
hs 
pye  
ae 
r i  
rv t  
vasc  
sc l  
cgae 
mh 

How large is the tree? 

•  Infinite, or at least (27+3+8)^(27+3+8), ~10^60 
•  What can we do? 
–  Assume any action is done only once 
–  Order: 
•  questions 
•  tests 
•  treatments 
•  27! x 4 x 3 x 2 x 8, ~10^30 
•  Search, with a myopic evaluation function 
–  like game -tree search; what’s the static evaluator? 
–  Measure of certainty in the probability distribution 

How many questions needed? 

•	 How many items can you distinguish by 
asking 20 (binary) questions?  2^20 
•	 How many questions do you need to ask 
to distinguish among n items?  log2(n) 
•	 Entropy of a probability distribution is a 
measure of how certainly the distribution 
identifies a single answer; or how many 
more questions are needed to identify it 

Entropy of a distribution


n 
H i ( P1 ,K, Pn ) =  � - Pj  log 2 Pj
j =1 

For example: 
H(.5, .5) = 1.0 
H(.1, .9) = 0.47

H(.01, .99) = 0.08

H(.001, .999) = 0.01


H(.33, .33, .33) = 1.58 (!)

H(.005, .455, .5) = 1.04 
H(.005, .995, 0) = 0.045


(!) -- should use  logn 

P

j


Interacting with ARF in 1973

Question 1: What is the patient's age? 

1  0-10 

2  11-30 

3  31-50 

4  51-70 

5  Over 70 

Reply: 5


The current distribution is:

Disease 
Probability

FARF  0.58

IBSTR  0.22

0.09

ATN 

Question 2: What is the patient's sex?

1  Male

2  Pregnant Female 

3  Non-pregnant Female

Reply: 1

. . .


Local Sensitivity Analysis


Case-specific Likelihood Ratios


Therapy Planning Based on  

Utilities


Global Sensitivity Analysis 


•	 When asking questions, “how bad could it 
get for the leading hypothesis?” 
– Assume all future answers are worst possible 
in terms of likelihood ratio P(obs|D)/P(obs|~D) 
– Usually, (0,1) 
– Can compute second order probability
P(p)distribution 
“real” p 
= average 

p


Assumptions in ARF 


•	 Exhaustive, mutually exclusive set of 
diseases 
•	 Conditional independence of all questions, 
tests, and treatments 
•	 Cumulative (additive) disutilities of tests 
and treatments 
•	 Questions have no modeled disutility, but 
we choose to minimize the number asked 
anyway 

DeDombal, et al. Experience

1970’s & 80’s

•  “Idiot Bayes” for appendicitis 
•  1.  Based on expert estimates -- lousy 
•  2.  Statistics -- better than docs 
•  3.  Different hospital -- lousy again 
•  4.  Retrained on local statistics -- good 

Demo of ARF & Similar Programs


