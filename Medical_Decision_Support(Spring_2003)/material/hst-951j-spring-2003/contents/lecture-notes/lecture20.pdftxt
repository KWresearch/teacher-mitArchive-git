Unsupervised Learning 

A review of clustering and other

exploratory data analysis methods


HST.951J: Medical Decision Support

Harvard-MIT Division of Health Sciences and Technology 
HST.951J: Medical Decision Support 

A few “synonyms”… 
n Nosography 
n Agminatics 
n Nosology 
n Aciniformics 
n Q-analysis 
n Numerical taxonomy 
n Typology 
n Botryology 
n Clustering 
n Systematics 
n Taximetrics 
n Clumping 
n Morphometrics 

n A multidimensional 
space needs to be 
reduced… 

What we are trying to do 
Predict this 
test1 
-0.2 
0.5 
0.1 
-0.9
0.4 
0.6 
-0.7 

We are trying to 
see whether 
there seems to 
exist patterns in 
the data… 

0.8 
-0.4 
0.2 
0.3 
0.2 
0.3 
-0.4

Case 1


Case 2


age 
0.7 
0.6 
-0.6 
0 
-0.4 
-0.8 
0.5 

Using these 

Exploratory Data Analysis 

n Hypothesis generation versus 
hypothesis testing… 
n The goal is to visualize patterns and 
then interpret them 

n Unsupervised: No GOLD STANDARD 


See Khan et al. Nature Medicine, 7(6): 673  - 679. 

Outline 
n Proximity 
n Distance Metrics 
n Similarity Measures 
n Clustering 
n Hierarchical Clustering 
n Agglomerative 
n K-means 
n Multidimensional Scaling 
n Graphical Representations 

Similarity between objects 

Similarity Data 

Relation of Data to 
Spatial Representation 

Spatial Representation 

Percent “same” 
judgments for all pairs of 
successively presented 
aural signals of the 
International Morse 
Code (see Rothkopf, 
1957). 

Obtained relation between 
Rothkopf’s original similarity 
data for the 36 Morse Code 
signals and the Euclidean 
distances in Shepard’s spatial 
solution. 

Two-dimensional spatial solution 
for the 36 Morse Code signals 
obtained by Shepard (1963) on 
the basis of Rothkopf’s (1957) 
data. 

Unsupervised Learning 

Raw 
Data 

Distance 
or 
Similarity 
Matrix 

Dimensionality 
Reduction 
•MDS 

•Wavelet 

Clustering 
•Hierarchical 

•Non-hierar. 

Graphical 
Representation 

“Validation” 
•Interna
l 
•Extermal 

Algorithms, similarity measures, and 
graphica representations 
l 

n Most algorithms are not necessarily linked to 
a particular metric or similarity measure 
n Also not necessarily linked to a particular 
graphical representation 

n There has been interest in this given high 
throughput gene expression technologies 
n Old algorithms have been rediscovered and 
renamed 

Metrics 

Minkowski r-metric 

d


ij 

d 
ij 

K 
ÏÂ 
xik

= 
Ì
1Ó
k 
= 
K

Ï
Â

= 
Ì
Ó 
=k  1 

xik 

-

x

jk 

-

x

jk 

d

ij 

K 
Ï
Â

= 
Ì
Ó 
=k  1 

xik


-

x

jk

r 

1 
r

¸
˝
˛ 

¸
˝
˛ 
1 
2 

¸
2 
˝
˛ 

j 

Manhattan 
n 
n (city-block) 


Euclidean 
n 

i


Metric spaces 

n Positivity  d ij  > d ii  = 0 
Reflexivity 
n Symmetry  d ij  = d ji 
n Triangle 
inequality  d ij  £ d ih  + d hj 

j

h 

i 

More metrics 
n Ultrametric  d ij  £ max[d ih , d hj ] 
replaces 
d ij  £ d ih  + d hj 

j


i 

h 

n Four-point  d hi  + d  £ max [(d hj  + d ik  )( d  + d ij )]
, 
jk 
hk 
additive 
replaces 
d ij  £ d ih  + d
condition 

hj 

Similarity measures 

n Similarity function

n For binary, “shared attributes” 
i t  j
i  j 

i s 
, ( 

j ) =

, ( 
i s 

j ) = 

1 
2 ¥1 

it = [1,0,1] 
0
j =


0

 1


Variations… 

j ) =

, ( 
i s 

Fraction of  attributes shared 
d 
n 
t i j
d 
n Tanimoto coefficient 
t i j 
j ) =  t
i i  +  j j - i t  j 
t 
1
2 + 1 - 1 

i s  , ( 

, ( 
i s 

j ) =

it = [1,0,1]
j =  0

0
1

More variations… 

n Correlation

n Linear 
n Rank 
n Entropy-based 
n Mutual information 
n Ad-hoc 
n Neural networks 

Clustering


Hierarchical Clustering 

n Agglomerative Technique

n Successive “fusing” cases 
n Respect (or not) definitions of intra- and 
/or inter-group proximity 
n Visualization 
n Dendrogram, Tree, Venn diagram 

Data Visualization 

Linkages 

n Single-linkage: proximity to the closest 
element in another cluster 
n Complete-linkage: proximity to the most 
distant element 
n Mean: proximity to the mean (centroid)


Graphical Representations


Hierarchical 

Additive Trees 

n Commonly the minimum spanning tree

n Nearest neighbor approach to 
hierarchical clustering 

Non-Hierarchical: 
Distance threshold 

See Duda et al., “Pattern Classification”


k-means clustering 
(Lloyd’s algorithm) 

1.  Select k (number of clusters)

2.  Select k initial cluster centers c1,…,ck 
Iterate until convergence: For each i,

3. 
1.	 Determine data vectors vi1,…,vin closest 
(i.e., partition space)
to ci 
2.  Update ci as ci = 1/n (vi1+…+vin ) 

k-means clustering example


k-means clustering example


k-means clustering example


Common mistakes 

n Refer to dendrograms as meaning 
“hierarchical clustering” in general 
n Misinterpretation of tree-like graphical 
representations 
n Ill definition of clustering criterion 
n Declare a clustering algorithm as “best” 
n Expect classification model from clusters 
n Expect robust results with little/poor data 

Dimensionality Reduction


Multidimensional Scaling 

n Geometrical models

n Uncover structure or pattern in 
observed proximity matrix 
n Objective is to determine both 
dimensionality  d  and the position of 
points in the d-dimensional space 

Metric and non-metric MDS 

n Metric (Torgerson 1952)

n Non-metric (Shepard 1961)

n Estimates nonlinear form of the monotonic 
function 

sij  =  f 
(d ij )

mon 

Similarity Data 

Judged similaritied 
between 14 spectral 
colors varying in 
wavelength from 434 to 
674 nanometers (from 
Ekman, 1954) 

Relation of Data to 
Spatial Representation 

Spatial Representation 

Obtained relation between 
Ekman’s original similarity data 
for the 14 colors and the 
Euclidean distances in Shepard’s 
spatial solution. 

Two-dimensional spatial solution 
for the 14 colors obtained by 
Shepard (1962) on the basis of 
Ekman’s (1954) similarity data. 

Stress and goodness-of-fit 

Stress 

n 20 
n 10 
n 5 
n 2.5 
n 0 

Goodness of fit 


n Poor 
n Fair 
n Good 
n Excellent 
n Perfect 

References 

n Reference books for this course (Duda 
and Hard, Hastie et al.) 
n B. Everitt 
n J. Hartigan

n R. Shepard


n Sage books 


