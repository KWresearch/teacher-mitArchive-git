18.700  STUDY  GUIDE  FOR  CHAPTERS  0–1 

This  guide  contains  a  checklist  of  important  skills,   deﬁnitions  and   theorems  to  learn  before  Exam 
1.  You  do  not  need  to  memorize   the   proofs  of   the  theorems,  but  you  should  learn  the   statements 
and  be  able  to   use  the  theorems. 

If  linearly 

Skills  checklist: 
1.  Put a  linear  system  or  matrix  in  row  echelon  form  and   in  reduced row  echelon  form. 
2.  Determine  when  2  linear  system  or  matrices  are  row  equivalent. 
3.  Determine  whether  a  linear  system  is   consistent,  and   if  so,  determine  all  solutions. 
4.  Determine   if  2  matrices  can   be  multiplied   in   a  particular  order,   and  if  so,  compute  their   product. 
5.  If  it  exists,   compute  the   left  inverse,  resp.  right  inverse,  left­right  inverse,   of  a  matrix. 
6.  Determine  if  a  vector  w  is  a  linear  combination  of   a  set  of   vectors  (v1 , . . . , vm ),  and  if   so,  ﬁnd 
· · · 
coeﬃcients  c1 , . . . , cm  such that  w  =  c1v1  +
+  cmwm .
7.  Determine  whether  a   set  of  vectors  is  linearly  independent  or   linearly  dependent. 
dependent,  ﬁnd  a  linearly   independent  subset  spanning  the  same  vector  space. 
8.  Find  the  rank  of  a  matrix,  a   basis   for  the  row  space,  a  basis   for  the  column  space,  and  a  basis 
for  the  nullspace. 
9.  Given  2  ordered  bases  for  a  vector  space,  compute   the  change­of­basis  matrix. 
Deﬁnition   checklist:  Learn  each  of  the  following  deﬁnitions. 
System  of  linear  equations   =  Linear  system  of  equations  (Def.   0.1.1);  Set  of   solutions   = 
Solution  set  (Def.  0.1.2);  Elementary row  operations  (Def.   0.1.3,   Def.  0.4.1);  Row  equivalent  
(Def.  0.1.6,   Def.  0.4.1);  Echelon  form  (Def.  0.2.4,  Def.  0.4.3);  Leading  variable  ≈ Determined 
variable  (Def.  0.2.4);   Free  variable  (Def.   0.2.4);  Reduced  echelon  form  (Def.   0.2.6,  Def.   0.4.3); 
Matrix  (Def.  0.3.1);  Row  vector,  Column  vector  (p.   24);  Upper  triangular   matrix,   Lower 
triangular  matrix,  Diagonal  matrix  (Def.   0.3.8);  Block  matrix   (Def.   0.3.11);  Coeﬃcient 
matrix,  Value  matrix  (p.  39);   Augmented  matrix  (p.  40);  Elementary  matrix  (Def.   0.4.8); 
Homogeneous  system,   Associated  homogeneous  system  (Def.   0.5.1);  Rank   (Def.  0.5.6); 
Left   inverse,  Right  inverse,  Inverse  (Def.  0.6.2);  Transpose   (Def.  0.6.13);  Symmetric  matrix 
(Def.  0.6.13); 
Field  (Def.  1.1.1);   Linear   combination,  Span   (Def.  1.1.2);  Vector  subspace  (Def.  1.1.5, 
Def.  1.2.5);  Row  space,  Column  space,  Nullspace  (Def.   1.2.1);   Vector  space  (Def.  1.2.4); 
Linearly  independent,  Linearly  dependent  (Def.   1.3.1);  Linear  relation,  Trivial   linear 
relation,  Nontrivial  linear   relation  (in  lecture);  Basis  (Def.   1.4.1);  Dimension  (Def.   1.4.3); 
Nullity  (p.  121);   Ordered  basis   (Def.  1.5.2);  Coordinates  (Def.   1.5.2);  Change­of­basis 
matrix  (in  lecture) 
Theorem   checklist:  Learn  the   statements  of  the   following  theorems  (you  do  not  need  to  learn 
them  verbatim,   but  learn  their  meaning).  You   do  not  need  to  memorize  the   proofs,  but  be  able  to 
use  the  theorems. 
Theorem   0.1.8  Row   equivalent  linear  systems  have   the  same  set  of   solutions. 
Theorem   The  result  of  Gaussian  elimination  is  a  row  equivalent  linear  system  or  matrix  in  row­
echelon  form.  The   result  of  Gauss­Jordan  elimination   is  a   equivalent  linear   system  or   matrix  in 
reduced  row­echelon  form. 

1 

Theorem  0.3.3   Addition,  scalar  multiplication,   and  multiplication  of   matrices  satisfy  familiar

arithmetic  identities,  but  matrix   multiplication  is  not   necessarily  commutative,  i.e.,  AB  =� BA. 

Theorem   0.4.10,  Theorem  0.6.8  Row  equivalent  matrices   diﬀer  by  left  multiplication   by  an

invertible  matrix.

Theorem  0.5.5  Row   equivalent  matrices  have   equal  reduced   row­echelon  matrices.

Corollary  Consistent  m × n  linear  systems  with  the  same  set  of  solutions   are  row  equivalent.

Theorem   0.5.7  The   linear  system  AX  =  B  is  consistent  iﬀ  rank(A)  =  rank(A|B ).  There  is   a

unique  solution  iﬀ  rank(A) =   n = rank(A|B ) where  n  is  the  number  of   variables.

Theorem   0.6.6  A  product  of  invertible  matrices  is  invertible,  and  the  inverse   is  the  product  of  the

inverses  in  reverse   order.

Theorem   0.6.9   A  square  matrix  A is  invertible  iﬀ   AX  =  B  is   consistent  for   every  B  iﬀ   rank(A) is 

the  number  of   rows  iﬀ  A is  a  product  of  elementary  matrices.

Corollary  Matrices  diﬀering  by   left  multiplication   by  an  invertible   matrix  are   row  equivalent.

Theorem   1.1.4   The   p­vector  w  is  a   linear  combination   of  the  p­vectors  v1 , . . . , vm  iﬀ  the   system

AX   =  w  is  consistent,  where   A = (v1 | . . . vm ).
|
Theorem   1.3.4  The   p­vectors   v1 , . . . , vm  are   linearly  independent  iﬀ  the  matrix  A = (v1 | . . . vm )
|
has  rank  m. 
Theorem   1.4.6   The   rank,  row   space,  column  space  and   nullspace  of  a   matrix  can   be   simply 
computed  given  the   reduced  row­echelon   form. 

2 

