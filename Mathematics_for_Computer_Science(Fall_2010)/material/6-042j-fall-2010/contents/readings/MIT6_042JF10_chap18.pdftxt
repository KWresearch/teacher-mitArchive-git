“mcs-ftl” — 2010/9/8 — 0:40 — page 467 — #473

18

Expectation

18.1 Deﬁnitions and Examples

The expectation or expected value of a random variable is a single number that
tells you a lot about the behavior of the variable. Roughly, the expectation is the
average value of the random variable where each value is weighted according to its
probability. Formally, the expected value (also known as the average or mean) of a
random variable is deﬁned as follows.
ExŒR WWD X
Deﬁnition 18.1.1. If R is a random variable deﬁned on a sample space S , then the
expectation of R is
w 2S
For example, suppose S is the set of students in a class, and we select a student
uniformly at random. Let R be the selected student’s exam score. Then ExŒR is
just the class average—the ﬁrst thing everyone wants to know after getting their test
back! For similar reasons, the ﬁrst thing you usually want to know about a random
variable is its expected value.
Let’s work through some examples.

R.w / PrŒw :

(18.1)

18.1.1 The Expected Value of a Uniform Random Variable
Let R be the value that comes up with you roll a fair 6-sided die. The the expected
value of R is
ExŒR D 1 (cid:1) 1
C 2 (cid:1) 1
C 3 (cid:1) 1
C 4 (cid:1) 1
C 5 (cid:1) 1
C 6 (cid:1) 1
D 7
6
6
6
6
6
6
2
This calculation shows that the name “expected value” is a little misleading; the
random variable might never actually take on that value. You don’t ever expect to
2 on an ordinary die!
roll a 3 1
Also note that the mean of a random variable is not the same as the median. The
median is the midpoint of a distribution.
Deﬁnition 18.1.2. The median1 of a random variable R is the value x 2 range.R/
1Some texts deﬁne the median to be the value of x 2 range.R/ for which PrŒR  x  < 1=2 and
PrŒR > x   1=2. The difference in deﬁnitions is not important.

:

1“mcs-ftl” — 2010/9/8 — 0:40 — page 468 — #474

Chapter 18 Expectation

such that

PrŒR  x   1
2
1

PrŒR > x  <

:

and

2
In this text, we will not devote much attention to the median. Rather, we will
focus on the expected value, which is much more interesting and useful.
Rolling a 6-sided die provides an example of a uniform random variable.
In
general, if Rn is a random variable with a uniform distribution on f1; 2 ; : : : ; ng,
ExŒRn  D nX
then
D n C 1
D n.n C 1/
i D1
2
2n
18.1.2 The Expected Value of an Indicator Random Variable
The expected value of an indicator random variable for an event is just the proba-
bility of that event.
Lemma 18.1.3. If IA is the indicator random variable for event A, then
ExŒIA  D PrŒA:

i (cid:1) 1
n

:

Proof.

(cid:4)

(def of IA )

ExŒIA  D 1 (cid:1) PrŒIA D 1 C 0 (cid:1) PrŒIA D 0
D PrŒIA D 1
D PrŒA:
For example, if A is the event that a coin with bias p comes up heads, then
ExŒIA  D PrŒIA D 1 D p .
18.1.3 Alternate Deﬁnitions
There are several equivalent ways to deﬁne expectation.
ExŒR D X
Theorem 18.1.4. If R is a random variable deﬁned on a sample space S then
x (cid:1) PrŒR D x :
x2range.R/
The proof of Theorem 18.1.4, like many of the elementary proofs about expecta-
tion in this chapter, follows by judicious regrouping of terms in the Equation 18.1:

(18.2)

2“mcs-ftl” — 2010/9/8 — 0:40 — page 469 — #475

(Def 18.1.1 of expectation)

18.1. Deﬁnitions and Examples
ExŒR D X
Proof.
D X
X
R.! / PrŒ! 
!2S
X
D X
R.! / PrŒ! 
!2ŒRDx 
x2range.R/
(def of the event ŒR D x )
1A (distributing x over the inner sum)
0@ X
x PrŒ! 
D X
x2range.R/
!2ŒRDx 
D X
PrŒ! 
x
!2ŒRDx 
x2range.R/
(def of PrŒR D x )
x (cid:1) PrŒR D x :
x2range.R/
The ﬁrst equality follows because the events ŒR D x  for x 2 range.R/ partition
the sample space S , so summing over the outcomes in ŒR D x  for x 2 range.R/
is the same as summing over S .
(cid:4)
In general, Equation 18.2 is more useful than Equation 18.1 for calculating ex-
pected values and has the advantage that it does not depend on the sample space,
but only on the density function of the random variable. It is especially useful when
the range of the random variable is N, as we will see from the following corollary.
1X
1X
Corollary 18.1.5. If the range of a random variable R is N, then
ExŒR D
i PrŒR D i  D
i D1
i D0
Proof. The ﬁrst equality follows directly from Theorem 18.1.4 and the fact that
range.R/ D N. The second equality is derived by adding the following equations:
PrŒR > 0 D PrŒR D 1 C PrŒR D 2 C PrŒR D 3 C (cid:1) (cid:1) (cid:1)
PrŒR > 1 D
PrŒR D 2 C PrŒR D 3 C (cid:1) (cid:1) (cid:1)
PrŒR > 2 D
PrŒR D 3 C (cid:1) (cid:1) (cid:1)

PrŒR > i :

1X
i D0

:::
PrŒR > i  D 1 (cid:1) PrŒR D 1 C 2 (cid:1) PrŒR D 2 C 3 (cid:1) PrŒR D 3 C (cid:1) (cid:1) (cid:1)
1X
i D1

i PrŒR D i :

D

(cid:4)

3“mcs-ftl” — 2010/9/8 — 0:40 — page 470 — #476

Chapter 18 Expectation

18.1.4 Mean Time to Failure
The mean time to failure is a critical parameter in the design of most any system.
For example, suppose that a computer program crashes at the end of each hour of
use with probability p , if it has not crashed already. What is the expected time until
the program crashes?
If we let C be the number of hours until the crash, then the answer to our prob-
lem is ExŒC . C is a random variable with values in N and so we can use Corol-
1X
lary 18.1.5 to determine that
i D0

ExŒC  D

PrŒC > i :

(18.3)

PrŒC > i  is easy to evaluate: a crash happens later than the i th hour iff the
system did not crash during the ﬁrst i hours, which happens with probability .1 (cid:0)
1X
p /i . Plugging this into Equation 18.3 gives:
ExŒC  D
.1 (cid:0) p /i
i D0
D
1
1 (cid:0) .1 (cid:0) p /
D 1
p

(sum of geometric series)

(18.4)

:

For example, if there is a 1% chance that the program crashes at the end of each
hour, then the expected time until the program crashes is 1=0:01 D 100 hours.
The general principle here is well-worth remembering:

If a system fails at each time step with probability p , then the expected
number of steps up to (and including) the ﬁrst failure is 1=p .

Making Babies
As a related example, suppose a couple really wants to have a baby girl. For sim-
plicity, assume that there is a 50% chance that each child they have is a girl, and
that the genders of their children are mutually independent. If the couple insists on
having children until they get a girl, then how many baby boys should they expect
ﬁrst?
The question, “How many hours until the program crashes?” is mathematically
the same as the question, “How many children must the couple have until they
get a girl?” In this case, a crash corresponds to having a girl, so we should set

4“mcs-ftl” — 2010/9/8 — 0:40 — page 471 — #477

18.1. Deﬁnitions and Examples
p D 1=2. By the preceding analysis, the couple should expect a baby girl after
having 1=p D 2 children. Since the last of these will be the girl, they should
expect just one boy.

18.1.5 Dealing with Inﬁnity
The analysis of the mean time to failure was easy enough. But if you think about it
further, you might start to wonder about the case when the computer program never
fails. For example, what if the program runs forever? How do we handle outcomes
with an inﬁnite value?
These are good questions and we wonder about them too. Indeed, mathemati-
cians have gone to a lot of work to reason about sample spaces with an inﬁnite
number of outcomes or outcomes with inﬁnite value.
To keep matters simple in this text, we will follow the common convention of
ignoring the contribution of outcomes that have probability zero when computing
expected values. This means that we can safely ignore the “never-fail” outcome,
because it has probability
n!1.1 (cid:0) p /n D 0:
lim
In general, when we are computing expectations for inﬁnite sample spaces, we
will generally focus our attention on a subset of outcomes that occur with collec-
tive probability one. For the most part, this will allow us to ignore the “inﬁnite”
outcomes because they will typically happen with probability zero.2
This assumption does not mean that the expected value of a random variable is
always ﬁnite, however. Indeed, there are many examples where the expected value
is inﬁnite. And where inﬁnity raises its ugly head, trouble is sure to follow. Let’s
see an example.

18.1.6 Pitfall: Computing Expectations by Sampling
Suppose that you are trying to estimate a parameter such as the average delay across
a communication channel. So you set up an experiment to measure how long it
takes to send a test packet from one end to the other and you run the experiment
100 times.
You record the latency, rounded to the nearest millisecond, for each of the hun-
dred experiments, and then compute the average of the 100 measurements. Suppose
that this average is 8.3 ms.
Because you are careful, you repeat the entire process twice more and get aver-
ages of 7.8 ms and 7.9 ms. You conclude that the average latency across the channel

2 If this still bothers you, you might consider taking a course on measure theory.

5“mcs-ftl” — 2010/9/8 — 0:40 — page 472 — #478

Chapter 18 Expectation

is



:

(cid:0) 1
4

(cid:0) 1
3

(18.5)

7:8 C 7:9 C 8:3
D 8 ms:
3
You might be right but you might also be horribly wrong. In fact, the expected
latency might well be inﬁnite. Here’s how.
(
Let D be a random variable that denotes the time it takes for the packet to cross
the channel. Suppose that
for i D 0
PrŒD D i  D
0
for i 2 NC
(cid:0) 1
i C1
1
i
 C (cid:1) (cid:1) (cid:1) D 1
 C  1
 C  1
PrŒD D i  D 
1X
It is easy to check that
1 (cid:0) 1
i D0
2
2
3
and so D is, in fact, a random variable.
From Equation 18.5, we might expect that D is likely to be small. Indeed, D D 1
with probability 1=2, D D 2 with probability 1=6, and so forth. So if we took
100 samples of D , about 50 would be 1 ms, about 16 would be 2 ms, and very
few would be large. In summary, it might well be the case that the average of the
100 measurements would be under 10 ms, just as in our example.
This sort of reasoning and the calculation of expected values by averaging ex-
perimental values is very common in practice. It can easily lead to incorrect con-
clusions, however. For example, using Corollary 18.1.5, we can quickly (and accu-
1X
rately) determine that
1X
i D1
1X
i D1
1X
i D1
D
i D1
D 1:
Uh-oh! The expected time to cross the communication channel is inﬁnite! This
result is a far cry from the 10 ms that we calculated. What went wrong?

i PrŒD D i 
 1
(cid:0) 1


i C 1
i
i
1

 1
i .i C 1/
i
i C 1

ExŒD  D

D

D

6“mcs-ftl” — 2010/9/8 — 0:40 — page 473 — #479

18.1. Deﬁnitions and Examples

It is true that most of the time, the value of D will be small. But sometimes
D will be very large and this happens with sufﬁcient probability that the expected
value of D is unbounded. In fact, if you keep repeating the experiment, you are
likely to see some outcomes and averages that are much larger than 10 ms.
In
practice, such “outliers” are sometimes discarded, which masks the true behavior
of D .
In general, the best way to compute an expected value in practice is to ﬁrst use
the experimental data to ﬁgure out the distribution as best you can, and then to use
Theorem 18.1.4 or Corollary 18.1.5 to compute its expectation. This method will
help you identify cases where the expectation is inﬁnite, and will generally be more
accurate than a simple averaging of the data.

18.1.7 Conditional Expectation
Just like event probabilities, expectations can be conditioned on some event. Given
a random variable R, the expected value of R conditioned on an event A is the
(probability-weighted) average value of R over outcomes in A. More formally:
Deﬁnition 18.1.6. The conditional expectation ExŒR j A of a random variable R
ExŒR j A WWD X
r (cid:1) Pr (cid:2)R D r j A(cid:3) :
given event A is:
r 2range.R/
For example, we can compute the expected value of a roll of a fair die, given,
for example, that the number rolled is at least 4. We do this by letting R be the
ExŒR j R (cid:21) 4 D 6X
i (cid:1)Pr (cid:2)R D i j R (cid:21) 4(cid:3) D 1(cid:1)0C2(cid:1)0C3(cid:1)0C4(cid:1) 1
outcome of a roll of the die. Then by equation (18.6),
i D1
3
As another example, consider the channel latency problem from Section 18.1.6.
The expected latency for this problem was inﬁnite. But what if we look at the

C6(cid:1) 1
3

(18.6)

C5(cid:1) 1
3

D 5:

7“mcs-ftl” — 2010/9/8 — 0:40 — page 474 — #480

Chapter 18 Expectation

1
i .i C 1/

1X
i Pr (cid:2)D D i j D  n(cid:3)
expected latency conditioned on the latency not exceeding n. Then
ExŒD  D
1X
i D1
PrŒD D i ^ D  n
D
PrŒD  n
D nX
i
i D1
i PrŒD D i 

PrŒD  n
nX
i D1
D
1
PrŒD  n
nX
i D1
1
1
i C 1
PrŒD  n
i D1
.HnC1 (cid:0) 1/;
D
1
PrŒD  n
where HnC1 is the .n C 1/st Harmonic number
C (cid:15) .n/
C 1
HnC1 D ln.n C 1/ C (cid:13) C 1
120n4
12n2
2n
and 0  (cid:15) .n/  1. The second equality follows from the deﬁnition of conditional
expectation, the third equality follows from the fact that PrŒD D i ^ D  n D 0
for i > n, and the fourth equality follows from the deﬁnition of D in Equation 18.5.
To compute PrŒD  n, we observe that
 1

1X
PrŒD  n D 1 (cid:0) PrŒD > n
D 1 (cid:0)
(cid:0) 1
 C  1
D 1 (cid:0)  1
i C 1
i DnC1
i
 C (cid:1) (cid:1) (cid:1) (cid:21)
C  1
(cid:0) 1
(cid:0) 1
n C 3
n C 1
n C 2
n C 2
(cid:0) 1
n C 4
n C 3





i

D

D 1 (cid:0) 1
n C 1
D n
n C 1
:

8“mcs-ftl” — 2010/9/8 — 0:40 — page 475 — #481

18.1. Deﬁnitions and Examples

Hence,

ExŒD  D n C 1
.HnC1 (cid:0) 1/:
(18.7)
n
For n D 1000, this is about 6.5. This explains why the expected value of D appears
to be ﬁnite when you try to evaluate it experimentally. If you compute 100 samples
of D , it is likely that all of them will be at most 1000 ms. If you condition on not
having any outcomes greater than 1000 ms, then the conditional expected value will
be about 6.5 ms, which would be a commonly observed result in practice. Yet we
know that ExŒD  is inﬁnite. For this reason, expectations computed in practice are
often really just conditional expectations where the condition is that rare “outlier”
sample points are eliminated from the analysis.

18.1.8 The Law of Total Expectation
Another useful feature of conditional expectation is that it lets us divide compli-
cated expectation calculations into simpler cases. We can then ﬁnd the desired
expectation by calculating the conditional expectation in each simple case and av-
eraging them, weighing each case by its probability.
For example, suppose that 49.8% of the people in the world are male and the
rest female—which is more or less true. Also suppose the expected height of a
00 , while the expected height of a randomly chosen
0
randomly chosen male is 5
11
0
00 . What is the expected height of a randomly chosen individual? We
female is 5
5
can calculate this by averaging the heights of men and women. Namely, let H be
the height (in feet) of a randomly chosen person, and let M be the event that the
person is male and F the event that the person is female. Then
ExŒH  D ExŒH j M  PrŒM  C ExŒH j F  PrŒF 
D .5 C 11=12/ (cid:1) 0:498 C .5 C 5=12/ (cid:1) 0:502
D 5:665

which is a little less than 5’ 8”.
This method is justiﬁed by the Law of Total Expectation.
Theorem 18.1.7 (Law of Total Expectation). Let R be a random variable on a
ExŒR D X
sample space S and suppose that A1 , A2 , . . . , is a partition of S . Then
ExŒR j Ai  PrŒAi :
i

9“mcs-ftl” — 2010/9/8 — 0:40 — page 476 — #482

Chapter 18 Expectation
ExŒR D X
Proof.
r (cid:1) PrŒR D r 
r (cid:1) X
D X
(cid:3) PrŒAi 
Pr (cid:2)R D r j Ai
r 2range.R/
D X
X
(cid:3) PrŒAi 
r (cid:1) Pr (cid:2)R D r j Ai
r
i
X
D X
(cid:3) PrŒAi 
r (cid:1) Pr (cid:2)R D r j Ai
r
i
D X
X
r (cid:1) Pr (cid:2)R D r j Ai
(cid:3)
r
i
D X
PrŒAi 
r
i
PrŒAi  ExŒR j Ai :
i

(Equation 18.2)

(Law of Total Probability)

(distribute constant r )

(exchange order of summation)

(factor constant PrŒAi )

(Def 18.1.6 of cond. expectation)

(cid:4)

As a more interesting application of the Law of Total Expectation, let’s take
another look at the mean time to failure of a system that fails with probability p at
each step. We’ll deﬁne A to be the event that the system fails on the ﬁrst step and
A to be the complementary event (namely, that the system does not fail on the ﬁrst
step). Then the mean time to failure ExŒC  is
ExŒC  D ExŒC j A PrŒA C ExŒC j A PrŒA:

(18.8)

Since A is the condition that the system crashes on the ﬁrst step, we know that
ExŒC j A D 1:

(18.9)

Since A is the condition that the system does not crash on the ﬁrst step, conditioning
on A is equivalent to taking a ﬁrst step without failure and then starting over without
conditioning. Hence,
ExŒC j A D 1 C ExŒC :
Plugging Equations 18.9 and 18.10 into Equation 18.8, we ﬁnd that
ExŒC  D 1 (cid:1) p C .1 C ExŒC /.1 (cid:0) p /
D p C 1 (cid:0) p C .1 (cid:0) p / ExŒC 
D 1 C .1 (cid:0) p / ExŒC :

(18.10)

10“mcs-ftl” — 2010/9/8 — 0:40 — page 477 — #483

18.2. Expected Returns in Gambling Games

Rearranging terms, we ﬁnd that
1 D ExŒC  (cid:0) .1 (cid:0) p / ExŒC  D p ExŒC ;

and thus that

ExŒC  D 1
p

;

as expected.
We will use this sort of analysis extensively in Chapter 20 when we examine the
expected behavior of random walks.

18.1.9 Expectations of Functions
Expectations can also be deﬁned for functions of random variables.
Deﬁnition 18.1.8. Let R W S ! V be a random variable and f W V ! R be a total
ExŒf .R/ D X
function on the range of R. Then
w 2S
ExŒf .R/ D X
r 2range.R/
(cid:21) D 1
 1
For example, suppose that R is the value obtained by rolling a fair 6-sided die.
Then
R
1

f .r / PrŒR D r :

f .R.w // PrŒw :

Equivalently,

D 49
120

:

(cid:1) 1
6

C 1
4

(cid:1) 1
6

C 1
6

C 1
5

(18.12)

(18.11)

(cid:1) 1
6

Ex

(cid:1) 1
6

C 1
2

(cid:1) 1
6

C 1
3

(cid:1) 1
6

18.2 Expected Returns in Gambling Games

Some of the most interesting examples of expectation can be explained in terms of
gambling games. For straightforward games where you win $A with probability p
and you lose $B with probability 1 (cid:0) p , it is easy to compute your expected return
or winnings. It is simply
pA (cid:0) .1 (cid:0) p /B:
 (cid:1) 1 D 0:
(cid:1) 1 (cid:0) 
For example, if you are ﬂipping a fair coin and you win $1 for heads and you lose $1
for tails, then your expected winnings are
1 (cid:0) 1
2

1

2

11“mcs-ftl” — 2010/9/8 — 0:40 — page 478 — #484

Chapter 18 Expectation

In such cases, the game is said to be fair since your expected return is zero.
Some gambling games are more complicated and thus more interesting. For
example, consider the following game where the winners split a pot. This sort of
game is representative of many poker games, betting pools, and lotteries.

18.2.1 Splitting the Pot
After your last encounter with biker dude, one thing lead to another and you have
dropped out of school and become a Hell’s Angel. It’s late on a Friday night and,
feeling nostalgic for the old days, you drop by your old hangout, where you en-
counter two of your former TAs, Eric and Nick. Eric and Nick propose that you
join them in a simple wager. Each player will put $2 on the bar and secretly write
“heads” or “tails” on their napkin. Then one player will ﬂip a fair coin. The $6 on
the bar will then be divided equally among the players who correctly predicted the
outcome of the coin toss.
After your life-altering encounter with strange dice, you are more than a little
skeptical. So Eric and Nick agree to let you be the one to ﬂip the coin. This
certainly seems fair. How can you lose?
But you have learned your lesson and so before agreeing, you go through the
four-step method and write out the tree diagram to compute your expected return.
The tree diagram is shown in Figure 18.1.
The “payoff ” values in Figure 18.1 are computed by dividing the $6 pot3 among
those players who guessed correctly and then subtracting the $2 that you put into
the pot at the beginning. For example, if all three players guessed correctly, then
you payoff is $0, since you just get back your $2 wager. If you and Nick guess
correctly and Eric guessed wrong, then your payoff is
(cid:0) 2 D 1:

6

2
In the case that everyone is wrong, you all agree to split the pot and so, again, your
payoff is zero.
To compute your expected return, you use Equation 18.1 in the deﬁnition of
expected value. This yields
C 1 (cid:1) 1
ExŒpayoff D 0 (cid:1) 1
8
8
C .(cid:0)2/ (cid:1) 1
8

C 4 (cid:1) 1
C 1 (cid:1) 1
8
8
C .(cid:0)2/ (cid:1) 1
C .(cid:0)2/ (cid:1) 1
8
8

C 0 (cid:1) 1
8

D 0:
3The money invested in a wager is commonly referred to as the pot.

12“mcs-ftl” — 2010/9/8 — 0:40 — page 479 — #485

18.2. Expected Returns in Gambling Games

Figure 18.1 The tree diagram for the game where three players each wager $2
and then guess the outcome of a fair coin toss. The winners split the pot.

you guessright?Eric guessesright?noyesnoyes1=21=21=21=21=21=2yes1=2no1=2yes1=2no1=2yes1=2no1=2yes1=2no1=2yesnoyourpayoff$0$1$1$4�$2�$2�$2$0probability1=81=81=81=81=81=81=81=8Nick guessesright?13“mcs-ftl” — 2010/9/8 — 0:40 — page 480 — #486

Chapter 18 Expectation

This conﬁrms that the game is fair. So, for old time’s sake, you break your solemn
vow to never ever engage in strange gambling games.

18.2.2 The Impact of Collusion
Needless to say, things are not turning out well for you. The more times you play
the game, the more money you seem to be losing. After 1000 wagers, you have lost
over $500. As Nick and Eric are consoling you on your “bad luck,” you do a back-
of-the-napkin calculation using the bounds on the tails of the binomial distribution
from Section 17.5 that suggests that the probability of losing $500 in 1000 wagers
is less than the probability of a Vietnamese Monk waltzing in and handing you one
of those golden disks. How can this be?
It is possible that you are truly very very unlucky. But it is more likely that
something is wrong with the tree diagram in Figure 18.1 and that “something” just
might have something to do with the possibility that Nick and Eric are colluding
against you.
To be sure, Nick and Eric can only guess the outcome of the coin toss with
probability 1=2, but what if Nick and Eric always guess differently? In other words,
what if Nick always guesses “tails” when Eric guesses “heads,” and vice-versa?
This would result in a slightly different tree diagram, as shown in Figure 18.2.
The payoffs for each outcome are the same in Figures 18.1 and 18.2, but the
probabilities of the outcomes are different. For example, it is no longer possible
for all three players to guess correctly, since Nick and Eric are always guessing
differently. More importantly, the outcome where your payoff is $4 is also no
longer possible. Since Nick and Eric are always guessing differently, one of them
will always get a share of the pot. As you might imagine, this is not good for you!
When we use Equation 18.1 to compute your expected return in the collusion
scenario, we ﬁnd that
ExŒpayoff D 0 (cid:1) 0 C 1 (cid:1) 1
C 4 (cid:1) 0
C 1 (cid:1) 1
4
4
C .(cid:0)2/ (cid:1) 0 C .(cid:0)2/ (cid:1) 1
C .(cid:0)2/ (cid:1) 1
4
4
D (cid:0) 1
2
This is very bad indeed. By colluding, Nick and Eric have made it so that you
expect to lose $.50 every time you play. No wonder you lost $500 over the course
of 1000 wagers.
Maybe it would be a good idea to go back to school—your Hell’s Angels buds
may not be too happy that you just lost their $500.

C 0 (cid:1) 0

:

14“mcs-ftl” — 2010/9/8 — 0:40 — page 481 — #487

18.2. Expected Returns in Gambling Games

Figure 18.2 The revised tree diagram reﬂecting the scenario where Nick always
guesses the opposite of Eric.

you guessright?Eric guessesright?noyesnoyes1=21=21=21=21=21=2yes0no1yes1no0yes0no1yes1no0yesnoyourpayoff$0$1$1$4�$2�$2�$2$10probability01=41=4001=41=40Nick guessesright?15“mcs-ftl” — 2010/9/8 — 0:40 — page 482 — #488

Chapter 18 Expectation

18.2.3 How to Win the Lottery
Similar opportunities to “collude” arise in many betting games. For example, con-
sider the typical weekly football betting pool, where each participant wagers $10
and the participants that pick the most games correctly split a large pot. The pool
seems fair if you think of it as in Figure 18.1. But, in fact, if two or more players
collude by guessing differently, they can get an “unfair” advantage at your expense!
In some cases, the collusion is inadvertent and you can proﬁt from it. For ex-
ample, many years ago, a former MIT Professor of Mathematics named Herman
Chernoff ﬁgured out a way to make money by playing the state lottery. This was
surprising since state lotteries typically have very poor expected returns. That’s be-
cause the state usually takes a large share of the wagers before distributing the rest
of the pot among the winners. Hence, anyone who buys a lottery ticket is expected
to lose money. So how did Chernoff ﬁnd a way to make money? It turned out to be
easy!
In a typical state lottery,
(cid:15) all players pay $1 to play and select 4 numbers from 1 to 36,
(cid:15) the state draws 4 numbers from 1 to 36 uniformly at random,
(cid:15) the states divides 1/2 of the money collected among the people who guessed
correctly and spends the other half redecorating the governor’s residence.

This is a lot like the game you played with Nick and Eric, except that there are
more players and more choices. Chernoff discovered that a small set of numbers
was selected by a large fraction of the population. Apparently many people think
the same way; they pick the same numbers not on purpose as in the previous game
with Nick and Eric, but based on Manny’s batting average or today’s date.
It was as if the players were colluding to lose!
If any one of them guessed
correctly, then they’d have to split the pot with many other players. By selecting
numbers uniformly at random, Chernoff was unlikely to get one of these favored
sequences. So if he won, he’d likely get the whole pot! By analyzing actual state
lottery data, he determined that he could win an average of 7 cents on the dollar. In
other words, his expected return was not (cid:0)$:50 as you might think, but C$:07.4
Inadvertent collusion often arises in betting pools and is a phenomenon that you
can take advantage of. For example, suppose you enter a Super Bowl betting pool
where the goal is to get closest to the total number of points scored in the game.
Also suppose that the average Super Bowl has a total of 30 point scored and that

4Most lotteries now offer randomized tickets to help smooth out the distribution of selected se-
quences.

16“mcs-ftl” — 2010/9/8 — 0:40 — page 483 — #489

18.3. Expectations of Sums

everyone knows this. Then most people will guess around 30 points. Where should
you guess? Well, you should guess just outside of this range because you get to
cover a lot more ground and you don’t share the pot if you win. Of course, if you
are in a pool with math students and they all know this strategy, then maybe you
should guess 30 points after all.

18.3 Expectations of Sums

18.3.1 Linearity of Expectation
Expected values obey a simple, very helpful rule called Linearity of Expectation.
Its simplest form says that the expected value of a sum of random variables is the
sum of the expected values of the variables.
Theorem 18.3.1. For any random variables R1 and R2 ,
ExŒR1 C R2  D ExŒR1  C ExŒR2 :
Proof. Let T WWD R1 C R2 . The proof follows straightforwardly by rearranging
ExŒT  D X
terms in Equation (18.1):
T .! / (cid:1) PrŒ! 
D X
!2S
.R1 .! / C R2 .! // (cid:1) PrŒ! 
D X
R1 .! / PrŒ!  C X
!2S
!2S
!2S
D ExŒR1  C ExŒR2 :
(Deﬁnition 18.1.1)
A small extension of this proof, which we leave to the reader, implies
Theorem 18.3.2. For random variables R1 , R2 and constants a1 ; a2 2 R,
ExŒa1R1 C a2R2  D a1 ExŒR1  C a2 ExŒR2 :
In other words, expectation is a linear function. A routine induction extends the
result to more than two variables:
Corollary 18.3.3 (Linearity of Expectation). For any random variables R1 ; : : : ; Rk
and constants a1 ; : : : ; ak 2 R,
ai Ri  D kX
kX
ExŒ
i D1
i D1

(rearranging terms)

R2 .! / PrŒ! 

ai ExŒRi :

(Deﬁnition 18.1.1)

(deﬁnition of T )

(cid:4)

17“mcs-ftl” — 2010/9/8 — 0:40 — page 484 — #490

Chapter 18 Expectation

The great thing about linearity of expectation is that no independence is required.
This is really useful, because dealing with independence is a pain, and we often
need to work with random variables that are not known to be independent.
As an example, let’s compute the expected value of the sum of two fair dice. Let
the random variable R1 be the number on the ﬁrst die, and let R2 be the number on
the second die. We observed earlier that the expected value of one die is 3.5. We
can ﬁnd the expected value of the sum using linearity of expectation:
ExŒR1 C R2  D ExŒR1  C ExŒR2  D 3:5 C 3:5 D 7:
Notice that we did not have to assume that the two dice were independent. The
expected sum of two dice is 7, even if they are glued together (provided each indi-
vidual die remains fair after the gluing). Proving that this expected sum is 7 with a
tree diagram would be a bother: there are 36 cases. And if we did not assume that
the dice were independent, the job would be really tough!

18.3.2 Sums of Indicator Random Variables
Linearity of expectation is especially useful when you have a sum of indicator ran-
dom variables. As an example, suppose there is a dinner party where n men check
their hats. The hats are mixed up during dinner, so that afterward each man receives
a random hat. In particular, each man gets his own hat with probability 1=n. What
is the expected number of men who get their own hat?
Letting G be the number of men that get their own hat, we want to ﬁnd the
expectation of G . But all we know about G is that the probability that a man gets
his own hat back is 1=n. There are many different probability distributions of hat
permutations with this property, so we don’t know enough about the distribution
of G to calculate its expectation directly. But linearity of expectation makes the
problem really easy.
The trick5 is to express G as a sum of indicator variables. In particular, let Gi be
an indicator for the event that the i th man gets his own hat. That is, Gi D 1 if the
i th man gets his own hat, and Gi D 0 otherwise. The number of men that get their
own hat is then the sum of these indicator random variables:
G D G1 C G2 C (cid:1) (cid:1) (cid:1) C Gn :
(18.13)
These indicator variables are not mutually independent. For example, if n (cid:0) 1 men
all get their own hats, then the last man is certain to receive his own hat. But, since
we plan to use linearity of expectation, we don’t have worry about independence!

5We are going to use this trick a lot so it is important to understand it.

18“mcs-ftl” — 2010/9/8 — 0:40 — page 485 — #491

18.3. Expectations of Sums

(18.14)

C 1
n

PrŒAi :

Since Gi is an indicator random variable, we know from Lemma 18.1.3 that
ExŒGi  D PrŒGi D 1 D 1=n:
By Linearity of Expectation and Equation 18.13, this means that
ExŒG  D ExŒG1 C G2 C (cid:1) (cid:1) (cid:1) C Gn 
D ExŒG1  C ExŒG2  C (cid:1) (cid:1) (cid:1) C ExŒGn 
…„
‚
ƒ
n
D
C (cid:1) (cid:1) (cid:1) C 1
1
n
n
D 1:
So even though we don’t know much about how hats are scrambled, we’ve ﬁgured
out that on average, just one man gets his own hat back!
More generally, Linearity of Expectation provides a very good method for com-
puting the expected number of events that will happen.
Theorem 18.3.4. Given any collection of n events A1 ; A2 ; : : : ; An  S , the ex-
nX
pected number of events that will occur is
i D1
For example, Ai could be the event that the i th man gets the right hat back. But
in general, it could be any subset of the sample space, and we are asking for the
expected number of events that will contain a random sample point.
Proof. Deﬁne Ri to be the indicator random variable for Ai , where Ri .w / D 1 if
w 2 Ai and Ri .w / D 0 if w … Ai . Let R D R1 C R2 C (cid:1) (cid:1) (cid:1) C Rn . Then
ExŒR D nX
D nX
i D1
D nX
i D1
D nX
i D1
i D1

PrŒRi D 1
X
w 2Ai

(by Linearity of Expectation)

PrŒw 

(deﬁnition of indicator variable)

ExŒRi 

PrŒAi :

(by Lemma 18.1.3)

(cid:4)

19“mcs-ftl” — 2010/9/8 — 0:40 — page 486 — #492

Chapter 18 Expectation

So whenever you are asked for the expected number of events that occur, all you
have to do is sum the probabilities that each event occurs. Independence is not
needed.

n

k

18.3.3 Expectation of a Binomial Distribution
Suppose that we independently ﬂip n biased coins, each with probability p of com-
ing up heads. What is the expected number of heads?
Let J be the random variable denoting the number of heads. Then J has a
 
!
binomial distribution with parameters n, p , and
kp .n (cid:0) k /1(cid:0)p :

PrŒJ D k  D
ExŒJ  D nX
Applying Equation 18.2, this means that
k PrŒJ D k 
 
!
D nX
kD0
kD0
Ouch! This is one nasty looking sum. Let’s try another approach.
Since we have just learned about linearity of expectation for sums of indicator
random variables, maybe Theorem 18.3.4 will be helpful. But how do we express J
as a sum of indicator random variables? It turns out to be easy. Let Ji be the
(
indicator random variable for the i th coin. In particular, deﬁne
Ji D

kp .n (cid:0) k /1(cid:0)p :

1 if the i th coin is heads
0 if the i th coin is tails:

(18.15)

k

n

k

By Theorem 18.3.4,

Then the number of heads is simply
J D J1 C J2 C (cid:1) (cid:1) (cid:1) C Jn :
ExŒJ  D nX
i D1
D np:

PrŒJi 

(18.16)

20“mcs-ftl” — 2010/9/8 — 0:40 — page 487 — #493

18.3. Expectations of Sums

That really was easy. If we ﬂip n mutually independent coins, we expect to get
p n heads. Hence the expected value of a binomial distribution with parameters n
and p is simply p n.
But what if the coins are not mutually independent? It doesn’t matter—the an-
swer is still p n because Linearity of Expectation and Theorem 18.3.4 do not as-
sume any independence.
If you are not yet convinced that Linearity of Expectation and Theorem 18.3.4
 
!
are powerful tools, consider this: without even trying, we have used them to prove
nX
a very complicated identity, namely6
kp .n (cid:0) k /1(cid:0)p D p n:
kD0
If you are still not convinced, then take a look at the next problem.

n

k

k

18.3.4 The Coupon Collector Problem
Every time we purchase a kid’s meal at Taco Bell, we are graciously presented with
a miniature “Racin’ Rocket” car together with a launching device which enables us
to project our new vehicle across any tabletop or smooth ﬂoor at high velocity.
Truly, our delight knows no bounds.
There are n different types of Racin’ Rocket cars (blue, green, red, gray, etc.).
The type of car awarded to us each day by the kind woman at the Taco Bell reg-
ister appears to be selected uniformly and independently at random. What is the
expected number of kid’s meals that we must purchase in order to acquire at least
one of each type of Racin’ Rocket car?
The same mathematical question shows up in many guises: for example, what
is the expected number of people you must poll in order to ﬁnd at least one person
with each possible birthday? Here, instead of collecting Racin’ Rocket cars, you’re
collecting birthdays. The general question is commonly called the coupon collector
problem after yet another interpretation.
A clever application of linearity of expectation leads to a simple solution to the
coupon collector problem. Suppose there are ﬁve different types of Racin’ Rocket
cars, and we receive this sequence:
blue
green
green
red
blue
orange
Let’s partition the sequence into 5 segments:
„ ƒ‚ …
green„ƒ‚…
blue„ƒ‚…
„
ƒ‚
…
red
green
orange
blue
X1
X0
X2
X3
6This follows by combining Equations 18.15 and 18.16.

orange
ƒ‚
orange
X4

gray.
…
gray

blue
„
blue

:

21“mcs-ftl” — 2010/9/8 — 0:40 — page 488 — #494

Chapter 18 Expectation

The rule is that a segment ends whenever we get a new kind of car. For example, the
middle segment ends when we get a red car for the ﬁrst time. In this way, we can
break the problem of collecting every type of car into stages. Then we can analyze
each stage individually and assemble the results using linearity of expectation.
Let’s return to the general case where we’re collecting n Racin’ Rockets. Let
Xk be the length of the k th segment. The total number of kid’s meals we must
purchase to get all n Racin’ Rockets is the sum of the lengths of all these segments:
T D X0 C X1 C (cid:1) (cid:1) (cid:1) C Xn(cid:0)1
Now let’s focus our attention on Xk , the length of the k th segment. At the
beginning of segment k , we have k different types of car, and the segment ends
when we acquire a new type. When we own k types, each kid’s meal contains a
type that we already have with probability k=n. Therefore, each meal contains a
new type of car with probability 1 (cid:0) k=n D .n (cid:0) k /=n. Thus, the expected number
of meals until we get a new kind of car is n=.n (cid:0) k / by the “mean time to failure”
formula in Equation 18.4. This means that
ExŒXk  D n
n (cid:0) k
Linearity of expectation, together with this observation, solves the coupon col-
lector problem:

:

ExŒT  D ExŒX0 C X1 C (cid:1) (cid:1) (cid:1) C Xn(cid:0)1 
D ExŒX0  C ExŒX1  C (cid:1) (cid:1) (cid:1) C ExŒXn(cid:0)1 
 1

C n
C (cid:1) (cid:1) (cid:1) C n
C n
C n
D n
n (cid:0) 1
n (cid:0) 0
1
2
3
 1

D n
C 1
C 1
C (cid:1) (cid:1) (cid:1) C 1
C 1
n (cid:0) 1
n
3
2
1
D n
C 1
C (cid:1) (cid:1) (cid:1) C 1
C 1
C 1
n (cid:0) 1
1
2
3
n
D nHn
(cid:24) n ln n:
Wow! It’s those Harmonic Numbers again!
We can use Equation 18.18 to answer some concrete questions. For example, the
expected number of die rolls required to see every number from 1 to 6 is:
6H6 D 14 :7 : : : :

(18.17)
(18.18)

22“mcs-ftl” — 2010/9/8 — 0:40 — page 489 — #495

18.3. Expectations of Sums

And the expected number of people you must poll to ﬁnd at least one person with
each possible birthday is:

365H365 D 2364 :6 : : : :

Ex

D

Ri

ExŒRi :

18.3.5
Inﬁnite Sums
Linearity of expectation also works for an inﬁnite number of random variables
provided that the variables satisfy some stringent absolute convergence criteria.
1X
Theorem 18.3.5 (Linearity of Expectation). Let R0 , R1 , . . . , be random variables
such that
ExŒjRi j
" 1X
#
i D0
1X
i D0
i D0

converges. Then
Proof. Let T WWD P1
i D0 Ri .
We leave it to the reader to verify that, under the given convergence hypothesis,
all the sums in the following derivation are absolutely convergent, which justiﬁes
1X
X
1X
rearranging them as follows:
ExŒRi  D
Ri .s / (cid:1) PrŒs 
D X
1X
s2S
i D0
i D0
Ri .s / (cid:1) PrŒs 
#
" 1X
D X
s2S
i D0
D X
Ri .s /
s2S
i D0
T .s / (cid:1) PrŒs 
s2S
1X
D ExŒT 
D ExŒ
i D0

(exchanging order of summation)

(Def. of T ): (cid:4)

(factoring out PrŒs )

(cid:1) PrŒs 

(Def. 18.1.1)

(Def. of T )

(Def. 18.1.1)

Ri :

23“mcs-ftl” — 2010/9/8 — 0:40 — page 490 — #496

Chapter 18 Expectation

18.4 Expectations of Products

While the expectation of a sum is the sum of the expectations, the same is usually
not true for products. For example, suppose that we roll a fair 6-sided die and
denote the outcome with the random variable R. Does ExŒR (cid:1) R D ExŒR (cid:1) ExŒR?
We know that ExŒR D 3 1
2 and thus ExŒR2 D 12 1
4 . Let’s compute ExŒR2  to
ExŒR2  D X
see if we get the same result.
D 6X
w 2S
i 2 (cid:1) PrŒRi D i 
i D1
C 22
D 12
6
6
D 15 1=6
¤ 12 1=4 :

R2 .w / PrŒw 

C 32
6

C 42
6

C 52
6

C 62
6

Hence,

ExŒR (cid:1) R ¤ ExŒR (cid:1) ExŒR
and so the expectation of a product is not always equal to the product of the expec-
tations.
There is a special case when such a relationship does hold however; namely,
when the random variables in the product are independent.

Theorem 18.4.1. For any two independent random variables R1 , R2 ,
ExŒR1 (cid:1) R2  D ExŒR1  (cid:1) ExŒR2 :
Proof. The event ŒR1 (cid:1) R2 D r  can be split up into events of the form ŒR1 D

24“mcs-ftl” — 2010/9/8 — 0:40 — page 491 — #497

(Theorem 18.1.4)

18.4. Expectations of Products
r1 and R2 D r2  where r1 (cid:1) r2 D r . So
D X
ExŒR1 (cid:1) R2 
r (cid:1) PrŒR1 (cid:1) R2 D r 
D X
X
r 2range.R1 (cid:1)R2 /
r1 r2 (cid:1) PrŒR1 D r1 and R2 D r2 
D X
X
r12range.R1 /
r22range.R2 /
r1 r2 (cid:1) PrŒR1 D r1  (cid:1) PrŒR2 D r2 
0@ X
1A (factor out r1 PrŒR1 D r1 )
(independence of R1 ; R2 )
r12range.R1 /
r22range.R2 /
D X
r1 PrŒR1 D r1 
r2 PrŒR2 D r2 
D X
r12range.R1 /
r22range.R2 /
r1 PrŒR1 D r1  (cid:1) ExŒR2 
0@ X
1A
(Theorem 18.1.4)
r12range.R1 /
D ExŒR2 
r1 PrŒR1 D r1 
r12range.R1 /
D ExŒR2  (cid:1) ExŒR1 :

(factor out ExŒR2 )

(Theorem 18.1.4)
(cid:4)

For example, let R1 and R2 be random variables denoting the result of rolling
two independent and fair 6-sided dice. Then
ExŒR1 (cid:1) R2  D ExŒR1  ExŒR2  D 3

2
2
4
Theorem 18.4.1 extends by induction to a collection of mutually independent
random variables.
35 D kY
24 kY
Corollary 18.4.2. If random variables R1 ; R2 ; : : : ; Rk are mutually independent,
then
i D1
i D1

D 12

ExŒRi :

1

:

Ex

1

(cid:1) 3

1

Ri

25“mcs-ftl” — 2010/9/8 — 0:40 — page 492 — #498

Chapter 18 Expectation

18.5 Expectations of Quotients

If S and T are random variables, we know from Linearity of Expectation that
ExŒS C T  D ExŒS  C ExŒT :

If S and T are independent, we know from Theorem 18.4.1 that
ExŒS T  D ExŒS  ExŒT :

Is it also true that

ExŒS = T  D ExŒS = ExŒT ‹
(18.19)
Of course, we have to worry about the situation when ExŒT  D 0, but what if we
assume that T is always positive? As we will soon see, Equation 18.19 is usually
not true, but let’s see if we can prove it anyway.

False Claim 18.5.1. If S and T are independent random variables with T > 0,
then
ExŒS = T  D ExŒS = ExŒT :

(18.20)

Bogus proof.

ExŒ

S

T

 1
T
1
ExŒT 

 D ExŒS (cid:1) 1

T
D ExŒS  (cid:1) Ex
D ExŒS  (cid:1)
D ExŒS 
ExŒT 

:

(cid:21)

:

(cid:4)

(independence of S and T )

(18.21)

(18.22)

Note that line 18.21 uses the fact that if S and T are independent, then so are
S and 1= T . This holds because functions of independent random variables are
independent. It is a fact that needs proof, which we will leave to the reader, but it
is not the bug. The bug is in line (18.22), which assumes

False Claim 18.5.2.

ExŒ

 D 1
ExŒT 

:

1

T

26“mcs-ftl” — 2010/9/8 — 0:40 — page 493 — #499

18.5. Expectations of Quotients

Benchmark
E-string search
F-bit test
Ackerman
Rec 2-sort
Average

RISC CISC CISC/RISC
0.8
120
150
1.5
180
120
150
300
2.0
0.5
1400
2800
1.2

Table 18.1 Sample program lengths for benchmark problems using RISC and
CISC compilers.

Here is a counterexample. Deﬁne T so that
PrŒT D 1 D 1
PrŒT D 2 D 1
2
2

and

:

Then

and

and

1
ExŒT 

D 2
3

D 3
2

C 2 (cid:1) 1
2

ExŒT  D 1 (cid:1) 1
2
(cid:21) D 1
 1
¤
D 3
(cid:1) 1
C 1
(cid:1) 1
1
Ex
:
ExŒ1= T 
4
2
2
T
1
2
This means that Claim 18.5.1 is also false since we could deﬁne S D 1 with prob-
ability 1. In fact, both Claims 18.5.1 and 18.5.2 are untrue for most all choices of
S and T . Unfortunately, the fact that they are false does not keep them from being
widely used in practice! Let’s see an example.

18.5.1 A RISC Paradox
The data in Table 18.1 is representative of data in a paper by some famous pro-
fessors. They wanted to show that programs on a RISC processor are generally
shorter than programs on a CISC processor. For this purpose, they applied a RISC
compiler and then a CISC compiler to some benchmark source programs and made
a table of compiled program lengths.
Each row in Table 18.1 contains the data for one benchmark. The numbers in
the second and third columns are program lengths for each type of compiler. The
fourth column contains the ratio of the CISC program length to the RISC program
length. Averaging this ratio over all benchmarks gives the value 1.2 in the lower
right. The conclusion is that CISC programs are 20% longer on average.

27“mcs-ftl” — 2010/9/8 — 0:40 — page 494 — #500

Chapter 18 Expectation

Benchmark
E-string search
F-bit test
Ackerman
Rec 2-sort
Average

RISC CISC RISC/CISC
1.25
120
150
0.67
180
120
150
300
0.5
2.0
1400
2800
1.1

Table 18.2 The same data as in Table 18.1, but with the opposite ratio in the last
column.

However, some critics of their paper took the same data and argued this way:
redo the ﬁnal column, taking the other ratio, RISC/CISC instead of CISC/RISC, as
shown in Table 18.2.
From Table 18.2, we would conclude that RISC programs are 10% longer than
CISC programs on average! We are using the same reasoning as in the paper, so
this conclusion is equally justiﬁable—yet the result is opposite. What is going on?

A Probabilistic Interpretation
To resolve these contradictory conclusions, we can model the RISC vs. CISC de-
bate with the machinery of probability theory.
Let the sample space be the set of benchmark programs. Let the random variable
R be the length of the compiled RISC program, and let the random variable C be
the length of the compiled CISC program. We would like to compare the average
length ExŒR of a RISC program to the average length ExŒC  of a CISC program.
To compare average program lengths, we must assign a probability to each sam-
ple point; in effect, this assigns a “weight” to each benchmark. One might like
to weigh benchmarks based on how frequently similar programs arise in practice.
Lacking such data, however, we will assign all benchmarks equal weight; that is,
our sample space is uniform.
In terms of our probability model, the paper computes C =R for each sample
point, and then averages to obtain ExŒC =R D 1:2. This much is correct. The
authors then conclude that CISC programs are 20% longer on average; that is, they
conclude that ExŒC  D 1:2 ExŒR. Therein lies the problem. The authors have
implicitly used False Claim 18.5.1 to assume that ExŒC =R D ExŒC = ExŒR. By
using the same false logic, the critics can arrive at the opposite conclusion; namely,
that RISC programs are 10% longer on average.

28“mcs-ftl” — 2010/9/8 — 0:40 — page 495 — #501

18.5. Expectations of Quotients

The Proper Quotient
ExŒR D X
We can compute ExŒR and ExŒC  as follows:
i (cid:1) PrŒR D i 
i 2Range(R)
C 120
D 150
4
4
D 805;
ExŒC  D X
i 2Range(C)
D 120
C 180
4
4
D 500
Now since ExŒR= ExŒC  D 1:61, we conclude that the average RISC program
is 61% longer than the average CISC program. This is a third answer, completely
different from the other two! Furthermore, this answer makes RISC look really
bad in terms of code length. This one is the correct conclusion, under our assump-
tion that the benchmarks deserve equal weight. Neither of the earlier results were
correct—not surprising since both were based on the same False Claim.

i (cid:1) PrŒC D i 

C 1400
4

C 150
4

C 2800
4

C 300
4

A Simpler Example
The source of the problem is clearer in the following, simpler example. Suppose
the data were as follows.
Benchmark Processor A Processor B B=A A=B
1/2
1
2
Problem 1
2
1/2
Problem 2
1
2
2
1.25
1.25
Average

Now the data for the processors A and B is exactly symmetric; the two proces-
sors are equivalent. Yet, from the third column we would conclude that Processor B
programs are 25% longer on average, and from the fourth column we would con-
clude that Processor A programs are 25% longer on average. Both conclusions are
obviously wrong.
The moral is that one must be very careful in summarizing data, we must not
take an average of ratios blindly!

29“mcs-ftl” — 2010/9/8 — 0:40 — page 496 — #502

30MIT OpenCourseWare
http://ocw.mit.edu 

6.042J / 18.062J Mathematics for Computer Science 
Fall 2010 

For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms . 

